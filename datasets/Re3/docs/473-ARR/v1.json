{
    "nodes": [
        {
            "ix": "473-ARR_v1_0",
            "content": "Multitasking Framework for Unsupervised Simple Definition Generation",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_2",
            "content": "The definition generation task can help language learners by providing explanations for unfamiliar words. This task has attracted much attention in recent years. We propose a novel task of Simple Definition Generation (SDG) to help language learners and low literacy readers better. A significant challenge of this task is the lack of learner's dictionaries in many languages, and therefore the lack of data for supervised training. We explore this task and propose a multitasking framework SimpDefiner that only requires a standard dictionary with complex definitions and a corpus containing arbitrary simple texts. We disentangle the complexity factors from the text by carefully designing a parameter sharing scheme between the components. By joint training these components, the framework can generate both complex and simple definitions simultaneously. We demonstrate that the framework can generate relevant, simple definitions for the target words through automatic and manual evaluations on English and Chinese datasets. Our method outperforms the baseline model by a 1.6 SARI score on the English dataset, and the low level (HSK level 1-3) words in Chinese definitions raised by 5.03%.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "473-ARR_v1_4",
            "content": "Helping language learners understand words in doubt is an important topic in the field of Intelligent Computer-Assisted Language Learning (ICALL) (Segler et al., 2002;Enayati and Gilakjani, 2020;Lolita et al., 2020). In recent years, researchers attempted to automatically generate definitions for words rather than formulating predefined worddefinition inventories (Ishiwatari et al., 2019;Yang et al., 2020;Huang et al., 2021). There are two reasons for this. Firstly, it can be difficult for users to distinguish which sense is appropriate in the current context because of the cognitively inaccurate nature of discrete sense boundaries (Rosch and Mervis, 1975;Kilgarriff, 1997;Tyler and Evans, a notice, picture or film telling people about a product, job or service.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_5",
            "content": "Simple definition in OALD a notice or announcement in a public medium promoting a product, service, or event or publicizing a job vacancy. 2001). Secondly, the predefined inventories need to be updated manually by lexicographers, which is time-consuming and causes dictionaries to lag behind the ever-changing language usage.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_6",
            "content": "Different from previous work (Noraset et al., 2017;Gadetsky et al., 2018;Mickus et al., 2019;Kong et al., 2020) that focused only on how to generate definitions, we further propose a novel task of Simple Definition Generation (SDG). Make the definitions easier to read and understand could benefit the language learners, low literacy readers, as well as helping people with aphasia or dyslexia. For example, compared with the Oxford Dictionary (OD), the Oxford Advanced Learner's Dictionary (OALD) has simpler definitions, which is specifically designed for language learners. As shown in Figure 1, the definition of the word advertisement in OALD does not contain difficult words or phrases such as announcement and public medium.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_7",
            "content": "The goal of SDG task is to generate simple definitions for languages that lack learner's dictionary. For example, Chinese as Second Language (CSL) learners do not have suitable dictionaries. As Zhang (2011) pointed out, since the difficulty of definitions is not considered, the existing dictionary cannot meet CSL learner's needs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_8",
            "content": "The SDG task is challenging because it requires a model to learn from a standard dictionary containing complex definitions and then generate simple ones, and hence fully unsupervised. A seemingly feasible solution is to generate definitions first and then simplify them, i.e., the generationsimplification pipeline. However, the simplification task requires dataset with complex-simple sentence pairs, and such data is also difficult to find in languages other than English (Martin et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_9",
            "content": "Besides, the pipeline methods do not perform well due to accumulated errors (Section 6.1).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_10",
            "content": "To solve this dilemma and bridge the gap between practical needs for simple definitions and current trivial definition generation systems, we present a novel method for the SDG task. As illustrated in Figure 2, our method leverages a multitasking framework SimpDefiner to generate simple definitions by performing three sub-tasks at the same time, which are definition generation, text reconstruction, and language modeling tasks. The framework consists of a fully shared encoder and two partially shared decoders. We disentangle the complexity factors from the text by designing a parameter sharing scheme. Particularly, we share parameters in Complexity-Dependent Layer Normalization and Complexity-Dependent Query Projection of the transformer architecture (Vaswani et al., 2017) to control the complexity (Section 3.3). Through joint learning and sharing parameters between the decoders, the SimpDefiner is able to generate complex and simple definitions simultaneously.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_11",
            "content": "Main contributions of our paper are listed below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_12",
            "content": "\u2022 For the first time, we propose the task of SDG to generate simple definitions without supervised training data. \u2022 We propose a multitasking framework Sim-pDefiner to tackle this task. Through joint training three sub-tasks, the framework can generate complex and simple definitions simultaneously. \u2022 Both automatic and manual evaluations demonstrate the effectiveness of SimpDefiner. The framework outperforms the baseline model by 1.9 SARI score on the English test set. And the proportion of low level words (HSK level 1-3) in generated definitions raised by 5.03% on the Chinese test set. 2 Related Work",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_13",
            "content": "Definition Generation",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "473-ARR_v1_14",
            "content": "The definition generation task is first introduced by Noraset et al. (2017). Although this task is proposed as a potentially useful tool for explainable AI, many subsequent works believe that it can assist language learning by giving definitions for words in the text (Ishiwatari et al., 2019;Mickus et al., 2019;Yang et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_15",
            "content": "Various studies attempted to generate multiple different definitions for polysemous words. Gadetsky et al. (2018) tackled this problem by computing the AdaGram vectors (Bartunov et al., 2016) of input words, which is capable to learn different representations at desired semantic resolution. However, generating different definitions based on contexts, i.e., example sentences, became the mainstream method (Chang et al., 2018;Reid et al., 2020;Li et al., 2020;Bevilacqua et al., 2020). Among them, some studies used pre-trained language models to obtain contextualized embeddings. Reid et al. (2020) initialized encoders with BERT (Devlin et al., 2019) and employed variational inference for estimation and leverage contextualized word embeddings for improved performance. Bevilacqua et al. (2020) employed a novel span-based encoding scheme to fine-tune a pre-trained English encoderdecoder system to generate definitions. Huang et al. (2021) leveraged the T5 (Raffel et al., 2019) model for this task and introduced a re-ranking mechanism to model specificity in definitions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_16",
            "content": "Our proposed SimpDefiner also takes the given word and context as input. Differently, our main focus is to generate definitions with appropriate complexity to better help language learners. Besides, our model is based on MASS (Song et al., 2019), which is a pre-trained encoder-decoder model and is more suitable for generation tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_17",
            "content": "Sentence Simplification",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "473-ARR_v1_18",
            "content": "Researchers usually regard the sentence simplification task as a monolingual variant of machine translation (MT) (Wubben et al., 2012). Benefiting from the advancement of neural machine translation, this task has also made great progress in recent years.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_19",
            "content": "Lately, many works built upon the Seq2Seq MT model (Sutskever et al., 2014) performed well. First attempted by Nisioi et al. (2017), the Seq2Seq models for this task are able to perform lexical simplification and content reduction simultaneously by training on complex-simple sentence pairs. This method was inherited and improved by many subsequent works, such as combining with the reinforcement learning method by setting a simplification reward (Zhang and Lapata, 2017), augmenting memory capacities (Vu et al., 2018) or training with multitasking on entailment and paraphrase generation (Guo et al., 2018). Martin et al. (2019) proposed to prepend additional prompt tokens to source sentences at train time, which enable the end-users to condition the simplifications returned by the model on attributes like length, lexical complexity, and syntactic complexity. This controllable simplification system (called ACCESS) and its improved version MUSS (Martin et al., 2020) achieved SOTA results on the Turk corpus in terms of the SARI metric (Xu et al., 2016).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_20",
            "content": "The generation-simplification pipeline methods are used as baselines of the SDG task, and we use both ACCESS and MUSS models for the simplification. Unlike the baseline, the SimpDefiner can simultaneously generate complex and simple definitions without the need for aligned complex-simple sentence pairs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_21",
            "content": "Unsupervised Style Transfer",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "473-ARR_v1_22",
            "content": "Style transfer aims to change the style attributes while preserving the content. Our work is related to unsupervised style transfer by regarding the text complexity as one of the style attributes (Kawashima and Takagi, 2019). Dumoulin et al. (2017) demonstrated that the neural networks can capture the artistic style of a diversity of paintings. The authors discovered that adjusting parameters in the layer normalization mechanism leads to different artistic styles. This method permits users to transform images to arbitrary styles learned from individual paintings. Jin et al. (2020) successfully applied this method to the task of headline generation, allowing the model to generate headlines of a specific style, such as humorous, romantic or click-baity, in an unsupervised manner.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_23",
            "content": "By treating the task of simplification as a variant of style transfer, we borrow the insight of learning complexity-dependent parameters in the Layer Normalization mechanism. Additionally, we introduce the language modeling task into SimpDefiner, which is to enhance the decoder and make it more sensitive to text complexity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_24",
            "content": "Method",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "473-ARR_v1_25",
            "content": "We integrate three sub-tasks of definition generation, text reconstruction, and language modeling into the SimpDefiner. This section first gives a formal definition of the SDG task, then introduces each sub-task, and finally the parameter sharing scheme.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_26",
            "content": "Task Formulation",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "473-ARR_v1_27",
            "content": "The SDG task consists in generating a simple definition d sim for a given word and context (w * , c), where c = [w 1 , . . . , w * , . . . , w n ] is a sentence containing w * . This task is challenging because there is no corpus like {(w * i , c i , d sim i )} N i=1 and hence fully unsupervised.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_28",
            "content": "The only data available in this work include a standard dictionary dataset G",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_29",
            "content": "= {(w * i , c i , d com i )} N i=1 and a simple text corpus Y = {y i } M",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_30",
            "content": "i=1 . Note that we use d com for complex definitions and d sim for simple ones.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_31",
            "content": "Multitasking Framework",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "473-ARR_v1_32",
            "content": "We design the three sub-tasks in the SimpDefiner to learn different abilities. Cooperating with each other, the entire framework obtains the ability to compute the conditional probability P (d sim |w * , c) of simple definitions in a zero-shot manner.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_33",
            "content": "Specifically, the definition generation task aims to model the probability of a complex definition given the word and context P (d com |w * , c) (Section 3.2.1). And the text reconstruction task aims to model the probability of a simple sentence given the corrupted version P (y| \u1ef9) (Section 3.2.2). As we can see, neither task can directly get the P (d sim |w * , c). To solve the problem, we attempt to disentangle the complexity factors from the text by sharing parameters between the generation and reconstruction decoders. This scheme shares semantic information between decoders, while keeping complexity information independent. In the inference stage, we obtain a simple definition by feeding the encoded hidden state into the reconstruction decoder as in Figure 2. The detailed parameter sharing scheme is in Section 3.3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_34",
            "content": "Nevertheless, the complexity information may still be kept in some shared parameters, resulting in the reconstruction decoder fail to generate simple definitions occasionally. Eliminating the complexity information in all shared parameters is obviously technically impossible. Instead, we introduce the language modeling task (Section 3.2.3) to enhance the reconstruction decoder and make it more focusd on simple text generation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_35",
            "content": "Definition Generation Task",
            "ntype": "title",
            "meta": {
                "section": "3.2.1"
            }
        },
        {
            "ix": "473-ARR_v1_36",
            "content": "We follow the mainstream method (Yang et al., 2020;Kong et al., 2020;Reid et al., 2020) to concatenate the word and context together with a special token [SEP] as x = (w * ; [SEP]; c). The entire sequence is then fed into SimpDefiner, and the definition is obtained by the following language model:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_37",
            "content": "P (d com |x; \u03b8) = t P (d com t |d com <t , x; \u03b8) ,(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_38",
            "content": "where d com t is the t-th token of the definition, and \u03b8 is the set of parameters. The model is optimized using the following loss function:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_39",
            "content": "L gen (\u03b8) = \u2212 (x,d com )\u2208G log P (d com |x; \u03b8). (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_40",
            "content": "Text Reconstruction Task",
            "ntype": "title",
            "meta": {
                "section": "3.2.2"
            }
        },
        {
            "ix": "473-ARR_v1_41",
            "content": "We corrupt each sentence in the corpus Y by randomly deleting or blanking some words and shuffling the word orders. And then we obtain a new corpus \u1ef8 = {( \u1ef9i , y i )} M i=1 . The \u1ef9 is a corrupted version of y by randomly deleting or blanking some words and shuffling the word orders. We input \u1ef9 into SimpDefiner and obtain y by solving a self-supervised task of",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_42",
            "content": "P (y| \u1ef9; \u03b8) = t P (y t |y <t , \u1ef9; \u03b8) ,(3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_43",
            "content": "where y t is the t-th token of the sentence, and \u03b8 is a set of parameters. The loss function of this task is as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_44",
            "content": "L rec (\u03b8) = \u2212 M (y, \u1ef9)\u2208",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_45",
            "content": "\u1ef8 log P (y| \u1ef9; \u03b8).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_46",
            "content": "(4)",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_47",
            "content": "Language Modeling Task",
            "ntype": "title",
            "meta": {
                "section": "3.2.3"
            }
        },
        {
            "ix": "473-ARR_v1_48",
            "content": "This task facilitates zero-shot generation of P (d sim |x) by jointly training the reconstruction decoder as a language model. Once the model captures correct complexity that guides the model to generate the desired simple texts, it's more likely for the model to ignore the wrongly shared complexity information. Similar to Eq. 3, we have:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_49",
            "content": "P (y|\u03b8) = t P (y t |y <t ; \u03b8) .(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_50",
            "content": "It is equivalent to masking the encoder out and ignoring the attention modules between the encoder and reconstruction decoder. The model is optimized by the following loss function:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_51",
            "content": "L lm (\u03b8) = \u2212 y\u2208Y log P (y|\u03b8).(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_52",
            "content": "Finally, we train the entire SimpDefiner by jointly minimizing the weighted sum of all above mentioned loss functions. And the overall loss function is calculated as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_53",
            "content": "L = \u03bb \u03b1 L gen + \u03bb \u03b2 L rec + \u03bb \u03b3 L lm ,(7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_54",
            "content": "where \u03bb \u03b1 , \u03bb \u03b2 , \u03bb \u03b3 are hyper-parameters.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_55",
            "content": "Parameter-Sharing Scheme",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "473-ARR_v1_56",
            "content": "For parameters in the decoders, we dived them into two parts, which are complexity-independent and complexity-dependent parameters. The former ones are shared between decoders, and the latter ones are not, as illustrated in Figure 3. We now introduce the complexity-dependent layers, namely Complexity-Dependent Layer Normalization and Complexity-Dependent Query Projection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_57",
            "content": "Previous works (Dumoulin et al., 2017;Jin et al., 2020) demonstrated that the layer normalization is related to the style of the target texts. We further argue that as an attribute of style, the complexity can be retained by independent layer normalization. Thus, we make the scaling and shifting parameters for layer normalization not shared in both decoders. This approach is to transform a layer activation x into a complexity-specific normalized activation z as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_58",
            "content": "z = \u03b3 c ( x \u2212 \u00b5 \u03c3 ) \u2212 \u03b2 c ,(8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_59",
            "content": "where \u00b5, \u03c3 are the mean and standard deviation of the batch of x, and \u03b3 c , \u03b2 c are learnable parameters specific to complexity c. This mechanism is used in all decoder layers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_60",
            "content": "Complexity-Dependent Query Projection The decoder layers extract information from encoded hidden states through cross-attention mechanism.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_61",
            "content": "We believe that the required information may be various for different complexity. Therefore, the parameters of the linear mapping used for the query transformation in the cross-attention are not shared among decoders. This calculation is as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_62",
            "content": "Q = query \u2022 W q c ,(9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_63",
            "content": "where W q c is the query transformation matrix specific to complexity c. By using this approach, the model can obtain different information from the encoded hidden states for different complexities.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_64",
            "content": "Datasets",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "473-ARR_v1_65",
            "content": "We evaluate the proposed multitasking framework on both English and Chinese datasets. Each language has a definition generation dataset and a simple text corpus.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_66",
            "content": "English Dataset",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "473-ARR_v1_67",
            "content": "The English datasets are constructed from the Oxford Dictionary (OD) and Oxford Advanced Learner's Dictionary (OALD). Since the OALD is for language learners, it has much simpler definitions than OD. Therefore, we use the OD for the definition generation training, and use the OALD for validation of simple definition generation. Note that the words used for testing are excluded from the training and validation sets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_68",
            "content": "For the definition generation dataset, we directly use the OD dataset published by Gadetsky et al. (2018). The training set has 33,128 words and 97,855 entries. Each entry consists of a triplet of (w * , c, d com ). For testing, we align the words and context in OD with the definitions in OALD through manual annotation. The annotated test set includes 3,881 words and 5,111 entries, which is used for automatic evaluation in experiments. Each entry in the test set has both golden complex and simple definitions from OD and OALD, respectively. Detailed statistics are listed in Table 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_69",
            "content": "We extract the OALD definitions that are not in the test set for constructing the simple text corpus. This corpus has 32,395 sentences with an average length of 12.12. We list more detailed statistics in Table 2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_70",
            "content": "During training, the definition generation dataset and the simple text corpus are randomly sampled as mini-batches respectively. And there is no correlation between the two mini-batches at each step.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_71",
            "content": "Chinese Dataset",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "473-ARR_v1_72",
            "content": "For the definition generation dataset, we use the Chinese WordNet (CWN) (Huang et al., 2010), which is a semantic lexicon aiming to provide a knowledge base of sense distinction. 1 We use the corresponding words, contexts, and definitions in CWN for the definition generation task. We split the entire dataset into training, validation, and test sets roughly according to the ratio of 8:1:1. The training set contains 6,574 words and 67,861 entries. Statistics are listed in Table 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_73",
            "content": "For the simple text corpus, we extract 58,867 sentences from a number of primary level Chinese as Second Language textbooks, with an average sentence length of 14.62.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_74",
            "content": "Since no suitable dictionary can be used for evaluation, there are no golden simple definitions in Chinese Dataset. In the experiments, we count the difficulty level of words in definitions to estimate if they are simple. We also organize a manual evaluation to score the accuracy and simplicity of definitions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_75",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "473-ARR_v1_76",
            "content": "This section presents the experimental settings and evaluation methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_77",
            "content": "Settings",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "473-ARR_v1_78",
            "content": "Baselines We compare the SimpDefiner with generation-simplification pipelines. We first employ LOG-CaD (Ishiwatari et al., 2019) and MASS (Song et al., 2019) models to generate definitions, and then employ ACCESS (Martin et al., 2019) and MUSS (Martin et al., 2020) models to simplify them. Thus, we have four different pipeline baselines. Since these models are not available in Chinese, we only apply these pipelines to English datasets. For the Chinese SDG task, we specially pretrained a MASS-ZH model from scratch using the Chinese Gigaword Fifth Edition 2 corpus. Note that we set the learning rate to 3e-4, warmup steps to 500, and random seed to 1111 when fine-tuning both MASS and MASS-ZH.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_79",
            "content": "SimpDefiner We use the parameters in the MASS model to initialize the encoder and two decoders in SimpDefiner. For the sentence corruption in the text reconstruction task, we randomly delete or blank words with a uniform probability of 0.2, and randomly shuffle the order of words within 5 tokens. For the language modeling task, we set the input representations to 0 and use the simplified text as the target output. We adopt the same hyper-parameters as the baseline for comparison.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_80",
            "content": "Evaluation",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "473-ARR_v1_81",
            "content": "Evaluation of the generated definitions mainly focuses on two aspects, i.e., accuracy and simplicity. We perform both automatic and manual evaluations for each aspect. Specifically, we use the BLEU (Papineni et al., 2002) and Semantic Similarity metrics to evaluate the accuracy, and use the SARI (Xu et al., 2016), and HSK Level metrics to evaluate the simplicity. We first introduce these automatic metrics, and then the manual evaluation method.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_82",
            "content": "BLEU Previous definition generation studies (Noraset et al., 2017;Yang et al., 2020;Kong et al., 2020) used the BLEU score to measure the closeness of generated results to the standard answers, and to evaluate the accuracy of results. Since the English test set is manually annotated, we calculate the BLEU score of both complex and simple definitions, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_83",
            "content": "Semantic Similarity In addition to the BLEU score, we use the sentence-transformers toolkit (Reimers and Gurevych, 2020) to convert the generated definitions and references into sentence vectors, and calculate cosine similarity between them. SARI SARI (Xu et al., 2016) is a lexical simplicity metric that measures how good are the words added, deleted and kept by a simplification model. This metric compares the model output to simplification references and the original sentence. We use the SARI implementation in the EASSE toolkit 3 . HSK Level HSK, namely Chinese Proficiency Test, is set up to test the proficiency of non-native speakers 4 . It has nine levels, from easy to hard, and each level corresponds to a vocabulary. We count the proportion of words at levels 1-3 and 7+ in the generated definitions. The higher the proportion of words in levels 1-3 (7+), the easier (more challenging) the definitions are understood.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_84",
            "content": "Manual Evaluation We randomly select 200 words and contexts from the Chinese test set and let the MASS and SimpDefiner generate definitions for them one by one. We mix the two generated definitions and the golden complex definition and then ask three native-speaker annotators to score them. Specifically, each annotator evaluates the definitions on two criteria of accuracy and simplicity. Both criteria have a range of 1-3. For accuracy, the annotators are asked to evaluate how semantically relevant the definitions are to the word. For simplicity, the annotators are asked to evaluate how simple the definitions are. After collecting evaluation results, we average the scores as final score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_85",
            "content": "6 Results and Analysis",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_86",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "473-ARR_v1_87",
            "content": "Table 3 and Table 4 present the experiment results on the English and Chinese test sets respectively. Results show that our proposed SimpDe-finer significantly outperforms baseline methods of generation-simplification pipelines on both English and Chinese datasets. For English results, the performance of simple definition generation improves 2.29 and 8.52 on the BLEU and SemSim metrics respectively, and improves 1.6 on the SARI metric. This indicates that both accuracy and simplicity are effectively improved comparing with the baseline. We also observe that complex definition generation also slightly improves by 0.31 on BLEU and 0.82 on SemSim. This indicates that SimpDefiner improves the ability to generate both complex and simple definitions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_88",
            "content": "For Chinese results, we compute the HSK Level metric on generated simple definitions. We can see that the proportion of low-level (HSK level 1-3) words increases by 5.03%, and that of high-level (HSK level 7+) words decreases by 1.61%. The lexical complexity of the SimpDefiner generated definitions are significantly reduced.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_89",
            "content": "Besides, we also conduct a manual evaluation on the Chinese test set, and the results are listed in Table 5. From the averaged scores, we observe that SimpDefiner outperforms MASS by 0.2 in terms of accuracy (more accurate) and 0.18 in terms of simplicity (more straightforward). On the accuracy score, all three annotators agree that SimpDefiner has higher accuracy than MASS, which shows the superiority of our framework. As expected, the golden definitions have the highest accuracy in the table, far exceeding the definitions generated by the two models. We believe this is caused by insufficient knowledge in the model, and this can be solved by using larger pretrained models, such as BART (Lewis et al., 2019). On the simplicity score, three annotators agree that SimpDefiner generates simpler definitions than MASS, and two of three annotators think SimpDefiner generates simpler definitions than the golden ones.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_90",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "6.2"
            }
        },
        {
            "ix": "473-ARR_v1_91",
            "content": "We conduct ablation experiment to demonstrate the effectiveness of SimpDefiner components and the parameter sharing scheme. For the language modeling (LM) and text reconstruction (TR) tasks, we ablate them by setting their weights to 0. For the layer normalization (LN) and query projection (QP) as parameter-shared layers, we ablate them by share their parameters between models. We illustrate the experiment results in Table 6. In general, ablating any of the components or parameter-shared layers reduces the performance in terms of simple definitions, which indicates that the SimpDefiner benefits from both components and parameter sharing scheme. We also observe that the performance of ablation experiments have slight disturbance on complex definitions. But since we pay more attention to the performance on simple definitions, we argue that the benefits of SimpDefiner far outweigh the losses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_92",
            "content": "Analysis on Hyper-Parameters",
            "ntype": "title",
            "meta": {
                "section": "6.3"
            }
        },
        {
            "ix": "473-ARR_v1_93",
            "content": "Furthermore, we conduct additional experiments on the English dataset to study how hyperparameters affect the performance. By setting different \u03bb to each model, we observe the relationship between the performance and these weights.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_94",
            "content": "The experiment results are listed in Table 7. From the table, we observe the inconsistency between metrics. As the definition generation task weight declines, the BLEU and SemSim metrics are generally declining, but the SARI metric is increasing. Since the BLEU and SemSim measure the accuracy and the SARI measures simplicity , we consider this phenomenon as a seesaw between the two attributes of accuracy and simplicity. The balance between them can be achieved by conditioning the hyper-parameters. plicated syntax. The baseline generated definitions contains difficult words and often wrongly defines the given word. In the English case, the word commander is defined by the baseline as an officer of the highest rank in a country, which is incorrect in most cases. In the Chinese case, the baseline generated definition contains difficult words like \u51ed\u501f (reference) and \u7279\u5b9a\u4e8b\u4ef6 (specific events). On the other hand, the SimpDefiner generates simple and accurate definitions in both cases.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_95",
            "content": "Case Study",
            "ntype": "title",
            "meta": {
                "section": "6.4"
            }
        },
        {
            "ix": "473-ARR_v1_96",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "473-ARR_v1_97",
            "content": "In this work, we propose the SDG task, a novel task of generating simplified definitions in a zero-shot manner. To this end, we leverage a multitasking framework SimpDefiner to tackle this task. We introduce a text reconstruction task to the framework to control the text complexity, and a language modeling task to enhance the decoder. For evaluation, we construct a novel test set in English by manually aligning the two dictionaries of OD and OALD. The automatic and manual evaluations indicate that the our proposed framework can generate more accurate and more straightforward definitions than other models and the generation-simplification pipelines. In the future, we will try to combine the current method with prompt learning methods, aiming to let users condition the complexity of generated definitions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "473-ARR_v1_98",
            "content": "Sergey Bartunov, Dmitry Kondrashkin, Anton Osokin, Dmitry Vetrov, Breaking sticks and ambiguities with adaptive skip-gram, 2016, Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Sergey Bartunov",
                    "Dmitry Kondrashkin",
                    "Anton Osokin",
                    "Dmitry Vetrov"
                ],
                "title": "Breaking sticks and ambiguities with adaptive skip-gram",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 19th International Conference on Artificial Intelligence and Statistics",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_99",
            "content": "Michele Bevilacqua, Marco Maru, Roberto Navigli, Generationary or \"how we went beyond word sense inventories and learned to gloss, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Michele Bevilacqua",
                    "Marco Maru",
                    "Roberto Navigli"
                ],
                "title": "Generationary or \"how we went beyond word sense inventories and learned to gloss",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_100",
            "content": "UNKNOWN, None, 2018, xsense: Learning senseseparated sparse representations and textual definitions for explainable word sense networks, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "xsense: Learning senseseparated sparse representations and textual definitions for explainable word sense networks",
                "pub": "CoRR"
            }
        },
        {
            "ix": "473-ARR_v1_101",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "473-ARR_v1_102",
            "content": "Jonathon Vincent Dumoulin, Manjunath Shlens,  Kudlur, A learned representation for artistic style, 2017, 5th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Jonathon Vincent Dumoulin",
                    "Manjunath Shlens",
                    " Kudlur"
                ],
                "title": "A learned representation for artistic style",
                "pub_date": "2017",
                "pub_title": "5th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_103",
            "content": "Fatemeh Enayati,  Abbas Pourhosein Gilakjani, The impact of computer assisted language learning (CALL) on improving intermediate EFL learners' vocabulary learning, 2020, International Journal of Language Education, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Fatemeh Enayati",
                    " Abbas Pourhosein Gilakjani"
                ],
                "title": "The impact of computer assisted language learning (CALL) on improving intermediate EFL learners' vocabulary learning",
                "pub_date": "2020",
                "pub_title": "International Journal of Language Education",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_104",
            "content": "Artyom Gadetsky, Ilya Yakubovskiy, Dmitry Vetrov, Conditional generators of words definitions, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Artyom Gadetsky",
                    "Ilya Yakubovskiy",
                    "Dmitry Vetrov"
                ],
                "title": "Conditional generators of words definitions",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "473-ARR_v1_105",
            "content": "UNKNOWN, None, 2018, Dynamic multi-level multi-task learning for sentence simplification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Dynamic multi-level multi-task learning for sentence simplification",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_106",
            "content": "Chu-Ren Huang, S Hsieh, Jia-Fei Hong, Yun-Zhu Chen, I Su, Yong-Xiang Chen, Sheng-Wei Huang, Chinese wordnet : design, implementation, and application of an infrastructure for crosslingual knowledge processing, 2010, Journal of Chinese information processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Chu-Ren Huang",
                    "S Hsieh",
                    "Jia-Fei Hong",
                    "Yun-Zhu Chen",
                    "I Su",
                    "Yong-Xiang Chen",
                    "Sheng-Wei Huang"
                ],
                "title": "Chinese wordnet : design, implementation, and application of an infrastructure for crosslingual knowledge processing",
                "pub_date": "2010",
                "pub_title": "Journal of Chinese information processing",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_107",
            "content": "Han Huang, Tomoyuki Kajiwara, Yuki Arase, Definition modelling for appropriate specificity, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Han Huang",
                    "Tomoyuki Kajiwara",
                    "Yuki Arase"
                ],
                "title": "Definition modelling for appropriate specificity",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_108",
            "content": "Shonosuke Ishiwatari, Hiroaki Hayashi, Naoki Yoshinaga, Graham Neubig, Shoetsu Sato, Masashi Toyoda, Masaru Kitsuregawa, Learning to describe unknown phrases with local and global contexts, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Shonosuke Ishiwatari",
                    "Hiroaki Hayashi",
                    "Naoki Yoshinaga",
                    "Graham Neubig",
                    "Shoetsu Sato",
                    "Masashi Toyoda",
                    "Masaru Kitsuregawa"
                ],
                "title": "Learning to describe unknown phrases with local and global contexts",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "473-ARR_v1_109",
            "content": "Di Jin, Zhijing Jin, Joey Zhou, Lisa Orii, Peter Szolovits, Hooks in the headline: Learning to generate headlines with controlled styles, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Di Jin",
                    "Zhijing Jin",
                    "Joey Zhou",
                    "Lisa Orii",
                    "Peter Szolovits"
                ],
                "title": "Hooks in the headline: Learning to generate headlines with controlled styles",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_110",
            "content": "Takashi Kawashima, Tomohiro Takagi, Sentence simplification from non-parallel corpus with adversarial learning, 2019, 2019 IEEE/WIC/ACM International Conference on Web Intelligence (WI), IEEE.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Takashi Kawashima",
                    "Tomohiro Takagi"
                ],
                "title": "Sentence simplification from non-parallel corpus with adversarial learning",
                "pub_date": "2019",
                "pub_title": "2019 IEEE/WIC/ACM International Conference on Web Intelligence (WI)",
                "pub": "IEEE"
            }
        },
        {
            "ix": "473-ARR_v1_111",
            "content": "Adam Kilgarriff, I don't believe in word senses, 1997, Computers and the Humanities, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Adam Kilgarriff"
                ],
                "title": "I don't believe in word senses",
                "pub_date": "1997",
                "pub_title": "Computers and the Humanities",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_112",
            "content": "UNKNOWN, None, 2020, Toward cross-lingual definition generation for language learners, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Toward cross-lingual definition generation for language learners",
                "pub": "CoRR"
            }
        },
        {
            "ix": "473-ARR_v1_113",
            "content": "UNKNOWN, None, 1910, BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "1910",
                "pub_title": "BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_114",
            "content": "Jiahuan Li, Yu Bao, Shujian Huang, Xinyu Dai, Jiajun Chen, Explicit semantic decomposition for definition generation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Jiahuan Li",
                    "Yu Bao",
                    "Shujian Huang",
                    "Xinyu Dai",
                    "Jiajun Chen"
                ],
                "title": "Explicit semantic decomposition for definition generation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_115",
            "content": "Yuri Lolita, Endry Boeriswati, Ninuk Lustyantie, The impact of computer assisted language learning (CALL) use of english vocabulary enhancement, 2020, Linguistic, English Education and Art (LEEA) Journal, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Yuri Lolita",
                    "Endry Boeriswati",
                    "Ninuk Lustyantie"
                ],
                "title": "The impact of computer assisted language learning (CALL) use of english vocabulary enhancement",
                "pub_date": "2020",
                "pub_title": "Linguistic, English Education and Art (LEEA) Journal",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_116",
            "content": "UNKNOWN, None, , \u00c9ric de la Clergerie, Antoine Bordes, and Beno\u00eet Sagot. 2020. Multilingual unsupervised sentence simplification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "\u00c9ric de la Clergerie, Antoine Bordes, and Beno\u00eet Sagot. 2020. Multilingual unsupervised sentence simplification",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_117",
            "content": "UNKNOWN, None, 1910, Controllable sentence simplification. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "1910",
                "pub_title": "Controllable sentence simplification. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_118",
            "content": "Timothee Mickus, Denis Paperno, Matthieu , Mark my word: A sequence-tosequence approach to definition modeling, 2019, Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing, Link\u00f6ping University Electronic Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Timothee Mickus",
                    "Denis Paperno",
                    "Matthieu "
                ],
                "title": "Mark my word: A sequence-tosequence approach to definition modeling",
                "pub_date": "2019",
                "pub_title": "Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing",
                "pub": "Link\u00f6ping University Electronic Press"
            }
        },
        {
            "ix": "473-ARR_v1_119",
            "content": "Ke Ni, William Wang, Learning to explain non-standard English words and phrases, 2017, Proceedings of the Eighth International Joint Conference on Natural Language Processing, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Ke Ni",
                    "William Wang"
                ],
                "title": "Learning to explain non-standard English words and phrases",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Eighth International Joint Conference on Natural Language Processing",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "473-ARR_v1_120",
            "content": "Sergiu Nisioi, Sanja \u0160tajner, Simone Ponzetto, Liviu Dinu, Exploring neural text simplification models, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Sergiu Nisioi",
                    "Sanja \u0160tajner",
                    "Simone Ponzetto",
                    "Liviu Dinu"
                ],
                "title": "Exploring neural text simplification models",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "473-ARR_v1_121",
            "content": "Thanapon Noraset, Chen Liang, Larry Birnbaum, Doug Downey, Definition modeling: Learning to define word embeddings in natural language, 2017, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Thanapon Noraset",
                    "Chen Liang",
                    "Larry Birnbaum",
                    "Doug Downey"
                ],
                "title": "Definition modeling: Learning to define word embeddings in natural language",
                "pub_date": "2017",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_122",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Kishore Papineni",
                    "Salim Roukos",
                    "Todd Ward",
                    "Wei-Jing Zhu"
                ],
                "title": "Bleu: a method for automatic evaluation of machine translation",
                "pub_date": "2002",
                "pub_title": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_123",
            "content": "UNKNOWN, None, 1910, Exploring the limits of transfer learning with a unified text-to-text transformer, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": null,
                "title": null,
                "pub_date": "1910",
                "pub_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_124",
            "content": "Machel Reid, Edison Marrese-Taylor, Yutaka Matsuo, VCDM: Leveraging Variational Biencoding and Deep Contextualized Word Representations for Improved Definition Modeling, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Machel Reid",
                    "Edison Marrese-Taylor",
                    "Yutaka Matsuo"
                ],
                "title": "VCDM: Leveraging Variational Biencoding and Deep Contextualized Word Representations for Improved Definition Modeling",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_125",
            "content": "Nils Reimers, Iryna Gurevych, Making monolingual sentence embeddings multilingual using knowledge distillation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Nils Reimers",
                    "Iryna Gurevych"
                ],
                "title": "Making monolingual sentence embeddings multilingual using knowledge distillation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_126",
            "content": "Eleanor Rosch, Carolyn Mervis, Family resemblances: Studies in the internal structure of categories, 1975, Cognitive Psychology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Eleanor Rosch",
                    "Carolyn Mervis"
                ],
                "title": "Family resemblances: Studies in the internal structure of categories",
                "pub_date": "1975",
                "pub_title": "Cognitive Psychology",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_127",
            "content": "M Thomas, Helen Segler, Antonella Pain,  Sorace, Second language vocabulary acquisition and learning strategies in ICALL environments, 2002, Computer Assisted Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "M Thomas",
                    "Helen Segler",
                    "Antonella Pain",
                    " Sorace"
                ],
                "title": "Second language vocabulary acquisition and learning strategies in ICALL environments",
                "pub_date": "2002",
                "pub_title": "Computer Assisted Language Learning",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_128",
            "content": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu, Mass: Masked sequence to sequence pre-training for language generation, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Kaitao Song",
                    "Xu Tan",
                    "Tao Qin",
                    "Jianfeng Lu",
                    "Tie-Yan Liu"
                ],
                "title": "Mass: Masked sequence to sequence pre-training for language generation",
                "pub_date": "2019",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "473-ARR_v1_129",
            "content": "Ilya Sutskever, Oriol Vinyals, Quoc V Le, Sequence to sequence learning with neural networks, 2014, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Ilya Sutskever",
                    "Oriol Vinyals",
                    "Quoc V Le"
                ],
                "title": "Sequence to sequence learning with neural networks",
                "pub_date": "2014",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_130",
            "content": "UNKNOWN, None, 2001, Reconsidering prepositional polysemy networks: The case of over. Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2001",
                "pub_title": "Reconsidering prepositional polysemy networks: The case of over. Language",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_131",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proceedings of the 31st International Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 31st International Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_132",
            "content": "Tu Vu, Baotian Hu, Tsendsuren Munkhdalai, Hong Yu, Sentence simplification with memoryaugmented neural networks, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Tu Vu",
                    "Baotian Hu",
                    "Tsendsuren Munkhdalai",
                    "Hong Yu"
                ],
                "title": "Sentence simplification with memoryaugmented neural networks",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_133",
            "content": "Sander Wubben,  Van Den, Emiel Bosch,  Krahmer, Sentence simplification by monolingual machine translation, 2012, Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    " Sander Wubben",
                    " Van Den",
                    "Emiel Bosch",
                    " Krahmer"
                ],
                "title": "Sentence simplification by monolingual machine translation",
                "pub_date": "2012",
                "pub_title": "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "473-ARR_v1_134",
            "content": "Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, Chris Callison-Burch, Optimizing statistical machine translation for text simplification, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Wei Xu",
                    "Courtney Napoles",
                    "Ellie Pavlick",
                    "Quanze Chen",
                    "Chris Callison-Burch"
                ],
                "title": "Optimizing statistical machine translation for text simplification",
                "pub_date": "2016",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_135",
            "content": "UNKNOWN, None, , Qinan Fan, and Erhong Yang. 2020. Incorporating sememes into chinese definition modeling, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Qinan Fan, and Erhong Yang. 2020. Incorporating sememes into chinese definition modeling",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_136",
            "content": "UNKNOWN, None, , Speech, and Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Speech, and Language Processing",
                "pub": null
            }
        },
        {
            "ix": "473-ARR_v1_137",
            "content": "Xingxing Zhang, Mirella Lapata, Sentence simplification with deep reinforcement learning, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Xingxing Zhang",
                    "Mirella Lapata"
                ],
                "title": "Sentence simplification with deep reinforcement learning",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "473-ARR_v1_138",
            "content": "Yihua Zhang, Discussion on the Definitions in Chinese Learner's Dictionaries: Comparative Study of Domestic and Foreign Learner Dictionaries (Translated from Chinese), 2011, Chinese Teaching in the World, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Yihua Zhang"
                ],
                "title": "Discussion on the Definitions in Chinese Learner's Dictionaries: Comparative Study of Domestic and Foreign Learner Dictionaries (Translated from Chinese)",
                "pub_date": "2011",
                "pub_title": "Chinese Teaching in the World",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "473-ARR_v1_0@0",
            "content": "Multitasking Framework for Unsupervised Simple Definition Generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_0",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@0",
            "content": "The definition generation task can help language learners by providing explanations for unfamiliar words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@1",
            "content": "This task has attracted much attention in recent years.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 106,
            "end": 160,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@2",
            "content": "We propose a novel task of Simple Definition Generation (SDG) to help language learners and low literacy readers better.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 162,
            "end": 281,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@3",
            "content": "A significant challenge of this task is the lack of learner's dictionaries in many languages, and therefore the lack of data for supervised training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 283,
            "end": 431,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@4",
            "content": "We explore this task and propose a multitasking framework SimpDefiner that only requires a standard dictionary with complex definitions and a corpus containing arbitrary simple texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 433,
            "end": 615,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@5",
            "content": "We disentangle the complexity factors from the text by carefully designing a parameter sharing scheme between the components.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 617,
            "end": 741,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@6",
            "content": "By joint training these components, the framework can generate both complex and simple definitions simultaneously.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 743,
            "end": 856,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@7",
            "content": "We demonstrate that the framework can generate relevant, simple definitions for the target words through automatic and manual evaluations on English and Chinese datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 858,
            "end": 1027,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_2@8",
            "content": "Our method outperforms the baseline model by a 1.6 SARI score on the English dataset, and the low level (HSK level 1-3) words in Chinese definitions raised by 5.03%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_2",
            "start": 1029,
            "end": 1193,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_4@0",
            "content": "Helping language learners understand words in doubt is an important topic in the field of Intelligent Computer-Assisted Language Learning (ICALL) (Segler et al., 2002;Enayati and Gilakjani, 2020;Lolita et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_4",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_4@1",
            "content": "In recent years, researchers attempted to automatically generate definitions for words rather than formulating predefined worddefinition inventories (Ishiwatari et al., 2019;Yang et al., 2020;Huang et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_4",
            "start": 217,
            "end": 428,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_4@2",
            "content": "There are two reasons for this.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_4",
            "start": 430,
            "end": 460,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_4@3",
            "content": "Firstly, it can be difficult for users to distinguish which sense is appropriate in the current context because of the cognitively inaccurate nature of discrete sense boundaries (Rosch and Mervis, 1975;Kilgarriff, 1997;Tyler and Evans, a notice, picture or film telling people about a product, job or service.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_4",
            "start": 462,
            "end": 770,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_5@0",
            "content": "Simple definition in OALD a notice or announcement in a public medium promoting a product, service, or event or publicizing a job vacancy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_5",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_5@1",
            "content": "2001).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_5",
            "start": 139,
            "end": 144,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_5@2",
            "content": "Secondly, the predefined inventories need to be updated manually by lexicographers, which is time-consuming and causes dictionaries to lag behind the ever-changing language usage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_5",
            "start": 146,
            "end": 324,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_6@0",
            "content": "Different from previous work (Noraset et al., 2017;Gadetsky et al., 2018;Mickus et al., 2019;Kong et al., 2020) that focused only on how to generate definitions, we further propose a novel task of Simple Definition Generation (SDG).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_6",
            "start": 0,
            "end": 231,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_6@1",
            "content": "Make the definitions easier to read and understand could benefit the language learners, low literacy readers, as well as helping people with aphasia or dyslexia.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_6",
            "start": 233,
            "end": 393,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_6@2",
            "content": "For example, compared with the Oxford Dictionary (OD), the Oxford Advanced Learner's Dictionary (OALD) has simpler definitions, which is specifically designed for language learners.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_6",
            "start": 395,
            "end": 575,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_6@3",
            "content": "As shown in Figure 1, the definition of the word advertisement in OALD does not contain difficult words or phrases such as announcement and public medium.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_6",
            "start": 577,
            "end": 730,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_7@0",
            "content": "The goal of SDG task is to generate simple definitions for languages that lack learner's dictionary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_7",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_7@1",
            "content": "For example, Chinese as Second Language (CSL) learners do not have suitable dictionaries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_7",
            "start": 101,
            "end": 189,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_7@2",
            "content": "As Zhang (2011) pointed out, since the difficulty of definitions is not considered, the existing dictionary cannot meet CSL learner's needs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_7",
            "start": 191,
            "end": 330,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_8@0",
            "content": "The SDG task is challenging because it requires a model to learn from a standard dictionary containing complex definitions and then generate simple ones, and hence fully unsupervised.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_8",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_8@1",
            "content": "A seemingly feasible solution is to generate definitions first and then simplify them, i.e., the generationsimplification pipeline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_8",
            "start": 184,
            "end": 314,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_8@2",
            "content": "However, the simplification task requires dataset with complex-simple sentence pairs, and such data is also difficult to find in languages other than English (Martin et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_8",
            "start": 316,
            "end": 495,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_9@0",
            "content": "Besides, the pipeline methods do not perform well due to accumulated errors (Section 6.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_9",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_10@0",
            "content": "To solve this dilemma and bridge the gap between practical needs for simple definitions and current trivial definition generation systems, we present a novel method for the SDG task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_10",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_10@1",
            "content": "As illustrated in Figure 2, our method leverages a multitasking framework SimpDefiner to generate simple definitions by performing three sub-tasks at the same time, which are definition generation, text reconstruction, and language modeling tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_10",
            "start": 183,
            "end": 429,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_10@2",
            "content": "The framework consists of a fully shared encoder and two partially shared decoders.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_10",
            "start": 431,
            "end": 513,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_10@3",
            "content": "We disentangle the complexity factors from the text by designing a parameter sharing scheme.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_10",
            "start": 515,
            "end": 606,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_10@4",
            "content": "Particularly, we share parameters in Complexity-Dependent Layer Normalization and Complexity-Dependent Query Projection of the transformer architecture (Vaswani et al., 2017) to control the complexity (Section 3.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_10",
            "start": 608,
            "end": 822,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_10@5",
            "content": "Through joint learning and sharing parameters between the decoders, the SimpDefiner is able to generate complex and simple definitions simultaneously.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_10",
            "start": 824,
            "end": 973,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_11@0",
            "content": "Main contributions of our paper are listed below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_11",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_12@0",
            "content": "\u2022 For the first time, we propose the task of SDG to generate simple definitions without supervised training data. \u2022 We propose a multitasking framework Sim-pDefiner to tackle this task. Through joint training three sub-tasks, the framework can generate complex and simple definitions simultaneously. \u2022 Both automatic and manual evaluations demonstrate the effectiveness of SimpDefiner. The framework outperforms the baseline model by 1.9 SARI score on the English test set. And the proportion of low level words (HSK level 1-3) in generated definitions raised by 5.03% on the Chinese test set. 2 Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_12",
            "start": 0,
            "end": 607,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_13@0",
            "content": "Definition Generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_13",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_14@0",
            "content": "The definition generation task is first introduced by Noraset et al. (2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_14",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_14@1",
            "content": "Although this task is proposed as a potentially useful tool for explainable AI, many subsequent works believe that it can assist language learning by giving definitions for words in the text (Ishiwatari et al., 2019;Mickus et al., 2019;Yang et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_14",
            "start": 77,
            "end": 331,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_15@0",
            "content": "Various studies attempted to generate multiple different definitions for polysemous words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_15",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_15@1",
            "content": "Gadetsky et al. (2018) tackled this problem by computing the AdaGram vectors (Bartunov et al., 2016) of input words, which is capable to learn different representations at desired semantic resolution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_15",
            "start": 91,
            "end": 290,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_15@2",
            "content": "However, generating different definitions based on contexts, i.e., example sentences, became the mainstream method (Chang et al., 2018;Reid et al., 2020;Li et al., 2020;Bevilacqua et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_15",
            "start": 292,
            "end": 485,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_15@3",
            "content": "Among them, some studies used pre-trained language models to obtain contextualized embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_15",
            "start": 487,
            "end": 580,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_15@4",
            "content": "Reid et al. (2020) initialized encoders with BERT (Devlin et al., 2019) and employed variational inference for estimation and leverage contextualized word embeddings for improved performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_15",
            "start": 582,
            "end": 772,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_15@5",
            "content": "Bevilacqua et al. (2020) employed a novel span-based encoding scheme to fine-tune a pre-trained English encoderdecoder system to generate definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_15",
            "start": 774,
            "end": 923,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_15@6",
            "content": "Huang et al. (2021) leveraged the T5 (Raffel et al., 2019) model for this task and introduced a re-ranking mechanism to model specificity in definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_15",
            "start": 925,
            "end": 1077,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_16@0",
            "content": "Our proposed SimpDefiner also takes the given word and context as input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_16",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_16@1",
            "content": "Differently, our main focus is to generate definitions with appropriate complexity to better help language learners.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_16",
            "start": 73,
            "end": 188,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_16@2",
            "content": "Besides, our model is based on MASS (Song et al., 2019), which is a pre-trained encoder-decoder model and is more suitable for generation tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_16",
            "start": 190,
            "end": 333,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_17@0",
            "content": "Sentence Simplification",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_17",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_18@0",
            "content": "Researchers usually regard the sentence simplification task as a monolingual variant of machine translation (MT) (Wubben et al., 2012).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_18",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_18@1",
            "content": "Benefiting from the advancement of neural machine translation, this task has also made great progress in recent years.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_18",
            "start": 136,
            "end": 253,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_19@0",
            "content": "Lately, many works built upon the Seq2Seq MT model (Sutskever et al., 2014) performed well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_19",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_19@1",
            "content": "First attempted by Nisioi et al. (2017), the Seq2Seq models for this task are able to perform lexical simplification and content reduction simultaneously by training on complex-simple sentence pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_19",
            "start": 92,
            "end": 290,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_19@2",
            "content": "This method was inherited and improved by many subsequent works, such as combining with the reinforcement learning method by setting a simplification reward (Zhang and Lapata, 2017), augmenting memory capacities (Vu et al., 2018) or training with multitasking on entailment and paraphrase generation (Guo et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_19",
            "start": 292,
            "end": 610,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_19@3",
            "content": "Martin et al. (2019) proposed to prepend additional prompt tokens to source sentences at train time, which enable the end-users to condition the simplifications returned by the model on attributes like length, lexical complexity, and syntactic complexity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_19",
            "start": 612,
            "end": 866,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_19@4",
            "content": "This controllable simplification system (called ACCESS) and its improved version MUSS (Martin et al., 2020) achieved SOTA results on the Turk corpus in terms of the SARI metric (Xu et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_19",
            "start": 868,
            "end": 1062,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_20@0",
            "content": "The generation-simplification pipeline methods are used as baselines of the SDG task, and we use both ACCESS and MUSS models for the simplification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_20",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_20@1",
            "content": "Unlike the baseline, the SimpDefiner can simultaneously generate complex and simple definitions without the need for aligned complex-simple sentence pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_20",
            "start": 149,
            "end": 303,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_21@0",
            "content": "Unsupervised Style Transfer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_21",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_22@0",
            "content": "Style transfer aims to change the style attributes while preserving the content.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_22",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_22@1",
            "content": "Our work is related to unsupervised style transfer by regarding the text complexity as one of the style attributes (Kawashima and Takagi, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_22",
            "start": 81,
            "end": 224,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_22@2",
            "content": "Dumoulin et al. (2017) demonstrated that the neural networks can capture the artistic style of a diversity of paintings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_22",
            "start": 226,
            "end": 345,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_22@3",
            "content": "The authors discovered that adjusting parameters in the layer normalization mechanism leads to different artistic styles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_22",
            "start": 347,
            "end": 467,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_22@4",
            "content": "This method permits users to transform images to arbitrary styles learned from individual paintings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_22",
            "start": 469,
            "end": 568,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_22@5",
            "content": "Jin et al. (2020) successfully applied this method to the task of headline generation, allowing the model to generate headlines of a specific style, such as humorous, romantic or click-baity, in an unsupervised manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_22",
            "start": 570,
            "end": 787,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_23@0",
            "content": "By treating the task of simplification as a variant of style transfer, we borrow the insight of learning complexity-dependent parameters in the Layer Normalization mechanism.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_23",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_23@1",
            "content": "Additionally, we introduce the language modeling task into SimpDefiner, which is to enhance the decoder and make it more sensitive to text complexity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_23",
            "start": 175,
            "end": 324,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_24@0",
            "content": "Method",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_24",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_25@0",
            "content": "We integrate three sub-tasks of definition generation, text reconstruction, and language modeling into the SimpDefiner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_25",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_25@1",
            "content": "This section first gives a formal definition of the SDG task, then introduces each sub-task, and finally the parameter sharing scheme.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_25",
            "start": 120,
            "end": 253,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_26@0",
            "content": "Task Formulation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_26",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_27@0",
            "content": "The SDG task consists in generating a simple definition d sim for a given word and context (w * , c), where c = [w 1 , . . . , w * , . . . , w n ] is a sentence containing w * .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_27",
            "start": 0,
            "end": 176,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_27@1",
            "content": "This task is challenging because there is no corpus like {(w * i , c i , d sim i )} N i=1 and hence fully unsupervised.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_27",
            "start": 178,
            "end": 296,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_28@0",
            "content": "The only data available in this work include a standard dictionary dataset G",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_28",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_29@0",
            "content": "= {(w * i , c i , d com i )} N i=1 and a simple text corpus Y = {y i } M",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_29",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_30@0",
            "content": "i=1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_30",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_30@1",
            "content": "Note that we use d com for complex definitions and d sim for simple ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_30",
            "start": 6,
            "end": 78,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_31@0",
            "content": "Multitasking Framework",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_31",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_32@0",
            "content": "We design the three sub-tasks in the SimpDefiner to learn different abilities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_32",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_32@1",
            "content": "Cooperating with each other, the entire framework obtains the ability to compute the conditional probability P (d sim |w * , c) of simple definitions in a zero-shot manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_32",
            "start": 79,
            "end": 250,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_33@0",
            "content": "Specifically, the definition generation task aims to model the probability of a complex definition given the word and context P (d com |w * , c) (Section 3.2.1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_33",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_33@1",
            "content": "And the text reconstruction task aims to model the probability of a simple sentence given the corrupted version P (y| \u1ef9) (Section 3.2.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_33",
            "start": 162,
            "end": 298,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_33@2",
            "content": "As we can see, neither task can directly get the P (d sim |w * , c).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_33",
            "start": 300,
            "end": 367,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_33@3",
            "content": "To solve the problem, we attempt to disentangle the complexity factors from the text by sharing parameters between the generation and reconstruction decoders.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_33",
            "start": 369,
            "end": 526,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_33@4",
            "content": "This scheme shares semantic information between decoders, while keeping complexity information independent.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_33",
            "start": 528,
            "end": 634,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_33@5",
            "content": "In the inference stage, we obtain a simple definition by feeding the encoded hidden state into the reconstruction decoder as in Figure 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_33",
            "start": 636,
            "end": 772,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_33@6",
            "content": "The detailed parameter sharing scheme is in Section 3.3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_33",
            "start": 774,
            "end": 829,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_34@0",
            "content": "Nevertheless, the complexity information may still be kept in some shared parameters, resulting in the reconstruction decoder fail to generate simple definitions occasionally.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_34",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_34@1",
            "content": "Eliminating the complexity information in all shared parameters is obviously technically impossible.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_34",
            "start": 176,
            "end": 275,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_34@2",
            "content": "Instead, we introduce the language modeling task (Section 3.2.3) to enhance the reconstruction decoder and make it more focusd on simple text generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_34",
            "start": 277,
            "end": 429,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_35@0",
            "content": "Definition Generation Task",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_35",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_36@0",
            "content": "We follow the mainstream method (Yang et al., 2020;Kong et al., 2020;Reid et al., 2020) to concatenate the word and context together with a special token [SEP] as x = (w * ; [SEP]; c).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_36",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_36@1",
            "content": "The entire sequence is then fed into SimpDefiner, and the definition is obtained by the following language model:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_36",
            "start": 185,
            "end": 297,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_37@0",
            "content": "P (d com |x; \u03b8) = t P (d com t |d com <t , x; \u03b8) ,(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_37",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_38@0",
            "content": "where d com t is the t-th token of the definition, and \u03b8 is the set of parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_38",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_38@1",
            "content": "The model is optimized using the following loss function:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_38",
            "start": 83,
            "end": 139,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_39@0",
            "content": "L gen (\u03b8) = \u2212 (x,d com )\u2208G log P (d com |x; \u03b8). (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_39",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_40@0",
            "content": "Text Reconstruction Task",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_40",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_41@0",
            "content": "We corrupt each sentence in the corpus Y by randomly deleting or blanking some words and shuffling the word orders. And then we obtain a new corpus \u1ef8 = {( \u1ef9i , y i )} M i=1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_41",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_41@1",
            "content": "The \u1ef9 is a corrupted version of y by randomly deleting or blanking some words and shuffling the word orders.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_41",
            "start": 175,
            "end": 282,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_41@2",
            "content": "We input \u1ef9 into SimpDefiner and obtain y by solving a self-supervised task of",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_41",
            "start": 284,
            "end": 360,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_42@0",
            "content": "P (y| \u1ef9; \u03b8) = t P (y t |y <t , \u1ef9; \u03b8) ,(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_42",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_43@0",
            "content": "where y t is the t-th token of the sentence, and \u03b8 is a set of parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_43",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_43@1",
            "content": "The loss function of this task is as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_43",
            "start": 75,
            "end": 119,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_44@0",
            "content": "L rec (\u03b8) = \u2212 M (y, \u1ef9)\u2208",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_44",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_45@0",
            "content": "\u1ef8 log P (y| \u1ef9; \u03b8).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_45",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_46@0",
            "content": "(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_46",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_47@0",
            "content": "Language Modeling Task",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_47",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_48@0",
            "content": "This task facilitates zero-shot generation of P (d sim |x) by jointly training the reconstruction decoder as a language model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_48",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_48@1",
            "content": "Once the model captures correct complexity that guides the model to generate the desired simple texts, it's more likely for the model to ignore the wrongly shared complexity information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_48",
            "start": 127,
            "end": 312,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_48@2",
            "content": "Similar to Eq. 3, we have:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_48",
            "start": 314,
            "end": 339,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_49@0",
            "content": "P (y|\u03b8) = t P (y t |y <t ; \u03b8) .(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_49",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_50@0",
            "content": "It is equivalent to masking the encoder out and ignoring the attention modules between the encoder and reconstruction decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_50",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_50@1",
            "content": "The model is optimized by the following loss function:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_50",
            "start": 127,
            "end": 180,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_51@0",
            "content": "L lm (\u03b8) = \u2212 y\u2208Y log P (y|\u03b8).(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_51",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_52@0",
            "content": "Finally, we train the entire SimpDefiner by jointly minimizing the weighted sum of all above mentioned loss functions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_52",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_52@1",
            "content": "And the overall loss function is calculated as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_52",
            "start": 119,
            "end": 165,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_53@0",
            "content": "L = \u03bb \u03b1 L gen + \u03bb \u03b2 L rec + \u03bb \u03b3 L lm ,(7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_53",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_54@0",
            "content": "where \u03bb \u03b1 , \u03bb \u03b2 , \u03bb \u03b3 are hyper-parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_54",
            "start": 0,
            "end": 42,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_55@0",
            "content": "Parameter-Sharing Scheme",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_55",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_56@0",
            "content": "For parameters in the decoders, we dived them into two parts, which are complexity-independent and complexity-dependent parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_56",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_56@1",
            "content": "The former ones are shared between decoders, and the latter ones are not, as illustrated in Figure 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_56",
            "start": 132,
            "end": 232,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_56@2",
            "content": "We now introduce the complexity-dependent layers, namely Complexity-Dependent Layer Normalization and Complexity-Dependent Query Projection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_56",
            "start": 234,
            "end": 373,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_57@0",
            "content": "Previous works (Dumoulin et al., 2017;Jin et al., 2020) demonstrated that the layer normalization is related to the style of the target texts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_57",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_57@1",
            "content": "We further argue that as an attribute of style, the complexity can be retained by independent layer normalization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_57",
            "start": 143,
            "end": 256,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_57@2",
            "content": "Thus, we make the scaling and shifting parameters for layer normalization not shared in both decoders.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_57",
            "start": 258,
            "end": 359,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_57@3",
            "content": "This approach is to transform a layer activation x into a complexity-specific normalized activation z as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_57",
            "start": 361,
            "end": 465,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_58@0",
            "content": "z = \u03b3 c ( x \u2212 \u00b5 \u03c3 ) \u2212 \u03b2 c ,(8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_58",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_59@0",
            "content": "where \u00b5, \u03c3 are the mean and standard deviation of the batch of x, and \u03b3 c , \u03b2 c are learnable parameters specific to complexity c. This mechanism is used in all decoder layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_59",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_60@0",
            "content": "Complexity-Dependent Query Projection The decoder layers extract information from encoded hidden states through cross-attention mechanism.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_60",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_61@0",
            "content": "We believe that the required information may be various for different complexity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_61",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_61@1",
            "content": "Therefore, the parameters of the linear mapping used for the query transformation in the cross-attention are not shared among decoders.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_61",
            "start": 82,
            "end": 216,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_61@2",
            "content": "This calculation is as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_61",
            "start": 218,
            "end": 248,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_62@0",
            "content": "Q = query \u2022 W q c ,(9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_62",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_63@0",
            "content": "where W q c is the query transformation matrix specific to complexity c. By using this approach, the model can obtain different information from the encoded hidden states for different complexities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_63",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_64@0",
            "content": "Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_64",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_65@0",
            "content": "We evaluate the proposed multitasking framework on both English and Chinese datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_65",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_65@1",
            "content": "Each language has a definition generation dataset and a simple text corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_65",
            "start": 86,
            "end": 160,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_66@0",
            "content": "English Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_66",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_67@0",
            "content": "The English datasets are constructed from the Oxford Dictionary (OD) and Oxford Advanced Learner's Dictionary (OALD).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_67",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_67@1",
            "content": "Since the OALD is for language learners, it has much simpler definitions than OD.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_67",
            "start": 118,
            "end": 198,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_67@2",
            "content": "Therefore, we use the OD for the definition generation training, and use the OALD for validation of simple definition generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_67",
            "start": 200,
            "end": 328,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_67@3",
            "content": "Note that the words used for testing are excluded from the training and validation sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_67",
            "start": 330,
            "end": 417,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_68@0",
            "content": "For the definition generation dataset, we directly use the OD dataset published by Gadetsky et al. (2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_68",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_68@1",
            "content": "The training set has 33,128 words and 97,855 entries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_68",
            "start": 107,
            "end": 159,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_68@2",
            "content": "Each entry consists of a triplet of (w * , c, d com ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_68",
            "start": 161,
            "end": 214,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_68@3",
            "content": "For testing, we align the words and context in OD with the definitions in OALD through manual annotation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_68",
            "start": 216,
            "end": 320,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_68@4",
            "content": "The annotated test set includes 3,881 words and 5,111 entries, which is used for automatic evaluation in experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_68",
            "start": 322,
            "end": 438,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_68@5",
            "content": "Each entry in the test set has both golden complex and simple definitions from OD and OALD, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_68",
            "start": 440,
            "end": 544,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_68@6",
            "content": "Detailed statistics are listed in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_68",
            "start": 546,
            "end": 587,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_69@0",
            "content": "We extract the OALD definitions that are not in the test set for constructing the simple text corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_69",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_69@1",
            "content": "This corpus has 32,395 sentences with an average length of 12.12.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_69",
            "start": 102,
            "end": 166,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_69@2",
            "content": "We list more detailed statistics in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_69",
            "start": 168,
            "end": 211,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_70@0",
            "content": "During training, the definition generation dataset and the simple text corpus are randomly sampled as mini-batches respectively. And there is no correlation between the two mini-batches at each step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_70",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_71@0",
            "content": "Chinese Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_71",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_72@0",
            "content": "For the definition generation dataset, we use the Chinese WordNet (CWN) (Huang et al., 2010), which is a semantic lexicon aiming to provide a knowledge base of sense distinction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_72",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_72@1",
            "content": "1 We use the corresponding words, contexts, and definitions in CWN for the definition generation task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_72",
            "start": 179,
            "end": 280,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_72@2",
            "content": "We split the entire dataset into training, validation, and test sets roughly according to the ratio of 8:1:1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_72",
            "start": 282,
            "end": 390,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_72@3",
            "content": "The training set contains 6,574 words and 67,861 entries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_72",
            "start": 392,
            "end": 448,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_72@4",
            "content": "Statistics are listed in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_72",
            "start": 450,
            "end": 482,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_73@0",
            "content": "For the simple text corpus, we extract 58,867 sentences from a number of primary level Chinese as Second Language textbooks, with an average sentence length of 14.62.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_73",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_74@0",
            "content": "Since no suitable dictionary can be used for evaluation, there are no golden simple definitions in Chinese Dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_74",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_74@1",
            "content": "In the experiments, we count the difficulty level of words in definitions to estimate if they are simple.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_74",
            "start": 116,
            "end": 220,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_74@2",
            "content": "We also organize a manual evaluation to score the accuracy and simplicity of definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_74",
            "start": 222,
            "end": 310,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_75@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_75",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_76@0",
            "content": "This section presents the experimental settings and evaluation methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_76",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_77@0",
            "content": "Settings",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_77",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_78@0",
            "content": "Baselines We compare the SimpDefiner with generation-simplification pipelines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_78",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_78@1",
            "content": "We first employ LOG-CaD (Ishiwatari et al., 2019) and MASS (Song et al., 2019) models to generate definitions, and then employ ACCESS (Martin et al., 2019) and MUSS (Martin et al., 2020) models to simplify them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_78",
            "start": 79,
            "end": 289,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_78@2",
            "content": "Thus, we have four different pipeline baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_78",
            "start": 291,
            "end": 338,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_78@3",
            "content": "Since these models are not available in Chinese, we only apply these pipelines to English datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_78",
            "start": 340,
            "end": 438,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_78@4",
            "content": "For the Chinese SDG task, we specially pretrained a MASS-ZH model from scratch using the Chinese Gigaword Fifth Edition 2 corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_78",
            "start": 440,
            "end": 568,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_78@5",
            "content": "Note that we set the learning rate to 3e-4, warmup steps to 500, and random seed to 1111 when fine-tuning both MASS and MASS-ZH.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_78",
            "start": 570,
            "end": 697,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_79@0",
            "content": "SimpDefiner We use the parameters in the MASS model to initialize the encoder and two decoders in SimpDefiner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_79",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_79@1",
            "content": "For the sentence corruption in the text reconstruction task, we randomly delete or blank words with a uniform probability of 0.2, and randomly shuffle the order of words within 5 tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_79",
            "start": 111,
            "end": 296,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_79@2",
            "content": "For the language modeling task, we set the input representations to 0 and use the simplified text as the target output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_79",
            "start": 298,
            "end": 416,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_79@3",
            "content": "We adopt the same hyper-parameters as the baseline for comparison.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_79",
            "start": 418,
            "end": 483,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_80@0",
            "content": "Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_80",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_81@0",
            "content": "Evaluation of the generated definitions mainly focuses on two aspects, i.e., accuracy and simplicity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_81",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_81@1",
            "content": "We perform both automatic and manual evaluations for each aspect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_81",
            "start": 102,
            "end": 166,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_81@2",
            "content": "Specifically, we use the BLEU (Papineni et al., 2002) and Semantic Similarity metrics to evaluate the accuracy, and use the SARI (Xu et al., 2016), and HSK Level metrics to evaluate the simplicity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_81",
            "start": 168,
            "end": 364,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_81@3",
            "content": "We first introduce these automatic metrics, and then the manual evaluation method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_81",
            "start": 366,
            "end": 447,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_82@0",
            "content": "BLEU Previous definition generation studies (Noraset et al., 2017;Yang et al., 2020;Kong et al., 2020) used the BLEU score to measure the closeness of generated results to the standard answers, and to evaluate the accuracy of results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_82",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_82@1",
            "content": "Since the English test set is manually annotated, we calculate the BLEU score of both complex and simple definitions, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_82",
            "start": 235,
            "end": 365,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@0",
            "content": "Semantic Similarity In addition to the BLEU score, we use the sentence-transformers toolkit (Reimers and Gurevych, 2020) to convert the generated definitions and references into sentence vectors, and calculate cosine similarity between them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@1",
            "content": "SARI SARI (Xu et al., 2016) is a lexical simplicity metric that measures how good are the words added, deleted and kept by a simplification model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 242,
            "end": 387,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@2",
            "content": "This metric compares the model output to simplification references and the original sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 389,
            "end": 481,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@3",
            "content": "We use the SARI implementation in the EASSE toolkit 3 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 483,
            "end": 537,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@4",
            "content": "HSK Level HSK, namely Chinese Proficiency Test, is set up to test the proficiency of non-native speakers 4 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 539,
            "end": 646,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@5",
            "content": "It has nine levels, from easy to hard, and each level corresponds to a vocabulary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 648,
            "end": 729,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@6",
            "content": "We count the proportion of words at levels 1-3 and 7+ in the generated definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 731,
            "end": 813,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_83@7",
            "content": "The higher the proportion of words in levels 1-3 (7+), the easier (more challenging) the definitions are understood.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_83",
            "start": 815,
            "end": 930,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_84@0",
            "content": "Manual Evaluation We randomly select 200 words and contexts from the Chinese test set and let the MASS and SimpDefiner generate definitions for them one by one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_84",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_84@1",
            "content": "We mix the two generated definitions and the golden complex definition and then ask three native-speaker annotators to score them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_84",
            "start": 161,
            "end": 290,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_84@2",
            "content": "Specifically, each annotator evaluates the definitions on two criteria of accuracy and simplicity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_84",
            "start": 292,
            "end": 389,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_84@3",
            "content": "Both criteria have a range of 1-3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_84",
            "start": 391,
            "end": 424,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_84@4",
            "content": "For accuracy, the annotators are asked to evaluate how semantically relevant the definitions are to the word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_84",
            "start": 426,
            "end": 534,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_84@5",
            "content": "For simplicity, the annotators are asked to evaluate how simple the definitions are.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_84",
            "start": 536,
            "end": 619,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_84@6",
            "content": "After collecting evaluation results, we average the scores as final score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_84",
            "start": 621,
            "end": 694,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_85@0",
            "content": "6 Results and Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_85",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_86@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_86",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_87@0",
            "content": "Table 3 and Table 4 present the experiment results on the English and Chinese test sets respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_87",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_87@1",
            "content": "Results show that our proposed SimpDe-finer significantly outperforms baseline methods of generation-simplification pipelines on both English and Chinese datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_87",
            "start": 102,
            "end": 264,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_87@2",
            "content": "For English results, the performance of simple definition generation improves 2.29 and 8.52 on the BLEU and SemSim metrics respectively, and improves 1.6 on the SARI metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_87",
            "start": 266,
            "end": 438,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_87@3",
            "content": "This indicates that both accuracy and simplicity are effectively improved comparing with the baseline.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_87",
            "start": 440,
            "end": 541,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_87@4",
            "content": "We also observe that complex definition generation also slightly improves by 0.31 on BLEU and 0.82 on SemSim.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_87",
            "start": 543,
            "end": 651,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_87@5",
            "content": "This indicates that SimpDefiner improves the ability to generate both complex and simple definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_87",
            "start": 653,
            "end": 753,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_88@0",
            "content": "For Chinese results, we compute the HSK Level metric on generated simple definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_88",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_88@1",
            "content": "We can see that the proportion of low-level (HSK level 1-3) words increases by 5.03%, and that of high-level (HSK level 7+) words decreases by 1.61%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_88",
            "start": 86,
            "end": 234,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_88@2",
            "content": "The lexical complexity of the SimpDefiner generated definitions are significantly reduced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_88",
            "start": 236,
            "end": 325,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_89@0",
            "content": "Besides, we also conduct a manual evaluation on the Chinese test set, and the results are listed in Table 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_89",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_89@1",
            "content": "From the averaged scores, we observe that SimpDefiner outperforms MASS by 0.2 in terms of accuracy (more accurate) and 0.18 in terms of simplicity (more straightforward).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_89",
            "start": 109,
            "end": 278,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_89@2",
            "content": "On the accuracy score, all three annotators agree that SimpDefiner has higher accuracy than MASS, which shows the superiority of our framework.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_89",
            "start": 280,
            "end": 422,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_89@3",
            "content": "As expected, the golden definitions have the highest accuracy in the table, far exceeding the definitions generated by the two models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_89",
            "start": 424,
            "end": 557,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_89@4",
            "content": "We believe this is caused by insufficient knowledge in the model, and this can be solved by using larger pretrained models, such as BART (Lewis et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_89",
            "start": 559,
            "end": 716,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_89@5",
            "content": "On the simplicity score, three annotators agree that SimpDefiner generates simpler definitions than MASS, and two of three annotators think SimpDefiner generates simpler definitions than the golden ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_89",
            "start": 718,
            "end": 920,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_90@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_90",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_91@0",
            "content": "We conduct ablation experiment to demonstrate the effectiveness of SimpDefiner components and the parameter sharing scheme.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_91",
            "start": 0,
            "end": 122,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_91@1",
            "content": "For the language modeling (LM) and text reconstruction (TR) tasks, we ablate them by setting their weights to 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_91",
            "start": 124,
            "end": 235,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_91@2",
            "content": "For the layer normalization (LN) and query projection (QP) as parameter-shared layers, we ablate them by share their parameters between models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_91",
            "start": 237,
            "end": 379,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_91@3",
            "content": "We illustrate the experiment results in Table 6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_91",
            "start": 381,
            "end": 428,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_91@4",
            "content": "In general, ablating any of the components or parameter-shared layers reduces the performance in terms of simple definitions, which indicates that the SimpDefiner benefits from both components and parameter sharing scheme.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_91",
            "start": 430,
            "end": 651,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_91@5",
            "content": "We also observe that the performance of ablation experiments have slight disturbance on complex definitions. But since we pay more attention to the performance on simple definitions, we argue that the benefits of SimpDefiner far outweigh the losses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_91",
            "start": 653,
            "end": 901,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_92@0",
            "content": "Analysis on Hyper-Parameters",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_92",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_93@0",
            "content": "Furthermore, we conduct additional experiments on the English dataset to study how hyperparameters affect the performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_93",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_93@1",
            "content": "By setting different \u03bb to each model, we observe the relationship between the performance and these weights.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_93",
            "start": 123,
            "end": 230,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@0",
            "content": "The experiment results are listed in Table 7.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@1",
            "content": "From the table, we observe the inconsistency between metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 46,
            "end": 106,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@2",
            "content": "As the definition generation task weight declines, the BLEU and SemSim metrics are generally declining, but the SARI metric is increasing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 108,
            "end": 245,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@3",
            "content": "Since the BLEU and SemSim measure the accuracy and the SARI measures simplicity , we consider this phenomenon as a seesaw between the two attributes of accuracy and simplicity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 247,
            "end": 422,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@4",
            "content": "The balance between them can be achieved by conditioning the hyper-parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 424,
            "end": 501,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@5",
            "content": "plicated syntax.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 503,
            "end": 518,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@6",
            "content": "The baseline generated definitions contains difficult words and often wrongly defines the given word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 520,
            "end": 620,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@7",
            "content": "In the English case, the word commander is defined by the baseline as an officer of the highest rank in a country, which is incorrect in most cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 622,
            "end": 769,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@8",
            "content": "In the Chinese case, the baseline generated definition contains difficult words like \u51ed\u501f (reference) and \u7279\u5b9a\u4e8b\u4ef6 (specific events).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 771,
            "end": 897,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_94@9",
            "content": "On the other hand, the SimpDefiner generates simple and accurate definitions in both cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_94",
            "start": 899,
            "end": 989,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_95@0",
            "content": "Case Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_95",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_96@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_96",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_97@0",
            "content": "In this work, we propose the SDG task, a novel task of generating simplified definitions in a zero-shot manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_97",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_97@1",
            "content": "To this end, we leverage a multitasking framework SimpDefiner to tackle this task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_97",
            "start": 112,
            "end": 193,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_97@2",
            "content": "We introduce a text reconstruction task to the framework to control the text complexity, and a language modeling task to enhance the decoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_97",
            "start": 195,
            "end": 335,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_97@3",
            "content": "For evaluation, we construct a novel test set in English by manually aligning the two dictionaries of OD and OALD.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_97",
            "start": 337,
            "end": 450,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_97@4",
            "content": "The automatic and manual evaluations indicate that the our proposed framework can generate more accurate and more straightforward definitions than other models and the generation-simplification pipelines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_97",
            "start": 452,
            "end": 655,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_97@5",
            "content": "In the future, we will try to combine the current method with prompt learning methods, aiming to let users condition the complexity of generated definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_97",
            "start": 657,
            "end": 813,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_98@0",
            "content": "Sergey Bartunov, Dmitry Kondrashkin, Anton Osokin, Dmitry Vetrov, Breaking sticks and ambiguities with adaptive skip-gram, 2016, Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_98",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_99@0",
            "content": "Michele Bevilacqua, Marco Maru, Roberto Navigli, Generationary or \"how we went beyond word sense inventories and learned to gloss, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_99",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_100@0",
            "content": "UNKNOWN, None, 2018, xsense: Learning senseseparated sparse representations and textual definitions for explainable word sense networks, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_100",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_101@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_101",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_102@0",
            "content": "Jonathon Vincent Dumoulin, Manjunath Shlens,  Kudlur, A learned representation for artistic style, 2017, 5th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_102",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_103@0",
            "content": "Fatemeh Enayati,  Abbas Pourhosein Gilakjani, The impact of computer assisted language learning (CALL) on improving intermediate EFL learners' vocabulary learning, 2020, International Journal of Language Education, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_103",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_104@0",
            "content": "Artyom Gadetsky, Ilya Yakubovskiy, Dmitry Vetrov, Conditional generators of words definitions, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_104",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_105@0",
            "content": "UNKNOWN, None, 2018, Dynamic multi-level multi-task learning for sentence simplification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_105",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_106@0",
            "content": "Chu-Ren Huang, S Hsieh, Jia-Fei Hong, Yun-Zhu Chen, I Su, Yong-Xiang Chen, Sheng-Wei Huang, Chinese wordnet : design, implementation, and application of an infrastructure for crosslingual knowledge processing, 2010, Journal of Chinese information processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_106",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_107@0",
            "content": "Han Huang, Tomoyuki Kajiwara, Yuki Arase, Definition modelling for appropriate specificity, 2021, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_107",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_108@0",
            "content": "Shonosuke Ishiwatari, Hiroaki Hayashi, Naoki Yoshinaga, Graham Neubig, Shoetsu Sato, Masashi Toyoda, Masaru Kitsuregawa, Learning to describe unknown phrases with local and global contexts, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_108",
            "start": 0,
            "end": 361,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_109@0",
            "content": "Di Jin, Zhijing Jin, Joey Zhou, Lisa Orii, Peter Szolovits, Hooks in the headline: Learning to generate headlines with controlled styles, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_109",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_110@0",
            "content": "Takashi Kawashima, Tomohiro Takagi, Sentence simplification from non-parallel corpus with adversarial learning, 2019, 2019 IEEE/WIC/ACM International Conference on Web Intelligence (WI), IEEE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_110",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_111@0",
            "content": "Adam Kilgarriff, I don't believe in word senses, 1997, Computers and the Humanities, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_111",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_112@0",
            "content": "UNKNOWN, None, 2020, Toward cross-lingual definition generation for language learners, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_112",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_113@0",
            "content": "UNKNOWN, None, 1910, BART: denoising sequence-to-sequence pretraining for natural language generation, translation, and comprehension, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_113",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_114@0",
            "content": "Jiahuan Li, Yu Bao, Shujian Huang, Xinyu Dai, Jiajun Chen, Explicit semantic decomposition for definition generation, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_114",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_115@0",
            "content": "Yuri Lolita, Endry Boeriswati, Ninuk Lustyantie, The impact of computer assisted language learning (CALL) use of english vocabulary enhancement, 2020, Linguistic, English Education and Art (LEEA) Journal, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_115",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_116@0",
            "content": "UNKNOWN, None, , \u00c9ric de la Clergerie, Antoine Bordes, and Beno\u00eet Sagot. 2020. Multilingual unsupervised sentence simplification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_116",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_117@0",
            "content": "UNKNOWN, None, 1910, Controllable sentence simplification. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_117",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_118@0",
            "content": "Timothee Mickus, Denis Paperno, Matthieu , Mark my word: A sequence-tosequence approach to definition modeling, 2019, Proceedings of the First NLPL Workshop on Deep Learning for Natural Language Processing, Link\u00f6ping University Electronic Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_118",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_119@0",
            "content": "Ke Ni, William Wang, Learning to explain non-standard English words and phrases, 2017, Proceedings of the Eighth International Joint Conference on Natural Language Processing, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_119",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_120@0",
            "content": "Sergiu Nisioi, Sanja \u0160tajner, Simone Ponzetto, Liviu Dinu, Exploring neural text simplification models, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_120",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_121@0",
            "content": "Thanapon Noraset, Chen Liang, Larry Birnbaum, Doug Downey, Definition modeling: Learning to define word embeddings in natural language, 2017, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_121",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_122@0",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_122",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_123@0",
            "content": "UNKNOWN, None, 1910, Exploring the limits of transfer learning with a unified text-to-text transformer, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_123",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_124@0",
            "content": "Machel Reid, Edison Marrese-Taylor, Yutaka Matsuo, VCDM: Leveraging Variational Biencoding and Deep Contextualized Word Representations for Improved Definition Modeling, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_124",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_125@0",
            "content": "Nils Reimers, Iryna Gurevych, Making monolingual sentence embeddings multilingual using knowledge distillation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_125",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_126@0",
            "content": "Eleanor Rosch, Carolyn Mervis, Family resemblances: Studies in the internal structure of categories, 1975, Cognitive Psychology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_126",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_127@0",
            "content": "M Thomas, Helen Segler, Antonella Pain,  Sorace, Second language vocabulary acquisition and learning strategies in ICALL environments, 2002, Computer Assisted Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_127",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_128@0",
            "content": "Kaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu, Mass: Masked sequence to sequence pre-training for language generation, 2019, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_128",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_129@0",
            "content": "Ilya Sutskever, Oriol Vinyals, Quoc V Le, Sequence to sequence learning with neural networks, 2014, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_129",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_130@0",
            "content": "UNKNOWN, None, 2001, Reconsidering prepositional polysemy networks: The case of over. Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_130",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_131@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proceedings of the 31st International Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_131",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_132@0",
            "content": "Tu Vu, Baotian Hu, Tsendsuren Munkhdalai, Hong Yu, Sentence simplification with memoryaugmented neural networks, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_132",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_133@0",
            "content": "Sander Wubben,  Van Den, Emiel Bosch,  Krahmer, Sentence simplification by monolingual machine translation, 2012, Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_133",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_134@0",
            "content": "Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, Chris Callison-Burch, Optimizing statistical machine translation for text simplification, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_134",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_135@0",
            "content": "UNKNOWN, None, , Qinan Fan, and Erhong Yang. 2020. Incorporating sememes into chinese definition modeling, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_135",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_136@0",
            "content": "UNKNOWN, None, , Speech, and Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_136",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_137@0",
            "content": "Xingxing Zhang, Mirella Lapata, Sentence simplification with deep reinforcement learning, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_137",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "473-ARR_v1_138@0",
            "content": "Yihua Zhang, Discussion on the Definitions in Chinese Learner's Dictionaries: Comparative Study of Domestic and Foreign Learner Dictionaries (Translated from Chinese), 2011, Chinese Teaching in the World, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "473-ARR_v1_138",
            "start": 0,
            "end": 205,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_1",
            "tgt_ix": "473-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_1",
            "tgt_ix": "473-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_4",
            "tgt_ix": "473-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_5",
            "tgt_ix": "473-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_6",
            "tgt_ix": "473-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_7",
            "tgt_ix": "473-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_8",
            "tgt_ix": "473-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_9",
            "tgt_ix": "473-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_10",
            "tgt_ix": "473-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_11",
            "tgt_ix": "473-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_14",
            "tgt_ix": "473-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_13",
            "tgt_ix": "473-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_13",
            "tgt_ix": "473-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_13",
            "tgt_ix": "473-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_13",
            "tgt_ix": "473-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_16",
            "tgt_ix": "473-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_18",
            "tgt_ix": "473-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_19",
            "tgt_ix": "473-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_17",
            "tgt_ix": "473-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_17",
            "tgt_ix": "473-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_17",
            "tgt_ix": "473-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_17",
            "tgt_ix": "473-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_20",
            "tgt_ix": "473-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_22",
            "tgt_ix": "473-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_21",
            "tgt_ix": "473-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_21",
            "tgt_ix": "473-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_21",
            "tgt_ix": "473-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_23",
            "tgt_ix": "473-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_25",
            "tgt_ix": "473-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_27",
            "tgt_ix": "473-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_28",
            "tgt_ix": "473-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_29",
            "tgt_ix": "473-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_26",
            "tgt_ix": "473-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_26",
            "tgt_ix": "473-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_26",
            "tgt_ix": "473-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_26",
            "tgt_ix": "473-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_26",
            "tgt_ix": "473-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_30",
            "tgt_ix": "473-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_32",
            "tgt_ix": "473-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_31",
            "tgt_ix": "473-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_31",
            "tgt_ix": "473-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_31",
            "tgt_ix": "473-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_31",
            "tgt_ix": "473-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_34",
            "tgt_ix": "473-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_36",
            "tgt_ix": "473-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_37",
            "tgt_ix": "473-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_38",
            "tgt_ix": "473-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_35",
            "tgt_ix": "473-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_35",
            "tgt_ix": "473-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_35",
            "tgt_ix": "473-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_35",
            "tgt_ix": "473-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_35",
            "tgt_ix": "473-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_39",
            "tgt_ix": "473-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_41",
            "tgt_ix": "473-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_42",
            "tgt_ix": "473-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_43",
            "tgt_ix": "473-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_44",
            "tgt_ix": "473-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_45",
            "tgt_ix": "473-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_46",
            "tgt_ix": "473-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_48",
            "tgt_ix": "473-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_49",
            "tgt_ix": "473-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_50",
            "tgt_ix": "473-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_51",
            "tgt_ix": "473-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_52",
            "tgt_ix": "473-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_53",
            "tgt_ix": "473-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_54",
            "tgt_ix": "473-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_57",
            "tgt_ix": "473-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_58",
            "tgt_ix": "473-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_59",
            "tgt_ix": "473-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_60",
            "tgt_ix": "473-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_61",
            "tgt_ix": "473-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_62",
            "tgt_ix": "473-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_56",
            "tgt_ix": "473-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_63",
            "tgt_ix": "473-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_64",
            "tgt_ix": "473-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_64",
            "tgt_ix": "473-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_64",
            "tgt_ix": "473-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_65",
            "tgt_ix": "473-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_67",
            "tgt_ix": "473-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_69",
            "tgt_ix": "473-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_66",
            "tgt_ix": "473-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_66",
            "tgt_ix": "473-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_66",
            "tgt_ix": "473-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_66",
            "tgt_ix": "473-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_66",
            "tgt_ix": "473-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_64",
            "tgt_ix": "473-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_70",
            "tgt_ix": "473-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_72",
            "tgt_ix": "473-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_73",
            "tgt_ix": "473-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_71",
            "tgt_ix": "473-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_71",
            "tgt_ix": "473-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_71",
            "tgt_ix": "473-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_71",
            "tgt_ix": "473-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_74",
            "tgt_ix": "473-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_75",
            "tgt_ix": "473-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_75",
            "tgt_ix": "473-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_75",
            "tgt_ix": "473-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_76",
            "tgt_ix": "473-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_77",
            "tgt_ix": "473-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_77",
            "tgt_ix": "473-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_77",
            "tgt_ix": "473-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_75",
            "tgt_ix": "473-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_79",
            "tgt_ix": "473-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_81",
            "tgt_ix": "473-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_82",
            "tgt_ix": "473-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_80",
            "tgt_ix": "473-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_80",
            "tgt_ix": "473-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_80",
            "tgt_ix": "473-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_80",
            "tgt_ix": "473-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_80",
            "tgt_ix": "473-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_80",
            "tgt_ix": "473-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_85",
            "tgt_ix": "473-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_87",
            "tgt_ix": "473-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_88",
            "tgt_ix": "473-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_86",
            "tgt_ix": "473-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_86",
            "tgt_ix": "473-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_86",
            "tgt_ix": "473-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_86",
            "tgt_ix": "473-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_89",
            "tgt_ix": "473-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_90",
            "tgt_ix": "473-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_90",
            "tgt_ix": "473-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_91",
            "tgt_ix": "473-ARR_v1_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_93",
            "tgt_ix": "473-ARR_v1_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_92",
            "tgt_ix": "473-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_92",
            "tgt_ix": "473-ARR_v1_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_92",
            "tgt_ix": "473-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_95",
            "tgt_ix": "473-ARR_v1_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_96",
            "tgt_ix": "473-ARR_v1_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_96",
            "tgt_ix": "473-ARR_v1_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "473-ARR_v1_0",
            "tgt_ix": "473-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_1",
            "tgt_ix": "473-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_2",
            "tgt_ix": "473-ARR_v1_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_3",
            "tgt_ix": "473-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_4",
            "tgt_ix": "473-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_4",
            "tgt_ix": "473-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_4",
            "tgt_ix": "473-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_4",
            "tgt_ix": "473-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_5",
            "tgt_ix": "473-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_5",
            "tgt_ix": "473-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_5",
            "tgt_ix": "473-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_6",
            "tgt_ix": "473-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_6",
            "tgt_ix": "473-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_6",
            "tgt_ix": "473-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_6",
            "tgt_ix": "473-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_7",
            "tgt_ix": "473-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_7",
            "tgt_ix": "473-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_7",
            "tgt_ix": "473-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_8",
            "tgt_ix": "473-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_8",
            "tgt_ix": "473-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_8",
            "tgt_ix": "473-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_9",
            "tgt_ix": "473-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_10",
            "tgt_ix": "473-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_10",
            "tgt_ix": "473-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_10",
            "tgt_ix": "473-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_10",
            "tgt_ix": "473-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_10",
            "tgt_ix": "473-ARR_v1_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_10",
            "tgt_ix": "473-ARR_v1_10@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_11",
            "tgt_ix": "473-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_12",
            "tgt_ix": "473-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_13",
            "tgt_ix": "473-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_14",
            "tgt_ix": "473-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_14",
            "tgt_ix": "473-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_15@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_15",
            "tgt_ix": "473-ARR_v1_15@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_16",
            "tgt_ix": "473-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_16",
            "tgt_ix": "473-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_16",
            "tgt_ix": "473-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_17",
            "tgt_ix": "473-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_18",
            "tgt_ix": "473-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_18",
            "tgt_ix": "473-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_19",
            "tgt_ix": "473-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_19",
            "tgt_ix": "473-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_19",
            "tgt_ix": "473-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_19",
            "tgt_ix": "473-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_19",
            "tgt_ix": "473-ARR_v1_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_20",
            "tgt_ix": "473-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_20",
            "tgt_ix": "473-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_21",
            "tgt_ix": "473-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_22",
            "tgt_ix": "473-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_22",
            "tgt_ix": "473-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_22",
            "tgt_ix": "473-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_22",
            "tgt_ix": "473-ARR_v1_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_22",
            "tgt_ix": "473-ARR_v1_22@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_22",
            "tgt_ix": "473-ARR_v1_22@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_23",
            "tgt_ix": "473-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_23",
            "tgt_ix": "473-ARR_v1_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_24",
            "tgt_ix": "473-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_25",
            "tgt_ix": "473-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_25",
            "tgt_ix": "473-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_26",
            "tgt_ix": "473-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_27",
            "tgt_ix": "473-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_27",
            "tgt_ix": "473-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_28",
            "tgt_ix": "473-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_29",
            "tgt_ix": "473-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_30",
            "tgt_ix": "473-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_30",
            "tgt_ix": "473-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_31",
            "tgt_ix": "473-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_32",
            "tgt_ix": "473-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_32",
            "tgt_ix": "473-ARR_v1_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_33@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_33@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_33@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_33",
            "tgt_ix": "473-ARR_v1_33@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_34",
            "tgt_ix": "473-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_34",
            "tgt_ix": "473-ARR_v1_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_34",
            "tgt_ix": "473-ARR_v1_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_35",
            "tgt_ix": "473-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_36",
            "tgt_ix": "473-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_36",
            "tgt_ix": "473-ARR_v1_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_37",
            "tgt_ix": "473-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_38",
            "tgt_ix": "473-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_38",
            "tgt_ix": "473-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_39",
            "tgt_ix": "473-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_40",
            "tgt_ix": "473-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_41",
            "tgt_ix": "473-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_41",
            "tgt_ix": "473-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_41",
            "tgt_ix": "473-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_42",
            "tgt_ix": "473-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_43",
            "tgt_ix": "473-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_43",
            "tgt_ix": "473-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_44",
            "tgt_ix": "473-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_45",
            "tgt_ix": "473-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_46",
            "tgt_ix": "473-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_47",
            "tgt_ix": "473-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_48",
            "tgt_ix": "473-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_48",
            "tgt_ix": "473-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_48",
            "tgt_ix": "473-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_49",
            "tgt_ix": "473-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_50",
            "tgt_ix": "473-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_50",
            "tgt_ix": "473-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_51",
            "tgt_ix": "473-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_52",
            "tgt_ix": "473-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_52",
            "tgt_ix": "473-ARR_v1_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_53",
            "tgt_ix": "473-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_54",
            "tgt_ix": "473-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_55",
            "tgt_ix": "473-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_56",
            "tgt_ix": "473-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_56",
            "tgt_ix": "473-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_56",
            "tgt_ix": "473-ARR_v1_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_57",
            "tgt_ix": "473-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_57",
            "tgt_ix": "473-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_57",
            "tgt_ix": "473-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_57",
            "tgt_ix": "473-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_58",
            "tgt_ix": "473-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_59",
            "tgt_ix": "473-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_60",
            "tgt_ix": "473-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_61",
            "tgt_ix": "473-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_61",
            "tgt_ix": "473-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_61",
            "tgt_ix": "473-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_62",
            "tgt_ix": "473-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_63",
            "tgt_ix": "473-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_64",
            "tgt_ix": "473-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_65",
            "tgt_ix": "473-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_65",
            "tgt_ix": "473-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_66",
            "tgt_ix": "473-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_67",
            "tgt_ix": "473-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_67",
            "tgt_ix": "473-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_67",
            "tgt_ix": "473-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_67",
            "tgt_ix": "473-ARR_v1_67@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_68@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_68@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_68@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_68",
            "tgt_ix": "473-ARR_v1_68@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_69",
            "tgt_ix": "473-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_69",
            "tgt_ix": "473-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_69",
            "tgt_ix": "473-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_70",
            "tgt_ix": "473-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_71",
            "tgt_ix": "473-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_72",
            "tgt_ix": "473-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_72",
            "tgt_ix": "473-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_72",
            "tgt_ix": "473-ARR_v1_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_72",
            "tgt_ix": "473-ARR_v1_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_72",
            "tgt_ix": "473-ARR_v1_72@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_73",
            "tgt_ix": "473-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_74",
            "tgt_ix": "473-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_74",
            "tgt_ix": "473-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_74",
            "tgt_ix": "473-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_75",
            "tgt_ix": "473-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_76",
            "tgt_ix": "473-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_77",
            "tgt_ix": "473-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_78",
            "tgt_ix": "473-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_78",
            "tgt_ix": "473-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_78",
            "tgt_ix": "473-ARR_v1_78@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_78",
            "tgt_ix": "473-ARR_v1_78@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_78",
            "tgt_ix": "473-ARR_v1_78@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_78",
            "tgt_ix": "473-ARR_v1_78@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_79",
            "tgt_ix": "473-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_79",
            "tgt_ix": "473-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_79",
            "tgt_ix": "473-ARR_v1_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_79",
            "tgt_ix": "473-ARR_v1_79@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_80",
            "tgt_ix": "473-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_81",
            "tgt_ix": "473-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_81",
            "tgt_ix": "473-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_81",
            "tgt_ix": "473-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_81",
            "tgt_ix": "473-ARR_v1_81@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_82",
            "tgt_ix": "473-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_82",
            "tgt_ix": "473-ARR_v1_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_83",
            "tgt_ix": "473-ARR_v1_83@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_84@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_84@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_84@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_84@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_84",
            "tgt_ix": "473-ARR_v1_84@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_85",
            "tgt_ix": "473-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_86",
            "tgt_ix": "473-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_87",
            "tgt_ix": "473-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_87",
            "tgt_ix": "473-ARR_v1_87@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_87",
            "tgt_ix": "473-ARR_v1_87@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_87",
            "tgt_ix": "473-ARR_v1_87@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_87",
            "tgt_ix": "473-ARR_v1_87@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_87",
            "tgt_ix": "473-ARR_v1_87@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_88",
            "tgt_ix": "473-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_88",
            "tgt_ix": "473-ARR_v1_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_88",
            "tgt_ix": "473-ARR_v1_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_89",
            "tgt_ix": "473-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_89",
            "tgt_ix": "473-ARR_v1_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_89",
            "tgt_ix": "473-ARR_v1_89@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_89",
            "tgt_ix": "473-ARR_v1_89@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_89",
            "tgt_ix": "473-ARR_v1_89@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_89",
            "tgt_ix": "473-ARR_v1_89@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_90",
            "tgt_ix": "473-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_91",
            "tgt_ix": "473-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_91",
            "tgt_ix": "473-ARR_v1_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_91",
            "tgt_ix": "473-ARR_v1_91@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_91",
            "tgt_ix": "473-ARR_v1_91@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_91",
            "tgt_ix": "473-ARR_v1_91@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_91",
            "tgt_ix": "473-ARR_v1_91@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_92",
            "tgt_ix": "473-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_93",
            "tgt_ix": "473-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_93",
            "tgt_ix": "473-ARR_v1_93@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_94",
            "tgt_ix": "473-ARR_v1_94@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_95",
            "tgt_ix": "473-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_96",
            "tgt_ix": "473-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_97",
            "tgt_ix": "473-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_97",
            "tgt_ix": "473-ARR_v1_97@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_97",
            "tgt_ix": "473-ARR_v1_97@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_97",
            "tgt_ix": "473-ARR_v1_97@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_97",
            "tgt_ix": "473-ARR_v1_97@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_97",
            "tgt_ix": "473-ARR_v1_97@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_98",
            "tgt_ix": "473-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_99",
            "tgt_ix": "473-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_100",
            "tgt_ix": "473-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_101",
            "tgt_ix": "473-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_102",
            "tgt_ix": "473-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_103",
            "tgt_ix": "473-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_104",
            "tgt_ix": "473-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_105",
            "tgt_ix": "473-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_106",
            "tgt_ix": "473-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_107",
            "tgt_ix": "473-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_108",
            "tgt_ix": "473-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_109",
            "tgt_ix": "473-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_110",
            "tgt_ix": "473-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_111",
            "tgt_ix": "473-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_112",
            "tgt_ix": "473-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_113",
            "tgt_ix": "473-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_114",
            "tgt_ix": "473-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_115",
            "tgt_ix": "473-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_116",
            "tgt_ix": "473-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_117",
            "tgt_ix": "473-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_118",
            "tgt_ix": "473-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_119",
            "tgt_ix": "473-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_120",
            "tgt_ix": "473-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_121",
            "tgt_ix": "473-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_122",
            "tgt_ix": "473-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_123",
            "tgt_ix": "473-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_124",
            "tgt_ix": "473-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_125",
            "tgt_ix": "473-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_126",
            "tgt_ix": "473-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_127",
            "tgt_ix": "473-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_128",
            "tgt_ix": "473-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_129",
            "tgt_ix": "473-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_130",
            "tgt_ix": "473-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_131",
            "tgt_ix": "473-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_132",
            "tgt_ix": "473-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_133",
            "tgt_ix": "473-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_134",
            "tgt_ix": "473-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_135",
            "tgt_ix": "473-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_136",
            "tgt_ix": "473-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_137",
            "tgt_ix": "473-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "473-ARR_v1_138",
            "tgt_ix": "473-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1372,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "473-ARR",
        "version": 1
    }
}