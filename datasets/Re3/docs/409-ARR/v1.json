{
    "nodes": [
        {
            "ix": "409-ARR_v1_0",
            "content": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_2",
            "content": "Metamorphic testing has recently been used to check the safety of neural NLP models. Its main advantage is that it does not rely on a ground truth to generate test cases. However, existing studies are mostly concerned with robustness-like metamorphic relations, limiting the scope of linguistic properties they can test. We propose three new classes of metamorphic relations, which address the properties of systematicity, compositionality and transitivity. Unlike robustness, our relations are defined over multiple source inputs, thus increasing the number of test cases that we can produce by a polynomial factor. With them, we test the internal consistency of state-of-theart NLP models, and show that they do not always behave according to their expected linguistic properties. Lastly, we introduce a novel graphical notation that efficiently summarises the inner structure of metamorphic relations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "409-ARR_v1_4",
            "content": "Many recent advances in neural models for NLP have been driven by the ability to learn from unlabeled data (Devlin et al., 2019;Liu et al., 2019b). This approach allows for training the models on large-scale corpora without the costly process of annotating them. As a result, the accuracy and complexity of state-of-the-art neural models for NLP have increased (Brown et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_5",
            "content": "This trend towards unlabeled data does not have a counterpart in testing NLP models. Instead, both in-distribution testing and out-of-distribution testing (Yin et al., 2019;Teney et al., 2020) rely on comparing the model's predictions to the ground truth. Similarly, attempts at probing the internal computation of large NLP models use supervised classifiers as a diagnostic tool (Ettinger et al., 2016;Belinkov et al., 2017).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_6",
            "content": "In general, such extreme reliance on groundtruth data limits the quantity and quality of test cases we can produce, which is a known problem in the software testing community (Barr et al., 2015). In this regard, a promising solution is metamorphic testing (Chen et al., 2018). Under this paradigm, we test the internal consistency of an NLP model by checking whether it satisfies a necessary relation of its inputs and outputs (Ribeiro et al., 2020). Consequently, metamorphic testing relies on our ability to formally express our expectations on the behaviour of an NLP model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_7",
            "content": "Still, most of the metamorphic relations proposed in the literature target the same type of behaviour, as we show in this paper. Indeed, the majority of them are robustness relations, which require that the output of an NLP model remains stable in the face of small input perturbations (Aspillaga et al., 2020). These perturbations may involve simple typos (Belinkov and Bisk, 2018;Gao et al., 2018;Heigold et al., 2018), replacing individual words with a synonym (Li et al., 2017;Jia et al., 2019;La Malfa et al., 2020), or adding irrelevant information to the input (Tu et al., 2021). Due to their simple structure, robustness-like relations have been applied to the testing of several NLP tasks, including sentiment analysis (Ribeiro et al., 2020), machine translation (Sun and Zhou, 2018), and question answering (Chan et al., 2021). Even testing the fairness of NLP models falls in this category (Ma et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_8",
            "content": "At the same time, we expect state-of-the-art NLP models to exhibit a broader range of linguistic properties than just robustness. First and foremost, NLP models should generalise systematically, i.e. their ability to understand some inputs should be intrinsically connected to their ability to understand related ones (Fodor and Pylyshyn, 1988). While the exact definition of systematic behaviour varies in the literature (Hupkes et al., 2020), a common requirement is that the model's predictions are a result of a composition of syntactic and semantic constituents of the input (Baroni, 2020). Several supervised methods to test against such requirements exist ( Et-tinger et al., 2016;Goodwin et al., 2020), but they all rely on comparing the model's predictions to the ground truth. Likewise, Yanaka et al. (2021) interprets systematicity as the ability to generalise over transitive relations. Their supervised method shows that current models struggle to do so.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_9",
            "content": "In this paper, we propose three new classes of metamorphic relations, which are designed to test the systematicity, compositionality and transitivity of NLP models. In true metamorphic fashion, our relations do not rely on ground-truth data and scale up the generation of test cases by a polynomial factor. For each proposed relation, we provide an illustrative experiment where we test state-of-theart models for the expected linguistic behaviours. More in detail, our main original contributions are: \u2022 Pairwise compositionality. Second, we modify pairwise systematicity to test the presence of compositional constituents in the hidden layers of neural models (Section 5). Accordingly, we test the pairwise compositionality of a natural language inference (NLI) model in Section 5.1, and show that it does not behave in a compositional way.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_10",
            "content": "\u2022 Three-way transitivity. Third, we introduce a class of relations to test the internal transitivity of an NLP model (Section 6). These relations are defined over triplets of source inputs. In Section 6.1, we test a state-of-theart model that predicts the lexical relation of words (synonymy, hypernymy), and show that it does not behave in a transitive way. \u2022 Graphical notation. Fourth, we propose a formal graphical notation for NLP metamorphic relations, that efficiently expresses their internal structure (Section 2). \u2022 Taxonomy of existing work. Fifth, we review the existing literature on metamorphic testing for NLP, and show that the relations proposed therein share the same structure with a single source input (Section 3).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_11",
            "content": "Lastly, in Section 7 we conclude and outline possible future work. We discuss the ethical implications of our work in Appendix A. We provide a quick-reference guide to our contribution in Appendix B. The code of our experiments and reproducibility checklist are available at https: //doi.org/10.5281/zenodo.5703459.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_12",
            "content": "A graphical notation for NLP metamorphic relations",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "409-ARR_v1_13",
            "content": "This section gives preliminary definitions and proposes a compact graphical notation for NLP metamorphic relations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_14",
            "content": ", . . . , x v , f (x 1 ), . . . , f (x v )), such that R \u2286 X 1 \u00d7 \u2022 \u2022 \u2022 \u00d7 X v \u00d7 Y 1 \u00d7 \u2022 \u2022 \u2022 \u00d7 Y v .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_15",
            "content": "However, we are interested in the internal structure of such a relation. Thus, let us discriminate between two types of inputs (Chen et al., 2018): Definition 2.3 (Source inputs). Given a relation R with v inputs, let (x 1 , . . . , x u ) with u \u2264 v be the sequence of source inputs. These can be chosen freely, e.g. by extracting them from a dataset D.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_16",
            "content": "Definition 2.4 (Follow-up inputs). Given a relation R with u source inputs, let (x u+1 , . . . , x v ) with u \u2264 v be the sequence of follow-up inputs. These are computed by a transformation of the source inputs",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_17",
            "content": "x i = T i (x 1 , . . . , x u ) for i \u2208 [u + 1, v].",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_18",
            "content": "Furthermore, all the relations in this paper prescribe specific conditions over the model's output: Definition 2.5 (Output property). Define P \u2286 Y 1 , . . . , Y v as a relation over the output. Here, we always write it in decidable first-order logic.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_19",
            "content": "Altogether, the structure of an NLP metamorphic relation can be easily described in graphical form. To do so, we introduce the following compact notation (see example in Figure 1). Textual variables are represented as circles, whereas numerical variables (e.g. embeddings, softmax outputs) are squares. Moreover, source inputs are shaded in grey, while all other nodes are in white. Arrows represent the neural function f and the transformation T i . Lastly, the output property P is linked to the relevant nodes with dashed lines.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_20",
            "content": "A taxonomy of existing NLP metamorphic relations",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "409-ARR_v1_21",
            "content": "Most of the existing literature on NLP metamorphic testing proposes relations that fit in the structure of Figure 1. Due to their reliance on just one source input, we refer to these metamorphic relations as single-input. The individual differences among them can be ascribed to the specific transformation T and property P . The present section derives a taxonomy of existing NLP relations by organising them along these two axes T and P . The transformation T is defined over the input text and thus allows for considerable creative freedom. A list of common options is presented here:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_22",
            "content": "\u2022 Character-level T . Character-level transformations are typically used to introduce noise in the input. Examples include replacing individual characters with a neighbouring one on a computer keyboard (Belinkov and Bisk, 2018) or a random one (Heigold et al., 2018). More aggressive transformations may involve swapping neighbouring characters (Belinkov and Bisk, 2018;Gao et al., 2018;Heigold et al., 2018) and shuffling a subset of the characters in a word (Belinkov and Bisk, 2018). Alternatively, a collection of real-world typos can be retrieved from datasets with edit history (e.g. Wikipedia) (Belinkov and Bisk, 2018). \u2022 Word-level T . A common word-level transformation involves replacing words with their synonym (Li et al., 2017). This operation has been shown to produce adversarial examples in (Jia et al., 2019;La Malfa et al., 2020). The use of antonyms has also been explored in Tu et al. (2021). In contrast, changing the gender of keywords in the input text can reveal the social biases of an NLP model (Ma et al., 2020).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_23",
            "content": "Similarly, swapping keywords in the context of a question-answer (QA) system can reveal inconsistent answers (Ribeiro et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_24",
            "content": "\u2022 Sentence-level T . Removal or concatenation of entire sentences from the input text has been tried too. Aspillaga et al. (2020) experiments with adding positive and negative tautologies at the end of the input. Similarly, Ribeiro et al. (2020) propose to concatenate both well-formed sentences and randomlygenerated URLs. More generally, the whole input text can have its sentences shuffled (Tu et al., 2021) or paraphrased (Li et al., 2017).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_25",
            "content": "Regarding the output property P , the current literature only offers three choices. We list them here, alongside their first-order logic formulation:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_26",
            "content": "\u2022 Equivalence P . Robustness relations require that the output does not change in the face of small input perturbations. Thus, we need a notion of equivalence between the source output y and its follow-up y (see Figure 1).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_27",
            "content": "For classification models, we can express it via the softmax output y = (y 1 , . . . , y c ) as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_28",
            "content": "P eq : \u2203i \u2200j = i (y i > y j ) \u2227 (y i > y j ) (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_29",
            "content": "where i is the predicted class. In rarer cases, where the output is textual, verbatim comparison can be used (Sun and Zhou, 2018).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_30",
            "content": "\u2022 Similarity P . For other applications, the equivalence property cannot be applied. For example, when testing QA systems, we want to detect similar but not identical answers. In such cases, we can define a similarity score s(y, y ) \u2208 R, e.g. cosine similarity between the embeddings of the two answers (Tu et al., 2021). With it, we can write similarity as:",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_31",
            "content": "P sim : s(y, y ) > \u03b8 (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_32",
            "content": "where \u03b8 is an arbitrary threshold chosen according to the user's domain knowledge.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_33",
            "content": "\u2022 Order P . At the same time, we can establish an order relation between the two outputs y and y . This order relation is useful in conjunction with transformations that have a monotonic effect on the output. For example, concatenating positive sentences to the input of a sentiment analysis system (Ribeiro et al., 2020). In such cases, let us define an order score s(y) \u2208 R, and write the output property as:",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_34",
            "content": "P ord : s(y) < s(y )(3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_35",
            "content": "In Sections 4, 5 and 6 we employ some of the transformations T and properties P defined here as building blocks for new metamorphic relations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_36",
            "content": "Pairwise NLP metamorphic relations for testing systematicity",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "409-ARR_v1_37",
            "content": "We introduce a new class of metamorphic relations to test the systematicity of NLP models. Here, we take the general definition of systematicity in Fodor and Pylyshyn (1988), which states that the predictions of an NLP model across related inputs should be intrinsically connected and express it as a metamorphic relation (see Figure 2). Since we do not want to rely on ground-truth data, we first establish a baseline for the model's behaviour by comparing its predictions across two different source inputs. Then, we perturb both source inputs via the same transformation and test whether the model's behaviour changes accordingly.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_38",
            "content": "x 1",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_39",
            "content": "x 1 y 1 y 1 y 2 y 2 x 2 x 2 P f f f f T T Figure 2: Structure of pairwise-systematicity relations.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_40",
            "content": "The two source inputs allow us to establish a baseline for the behaviour of model f , and test whether it changes according to expectations once T is applied.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_41",
            "content": "More formally, we define pairwise-systematicity relations as follows. Let x 1 , x 2 \u2208 D be a pair of source inputs, and x 1 , x 2 their corresponding follow-up inputs via transformation T . Furthermore, denote with y 1 , y 2 , y 1 , y 2 the outputs produced by model f . Finally, define the output property P in the following form:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_42",
            "content": "P : P src (y 1 , y 2 ) =\u21d2 P f lw (y 1 , y 2 ) (4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_43",
            "content": "Note that this definition does not rely on groundtruth data. In fact, we trust the model's predictions (y 1 , y 2 ) over the source inputs to establish our premise P src . The actual test checks whether transforming the source inputs with T produces outputs that satisfy the expected property P f wl . Any violation of this property, i.e. when P src \u2227 \u00acP f wl , reveals an inconsistency in the model's predictions that breaks the user's expectation of systematic behaviour. In Section 4.2, we give an intuitive geometrical explanation of the type of constraints imposed by pairwise-systematicity relations on the embedding space of a neural NLP model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_44",
            "content": "A hidden advantage of metamorphic relations with multiple source inputs (see also Sections 5 and 6) is that they naturally produce more test cases than single-input ones. In the case of pairwise systematicity, each input in the pair (x 1 , x 2 ) is extracted from the same dataset D. Thus, a dataset with |D| = k entries generates an O(k 2 ) number of test cases, as opposed to O(k) for single-input relations. We see an example of this in Section 4.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_45",
            "content": "Illustrative example: pairwise systematicity of sentiment analysis",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "409-ARR_v1_46",
            "content": "Now, let us apply the pairwise-systematicity relation structure shown in Figure 2 to a sentiment analysis task. To do so, we choose the following:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_47",
            "content": "\u2022 Transformation T . For each source input x i , we create a follow-up input x i = T (x i ) by concatenating a short sentence to it. A list of all transformations we use is in Table 1. \u2022 Output premise P src . Let s pos (y 1 ) and s pos (y 2 ) be the (positive) sentiment scores predicted by model f . Define the baseline behaviour of f as the order property P src = P ord between these two scores (see Equation 3). \u2022 Output hypothesis P f lw . Let s pos (y 1 ) and s pos (y 2 ) be the sentiment scores of the followup inputs. We require that their order matches the one of the source inputs. More formally: P f lw = P ord and P src \u21d0\u21d2 P f lw .",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_48",
            "content": "Our rationale is that the sentiment of any input shifts when we concatenate additional text. If we have ground-truth information on the sentiment of the text we are adding, we can test whether our predictions shift in the expected direction. For instance, concatenating \"I am very happy\" should make the score of any input more positive. This is an example of single-input relation (see Section 3 and Ribeiro et al., 2020). However, if we do not have such ground truth, we can still test our model. We do so by considering a pair of inputs (x 1 , x 2 ), and concatenating the same text to both of them. Then, whenever x 1 is predicted more positive than x 2 , we require that its transformed version x 1 is also more positive than x 2 and vice versa. This is pairwise systematicity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_49",
            "content": "Experiment description and results. We select a fine-tuned version of RoBERTa (Liu et al., 2019b) for sentiment analysis from the Hugging-Face library. 1 . We choose 10,605 movie reviews from Socher et al. (2013) as our dataset D. From it, we generate all 112M+ possible source input pairs. We repeat our experiment with different neutral transformations T , and report their aggregated results in Table 1. Note how the proportion of satisfied relations (\"Safety\") varies across different transformations. Yet, the model's behaviour is fairly systematic, never exceeding 10% violations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_50",
            "content": "We get a different picture by counting the number of violations per each source input x i \u2208 D (see Table 2). There, we can see that some inputs are more likely to make the source order P src (y 1 , y 2 ) unstable across all the transformations T . Interestingly, a quick read through the reviews in Table 2 shows that they are all misclassified. Thus, we can conclude that pairwise-systematicity testing reveals a different issue in the model f than classic non-metamorphic testing. For this reason, we encourage practitioners to perform both types of testing on their NLP models, as it will give a clearer",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_51",
            "content": "Table 2: Source inputs and their sentiment predictions, sorted by the number of times they appear in a safe pair.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_52",
            "content": "picture of their strengths and weaknesses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_53",
            "content": "Geometric interpretation of pairwise systematicity",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "409-ARR_v1_54",
            "content": "Metamorphic relations impose constraints between the inputs and outputs while treating the model f as a black box (Chen et al., 2018). Still, in neural networks, it is possible to trace the effect of a relation R on the hidden layers. Here, we give a geometric explanation of the type of constraints pairwise-systematicity relations put on the last embedding space of a neural NLP model. To this end, let us consider the relations in Section 4.1. Recall, that model f outputs a sentiment score s(y), which is a one-dimensional projection of the embedding space (see Figure 3). Accordingly, the premise P src and hypothesis P f lw are only concerned with the position of each embedding y along direction s. However, since the source and follow-up inputs differ due to transformation T , the two output properties P src and P f lw act on different points in the embedding space. Once we require that P src \u21d0\u21d2 P f lw , we set the expectation that f is exceptionally consistent at mapping pairs of inputs (x 1 , x 2 ) onto space Y in the same order. Such expectation is met if and only if f is a systematic, though not necessarily correct, function.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_55",
            "content": "Similar considerations apply if P src and P f lw are based on equality or similarity rather than order. Indeed, equality (see Equation 1) is defined over the softmax outputs, which are affine combinations of the embeddings (Bishop, 2006). In such case, the condition P src =\u21d2 P f lw translates to a requirement that if the source inputs are both mapped to the same half-space, the follow-up inputs should be too. Conversely, similarity (Equation 2) defines a measure on the embedding space. Source inputs that are within a certain threshold \u03b8 should be matched by follow-up inputs that are also close.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_56",
            "content": "The following section introduces a class of pairwise relations where the output premise and hypothesis are defined over different embedding spaces.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_57",
            "content": "Pairwise NLP metamorphic relations for testing compositionality",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "409-ARR_v1_58",
            "content": "Many probing works train simple supervised classifiers on top of the hidden representations of an NLP model (e.g. Hewitt and Manning, 2019).These classifiers, called probes, can reveal whether the neural model has learnt to recognise some fundamental constituents of the input language early on.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_59",
            "content": "The presence of such building blocks is a necessary condition for an NLP model to exhibit compositional behaviour (Baroni, 2020). Here, we propose to test the presence of compositional constituents in the hidden layers via metamorphic testing. Consider the graph in Figure 4. There, the neural model is split into the mathematical composition of two functions f \u2022 g. More precisely, z = f (x) are the hidden representation of some hidden layer, and y = g(z) is the final output. Now, let us define the output property P as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_60",
            "content": "P : P hid (z 1 , z 2 ) =\u21d2 P out (y 1 , y 2 ) (5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_61",
            "content": "A relation in this form allows us to express whether specific precursor signals in z are expected to have a direct effect on y. In a similar way to the relations in Section 4, both the premise P hid and hypothesis P out are established by comparing across pairs of inputs, rather than a ground-truth. In Section 5.1, we show how our technique can reveal the presence (or absence) of compositional building blocks in an NLP model. To test whether the model's predictions exhibit a compositional behaviour, we construct our test inputs according to Rozanova et al. (2021) we first choose a prototypical sentence template C( ), which we call a context. Each context includes a placeholder token that can be replaced with some insertion text. Second, we construct each input x = (C( a ), C( b )) by copying the same context twice with different insertions. Finally, we choose the contexts C i and insertion pairs ( a , b ) j in such a way that their composition (C( a ), C( b )) ij has a well-definite entailment relation. Namely, the insertion pairs (see Table 4) are either hypernyms (\u2287), hyponyms (\u2286), or unrelated (none). Similarly, the contexts (see Table 3) are either upward monotone if they preserve the insertion relation, or downward monotone if they invert it. As a result, only the compositions Up(\u2286) and Down(\u2287) are entailed, while the rest are not. Now, assume that both inputs x 1 and x 2 in Figure 4 are based on the same context C i . We can test whether the NLI model build its output by reasoning over the monotonicity of C i and the lexical relation of the insertion pairs ( a , b ) j as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_62",
            "content": "\u2022 Hidden premise P hid . Let z be the embeddings of the second to last layer, for the tokens corresponding to the insertions a and b . Train a linear probe s hyp on z (Liu et al., 2019a) to predict whether a is a hypernym of b . Define P hid = P ord as the order property (see Equation 3) over the hypernymy scores s hyp (z 1 ) and s hyp (z 2 ) of the two inputs. If the NLI model f \u2022 g had a compositional behaviour, the order P hid of the hypernymy scores in the hidden layer should be reflected in the order P out of the entailment scores in the output. Here, we show that this is not the case for a popular stateof-the-art NLI model.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_63",
            "content": "Experiment description and results. We build a dataset D of 292 insertions pairs and repeat our experiment with 211 contexts, for a total of about 9M test cases. We chose a fine-tuned version of RoBERTa for NLI as our model. 2 The accuracy of the hypernymy probe is 0.9881. We report the aggregated result by context in Table 3. Note how downward monotone contexts lead to less compositional behaviour: overall, we have 0.6880 successful test cases with upward contexts and only 0.4808 with downward ones. This phenomenon is known in the literature (Yanaka et al., 2019), but we show that metamorphic testing can independently detect it. If we aggregate the results by insertion pair (see Table 4), the picture does not change. The overall safety is 0.5936, which is barely above random chance. Any deviations from this baseline can be interpreted as noise.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_64",
            "content": "6 Three-way NLP metamorphic relations for testing transitivity",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_65",
            "content": "An NLP model that generalises correctly should exhibit transitive behaviour under the right circumstances Yanaka et al. (2021). That is, if the model predicts a transitive linguistic property over the input pairs (x 1 , x 2 ) and (x 2 , x 3 ), then it should also predict it for the pair (x 1 , x 3 ). Here, we propose to test this behaviour in a metamorphic way. More specifically, let us introduce the three-way transitivity relation in Figure 5. There, the three source inputs x 1 , x 2 , x 3 are combined to form all possible input pairs x ij = (x i , x j ). Then, we can test whether their corresponding outputs are transitive with the following output property:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_66",
            "content": "P : v(y 12 ) \u2227 v(y 23 ) \u21d2 v(y 13 )(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_67",
            "content": "where v(\u2022) : Y \u2192 {0, 1} is the Boolean prediction of model f . Note that the output property P , being defined over three outputs, has a different structure from those in Sections 3, 4 and 5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_68",
            "content": "Illustrative example: three-way transitivity of lexical relations",
            "ntype": "title",
            "meta": {
                "section": "6.1"
            }
        },
        {
            "ix": "409-ARR_v1_69",
            "content": "In this section, we apply the metamorphic structure from Figure 5 to test the transitivity of lexical semantic relations, e.g. synonymy and hypernymy (Santus et al., 2016). In general, learning these linguistic properties is crucial for solving several NLI tasks (Glockner et al., 2018). Thus, we can expect an NLP model to generalise over them in a transitive way. We can test whether this is true in the following way:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_70",
            "content": "\u2022 Transformation T . The model f we test already accepts a pair of words x ij = (x i , x j ) as input. Thus, T is merely a formalism here. Note that transitivity can be tested in a supervised fashion by comparing the model's predictions to a ground truth (Yanaka et al., 2021). In contrast, the three-way transitivity relations we propose test the internal transitivity of a model trained to predict lexical relations.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_71",
            "content": "Experiment description and results. We reproduce a state-of-the-art model for lexical relations (Wachowiak et al., 2020), which is a finetuned version of the multi-lingual transformer model xlmroberta (Conneau et al., 2020). We extract the multi-lingual test set from the Co-gALex_VI shared task (Santus et al., 2016), and generate a random sample of source triplets from its corpus of words, keeping those that satisfy v(y 12 ) \u2227 v(y 23 ). We present our empirical results in Table 5, organised by the language of the source words and lexical relation v predicted by the model. As the table shows, this state-of-the-art NLP model fails to predict v(y 13 ) in a transitive way across all languages. This is in contrast with the results of classic supervised testing in Wachowiak et al. (2020), which show that their model can predict the correct lexical relations (synonym, hypernym, antonym or random) with at least 0.5 of accuracy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_72",
            "content": "Conclusions and future work",
            "ntype": "title",
            "meta": {
                "section": "7"
            }
        },
        {
            "ix": "409-ARR_v1_73",
            "content": "In this paper, we presented three new classes on metamorphic relations. Thanks to them, we could test the systematicity, compositionality and transitivity of state-of-the-art NLP models. The advantage of our approach is that it does not rely on ground-truth annotations. It can generate a polynomially larger number of test cases than supervised testing, revealing whether the NLP model under test is internally consistent.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_74",
            "content": "Still, testing is only one side of the coin. Like in recent work about robustness (Aspillaga et al., 2020), the tested models have not been trained on a metamorphic objective (e.g. as an additional loss term). We believe that doing so could improve the safety and consistency of a model's predictions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "409-ARR_v1_75",
            "content": "Carlos Aspillaga, Andr\u00e9s Carvallo, Vladimir Araujo, Stress test evaluation of transformerbased models in natural language understanding tasks, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Carlos Aspillaga",
                    "Andr\u00e9s Carvallo",
                    "Vladimir Araujo"
                ],
                "title": "Stress test evaluation of transformerbased models in natural language understanding tasks",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 12th Language Resources and Evaluation Conference",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_76",
            "content": "Marco Baroni, Linguistic generalization and compositionality in modern artificial neural networks, 1791, Philosophical Transactions of the Royal Society B: Biological Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Marco Baroni"
                ],
                "title": "Linguistic generalization and compositionality in modern artificial neural networks",
                "pub_date": "1791",
                "pub_title": "Philosophical Transactions of the Royal Society B: Biological Sciences",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_77",
            "content": "T Earl, Mark Barr, Phil Harman, Muzammil Mcminn, Shin Shahbaz,  Yoo, The oracle problem in software testing: A survey, 2015, IEEE Transactions on Software Engineering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "T Earl",
                    "Mark Barr",
                    "Phil Harman",
                    "Muzammil Mcminn",
                    "Shin Shahbaz",
                    " Yoo"
                ],
                "title": "The oracle problem in software testing: A survey",
                "pub_date": "2015",
                "pub_title": "IEEE Transactions on Software Engineering",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_78",
            "content": "Yonatan Belinkov, Yonatan Bisk, Synthetic and natural noise both break neural machine translation, 2018, International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Yonatan Belinkov",
                    "Yonatan Bisk"
                ],
                "title": "Synthetic and natural noise both break neural machine translation",
                "pub_date": "2018",
                "pub_title": "International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_79",
            "content": "Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, James Glass, What do neural machine translation models learn about morphology?, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Yonatan Belinkov",
                    "Nadir Durrani",
                    "Fahim Dalvi",
                    "Hassan Sajjad",
                    "James Glass"
                ],
                "title": "What do neural machine translation models learn about morphology?",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "409-ARR_v1_80",
            "content": "UNKNOWN, None, 2006, Pattern Recognition and Machine Learning (Information Science and Statistics), Springer-Verlag.",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2006",
                "pub_title": "Pattern Recognition and Machine Learning (Information Science and Statistics)",
                "pub": "Springer-Verlag"
            }
        },
        {
            "ix": "409-ARR_v1_81",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Tom Brown",
                    "Benjamin Mann",
                    "Nick Ryder",
                    "Melanie Subbiah",
                    "Jared Kaplan",
                    "Prafulla Dhariwal",
                    "Arvind Neelakantan",
                    "Pranav Shyam",
                    "Girish Sastry",
                    "Amanda Askell",
                    "Sandhini Agarwal",
                    "Ariel Herbert-Voss",
                    "Gretchen Krueger",
                    "Tom Henighan",
                    "Rewon Child",
                    "Aditya Ramesh",
                    "Daniel Ziegler",
                    "Jeffrey Wu",
                    "Clemens Winter",
                    "Chris Hesse",
                    "Mark Chen",
                    "Eric Sigler",
                    "Mateusz Litwin"
                ],
                "title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners",
                "pub_date": null,
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "409-ARR_v1_82",
            "content": "Alvin Chan, Lei Ma, Felix Juefei-Xu, Yew-Soon Ong, Xiaofei Xie, Minhui Xue, Yang Liu, Breaking neural reasoning architectures with metamorphic relation-based adversarial examples, 2021, IEEE Transactions on Neural Networks and Learning Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Alvin Chan",
                    "Lei Ma",
                    "Felix Juefei-Xu",
                    "Yew-Soon Ong",
                    "Xiaofei Xie",
                    "Minhui Xue",
                    "Yang Liu"
                ],
                "title": "Breaking neural reasoning architectures with metamorphic relation-based adversarial examples",
                "pub_date": "2021",
                "pub_title": "IEEE Transactions on Neural Networks and Learning Systems",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_83",
            "content": "Fei-Ching Tsong Yueh Chen, Huai Kuo, Pak-Lok Liu, Dave Poon, T Towey, Zhi Quan Tse,  Zhou, Metamorphic testing: A review of challenges and opportunities, 2018, ACM Comput. Surv, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Fei-Ching Tsong Yueh Chen",
                    "Huai Kuo",
                    "Pak-Lok Liu",
                    "Dave Poon",
                    "T Towey",
                    "Zhi Quan Tse",
                    " Zhou"
                ],
                "title": "Metamorphic testing: A review of challenges and opportunities",
                "pub_date": "2018",
                "pub_title": "ACM Comput. Surv",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_84",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_85",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "409-ARR_v1_86",
            "content": "Allyson Ettinger, Ahmed Elgohary, Philip Resnik, Probing for semantic evidence of composition by means of simple classification tasks, 2016, Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Allyson Ettinger",
                    "Ahmed Elgohary",
                    "Philip Resnik"
                ],
                "title": "Probing for semantic evidence of composition by means of simple classification tasks",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_87",
            "content": "Jerry Fodor, Zenon Pylyshyn, Connectionism and cognitive architecture: A critical analysis, 1988, Cognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Jerry Fodor",
                    "Zenon Pylyshyn"
                ],
                "title": "Connectionism and cognitive architecture: A critical analysis",
                "pub_date": "1988",
                "pub_title": "Cognition",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_88",
            "content": "Ji Gao, Jack Lanchantin, Mary Soffa, Yanjun Qi, Black-box generation of adversarial text sequences to evade deep learning classifiers, 2018, 2018 IEEE Security and Privacy Workshops (SPW), .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Ji Gao",
                    "Jack Lanchantin",
                    "Mary Soffa",
                    "Yanjun Qi"
                ],
                "title": "Black-box generation of adversarial text sequences to evade deep learning classifiers",
                "pub_date": "2018",
                "pub_title": "2018 IEEE Security and Privacy Workshops (SPW)",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_89",
            "content": "Max Glockner, Vered Shwartz, Yoav Goldberg, Breaking NLI systems with sentences that require simple lexical inferences, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Max Glockner",
                    "Vered Shwartz",
                    "Yoav Goldberg"
                ],
                "title": "Breaking NLI systems with sentences that require simple lexical inferences",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "409-ARR_v1_90",
            "content": "Emily Goodwin, Koustuv Sinha, Timothy O'donnell, Probing linguistic systematicity, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Emily Goodwin",
                    "Koustuv Sinha",
                    "Timothy O'donnell"
                ],
                "title": "Probing linguistic systematicity",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "409-ARR_v1_91",
            "content": "Georg Heigold, Stalin Varanasi, G\u00fcnter Neumann, Josef Van Genabith, How robust are characterbased word embeddings in tagging and MT against wrod scramlbing or randdm nouse?, 2018, Proceedings of the 13th Conference of the Association for Machine Translation in the Americas, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Georg Heigold",
                    "Stalin Varanasi",
                    "G\u00fcnter Neumann",
                    "Josef Van Genabith"
                ],
                "title": "How robust are characterbased word embeddings in tagging and MT against wrod scramlbing or randdm nouse?",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 13th Conference of the Association for Machine Translation in the Americas",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_92",
            "content": "John Hewitt, Christopher Manning, A structural probe for finding syntax in word representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "John Hewitt",
                    "Christopher Manning"
                ],
                "title": "A structural probe for finding syntax in word representations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "409-ARR_v1_93",
            "content": "Dieuwke Hupkes, Verna Dankers, Mathijs Mul, Elia Bruni, Compositionality decomposed: how do neural networks generalise, 2020, Journal of Artificial Intelligence Research, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Dieuwke Hupkes",
                    "Verna Dankers",
                    "Mathijs Mul",
                    "Elia Bruni"
                ],
                "title": "Compositionality decomposed: how do neural networks generalise",
                "pub_date": "2020",
                "pub_title": "Journal of Artificial Intelligence Research",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_94",
            "content": "Robin Jia, Aditi Raghunathan, Kerem G\u00f6ksel, Percy Liang, Certified robustness to adversarial word substitutions, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Robin Jia",
                    "Aditi Raghunathan",
                    "Kerem G\u00f6ksel",
                    "Percy Liang"
                ],
                "title": "Certified robustness to adversarial word substitutions",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "409-ARR_v1_95",
            "content": "Min Emanuele La Malfa, Luca Wu, Benjie Laurenti, Anthony Wang, Marta Hartshorn,  Kwiatkowska, Assessing robustness of text classification through maximal safe radius computation, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Min Emanuele La Malfa",
                    "Luca Wu",
                    "Benjie Laurenti",
                    "Anthony Wang",
                    "Marta Hartshorn",
                    " Kwiatkowska"
                ],
                "title": "Assessing robustness of text classification through maximal safe radius computation",
                "pub_date": "2020",
                "pub_title": "Findings of the Association for Computational Linguistics: EMNLP 2020",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_96",
            "content": "Yitong Li, Trevor Cohn, Timothy Baldwin, Robust training under linguistic adversity, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Yitong Li",
                    "Trevor Cohn",
                    "Timothy Baldwin"
                ],
                "title": "Robust training under linguistic adversity",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "409-ARR_v1_97",
            "content": "Nelson Liu, Matt Gardner, Yonatan Belinkov, Matthew Peters, Noah Smith, Linguistic knowledge and transferability of contextual representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Nelson Liu",
                    "Matt Gardner",
                    "Yonatan Belinkov",
                    "Matthew Peters",
                    "Noah Smith"
                ],
                "title": "Linguistic knowledge and transferability of contextual representations",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "409-ARR_v1_98",
            "content": "UNKNOWN, None, 1907, RoBERTa: A robustly optimized bert pretraining approach. ArXiv, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "1907",
                "pub_title": "RoBERTa: A robustly optimized bert pretraining approach. ArXiv, abs",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_99",
            "content": "Pingchuan Ma, Shuai Wang, Jin Liu, Metamorphic testing and certified mitigation of fairness violations in NLP models, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Pingchuan Ma",
                    "Shuai Wang",
                    "Jin Liu"
                ],
                "title": "Metamorphic testing and certified mitigation of fairness violations in NLP models",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_100",
            "content": "Tongshuang Marco Tulio Ribeiro, Carlos Wu, Sameer Guestrin,  Singh, Beyond accuracy: Behavioral testing of NLP models with CheckList, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Tongshuang Marco Tulio Ribeiro",
                    "Carlos Wu",
                    "Sameer Guestrin",
                    " Singh"
                ],
                "title": "Beyond accuracy: Behavioral testing of NLP models with CheckList",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_101",
            "content": "UNKNOWN, None, 2021, Supporting context monotonicity abstractions in neural NLI models, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Supporting context monotonicity abstractions in neural NLI models",
                "pub": "CoRR"
            }
        },
        {
            "ix": "409-ARR_v1_102",
            "content": "Enrico Santus, Anna Gladkova, Stefan Evert, Alessandro Lenci, The CogALex-V shared task on the corpus-based identification of semantic relations, 2016, Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex -V), .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Enrico Santus",
                    "Anna Gladkova",
                    "Stefan Evert",
                    "Alessandro Lenci"
                ],
                "title": "The CogALex-V shared task on the corpus-based identification of semantic relations",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex -V)",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_103",
            "content": "Richard Socher, John Bauer, Christopher Manning, Andrew Ng, Parsing with compositional vector grammars, 2013, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Richard Socher",
                    "John Bauer",
                    "Christopher Manning",
                    "Andrew Ng"
                ],
                "title": "Parsing with compositional vector grammars",
                "pub_date": "2013",
                "pub_title": "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "409-ARR_v1_104",
            "content": "Liqun Sun,  Zhi Quan,  Zhou, Metamorphic testing for machine translations: Mt4mt, 2018, 25th Australasian Software Engineering Conference (ASWEC), .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Liqun Sun",
                    " Zhi Quan",
                    " Zhou"
                ],
                "title": "Metamorphic testing for machine translations: Mt4mt",
                "pub_date": "2018",
                "pub_title": "25th Australasian Software Engineering Conference (ASWEC)",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_105",
            "content": "Damien Teney, Ehsan Abbasnejad, Kushal Kafle, Robik Shrestha, Christopher Kanan, Anton Van Den,  Hengel, On the value of out-of-distribution testing: An example of goodhart's law, 2020, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Damien Teney",
                    "Ehsan Abbasnejad",
                    "Kushal Kafle",
                    "Robik Shrestha",
                    "Christopher Kanan",
                    "Anton Van Den",
                    " Hengel"
                ],
                "title": "On the value of out-of-distribution testing: An example of goodhart's law",
                "pub_date": "2020",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "409-ARR_v1_106",
            "content": "Kaiyi Tu, Mingyue Jiang, Zuohua Ding, A metamorphic testing approach for assessing question answering systems, 2021, Mathematics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Kaiyi Tu",
                    "Mingyue Jiang",
                    "Zuohua Ding"
                ],
                "title": "A metamorphic testing approach for assessing question answering systems",
                "pub_date": "2021",
                "pub_title": "Mathematics",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_107",
            "content": "Lennart Wachowiak, Christian Lang, Barbara Heinisch, Dagmar Gromann, CogALex-VI shared task: Transrelation -a robust multilingual language model for multilingual relation identification, 2020, Proceedings of the Workshop on the Cognitive Aspects of the Lexicon, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Lennart Wachowiak",
                    "Christian Lang",
                    "Barbara Heinisch",
                    "Dagmar Gromann"
                ],
                "title": "CogALex-VI shared task: Transrelation -a robust multilingual language model for multilingual relation identification",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Workshop on the Cognitive Aspects of the Lexicon",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_108",
            "content": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, Kentaro Inui, Satoshi Sekine, Lasha Abzianidze, Johan Bos, HELP: A dataset for identifying shortcomings of neural models in monotonicity reasoning, 2019, Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Hitomi Yanaka",
                    "Koji Mineshima",
                    "Daisuke Bekki",
                    "Kentaro Inui",
                    "Satoshi Sekine",
                    "Lasha Abzianidze",
                    "Johan Bos"
                ],
                "title": "HELP: A dataset for identifying shortcomings of neural models in monotonicity reasoning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "409-ARR_v1_109",
            "content": "Hitomi Yanaka, Koji Mineshima, Kentaro Inui, Exploring transitivity in neural NLI models through veridicality, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Hitomi Yanaka",
                    "Koji Mineshima",
                    "Kentaro Inui"
                ],
                "title": "Exploring transitivity in neural NLI models through veridicality",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_110",
            "content": "UNKNOWN, None, 2019, Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach",
                "pub": null
            }
        },
        {
            "ix": "409-ARR_v1_111",
            "content": "UNKNOWN, None, , Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "409-ARR_v1_0@0",
            "content": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_0",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_2@0",
            "content": "Metamorphic testing has recently been used to check the safety of neural NLP models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_2",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_2@1",
            "content": "Its main advantage is that it does not rely on a ground truth to generate test cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_2",
            "start": 85,
            "end": 169,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_2@2",
            "content": "However, existing studies are mostly concerned with robustness-like metamorphic relations, limiting the scope of linguistic properties they can test.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_2",
            "start": 171,
            "end": 319,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_2@3",
            "content": "We propose three new classes of metamorphic relations, which address the properties of systematicity, compositionality and transitivity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_2",
            "start": 321,
            "end": 456,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_2@4",
            "content": "Unlike robustness, our relations are defined over multiple source inputs, thus increasing the number of test cases that we can produce by a polynomial factor.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_2",
            "start": 458,
            "end": 615,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_2@5",
            "content": "With them, we test the internal consistency of state-of-theart NLP models, and show that they do not always behave according to their expected linguistic properties.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_2",
            "start": 617,
            "end": 781,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_2@6",
            "content": "Lastly, we introduce a novel graphical notation that efficiently summarises the inner structure of metamorphic relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_2",
            "start": 783,
            "end": 903,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_4@0",
            "content": "Many recent advances in neural models for NLP have been driven by the ability to learn from unlabeled data (Devlin et al., 2019;Liu et al., 2019b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_4",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_4@1",
            "content": "This approach allows for training the models on large-scale corpora without the costly process of annotating them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_4",
            "start": 148,
            "end": 261,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_4@2",
            "content": "As a result, the accuracy and complexity of state-of-the-art neural models for NLP have increased (Brown et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_4",
            "start": 263,
            "end": 381,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_5@0",
            "content": "This trend towards unlabeled data does not have a counterpart in testing NLP models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_5",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_5@1",
            "content": "Instead, both in-distribution testing and out-of-distribution testing (Yin et al., 2019;Teney et al., 2020) rely on comparing the model's predictions to the ground truth.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_5",
            "start": 85,
            "end": 254,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_5@2",
            "content": "Similarly, attempts at probing the internal computation of large NLP models use supervised classifiers as a diagnostic tool (Ettinger et al., 2016;Belinkov et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_5",
            "start": 256,
            "end": 425,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_6@0",
            "content": "In general, such extreme reliance on groundtruth data limits the quantity and quality of test cases we can produce, which is a known problem in the software testing community (Barr et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_6",
            "start": 0,
            "end": 194,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_6@1",
            "content": "In this regard, a promising solution is metamorphic testing (Chen et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_6",
            "start": 196,
            "end": 275,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_6@2",
            "content": "Under this paradigm, we test the internal consistency of an NLP model by checking whether it satisfies a necessary relation of its inputs and outputs (Ribeiro et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_6",
            "start": 277,
            "end": 449,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_6@3",
            "content": "Consequently, metamorphic testing relies on our ability to formally express our expectations on the behaviour of an NLP model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_6",
            "start": 451,
            "end": 576,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_7@0",
            "content": "Still, most of the metamorphic relations proposed in the literature target the same type of behaviour, as we show in this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_7",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_7@1",
            "content": "Indeed, the majority of them are robustness relations, which require that the output of an NLP model remains stable in the face of small input perturbations (Aspillaga et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_7",
            "start": 129,
            "end": 310,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_7@2",
            "content": "These perturbations may involve simple typos (Belinkov and Bisk, 2018;Gao et al., 2018;Heigold et al., 2018), replacing individual words with a synonym (Li et al., 2017;Jia et al., 2019;La Malfa et al., 2020), or adding irrelevant information to the input (Tu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_7",
            "start": 312,
            "end": 585,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_7@3",
            "content": "Due to their simple structure, robustness-like relations have been applied to the testing of several NLP tasks, including sentiment analysis (Ribeiro et al., 2020), machine translation (Sun and Zhou, 2018), and question answering (Chan et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_7",
            "start": 587,
            "end": 836,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_7@4",
            "content": "Even testing the fairness of NLP models falls in this category (Ma et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_7",
            "start": 838,
            "end": 918,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_8@0",
            "content": "At the same time, we expect state-of-the-art NLP models to exhibit a broader range of linguistic properties than just robustness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_8",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_8@1",
            "content": "First and foremost, NLP models should generalise systematically, i.e. their ability to understand some inputs should be intrinsically connected to their ability to understand related ones (Fodor and Pylyshyn, 1988).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_8",
            "start": 130,
            "end": 344,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_8@2",
            "content": "While the exact definition of systematic behaviour varies in the literature (Hupkes et al., 2020), a common requirement is that the model's predictions are a result of a composition of syntactic and semantic constituents of the input (Baroni, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_8",
            "start": 346,
            "end": 594,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_8@3",
            "content": "Several supervised methods to test against such requirements exist ( Et-tinger et al., 2016;Goodwin et al., 2020), but they all rely on comparing the model's predictions to the ground truth.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_8",
            "start": 596,
            "end": 785,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_8@4",
            "content": "Likewise, Yanaka et al. (2021) interprets systematicity as the ability to generalise over transitive relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_8",
            "start": 787,
            "end": 897,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_8@5",
            "content": "Their supervised method shows that current models struggle to do so.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_8",
            "start": 899,
            "end": 966,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_9@0",
            "content": "In this paper, we propose three new classes of metamorphic relations, which are designed to test the systematicity, compositionality and transitivity of NLP models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_9",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_9@1",
            "content": "In true metamorphic fashion, our relations do not rely on ground-truth data and scale up the generation of test cases by a polynomial factor.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_9",
            "start": 165,
            "end": 305,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_9@2",
            "content": "For each proposed relation, we provide an illustrative experiment where we test state-of-theart models for the expected linguistic behaviours.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_9",
            "start": 307,
            "end": 448,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_9@3",
            "content": "More in detail, our main original contributions are: \u2022 Pairwise compositionality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_9",
            "start": 450,
            "end": 530,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_9@4",
            "content": "Second, we modify pairwise systematicity to test the presence of compositional constituents in the hidden layers of neural models (Section 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_9",
            "start": 532,
            "end": 673,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_9@5",
            "content": "Accordingly, we test the pairwise compositionality of a natural language inference (NLI) model in Section 5.1, and show that it does not behave in a compositional way.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_9",
            "start": 675,
            "end": 841,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_10@0",
            "content": "\u2022 Three-way transitivity. Third, we introduce a class of relations to test the internal transitivity of an NLP model (Section 6). These relations are defined over triplets of source inputs. In Section 6.1, we test a state-of-theart model that predicts the lexical relation of words (synonymy, hypernymy), and show that it does not behave in a transitive way. \u2022 Graphical notation. Fourth, we propose a formal graphical notation for NLP metamorphic relations, that efficiently expresses their internal structure (Section 2). \u2022 Taxonomy of existing work. Fifth, we review the existing literature on metamorphic testing for NLP, and show that the relations proposed therein share the same structure with a single source input (Section 3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_10",
            "start": 0,
            "end": 734,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_11@0",
            "content": "Lastly, in Section 7 we conclude and outline possible future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_11",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_11@1",
            "content": "We discuss the ethical implications of our work in Appendix A. We provide a quick-reference guide to our contribution in Appendix B. The code of our experiments and reproducibility checklist are available at https: //doi.org/10.5281/zenodo.5703459.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_11",
            "start": 67,
            "end": 314,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_12@0",
            "content": "A graphical notation for NLP metamorphic relations",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_12",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_13@0",
            "content": "This section gives preliminary definitions and proposes a compact graphical notation for NLP metamorphic relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_13",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_14@0",
            "content": ", . . . , x v , f (x 1 ), . . . , f (x v )), such that R \u2286 X 1 \u00d7 \u2022 \u2022 \u2022 \u00d7 X v \u00d7 Y 1 \u00d7 \u2022 \u2022 \u2022 \u00d7 Y v .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_14",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_15@0",
            "content": "However, we are interested in the internal structure of such a relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_15",
            "start": 0,
            "end": 71,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_15@1",
            "content": "Thus, let us discriminate between two types of inputs (Chen et al., 2018): Definition 2.3 (Source inputs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_15",
            "start": 73,
            "end": 178,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_15@2",
            "content": "Given a relation R with v inputs, let (x 1 , . . . , x u ) with u \u2264 v be the sequence of source inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_15",
            "start": 180,
            "end": 282,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_15@3",
            "content": "These can be chosen freely, e.g. by extracting them from a dataset D.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_15",
            "start": 284,
            "end": 352,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_16@0",
            "content": "Definition 2.4 (Follow-up inputs).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_16",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_16@1",
            "content": "Given a relation R with u source inputs, let (x u+1 , . . . , x v ) with u \u2264 v be the sequence of follow-up inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_16",
            "start": 35,
            "end": 149,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_16@2",
            "content": "These are computed by a transformation of the source inputs",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_16",
            "start": 151,
            "end": 209,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_17@0",
            "content": "x i = T i (x 1 , . . . , x u ) for i \u2208 [u + 1, v].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_17",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_18@0",
            "content": "Furthermore, all the relations in this paper prescribe specific conditions over the model's output: Definition 2.5 (Output property).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_18",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_18@1",
            "content": "Define P \u2286 Y 1 , . . . , Y v as a relation over the output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_18",
            "start": 134,
            "end": 192,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_18@2",
            "content": "Here, we always write it in decidable first-order logic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_18",
            "start": 194,
            "end": 249,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_19@0",
            "content": "Altogether, the structure of an NLP metamorphic relation can be easily described in graphical form.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_19",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_19@1",
            "content": "To do so, we introduce the following compact notation (see example in Figure 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_19",
            "start": 100,
            "end": 179,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_19@2",
            "content": "Textual variables are represented as circles, whereas numerical variables (e.g. embeddings, softmax outputs) are squares.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_19",
            "start": 181,
            "end": 301,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_19@3",
            "content": "Moreover, source inputs are shaded in grey, while all other nodes are in white.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_19",
            "start": 303,
            "end": 381,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_19@4",
            "content": "Arrows represent the neural function f and the transformation T i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_19",
            "start": 383,
            "end": 449,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_19@5",
            "content": "Lastly, the output property P is linked to the relevant nodes with dashed lines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_19",
            "start": 451,
            "end": 530,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_20@0",
            "content": "A taxonomy of existing NLP metamorphic relations",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_20",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_21@0",
            "content": "Most of the existing literature on NLP metamorphic testing proposes relations that fit in the structure of Figure 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_21",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_21@1",
            "content": "Due to their reliance on just one source input, we refer to these metamorphic relations as single-input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_21",
            "start": 117,
            "end": 220,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_21@2",
            "content": "The individual differences among them can be ascribed to the specific transformation T and property P .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_21",
            "start": 222,
            "end": 324,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_21@3",
            "content": "The present section derives a taxonomy of existing NLP relations by organising them along these two axes T and P .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_21",
            "start": 326,
            "end": 439,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_21@4",
            "content": "The transformation T is defined over the input text and thus allows for considerable creative freedom.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_21",
            "start": 441,
            "end": 542,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_21@5",
            "content": "A list of common options is presented here:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_21",
            "start": 544,
            "end": 586,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_22@0",
            "content": "\u2022 Character-level T . Character-level transformations are typically used to introduce noise in the input. Examples include replacing individual characters with a neighbouring one on a computer keyboard (Belinkov and Bisk, 2018) or a random one (Heigold et al., 2018). More aggressive transformations may involve swapping neighbouring characters (Belinkov and Bisk, 2018;Gao et al., 2018;Heigold et al., 2018) and shuffling a subset of the characters in a word (Belinkov and Bisk, 2018). Alternatively, a collection of real-world typos can be retrieved from datasets with edit history (e.g. Wikipedia) (Belinkov and Bisk, 2018). \u2022 Word-level T . A common word-level transformation involves replacing words with their synonym (Li et al., 2017). This operation has been shown to produce adversarial examples in (Jia et al., 2019;La Malfa et al., 2020). The use of antonyms has also been explored in Tu et al. (2021). In contrast, changing the gender of keywords in the input text can reveal the social biases of an NLP model (Ma et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_22",
            "start": 0,
            "end": 1039,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_23@0",
            "content": "Similarly, swapping keywords in the context of a question-answer (QA) system can reveal inconsistent answers (Ribeiro et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_23",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_24@0",
            "content": "\u2022 Sentence-level T . Removal or concatenation of entire sentences from the input text has been tried too. Aspillaga et al. (2020) experiments with adding positive and negative tautologies at the end of the input. Similarly, Ribeiro et al. (2020) propose to concatenate both well-formed sentences and randomlygenerated URLs. More generally, the whole input text can have its sentences shuffled (Tu et al., 2021) or paraphrased (Li et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_24",
            "start": 0,
            "end": 443,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_25@0",
            "content": "Regarding the output property P , the current literature only offers three choices.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_25",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_25@1",
            "content": "We list them here, alongside their first-order logic formulation:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_25",
            "start": 84,
            "end": 148,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_26@0",
            "content": "\u2022 Equivalence P . Robustness relations require that the output does not change in the face of small input perturbations. Thus, we need a notion of equivalence between the source output y and its follow-up y (see Figure 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_26",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_27@0",
            "content": "For classification models, we can express it via the softmax output y = (y 1 , . . . , y c ) as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_27",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_28@0",
            "content": "P eq : \u2203i \u2200j = i (y i > y j ) \u2227 (y i > y j ) (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_28",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_29@0",
            "content": "where i is the predicted class.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_29",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_29@1",
            "content": "In rarer cases, where the output is textual, verbatim comparison can be used (Sun and Zhou, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_29",
            "start": 32,
            "end": 129,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_30@0",
            "content": "\u2022 Similarity P . For other applications, the equivalence property cannot be applied. For example, when testing QA systems, we want to detect similar but not identical answers. In such cases, we can define a similarity score s(y, y ) \u2208 R, e.g. cosine similarity between the embeddings of the two answers (Tu et al., 2021). With it, we can write similarity as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_30",
            "start": 0,
            "end": 357,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_31@0",
            "content": "P sim : s(y, y ) > \u03b8 (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_31",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_32@0",
            "content": "where \u03b8 is an arbitrary threshold chosen according to the user's domain knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_32",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_33@0",
            "content": "\u2022 Order P . At the same time, we can establish an order relation between the two outputs y and y . This order relation is useful in conjunction with transformations that have a monotonic effect on the output. For example, concatenating positive sentences to the input of a sentiment analysis system (Ribeiro et al., 2020). In such cases, let us define an order score s(y) \u2208 R, and write the output property as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_33",
            "start": 0,
            "end": 409,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_34@0",
            "content": "P ord : s(y) < s(y )(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_34",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_35@0",
            "content": "In Sections 4, 5 and 6 we employ some of the transformations T and properties P defined here as building blocks for new metamorphic relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_35",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_36@0",
            "content": "Pairwise NLP metamorphic relations for testing systematicity",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_36",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_37@0",
            "content": "We introduce a new class of metamorphic relations to test the systematicity of NLP models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_37",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_37@1",
            "content": "Here, we take the general definition of systematicity in Fodor and Pylyshyn (1988), which states that the predictions of an NLP model across related inputs should be intrinsically connected and express it as a metamorphic relation (see Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_37",
            "start": 91,
            "end": 336,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_37@2",
            "content": "Since we do not want to rely on ground-truth data, we first establish a baseline for the model's behaviour by comparing its predictions across two different source inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_37",
            "start": 338,
            "end": 508,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_37@3",
            "content": "Then, we perturb both source inputs via the same transformation and test whether the model's behaviour changes accordingly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_37",
            "start": 510,
            "end": 632,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_38@0",
            "content": "x 1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_38",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_39@0",
            "content": "x 1 y 1 y 1 y 2 y 2 x 2 x 2 P f f f f T T Figure 2: Structure of pairwise-systematicity relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_39",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_40@0",
            "content": "The two source inputs allow us to establish a baseline for the behaviour of model f , and test whether it changes according to expectations once T is applied.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_40",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_41@0",
            "content": "More formally, we define pairwise-systematicity relations as follows. Let x 1 , x 2 \u2208 D be a pair of source inputs, and x 1 , x 2 their corresponding follow-up inputs via transformation T .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_41",
            "start": 0,
            "end": 188,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_41@1",
            "content": "Furthermore, denote with y 1 , y 2 , y 1 , y 2 the outputs produced by model f .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_41",
            "start": 190,
            "end": 269,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_41@2",
            "content": "Finally, define the output property P in the following form:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_41",
            "start": 271,
            "end": 330,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_42@0",
            "content": "P : P src (y 1 , y 2 ) =\u21d2 P f lw (y 1 , y 2 ) (4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_42",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_43@0",
            "content": "Note that this definition does not rely on groundtruth data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_43",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_43@1",
            "content": "In fact, we trust the model's predictions (y 1 , y 2 ) over the source inputs to establish our premise P src .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_43",
            "start": 61,
            "end": 170,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_43@2",
            "content": "The actual test checks whether transforming the source inputs with T produces outputs that satisfy the expected property P f wl .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_43",
            "start": 172,
            "end": 300,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_43@3",
            "content": "Any violation of this property, i.e. when P src \u2227 \u00acP f wl , reveals an inconsistency in the model's predictions that breaks the user's expectation of systematic behaviour.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_43",
            "start": 302,
            "end": 472,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_43@4",
            "content": "In Section 4.2, we give an intuitive geometrical explanation of the type of constraints imposed by pairwise-systematicity relations on the embedding space of a neural NLP model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_43",
            "start": 474,
            "end": 650,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_44@0",
            "content": "A hidden advantage of metamorphic relations with multiple source inputs (see also Sections 5 and 6) is that they naturally produce more test cases than single-input ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_44",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_44@1",
            "content": "In the case of pairwise systematicity, each input in the pair (x 1 , x 2 ) is extracted from the same dataset D. Thus, a dataset with |D| = k entries generates an O(k 2 ) number of test cases, as opposed to O(k) for single-input relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_44",
            "start": 171,
            "end": 409,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_44@2",
            "content": "We see an example of this in Section 4.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_44",
            "start": 411,
            "end": 451,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_45@0",
            "content": "Illustrative example: pairwise systematicity of sentiment analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_45",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_46@0",
            "content": "Now, let us apply the pairwise-systematicity relation structure shown in Figure 2 to a sentiment analysis task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_46",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_46@1",
            "content": "To do so, we choose the following:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_46",
            "start": 112,
            "end": 145,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_47@0",
            "content": "\u2022 Transformation T . For each source input x i , we create a follow-up input x i = T (x i ) by concatenating a short sentence to it. A list of all transformations we use is in Table 1. \u2022 Output premise P src . Let s pos (y 1 ) and s pos (y 2 ) be the (positive) sentiment scores predicted by model f . Define the baseline behaviour of f as the order property P src = P ord between these two scores (see Equation 3). \u2022 Output hypothesis P f lw . Let s pos (y 1 ) and s pos (y 2 ) be the sentiment scores of the followup inputs. We require that their order matches the one of the source inputs. More formally: P f lw = P ord and P src \u21d0\u21d2 P f lw .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_47",
            "start": 0,
            "end": 643,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@0",
            "content": "Our rationale is that the sentiment of any input shifts when we concatenate additional text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@1",
            "content": "If we have ground-truth information on the sentiment of the text we are adding, we can test whether our predictions shift in the expected direction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 93,
            "end": 240,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@2",
            "content": "For instance, concatenating \"I am very happy\" should make the score of any input more positive.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 242,
            "end": 336,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@3",
            "content": "This is an example of single-input relation (see Section 3 and Ribeiro et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 338,
            "end": 422,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@4",
            "content": "However, if we do not have such ground truth, we can still test our model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 424,
            "end": 497,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@5",
            "content": "We do so by considering a pair of inputs (x 1 , x 2 ), and concatenating the same text to both of them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 499,
            "end": 601,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@6",
            "content": "Then, whenever x 1 is predicted more positive than x 2 , we require that its transformed version x 1 is also more positive than x 2 and vice versa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 603,
            "end": 749,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_48@7",
            "content": "This is pairwise systematicity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_48",
            "start": 751,
            "end": 781,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_49@0",
            "content": "Experiment description and results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_49",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_49@1",
            "content": "We select a fine-tuned version of RoBERTa (Liu et al., 2019b) for sentiment analysis from the Hugging-Face library.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_49",
            "start": 36,
            "end": 150,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_49@2",
            "content": "1 . We choose 10,605 movie reviews from Socher et al. (2013) as our dataset D. From it, we generate all 112M+ possible source input pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_49",
            "start": 152,
            "end": 289,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_49@3",
            "content": "We repeat our experiment with different neutral transformations T , and report their aggregated results in Table 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_49",
            "start": 291,
            "end": 405,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_49@4",
            "content": "Note how the proportion of satisfied relations (\"Safety\") varies across different transformations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_49",
            "start": 407,
            "end": 504,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_49@5",
            "content": "Yet, the model's behaviour is fairly systematic, never exceeding 10% violations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_49",
            "start": 506,
            "end": 585,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_50@0",
            "content": "We get a different picture by counting the number of violations per each source input x i \u2208 D (see Table 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_50",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_50@1",
            "content": "There, we can see that some inputs are more likely to make the source order P src (y 1 , y 2 ) unstable across all the transformations T .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_50",
            "start": 109,
            "end": 246,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_50@2",
            "content": "Interestingly, a quick read through the reviews in Table 2 shows that they are all misclassified.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_50",
            "start": 248,
            "end": 344,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_50@3",
            "content": "Thus, we can conclude that pairwise-systematicity testing reveals a different issue in the model f than classic non-metamorphic testing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_50",
            "start": 346,
            "end": 481,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_50@4",
            "content": "For this reason, we encourage practitioners to perform both types of testing on their NLP models, as it will give a clearer",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_50",
            "start": 483,
            "end": 605,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_51@0",
            "content": "Table 2: Source inputs and their sentiment predictions, sorted by the number of times they appear in a safe pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_51",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_52@0",
            "content": "picture of their strengths and weaknesses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_52",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_53@0",
            "content": "Geometric interpretation of pairwise systematicity",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_53",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@0",
            "content": "Metamorphic relations impose constraints between the inputs and outputs while treating the model f as a black box (Chen et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@1",
            "content": "Still, in neural networks, it is possible to trace the effect of a relation R on the hidden layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 135,
            "end": 233,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@2",
            "content": "Here, we give a geometric explanation of the type of constraints pairwise-systematicity relations put on the last embedding space of a neural NLP model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 235,
            "end": 386,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@3",
            "content": "To this end, let us consider the relations in Section 4.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 388,
            "end": 445,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@4",
            "content": "Recall, that model f outputs a sentiment score s(y), which is a one-dimensional projection of the embedding space (see Figure 3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 447,
            "end": 575,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@5",
            "content": "Accordingly, the premise P src and hypothesis P f lw are only concerned with the position of each embedding y along direction s.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 577,
            "end": 704,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@6",
            "content": "However, since the source and follow-up inputs differ due to transformation T , the two output properties P src and P f lw act on different points in the embedding space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 706,
            "end": 875,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@7",
            "content": "Once we require that P src \u21d0\u21d2 P f lw , we set the expectation that f is exceptionally consistent at mapping pairs of inputs (x 1 , x 2 ) onto space Y in the same order.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 877,
            "end": 1044,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_54@8",
            "content": "Such expectation is met if and only if f is a systematic, though not necessarily correct, function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_54",
            "start": 1046,
            "end": 1144,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_55@0",
            "content": "Similar considerations apply if P src and P f lw are based on equality or similarity rather than order.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_55",
            "start": 0,
            "end": 102,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_55@1",
            "content": "Indeed, equality (see Equation 1) is defined over the softmax outputs, which are affine combinations of the embeddings (Bishop, 2006).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_55",
            "start": 104,
            "end": 237,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_55@2",
            "content": "In such case, the condition P src =\u21d2 P f lw translates to a requirement that if the source inputs are both mapped to the same half-space, the follow-up inputs should be too.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_55",
            "start": 239,
            "end": 411,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_55@3",
            "content": "Conversely, similarity (Equation 2) defines a measure on the embedding space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_55",
            "start": 413,
            "end": 489,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_55@4",
            "content": "Source inputs that are within a certain threshold \u03b8 should be matched by follow-up inputs that are also close.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_55",
            "start": 491,
            "end": 600,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_56@0",
            "content": "The following section introduces a class of pairwise relations where the output premise and hypothesis are defined over different embedding spaces.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_56",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_57@0",
            "content": "Pairwise NLP metamorphic relations for testing compositionality",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_57",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_58@0",
            "content": "Many probing works train simple supervised classifiers on top of the hidden representations of an NLP model (e.g. Hewitt and Manning, 2019).These classifiers, called probes, can reveal whether the neural model has learnt to recognise some fundamental constituents of the input language early on.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_58",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_59@0",
            "content": "The presence of such building blocks is a necessary condition for an NLP model to exhibit compositional behaviour (Baroni, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_59",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_59@1",
            "content": "Here, we propose to test the presence of compositional constituents in the hidden layers via metamorphic testing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_59",
            "start": 130,
            "end": 242,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_59@2",
            "content": "Consider the graph in Figure 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_59",
            "start": 244,
            "end": 274,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_59@3",
            "content": "There, the neural model is split into the mathematical composition of two functions f \u2022 g. More precisely, z = f (x) are the hidden representation of some hidden layer, and y = g(z) is the final output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_59",
            "start": 276,
            "end": 477,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_59@4",
            "content": "Now, let us define the output property P as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_59",
            "start": 479,
            "end": 530,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_60@0",
            "content": "P : P hid (z 1 , z 2 ) =\u21d2 P out (y 1 , y 2 ) (5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_60",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@0",
            "content": "A relation in this form allows us to express whether specific precursor signals in z are expected to have a direct effect on y. In a similar way to the relations in Section 4, both the premise P hid and hypothesis P out are established by comparing across pairs of inputs, rather than a ground-truth.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 0,
            "end": 299,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@1",
            "content": "In Section 5.1, we show how our technique can reveal the presence (or absence) of compositional building blocks in an NLP model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 301,
            "end": 428,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@2",
            "content": "To test whether the model's predictions exhibit a compositional behaviour, we construct our test inputs according to Rozanova et al. (2021) we first choose a prototypical sentence template C( ), which we call a context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 430,
            "end": 648,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@3",
            "content": "Each context includes a placeholder token that can be replaced with some insertion text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 650,
            "end": 737,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@4",
            "content": "Second, we construct each input x = (C( a ), C( b )) by copying the same context twice with different insertions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 739,
            "end": 851,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@5",
            "content": "Finally, we choose the contexts C i and insertion pairs ( a , b ) j in such a way that their composition (C( a ), C( b )) ij has a well-definite entailment relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 853,
            "end": 1017,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@6",
            "content": "Namely, the insertion pairs (see Table 4) are either hypernyms (\u2287), hyponyms (\u2286), or unrelated (none).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 1019,
            "end": 1120,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@7",
            "content": "Similarly, the contexts (see Table 3) are either upward monotone if they preserve the insertion relation, or downward monotone if they invert it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 1122,
            "end": 1266,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@8",
            "content": "As a result, only the compositions Up(\u2286) and Down(\u2287) are entailed, while the rest are not. Now, assume that both inputs x 1 and x 2 in Figure 4 are based on the same context C i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 1268,
            "end": 1446,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_61@9",
            "content": "We can test whether the NLI model build its output by reasoning over the monotonicity of C i and the lexical relation of the insertion pairs ( a , b ) j as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_61",
            "start": 1448,
            "end": 1611,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_62@0",
            "content": "\u2022 Hidden premise P hid . Let z be the embeddings of the second to last layer, for the tokens corresponding to the insertions a and b . Train a linear probe s hyp on z (Liu et al., 2019a) to predict whether a is a hypernym of b . Define P hid = P ord as the order property (see Equation 3) over the hypernymy scores s hyp (z 1 ) and s hyp (z 2 ) of the two inputs. If the NLI model f \u2022 g had a compositional behaviour, the order P hid of the hypernymy scores in the hidden layer should be reflected in the order P out of the entailment scores in the output. Here, we show that this is not the case for a popular stateof-the-art NLI model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_62",
            "start": 0,
            "end": 636,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@0",
            "content": "Experiment description and results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@1",
            "content": "We build a dataset D of 292 insertions pairs and repeat our experiment with 211 contexts, for a total of about 9M test cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 36,
            "end": 160,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@2",
            "content": "We chose a fine-tuned version of RoBERTa for NLI as our model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 162,
            "end": 223,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@3",
            "content": "2 The accuracy of the hypernymy probe is 0.9881.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 225,
            "end": 272,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@4",
            "content": "We report the aggregated result by context in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 274,
            "end": 327,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@5",
            "content": "Note how downward monotone contexts lead to less compositional behaviour: overall, we have 0.6880 successful test cases with upward contexts and only 0.4808 with downward ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 329,
            "end": 504,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@6",
            "content": "This phenomenon is known in the literature (Yanaka et al., 2019), but we show that metamorphic testing can independently detect it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 506,
            "end": 636,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@7",
            "content": "If we aggregate the results by insertion pair (see Table 4), the picture does not change.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 638,
            "end": 726,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@8",
            "content": "The overall safety is 0.5936, which is barely above random chance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 728,
            "end": 793,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_63@9",
            "content": "Any deviations from this baseline can be interpreted as noise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_63",
            "start": 795,
            "end": 856,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_64@0",
            "content": "6 Three-way NLP metamorphic relations for testing transitivity",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_64",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_65@0",
            "content": "An NLP model that generalises correctly should exhibit transitive behaviour under the right circumstances Yanaka et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_65",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_65@1",
            "content": "That is, if the model predicts a transitive linguistic property over the input pairs (x 1 , x 2 ) and (x 2 , x 3 ), then it should also predict it for the pair (x 1 , x 3 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_65",
            "start": 128,
            "end": 300,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_65@2",
            "content": "Here, we propose to test this behaviour in a metamorphic way.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_65",
            "start": 302,
            "end": 362,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_65@3",
            "content": "More specifically, let us introduce the three-way transitivity relation in Figure 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_65",
            "start": 364,
            "end": 447,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_65@4",
            "content": "There, the three source inputs x 1 , x 2 , x 3 are combined to form all possible input pairs x ij = (x i , x j ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_65",
            "start": 449,
            "end": 561,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_65@5",
            "content": "Then, we can test whether their corresponding outputs are transitive with the following output property:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_65",
            "start": 563,
            "end": 666,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_66@0",
            "content": "P : v(y 12 ) \u2227 v(y 23 ) \u21d2 v(y 13 )(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_66",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_67@0",
            "content": "where v(\u2022) : Y \u2192 {0, 1} is the Boolean prediction of model f .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_67",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_67@1",
            "content": "Note that the output property P , being defined over three outputs, has a different structure from those in Sections 3, 4 and 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_67",
            "start": 63,
            "end": 190,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_68@0",
            "content": "Illustrative example: three-way transitivity of lexical relations",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_68",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_69@0",
            "content": "In this section, we apply the metamorphic structure from Figure 5 to test the transitivity of lexical semantic relations, e.g. synonymy and hypernymy (Santus et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_69",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_69@1",
            "content": "In general, learning these linguistic properties is crucial for solving several NLI tasks (Glockner et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_69",
            "start": 173,
            "end": 286,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_69@2",
            "content": "Thus, we can expect an NLP model to generalise over them in a transitive way.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_69",
            "start": 288,
            "end": 364,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_69@3",
            "content": "We can test whether this is true in the following way:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_69",
            "start": 366,
            "end": 419,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_70@0",
            "content": "\u2022 Transformation T . The model f we test already accepts a pair of words x ij = (x i , x j ) as input. Thus, T is merely a formalism here. Note that transitivity can be tested in a supervised fashion by comparing the model's predictions to a ground truth (Yanaka et al., 2021). In contrast, the three-way transitivity relations we propose test the internal transitivity of a model trained to predict lexical relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_70",
            "start": 0,
            "end": 417,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_71@0",
            "content": "Experiment description and results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_71",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_71@1",
            "content": "We reproduce a state-of-the-art model for lexical relations (Wachowiak et al., 2020), which is a finetuned version of the multi-lingual transformer model xlmroberta (Conneau et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_71",
            "start": 36,
            "end": 223,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_71@2",
            "content": "We extract the multi-lingual test set from the Co-gALex_VI shared task (Santus et al., 2016), and generate a random sample of source triplets from its corpus of words, keeping those that satisfy v(y 12 ) \u2227 v(y 23 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_71",
            "start": 225,
            "end": 439,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_71@3",
            "content": "We present our empirical results in Table 5, organised by the language of the source words and lexical relation v predicted by the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_71",
            "start": 441,
            "end": 577,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_71@4",
            "content": "As the table shows, this state-of-the-art NLP model fails to predict v(y 13 ) in a transitive way across all languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_71",
            "start": 579,
            "end": 697,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_71@5",
            "content": "This is in contrast with the results of classic supervised testing in Wachowiak et al. (2020), which show that their model can predict the correct lexical relations (synonym, hypernym, antonym or random) with at least 0.5 of accuracy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_71",
            "start": 699,
            "end": 932,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_72@0",
            "content": "Conclusions and future work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_72",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_73@0",
            "content": "In this paper, we presented three new classes on metamorphic relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_73",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_73@1",
            "content": "Thanks to them, we could test the systematicity, compositionality and transitivity of state-of-the-art NLP models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_73",
            "start": 72,
            "end": 185,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_73@2",
            "content": "The advantage of our approach is that it does not rely on ground-truth annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_73",
            "start": 187,
            "end": 269,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_73@3",
            "content": "It can generate a polynomially larger number of test cases than supervised testing, revealing whether the NLP model under test is internally consistent.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_73",
            "start": 271,
            "end": 422,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_74@0",
            "content": "Still, testing is only one side of the coin.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_74",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_74@1",
            "content": "Like in recent work about robustness (Aspillaga et al., 2020), the tested models have not been trained on a metamorphic objective (e.g. as an additional loss term).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_74",
            "start": 45,
            "end": 208,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_74@2",
            "content": "We believe that doing so could improve the safety and consistency of a model's predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_74",
            "start": 210,
            "end": 300,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_75@0",
            "content": "Carlos Aspillaga, Andr\u00e9s Carvallo, Vladimir Araujo, Stress test evaluation of transformerbased models in natural language understanding tasks, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_75",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_76@0",
            "content": "Marco Baroni, Linguistic generalization and compositionality in modern artificial neural networks, 1791, Philosophical Transactions of the Royal Society B: Biological Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_76",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_77@0",
            "content": "T Earl, Mark Barr, Phil Harman, Muzammil Mcminn, Shin Shahbaz,  Yoo, The oracle problem in software testing: A survey, 2015, IEEE Transactions on Software Engineering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_77",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_78@0",
            "content": "Yonatan Belinkov, Yonatan Bisk, Synthetic and natural noise both break neural machine translation, 2018, International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_78",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_79@0",
            "content": "Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, James Glass, What do neural machine translation models learn about morphology?, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_79",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_80@0",
            "content": "UNKNOWN, None, 2006, Pattern Recognition and Machine Learning (Information Science and Statistics), Springer-Verlag.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_80",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_81@0",
            "content": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_81",
            "start": 0,
            "end": 501,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_82@0",
            "content": "Alvin Chan, Lei Ma, Felix Juefei-Xu, Yew-Soon Ong, Xiaofei Xie, Minhui Xue, Yang Liu, Breaking neural reasoning architectures with metamorphic relation-based adversarial examples, 2021, IEEE Transactions on Neural Networks and Learning Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_82",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_83@0",
            "content": "Fei-Ching Tsong Yueh Chen, Huai Kuo, Pak-Lok Liu, Dave Poon, T Towey, Zhi Quan Tse,  Zhou, Metamorphic testing: A review of challenges and opportunities, 2018, ACM Comput. Surv, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_83",
            "start": 0,
            "end": 178,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_84@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_84",
            "start": 0,
            "end": 322,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_85@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_85",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_86@0",
            "content": "Allyson Ettinger, Ahmed Elgohary, Philip Resnik, Probing for semantic evidence of composition by means of simple classification tasks, 2016, Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_86",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_87@0",
            "content": "Jerry Fodor, Zenon Pylyshyn, Connectionism and cognitive architecture: A critical analysis, 1988, Cognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_87",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_88@0",
            "content": "Ji Gao, Jack Lanchantin, Mary Soffa, Yanjun Qi, Black-box generation of adversarial text sequences to evade deep learning classifiers, 2018, 2018 IEEE Security and Privacy Workshops (SPW), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_88",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_89@0",
            "content": "Max Glockner, Vered Shwartz, Yoav Goldberg, Breaking NLI systems with sentences that require simple lexical inferences, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_89",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_90@0",
            "content": "Emily Goodwin, Koustuv Sinha, Timothy O'donnell, Probing linguistic systematicity, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_90",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_91@0",
            "content": "Georg Heigold, Stalin Varanasi, G\u00fcnter Neumann, Josef Van Genabith, How robust are characterbased word embeddings in tagging and MT against wrod scramlbing or randdm nouse?, 2018, Proceedings of the 13th Conference of the Association for Machine Translation in the Americas, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_91",
            "start": 0,
            "end": 275,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_92@0",
            "content": "John Hewitt, Christopher Manning, A structural probe for finding syntax in word representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_92",
            "start": 0,
            "end": 268,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_93@0",
            "content": "Dieuwke Hupkes, Verna Dankers, Mathijs Mul, Elia Bruni, Compositionality decomposed: how do neural networks generalise, 2020, Journal of Artificial Intelligence Research, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_93",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_94@0",
            "content": "Robin Jia, Aditi Raghunathan, Kerem G\u00f6ksel, Percy Liang, Certified robustness to adversarial word substitutions, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_94",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_95@0",
            "content": "Min Emanuele La Malfa, Luca Wu, Benjie Laurenti, Anthony Wang, Marta Hartshorn,  Kwiatkowska, Assessing robustness of text classification through maximal safe radius computation, 2020, Findings of the Association for Computational Linguistics: EMNLP 2020, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_95",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_96@0",
            "content": "Yitong Li, Trevor Cohn, Timothy Baldwin, Robust training under linguistic adversity, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_96",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_97@0",
            "content": "Nelson Liu, Matt Gardner, Yonatan Belinkov, Matthew Peters, Noah Smith, Linguistic knowledge and transferability of contextual representations, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_97",
            "start": 0,
            "end": 335,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_98@0",
            "content": "UNKNOWN, None, 1907, RoBERTa: A robustly optimized bert pretraining approach. ArXiv, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_98",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_99@0",
            "content": "Pingchuan Ma, Shuai Wang, Jin Liu, Metamorphic testing and certified mitigation of fairness violations in NLP models, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_99",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_100@0",
            "content": "Tongshuang Marco Tulio Ribeiro, Carlos Wu, Sameer Guestrin,  Singh, Beyond accuracy: Behavioral testing of NLP models with CheckList, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_100",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_101@0",
            "content": "UNKNOWN, None, 2021, Supporting context monotonicity abstractions in neural NLI models, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_101",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_102@0",
            "content": "Enrico Santus, Anna Gladkova, Stefan Evert, Alessandro Lenci, The CogALex-V shared task on the corpus-based identification of semantic relations, 2016, Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex -V), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_102",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_103@0",
            "content": "Richard Socher, John Bauer, Christopher Manning, Andrew Ng, Parsing with compositional vector grammars, 2013, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_103",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_104@0",
            "content": "Liqun Sun,  Zhi Quan,  Zhou, Metamorphic testing for machine translations: Mt4mt, 2018, 25th Australasian Software Engineering Conference (ASWEC), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_104",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_105@0",
            "content": "Damien Teney, Ehsan Abbasnejad, Kushal Kafle, Robik Shrestha, Christopher Kanan, Anton Van Den,  Hengel, On the value of out-of-distribution testing: An example of goodhart's law, 2020, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_105",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_106@0",
            "content": "Kaiyi Tu, Mingyue Jiang, Zuohua Ding, A metamorphic testing approach for assessing question answering systems, 2021, Mathematics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_106",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_107@0",
            "content": "Lennart Wachowiak, Christian Lang, Barbara Heinisch, Dagmar Gromann, CogALex-VI shared task: Transrelation -a robust multilingual language model for multilingual relation identification, 2020, Proceedings of the Workshop on the Cognitive Aspects of the Lexicon, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_107",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_108@0",
            "content": "Hitomi Yanaka, Koji Mineshima, Daisuke Bekki, Kentaro Inui, Satoshi Sekine, Lasha Abzianidze, Johan Bos, HELP: A dataset for identifying shortcomings of neural models in monotonicity reasoning, 2019, Proceedings of the Eighth Joint Conference on Lexical and Computational Semantics (*SEM 2019), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_108",
            "start": 0,
            "end": 336,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_109@0",
            "content": "Hitomi Yanaka, Koji Mineshima, Kentaro Inui, Exploring transitivity in neural NLI models through veridicality, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_109",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_110@0",
            "content": "UNKNOWN, None, 2019, Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_110",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "409-ARR_v1_111@0",
            "content": "UNKNOWN, None, , Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "409-ARR_v1_111",
            "start": 0,
            "end": 235,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_1",
            "tgt_ix": "409-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_1",
            "tgt_ix": "409-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_4",
            "tgt_ix": "409-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_5",
            "tgt_ix": "409-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_6",
            "tgt_ix": "409-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_7",
            "tgt_ix": "409-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_8",
            "tgt_ix": "409-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_9",
            "tgt_ix": "409-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_11",
            "tgt_ix": "409-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_13",
            "tgt_ix": "409-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_14",
            "tgt_ix": "409-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_15",
            "tgt_ix": "409-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_16",
            "tgt_ix": "409-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_17",
            "tgt_ix": "409-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_18",
            "tgt_ix": "409-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_19",
            "tgt_ix": "409-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_21",
            "tgt_ix": "409-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_23",
            "tgt_ix": "409-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_25",
            "tgt_ix": "409-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_27",
            "tgt_ix": "409-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_28",
            "tgt_ix": "409-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_29",
            "tgt_ix": "409-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_31",
            "tgt_ix": "409-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_32",
            "tgt_ix": "409-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_34",
            "tgt_ix": "409-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_35",
            "tgt_ix": "409-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_37",
            "tgt_ix": "409-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_38",
            "tgt_ix": "409-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_39",
            "tgt_ix": "409-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_40",
            "tgt_ix": "409-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_41",
            "tgt_ix": "409-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_42",
            "tgt_ix": "409-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_43",
            "tgt_ix": "409-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_44",
            "tgt_ix": "409-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_46",
            "tgt_ix": "409-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_49",
            "tgt_ix": "409-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_51",
            "tgt_ix": "409-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_50",
            "tgt_ix": "409-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_52",
            "tgt_ix": "409-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_55",
            "tgt_ix": "409-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_53",
            "tgt_ix": "409-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_53",
            "tgt_ix": "409-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_53",
            "tgt_ix": "409-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_53",
            "tgt_ix": "409-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_56",
            "tgt_ix": "409-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_58",
            "tgt_ix": "409-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_59",
            "tgt_ix": "409-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_60",
            "tgt_ix": "409-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_64",
            "tgt_ix": "409-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_65",
            "tgt_ix": "409-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_66",
            "tgt_ix": "409-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_67",
            "tgt_ix": "409-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_69",
            "tgt_ix": "409-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_68",
            "tgt_ix": "409-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_68",
            "tgt_ix": "409-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_68",
            "tgt_ix": "409-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_68",
            "tgt_ix": "409-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_71",
            "tgt_ix": "409-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_73",
            "tgt_ix": "409-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_72",
            "tgt_ix": "409-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_72",
            "tgt_ix": "409-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_72",
            "tgt_ix": "409-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "409-ARR_v1_0",
            "tgt_ix": "409-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_1",
            "tgt_ix": "409-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_2",
            "tgt_ix": "409-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_3",
            "tgt_ix": "409-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_4",
            "tgt_ix": "409-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_4",
            "tgt_ix": "409-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_4",
            "tgt_ix": "409-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_5",
            "tgt_ix": "409-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_5",
            "tgt_ix": "409-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_5",
            "tgt_ix": "409-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_6",
            "tgt_ix": "409-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_6",
            "tgt_ix": "409-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_6",
            "tgt_ix": "409-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_6",
            "tgt_ix": "409-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_7",
            "tgt_ix": "409-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_7",
            "tgt_ix": "409-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_7",
            "tgt_ix": "409-ARR_v1_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_7",
            "tgt_ix": "409-ARR_v1_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_7",
            "tgt_ix": "409-ARR_v1_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_8",
            "tgt_ix": "409-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_8",
            "tgt_ix": "409-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_8",
            "tgt_ix": "409-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_8",
            "tgt_ix": "409-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_8",
            "tgt_ix": "409-ARR_v1_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_8",
            "tgt_ix": "409-ARR_v1_8@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_9",
            "tgt_ix": "409-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_9",
            "tgt_ix": "409-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_9",
            "tgt_ix": "409-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_9",
            "tgt_ix": "409-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_9",
            "tgt_ix": "409-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_9",
            "tgt_ix": "409-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_10",
            "tgt_ix": "409-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_11",
            "tgt_ix": "409-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_11",
            "tgt_ix": "409-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_12",
            "tgt_ix": "409-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_13",
            "tgt_ix": "409-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_14",
            "tgt_ix": "409-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_15",
            "tgt_ix": "409-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_15",
            "tgt_ix": "409-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_15",
            "tgt_ix": "409-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_15",
            "tgt_ix": "409-ARR_v1_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_16",
            "tgt_ix": "409-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_16",
            "tgt_ix": "409-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_16",
            "tgt_ix": "409-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_17",
            "tgt_ix": "409-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_18",
            "tgt_ix": "409-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_18",
            "tgt_ix": "409-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_18",
            "tgt_ix": "409-ARR_v1_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_19",
            "tgt_ix": "409-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_19",
            "tgt_ix": "409-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_19",
            "tgt_ix": "409-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_19",
            "tgt_ix": "409-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_19",
            "tgt_ix": "409-ARR_v1_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_19",
            "tgt_ix": "409-ARR_v1_19@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_20",
            "tgt_ix": "409-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_21",
            "tgt_ix": "409-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_21",
            "tgt_ix": "409-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_21",
            "tgt_ix": "409-ARR_v1_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_21",
            "tgt_ix": "409-ARR_v1_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_21",
            "tgt_ix": "409-ARR_v1_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_21",
            "tgt_ix": "409-ARR_v1_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_22",
            "tgt_ix": "409-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_23",
            "tgt_ix": "409-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_24",
            "tgt_ix": "409-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_25",
            "tgt_ix": "409-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_25",
            "tgt_ix": "409-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_26",
            "tgt_ix": "409-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_27",
            "tgt_ix": "409-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_28",
            "tgt_ix": "409-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_29",
            "tgt_ix": "409-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_29",
            "tgt_ix": "409-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_30",
            "tgt_ix": "409-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_31",
            "tgt_ix": "409-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_32",
            "tgt_ix": "409-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_33",
            "tgt_ix": "409-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_34",
            "tgt_ix": "409-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_35",
            "tgt_ix": "409-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_36",
            "tgt_ix": "409-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_37",
            "tgt_ix": "409-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_37",
            "tgt_ix": "409-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_37",
            "tgt_ix": "409-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_37",
            "tgt_ix": "409-ARR_v1_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_38",
            "tgt_ix": "409-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_39",
            "tgt_ix": "409-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_40",
            "tgt_ix": "409-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_41",
            "tgt_ix": "409-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_41",
            "tgt_ix": "409-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_41",
            "tgt_ix": "409-ARR_v1_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_42",
            "tgt_ix": "409-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_43",
            "tgt_ix": "409-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_43",
            "tgt_ix": "409-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_43",
            "tgt_ix": "409-ARR_v1_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_43",
            "tgt_ix": "409-ARR_v1_43@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_43",
            "tgt_ix": "409-ARR_v1_43@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_44",
            "tgt_ix": "409-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_44",
            "tgt_ix": "409-ARR_v1_44@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_44",
            "tgt_ix": "409-ARR_v1_44@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_45",
            "tgt_ix": "409-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_46",
            "tgt_ix": "409-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_46",
            "tgt_ix": "409-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_47",
            "tgt_ix": "409-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_48",
            "tgt_ix": "409-ARR_v1_48@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_49",
            "tgt_ix": "409-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_49",
            "tgt_ix": "409-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_49",
            "tgt_ix": "409-ARR_v1_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_49",
            "tgt_ix": "409-ARR_v1_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_49",
            "tgt_ix": "409-ARR_v1_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_49",
            "tgt_ix": "409-ARR_v1_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_50",
            "tgt_ix": "409-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_50",
            "tgt_ix": "409-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_50",
            "tgt_ix": "409-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_50",
            "tgt_ix": "409-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_50",
            "tgt_ix": "409-ARR_v1_50@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_51",
            "tgt_ix": "409-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_52",
            "tgt_ix": "409-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_53",
            "tgt_ix": "409-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_54",
            "tgt_ix": "409-ARR_v1_54@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_55",
            "tgt_ix": "409-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_55",
            "tgt_ix": "409-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_55",
            "tgt_ix": "409-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_55",
            "tgt_ix": "409-ARR_v1_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_55",
            "tgt_ix": "409-ARR_v1_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_56",
            "tgt_ix": "409-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_57",
            "tgt_ix": "409-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_58",
            "tgt_ix": "409-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_59",
            "tgt_ix": "409-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_59",
            "tgt_ix": "409-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_59",
            "tgt_ix": "409-ARR_v1_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_59",
            "tgt_ix": "409-ARR_v1_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_59",
            "tgt_ix": "409-ARR_v1_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_60",
            "tgt_ix": "409-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_61",
            "tgt_ix": "409-ARR_v1_61@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_62",
            "tgt_ix": "409-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_63",
            "tgt_ix": "409-ARR_v1_63@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_64",
            "tgt_ix": "409-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_65",
            "tgt_ix": "409-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_65",
            "tgt_ix": "409-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_65",
            "tgt_ix": "409-ARR_v1_65@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_65",
            "tgt_ix": "409-ARR_v1_65@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_65",
            "tgt_ix": "409-ARR_v1_65@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_65",
            "tgt_ix": "409-ARR_v1_65@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_66",
            "tgt_ix": "409-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_67",
            "tgt_ix": "409-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_67",
            "tgt_ix": "409-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_68",
            "tgt_ix": "409-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_69",
            "tgt_ix": "409-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_69",
            "tgt_ix": "409-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_69",
            "tgt_ix": "409-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_69",
            "tgt_ix": "409-ARR_v1_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_70",
            "tgt_ix": "409-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_71",
            "tgt_ix": "409-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_71",
            "tgt_ix": "409-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_71",
            "tgt_ix": "409-ARR_v1_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_71",
            "tgt_ix": "409-ARR_v1_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_71",
            "tgt_ix": "409-ARR_v1_71@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_71",
            "tgt_ix": "409-ARR_v1_71@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_72",
            "tgt_ix": "409-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_73",
            "tgt_ix": "409-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_73",
            "tgt_ix": "409-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_73",
            "tgt_ix": "409-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_73",
            "tgt_ix": "409-ARR_v1_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_74",
            "tgt_ix": "409-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_74",
            "tgt_ix": "409-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_74",
            "tgt_ix": "409-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_75",
            "tgt_ix": "409-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_76",
            "tgt_ix": "409-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_77",
            "tgt_ix": "409-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_78",
            "tgt_ix": "409-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_79",
            "tgt_ix": "409-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_80",
            "tgt_ix": "409-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_81",
            "tgt_ix": "409-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_82",
            "tgt_ix": "409-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_83",
            "tgt_ix": "409-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_84",
            "tgt_ix": "409-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_85",
            "tgt_ix": "409-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_86",
            "tgt_ix": "409-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_87",
            "tgt_ix": "409-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_88",
            "tgt_ix": "409-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_89",
            "tgt_ix": "409-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_90",
            "tgt_ix": "409-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_91",
            "tgt_ix": "409-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_92",
            "tgt_ix": "409-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_93",
            "tgt_ix": "409-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_94",
            "tgt_ix": "409-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_95",
            "tgt_ix": "409-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_96",
            "tgt_ix": "409-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_97",
            "tgt_ix": "409-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_98",
            "tgt_ix": "409-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_99",
            "tgt_ix": "409-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_100",
            "tgt_ix": "409-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_101",
            "tgt_ix": "409-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_102",
            "tgt_ix": "409-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_103",
            "tgt_ix": "409-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_104",
            "tgt_ix": "409-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_105",
            "tgt_ix": "409-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_106",
            "tgt_ix": "409-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_107",
            "tgt_ix": "409-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_108",
            "tgt_ix": "409-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_109",
            "tgt_ix": "409-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_110",
            "tgt_ix": "409-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "409-ARR_v1_111",
            "tgt_ix": "409-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1248,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "409-ARR",
        "version": 1
    }
}