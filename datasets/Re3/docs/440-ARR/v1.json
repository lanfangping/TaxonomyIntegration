{
    "nodes": [
        {
            "ix": "440-ARR_v1_0",
            "content": "KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_2",
            "content": "Political perspective detection has become an increasingly important task that can help combat echo chambers and political polarization. Previous approaches generally focus on leveraging textual content to identify stances, while they fail to reason with background knowledge or leverage the rich semantic and syntactic textual labels in news articles. In light of these limitations, we propose KCD, a political perspective detection approach to enable multihop knowledge reasoning and incorporate textual cues as paragraph-level labels. Specifically, we firstly generate random walks on external knowledge graphs and infuse them with news text representations. We then construct a heterogeneous information network to jointly model news content as well as semantic, syntactic and entity cues in news articles. Finally, we adopt relational graph neural networks for graph-level representation learning and conduct political perspective detection. Extensive experiments demonstrate that our approach outperforms state-of-the-art methods on two benchmark datasets. We further examine the effect of knowledge walks and textual cues and how they contribute to our approach's data efficiency.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "440-ARR_v1_4",
            "content": "Political perspective detection aims to identify ideological stances of textual data such as social media posts and news articles. Previous approaches generally leverage the textual content of news articles with various text modeling techniques to identify stances. Those works (Jiang et al., 2019; labels. Later approaches incorporate information sources beyond text to facilitate argument mining and boost task performance. News discussion on social networks (Li and Goldwasser, 2019), social and linguistic information about news articles (Li and Goldwasser, 2021), media sources and information (Baly et al., 2020) as well as external knowledge from knowledge graphs (Feng et al., 2021a) are introduced in the task of political perspective detection and achieve better performance.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_5",
            "content": "Although these methods attempted to leverage more than news content, they fail to present a framework capable of reasoning with background knowledge and leveraging implicit semantic and syntactic indicators such as sentiment and tense of news articles. For example, Figure 1 presents a typical news article from Daily Kos 1 . This article discusses remarks from the Trump campaign team about Wikileaks and its effect on Hillary Clinton's bid for president. Individuals often rely on the multi-hop reasoning that Clinton and Trump are from opposite political parties and run against each other to inform their perspective analysis process. Besides, the negative sentiment expressed in satiric tones and the quotation of Trump campaign staff also give away the author's denial and left-leaning perspective. That being said, knowledge reasoning and implicit textual indicators are essential in the news bias detection process.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_6",
            "content": "In light of these limitations, we propose a political perspective detection framework KCD (Knowledge Walks and Textual Cues Enhanced Political Perspective Detection). Specifically, KCD generates multi-hop knowledge walks, aggregates them based on semantic relevance and incorporates them in textual representations with multi-head attention. KCD then constructs a heterogeneous information network to jointly model knowledgeenriched news content and diversified textual cues as paragraph-level labels. Finally, KCD learns graph representations with relational graph neural networks and conduct perspective detection with different aggregation strategies. Our main contributions are summarized as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_7",
            "content": "\u2022 We propose knowledge walks, a strategy to incorporate multi-hop knowledge reasoning in textual representations for knowledge-aware political perspective detection. \u2022 We propose to construct a heterogeneous information network to represent news articles, which jointly models knowledge-enriched news content and implicit textual cues in news articles. \u2022 Extensive experiments demonstrate that our approach consistently outperforms state-of-the-art methods on two widely adopted benchmarks. Further analysis bears out the necessity of knowledge walks and textual cues in our approach.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_8",
            "content": "2 Related Work",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_9",
            "content": "Political Perspective Detection",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "440-ARR_v1_10",
            "content": "Political perspective detection aims to identify the ideological stances of news articles, which is widely studied to help strengthen the online information landscape (Li and Goldwasser, 2019) and mitigate ideological echo chambers (Li and Goldwasser, 2021;Feng et al., 2021a). Early approaches leverage text analysis techniques for bias detection, such as sentiment analysis (Jiang et al., 2011;Wang et al., 2017), bias feature extraction (Horne et al., 2018), word embeddings (Jiang et al., 2019;Li and Goldwasser, 2019) and different neural network architectures (Augenstein et al., 2016;Du et al., 2017;Xu et al., 2018;Yang et al., 2016;Jiang et al., 2019;Feng et al., 2021b;Li and Goldwasser, 2021;Feng et al., 2021a). In addition to textual content of news articles, social media users also become the focus of perspective detection research (Bel-Enguix et al., 2021). User interactions (Magdy et al., 2016), user clustering , and label propagation are leveraged to identify the ideological preferences on social media. Fusing both news text and social network analysis directions, Li and Goldwasser (2019) propose to enrich news text with the content and structure of social media discussions about these news articles. Recent state-of-the-art approaches chart a new path by incorporating social and political external knowledge into stance detection. Baly et al. (2020) propose adversarial media adaptation and leverage source background knowledge for political perspective detection. Li and Goldwasser (2021) combine language encoders with pre-training tasks of social and linguistic information. Feng et al. (2021a) propose to construct and leverage political knowledge graphs as domain-specific external knowledge. In this paper, we build on these works to examine and explore the effect of multi-hop knowledge reasoning and diversified textual cues in the task of political perspective detection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_11",
            "content": "Knowledge Graph in NLP",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "440-ARR_v1_12",
            "content": "Knowledge graphs (KGs) are effective representations of real-world entities, relations, and knowledge. Generic (Fellbaum, 2010;Tanon et al., 2020;Bollacker et al., 2008;Speer et al., 2017) and domain-specific KGs (Feng et al., 2021a;Chang et al., 2020) are widely adopted in NLP tasks as external knowledge sources. These approaches could mainly be categorized into feature extraction, language model and graph-based methods. For feature extraction approaches, KG embedding technique TransE (Bordes et al., 2013) is leveraged to learn features for knowledge injecton (Ostendorff et al., 2019;Hu et al., 2021). For language model approaches, the adapter architecture is leveraged to fine-tune on KG-related tasks (Majewska et al., 2020;Meng et al., 2021;Wei et al., 2021). In ad-",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_13",
            "content": "The September 4 date on the email puts it over a month before Trump shouted \"I love Wikileaks\" in the midst of one of his rallies while reading clips from stolen emails in an effort to demean Hillary Clinton.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_14",
            "content": "The September 4 date on the email puts it over a month before Trump shouted \"I love Wikileaks\" in the midst of one of his rallies while reading clips from stolen emails in an effort to demean Hillary Clinton.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_15",
            "content": "Graph Construction \uf052 1 \uf052 2 \uf052 3 \uf052 4 \uf052 5 \uf052 6 \uf052 1 \uf052 2 \uf052 3 \uf052 4 \uf052 5 \uf052 6 \uf056 1 \uf056 2 \uf056 3 \uf056 4 \uf056 5 \uf056 6 \uf056 1 \uf056 2 \uf056 3 \uf056 4 \uf056 5 \uf056 6",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_16",
            "content": "Knowledge Walk Generation dition, propose a unified model to combine knowledge embedding with language representation pre-training. For graph-based approaches, KG entities and relations are injected into graphs and heterogeneous information networks (Hu et al., 2021;Feng et al., 2021a;Lu et al., 2021). Graph neural networks are then adopted to learn knowledge-aware text representations. In this paper, we propose knowledge walk, a novel strategy to infuse multi-hop knowledge reasoning into language representations and apply them in political perspective detection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_17",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "440-ARR_v1_18",
            "content": "Figure 2 presents an overview of our proposed political perspective detection framework KCD (Knowledge Walks and Textual Cues Enhanced Political Perspective Detection). We firstly generate knowledge walks on the external knowledge graph. These knowledge walks are then selected based on semantic relevance and injected into textual representations with multi-head attention. We then construct a heterogeneous information network to jointly model knowledge-enriched news content and diversified textual cues as paragraph-level labels and supernodes. Finally, we adopt relational graph neural networks and different aggregation strategies to learn graph-level representation and conduct political perspective detection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_19",
            "content": "Knowledge Walks and Infusion",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "440-ARR_v1_20",
            "content": "We firstly propose the novel strategy of knowledge walks and combine them with textual representations to enable multi-hop knowledge reasoning. We partition an n-paragraph news document into different paragraphs and denote them as S = {s 1 , ..., s n }. We encode each paragraph with pre-trained RoBERTa (Liu et al., 2019):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_21",
            "content": "v s i = RoBERT a(s i ), 1 \u2264 i \u2264 n (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_22",
            "content": "We use a political knowledge graph 2 as external knowledge for perspective detection. Let the ith triple in the knowledge graph be (e ih , r i , e it ), where e ih and e it denote the head and tail entity and r i represents the relation of the i-th triple.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_23",
            "content": "Knowledge Walk Generation",
            "ntype": "title",
            "meta": {
                "section": "3.1.1"
            }
        },
        {
            "ix": "440-ARR_v1_24",
            "content": "We firstly use TagMe (Ferragina and Scaiella, 2011) to identify mentioned KG entities in each paragraph s i . For each mentioned entity, we use it as the starting point e (0) in a K-hop knowledge walk:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_25",
            "content": "kw i = {e (0) , r 0,1 , e (1) , ..., r K\u22121,K , e (K) } (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_26",
            "content": "where e (i\u22121) and r i\u22121,i denote the i-th triple's head entity and relation. Specifically, a knowledge walk is generated by adopting biased random walk of length K starting from e (0) . The conditional probability of arriving at e (i) from e (i\u22121) through r i\u22121,i is formulated as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_27",
            "content": "P (e (i) |e (i\u22121) , r i\u22121,i ) = exp(p(r i\u22121,i )) |Nr(i\u22121)| j=1",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_28",
            "content": "exp(p(r j ))",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_29",
            "content": "(3) where N r (i \u2212 1) denotes the neighboring relations of e (i\u22121) , p(r) is the importance score of KG relation r, which could be tuned by domain experts for human-in-the-loop knowledge walk generation. In this way, we generate multiple knowledge walks for each paragraph based on its mentioned entities, which models the multi-hop reasoning process with external knowledge.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_30",
            "content": "Semantic-Guided Selection",
            "ntype": "title",
            "meta": {
                "section": "3.1.2"
            }
        },
        {
            "ix": "440-ARR_v1_31",
            "content": "After obtaining multiple knowledge walks for a single news paragraph, we propose a selection and aggregation process guided by text semantics to differentiate essential knowledge walks from the irrelevant ones. We firstly transform each knowledge walk kw i into a sentence t i by concatenating the textual description of entities and relations. We then encode the knowledge walk sentence t i with pre-trained RoBERTa (Liu et al., 2019):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_32",
            "content": "v k i = RoBERT a(t i )(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_33",
            "content": "Suppose a total of m knowledge walks {kw i,j } m j=1 are generated for paragraph s i , we then aggregate their knowledge walk sentence embeddings {v k i,j } m j=1 as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_34",
            "content": "v p i = m j=1 exp(\u03b1 \u2022 v k i,j ) m q=1 exp(\u03b1 \u2022 v k i,q ) v k i,j(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_35",
            "content": "where \u03b1 denotes the learnable attention vector guided by paragraph semantics:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_36",
            "content": "\u03b1 = \u03d5(W a v s i + b a )(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_37",
            "content": "where W a and b a are learnable parameters of the attention module and we use Leaky-ReLU for \u03d5. In this way, we aggregate m knowledge walks based on semantic relevance to the paragraph to filter and retain important knowledge reasoning paths.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_38",
            "content": "Knowledge Infusion",
            "ntype": "title",
            "meta": {
                "section": "3.1.3"
            }
        },
        {
            "ix": "440-ARR_v1_39",
            "content": "After representing multi-hop knowledge reasoning for paragraph s i with v p i , we conduct documentwise multi-head self-attention to infuse knowledge walks into textaul representations v s i . We concatenate knowledge walk and text representations:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_40",
            "content": "T = concat([v s 1 , v p 1 , ..., v s n , v p n ]) (7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_41",
            "content": "where T is the input for multi-head self-attention:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_42",
            "content": "T = M ultiHead(Q, K, V )(8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_43",
            "content": "where",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_44",
            "content": "Q = K = V = T and the output T = concat([ \u1e7ds 1 , \u1e7dp 1 , ..., \u1e7ds n , \u1e7dp n ]).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_45",
            "content": "In this way, we obtain language representations of news paragraphs { \u1e7ds i } n i=1 , which jointly models textual content and related multi-hop knowledge reasoning paths.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_46",
            "content": "Textual Cues and Graph Construction",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "440-ARR_v1_47",
            "content": "We construct a heterogeneous information network (HIN) as in Figure 2 \"Graph Construction\" to jointly represent knowledge-enriched news content and diversified textual cues in news articles. Specifically, we use paragraph nodes to represent the news content and connect them with different paragraph-level labels with heterogeneous edges. Firstly, for paragraph nodes: V1 and R1: Paragraph Nodes We use one node in V1 to represent each paragraph in the news article to partition the entire document and allow fine-grained analysis. We adopt the knowledgeenriched representations { \u1e7ds i } n i=1 in Section 3.1 as initial node features for V1. We then use relation R1 to connect adjacent paragraphs to preserve the original flow of the news article.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_48",
            "content": "Semantic Cues",
            "ntype": "title",
            "meta": {
                "section": "3.2.1"
            }
        },
        {
            "ix": "440-ARR_v1_49",
            "content": "We further analyze the topic and sentiment of news paragraphs, extract paragraph-level labels and inject them into our news HIN structure. V2 and R2: Topic Cues The topics and frequent topic switching in news articles often give away the stance and argument of authors. We train LDA to extract the topics in each political perspective detection corpus and use one node to represent each topic. We then encode the topic text with pretrained RoBERTa as node attributes. We then use R2 to connect each paragraph node in V1 with its affiliated topic node in V2 with the help of Bert-Topic (Grootendorst, 2020). V3 and R3: Sentiment Cues The sentiment of news articles signal the authors' approval or denial, which helps identify their stances towards individuals and issues. We use two nodes to represent positive and negative sentiment and we make their node attributes learnable. We then conduct sentiment analysis (Wolf et al., 2020) to identify paragraph sentiment and use R3 to connect V1 with their corresponding sentiment nodes in V3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_50",
            "content": "Syntactic Cues",
            "ntype": "title",
            "meta": {
                "section": "3.2.2"
            }
        },
        {
            "ix": "440-ARR_v1_51",
            "content": "Apart from semantic cues, syntactic information in news articles also contribute to the perspective analysis process (Dutta et al., 2022). In light of this, we analyze the tense of news paragraphs and whether it contains direct quotation and use them as paragraph-level labels in our constructed HIN. V4 and R4: Tense Cues The tense of news paragraphs helps separate facts from opinions. For example, simple past tense often indicates factual statements while simple future tense suggests opinions and projections that might not be factual. We use 17 nodes in V4 to represent 17 possible tenses in our constructed news HIN. We use NLTK (Bird et al., 2009) to extract paragraph tenses and use R4 to connect paragraph nodes in V1 with V4. V5 and R5: Quotation Cues It is common for authors to directly quote others' words in news articles, which helps to identify the basis of the author's argument. We use two nodes to differentiate between whether a news paragraph quotes someone or not. Specifically, we identify quotation marks in news paragraphs and use R6 to connect V1 with V6 based on whether direct quotation is detected.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_52",
            "content": "Entity Cues",
            "ntype": "title",
            "meta": {
                "section": "3.2.3"
            }
        },
        {
            "ix": "440-ARR_v1_53",
            "content": "V6 and R6: Entity Cues We follow previous works (Feng et al., 2021a;Hu et al., 2021) to use one node to represent each entity in the external knowledge graph. We adopt TransE (Bordes et al., 2013) to learn knowledge graph embeddings and use them as initial node features for V6. We then adopt Tagme (Ferragina and Scaiella, 2011) to align news paragraphs with their mentioned entities and use R6 to connect V1 with V6 correspondingly.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_54",
            "content": "In this way, we obtain a heterogeneous information network for news articles that jointly models knowledge-enriched news content and diversified textual cues in news articles. Our approach could be similarly extended to other textual cues and paragraph-level labels that would be helpful in political perspective detection and related tasks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_55",
            "content": "Learning and Optimization",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "440-ARR_v1_56",
            "content": "Upon obtaining the news HINs, we adopt relational graph neural networks for representation learning and conduct political perspective detection as graph-level classification. Specifically, we follow Feng et al. (2021a) and use gated R-GCN to ensure a fair comparison and highlight the effectiveness of knowledge walks and textual cues. After L layers of gated R-GCN, we denote the learned node representations as v and obtain graph-level representation v g with three different aggregation strategies: Paragraph Average (PA), Cue Average (CA) and Global Average (GA): where V = 6 i=1 Vi represents the set of all nodes in our HIN. We then transform the graph-level representation v g with a softmax layer and classify news articles into perspective labels:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_57",
            "content": "v g = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 1 |V1| v\u2208V1 v if Paragraph Average; 1 |V\u2212V1| v / \u2208V1 v if",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_58",
            "content": "\u0177 = sof tmax(W o \u2022 v g + b o )(10)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_59",
            "content": "where W o and b o are learnable parameters and \u0177 is our model's prediction. The loss function of our method is as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_60",
            "content": "L = \u2212 Y i=1 y i log( \u0177i ) + \u03bb w\u2208\u03b8 w 2 (11)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_61",
            "content": "where Y is the number of stance labels, the onehot vector y = {y 1 , ..., y Y } denotes ground-truth annotation, \u03b8 is the set of learnable parameters and \u03bb is the regularization factor.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_62",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "440-ARR_v1_63",
            "content": "Dataset",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "440-ARR_v1_64",
            "content": "We make use of two real-world political perspective detection datasets SemEval (Kiesel et al., 2019) and Allsides (Li and Goldwasser, 2019), which are widely adopted in various previous works Goldwasser, 2019, 2021;Feng et al., 2021a). We follow the same evaluation settings as in previous works so that our results are directly comparable. Section B in the appendix provides more dataset details to facilitate reproduction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_65",
            "content": "Baselines",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "440-ARR_v1_66",
            "content": "We compare KCD with the following competitive baselines and state-of-the-art methods:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_67",
            "content": "\u2022 CNN (Jiang et al., 2019) is the first-place solution in the SemEval 2019 Task 4 contest (Kiesel et al., 2019). It combines convolutional neural networks with Glove (Jiang et al., 2019) and ELMo (Peters et al., 2018) for political perspective detection on the SemEval dataset. \u2022 HLSTM (Yang et al., 2016) is short for hierarchical long short-term memory networks. Li and Goldwasser (2019) uses HLSTMs and different word embeddings for news bias detection. \u2022 HLSTM_Embed and HLSTM_Output (Li and Goldwasser, 2021) leverage entity information with masked entity models in addition to news content for political perspective detection. \u2022 Word2Vec (Mikolov et al., 2013) \u2022 MAN (Li and Goldwasser, 2021) incorporates social and linguistic information with pre-training tasks and conducts fine-tuning on the task of political perspective detection. \u2022 KGAP (Feng et al., 2021a), short for Knowledge Graph Augmented Political perspective detection, leverages knowledge graphs and graph neural networks for a knowledge-aware approach. We compare our gated R-GCN based approach with KGAP's gated R-GCN setting.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_68",
            "content": "Implementation",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "440-ARR_v1_69",
            "content": "We implement our KCD framework with pytorch (Paszke et al., 2019), pytorch lightning (Falcon and The PyTorch Lightning team, 2019), pytorch geometric (Fey and Lenssen, 2019) and the transformers library (Wolf et al., 2020). We present our hyperparameter settings in Table 1 to facilitate reproduction. We adhere to these settings throughout all experiments in the paper unless stated otherwise. Our implementation is trained on a Titan X GPU with 12GB memory. We commit to make our code and data publicly available upon acceptance to facilitate reproduction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_70",
            "content": "Experiment Results",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "440-ARR_v1_71",
            "content": "We present model performance on two benchmark datasets in Table 2, which demonstrates that",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_72",
            "content": "\u2022 KCD, especially with the PA aggregation strategy, consistently outperforms state-of-the-art methods on both benchmark datasets. \u2022 KGAP and KCD, which incorporate knowledge graphs, outperform other baselines. This indicates that external knowledge is essential in providing background information and political context to analyze ideological perspectives. \u2022 PA outperforms CA and GA on both datasets, which suggest the aggregation strategy is important and paragraph nodes should be the focus in our heterogeneous information networks.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_73",
            "content": "In the following, we examine the effect of knowledge walks and textual cues in our approach. We also explore how our approach performs with limited data compared to baseline methods.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_74",
            "content": "Knowledge Walks Study",
            "ntype": "title",
            "meta": {
                "section": "4.5"
            }
        },
        {
            "ix": "440-ARR_v1_75",
            "content": "We propose knowledge walks, an approach to conduct multi-hop reasoning on knowledge graphs and inject them into textual representations. We study the effect of knowledge walk length and knowledge infusion strategies on our model's performance. Figure 3: Our approach's performance when the maximum length of knowledge walk generation is specified from 1 to 10 knowledge graph triples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_76",
            "content": "Knowledge Walks Length",
            "ntype": "title",
            "meta": {
                "section": "4.5.1"
            }
        },
        {
            "ix": "440-ARR_v1_77",
            "content": "Our proposed knowledge walks could be of any length, where shorter walks provide more condensed knowledge and longer walks provide more diverse knowledge. To examine the effect of knowledge walk length, we generate 5,088 3 knowledge walks of 1 to 10 triples and present model performance in Figure 3. It is illustrated that longer knowledge walks (8 or 9 for SemEval, 7 or 8 for Allsides) perform better than shorter ones, indicating the necessity of multi-hop knowledge reasoning in the task of political perspective detection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_78",
            "content": "Knowledge Infusion Strategy",
            "ntype": "title",
            "meta": {
                "section": "4.5.2"
            }
        },
        {
            "ix": "440-ARR_v1_79",
            "content": "We propose a two-step approach to infuse multihop knowledge reasoning into textual representations of news articles:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_80",
            "content": "\u2022 First Aggregation: We firstly aggregate different generated knowledge walks based on semantic relevance in Equ. (5) and Equ. ( 6). \u2022 Second Aggregation: We then use multi-head attention to aggregate all paragraphs and knowledge representations with Equ. ( 7) and Equ. (8).",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_81",
            "content": "To examine the effect of our knowledge infusion strategy, we substitute these two aggregation steps with different multi-head attention settings as well as max and average pooling. Results in Figure 4 demonstrate significant performance difference on the horizontal axis. This suggests that our semantic relevance-based knowledge walks aggregation strategy in Equ. (5) and Equ. (6) successfully filters out irrelevant knowledge reasoning and contributes to model performance. Besides, according to the 3 so that there is a knowledge walk beginning with every possible (entity, relation) in the knowledge graph. vertical axis, our adopted multi-head attention in Equ. ( 7) and Equ. ( 8) is generally effective and does not rely on specific attention head settings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_82",
            "content": "Textual Cue Study",
            "ntype": "title",
            "meta": {
                "section": "4.6"
            }
        },
        {
            "ix": "440-ARR_v1_83",
            "content": "We propose to leverage semantic, syntactic and entity textual cues as paragraph-level labels to leverage implicit indicators in news articles for political perspective detection. To examine the effectiveness of these textual cues, we randomly remove them with probability p and present model performance in Figure 5. It is illustrated that:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_84",
            "content": "\u2022 A performance boost is observed between 0%",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_85",
            "content": "and 100% for all five textual cues, suggesting the necessity of modeling implicit textual indicators. Besides, adding only part of textual cues sometimes leads to a decrease in performance, which implies that incomplete cues may be counterproductive.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_86",
            "content": "\u2022 Among five different cues, entity and quotation cues contribute more to model performance than others. This suggests some implicit textual cues are more important than others in analyzing the ideological perspectives of news articles. \u2022 The effect of textual cues is larger on the dataset SemEval, which is significantly smaller than Allsides. This suggests that we alleviate the datahungry problem by introducing diversified textual cues as paragraph-level labels and contribute to model performance.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_87",
            "content": "Data Efficiency Study",
            "ntype": "title",
            "meta": {
                "section": "4.7"
            }
        },
        {
            "ix": "440-ARR_v1_88",
            "content": "As Li and Goldwasser (2021) point out, supervised data annotations could be difficult and expensive to obtain for the task of political perspective detection in news media. Our proposed knowledge walks and textual cues serve as additional information and might help mitigate this issue. To examine whether we have achieved this end, we train KCD, kGAP (Feng et al., 2021a) as well as various text models with reduced training sets of SemEval and Allsides. Results in Figure 6 demonstrate that",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_89",
            "content": "\u2022 KCD has better data efficiency and achieves steady performance with smaller training sets. This observation is especially salient on Allsides where the news articles are longer (Li and Goldwasser, 2021), thus more knowledge walks and textual cues could be extracted and incorporated to alleviate data dependence. \u2022 Both KCD and KGAP leverage external knowledge and are more robust to reduced datasets. Our approach further leverages textual cues and has better data deficiency. This suggests a solution to limited data could be incorporating information in addition to news content. \u2022 With only 10% training set, KCD outperforms all baselines by at least 5.68% and 9.71% in accuracy on two datasets. This suggests that our approach is simple, effective, and not data-hungry under limited data settings.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_90",
            "content": "Our proposed model has two minor limitations:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_91",
            "content": "\u2022 We propose to model news articles with heterogeneous information networks. This graph-based approach might not fit well with shorter news articles with only a few paragraphs. This issue might be addressed by using sentence nodes instead of paragraph nodes for shorter articles. \u2022 For very large knowledge graphs with many different types of relations, it might be hard for domain experts to help set p(r) for every knowledge graph relation. This issue might be addressed by only setting a larger p(r) for several important rs according to domain expert.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_92",
            "content": "We used the same datasets as in previous works Goldwasser, 2019, 2021;Feng et al., 2021a), namely SemEval (Kiesel et al., 2019) and Allsides (Li and Goldwasser, 2019). We follow the same 10-fold setting for SemEval and 3-fold setting for Allsides (Li and Goldwasser, 2021). We use the exact same folds so that the results are directly comparable. A minor difference would be that we have to discard a few news articles on Allsides since their urls have expired and we could not retrieve their original news article. We report the statistical information of SemEval and Allsides in Table 3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_93",
            "content": "C.1 Computational Resources",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_94",
            "content": "Our proposed approach has a total of 7.8M learnable parameters. It takes approximately 0.7 and 1.6 GPU hours to train our approach on two datasets respectively. We train our model on one Titan X GPU with 12GB memory.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_95",
            "content": "We run our approach with three different aggregation strategies five times and report the average accuracy and macro F1-score in Table 2. For experiments in Section 4.5, 4.6 and 4.7, we do not have enough computational resources to run five times, thus we report the performance of a single run.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_96",
            "content": "We provide additional details about used scientific artifacts and specifically how we used them. \u2022 NLTK (Bird et al., 2009): We use NLTK to extract the tense of news articles. Specifically, we first use NLTK POS-tagger to process new paragraphs and attach speech tag to each word. Then we align verb tags with NLTK tagset to identify the tense of paragraphs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_97",
            "content": "\u2022 BertTopic (Grootendorst, 2020): We use Bert-Topic to mine the topics of news corpus. Specifically, we use BertTopic topic model to learn dataset-specific topic models. For SemEval we obtained 197 topics and for Allsides we obtained 1225 topics. Next, we predict topics for each news paragraph. Each topic consists of ten topic words with scores and we select the top five to serve as the news paragraph's topic. \u2022 Huggingface Transformers (Wolf et al., 2020):",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_98",
            "content": "We use the pipeline module for sentiment analysis. Specifically, we use the sentiment analysis API in the text classification pipeline to generate a sentiment label and score for news paragraphs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_99",
            "content": "We then use the sentiment label as the sentiment cues for news paragraphs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_100",
            "content": "\u2022 TagMe (Ferragina and Scaiella, 2011): We use TagMe to align news articles with entities in the knowledge graph. Specifically, we use TagMe to annotate named entities in news paragraphs and save the entities with a score higher than 0.1 for further alignment. We then calculate the similarity score between TagMe annotated entities and political knowledge graph entities. We recognize the entities with a score higher than 0.9 as entity cues in our constructed HIN. \u2022 Political knowledge graph (Feng et al., 2021a):",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_101",
            "content": "We use the political knowledge graph collected in Feng et al. (2021a) for external knowledge in political perspective detection.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_102",
            "content": "\u2022 OpenKE (Han et al., 2018): We use OpenKE to train TransE (Bordes et al., 2013) knowledge graph embeddings for the political knowledge graph. Specifically, we set the TransE hidden size to 768 and train the model with other default hyperparameters in OpenKE.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "440-ARR_v1_103",
            "content": "Isabelle Augenstein, Tim Rockt\u00e4schel, Andreas Vlachos, and Kalina Bontcheva, 2016, Stance detection with bidirectional conditional encoding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Isabelle Augenstein",
                    "Tim Rockt\u00e4schel"
                ],
                "title": "Andreas Vlachos, and Kalina Bontcheva",
                "pub_date": "2016",
                "pub_title": "Stance detection with bidirectional conditional encoding",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_104",
            "content": "UNKNOWN, None, 2020, We can detect your bias: Predicting the political ideology of news articles, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "We can detect your bias: Predicting the political ideology of news articles",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_105",
            "content": "Gemma Bel-Enguix, Helena G\u00f3mez-Adorno, Alejandro Pimentel, Sergio-Luis Ojeda-Trueba, Brian Aguilar-Vizuet, Negation detection on mexican spanish tweets: The t-mexneg corpus, 2021, Applied Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Gemma Bel-Enguix",
                    "Helena G\u00f3mez-Adorno",
                    "Alejandro Pimentel",
                    "Sergio-Luis Ojeda-Trueba",
                    "Brian Aguilar-Vizuet"
                ],
                "title": "Negation detection on mexican spanish tweets: The t-mexneg corpus",
                "pub_date": "2021",
                "pub_title": "Applied Sciences",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_106",
            "content": "UNKNOWN, None, 2009, Natural language processing with Python: analyzing text with the natural language toolkit, Reilly Media, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2009",
                "pub_title": "Natural language processing with Python: analyzing text with the natural language toolkit",
                "pub": "Reilly Media, Inc"
            }
        },
        {
            "ix": "440-ARR_v1_107",
            "content": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, Jamie Taylor, Freebase: a collaboratively created graph database for structuring human knowledge, 2008, Proceedings of the 2008 ACM SIG-MOD international conference on Management of data, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Kurt Bollacker",
                    "Colin Evans",
                    "Praveen Paritosh",
                    "Tim Sturge",
                    "Jamie Taylor"
                ],
                "title": "Freebase: a collaboratively created graph database for structuring human knowledge",
                "pub_date": "2008",
                "pub_title": "Proceedings of the 2008 ACM SIG-MOD international conference on Management of data",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_108",
            "content": "Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko, Translating embeddings for modeling multirelational data, 2013, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Antoine Bordes",
                    "Nicolas Usunier",
                    "Alberto Garcia-Duran",
                    "Jason Weston",
                    "Oksana Yakhnenko"
                ],
                "title": "Translating embeddings for modeling multirelational data",
                "pub_date": "2013",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_109",
            "content": "David Chang, Ivana Bala\u017eevi\u0107, Carl Allen, Daniel Chawla, Cynthia Brandt, Richard Taylor, Benchmark and best practices for biomedical knowledge graph embeddings, 2020, Proceedings of the conference. Association for Computational Linguistics. Meeting, NIH Public Access.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "David Chang",
                    "Ivana Bala\u017eevi\u0107",
                    "Carl Allen",
                    "Daniel Chawla",
                    "Cynthia Brandt",
                    "Richard Taylor"
                ],
                "title": "Benchmark and best practices for biomedical knowledge graph embeddings",
                "pub_date": "2020",
                "pub_title": "Proceedings of the conference. Association for Computational Linguistics. Meeting",
                "pub": "NIH Public Access"
            }
        },
        {
            "ix": "440-ARR_v1_110",
            "content": "Kareem Darwish, Peter Stefanov, Micha\u00ebl Aupetit, Preslav Nakov, Unsupervised user stance detection on twitter, 2020, Proceedings of the International AAAI Conference on Web and Social Media, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Kareem Darwish",
                    "Peter Stefanov",
                    "Micha\u00ebl Aupetit",
                    "Preslav Nakov"
                ],
                "title": "Unsupervised user stance detection on twitter",
                "pub_date": "2020",
                "pub_title": "Proceedings of the International AAAI Conference on Web and Social Media",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_111",
            "content": "UNKNOWN, None, 2018, Bert: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Bert: Pre-training of deep bidirectional transformers for language understanding",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_112",
            "content": "Jiachen Du, Ruifeng Xu, Yulan He, Lin Gui, Stance classification with target-specific neural attention networks, 2017, International Joint Conferences on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Jiachen Du",
                    "Ruifeng Xu",
                    "Yulan He",
                    "Lin Gui"
                ],
                "title": "Stance classification with target-specific neural attention networks",
                "pub_date": "2017",
                "pub_title": "International Joint Conferences on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_113",
            "content": "UNKNOWN, None, 2022, Semi-supervised stance detection of tweets via distant network supervision, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": null,
                "title": null,
                "pub_date": "2022",
                "pub_title": "Semi-supervised stance detection of tweets via distant network supervision",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_114",
            "content": "UNKNOWN, None, 2019, William Falcon and The PyTorch Lightning team, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "William Falcon and The PyTorch Lightning team",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_115",
            "content": "UNKNOWN, None, 2010, Theory and applications of ontology: computer applications, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": null,
                "title": null,
                "pub_date": "2010",
                "pub_title": "Theory and applications of ontology: computer applications",
                "pub": "Springer"
            }
        },
        {
            "ix": "440-ARR_v1_116",
            "content": "UNKNOWN, None, , Xiaojun Chang, and Qinghua Zheng. 2021a. Knowledge graph augmented political perspective detection in news media, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Xiaojun Chang, and Qinghua Zheng. 2021a. Knowledge graph augmented political perspective detection in news media",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_117",
            "content": "UNKNOWN, None, 2021, Legislator representation learning with social context and expert knowledge, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Legislator representation learning with social context and expert knowledge",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_118",
            "content": "Paolo Ferragina, Ugo Scaiella, Fast and accurate annotation of short texts with wikipedia pages, 2011, IEEE software, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Paolo Ferragina",
                    "Ugo Scaiella"
                ],
                "title": "Fast and accurate annotation of short texts with wikipedia pages",
                "pub_date": "2011",
                "pub_title": "IEEE software",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_119",
            "content": "UNKNOWN, None, 2019-01, Fast graph representation learning with pytorch geometric, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": null,
                "title": null,
                "pub_date": "2019-01",
                "pub_title": "Fast graph representation learning with pytorch geometric",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_120",
            "content": "UNKNOWN, None, 2020, Bertopic: Leveraging bert and c-tf-idf to create easily interpretable topics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Bertopic: Leveraging bert and c-tf-idf to create easily interpretable topics",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_121",
            "content": "Xu Han, Shulin Cao, Lv Xin, Yankai Lin, Zhiyuan Liu, Maosong Sun, Juanzi Li, Openke: An open toolkit for knowledge embedding, 2018, Proceedings of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Xu Han",
                    "Shulin Cao",
                    "Lv Xin",
                    "Yankai Lin",
                    "Zhiyuan Liu",
                    "Maosong Sun",
                    "Juanzi Li"
                ],
                "title": "Openke: An open toolkit for knowledge embedding",
                "pub_date": "2018",
                "pub_title": "Proceedings of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_122",
            "content": "Sara Benjamin D Horne, Sibel Khedr,  Adali, Sampling the news producers: A large news and feature data set for the study of the complex media landscape, 2018, Twelfth International AAAI Conference on Web and Social Media, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Sara Benjamin D Horne",
                    "Sibel Khedr",
                    " Adali"
                ],
                "title": "Sampling the news producers: A large news and feature data set for the study of the complex media landscape",
                "pub_date": "2018",
                "pub_title": "Twelfth International AAAI Conference on Web and Social Media",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_123",
            "content": "Linmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong, Duyu Tang, Chuan Shi, Nan Duan, Ming Zhou, Compare to the knowledge: Graph neural fake news detection with external knowledge, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Linmei Hu",
                    "Tianchi Yang",
                    "Luhao Zhang",
                    "Wanjun Zhong",
                    "Duyu Tang",
                    "Chuan Shi",
                    "Nan Duan",
                    "Ming Zhou"
                ],
                "title": "Compare to the knowledge: Graph neural fake news detection with external knowledge",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "440-ARR_v1_124",
            "content": "Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, Tiejun Zhao, Target-dependent twitter sentiment classification, 2011, Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Long Jiang",
                    "Mo Yu",
                    "Ming Zhou",
                    "Xiaohua Liu",
                    "Tiejun Zhao"
                ],
                "title": "Target-dependent twitter sentiment classification",
                "pub_date": "2011",
                "pub_title": "Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_125",
            "content": "Ye Jiang, Johann Petrak, Xingyi Song, Kalina Bontcheva, Diana Maynard, Team bertha von suttner at semeval-2019 task 4: Hyperpartisan news detection using elmo sentence representation convolutional network, 2019, Proceedings of the 13th International Workshop on Semantic Evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Ye Jiang",
                    "Johann Petrak",
                    "Xingyi Song",
                    "Kalina Bontcheva",
                    "Diana Maynard"
                ],
                "title": "Team bertha von suttner at semeval-2019 task 4: Hyperpartisan news detection using elmo sentence representation convolutional network",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 13th International Workshop on Semantic Evaluation",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_126",
            "content": "Johannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh, David Corney, Benno Stein, Martin Potthast, Semeval-2019 task 4: Hyperpartisan news detection, 2019, Proceedings of the 13th International Workshop on Semantic Evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Johannes Kiesel",
                    "Maria Mestre",
                    "Rishabh Shukla",
                    "Emmanuel Vincent",
                    "Payam Adineh",
                    "David Corney",
                    "Benno Stein",
                    "Martin Potthast"
                ],
                "title": "Semeval-2019 task 4: Hyperpartisan news detection",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 13th International Workshop on Semantic Evaluation",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_127",
            "content": "Chang Li, Dan Goldwasser, Encoding social information with graph convolutional networks forpolitical perspective detection in news media, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Chang Li",
                    "Dan Goldwasser"
                ],
                "title": "Encoding social information with graph convolutional networks forpolitical perspective detection in news media",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_128",
            "content": "Chang Li, Dan Goldwasser, Using social and linguistic information to adapt pretrained representations for political perspective identification, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Chang Li",
                    "Dan Goldwasser"
                ],
                "title": "Using social and linguistic information to adapt pretrained representations for political perspective identification",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_129",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Roberta: A robustly optimized bert pretraining approach",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_130",
            "content": "UNKNOWN, None, 2021, Kelm: Knowledge enhanced pretrained language representations with message passing on hierarchical relational graphs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Kelm: Knowledge enhanced pretrained language representations with message passing on hierarchical relational graphs",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_131",
            "content": "Walid Magdy, Kareem Darwish, Norah Abokhodair, Afshin Rahimi, Timothy Baldwin, # isisisnotislam or# deportallmuslims? predicting unspoken views, 2016, Proceedings of the 8th ACM Conference on Web Science, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Walid Magdy",
                    "Kareem Darwish",
                    "Norah Abokhodair",
                    "Afshin Rahimi",
                    "Timothy Baldwin"
                ],
                "title": "# isisisnotislam or# deportallmuslims? predicting unspoken views",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 8th ACM Conference on Web Science",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_132",
            "content": "UNKNOWN, None, 2020, Verb knowledge injection for multilingual event processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Verb knowledge injection for multilingual event processing",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_133",
            "content": "UNKNOWN, None, 2021, Mixtureof-partitions: Infusing large biomedical knowledge graphs into bert, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Mixtureof-partitions: Infusing large biomedical knowledge graphs into bert",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_134",
            "content": "UNKNOWN, None, 2013, Efficient estimation of word representations in vector space, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Efficient estimation of word representations in vector space",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_135",
            "content": "UNKNOWN, None, 2019, Enriching bert with knowledge graph embeddings for document classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Enriching bert with knowledge graph embeddings for document classification",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_136",
            "content": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Pytorch: An imperative style, high-performance deep learning library, 2019, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Adam Paszke",
                    "Sam Gross",
                    "Francisco Massa",
                    "Adam Lerer",
                    "James Bradbury",
                    "Gregory Chanan",
                    "Trevor Killeen",
                    "Zeming Lin",
                    "Natalia Gimelshein",
                    "Luca Antiga"
                ],
                "title": "Pytorch: An imperative style, high-performance deep learning library",
                "pub_date": "2019",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_137",
            "content": "Jeffrey Pennington, Richard Socher, Christopher D Manning, Glove: Global vectors for word representation, 2014, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Jeffrey Pennington",
                    "Richard Socher",
                    "Christopher D Manning"
                ],
                "title": "Glove: Global vectors for word representation",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_138",
            "content": "UNKNOWN, None, 2018, Deep contextualized word representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Deep contextualized word representations",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_139",
            "content": "Robyn Speer, Joshua Chin, Catherine Havasi, Conceptnet 5.5: An open multilingual graph of general knowledge, 2017, Thirty-first AAAI conference on artificial intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Robyn Speer",
                    "Joshua Chin",
                    "Catherine Havasi"
                ],
                "title": "Conceptnet 5.5: An open multilingual graph of general knowledge",
                "pub_date": "2017",
                "pub_title": "Thirty-first AAAI conference on artificial intelligence",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_140",
            "content": "Peter Stefanov, Kareem Darwish, Atanas Atanasov, Preslav Nakov, Predicting the topical stance and political leaning of media using tweets, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Peter Stefanov",
                    "Kareem Darwish",
                    "Atanas Atanasov",
                    "Preslav Nakov"
                ],
                "title": "Predicting the topical stance and political leaning of media using tweets",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_141",
            "content": "Gerhard Thomas Pellissier Tanon, Fabian Weikum,  Suchanek, Yago 4: A reason-able knowledge base, 2020, European Semantic Web Conference, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Gerhard Thomas Pellissier Tanon",
                    "Fabian Weikum",
                    " Suchanek"
                ],
                "title": "Yago 4: A reason-able knowledge base",
                "pub_date": "2020",
                "pub_title": "European Semantic Web Conference",
                "pub": "Springer"
            }
        },
        {
            "ix": "440-ARR_v1_142",
            "content": "Bo Wang, Maria Liakata, Arkaitz Zubiaga, Rob Procter, Tdparse: Multi-target-specific sentiment recognition on twitter, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Bo Wang",
                    "Maria Liakata",
                    "Arkaitz Zubiaga",
                    "Rob Procter"
                ],
                "title": "Tdparse: Multi-target-specific sentiment recognition on twitter",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "440-ARR_v1_143",
            "content": "Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, Jian Tang, Kepler: A unified model for knowledge embedding and pre-trained language representation, 2021, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Xiaozhi Wang",
                    "Tianyu Gao",
                    "Zhaocheng Zhu",
                    "Zhengyan Zhang",
                    "Zhiyuan Liu",
                    "Juanzi Li",
                    "Jian Tang"
                ],
                "title": "Kepler: A unified model for knowledge embedding and pre-trained language representation",
                "pub_date": "2021",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_144",
            "content": "UNKNOWN, None, 2021, Knowledge enhanced pretrained language models: A compreshensive survey, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "Knowledge enhanced pretrained language models: A compreshensive survey",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_145",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest,  Rush, Transformers: State-of-the-art natural language processing, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Thomas Wolf",
                    "Lysandre Debut",
                    "Victor Sanh",
                    "Julien Chaumond",
                    "Clement Delangue",
                    "Anthony Moi",
                    "Pierric Cistac",
                    "Tim Rault",
                    "R\u00e9mi Louf",
                    "Morgan Funtowicz",
                    "Joe Davison",
                    "Sam Shleifer",
                    "Clara Patrick Von Platen",
                    "Yacine Ma",
                    "Julien Jernite",
                    "Canwen Plu",
                    "Teven Xu",
                    "Sylvain Scao",
                    "Mariama Gugger",
                    "Quentin Drame",
                    "Alexander Lhoest",
                    " Rush"
                ],
                "title": "Transformers: State-of-the-art natural language processing",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "440-ARR_v1_146",
            "content": "UNKNOWN, None, 2018, Cross-target stance classification with self-attention networks, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Cross-target stance classification with self-attention networks",
                "pub": null
            }
        },
        {
            "ix": "440-ARR_v1_147",
            "content": "UNKNOWN, None, 2016, Hierarchical attention networks for document classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Hierarchical attention networks for document classification",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "440-ARR_v1_0@0",
            "content": "KCD: Knowledge Walks and Textual Cues Enhanced Political Perspective Detection in News Media",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_0",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@0",
            "content": "Political perspective detection has become an increasingly important task that can help combat echo chambers and political polarization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@1",
            "content": "Previous approaches generally focus on leveraging textual content to identify stances, while they fail to reason with background knowledge or leverage the rich semantic and syntactic textual labels in news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 137,
            "end": 351,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@2",
            "content": "In light of these limitations, we propose KCD, a political perspective detection approach to enable multihop knowledge reasoning and incorporate textual cues as paragraph-level labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 353,
            "end": 536,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@3",
            "content": "Specifically, we firstly generate random walks on external knowledge graphs and infuse them with news text representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 538,
            "end": 660,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@4",
            "content": "We then construct a heterogeneous information network to jointly model news content as well as semantic, syntactic and entity cues in news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 662,
            "end": 809,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@5",
            "content": "Finally, we adopt relational graph neural networks for graph-level representation learning and conduct political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 811,
            "end": 945,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@6",
            "content": "Extensive experiments demonstrate that our approach outperforms state-of-the-art methods on two benchmark datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 947,
            "end": 1061,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_2@7",
            "content": "We further examine the effect of knowledge walks and textual cues and how they contribute to our approach's data efficiency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_2",
            "start": 1063,
            "end": 1186,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_4@0",
            "content": "Political perspective detection aims to identify ideological stances of textual data such as social media posts and news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_4",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_4@1",
            "content": "Previous approaches generally leverage the textual content of news articles with various text modeling techniques to identify stances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_4",
            "start": 131,
            "end": 264,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_4@2",
            "content": "Those works (Jiang et al., 2019; labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_4",
            "start": 266,
            "end": 305,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_4@3",
            "content": "Later approaches incorporate information sources beyond text to facilitate argument mining and boost task performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_4",
            "start": 307,
            "end": 424,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_4@4",
            "content": "News discussion on social networks (Li and Goldwasser, 2019), social and linguistic information about news articles (Li and Goldwasser, 2021), media sources and information (Baly et al., 2020) as well as external knowledge from knowledge graphs (Feng et al., 2021a) are introduced in the task of political perspective detection and achieve better performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_4",
            "start": 426,
            "end": 784,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_5@0",
            "content": "Although these methods attempted to leverage more than news content, they fail to present a framework capable of reasoning with background knowledge and leveraging implicit semantic and syntactic indicators such as sentiment and tense of news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_5",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_5@1",
            "content": "For example, Figure 1 presents a typical news article from Daily Kos 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_5",
            "start": 253,
            "end": 324,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_5@2",
            "content": "This article discusses remarks from the Trump campaign team about Wikileaks and its effect on Hillary Clinton's bid for president.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_5",
            "start": 326,
            "end": 455,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_5@3",
            "content": "Individuals often rely on the multi-hop reasoning that Clinton and Trump are from opposite political parties and run against each other to inform their perspective analysis process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_5",
            "start": 457,
            "end": 637,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_5@4",
            "content": "Besides, the negative sentiment expressed in satiric tones and the quotation of Trump campaign staff also give away the author's denial and left-leaning perspective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_5",
            "start": 639,
            "end": 803,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_5@5",
            "content": "That being said, knowledge reasoning and implicit textual indicators are essential in the news bias detection process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_5",
            "start": 805,
            "end": 922,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_6@0",
            "content": "In light of these limitations, we propose a political perspective detection framework KCD (Knowledge Walks and Textual Cues Enhanced Political Perspective Detection).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_6",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_6@1",
            "content": "Specifically, KCD generates multi-hop knowledge walks, aggregates them based on semantic relevance and incorporates them in textual representations with multi-head attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_6",
            "start": 167,
            "end": 340,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_6@2",
            "content": "KCD then constructs a heterogeneous information network to jointly model knowledgeenriched news content and diversified textual cues as paragraph-level labels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_6",
            "start": 342,
            "end": 500,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_6@3",
            "content": "Finally, KCD learns graph representations with relational graph neural networks and conduct perspective detection with different aggregation strategies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_6",
            "start": 502,
            "end": 653,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_6@4",
            "content": "Our main contributions are summarized as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_6",
            "start": 655,
            "end": 703,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_7@0",
            "content": "\u2022 We propose knowledge walks, a strategy to incorporate multi-hop knowledge reasoning in textual representations for knowledge-aware political perspective detection. \u2022 We propose to construct a heterogeneous information network to represent news articles, which jointly models knowledge-enriched news content and implicit textual cues in news articles. \u2022 Extensive experiments demonstrate that our approach consistently outperforms state-of-the-art methods on two widely adopted benchmarks. Further analysis bears out the necessity of knowledge walks and textual cues in our approach.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_7",
            "start": 0,
            "end": 583,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_8@0",
            "content": "2 Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_8",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_9@0",
            "content": "Political Perspective Detection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_9",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@0",
            "content": "Political perspective detection aims to identify the ideological stances of news articles, which is widely studied to help strengthen the online information landscape (Li and Goldwasser, 2019) and mitigate ideological echo chambers (Li and Goldwasser, 2021;Feng et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 0,
            "end": 276,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@1",
            "content": "Early approaches leverage text analysis techniques for bias detection, such as sentiment analysis (Jiang et al., 2011;Wang et al., 2017), bias feature extraction (Horne et al., 2018), word embeddings (Jiang et al., 2019;Li and Goldwasser, 2019) and different neural network architectures (Augenstein et al., 2016;Du et al., 2017;Xu et al., 2018;Yang et al., 2016;Jiang et al., 2019;Feng et al., 2021b;Li and Goldwasser, 2021;Feng et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 278,
            "end": 722,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@2",
            "content": "In addition to textual content of news articles, social media users also become the focus of perspective detection research (Bel-Enguix et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 724,
            "end": 873,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@3",
            "content": "User interactions (Magdy et al., 2016), user clustering , and label propagation are leveraged to identify the ideological preferences on social media.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 875,
            "end": 1024,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@4",
            "content": "Fusing both news text and social network analysis directions, Li and Goldwasser (2019) propose to enrich news text with the content and structure of social media discussions about these news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 1026,
            "end": 1225,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@5",
            "content": "Recent state-of-the-art approaches chart a new path by incorporating social and political external knowledge into stance detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 1227,
            "end": 1357,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@6",
            "content": "Baly et al. (2020) propose adversarial media adaptation and leverage source background knowledge for political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 1359,
            "end": 1491,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@7",
            "content": "Li and Goldwasser (2021) combine language encoders with pre-training tasks of social and linguistic information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 1493,
            "end": 1604,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@8",
            "content": "Feng et al. (2021a) propose to construct and leverage political knowledge graphs as domain-specific external knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 1606,
            "end": 1724,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_10@9",
            "content": "In this paper, we build on these works to examine and explore the effect of multi-hop knowledge reasoning and diversified textual cues in the task of political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_10",
            "start": 1726,
            "end": 1907,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_11@0",
            "content": "Knowledge Graph in NLP",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_11",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_12@0",
            "content": "Knowledge graphs (KGs) are effective representations of real-world entities, relations, and knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_12",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_12@1",
            "content": "Generic (Fellbaum, 2010;Tanon et al., 2020;Bollacker et al., 2008;Speer et al., 2017) and domain-specific KGs (Feng et al., 2021a;Chang et al., 2020) are widely adopted in NLP tasks as external knowledge sources.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_12",
            "start": 103,
            "end": 314,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_12@2",
            "content": "These approaches could mainly be categorized into feature extraction, language model and graph-based methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_12",
            "start": 316,
            "end": 424,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_12@3",
            "content": "For feature extraction approaches, KG embedding technique TransE (Bordes et al., 2013) is leveraged to learn features for knowledge injecton (Ostendorff et al., 2019;Hu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_12",
            "start": 426,
            "end": 608,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_12@4",
            "content": "For language model approaches, the adapter architecture is leveraged to fine-tune on KG-related tasks (Majewska et al., 2020;Meng et al., 2021;Wei et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_12",
            "start": 610,
            "end": 770,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_12@5",
            "content": "In ad-",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_12",
            "start": 772,
            "end": 777,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_13@0",
            "content": "The September 4 date on the email puts it over a month before Trump shouted \"I love Wikileaks\" in the midst of one of his rallies while reading clips from stolen emails in an effort to demean Hillary Clinton.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_13",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_14@0",
            "content": "The September 4 date on the email puts it over a month before Trump shouted \"I love Wikileaks\" in the midst of one of his rallies while reading clips from stolen emails in an effort to demean Hillary Clinton.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_14",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_15@0",
            "content": "Graph Construction \uf052 1 \uf052 2 \uf052 3 \uf052 4 \uf052 5 \uf052 6 \uf052 1 \uf052 2 \uf052 3 \uf052 4 \uf052 5 \uf052 6 \uf056 1 \uf056 2 \uf056 3 \uf056 4 \uf056 5 \uf056 6 \uf056 1 \uf056 2 \uf056 3 \uf056 4 \uf056 5 \uf056 6",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_15",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_16@0",
            "content": "Knowledge Walk Generation dition, propose a unified model to combine knowledge embedding with language representation pre-training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_16",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_16@1",
            "content": "For graph-based approaches, KG entities and relations are injected into graphs and heterogeneous information networks (Hu et al., 2021;Feng et al., 2021a;Lu et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_16",
            "start": 132,
            "end": 302,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_16@2",
            "content": "Graph neural networks are then adopted to learn knowledge-aware text representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_16",
            "start": 304,
            "end": 388,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_16@3",
            "content": "In this paper, we propose knowledge walk, a novel strategy to infuse multi-hop knowledge reasoning into language representations and apply them in political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_16",
            "start": 390,
            "end": 568,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_17@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_17",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_18@0",
            "content": "Figure 2 presents an overview of our proposed political perspective detection framework KCD (Knowledge Walks and Textual Cues Enhanced Political Perspective Detection).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_18",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_18@1",
            "content": "We firstly generate knowledge walks on the external knowledge graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_18",
            "start": 169,
            "end": 236,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_18@2",
            "content": "These knowledge walks are then selected based on semantic relevance and injected into textual representations with multi-head attention.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_18",
            "start": 238,
            "end": 373,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_18@3",
            "content": "We then construct a heterogeneous information network to jointly model knowledge-enriched news content and diversified textual cues as paragraph-level labels and supernodes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_18",
            "start": 375,
            "end": 547,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_18@4",
            "content": "Finally, we adopt relational graph neural networks and different aggregation strategies to learn graph-level representation and conduct political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_18",
            "start": 549,
            "end": 716,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_19@0",
            "content": "Knowledge Walks and Infusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_19",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_20@0",
            "content": "We firstly propose the novel strategy of knowledge walks and combine them with textual representations to enable multi-hop knowledge reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_20",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_20@1",
            "content": "We partition an n-paragraph news document into different paragraphs and denote them as S = {s 1 , ..., s n }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_20",
            "start": 144,
            "end": 252,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_20@2",
            "content": "We encode each paragraph with pre-trained RoBERTa (Liu et al., 2019):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_20",
            "start": 254,
            "end": 322,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_21@0",
            "content": "v s i = RoBERT a(s i ), 1 \u2264 i \u2264 n (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_21",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_22@0",
            "content": "We use a political knowledge graph 2 as external knowledge for perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_22",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_22@1",
            "content": "Let the ith triple in the knowledge graph be (e ih , r i , e it ), where e ih and e it denote the head and tail entity and r i represents the relation of the i-th triple.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_22",
            "start": 86,
            "end": 255,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_23@0",
            "content": "Knowledge Walk Generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_23",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_24@0",
            "content": "We firstly use TagMe (Ferragina and Scaiella, 2011) to identify mentioned KG entities in each paragraph s i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_24",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_24@1",
            "content": "For each mentioned entity, we use it as the starting point e (0) in a K-hop knowledge walk:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_24",
            "start": 110,
            "end": 200,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_25@0",
            "content": "kw i = {e (0) , r 0,1 , e (1) , ..., r K\u22121,K , e (K) } (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_25",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_26@0",
            "content": "where e (i\u22121) and r i\u22121,i denote the i-th triple's head entity and relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_26",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_26@1",
            "content": "Specifically, a knowledge walk is generated by adopting biased random walk of length K starting from e (0) .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_26",
            "start": 77,
            "end": 184,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_26@2",
            "content": "The conditional probability of arriving at e (i) from e (i\u22121) through r i\u22121,i is formulated as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_26",
            "start": 186,
            "end": 279,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_27@0",
            "content": "P (e (i) |e (i\u22121) , r i\u22121,i ) = exp(p(r i\u22121,i )) |Nr(i\u22121)| j=1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_27",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_28@0",
            "content": "exp(p(r j ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_28",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_29@0",
            "content": "(3) where N r (i \u2212 1) denotes the neighboring relations of e (i\u22121) , p(r) is the importance score of KG relation r, which could be tuned by domain experts for human-in-the-loop knowledge walk generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_29",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_29@1",
            "content": "In this way, we generate multiple knowledge walks for each paragraph based on its mentioned entities, which models the multi-hop reasoning process with external knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_29",
            "start": 204,
            "end": 374,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_30@0",
            "content": "Semantic-Guided Selection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_30",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_31@0",
            "content": "After obtaining multiple knowledge walks for a single news paragraph, we propose a selection and aggregation process guided by text semantics to differentiate essential knowledge walks from the irrelevant ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_31",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_31@1",
            "content": "We firstly transform each knowledge walk kw i into a sentence t i by concatenating the textual description of entities and relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_31",
            "start": 211,
            "end": 343,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_31@2",
            "content": "We then encode the knowledge walk sentence t i with pre-trained RoBERTa (Liu et al., 2019):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_31",
            "start": 345,
            "end": 435,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_32@0",
            "content": "v k i = RoBERT a(t i )(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_32",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_33@0",
            "content": "Suppose a total of m knowledge walks {kw i,j } m j=1 are generated for paragraph s i , we then aggregate their knowledge walk sentence embeddings {v k i,j } m j=1 as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_33",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_34@0",
            "content": "v p i = m j=1 exp(\u03b1 \u2022 v k i,j ) m q=1 exp(\u03b1 \u2022 v k i,q ) v k i,j(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_34",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_35@0",
            "content": "where \u03b1 denotes the learnable attention vector guided by paragraph semantics:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_35",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_36@0",
            "content": "\u03b1 = \u03d5(W a v s i + b a )(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_36",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_37@0",
            "content": "where W a and b a are learnable parameters of the attention module and we use Leaky-ReLU for \u03d5. In this way, we aggregate m knowledge walks based on semantic relevance to the paragraph to filter and retain important knowledge reasoning paths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_37",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_38@0",
            "content": "Knowledge Infusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_38",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_39@0",
            "content": "After representing multi-hop knowledge reasoning for paragraph s i with v p i , we conduct documentwise multi-head self-attention to infuse knowledge walks into textaul representations v s i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_39",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_39@1",
            "content": "We concatenate knowledge walk and text representations:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_39",
            "start": 193,
            "end": 247,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_40@0",
            "content": "T = concat([v s 1 , v p 1 , ..., v s n , v p n ]) (7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_40",
            "start": 0,
            "end": 52,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_41@0",
            "content": "where T is the input for multi-head self-attention:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_41",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_42@0",
            "content": "T = M ultiHead(Q, K, V )(8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_42",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_43@0",
            "content": "where",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_43",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_44@0",
            "content": "Q = K = V = T and the output T = concat([ \u1e7ds 1 , \u1e7dp 1 , ..., \u1e7ds n , \u1e7dp n ]).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_44",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_45@0",
            "content": "In this way, we obtain language representations of news paragraphs { \u1e7ds i } n i=1 , which jointly models textual content and related multi-hop knowledge reasoning paths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_45",
            "start": 0,
            "end": 168,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_46@0",
            "content": "Textual Cues and Graph Construction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_46",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_47@0",
            "content": "We construct a heterogeneous information network (HIN) as in Figure 2 \"Graph Construction\" to jointly represent knowledge-enriched news content and diversified textual cues in news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_47",
            "start": 0,
            "end": 189,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_47@1",
            "content": "Specifically, we use paragraph nodes to represent the news content and connect them with different paragraph-level labels with heterogeneous edges.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_47",
            "start": 191,
            "end": 337,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_47@2",
            "content": "Firstly, for paragraph nodes: V1 and R1: Paragraph Nodes We use one node in V1 to represent each paragraph in the news article to partition the entire document and allow fine-grained analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_47",
            "start": 339,
            "end": 530,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_47@3",
            "content": "We adopt the knowledgeenriched representations { \u1e7ds i } n i=1 in Section 3.1 as initial node features for V1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_47",
            "start": 532,
            "end": 640,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_47@4",
            "content": "We then use relation R1 to connect adjacent paragraphs to preserve the original flow of the news article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_47",
            "start": 642,
            "end": 746,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_48@0",
            "content": "Semantic Cues",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_48",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@0",
            "content": "We further analyze the topic and sentiment of news paragraphs, extract paragraph-level labels and inject them into our news HIN structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@1",
            "content": "V2 and R2: Topic Cues The topics and frequent topic switching in news articles often give away the stance and argument of authors.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 139,
            "end": 268,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@2",
            "content": "We train LDA to extract the topics in each political perspective detection corpus and use one node to represent each topic.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 270,
            "end": 392,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@3",
            "content": "We then encode the topic text with pretrained RoBERTa as node attributes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 394,
            "end": 466,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@4",
            "content": "We then use R2 to connect each paragraph node in V1 with its affiliated topic node in V2 with the help of Bert-Topic (Grootendorst, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 468,
            "end": 605,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@5",
            "content": "V3 and R3: Sentiment Cues The sentiment of news articles signal the authors' approval or denial, which helps identify their stances towards individuals and issues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 607,
            "end": 769,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@6",
            "content": "We use two nodes to represent positive and negative sentiment and we make their node attributes learnable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 771,
            "end": 876,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_49@7",
            "content": "We then conduct sentiment analysis (Wolf et al., 2020) to identify paragraph sentiment and use R3 to connect V1 with their corresponding sentiment nodes in V3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_49",
            "start": 878,
            "end": 1036,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_50@0",
            "content": "Syntactic Cues",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_50",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@0",
            "content": "Apart from semantic cues, syntactic information in news articles also contribute to the perspective analysis process (Dutta et al., 2022).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@1",
            "content": "In light of this, we analyze the tense of news paragraphs and whether it contains direct quotation and use them as paragraph-level labels in our constructed HIN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 139,
            "end": 299,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@2",
            "content": "V4 and R4: Tense Cues The tense of news paragraphs helps separate facts from opinions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 301,
            "end": 386,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@3",
            "content": "For example, simple past tense often indicates factual statements while simple future tense suggests opinions and projections that might not be factual.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 388,
            "end": 539,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@4",
            "content": "We use 17 nodes in V4 to represent 17 possible tenses in our constructed news HIN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 541,
            "end": 622,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@5",
            "content": "We use NLTK (Bird et al., 2009) to extract paragraph tenses and use R4 to connect paragraph nodes in V1 with V4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 624,
            "end": 735,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@6",
            "content": "V5 and R5: Quotation Cues It is common for authors to directly quote others' words in news articles, which helps to identify the basis of the author's argument.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 737,
            "end": 896,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@7",
            "content": "We use two nodes to differentiate between whether a news paragraph quotes someone or not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 898,
            "end": 986,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_51@8",
            "content": "Specifically, we identify quotation marks in news paragraphs and use R6 to connect V1 with V6 based on whether direct quotation is detected.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_51",
            "start": 988,
            "end": 1127,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_52@0",
            "content": "Entity Cues",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_52",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_53@0",
            "content": "V6 and R6: Entity Cues We follow previous works (Feng et al., 2021a;Hu et al., 2021) to use one node to represent each entity in the external knowledge graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_53",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_53@1",
            "content": "We adopt TransE (Bordes et al., 2013) to learn knowledge graph embeddings and use them as initial node features for V6.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_53",
            "start": 159,
            "end": 277,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_53@2",
            "content": "We then adopt Tagme (Ferragina and Scaiella, 2011) to align news paragraphs with their mentioned entities and use R6 to connect V1 with V6 correspondingly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_53",
            "start": 279,
            "end": 433,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_54@0",
            "content": "In this way, we obtain a heterogeneous information network for news articles that jointly models knowledge-enriched news content and diversified textual cues in news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_54",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_54@1",
            "content": "Our approach could be similarly extended to other textual cues and paragraph-level labels that would be helpful in political perspective detection and related tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_54",
            "start": 176,
            "end": 340,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_55@0",
            "content": "Learning and Optimization",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_55",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_56@0",
            "content": "Upon obtaining the news HINs, we adopt relational graph neural networks for representation learning and conduct political perspective detection as graph-level classification.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_56",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_56@1",
            "content": "Specifically, we follow Feng et al. (2021a) and use gated R-GCN to ensure a fair comparison and highlight the effectiveness of knowledge walks and textual cues.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_56",
            "start": 175,
            "end": 334,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_56@2",
            "content": "After L layers of gated R-GCN, we denote the learned node representations as v and obtain graph-level representation v g with three different aggregation strategies: Paragraph Average (PA), Cue Average (CA) and Global Average (GA): where V = 6 i=1 Vi represents the set of all nodes in our HIN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_56",
            "start": 336,
            "end": 629,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_56@3",
            "content": "We then transform the graph-level representation v g with a softmax layer and classify news articles into perspective labels:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_56",
            "start": 631,
            "end": 755,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_57@0",
            "content": "v g = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 1 |V1| v\u2208V1 v if Paragraph Average; 1 |V\u2212V1| v / \u2208V1 v if",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_57",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_58@0",
            "content": "\u0177 = sof tmax(W o \u2022 v g + b o )(10)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_58",
            "start": 0,
            "end": 33,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_59@0",
            "content": "where W o and b o are learnable parameters and \u0177 is our model's prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_59",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_59@1",
            "content": "The loss function of our method is as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_59",
            "start": 76,
            "end": 121,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_60@0",
            "content": "L = \u2212 Y i=1 y i log( \u0177i ) + \u03bb w\u2208\u03b8 w 2 (11)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_60",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_61@0",
            "content": "where Y is the number of stance labels, the onehot vector y = {y 1 , ..., y Y } denotes ground-truth annotation, \u03b8 is the set of learnable parameters and \u03bb is the regularization factor.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_61",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_62@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_62",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_63@0",
            "content": "Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_63",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_64@0",
            "content": "We make use of two real-world political perspective detection datasets SemEval (Kiesel et al., 2019) and Allsides (Li and Goldwasser, 2019), which are widely adopted in various previous works Goldwasser, 2019, 2021;Feng et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_64",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_64@1",
            "content": "We follow the same evaluation settings as in previous works so that our results are directly comparable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_64",
            "start": 236,
            "end": 339,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_64@2",
            "content": "Section B in the appendix provides more dataset details to facilitate reproduction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_64",
            "start": 341,
            "end": 423,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_65@0",
            "content": "Baselines",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_65",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_66@0",
            "content": "We compare KCD with the following competitive baselines and state-of-the-art methods:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_66",
            "start": 0,
            "end": 84,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_67@0",
            "content": "\u2022 CNN (Jiang et al., 2019) is the first-place solution in the SemEval 2019 Task 4 contest (Kiesel et al., 2019). It combines convolutional neural networks with Glove (Jiang et al., 2019) and ELMo (Peters et al., 2018) for political perspective detection on the SemEval dataset. \u2022 HLSTM (Yang et al., 2016) is short for hierarchical long short-term memory networks. Li and Goldwasser (2019) uses HLSTMs and different word embeddings for news bias detection. \u2022 HLSTM_Embed and HLSTM_Output (Li and Goldwasser, 2021) leverage entity information with masked entity models in addition to news content for political perspective detection. \u2022 Word2Vec (Mikolov et al., 2013) \u2022 MAN (Li and Goldwasser, 2021) incorporates social and linguistic information with pre-training tasks and conducts fine-tuning on the task of political perspective detection. \u2022 KGAP (Feng et al., 2021a), short for Knowledge Graph Augmented Political perspective detection, leverages knowledge graphs and graph neural networks for a knowledge-aware approach. We compare our gated R-GCN based approach with KGAP's gated R-GCN setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_67",
            "start": 0,
            "end": 1099,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_68@0",
            "content": "Implementation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_68",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_69@0",
            "content": "We implement our KCD framework with pytorch (Paszke et al., 2019), pytorch lightning (Falcon and The PyTorch Lightning team, 2019), pytorch geometric (Fey and Lenssen, 2019) and the transformers library (Wolf et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_69",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_69@1",
            "content": "We present our hyperparameter settings in Table 1 to facilitate reproduction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_69",
            "start": 224,
            "end": 300,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_69@2",
            "content": "We adhere to these settings throughout all experiments in the paper unless stated otherwise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_69",
            "start": 302,
            "end": 393,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_69@3",
            "content": "Our implementation is trained on a Titan X GPU with 12GB memory.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_69",
            "start": 395,
            "end": 458,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_69@4",
            "content": "We commit to make our code and data publicly available upon acceptance to facilitate reproduction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_69",
            "start": 460,
            "end": 557,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_70@0",
            "content": "Experiment Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_70",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_71@0",
            "content": "We present model performance on two benchmark datasets in Table 2, which demonstrates that",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_71",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_72@0",
            "content": "\u2022 KCD, especially with the PA aggregation strategy, consistently outperforms state-of-the-art methods on both benchmark datasets. \u2022 KGAP and KCD, which incorporate knowledge graphs, outperform other baselines. This indicates that external knowledge is essential in providing background information and political context to analyze ideological perspectives. \u2022 PA outperforms CA and GA on both datasets, which suggest the aggregation strategy is important and paragraph nodes should be the focus in our heterogeneous information networks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_72",
            "start": 0,
            "end": 535,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_73@0",
            "content": "In the following, we examine the effect of knowledge walks and textual cues in our approach.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_73",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_73@1",
            "content": "We also explore how our approach performs with limited data compared to baseline methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_73",
            "start": 93,
            "end": 181,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_74@0",
            "content": "Knowledge Walks Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_74",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_75@0",
            "content": "We propose knowledge walks, an approach to conduct multi-hop reasoning on knowledge graphs and inject them into textual representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_75",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_75@1",
            "content": "We study the effect of knowledge walk length and knowledge infusion strategies on our model's performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_75",
            "start": 137,
            "end": 242,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_75@2",
            "content": "Figure 3: Our approach's performance when the maximum length of knowledge walk generation is specified from 1 to 10 knowledge graph triples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_75",
            "start": 244,
            "end": 383,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_76@0",
            "content": "Knowledge Walks Length",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_76",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_77@0",
            "content": "Our proposed knowledge walks could be of any length, where shorter walks provide more condensed knowledge and longer walks provide more diverse knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_77",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_77@1",
            "content": "To examine the effect of knowledge walk length, we generate 5,088 3 knowledge walks of 1 to 10 triples and present model performance in Figure 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_77",
            "start": 155,
            "end": 299,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_77@2",
            "content": "It is illustrated that longer knowledge walks (8 or 9 for SemEval, 7 or 8 for Allsides) perform better than shorter ones, indicating the necessity of multi-hop knowledge reasoning in the task of political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_77",
            "start": 301,
            "end": 527,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_78@0",
            "content": "Knowledge Infusion Strategy",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_78",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_79@0",
            "content": "We propose a two-step approach to infuse multihop knowledge reasoning into textual representations of news articles:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_79",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_80@0",
            "content": "\u2022 First Aggregation: We firstly aggregate different generated knowledge walks based on semantic relevance in Equ. (5) and Equ. ( 6). \u2022 Second Aggregation: We then use multi-head attention to aggregate all paragraphs and knowledge representations with Equ. ( 7) and Equ. (8).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_80",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_81@0",
            "content": "To examine the effect of our knowledge infusion strategy, we substitute these two aggregation steps with different multi-head attention settings as well as max and average pooling.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_81",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_81@1",
            "content": "Results in Figure 4 demonstrate significant performance difference on the horizontal axis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_81",
            "start": 181,
            "end": 270,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_81@2",
            "content": "This suggests that our semantic relevance-based knowledge walks aggregation strategy in Equ.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_81",
            "start": 272,
            "end": 363,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_81@3",
            "content": "(5) and Equ. (6) successfully filters out irrelevant knowledge reasoning and contributes to model performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_81",
            "start": 365,
            "end": 474,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_81@4",
            "content": "Besides, according to the 3 so that there is a knowledge walk beginning with every possible (entity, relation) in the knowledge graph.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_81",
            "start": 476,
            "end": 609,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_81@5",
            "content": "vertical axis, our adopted multi-head attention in Equ. ( 7) and Equ. ( 8) is generally effective and does not rely on specific attention head settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_81",
            "start": 611,
            "end": 762,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_82@0",
            "content": "Textual Cue Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_82",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_83@0",
            "content": "We propose to leverage semantic, syntactic and entity textual cues as paragraph-level labels to leverage implicit indicators in news articles for political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_83",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_83@1",
            "content": "To examine the effectiveness of these textual cues, we randomly remove them with probability p and present model performance in Figure 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_83",
            "start": 179,
            "end": 315,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_83@2",
            "content": "It is illustrated that:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_83",
            "start": 317,
            "end": 339,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_84@0",
            "content": "\u2022 A performance boost is observed between 0%",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_84",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_85@0",
            "content": "and 100% for all five textual cues, suggesting the necessity of modeling implicit textual indicators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_85",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_85@1",
            "content": "Besides, adding only part of textual cues sometimes leads to a decrease in performance, which implies that incomplete cues may be counterproductive.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_85",
            "start": 102,
            "end": 249,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_86@0",
            "content": "\u2022 Among five different cues, entity and quotation cues contribute more to model performance than others. This suggests some implicit textual cues are more important than others in analyzing the ideological perspectives of news articles. \u2022 The effect of textual cues is larger on the dataset SemEval, which is significantly smaller than Allsides. This suggests that we alleviate the datahungry problem by introducing diversified textual cues as paragraph-level labels and contribute to model performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_86",
            "start": 0,
            "end": 502,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_87@0",
            "content": "Data Efficiency Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_87",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_88@0",
            "content": "As Li and Goldwasser (2021) point out, supervised data annotations could be difficult and expensive to obtain for the task of political perspective detection in news media.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_88",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_88@1",
            "content": "Our proposed knowledge walks and textual cues serve as additional information and might help mitigate this issue.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_88",
            "start": 173,
            "end": 285,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_88@2",
            "content": "To examine whether we have achieved this end, we train KCD, kGAP (Feng et al., 2021a) as well as various text models with reduced training sets of SemEval and Allsides.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_88",
            "start": 287,
            "end": 454,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_88@3",
            "content": "Results in Figure 6 demonstrate that",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_88",
            "start": 456,
            "end": 491,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_89@0",
            "content": "\u2022 KCD has better data efficiency and achieves steady performance with smaller training sets. This observation is especially salient on Allsides where the news articles are longer (Li and Goldwasser, 2021), thus more knowledge walks and textual cues could be extracted and incorporated to alleviate data dependence. \u2022 Both KCD and KGAP leverage external knowledge and are more robust to reduced datasets. Our approach further leverages textual cues and has better data deficiency. This suggests a solution to limited data could be incorporating information in addition to news content. \u2022 With only 10% training set, KCD outperforms all baselines by at least 5.68% and 9.71% in accuracy on two datasets. This suggests that our approach is simple, effective, and not data-hungry under limited data settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_89",
            "start": 0,
            "end": 803,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_90@0",
            "content": "Our proposed model has two minor limitations:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_90",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_91@0",
            "content": "\u2022 We propose to model news articles with heterogeneous information networks. This graph-based approach might not fit well with shorter news articles with only a few paragraphs. This issue might be addressed by using sentence nodes instead of paragraph nodes for shorter articles. \u2022 For very large knowledge graphs with many different types of relations, it might be hard for domain experts to help set p(r) for every knowledge graph relation. This issue might be addressed by only setting a larger p(r) for several important rs according to domain expert.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_91",
            "start": 0,
            "end": 554,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_92@0",
            "content": "We used the same datasets as in previous works Goldwasser, 2019, 2021;Feng et al., 2021a), namely SemEval (Kiesel et al., 2019) and Allsides (Li and Goldwasser, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_92",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_92@1",
            "content": "We follow the same 10-fold setting for SemEval and 3-fold setting for Allsides (Li and Goldwasser, 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_92",
            "start": 168,
            "end": 272,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_92@2",
            "content": "We use the exact same folds so that the results are directly comparable.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_92",
            "start": 274,
            "end": 345,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_92@3",
            "content": "A minor difference would be that we have to discard a few news articles on Allsides since their urls have expired and we could not retrieve their original news article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_92",
            "start": 347,
            "end": 514,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_92@4",
            "content": "We report the statistical information of SemEval and Allsides in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_92",
            "start": 516,
            "end": 588,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_93@0",
            "content": "C.1 Computational Resources",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_93",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_94@0",
            "content": "Our proposed approach has a total of 7.8M learnable parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_94",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_94@1",
            "content": "It takes approximately 0.7 and 1.6 GPU hours to train our approach on two datasets respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_94",
            "start": 64,
            "end": 159,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_94@2",
            "content": "We train our model on one Titan X GPU with 12GB memory.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_94",
            "start": 161,
            "end": 215,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_95@0",
            "content": "We run our approach with three different aggregation strategies five times and report the average accuracy and macro F1-score in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_95",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_95@1",
            "content": "For experiments in Section 4.5, 4.6 and 4.7, we do not have enough computational resources to run five times, thus we report the performance of a single run.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_95",
            "start": 138,
            "end": 294,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_96@0",
            "content": "We provide additional details about used scientific artifacts and specifically how we used them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_96",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_96@1",
            "content": "\u2022 NLTK (Bird et al., 2009): We use NLTK to extract the tense of news articles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_96",
            "start": 97,
            "end": 174,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_96@2",
            "content": "Specifically, we first use NLTK POS-tagger to process new paragraphs and attach speech tag to each word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_96",
            "start": 176,
            "end": 279,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_96@3",
            "content": "Then we align verb tags with NLTK tagset to identify the tense of paragraphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_96",
            "start": 281,
            "end": 357,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_97@0",
            "content": "\u2022 BertTopic (Grootendorst, 2020): We use Bert-Topic to mine the topics of news corpus. Specifically, we use BertTopic topic model to learn dataset-specific topic models. For SemEval we obtained 197 topics and for Allsides we obtained 1225 topics. Next, we predict topics for each news paragraph. Each topic consists of ten topic words with scores and we select the top five to serve as the news paragraph's topic. \u2022 Huggingface Transformers (Wolf et al., 2020):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_97",
            "start": 0,
            "end": 460,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_98@0",
            "content": "We use the pipeline module for sentiment analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_98",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_98@1",
            "content": "Specifically, we use the sentiment analysis API in the text classification pipeline to generate a sentiment label and score for news paragraphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_98",
            "start": 51,
            "end": 194,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_99@0",
            "content": "We then use the sentiment label as the sentiment cues for news paragraphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_99",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_100@0",
            "content": "\u2022 TagMe (Ferragina and Scaiella, 2011): We use TagMe to align news articles with entities in the knowledge graph. Specifically, we use TagMe to annotate named entities in news paragraphs and save the entities with a score higher than 0.1 for further alignment. We then calculate the similarity score between TagMe annotated entities and political knowledge graph entities. We recognize the entities with a score higher than 0.9 as entity cues in our constructed HIN. \u2022 Political knowledge graph (Feng et al., 2021a):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_100",
            "start": 0,
            "end": 515,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_101@0",
            "content": "We use the political knowledge graph collected in Feng et al. (2021a) for external knowledge in political perspective detection.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_101",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_102@0",
            "content": "\u2022 OpenKE (Han et al., 2018): We use OpenKE to train TransE (Bordes et al., 2013) knowledge graph embeddings for the political knowledge graph. Specifically, we set the TransE hidden size to 768 and train the model with other default hyperparameters in OpenKE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_102",
            "start": 0,
            "end": 258,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_103@0",
            "content": "Isabelle Augenstein, Tim Rockt\u00e4schel, Andreas Vlachos, and Kalina Bontcheva, 2016, Stance detection with bidirectional conditional encoding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_103",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_104@0",
            "content": "UNKNOWN, None, 2020, We can detect your bias: Predicting the political ideology of news articles, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_104",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_105@0",
            "content": "Gemma Bel-Enguix, Helena G\u00f3mez-Adorno, Alejandro Pimentel, Sergio-Luis Ojeda-Trueba, Brian Aguilar-Vizuet, Negation detection on mexican spanish tweets: The t-mexneg corpus, 2021, Applied Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_105",
            "start": 0,
            "end": 198,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_106@0",
            "content": "UNKNOWN, None, 2009, Natural language processing with Python: analyzing text with the natural language toolkit, Reilly Media, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_106",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_107@0",
            "content": "Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, Jamie Taylor, Freebase: a collaboratively created graph database for structuring human knowledge, 2008, Proceedings of the 2008 ACM SIG-MOD international conference on Management of data, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_107",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_108@0",
            "content": "Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko, Translating embeddings for modeling multirelational data, 2013, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_108",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_109@0",
            "content": "David Chang, Ivana Bala\u017eevi\u0107, Carl Allen, Daniel Chawla, Cynthia Brandt, Richard Taylor, Benchmark and best practices for biomedical knowledge graph embeddings, 2020, Proceedings of the conference. Association for Computational Linguistics. Meeting, NIH Public Access.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_109",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_110@0",
            "content": "Kareem Darwish, Peter Stefanov, Micha\u00ebl Aupetit, Preslav Nakov, Unsupervised user stance detection on twitter, 2020, Proceedings of the International AAAI Conference on Web and Social Media, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_110",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_111@0",
            "content": "UNKNOWN, None, 2018, Bert: Pre-training of deep bidirectional transformers for language understanding, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_111",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_112@0",
            "content": "Jiachen Du, Ruifeng Xu, Yulan He, Lin Gui, Stance classification with target-specific neural attention networks, 2017, International Joint Conferences on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_112",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_113@0",
            "content": "UNKNOWN, None, 2022, Semi-supervised stance detection of tweets via distant network supervision, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_113",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_114@0",
            "content": "UNKNOWN, None, 2019, William Falcon and The PyTorch Lightning team, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_114",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_115@0",
            "content": "UNKNOWN, None, 2010, Theory and applications of ontology: computer applications, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_115",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_116@0",
            "content": "UNKNOWN, None, , Xiaojun Chang, and Qinghua Zheng. 2021a. Knowledge graph augmented political perspective detection in news media, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_116",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_117@0",
            "content": "UNKNOWN, None, 2021, Legislator representation learning with social context and expert knowledge, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_117",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_118@0",
            "content": "Paolo Ferragina, Ugo Scaiella, Fast and accurate annotation of short texts with wikipedia pages, 2011, IEEE software, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_118",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_119@0",
            "content": "UNKNOWN, None, 2019-01, Fast graph representation learning with pytorch geometric, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_119",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_120@0",
            "content": "UNKNOWN, None, 2020, Bertopic: Leveraging bert and c-tf-idf to create easily interpretable topics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_120",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_121@0",
            "content": "Xu Han, Shulin Cao, Lv Xin, Yankai Lin, Zhiyuan Liu, Maosong Sun, Juanzi Li, Openke: An open toolkit for knowledge embedding, 2018, Proceedings of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_121",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_122@0",
            "content": "Sara Benjamin D Horne, Sibel Khedr,  Adali, Sampling the news producers: A large news and feature data set for the study of the complex media landscape, 2018, Twelfth International AAAI Conference on Web and Social Media, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_122",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_123@0",
            "content": "Linmei Hu, Tianchi Yang, Luhao Zhang, Wanjun Zhong, Duyu Tang, Chuan Shi, Nan Duan, Ming Zhou, Compare to the knowledge: Graph neural fake news detection with external knowledge, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_123",
            "start": 0,
            "end": 360,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_124@0",
            "content": "Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, Tiejun Zhao, Target-dependent twitter sentiment classification, 2011, Proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_124",
            "start": 0,
            "end": 231,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_125@0",
            "content": "Ye Jiang, Johann Petrak, Xingyi Song, Kalina Bontcheva, Diana Maynard, Team bertha von suttner at semeval-2019 task 4: Hyperpartisan news detection using elmo sentence representation convolutional network, 2019, Proceedings of the 13th International Workshop on Semantic Evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_125",
            "start": 0,
            "end": 283,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_126@0",
            "content": "Johannes Kiesel, Maria Mestre, Rishabh Shukla, Emmanuel Vincent, Payam Adineh, David Corney, Benno Stein, Martin Potthast, Semeval-2019 task 4: Hyperpartisan news detection, 2019, Proceedings of the 13th International Workshop on Semantic Evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_126",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_127@0",
            "content": "Chang Li, Dan Goldwasser, Encoding social information with graph convolutional networks forpolitical perspective detection in news media, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_127",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_128@0",
            "content": "Chang Li, Dan Goldwasser, Using social and linguistic information to adapt pretrained representations for political perspective identification, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_128",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_129@0",
            "content": "UNKNOWN, None, 2019, Roberta: A robustly optimized bert pretraining approach, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_129",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_130@0",
            "content": "UNKNOWN, None, 2021, Kelm: Knowledge enhanced pretrained language representations with message passing on hierarchical relational graphs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_130",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_131@0",
            "content": "Walid Magdy, Kareem Darwish, Norah Abokhodair, Afshin Rahimi, Timothy Baldwin, # isisisnotislam or# deportallmuslims? predicting unspoken views, 2016, Proceedings of the 8th ACM Conference on Web Science, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_131",
            "start": 0,
            "end": 205,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_132@0",
            "content": "UNKNOWN, None, 2020, Verb knowledge injection for multilingual event processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_132",
            "start": 0,
            "end": 81,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_133@0",
            "content": "UNKNOWN, None, 2021, Mixtureof-partitions: Infusing large biomedical knowledge graphs into bert, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_133",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_134@0",
            "content": "UNKNOWN, None, 2013, Efficient estimation of word representations in vector space, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_134",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_135@0",
            "content": "UNKNOWN, None, 2019, Enriching bert with knowledge graph embeddings for document classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_135",
            "start": 0,
            "end": 97,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_136@0",
            "content": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Pytorch: An imperative style, high-performance deep learning library, 2019, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_136",
            "start": 0,
            "end": 273,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_137@0",
            "content": "Jeffrey Pennington, Richard Socher, Christopher D Manning, Glove: Global vectors for word representation, 2014, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_137",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_138@0",
            "content": "UNKNOWN, None, 2018, Deep contextualized word representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_138",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_139@0",
            "content": "Robyn Speer, Joshua Chin, Catherine Havasi, Conceptnet 5.5: An open multilingual graph of general knowledge, 2017, Thirty-first AAAI conference on artificial intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_139",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_140@0",
            "content": "Peter Stefanov, Kareem Darwish, Atanas Atanasov, Preslav Nakov, Predicting the topical stance and political leaning of media using tweets, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_140",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_141@0",
            "content": "Gerhard Thomas Pellissier Tanon, Fabian Weikum,  Suchanek, Yago 4: A reason-able knowledge base, 2020, European Semantic Web Conference, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_141",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_142@0",
            "content": "Bo Wang, Maria Liakata, Arkaitz Zubiaga, Rob Procter, Tdparse: Multi-target-specific sentiment recognition on twitter, 2017, Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_142",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_143@0",
            "content": "Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhengyan Zhang, Zhiyuan Liu, Juanzi Li, Jian Tang, Kepler: A unified model for knowledge embedding and pre-trained language representation, 2021, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_143",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_144@0",
            "content": "UNKNOWN, None, 2021, Knowledge enhanced pretrained language models: A compreshensive survey, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_144",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_145@0",
            "content": "Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander Lhoest,  Rush, Transformers: State-of-the-art natural language processing, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_145",
            "start": 0,
            "end": 536,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_146@0",
            "content": "UNKNOWN, None, 2018, Cross-target stance classification with self-attention networks, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_146",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "440-ARR_v1_147@0",
            "content": "UNKNOWN, None, 2016, Hierarchical attention networks for document classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "440-ARR_v1_147",
            "start": 0,
            "end": 82,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_1",
            "tgt_ix": "440-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_1",
            "tgt_ix": "440-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_4",
            "tgt_ix": "440-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_5",
            "tgt_ix": "440-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_6",
            "tgt_ix": "440-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_3",
            "tgt_ix": "440-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_3",
            "tgt_ix": "440-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_3",
            "tgt_ix": "440-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_3",
            "tgt_ix": "440-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_3",
            "tgt_ix": "440-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_3",
            "tgt_ix": "440-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_8",
            "tgt_ix": "440-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_9",
            "tgt_ix": "440-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_9",
            "tgt_ix": "440-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_11",
            "tgt_ix": "440-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_11",
            "tgt_ix": "440-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_13",
            "tgt_ix": "440-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_14",
            "tgt_ix": "440-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_15",
            "tgt_ix": "440-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_11",
            "tgt_ix": "440-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_11",
            "tgt_ix": "440-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_11",
            "tgt_ix": "440-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_11",
            "tgt_ix": "440-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_12",
            "tgt_ix": "440-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_16",
            "tgt_ix": "440-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_18",
            "tgt_ix": "440-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_20",
            "tgt_ix": "440-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_21",
            "tgt_ix": "440-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_19",
            "tgt_ix": "440-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_19",
            "tgt_ix": "440-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_19",
            "tgt_ix": "440-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_19",
            "tgt_ix": "440-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_22",
            "tgt_ix": "440-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_24",
            "tgt_ix": "440-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_25",
            "tgt_ix": "440-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_26",
            "tgt_ix": "440-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_27",
            "tgt_ix": "440-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_28",
            "tgt_ix": "440-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_29",
            "tgt_ix": "440-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_31",
            "tgt_ix": "440-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_32",
            "tgt_ix": "440-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_33",
            "tgt_ix": "440-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_34",
            "tgt_ix": "440-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_35",
            "tgt_ix": "440-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_36",
            "tgt_ix": "440-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_37",
            "tgt_ix": "440-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_39",
            "tgt_ix": "440-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_40",
            "tgt_ix": "440-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_41",
            "tgt_ix": "440-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_42",
            "tgt_ix": "440-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_43",
            "tgt_ix": "440-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_44",
            "tgt_ix": "440-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_45",
            "tgt_ix": "440-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_46",
            "tgt_ix": "440-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_46",
            "tgt_ix": "440-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_47",
            "tgt_ix": "440-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_48",
            "tgt_ix": "440-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_48",
            "tgt_ix": "440-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_50",
            "tgt_ix": "440-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_50",
            "tgt_ix": "440-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_53",
            "tgt_ix": "440-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_52",
            "tgt_ix": "440-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_52",
            "tgt_ix": "440-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_52",
            "tgt_ix": "440-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_54",
            "tgt_ix": "440-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_56",
            "tgt_ix": "440-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_57",
            "tgt_ix": "440-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_58",
            "tgt_ix": "440-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_59",
            "tgt_ix": "440-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_60",
            "tgt_ix": "440-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_61",
            "tgt_ix": "440-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_63",
            "tgt_ix": "440-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_63",
            "tgt_ix": "440-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_64",
            "tgt_ix": "440-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_66",
            "tgt_ix": "440-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_65",
            "tgt_ix": "440-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_65",
            "tgt_ix": "440-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_65",
            "tgt_ix": "440-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_68",
            "tgt_ix": "440-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_68",
            "tgt_ix": "440-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_69",
            "tgt_ix": "440-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_71",
            "tgt_ix": "440-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_70",
            "tgt_ix": "440-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_70",
            "tgt_ix": "440-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_70",
            "tgt_ix": "440-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_70",
            "tgt_ix": "440-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_73",
            "tgt_ix": "440-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_74",
            "tgt_ix": "440-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_74",
            "tgt_ix": "440-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_75",
            "tgt_ix": "440-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_76",
            "tgt_ix": "440-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_76",
            "tgt_ix": "440-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_77",
            "tgt_ix": "440-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_79",
            "tgt_ix": "440-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_78",
            "tgt_ix": "440-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_78",
            "tgt_ix": "440-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_78",
            "tgt_ix": "440-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_78",
            "tgt_ix": "440-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_81",
            "tgt_ix": "440-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_83",
            "tgt_ix": "440-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_85",
            "tgt_ix": "440-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_82",
            "tgt_ix": "440-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_82",
            "tgt_ix": "440-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_82",
            "tgt_ix": "440-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_82",
            "tgt_ix": "440-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_82",
            "tgt_ix": "440-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_88",
            "tgt_ix": "440-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_90",
            "tgt_ix": "440-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_93",
            "tgt_ix": "440-ARR_v1_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_92",
            "tgt_ix": "440-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_94",
            "tgt_ix": "440-ARR_v1_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_96",
            "tgt_ix": "440-ARR_v1_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_98",
            "tgt_ix": "440-ARR_v1_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_99",
            "tgt_ix": "440-ARR_v1_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_101",
            "tgt_ix": "440-ARR_v1_102",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_102",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_95",
            "tgt_ix": "440-ARR_v1_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "440-ARR_v1_0",
            "tgt_ix": "440-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_1",
            "tgt_ix": "440-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_2",
            "tgt_ix": "440-ARR_v1_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_3",
            "tgt_ix": "440-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_4",
            "tgt_ix": "440-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_4",
            "tgt_ix": "440-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_4",
            "tgt_ix": "440-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_4",
            "tgt_ix": "440-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_4",
            "tgt_ix": "440-ARR_v1_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_5",
            "tgt_ix": "440-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_5",
            "tgt_ix": "440-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_5",
            "tgt_ix": "440-ARR_v1_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_5",
            "tgt_ix": "440-ARR_v1_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_5",
            "tgt_ix": "440-ARR_v1_5@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_5",
            "tgt_ix": "440-ARR_v1_5@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_6",
            "tgt_ix": "440-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_6",
            "tgt_ix": "440-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_6",
            "tgt_ix": "440-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_6",
            "tgt_ix": "440-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_6",
            "tgt_ix": "440-ARR_v1_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_7",
            "tgt_ix": "440-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_8",
            "tgt_ix": "440-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_9",
            "tgt_ix": "440-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_10",
            "tgt_ix": "440-ARR_v1_10@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_11",
            "tgt_ix": "440-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_12",
            "tgt_ix": "440-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_12",
            "tgt_ix": "440-ARR_v1_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_12",
            "tgt_ix": "440-ARR_v1_12@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_12",
            "tgt_ix": "440-ARR_v1_12@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_12",
            "tgt_ix": "440-ARR_v1_12@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_12",
            "tgt_ix": "440-ARR_v1_12@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_13",
            "tgt_ix": "440-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_14",
            "tgt_ix": "440-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_15",
            "tgt_ix": "440-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_16",
            "tgt_ix": "440-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_16",
            "tgt_ix": "440-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_16",
            "tgt_ix": "440-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_16",
            "tgt_ix": "440-ARR_v1_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_17",
            "tgt_ix": "440-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_18",
            "tgt_ix": "440-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_18",
            "tgt_ix": "440-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_18",
            "tgt_ix": "440-ARR_v1_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_18",
            "tgt_ix": "440-ARR_v1_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_18",
            "tgt_ix": "440-ARR_v1_18@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_19",
            "tgt_ix": "440-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_20",
            "tgt_ix": "440-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_20",
            "tgt_ix": "440-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_20",
            "tgt_ix": "440-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_21",
            "tgt_ix": "440-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_22",
            "tgt_ix": "440-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_22",
            "tgt_ix": "440-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_23",
            "tgt_ix": "440-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_24",
            "tgt_ix": "440-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_24",
            "tgt_ix": "440-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_25",
            "tgt_ix": "440-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_26",
            "tgt_ix": "440-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_26",
            "tgt_ix": "440-ARR_v1_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_26",
            "tgt_ix": "440-ARR_v1_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_27",
            "tgt_ix": "440-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_28",
            "tgt_ix": "440-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_29",
            "tgt_ix": "440-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_29",
            "tgt_ix": "440-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_30",
            "tgt_ix": "440-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_31",
            "tgt_ix": "440-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_31",
            "tgt_ix": "440-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_31",
            "tgt_ix": "440-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_32",
            "tgt_ix": "440-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_33",
            "tgt_ix": "440-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_34",
            "tgt_ix": "440-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_35",
            "tgt_ix": "440-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_36",
            "tgt_ix": "440-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_37",
            "tgt_ix": "440-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_38",
            "tgt_ix": "440-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_39",
            "tgt_ix": "440-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_39",
            "tgt_ix": "440-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_40",
            "tgt_ix": "440-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_41",
            "tgt_ix": "440-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_42",
            "tgt_ix": "440-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_43",
            "tgt_ix": "440-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_44",
            "tgt_ix": "440-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_45",
            "tgt_ix": "440-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_46",
            "tgt_ix": "440-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_47",
            "tgt_ix": "440-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_47",
            "tgt_ix": "440-ARR_v1_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_47",
            "tgt_ix": "440-ARR_v1_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_47",
            "tgt_ix": "440-ARR_v1_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_47",
            "tgt_ix": "440-ARR_v1_47@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_48",
            "tgt_ix": "440-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_49",
            "tgt_ix": "440-ARR_v1_49@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_50",
            "tgt_ix": "440-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_51",
            "tgt_ix": "440-ARR_v1_51@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_52",
            "tgt_ix": "440-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_53",
            "tgt_ix": "440-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_53",
            "tgt_ix": "440-ARR_v1_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_53",
            "tgt_ix": "440-ARR_v1_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_54",
            "tgt_ix": "440-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_54",
            "tgt_ix": "440-ARR_v1_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_55",
            "tgt_ix": "440-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_56",
            "tgt_ix": "440-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_56",
            "tgt_ix": "440-ARR_v1_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_56",
            "tgt_ix": "440-ARR_v1_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_56",
            "tgt_ix": "440-ARR_v1_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_57",
            "tgt_ix": "440-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_58",
            "tgt_ix": "440-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_59",
            "tgt_ix": "440-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_59",
            "tgt_ix": "440-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_60",
            "tgt_ix": "440-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_61",
            "tgt_ix": "440-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_62",
            "tgt_ix": "440-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_63",
            "tgt_ix": "440-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_64",
            "tgt_ix": "440-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_64",
            "tgt_ix": "440-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_64",
            "tgt_ix": "440-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_65",
            "tgt_ix": "440-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_66",
            "tgt_ix": "440-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_67",
            "tgt_ix": "440-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_68",
            "tgt_ix": "440-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_69",
            "tgt_ix": "440-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_69",
            "tgt_ix": "440-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_69",
            "tgt_ix": "440-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_69",
            "tgt_ix": "440-ARR_v1_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_69",
            "tgt_ix": "440-ARR_v1_69@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_70",
            "tgt_ix": "440-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_71",
            "tgt_ix": "440-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_72",
            "tgt_ix": "440-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_73",
            "tgt_ix": "440-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_73",
            "tgt_ix": "440-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_74",
            "tgt_ix": "440-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_75",
            "tgt_ix": "440-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_75",
            "tgt_ix": "440-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_75",
            "tgt_ix": "440-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_76",
            "tgt_ix": "440-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_77",
            "tgt_ix": "440-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_77",
            "tgt_ix": "440-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_77",
            "tgt_ix": "440-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_78",
            "tgt_ix": "440-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_79",
            "tgt_ix": "440-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_80",
            "tgt_ix": "440-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_81",
            "tgt_ix": "440-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_81",
            "tgt_ix": "440-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_81",
            "tgt_ix": "440-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_81",
            "tgt_ix": "440-ARR_v1_81@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_81",
            "tgt_ix": "440-ARR_v1_81@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_81",
            "tgt_ix": "440-ARR_v1_81@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_82",
            "tgt_ix": "440-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_83",
            "tgt_ix": "440-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_83",
            "tgt_ix": "440-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_83",
            "tgt_ix": "440-ARR_v1_83@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_84",
            "tgt_ix": "440-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_85",
            "tgt_ix": "440-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_85",
            "tgt_ix": "440-ARR_v1_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_86",
            "tgt_ix": "440-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_87",
            "tgt_ix": "440-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_88",
            "tgt_ix": "440-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_88",
            "tgt_ix": "440-ARR_v1_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_88",
            "tgt_ix": "440-ARR_v1_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_88",
            "tgt_ix": "440-ARR_v1_88@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_89",
            "tgt_ix": "440-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_90",
            "tgt_ix": "440-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_91",
            "tgt_ix": "440-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_92",
            "tgt_ix": "440-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_92",
            "tgt_ix": "440-ARR_v1_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_92",
            "tgt_ix": "440-ARR_v1_92@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_92",
            "tgt_ix": "440-ARR_v1_92@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_92",
            "tgt_ix": "440-ARR_v1_92@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_93",
            "tgt_ix": "440-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_94",
            "tgt_ix": "440-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_94",
            "tgt_ix": "440-ARR_v1_94@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_94",
            "tgt_ix": "440-ARR_v1_94@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_95",
            "tgt_ix": "440-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_95",
            "tgt_ix": "440-ARR_v1_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_96",
            "tgt_ix": "440-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_96",
            "tgt_ix": "440-ARR_v1_96@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_96",
            "tgt_ix": "440-ARR_v1_96@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_96",
            "tgt_ix": "440-ARR_v1_96@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_97",
            "tgt_ix": "440-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_98",
            "tgt_ix": "440-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_98",
            "tgt_ix": "440-ARR_v1_98@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_99",
            "tgt_ix": "440-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_100",
            "tgt_ix": "440-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_101",
            "tgt_ix": "440-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_102",
            "tgt_ix": "440-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_103",
            "tgt_ix": "440-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_104",
            "tgt_ix": "440-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_105",
            "tgt_ix": "440-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_106",
            "tgt_ix": "440-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_107",
            "tgt_ix": "440-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_108",
            "tgt_ix": "440-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_109",
            "tgt_ix": "440-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_110",
            "tgt_ix": "440-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_111",
            "tgt_ix": "440-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_112",
            "tgt_ix": "440-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_113",
            "tgt_ix": "440-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_114",
            "tgt_ix": "440-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_115",
            "tgt_ix": "440-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_116",
            "tgt_ix": "440-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_117",
            "tgt_ix": "440-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_118",
            "tgt_ix": "440-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_119",
            "tgt_ix": "440-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_120",
            "tgt_ix": "440-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_121",
            "tgt_ix": "440-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_122",
            "tgt_ix": "440-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_123",
            "tgt_ix": "440-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_124",
            "tgt_ix": "440-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_125",
            "tgt_ix": "440-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_126",
            "tgt_ix": "440-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_127",
            "tgt_ix": "440-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_128",
            "tgt_ix": "440-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_129",
            "tgt_ix": "440-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_130",
            "tgt_ix": "440-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_131",
            "tgt_ix": "440-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_132",
            "tgt_ix": "440-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_133",
            "tgt_ix": "440-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_134",
            "tgt_ix": "440-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_135",
            "tgt_ix": "440-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_136",
            "tgt_ix": "440-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_137",
            "tgt_ix": "440-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_138",
            "tgt_ix": "440-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_139",
            "tgt_ix": "440-ARR_v1_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_140",
            "tgt_ix": "440-ARR_v1_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_141",
            "tgt_ix": "440-ARR_v1_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_142",
            "tgt_ix": "440-ARR_v1_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_143",
            "tgt_ix": "440-ARR_v1_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_144",
            "tgt_ix": "440-ARR_v1_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_145",
            "tgt_ix": "440-ARR_v1_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_146",
            "tgt_ix": "440-ARR_v1_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "440-ARR_v1_147",
            "tgt_ix": "440-ARR_v1_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1449,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "440-ARR",
        "version": 1
    }
}