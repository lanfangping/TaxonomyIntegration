{
    "nodes": [
        {
            "ix": "141-ARR_v2_0",
            "content": "Deep Inductive Logic Reasoning for Multi-Hop Reading Comprehension",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_2",
            "content": "Multi-hop reading comprehension requires an ability to reason across multiple documents. On the one hand, deep learning approaches only implicitly encode query-related information into distributed embeddings which fail to uncover the discrete relational reasoning process to infer the correct answer. On the other hand, logic-based approaches provide interpretable rules to infer the target answer, but mostly work on structured data where entities and relations are well-defined. In this paper, we propose a deep-learning based inductive logic reasoning method that firstly extracts query-related (candidate-related) information, and then conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation. The reasoning process is accomplished via attentive memories with novel differentiable logic operators. To demonstrate the effectiveness of our model, we evaluate it on two reading comprehension datasets, namely WikiHop and MedHop.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "141-ARR_v2_4",
            "content": "Reasoning has been extensively studied in the structured domain, e.g., knowledge base completion which infers missing facts given background entities and relations. However, when the background knowledge is expressed in natural languages, as shown in the multi-hop reading comprehension problem with triplet-form questions (Welbl et al., 2018), it becomes difficult to conduct complex reasoning because the entities and relations are not explicitly labeled in the documents. For example, consider the question \"country(Moonhole, ?)\", given the following documents:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_5",
            "content": "\"Moonhole is a private community on the island of Bequia. Moonhole was founded by Thomas and Gladys Johnston in the 1960s.\" \"Gladys Johnston was born in United States.\"",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_6",
            "content": "\"Bequia is an island and is part of the country of Saint Vincent and the Grenadines\"",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_7",
            "content": "In this example, the underlined entities are used to infer the correct answer, i.e., \"country(Moonhole, Saint Vincent and the Grenadines)\", but are not explicitly annotated for relational reasoning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_8",
            "content": "Deep neural networks (DNNs) for multi-hop reading comprehension (RC) can be summarized into following three categories. 1) Memory-based models Zhuang and Wang, 2019) that produce queryaware context representations. 2) Graph-based approaches (Song et al., 2018;De Cao et al., 2019) that use graph neural networks to propagate information based on pre-constructed entity (context) graphs. 3) Neural Module networks (Andreas et al., 2016) that decompose the question into a series of action modules Gupta et al., 2020). However, DNNs only implicitly encode relevant contexts and fail to explicitly uncover the underlying relational compositions for complex inference. For instance, in the above example, DNNs may encode Bequia and Gladys Johnson into 1-hop features, given the fact that both entities co-occur with the query Moonhole. As a result, the model may predict United States by linking it with Gladys Johnson instead of the correct answer Saint Vincent and the Grenadines. In contrast, human beings would easily produce the correct answer given the knowledge \"if A is in B and B is part of country C, then A is in country C\" and by examining the relations between each entity pair co-occurred in the context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_9",
            "content": "Inductive logic programming (ILP) (Muggleton, 1991) aligns with human reasoning by inducing interpretable rules to entail positive but not negative examples. To answer the previous query, ILP could generate a rule as located_in(X, Z) \u2227 country(Z, Y ) \u21d2 country(X, Y ). Combining deep learning with ILP is a promising direction to benefit from both worlds (Evans and Grefenstette, 2018;Dong et al., 2019). Deep logic models have been proposed for structured knowledge base completion (Minervini et al., 2017(Minervini et al., , 2020Yang and Song, 2020;Yang et al., 2017). However, it becomes much more challenging when dealing with natural language inputs, as in the case of multi-hop reading comprehension. Weber et al. (2019) proposed to combine a symbolic reasoner: prolog, with weak unifications based on distributed embeddings as a backwardchaining theorem prover to induce feasible rules for multi-hop reasoning. However, their work relies on the degree of precision for pre-extracted NERs and is limited by the number of rule templates.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_10",
            "content": "To address the aforementioned limitations, we propose a novel end-to-end integration of deep learning and logic reasoning termed Deep Inductive Logic Reasoning (DILR). It consists of two components: 1) a hierarchical attentive reader that filters query-related and candidate-related information from given documents, and 2) a multihop reasoner that conducts inductive logic reasoning by attentively selecting proper predicates to form candidate rules and refines them upon given examples. We introduce novel differentiable logic operators combined with attention mechanisms for smooth back-propagation. Compared to existing deep logic models, we build connections between raw text inputs and the symbolic domain by mapping high-level semantic representations to logic predicates and instantiating logic variables with neural representations to conduct relational reasoning. We also parameterize the entire process for end-to-end differentiable learning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_11",
            "content": "The contributions of this work include: 1) We introduce a novel smooth connection between deep representation learning with logic reasoning by associating distributed representations with discrete logic predicates and their probabilistic evaluations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_12",
            "content": "2) We propose deep-learning-based inductive logic programming via attentive memories and differentiable logic operators for the task of multi-hop reading comprehension considering the number of reasoning steps. 3) We provide comprehensive evaluations of our model on two benchmark datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_13",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "141-ARR_v2_14",
            "content": "Multi-Hop Reading Comprehension Recent works for multi-hop RC include memory-based methods which apply attentions to iteratively update query and context representations considering their interactions (Dhingra et al., 2018;Clark and Gardner, 2018;Zhuang and Wang, 2019;. To explicitly incorporate entity connections, De Cao et al. (2019), Ding et al. (2019), Qiu et al. (2019), Tang et al. (2020), Song et al. (2018) and Tu et al. (2019) proposed to build entity graphs and apply Graph Neural Networks for information propagation. Kundu et al. (2019) formalized reasoning as a path-finding problem with neural encoding to rank candidate paths. Path modeling was also adopted in using pointer networks. However, these approaches only focus on local information without the ability to generalize, and some of them rely on off-the-shelf NER tools. Dhingra et al. (2020) proposed to convert texts into a virtual knowledge base for retrieval using a pre-constructed entity database. Another research direction is to decompose target questions into subquestions (Min et al., 2019) or sub-modules parameterized with neural module networks Gupta et al., 2020;Chen et al., 2020) which also fail to explicitly uncover the underlying logic for reasoning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_15",
            "content": "Deep Learning with Logic Reasoning Neurosymbolic learning aims to integrate deep learning's ability on dealing with uncertainty and logic programming's ability on reasoning. Deep neural networks have been used to parameterize discrete logic operators and logic atoms (Fran\u00e7a et al., 2014;Hu et al., 2016;Manhaeve et al., 2018;Xu et al., 2018;Li and Srikumar, 2019;Wu et al., 2020) given the logic rules. A more challenging direction is inductive logic programming that automatically learns rules through representation learning and differentiable backpropagation (Evans and Grefenstette, 2018;Dong et al., 2019;Yang and Song, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_16",
            "content": "Neuro-symbolic learning has been applied to knowledge-base completion through logic embeddings (Guo et al., 2016), tensor operations (Cohen, 2016;, adversarial learning (Minervini et al., 2017), variational learning (Qu and Tang, 2019) or attentions (Yang and Song, 2020). Differentiable theorem proving has also been proposed with weak unifications and backward chaining Campero et al., 2018;Minervini et al., 2020). However, unlike multi-hop RC, knowledge-base completion only takes structured inputs without the need to address language ambiguity. The most related work to ours is NLProlog (Weber et al., 2019), a neural theorem prover for multi-hop RC by converting language utterances to distributed embeddings. However, NLProlog relies on a NER tool to extract entities and its expressiveness is limited by the number of rule templates.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_17",
            "content": "Background",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "141-ARR_v2_18",
            "content": "We focus on multi-hop reading comprehension tasks containing explicit query types which align with the standard ILP setting. Formally, for each RC problem, we are given a set of documents C = {c 1 , ..., c K }, a structured query in the form of a relational triplet (s, q, ?), where s denotes the subject of the relation q, and a list of candidate answers A = {a 1 , ..., a n }. The task is to select an answer a \u2208 A such that q(s, a) is satisfied, i.e., a is the object of relation q given the subject s. For example, country(M oonhole, ?) is a query asking for the country where Moonhole is located. This task could be converted into an ILP problem with the formal definition as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_19",
            "content": "Definition 3.1 (Inductive Logic Programming). Given a logic theory B representing the background knowledge (facts), a set of positive examples E + and a set of negative examples E \u2212 , an ILP system aims to derive a hypothesis H which entails all the positive and none of the negative examples:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_20",
            "content": "B \u2227 H |= \u03b3 for \u03b3 \u2208 E + . B \u2227 H \u0338 |= \u03b3 for \u03b3 \u2208 E \u2212 .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_21",
            "content": "The hypothesis H is a logic program consisting of definite clauses b 1 \u2227 ... \u2227 b N \u21d2 h where b 1 , ..., b N and h are logic atoms. The LHS of \"\u21d2\" is the clause body and h is the head. An atom is composed of a predicate and its arguments, e.g., h = located_in(X, Y ) with predicate \"located_in\" and arguments X, Y . A ground atom is obtained by instantiating variables in the arguments with constants, e.g., X = \"US\". We use \u00b5(\u2022) to denote the value of an atom or a clause. For smooth optimization, we assign \u00b5(\u2022) \u2208 [0, 1] which indicates the probability of the atom or clause being true.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_22",
            "content": "For multi-hop reading comprehension, we treat the query relation q(X, Y ) as the head atom of the clauses to be induced. The correct answer a + i from each problem forms the set of positive examples",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_23",
            "content": "E + ={q(s i , a + i )} N + i=1 ,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_24",
            "content": "and the incorrect answer a \u2212 i forms the set of negative examples",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_25",
            "content": "E \u2212 ={q(s i , a \u2212 i )} N \u2212 i=1 .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_26",
            "content": "Here we use lower cases: s i , a + i , a \u2212 i to represent constants and upper cases: X, Y to represent variables. The predicates in the logic domain correspond to pairwise relations between two entities 1 . To differentiate the number of inference steps, we define a l-hop reasoning clause as F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 )\u21d2r(X 0 , X l+1 ) with l denoting the number of extra arguments as bridging entities in the rule body except those in the head atom. Here r denotes a predicate, i.e., a relation between X 0 and X l+1 . Each subclause F t (X t , X t+1 ) can be one or a conjunction (\u2227) of 2-ary atoms taking only X t and X t+1 as arguments, e.g.,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_27",
            "content": "F t (X t , X t+1 ) = r 1 (X t , X t+1 ) \u2227 r 2 (X t , X t+1 ).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_28",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "141-ARR_v2_29",
            "content": "Overall, DILR simulates a multi-hop reasoning process considering different number of inference steps. It is an end-to-end framework consisting of two components: a Hierarchical Attentive Reader and a Multi-hop Reasoner. The attentive reader learns to select relevant information from the given documents to produce query-aware, candidateaware and bridging entity representations. These representations are passed to the multi-hop reasoner to instantiate logic atoms in order to generate and evaluate clauses that are relevant to the query relation. The multi-hop reasoner conducts rule induction via attentive memories that softly select atoms to form new clauses and novel differentiable logic operators that produce probabilistic values for generated clauses. The final loss can be backpropagated smoothly to update the attentive reader for more accurate selections. Next, we illustrate each component with more details.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_30",
            "content": "Hierarchical Attentive Reader",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "141-ARR_v2_31",
            "content": "To avoid inevitable errors brought by off-the-shelf NER tools for named entity extraction, we propose to extract relevant information using an attentive reader. Since multiple documents (contexts) are involved for each question, we design a 2-level hierarchical attention network to progressively filter token-level and context-level information. Specifically, the token-level attentions aim to select lhop (l = 0, ..., L) relevant entities in each context. Then the context-level attentions produce the final representations by softly attending to each context considering different number of reasoning hops.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_32",
            "content": "Token-Level Attention",
            "ntype": "title",
            "meta": {
                "section": "4.1.1"
            }
        },
        {
            "ix": "141-ARR_v2_33",
            "content": "Given a query subject s with n s tokens, a candidate a with n a tokens, and a context c of length n c , we denote by S \u2208 R ns\u00d7D , A \u2208 R na\u00d7D and C \u2208 R nc\u00d7D their word features after a biGRU layer, respectively. For multi-hop reasoning, we use different attentions for finding or relocating target tokens in each context, inspired by (Gupta et al., 2020). Firstly, a subject-to-context attention is adopted to find similar tokens as the subject in each context:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_34",
            "content": "B s ij = w \u22a4 s [S i ; C j ; S i \u2022 C j ]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_35",
            "content": "where w s is a learnable transformation vector and [; ] denotes concatenations. We obtain the normalized similarity score \u03b1 s ij between the i-th token in the subject and the j-th token in the context via a softmax operation on each row of B s . A subject-aware (0-hop) context representation is produced as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_36",
            "content": "h s = nc j=1 \u1fb1s j C j , with \u1fb1s j = ns i=1 \u03b1 s ij \u03b2 s i ,(1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_37",
            "content": "where \u03b2 s i weighs the contribution of each subject token via a self-attention: \u03b2 s = softmax( w\u22a4 s S + b s ). Similarly, we produce an attention score \u03b1 a ij for the j-th context token w.r.t. the i-th candidate token and a candidate-aware context representation h a . We denote by s = \u03b2 s S, and a = \u03b2 a A the feature representation of the query subject and the candidate entity, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_38",
            "content": "For (l + 1)-hop reasoning (l \u2265 0), it is desired to relocate to intermediate (bridging) entities that are related to the l-hop entities. Hence, we adopt context-to-context attentions",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_39",
            "content": "B l+1 ij = w \u22a4 l [C i + h l ; C j ; (C i + h l )\u2022C j ]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_40",
            "content": "given the l-hop representation h l where h 0 = h s . We use \u03b1 l+1 ij to denote a normalized attention score between the i-th and the j-th context tokens after applying a softmax operator over each row of B l+1 . With \u1fb10 j = \u1fb1s j , the (l + 1)-hop bridging context representation becomes",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_41",
            "content": "h l+1 = nc j=1 \u1fb1l+1 j C j , with \u1fb1l+1 j = nc i=1 \u03b1 l+1 ij \u1fb1l i . (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_42",
            "content": "Context-Level Attention",
            "ntype": "title",
            "meta": {
                "section": "4.1.2"
            }
        },
        {
            "ix": "141-ARR_v2_43",
            "content": "With multiple contexts (documents) available, we use a context-level attention to produce the final l-hop feature representations. When l = 0, the model softly attends to each context to produce context-attended subject representation as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_44",
            "content": "h s = K k=1 \u03b3s k h s,k ,(3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_45",
            "content": "where \u03b3s k is the attention weight of context c k obtained by normalizing over a score vector \u03b3 s",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_46",
            "content": "r 1 (s, a) r M (s, a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 1 k , a) r M (c 1 k , a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 2 k , a) r M (c 2 k , a) r 1 (c 1 k , c 2 k ) r M (c 1 k , c 2 k ) r 0 1 (s, a) r 0 M0 (s, a) r 1 1 (s, a) r 1 M1 (s, a) r 2 1 (s, a) r 2 M2 (s, a) c 1 1 c 1 K c 1 1 c 1 K q(s, a) 0-hop 1-hop 2-hop c 2 1 c 2 K Figure 1:",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_47",
            "content": "An example of multi-hop ILP. The existential predicates r 1 , ..., r M are used to define invented predicates r l 1 , ..., r l M l through attentions. The invented predicates will produce the final clauses to define q. with entries",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_48",
            "content": "\u03b3 s k = v \u22a4 s [s; h s,k ; s \u2022 h s,k ].",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_49",
            "content": "Here h s,k is the subject-aware context representation computed in (1) corresponding to the k-th context c k . v s is a trainable transformation vector. The final subject representation is produced as hs = W s [s; h s ; s \u2022 h s ] incorporating both original features and attended information. Similar procedure applies to each candidate entity to produce ha . We treat hs and ha as 0-hop subject and candidate representations, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_50",
            "content": "When l > 0, the context-level attention aims to produce the probability of each context being chosen as a bridging entity using",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_51",
            "content": "p l k = \u03c3(v \u22a4 l [ hs ; h l k ; hs \u2022 h l k ]),(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_52",
            "content": "where \u03c3(\u2022) is the sigmoid function, and h l k is the l-hop intermediate entity representation for context c k \u2208 C computed using (2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_53",
            "content": "Multi-Hop Reasoner",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "141-ARR_v2_54",
            "content": "The multi-hop reasoner aims to conduct complex reasoning by first generating probable logic clauses and then evaluating each clause by instantiating the variables with relevant contexts obtained from the attentive reader. The clause generation process is parameterized by attentive memories which compute the probability of selecting each atom to form a relevant clause to entail the query relation. An illustration of the procedure is shown in Figure 1 and is elaborated in the following sub-section. The clause evaluation process is then to instantiate variables in each atom with constants such as query subjects, candidate entities or bridging entities. The outputs from the attentive reader, i.e., hs , ha and {h l k }'s (l > 0), can be used as feature representations for these constants to compute the atom scores for clause evaluation and updates.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_55",
            "content": "Clause Generation",
            "ntype": "title",
            "meta": {
                "section": "4.2.1"
            }
        },
        {
            "ix": "141-ARR_v2_56",
            "content": "A definite clause is composed of atoms defined over relational predicates. Since there are no explicit relations given in this task, we pre-define a fixed set of relations for each corpus, named as existential predicates: P E ={r 1 , ..., r M }, e.g., \"located_in\", \"next_to\". For expressiveness, we further create a set of invented predicates P I =\u222a L l=0 P l I defined from the existential predicates, inspired by (Evans and Grefenstette, 2018). Specifically, P l I = {r l 1 , ..., r l M l } consists of invented predicates r l m defined using l-hop reasoning clauses F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 ) \u21d2 r l m (X 0 , X l+1 ). For example, located_in(X 0 , X 1 ) \u2227 next_to(X 1 , X 2 ) \u21d2 outside(X 0 , X 2 ) defines a 1-hop invented predicate \"outside\". Here L is the maximum hop number. The final clauses defining the query relation will be produced by learning to select relevant invented predicates, e.g., r",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_57",
            "content": "l 1 i (X, Y ) \u2227 ... \u2227 r ln j (X, Y ) \u21d2 q(X, Y ) with 0 \u2264 l 1 \u2264 ... \u2264 l n \u2264 L.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_58",
            "content": "The number of actual inference steps l n to answer q is flexibly decided by the model itself, which will be discussed later.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_59",
            "content": "The clause generation process is divided into two stages: 1) to generate clauses defining invented predicates using only the existential predicates, and 2) to generate final clauses defining query relation q using only the invented predicates. To allow for smooth optimization, we parameterize both stages by computing an attention weight for each predicate indicating its probability to appear in the clause body. Specifically, we assign each predicate a learnable embedding to indicate its semantics. Let U \u2208 R D\u00d7M denote the embedding matrix for M existential predicates and U l \u2208 R D\u00d7M l (l \u2208 {0, 1, ..., L}) denote the embedding matrix for l-hop invented predicates. In the first stage, we use attentive memories to generate",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_60",
            "content": "S l t = sparsemax((W l t U l t ) \u22a4 (W l b U)), (5) U l t+1 = U l t + S l t \u2022 (W l v U),(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_61",
            "content": "where U l 0 = U l , and W l t and W l b are transformation matrices for invented predicates (queries) and existential predicates (keys), respectively. We use sparsemax, a sparse version of softmax (Martins and Astudillo, 2016), to select only a small number of predicates. Intuitively, to learn to define a l-hop invented predicate r l m , ( 5) and ( 6) sequentially produce F t (X t , X t+1 ) at each step t \u2208 {0, ..., l} to form the clause body by attending over all the existential predicates with attention weight S l t . For example, when l = 1, (5) first attends to the existential predicate r i to generate F 0 (X 0 , X 1 ) = r i (X 0 , X 1 ) at step t = 0, and then attends to another predicate r j to generate F 1 (X 1 , X 2 ) = r j (X 1 , X 2 ) at step t = 1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_62",
            "content": "The resulting clause r i (X 0 , X 1 ) \u2227 r j (X 1 , X 2 ) \u21d2 r 1 m (X 0 , X 2 ) defines the invented predicate r 1 m . In the second stage, we produce H final clauses taking invented predicates to define the target atom q(X, Y ). Given an embedding u q \u2208 R D for the target relation q, we use a multi-head attention mechanism to compute a probability distribution s h over all the invented predicates for each head h \u2208 {1, ..., H} to produce the h-th final clause:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_63",
            "content": "s h =sparsemax{(W h q u q ) \u22a4 (W h e [U 0 ;...;U L ])},(7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_64",
            "content": "where s h is a sparse selective distribution over P I = {r 0 1 , ..., r L M L }. For example, if s h selects r 0 1 and r 1 2 , the final clause becomes r 0 1 (X, Y ) \u2227 r 1 2 (X, Y ) \u21d2 q(X, Y ), which involves at most 1 inference step because r 1 2 is a 1-hop invented predicate. This completes the recursive rule generation step with multi-hop inference. To this end, we generate H clauses that can be used to define q(X, Y ).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_65",
            "content": "Clause Evaluation",
            "ntype": "title",
            "meta": {
                "section": "4.2.2"
            }
        },
        {
            "ix": "141-ARR_v2_66",
            "content": "Instantiation The clauses generated using the attentive memories need to be tested and refined against the given positive and negative examples, known as learning from entailment that tries to maximize the truth probabilities of positive examples and minimize those of negative examples. The positive examples correspond to q(s, a) and the negative examples correspond to {q(s, a \u2212 )}'s, where s, a and a \u2212 refers to the query subject, correct answer and incorrect candidate, respectively. To obtain the truth probabilities of these atoms, we first instantiate the variables for each generated clause with constant contexts, e.g., X = s and Y = a (or Y = a \u2212 ) in q(X, Y ). The bridging variables X 1 , ..., X l are instantiated using the bridging contexts selected via the attentive reader as introduced in 4.1. Specifically, to instantiate each X l , we pick top-K contexts (documents) {c l 1 , ..., c l K } \u2286 C, namely X l = c l k , 1 \u2264 k \u2264 K with highest probabilities according to p l k computed via (4). Neural Logic Operator Given a definite clause b 1 \u2227 ... \u2227 b N \u21d2 h consisting of grounded atoms (e.g., b 1 = r 1 (s, a)), we could obtain the value for its head atom as \u00b5(h) = \u00b5(b 1 \u2227 ... \u2227 b N ). To compute the RHS involving logic operators (\u2227, \u2228), T-norm (Klement et al., 2013) is usually adopted:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_67",
            "content": "T : [0, 1] \u00d7 [0, 1] \u2192 [0, 1]. For example, mini- mum t-norm defines T \u2227 (\u00b5 1 , \u00b5 2 ) = min(\u00b5 1 , \u00b5 2 ), T \u2228 (\u00b5 1 , \u00b5 2 ) = max(\u00b5 1 , \u00b5 2 ). Product t-norm de- fines T \u2227 (\u00b5 1 , \u00b5 2 ) = \u00b5 1 \u2022 \u00b5 2 , T \u2228 (\u00b5 1 , \u00b5 2 ) = 1 \u2212 (1 \u2212 \u00b5 1 )\u2022(1\u2212\u00b5 2 ).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_68",
            "content": "Here \u00b5 1 , \u00b5 2 \u2208 [0, 1] refer to the value for the body atoms. However, minimum t-norm is prone to learning plateau because the gradient only flows through one of the inputs. Product t-norm is less stable and is prone to exponential decay when the number of atoms in the clause grows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_69",
            "content": "To address these limitations, we propose a novel neural logic operator G defined as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_70",
            "content": "G \u2228 (\u00b5 1 , ..., \u00b5 N )=1\u2212exp N n=1 log(1 \u2212 \u00b5 n + \u03f5) 1 N , G \u2227 (\u00b5 1 , ..., \u00b5 N )=exp N n=1 log(\u00b5 n + \u03f5) 1 N , (8",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_71",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_72",
            "content": "where \u00b5 1 , ..., \u00b5 N \u2208 [0, 1] refer to the probabilistic values of all the atoms in the conjunctive (\u2227) or disjunctive (\u2228) clause. \u03f5 is a small value to guarantee the validity for logarithm. The operator G has the following property that is ideal for logic semantics. 1) , where min refers to the index of the minimum value among {\u00b5 1 , ..., \u00b5 N }.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_73",
            "content": "Proposition 1. When \u2200\u00b5 n \u2192 1 with 1 \u2264 n \u2264 N , G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2192 1, aligning with logic \"AND\". When \u2203\u00b5 n \u2192 1, G \u2228 (\u00b5 1 , ..., \u00b5 N ) \u2192 1, aligning with logic \"OR\". Proposition 2. 0 \u2264 G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2212 \u00b5 min \u2264 (N 1/(1\u2212N ) \u2212 N N/(1\u2212N ) )( n\u0338 =min \u00b5 N ) 1/(N \u2212",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_74",
            "content": "Proof.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_75",
            "content": "G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2212 \u00b5 min = exp N n=1 log(\u00b5 n + \u03f5) 1/N \u2212 \u00b5 min \u2248 N n=1 \u00b5 1/N n \u2212 \u00b5 min . (9",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_76",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_77",
            "content": "Without loss of generality, assume the minimum value is \u00b5 min = \u00b5 1 . By fixing \u00b5 2 , ..., \u00b5 N as constants, we obtain the gradient for (9) w.r.t. \u00b5 1 as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_78",
            "content": "1 N \u00b5 (1\u2212N )/N 1 N n=2 \u00b5 1/N n \u2212 1.(10)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_79",
            "content": "(9) obtains its maximum value when (10) equals 0, resulting in",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_80",
            "content": "\u00b5 1 = N N/(1\u2212N ) N n=2 \u00b5 1/(N \u22121) n . (11",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_81",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_82",
            "content": "By replacing \u00b5 min in ( 9) with ( 11), we have",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_83",
            "content": "G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2212 \u00b5 min \u2264 N 1/(1\u2212N ) N n=2 \u00b5 1/N (N \u22121)+1/N n \u2212N N/(1\u2212N ) N n=2 \u00b5 1/(N \u22121) n = (N 1/(1\u2212N ) \u2212 N N/(1\u2212N ) ) N n=2 \u00b5 1/(N \u22121) n .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_84",
            "content": "This completes the proof.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_85",
            "content": "In other words, the difference between G \u2227 and \u00b5 min is bounded. When N = 2, the RHS of the inequality equals to 1/4 \u2022 \u00b5 n\u0338 =min , which makes G \u2227 closer to \u00b5 min when \u00b5 n\u0338 =min is smaller. This formulation results in a more stable and smooth gradient flow compared to minimum t-norm. Moreover, It avoids exponential decay in the output when N > 1. It also facilitates neural learning when the exact clause is parameterized with attention scores.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_86",
            "content": "Evaluation With the neural logic operator defined above, the value for the head atom can be inferred once the value for each body atom is given. For grounded atoms over existential predicates, e.g., r m (s, a), we directly generate its value using a relational network F : R d \u00d7 R d \u2192 R M that takes the features of two constant arguments as input to produce a probability distribution over all the existential predicates r 1 , ..., r M :",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_87",
            "content": "F( hs , ha ) = softmax(W r tanh[ hs ; ha ; hs \u2212 ha ; hs \u2022 ha ]),",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_88",
            "content": "where \u00b5(r m (s, a)) equals the m-th entry of F( hs , ha ), and hs and ha are the outputs from the attentive reader. Similarly, h l k can be regarded as the feature of c l k generated from the attentive reader which is used to compute atom values with bridging entities, e.g., \u00b5(r m (s, c l k )). For l-hop grounded atoms over invented predicates {r l 1 (s, a), ..., r l M l (s, a)}, we compute their values according to the value of the clause body that defines them, e.g., \u00b5(F 0 (s, c 1 k )\u2227...\u2227F l (c l k , a)) using neural logic operators:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_89",
            "content": "\u00b5 l = max z\u2208Z l exp l t=0 S l t log(\u00b5 (zt,z t+1 ) + \u03f5) 1 (l+1)(12)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_90",
            "content": "Here \u00b5 l = [\u00b5(r l 1 (s, a)), ..., \u00b5(r l M l (s, a))] \u22a4 denotes the vector of the atom values formed by those l-hop invented predicates. We denote by Z l = {(s, c 1 k , ..., c l k , a)} 1\u2264k\u2264K the set for all possible instantiations for l-hop reasoning and denote by z t the t-th constant of z \u2208 Z l . \u00b5 (zt,z t+1 ) = [\u00b5(r 1 (z t , z t+1 )), ..., \u00b5(r M (z t , z t+1 ))] \u22a4 is a vector of values for grounded atoms over existential predicates. Thus, exp(\u2022) gives a neural approximation of logic conjunctions as shown in (8) over {F t (z t , z t+1 )} 0\u2264t\u2264l , each of which is a sparse selection of existential predicates using S l t . We use a max operator to generate the maximum score over all possible instantiations in Z l to represent the final truth probability of each invented predicate. Intuitively, a relation between two entities should be satisfied as long as there is at least one instantiation that follows the rule. Also note that (12) has the effect that when S l t [i, j] \u2248 0, the corresponding predicate r j will have little effect on the value of its head r l i , which is in contrast to existing T-norms. The final value for q(s, a) is computed via",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_91",
            "content": "\u00b5(q(s, a))= max 1\u2264i\u2264H exp s i log([\u00b5 0 ; ...; \u00b5 L ] + \u03f5) ,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_92",
            "content": "which selects the maximum score over H final clauses that define q(s, a). We use the crossentropy loss over \u00b5(q(s, a)) as the final objective to train the entire model (except the word embeddings which are kept fixed) in an end-to-end manner. Here we organize the dataset according to subject-candidate pairs: (s, a). We associate the ground-truth label y = 1 with (s, a) if a is the correct answer, otherwise, y = 0.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_93",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "141-ARR_v2_94",
            "content": "We conduct experiments on two multi-hop reading comprehension datasets, namely WikiHop and MedHop (Welbl et al., 2018). The WikiHop dataset contains 43,738 training and 5,129 development instances ranging over 277 query relations. MedHop is a medical dataset containing 1,620 training and 342 development instances with a unique query relation, i.e., \"interact with\". For WikiHop, we experiment with both non-contextual (follow (Weber et al., 2019)) named as DILR and contextual word embeddings (BERT (Devlin et al., 2019)) named as DILR-BERT to demonstrate our model's generalization ability. For MedHop, we use the same setting following (Weber et al., 2019). We define M = 10 relations as existential predicates and M l = 5 invented predicates for each hop with (Weber et al., 2019). Clearly, DILR gives the best performances across all the baselines, demonstrating the advantage of combining deep attentive learning with logic reasoning. Though NLProlog also conducts logic reasoning, it is limited by the model's capacity and relies on the extraction accuracy of the NER tool. Even with well-trained contextualized word embeddings (DILR-BERT), our model still brings consistent performance gains.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_95",
            "content": "For a more thorough analysis, we take the entire WikiHop dataset and group the query relations in terms of the number of training instances. As shown in and 4,462 development instances. We report the micro-average accuracy scores over all the domains within each data group and their combinations in Table 2. Clearly, our model achieves the best performances over all data groups. The margin is larger for D1 and D3, demonstrating the consistency of our proposed model with varying data sizes. In fact, ILP could be beneficial when training data is not sufficient via learning of generalized rules.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_96",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "141-ARR_v2_97",
            "content": "To provide detailed analysis, we conduct ablation experiments on 6 datasets as shown in Table 3. For fair demonstration, we pick one relation in D3 (Located), 2 relations in D2 (Occupation and Record) and 3 relations in D1 (Publisher, Producer, Country). The first four rows reflect the accuracies by varying the maximum allowed number of reasoning hops (L). Clearly, \u2264 0 Hop and \u2264 3 Hop produce lower accuracies because \u2264 0 Hop fails to model the bridging entities and \u2264 3 Hop could overfit the model given most of the questions only involve at most 2 reasoning hops.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_98",
            "content": "The middle part of Table 3 reflects the effect of each element of DILR. Specifically, \u2212PI removes the invented predicates: remove ( 5), ( 6), ( 12) and replace U l with U in (7). \u2212ILP removes the reasoner and uses a classifier on top of the attentive reader to produce the final predictions. \u2212AR removes the attentive reader and uses NER tools to extract entities for reasoning. \u2212Rel only computes binary relations that decide whether two constants are related or not. This demonstrates the effect of relational reasoning considering different relations. By comparison, it is evident that removing any component will suffer from non-trivial prediction loss, especially for ILP. To verify the effect of the neural logic operator (NLO), we compare it with two T-norm operators, namely \"prod-T\" for product T-norm and \"min-T\" for minimum T-norm. Clearly, NLO produces the best performances across all the experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_99",
            "content": "To provide a concrete view of how the attentive reader filters relevant information and how the generated clauses look like, we list three examples as shown in Table 4. The underlined texts have the maximum attention weights learned from the attentive reader. The bold texts indicate the query subject and the correct answer for each query. Clearly, the attentive reader is able to select bridging entities relevant to the answer. The third column lists some learned clauses from the reasoner. The first row of each example shows the clauses that define an invented predicate and the second row shows the final clause that entails the query relation 4 . We use ab- 2. Hockey is a family of sports ... breviated entities as the constants in each grounded atom (e.g., \"CC\" is short for \"Chris Church\"). The two clauses for the first example could be read as: if Chris Church and Massachusetts has relation r 7 , and Massachusetts and United States has relation r 2 , then the country of Chris Church is United States.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_100",
            "content": "We further demonstrate the robustness of DILR by varying model parameters, as shown in Figure 2. The top subplots reveal the accuracies on MedHop and Country datasets when changing the number of final clauses H (left) and the number of existential predicates M (right). The subplot in the bottom depicts the accuracies when varying the number of instantiations K of the bridging contexts for Genre dataset under both DILR and BERT-DILR models. We shall observe that the performances are relatively stable given that the total number of testing examples are less than 400 for each dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_101",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "141-ARR_v2_102",
            "content": "We propose an end-to-end model DILR to solve the problem of multi-hop reading comprehension. DILR smoothly connects a hierarchical attentive reader with a multi-hop reasoner to conduct automatic information extraction and complex reasonkeeping those predicates with scores higher than 0.4. ing. We also introduce differentiable logic operators to induce valid clauses with smooth and stable gradient-based learning. Extensive experiments reveal consistent improvements brought by DILR.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v2_103",
            "content": "UNKNOWN, None, , Massachusetts is the most populous state in, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Massachusetts is the most populous state in",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_104",
            "content": "UNKNOWN, None, , Massachusetts. r7(CC, M ) \u2227 r2, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Massachusetts. r7(CC, M ) \u2227 r2",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_105",
            "content": "Jacob References, Marcus Andreas, Trevor Rohrbach, Dan Darrell,  Klein, Neural module networks, 2016-06-27, 2016 IEEE Conference on Computer Vision and Pattern Recognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Jacob References",
                    "Marcus Andreas",
                    "Trevor Rohrbach",
                    "Dan Darrell",
                    " Klein"
                ],
                "title": "Neural module networks",
                "pub_date": "2016-06-27",
                "pub_title": "2016 IEEE Conference on Computer Vision and Pattern Recognition",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_106",
            "content": "UNKNOWN, None, 2018, Logical rule induction and theory learning using neural theorem proving, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Logical rule induction and theory learning using neural theorem proving",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_107",
            "content": "UNKNOWN, None, 1910, Multi-hop question answering via reasoning chains. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "1910",
                "pub_title": "Multi-hop question answering via reasoning chains. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_108",
            "content": "Xinyun Chen, Chen Liang, Adams Yu, Denny Zhou, Dawn Song, V Quoc,  Le, Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Xinyun Chen",
                    "Chen Liang",
                    "Adams Yu",
                    "Denny Zhou",
                    "Dawn Song",
                    "V Quoc",
                    " Le"
                ],
                "title": "Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension",
                "pub_date": "2020-04-26",
                "pub_title": "8th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_109",
            "content": "Christopher Clark, Matt Gardner, Simple and effective multi-paragraph reading comprehension, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Christopher Clark",
                    "Matt Gardner"
                ],
                "title": "Simple and effective multi-paragraph reading comprehension",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "141-ARR_v2_110",
            "content": "UNKNOWN, None, 2016, Tensorlog: A differentiable deductive database, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Tensorlog: A differentiable deductive database",
                "pub": "CoRR"
            }
        },
        {
            "ix": "141-ARR_v2_111",
            "content": "Nicola De Cao, Wilker Aziz, Ivan Titov, Question answering by reasoning across documents with graph convolutional networks, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Nicola De Cao",
                    "Wilker Aziz",
                    "Ivan Titov"
                ],
                "title": "Question answering by reasoning across documents with graph convolutional networks",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_112",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_113",
            "content": "Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William Cohen, Ruslan Salakhutdinov, Neural models for reasoning over multiple mentions using coreference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Bhuwan Dhingra",
                    "Qiao Jin",
                    "Zhilin Yang",
                    "William Cohen",
                    "Ruslan Salakhutdinov"
                ],
                "title": "Neural models for reasoning over multiple mentions using coreference",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_114",
            "content": "Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, William Cohen, Differentiable reasoning over a virtual knowledge base, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Bhuwan Dhingra",
                    "Manzil Zaheer",
                    "Vidhisha Balachandran",
                    "Graham Neubig",
                    "Ruslan Salakhutdinov",
                    "William Cohen"
                ],
                "title": "Differentiable reasoning over a virtual knowledge base",
                "pub_date": "2020-04-26",
                "pub_title": "8th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_115",
            "content": "Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang, Cognitive graph for multi-hop reading comprehension at scale, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Ming Ding",
                    "Chang Zhou",
                    "Qibin Chen",
                    "Hongxia Yang",
                    "Jie Tang"
                ],
                "title": "Cognitive graph for multi-hop reading comprehension at scale",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_116",
            "content": "Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, Denny Zhou, Neural logic machines, 2019-05-06, 7th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Honghua Dong",
                    "Jiayuan Mao",
                    "Tian Lin",
                    "Chong Wang",
                    "Lihong Li",
                    "Denny Zhou"
                ],
                "title": "Neural logic machines",
                "pub_date": "2019-05-06",
                "pub_title": "7th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_117",
            "content": "Richard Evans, Edward Grefenstette, Learning explanatory rules from noisy data, 2018, J. Artif. Intelligent Res, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Richard Evans",
                    "Edward Grefenstette"
                ],
                "title": "Learning explanatory rules from noisy data",
                "pub_date": "2018",
                "pub_title": "J. Artif. Intelligent Res",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_118",
            "content": "V Manoel, Gerson Fran\u00e7a, Artur Zaverucha,  D'avila Garcez, Fast relational learning using bottom clause propositionalization with artificial neural networks, 2014, Mach. Learn, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "V Manoel",
                    "Gerson Fran\u00e7a",
                    "Artur Zaverucha",
                    " D'avila Garcez"
                ],
                "title": "Fast relational learning using bottom clause propositionalization with artificial neural networks",
                "pub_date": "2014",
                "pub_title": "Mach. Learn",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_119",
            "content": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, Li Guo, Jointly embedding knowledge graphs and logical rules, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Shu Guo",
                    "Quan Wang",
                    "Lihong Wang",
                    "Bin Wang",
                    "Li Guo"
                ],
                "title": "Jointly embedding knowledge graphs and logical rules",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_120",
            "content": "Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, Matt Gardner, Neural module networks for reasoning over text, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Nitish Gupta",
                    "Kevin Lin",
                    "Dan Roth",
                    "Sameer Singh",
                    "Matt Gardner"
                ],
                "title": "Neural module networks for reasoning over text",
                "pub_date": "2020-04-26",
                "pub_title": "8th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_121",
            "content": "Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric Xing, Harnessing deep neural networks with logic rules, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Zhiting Hu",
                    "Xuezhe Ma",
                    "Zhengzhong Liu",
                    "Eduard Hovy",
                    "Eric Xing"
                ],
                "title": "Harnessing deep neural networks with logic rules",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "141-ARR_v2_122",
            "content": "Yichen Jiang, Mohit Bansal, Self-assembling modular networks for interpretable multi-hop reasoning, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Yichen Jiang",
                    "Mohit Bansal"
                ],
                "title": "Self-assembling modular networks for interpretable multi-hop reasoning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_123",
            "content": "Yichen Jiang, Nitish Joshi, Yen-Chun Chen, Mohit Bansal, Explore, propose, and assemble: An interpretable model for multi-hop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Yichen Jiang",
                    "Nitish Joshi",
                    "Yen-Chun Chen",
                    "Mohit Bansal"
                ],
                "title": "Explore, propose, and assemble: An interpretable model for multi-hop reading comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_124",
            "content": "UNKNOWN, None, 2013, Triangular norms, Springer Science and Business Media.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Triangular norms",
                "pub": "Springer Science and Business Media"
            }
        },
        {
            "ix": "141-ARR_v2_125",
            "content": "Souvik Kundu, Tushar Khot, Ashish Sabharwal, Peter Clark, Exploiting explicit paths for multihop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Souvik Kundu",
                    "Tushar Khot",
                    "Ashish Sabharwal",
                    "Peter Clark"
                ],
                "title": "Exploiting explicit paths for multihop reading comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_126",
            "content": "Tao Li, Vivek Srikumar, Augmenting neural networks with first-order logic, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Tao Li",
                    "Vivek Srikumar"
                ],
                "title": "Augmenting neural networks with first-order logic",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_127",
            "content": "Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt, Deepproblog: Neural probabilistic logic programming, 2018-12-03, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Robin Manhaeve",
                    "Sebastijan Dumancic",
                    "Angelika Kimmig",
                    "Thomas Demeester",
                    "Luc De Raedt"
                ],
                "title": "Deepproblog: Neural probabilistic logic programming",
                "pub_date": "2018-12-03",
                "pub_title": "Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_128",
            "content": "F Andr\u00e9, Ram\u00f3n Martins,  Fernandez Astudillo, From softmax to sparsemax: A sparse model of attention and multi-label classification, 2016-06-19, Proceedings of the 33nd International Conference on Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "F Andr\u00e9",
                    "Ram\u00f3n Martins",
                    " Fernandez Astudillo"
                ],
                "title": "From softmax to sparsemax: A sparse model of attention and multi-label classification",
                "pub_date": "2016-06-19",
                "pub_title": "Proceedings of the 33nd International Conference on Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_129",
            "content": "Sewon Min, Victor Zhong, Luke Zettlemoyer, Hannaneh Hajishirzi, Multi-hop reading comprehension through question decomposition and rescoring, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Sewon Min",
                    "Victor Zhong",
                    "Luke Zettlemoyer",
                    "Hannaneh Hajishirzi"
                ],
                "title": "Multi-hop reading comprehension through question decomposition and rescoring",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_130",
            "content": "Pasquale Minervini, Matko Bosnjak, Tim Rockt\u00e4schel, Sebastian Riedel, Edward Grefenstette, Differentiable reasoning on large knowledge bases and natural language, 2020, AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Pasquale Minervini",
                    "Matko Bosnjak",
                    "Tim Rockt\u00e4schel",
                    "Sebastian Riedel",
                    "Edward Grefenstette"
                ],
                "title": "Differentiable reasoning on large knowledge bases and natural language",
                "pub_date": "2020",
                "pub_title": "AAAI",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_131",
            "content": "Pasquale Minervini, Thomas Demeester, Tim Rockt\u00e4schel, Sebastian Riedel, Adversarial sets for regularised neural link predictors, 2017, UAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Pasquale Minervini",
                    "Thomas Demeester",
                    "Tim Rockt\u00e4schel",
                    "Sebastian Riedel"
                ],
                "title": "Adversarial sets for regularised neural link predictors",
                "pub_date": "2017",
                "pub_title": "UAI",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_132",
            "content": "Stephen Muggleton, Inductive logic programming, 1991, New Generation Computing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    " Stephen Muggleton"
                ],
                "title": "Inductive logic programming",
                "pub_date": "1991",
                "pub_title": "New Generation Computing",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_133",
            "content": "Lin Qiu, Yunxuan Xiao, Yanru Qu, Hao Zhou, Lei Li, Weinan Zhang, Yong Yu, Dynamically fused graph network for multi-hop reasoning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Lin Qiu",
                    "Yunxuan Xiao",
                    "Yanru Qu",
                    "Hao Zhou",
                    "Lei Li",
                    "Weinan Zhang",
                    "Yong Yu"
                ],
                "title": "Dynamically fused graph network for multi-hop reasoning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_134",
            "content": "Meng Qu, Jian Tang, Probabilistic logic neural networks for reasoning, 2019-12-08, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Meng Qu",
                    "Jian Tang"
                ],
                "title": "Probabilistic logic neural networks for reasoning",
                "pub_date": "2019-12-08",
                "pub_title": "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_135",
            "content": "Tim Rockt\u00e4schel, Sebastian Riedel, End-toend differentiable proving, 2017-12-04, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Tim Rockt\u00e4schel",
                    "Sebastian Riedel"
                ],
                "title": "End-toend differentiable proving",
                "pub_date": "2017-12-04",
                "pub_title": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_136",
            "content": "UNKNOWN, None, 2018, Exploring graph-structured passage representation for multihop reading comprehension with graph neural networks, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Exploring graph-structured passage representation for multihop reading comprehension with graph neural networks",
                "pub": "CoRR"
            }
        },
        {
            "ix": "141-ARR_v2_137",
            "content": "Zeyun Tang, Yongliang Shen, Xinyin Ma, Wei Xu, Jiale Yu, Weiming Lu, Multi-hop reading comprehension across documents with path-based graph convolutional network, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Zeyun Tang",
                    "Yongliang Shen",
                    "Xinyin Ma",
                    "Wei Xu",
                    "Jiale Yu",
                    "Weiming Lu"
                ],
                "title": "Multi-hop reading comprehension across documents with path-based graph convolutional network",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_138",
            "content": "Ming Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, Bowen Zhou, Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Ming Tu",
                    "Guangtao Wang",
                    "Jing Huang",
                    "Yun Tang",
                    "Xiaodong He",
                    "Bowen Zhou"
                ],
                "title": "Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_139",
            "content": "Po-Wei Wang, Priya Donti, Bryan Wilder, J Kolter, Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver, 2019-06, Proceedings of the 36th International Conference on Machine Learning, ICML 2019, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Po-Wei Wang",
                    "Priya Donti",
                    "Bryan Wilder",
                    "J Kolter"
                ],
                "title": "Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
                "pub_date": "2019-06",
                "pub_title": "Proceedings of the 36th International Conference on Machine Learning, ICML 2019",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_140",
            "content": "Wenya Wang,  Sinno Jialin Pan, Integrating deep learning with logic fusion for information extraction, 2020, AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Wenya Wang",
                    " Sinno Jialin Pan"
                ],
                "title": "Integrating deep learning with logic fusion for information extraction",
                "pub_date": "2020",
                "pub_title": "AAAI",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_141",
            "content": "Yizhong Wang, Kai Liu, Jing Liu, Wei He, Yajuan Lyu, Hua Wu, Sujian Li, Haifeng Wang, Multipassage machine reading comprehension with crosspassage answer verification, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Yizhong Wang",
                    "Kai Liu",
                    "Jing Liu",
                    "Wei He",
                    "Yajuan Lyu",
                    "Hua Wu",
                    "Sujian Li",
                    "Haifeng Wang"
                ],
                "title": "Multipassage machine reading comprehension with crosspassage answer verification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "141-ARR_v2_142",
            "content": "Leon Weber, Pasquale Minervini, Jannes M\u00fcnchmeyer, Ulf Leser, Tim Rockt\u00e4schel, NLProlog: Reasoning with weak unification for question answering in natural language, 2019, Proceedings of the 57th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Leon Weber",
                    "Pasquale Minervini",
                    "Jannes M\u00fcnchmeyer",
                    "Ulf Leser",
                    "Tim Rockt\u00e4schel"
                ],
                "title": "NLProlog: Reasoning with weak unification for question answering in natural language",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_143",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_144",
            "content": "Johannes Welbl, Pontus Stenetorp, Sebastian Riedel, Constructing datasets for multi-hop reading comprehension across documents, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Johannes Welbl",
                    "Pontus Stenetorp",
                    "Sebastian Riedel"
                ],
                "title": "Constructing datasets for multi-hop reading comprehension across documents",
                "pub_date": "2018",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_145",
            "content": "Meixi Wu, Wenya Wang, Sinno Jialin Pan, Deep Weighted MaxSAT for Aspect-based Opinion Extraction, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Meixi Wu",
                    "Wenya Wang",
                    "Sinno Jialin Pan"
                ],
                "title": "Deep Weighted MaxSAT for Aspect-based Opinion Extraction",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_146",
            "content": "Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van Den Broeck, A semantic loss function for deep learning with symbolic knowledge, 2018-07-10, Proceedings of the 35th International Conference on Machine Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Jingyi Xu",
                    "Zilu Zhang",
                    "Tal Friedman",
                    "Yitao Liang",
                    "Guy Van Den Broeck"
                ],
                "title": "A semantic loss function for deep learning with symbolic knowledge",
                "pub_date": "2018-07-10",
                "pub_title": "Proceedings of the 35th International Conference on Machine Learning",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_147",
            "content": "Fan Yang, Zhilin Yang, William Cohen, Differentiable learning of logical rules for knowledge base reasoning, 2017-12-04, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Fan Yang",
                    "Zhilin Yang",
                    "William Cohen"
                ],
                "title": "Differentiable learning of logical rules for knowledge base reasoning",
                "pub_date": "2017-12-04",
                "pub_title": "Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_148",
            "content": "Yuan Yang, Le Song, Learn to explain efficiently via neural logic inductive learning, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Yuan Yang",
                    "Le Song"
                ],
                "title": "Learn to explain efficiently via neural logic inductive learning",
                "pub_date": "2020-04-26",
                "pub_title": "8th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_149",
            "content": "Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher, Coarse-grain fine-grain coattention network for multi-evidence question answering, 2019-05-06, 7th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Victor Zhong",
                    "Caiming Xiong",
                    "Nitish Shirish Keskar",
                    "Richard Socher"
                ],
                "title": "Coarse-grain fine-grain coattention network for multi-evidence question answering",
                "pub_date": "2019-05-06",
                "pub_title": "7th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v2_150",
            "content": "Yimeng Zhuang, Huadong Wang, Token-level dynamic self-attention network for multi-passage reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Yimeng Zhuang",
                    "Huadong Wang"
                ],
                "title": "Token-level dynamic self-attention network for multi-passage reading comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "141-ARR_v2_0@0",
            "content": "Deep Inductive Logic Reasoning for Multi-Hop Reading Comprehension",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_0",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_2@0",
            "content": "Multi-hop reading comprehension requires an ability to reason across multiple documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_2",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_2@1",
            "content": "On the one hand, deep learning approaches only implicitly encode query-related information into distributed embeddings which fail to uncover the discrete relational reasoning process to infer the correct answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_2",
            "start": 89,
            "end": 299,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_2@2",
            "content": "On the other hand, logic-based approaches provide interpretable rules to infer the target answer, but mostly work on structured data where entities and relations are well-defined.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_2",
            "start": 301,
            "end": 479,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_2@3",
            "content": "In this paper, we propose a deep-learning based inductive logic reasoning method that firstly extracts query-related (candidate-related) information, and then conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_2",
            "start": 481,
            "end": 754,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_2@4",
            "content": "The reasoning process is accomplished via attentive memories with novel differentiable logic operators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_2",
            "start": 756,
            "end": 858,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_2@5",
            "content": "To demonstrate the effectiveness of our model, we evaluate it on two reading comprehension datasets, namely WikiHop and MedHop.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_2",
            "start": 860,
            "end": 986,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_4@0",
            "content": "Reasoning has been extensively studied in the structured domain, e.g., knowledge base completion which infers missing facts given background entities and relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_4",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_4@1",
            "content": "However, when the background knowledge is expressed in natural languages, as shown in the multi-hop reading comprehension problem with triplet-form questions (Welbl et al., 2018), it becomes difficult to conduct complex reasoning because the entities and relations are not explicitly labeled in the documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_4",
            "start": 165,
            "end": 473,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_4@2",
            "content": "For example, consider the question \"country(Moonhole, ?)\", given the following documents:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_4",
            "start": 475,
            "end": 563,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_5@0",
            "content": "\"Moonhole is a private community on the island of Bequia. Moonhole was founded by Thomas and Gladys Johnston in the 1960s.\" \"Gladys Johnston was born in United States.\"",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_5",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_6@0",
            "content": "\"Bequia is an island and is part of the country of Saint Vincent and the Grenadines\"",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_6",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_7@0",
            "content": "In this example, the underlined entities are used to infer the correct answer, i.e., \"country(Moonhole, Saint Vincent and the Grenadines)\", but are not explicitly annotated for relational reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_7",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@0",
            "content": "Deep neural networks (DNNs) for multi-hop reading comprehension (RC) can be summarized into following three categories.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@1",
            "content": "1) Memory-based models Zhuang and Wang, 2019) that produce queryaware context representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 120,
            "end": 213,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@2",
            "content": "2) Graph-based approaches (Song et al., 2018;De Cao et al., 2019) that use graph neural networks to propagate information based on pre-constructed entity (context) graphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 215,
            "end": 385,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@3",
            "content": "3) Neural Module networks (Andreas et al., 2016) that decompose the question into a series of action modules Gupta et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 387,
            "end": 515,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@4",
            "content": "However, DNNs only implicitly encode relevant contexts and fail to explicitly uncover the underlying relational compositions for complex inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 517,
            "end": 663,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@5",
            "content": "For instance, in the above example, DNNs may encode Bequia and Gladys Johnson into 1-hop features, given the fact that both entities co-occur with the query Moonhole.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 665,
            "end": 830,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@6",
            "content": "As a result, the model may predict United States by linking it with Gladys Johnson instead of the correct answer Saint Vincent and the Grenadines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 832,
            "end": 977,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_8@7",
            "content": "In contrast, human beings would easily produce the correct answer given the knowledge \"if A is in B and B is part of country C, then A is in country C\" and by examining the relations between each entity pair co-occurred in the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_8",
            "start": 979,
            "end": 1213,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_9@0",
            "content": "Inductive logic programming (ILP) (Muggleton, 1991) aligns with human reasoning by inducing interpretable rules to entail positive but not negative examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_9",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_9@1",
            "content": "To answer the previous query, ILP could generate a rule as located_in(X, Z) \u2227 country(Z, Y ) \u21d2 country(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_9",
            "start": 158,
            "end": 267,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_9@2",
            "content": "Combining deep learning with ILP is a promising direction to benefit from both worlds (Evans and Grefenstette, 2018;Dong et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_9",
            "start": 269,
            "end": 403,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_9@3",
            "content": "Deep logic models have been proposed for structured knowledge base completion (Minervini et al., 2017(Minervini et al., , 2020Yang and Song, 2020;Yang et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_9",
            "start": 405,
            "end": 569,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_9@4",
            "content": "However, it becomes much more challenging when dealing with natural language inputs, as in the case of multi-hop reading comprehension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_9",
            "start": 571,
            "end": 705,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_9@5",
            "content": "Weber et al. (2019) proposed to combine a symbolic reasoner: prolog, with weak unifications based on distributed embeddings as a backwardchaining theorem prover to induce feasible rules for multi-hop reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_9",
            "start": 707,
            "end": 916,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_9@6",
            "content": "However, their work relies on the degree of precision for pre-extracted NERs and is limited by the number of rule templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_9",
            "start": 918,
            "end": 1041,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_10@0",
            "content": "To address the aforementioned limitations, we propose a novel end-to-end integration of deep learning and logic reasoning termed Deep Inductive Logic Reasoning (DILR).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_10",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_10@1",
            "content": "It consists of two components: 1) a hierarchical attentive reader that filters query-related and candidate-related information from given documents, and 2) a multihop reasoner that conducts inductive logic reasoning by attentively selecting proper predicates to form candidate rules and refines them upon given examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_10",
            "start": 168,
            "end": 487,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_10@2",
            "content": "We introduce novel differentiable logic operators combined with attention mechanisms for smooth back-propagation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_10",
            "start": 489,
            "end": 601,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_10@3",
            "content": "Compared to existing deep logic models, we build connections between raw text inputs and the symbolic domain by mapping high-level semantic representations to logic predicates and instantiating logic variables with neural representations to conduct relational reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_10",
            "start": 603,
            "end": 872,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_10@4",
            "content": "We also parameterize the entire process for end-to-end differentiable learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_10",
            "start": 874,
            "end": 952,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_11@0",
            "content": "The contributions of this work include: 1) We introduce a novel smooth connection between deep representation learning with logic reasoning by associating distributed representations with discrete logic predicates and their probabilistic evaluations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_11",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_12@0",
            "content": "2) We propose deep-learning-based inductive logic programming via attentive memories and differentiable logic operators for the task of multi-hop reading comprehension considering the number of reasoning steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_12",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_12@1",
            "content": "3) We provide comprehensive evaluations of our model on two benchmark datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_12",
            "start": 211,
            "end": 289,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_13@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_13",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_14@0",
            "content": "Multi-Hop Reading Comprehension Recent works for multi-hop RC include memory-based methods which apply attentions to iteratively update query and context representations considering their interactions (Dhingra et al., 2018;Clark and Gardner, 2018;Zhuang and Wang, 2019;.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_14",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_14@1",
            "content": "To explicitly incorporate entity connections, De Cao et al. (2019), Ding et al. (2019), Qiu et al. (2019), Tang et al. (2020), Song et al. (2018) and Tu et al. (2019) proposed to build entity graphs and apply Graph Neural Networks for information propagation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_14",
            "start": 271,
            "end": 529,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_14@2",
            "content": "Kundu et al. (2019) formalized reasoning as a path-finding problem with neural encoding to rank candidate paths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_14",
            "start": 531,
            "end": 642,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_14@3",
            "content": "Path modeling was also adopted in using pointer networks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_14",
            "start": 644,
            "end": 700,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_14@4",
            "content": "However, these approaches only focus on local information without the ability to generalize, and some of them rely on off-the-shelf NER tools.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_14",
            "start": 702,
            "end": 843,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_14@5",
            "content": "Dhingra et al. (2020) proposed to convert texts into a virtual knowledge base for retrieval using a pre-constructed entity database.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_14",
            "start": 845,
            "end": 976,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_14@6",
            "content": "Another research direction is to decompose target questions into subquestions (Min et al., 2019) or sub-modules parameterized with neural module networks Gupta et al., 2020;Chen et al., 2020) which also fail to explicitly uncover the underlying logic for reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_14",
            "start": 978,
            "end": 1242,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_15@0",
            "content": "Deep Learning with Logic Reasoning Neurosymbolic learning aims to integrate deep learning's ability on dealing with uncertainty and logic programming's ability on reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_15",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_15@1",
            "content": "Deep neural networks have been used to parameterize discrete logic operators and logic atoms (Fran\u00e7a et al., 2014;Hu et al., 2016;Manhaeve et al., 2018;Xu et al., 2018;Li and Srikumar, 2019;Wu et al., 2020) given the logic rules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_15",
            "start": 174,
            "end": 402,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_15@2",
            "content": "A more challenging direction is inductive logic programming that automatically learns rules through representation learning and differentiable backpropagation (Evans and Grefenstette, 2018;Dong et al., 2019;Yang and Song, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_15",
            "start": 404,
            "end": 631,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_16@0",
            "content": "Neuro-symbolic learning has been applied to knowledge-base completion through logic embeddings (Guo et al., 2016), tensor operations (Cohen, 2016;, adversarial learning (Minervini et al., 2017), variational learning (Qu and Tang, 2019) or attentions (Yang and Song, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_16",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_16@1",
            "content": "Differentiable theorem proving has also been proposed with weak unifications and backward chaining Campero et al., 2018;Minervini et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_16",
            "start": 273,
            "end": 416,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_16@2",
            "content": "However, unlike multi-hop RC, knowledge-base completion only takes structured inputs without the need to address language ambiguity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_16",
            "start": 418,
            "end": 549,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_16@3",
            "content": "The most related work to ours is NLProlog (Weber et al., 2019), a neural theorem prover for multi-hop RC by converting language utterances to distributed embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_16",
            "start": 551,
            "end": 715,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_16@4",
            "content": "However, NLProlog relies on a NER tool to extract entities and its expressiveness is limited by the number of rule templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_16",
            "start": 717,
            "end": 841,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_17@0",
            "content": "Background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_17",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_18@0",
            "content": "We focus on multi-hop reading comprehension tasks containing explicit query types which align with the standard ILP setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_18",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_18@1",
            "content": "Formally, for each RC problem, we are given a set of documents C = {c 1 , ..., c K }, a structured query in the form of a relational triplet (s, q, ?), where s denotes the subject of the relation q, and a list of candidate answers A = {a 1 , ..., a n }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_18",
            "start": 125,
            "end": 377,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_18@2",
            "content": "The task is to select an answer a \u2208 A such that q(s, a) is satisfied, i.e., a is the object of relation q given the subject s. For example, country(M oonhole, ?) is a query asking for the country where Moonhole is located.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_18",
            "start": 379,
            "end": 600,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_18@3",
            "content": "This task could be converted into an ILP problem with the formal definition as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_18",
            "start": 602,
            "end": 688,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_19@0",
            "content": "Definition 3.1 (Inductive Logic Programming).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_19",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_19@1",
            "content": "Given a logic theory B representing the background knowledge (facts), a set of positive examples E + and a set of negative examples E \u2212 , an ILP system aims to derive a hypothesis H which entails all the positive and none of the negative examples:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_19",
            "start": 46,
            "end": 292,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_20@0",
            "content": "B \u2227 H |= \u03b3 for \u03b3 \u2208 E + . B \u2227 H \u0338 |= \u03b3 for \u03b3 \u2208 E \u2212 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_20",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_21@0",
            "content": "The hypothesis H is a logic program consisting of definite clauses b 1 \u2227 ... \u2227 b N \u21d2 h where b 1 , ..., b N and h are logic atoms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_21",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_21@1",
            "content": "The LHS of \"\u21d2\" is the clause body and h is the head.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_21",
            "start": 131,
            "end": 182,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_21@2",
            "content": "An atom is composed of a predicate and its arguments, e.g., h = located_in(X, Y ) with predicate \"located_in\" and arguments X, Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_21",
            "start": 184,
            "end": 313,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_21@3",
            "content": "A ground atom is obtained by instantiating variables in the arguments with constants, e.g., X = \"US\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_21",
            "start": 315,
            "end": 415,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_21@4",
            "content": "We use \u00b5(\u2022) to denote the value of an atom or a clause.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_21",
            "start": 417,
            "end": 471,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_21@5",
            "content": "For smooth optimization, we assign \u00b5(\u2022) \u2208 [0, 1] which indicates the probability of the atom or clause being true.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_21",
            "start": 473,
            "end": 586,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_22@0",
            "content": "For multi-hop reading comprehension, we treat the query relation q(X, Y ) as the head atom of the clauses to be induced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_22",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_22@1",
            "content": "The correct answer a + i from each problem forms the set of positive examples",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_22",
            "start": 121,
            "end": 197,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_23@0",
            "content": "E + ={q(s i , a + i )} N + i=1 ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_23",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_24@0",
            "content": "and the incorrect answer a \u2212 i forms the set of negative examples",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_24",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_25@0",
            "content": "E \u2212 ={q(s i , a \u2212 i )} N \u2212 i=1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_25",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_26@0",
            "content": "Here we use lower cases: s i , a + i , a \u2212 i to represent constants and upper cases: X, Y to represent variables.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_26",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_26@1",
            "content": "The predicates in the logic domain correspond to pairwise relations between two entities 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_26",
            "start": 114,
            "end": 205,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_26@2",
            "content": "To differentiate the number of inference steps, we define a l-hop reasoning clause as F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 )\u21d2r(X 0 , X l+1 ) with l denoting the number of extra arguments as bridging entities in the rule body except those in the head atom.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_26",
            "start": 207,
            "end": 466,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_26@3",
            "content": "Here r denotes a predicate, i.e., a relation between X 0 and X l+1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_26",
            "start": 468,
            "end": 535,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_26@4",
            "content": "Each subclause F t (X t , X t+1 ) can be one or a conjunction (\u2227) of 2-ary atoms taking only X t and X t+1 as arguments, e.g.,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_26",
            "start": 537,
            "end": 662,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_27@0",
            "content": "F t (X t , X t+1 ) = r 1 (X t , X t+1 ) \u2227 r 2 (X t , X t+1 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_27",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_28@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_28",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_29@0",
            "content": "Overall, DILR simulates a multi-hop reasoning process considering different number of inference steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_29",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_29@1",
            "content": "It is an end-to-end framework consisting of two components: a Hierarchical Attentive Reader and a Multi-hop Reasoner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_29",
            "start": 103,
            "end": 219,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_29@2",
            "content": "The attentive reader learns to select relevant information from the given documents to produce query-aware, candidateaware and bridging entity representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_29",
            "start": 221,
            "end": 379,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_29@3",
            "content": "These representations are passed to the multi-hop reasoner to instantiate logic atoms in order to generate and evaluate clauses that are relevant to the query relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_29",
            "start": 381,
            "end": 548,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_29@4",
            "content": "The multi-hop reasoner conducts rule induction via attentive memories that softly select atoms to form new clauses and novel differentiable logic operators that produce probabilistic values for generated clauses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_29",
            "start": 550,
            "end": 761,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_29@5",
            "content": "The final loss can be backpropagated smoothly to update the attentive reader for more accurate selections.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_29",
            "start": 763,
            "end": 868,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_29@6",
            "content": "Next, we illustrate each component with more details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_29",
            "start": 870,
            "end": 922,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_30@0",
            "content": "Hierarchical Attentive Reader",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_30",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_31@0",
            "content": "To avoid inevitable errors brought by off-the-shelf NER tools for named entity extraction, we propose to extract relevant information using an attentive reader.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_31",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_31@1",
            "content": "Since multiple documents (contexts) are involved for each question, we design a 2-level hierarchical attention network to progressively filter token-level and context-level information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_31",
            "start": 161,
            "end": 345,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_31@2",
            "content": "Specifically, the token-level attentions aim to select lhop (l = 0, ..., L) relevant entities in each context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_31",
            "start": 347,
            "end": 456,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_31@3",
            "content": "Then the context-level attentions produce the final representations by softly attending to each context considering different number of reasoning hops.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_31",
            "start": 458,
            "end": 608,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_32@0",
            "content": "Token-Level Attention",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_32",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_33@0",
            "content": "Given a query subject s with n s tokens, a candidate a with n a tokens, and a context c of length n c , we denote by S \u2208 R ns\u00d7D , A \u2208 R na\u00d7D and C \u2208 R nc\u00d7D their word features after a biGRU layer, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_33",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_33@1",
            "content": "For multi-hop reasoning, we use different attentions for finding or relocating target tokens in each context, inspired by (Gupta et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_33",
            "start": 211,
            "end": 353,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_33@2",
            "content": "Firstly, a subject-to-context attention is adopted to find similar tokens as the subject in each context:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_33",
            "start": 355,
            "end": 459,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_34@0",
            "content": "B s ij = w \u22a4 s [S i ; C j ; S i \u2022 C j ]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_34",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_35@0",
            "content": "where w s is a learnable transformation vector and [; ] denotes concatenations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_35",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_35@1",
            "content": "We obtain the normalized similarity score \u03b1 s ij between the i-th token in the subject and the j-th token in the context via a softmax operation on each row of B s .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_35",
            "start": 80,
            "end": 244,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_35@2",
            "content": "A subject-aware (0-hop) context representation is produced as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_35",
            "start": 246,
            "end": 306,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_36@0",
            "content": "h s = nc j=1 \u1fb1s j C j , with \u1fb1s j = ns i=1 \u03b1 s ij \u03b2 s i ,(1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_36",
            "start": 0,
            "end": 59,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_37@0",
            "content": "where \u03b2 s i weighs the contribution of each subject token via a self-attention: \u03b2 s = softmax( w\u22a4 s S + b s ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_37",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_37@1",
            "content": "Similarly, we produce an attention score \u03b1 a ij for the j-th context token w.r.t. the i-th candidate token and a candidate-aware context representation h a .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_37",
            "start": 111,
            "end": 267,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_37@2",
            "content": "We denote by s = \u03b2 s S, and a = \u03b2 a A the feature representation of the query subject and the candidate entity, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_37",
            "start": 269,
            "end": 393,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_38@0",
            "content": "For (l + 1)-hop reasoning (l \u2265 0), it is desired to relocate to intermediate (bridging) entities that are related to the l-hop entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_38",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_38@1",
            "content": "Hence, we adopt context-to-context attentions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_38",
            "start": 137,
            "end": 181,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_39@0",
            "content": "B l+1 ij = w \u22a4 l [C i + h l ; C j ; (C i + h l )\u2022C j ]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_39",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_40@0",
            "content": "given the l-hop representation h l where h 0 = h s .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_40",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_40@1",
            "content": "We use \u03b1 l+1 ij to denote a normalized attention score between the i-th and the j-th context tokens after applying a softmax operator over each row of B l+1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_40",
            "start": 53,
            "end": 210,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_40@2",
            "content": "With \u1fb10 j = \u1fb1s j , the (l + 1)-hop bridging context representation becomes",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_40",
            "start": 212,
            "end": 285,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_41@0",
            "content": "h l+1 = nc j=1 \u1fb1l+1 j C j , with \u1fb1l+1 j = nc i=1 \u03b1 l+1 ij \u1fb1l i . (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_41",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_42@0",
            "content": "Context-Level Attention",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_42",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_43@0",
            "content": "With multiple contexts (documents) available, we use a context-level attention to produce the final l-hop feature representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_43",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_43@1",
            "content": "When l = 0, the model softly attends to each context to produce context-attended subject representation as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_43",
            "start": 131,
            "end": 236,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_44@0",
            "content": "h s = K k=1 \u03b3s k h s,k ,(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_44",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_45@0",
            "content": "where \u03b3s k is the attention weight of context c k obtained by normalizing over a score vector \u03b3 s",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_45",
            "start": 0,
            "end": 96,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_46@0",
            "content": "r 1 (s, a) r M (s, a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 1 k , a) r M (c 1 k , a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 2 k , a) r M (c 2 k , a) r 1 (c 1 k , c 2 k ) r M (c 1 k , c 2 k ) r 0 1 (s, a) r 0 M0 (s, a) r 1 1 (s, a) r 1 M1 (s, a) r 2 1 (s, a) r 2 M2 (s, a) c 1 1 c 1 K c 1 1 c 1 K q(s, a) 0-hop 1-hop 2-hop c 2 1 c 2 K Figure 1:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_46",
            "start": 0,
            "end": 343,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_47@0",
            "content": "An example of multi-hop ILP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_47",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_47@1",
            "content": "The existential predicates r 1 , ..., r M are used to define invented predicates r l 1 , ..., r l M l through attentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_47",
            "start": 29,
            "end": 149,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_47@2",
            "content": "The invented predicates will produce the final clauses to define q. with entries",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_47",
            "start": 151,
            "end": 230,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_48@0",
            "content": "\u03b3 s k = v \u22a4 s [s; h s,k ; s \u2022 h s,k ].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_48",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_49@0",
            "content": "Here h s,k is the subject-aware context representation computed in (1) corresponding to the k-th context c k .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_49",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_49@1",
            "content": "v s is a trainable transformation vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_49",
            "start": 111,
            "end": 151,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_49@2",
            "content": "The final subject representation is produced as hs = W s [s; h s ; s \u2022 h s ] incorporating both original features and attended information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_49",
            "start": 153,
            "end": 291,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_49@3",
            "content": "Similar procedure applies to each candidate entity to produce ha .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_49",
            "start": 293,
            "end": 358,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_49@4",
            "content": "We treat hs and ha as 0-hop subject and candidate representations, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_49",
            "start": 360,
            "end": 439,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_50@0",
            "content": "When l > 0, the context-level attention aims to produce the probability of each context being chosen as a bridging entity using",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_50",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_51@0",
            "content": "p l k = \u03c3(v \u22a4 l [ hs ; h l k ; hs \u2022 h l k ]),(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_51",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_52@0",
            "content": "where \u03c3(\u2022) is the sigmoid function, and h l k is the l-hop intermediate entity representation for context c k \u2208 C computed using (2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_52",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_53@0",
            "content": "Multi-Hop Reasoner",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_53",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_54@0",
            "content": "The multi-hop reasoner aims to conduct complex reasoning by first generating probable logic clauses and then evaluating each clause by instantiating the variables with relevant contexts obtained from the attentive reader.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_54",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_54@1",
            "content": "The clause generation process is parameterized by attentive memories which compute the probability of selecting each atom to form a relevant clause to entail the query relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_54",
            "start": 222,
            "end": 398,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_54@2",
            "content": "An illustration of the procedure is shown in Figure 1 and is elaborated in the following sub-section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_54",
            "start": 400,
            "end": 500,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_54@3",
            "content": "The clause evaluation process is then to instantiate variables in each atom with constants such as query subjects, candidate entities or bridging entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_54",
            "start": 502,
            "end": 656,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_54@4",
            "content": "The outputs from the attentive reader, i.e., hs , ha and {h l k }'s (l > 0), can be used as feature representations for these constants to compute the atom scores for clause evaluation and updates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_54",
            "start": 658,
            "end": 854,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_55@0",
            "content": "Clause Generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_55",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_56@0",
            "content": "A definite clause is composed of atoms defined over relational predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_56",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_56@1",
            "content": "Since there are no explicit relations given in this task, we pre-define a fixed set of relations for each corpus, named as existential predicates: P E ={r 1 , ..., r M }, e.g., \"located_in\", \"next_to\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_56",
            "start": 75,
            "end": 275,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_56@2",
            "content": "For expressiveness, we further create a set of invented predicates P I =\u222a L l=0 P l I defined from the existential predicates, inspired by (Evans and Grefenstette, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_56",
            "start": 277,
            "end": 446,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_56@3",
            "content": "Specifically, P l I = {r l 1 , ..., r l M l } consists of invented predicates r l m defined using l-hop reasoning clauses F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 ) \u21d2 r l m (X 0 , X l+1 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_56",
            "start": 448,
            "end": 636,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_56@4",
            "content": "For example, located_in(X 0 , X 1 ) \u2227 next_to(X 1 , X 2 ) \u21d2 outside(X 0 , X 2 ) defines a 1-hop invented predicate \"outside\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_56",
            "start": 638,
            "end": 762,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_56@5",
            "content": "Here L is the maximum hop number.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_56",
            "start": 764,
            "end": 796,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_56@6",
            "content": "The final clauses defining the query relation will be produced by learning to select relevant invented predicates, e.g., r",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_56",
            "start": 798,
            "end": 919,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_57@0",
            "content": "l 1 i (X, Y ) \u2227 ... \u2227 r ln j (X, Y ) \u21d2 q(X, Y ) with 0 \u2264 l 1 \u2264 ... \u2264 l n \u2264 L.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_57",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_58@0",
            "content": "The number of actual inference steps l n to answer q is flexibly decided by the model itself, which will be discussed later.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_58",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_59@0",
            "content": "The clause generation process is divided into two stages: 1) to generate clauses defining invented predicates using only the existential predicates, and 2) to generate final clauses defining query relation q using only the invented predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_59",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_59@1",
            "content": "To allow for smooth optimization, we parameterize both stages by computing an attention weight for each predicate indicating its probability to appear in the clause body.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_59",
            "start": 244,
            "end": 413,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_59@2",
            "content": "Specifically, we assign each predicate a learnable embedding to indicate its semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_59",
            "start": 415,
            "end": 501,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_59@3",
            "content": "Let U \u2208 R D\u00d7M denote the embedding matrix for M existential predicates and U l \u2208 R D\u00d7M l (l \u2208 {0, 1, ..., L}) denote the embedding matrix for l-hop invented predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_59",
            "start": 503,
            "end": 670,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_59@4",
            "content": "In the first stage, we use attentive memories to generate",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_59",
            "start": 672,
            "end": 728,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_60@0",
            "content": "S l t = sparsemax((W l t U l t ) \u22a4 (W l b U)), (5) U l t+1 = U l t + S l t \u2022 (W l v U),(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_60",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_61@0",
            "content": "where U l 0 = U l , and W l t and W l b are transformation matrices for invented predicates (queries) and existential predicates (keys), respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_61",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_61@1",
            "content": "We use sparsemax, a sparse version of softmax (Martins and Astudillo, 2016), to select only a small number of predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_61",
            "start": 151,
            "end": 271,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_61@2",
            "content": "Intuitively, to learn to define a l-hop invented predicate r l m , ( 5) and ( 6) sequentially produce F t (X t , X t+1 ) at each step t \u2208 {0, ..., l} to form the clause body by attending over all the existential predicates with attention weight S l t .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_61",
            "start": 273,
            "end": 524,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_61@3",
            "content": "For example, when l = 1, (5) first attends to the existential predicate r i to generate F 0 (X 0 , X 1 ) = r i (X 0 , X 1 ) at step t = 0, and then attends to another predicate r j to generate F 1 (X 1 , X 2 ) = r j (X 1 , X 2 ) at step t = 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_61",
            "start": 526,
            "end": 768,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_62@0",
            "content": "The resulting clause r i (X 0 , X 1 ) \u2227 r j (X 1 , X 2 ) \u21d2 r 1 m (X 0 , X 2 ) defines the invented predicate r 1 m .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_62",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_62@1",
            "content": "In the second stage, we produce H final clauses taking invented predicates to define the target atom q(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_62",
            "start": 117,
            "end": 226,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_62@2",
            "content": "Given an embedding u q \u2208 R D for the target relation q, we use a multi-head attention mechanism to compute a probability distribution s h over all the invented predicates for each head h \u2208 {1, ..., H} to produce the h-th final clause:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_62",
            "start": 228,
            "end": 461,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_63@0",
            "content": "s h =sparsemax{(W h q u q ) \u22a4 (W h e [U 0 ;...;U L ])},(7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_63",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_64@0",
            "content": "where s h is a sparse selective distribution over P I = {r 0 1 , ..., r L M L }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_64",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_64@1",
            "content": "For example, if s h selects r 0 1 and r 1 2 , the final clause becomes r 0 1 (X, Y ) \u2227 r 1 2 (X, Y ) \u21d2 q(X, Y ), which involves at most 1 inference step because r 1 2 is a 1-hop invented predicate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_64",
            "start": 81,
            "end": 277,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_64@2",
            "content": "This completes the recursive rule generation step with multi-hop inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_64",
            "start": 279,
            "end": 353,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_64@3",
            "content": "To this end, we generate H clauses that can be used to define q(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_64",
            "start": 355,
            "end": 425,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_65@0",
            "content": "Clause Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_65",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_66@0",
            "content": "Instantiation The clauses generated using the attentive memories need to be tested and refined against the given positive and negative examples, known as learning from entailment that tries to maximize the truth probabilities of positive examples and minimize those of negative examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_66",
            "start": 0,
            "end": 286,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_66@1",
            "content": "The positive examples correspond to q(s, a) and the negative examples correspond to {q(s, a \u2212 )}'s, where s, a and a \u2212 refers to the query subject, correct answer and incorrect candidate, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_66",
            "start": 288,
            "end": 488,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_66@2",
            "content": "To obtain the truth probabilities of these atoms, we first instantiate the variables for each generated clause with constant contexts, e.g., X = s and Y = a (or Y = a \u2212 ) in q(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_66",
            "start": 490,
            "end": 672,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_66@3",
            "content": "The bridging variables X 1 , ..., X l are instantiated using the bridging contexts selected via the attentive reader as introduced in 4.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_66",
            "start": 674,
            "end": 811,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_66@4",
            "content": "Specifically, to instantiate each X l , we pick top-K contexts (documents) {c l 1 , ..., c l K } \u2286 C, namely X l = c l k , 1 \u2264 k \u2264 K with highest probabilities according to p l k computed via (4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_66",
            "start": 813,
            "end": 1008,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_66@5",
            "content": "Neural Logic Operator Given a definite clause b 1 \u2227 ... \u2227 b N \u21d2 h consisting of grounded atoms (e.g., b 1 = r 1 (s, a)), we could obtain the value for its head atom as \u00b5(h) = \u00b5(b 1 \u2227 ... \u2227 b N ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_66",
            "start": 1010,
            "end": 1204,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_66@6",
            "content": "To compute the RHS involving logic operators (\u2227, \u2228), T-norm (Klement et al., 2013) is usually adopted:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_66",
            "start": 1206,
            "end": 1307,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_67@0",
            "content": "T : [0, 1] \u00d7 [0, 1] \u2192 [0, 1]. For example, mini- mum t-norm defines T \u2227 (\u00b5 1 , \u00b5 2 ) = min(\u00b5 1 , \u00b5 2 ), T \u2228 (\u00b5 1 , \u00b5 2 ) = max(\u00b5 1 , \u00b5 2 ). Product t-norm de- fines T \u2227 (\u00b5 1 , \u00b5 2 ) = \u00b5 1 \u2022 \u00b5 2 , T \u2228 (\u00b5 1 , \u00b5 2 ) = 1 \u2212 (1 \u2212 \u00b5 1 )\u2022(1\u2212\u00b5 2 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_67",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_68@0",
            "content": "Here \u00b5 1 , \u00b5 2 \u2208 [0, 1] refer to the value for the body atoms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_68",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_68@1",
            "content": "However, minimum t-norm is prone to learning plateau because the gradient only flows through one of the inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_68",
            "start": 63,
            "end": 173,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_68@2",
            "content": "Product t-norm is less stable and is prone to exponential decay when the number of atoms in the clause grows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_68",
            "start": 175,
            "end": 283,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_69@0",
            "content": "To address these limitations, we propose a novel neural logic operator G defined as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_69",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_70@0",
            "content": "G \u2228 (\u00b5 1 , ..., \u00b5 N )=1\u2212exp N n=1 log(1 \u2212 \u00b5 n + \u03f5) 1 N , G \u2227 (\u00b5 1 , ..., \u00b5 N )=exp N n=1 log(\u00b5 n + \u03f5) 1 N , (8",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_70",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_71@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_71",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_72@0",
            "content": "where \u00b5 1 , ..., \u00b5 N \u2208 [0, 1] refer to the probabilistic values of all the atoms in the conjunctive (\u2227) or disjunctive (\u2228) clause.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_72",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_72@1",
            "content": "\u03f5 is a small value to guarantee the validity for logarithm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_72",
            "start": 131,
            "end": 189,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_72@2",
            "content": "The operator G has the following property that is ideal for logic semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_72",
            "start": 191,
            "end": 266,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_72@3",
            "content": "1) , where min refers to the index of the minimum value among {\u00b5 1 , ..., \u00b5 N }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_72",
            "start": 268,
            "end": 347,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_73@0",
            "content": "Proposition 1. When \u2200\u00b5 n \u2192 1 with 1 \u2264 n \u2264 N , G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2192 1, aligning with logic \"AND\". When \u2203\u00b5 n \u2192 1, G \u2228 (\u00b5 1 , ..., \u00b5 N ) \u2192 1, aligning with logic \"OR\". Proposition 2. 0 \u2264 G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2212 \u00b5 min \u2264 (N 1/(1\u2212N ) \u2212 N N/(1\u2212N ) )( n\u0338 =min \u00b5 N ) 1/(N \u2212",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_73",
            "start": 0,
            "end": 266,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_74@0",
            "content": "Proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_74",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_75@0",
            "content": "G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2212 \u00b5 min = exp N n=1 log(\u00b5 n + \u03f5) 1/N \u2212 \u00b5 min \u2248 N n=1 \u00b5 1/N n \u2212 \u00b5 min . (9",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_75",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_76@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_76",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_77@0",
            "content": "Without loss of generality, assume the minimum value is \u00b5 min = \u00b5 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_77",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_77@1",
            "content": "By fixing \u00b5 2 , ..., \u00b5 N as constants, we obtain the gradient for (9) w.r.t. \u00b5 1 as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_77",
            "start": 70,
            "end": 152,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_78@0",
            "content": "1 N \u00b5 (1\u2212N )/N 1 N n=2 \u00b5 1/N n \u2212 1.(10)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_78",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_79@0",
            "content": "(9) obtains its maximum value when (10) equals 0, resulting in",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_79",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_80@0",
            "content": "\u00b5 1 = N N/(1\u2212N ) N n=2 \u00b5 1/(N \u22121) n . (11",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_80",
            "start": 0,
            "end": 40,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_81@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_81",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_82@0",
            "content": "By replacing \u00b5 min in ( 9) with ( 11), we have",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_82",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_83@0",
            "content": "G \u2227 (\u00b5 1 , ..., \u00b5 N ) \u2212 \u00b5 min \u2264 N 1/(1\u2212N ) N n=2 \u00b5 1/N (N \u22121)+1/N n \u2212N N/(1\u2212N ) N n=2 \u00b5 1/(N \u22121) n = (N 1/(1\u2212N ) \u2212 N N/(1\u2212N ) ) N n=2 \u00b5 1/(N \u22121) n .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_83",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_84@0",
            "content": "This completes the proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_84",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_85@0",
            "content": "In other words, the difference between G \u2227 and \u00b5 min is bounded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_85",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_85@1",
            "content": "When N = 2, the RHS of the inequality equals to 1/4 \u2022 \u00b5 n\u0338 =min , which makes G \u2227 closer to \u00b5 min when \u00b5 n\u0338 =min is smaller.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_85",
            "start": 65,
            "end": 188,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_85@2",
            "content": "This formulation results in a more stable and smooth gradient flow compared to minimum t-norm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_85",
            "start": 190,
            "end": 283,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_85@3",
            "content": "Moreover, It avoids exponential decay in the output when N > 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_85",
            "start": 285,
            "end": 347,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_85@4",
            "content": "It also facilitates neural learning when the exact clause is parameterized with attention scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_85",
            "start": 349,
            "end": 445,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_86@0",
            "content": "Evaluation With the neural logic operator defined above, the value for the head atom can be inferred once the value for each body atom is given.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_86",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_86@1",
            "content": "For grounded atoms over existential predicates, e.g., r m (s, a), we directly generate its value using a relational network F : R d \u00d7 R d \u2192 R M that takes the features of two constant arguments as input to produce a probability distribution over all the existential predicates r 1 , ..., r M :",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_86",
            "start": 145,
            "end": 437,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_87@0",
            "content": "F( hs , ha ) = softmax(W r tanh[ hs ; ha ; hs \u2212 ha ; hs \u2022 ha ]),",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_87",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_88@0",
            "content": "where \u00b5(r m (s, a)) equals the m-th entry of F( hs , ha ), and hs and ha are the outputs from the attentive reader.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_88",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_88@1",
            "content": "Similarly, h l k can be regarded as the feature of c l k generated from the attentive reader which is used to compute atom values with bridging entities, e.g., \u00b5(r m (s, c l k )).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_88",
            "start": 116,
            "end": 294,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_88@2",
            "content": "For l-hop grounded atoms over invented predicates {r l 1 (s, a), ..., r l M l (s, a)}, we compute their values according to the value of the clause body that defines them, e.g., \u00b5(F 0 (s, c 1 k )\u2227...\u2227F l (c l k , a)) using neural logic operators:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_88",
            "start": 296,
            "end": 541,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_89@0",
            "content": "\u00b5 l = max z\u2208Z l exp l t=0 S l t log(\u00b5 (zt,z t+1 ) + \u03f5) 1 (l+1)(12)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_89",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@0",
            "content": "Here \u00b5 l = [\u00b5(r l 1 (s, a)), ..., \u00b5(r l M l (s, a))] \u22a4 denotes the vector of the atom values formed by those l-hop invented predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@1",
            "content": "We denote by Z l = {(s, c 1 k , ..., c l k , a)} 1\u2264k\u2264K the set for all possible instantiations for l-hop reasoning and denote by z t the t-th constant of z \u2208 Z l .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 136,
            "end": 298,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@2",
            "content": "\u00b5 (zt,z t+1 ) = [\u00b5(r 1 (z t , z t+1 )), ..., \u00b5(r M (z t , z t+1 ))] \u22a4 is a vector of values for grounded atoms over existential predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 300,
            "end": 438,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@3",
            "content": "Thus, exp(\u2022) gives a neural approximation of logic conjunctions as shown in (8) over {F t (z t , z t+1 )} 0\u2264t\u2264l , each of which is a sparse selection of existential predicates using S l t .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 440,
            "end": 628,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@4",
            "content": "We use a max operator to generate the maximum score over all possible instantiations in Z l to represent the final truth probability of each invented predicate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 630,
            "end": 789,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@5",
            "content": "Intuitively, a relation between two entities should be satisfied as long as there is at least one instantiation that follows the rule.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 791,
            "end": 924,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@6",
            "content": "Also note that (12) has the effect that when S l t [i, j] \u2248 0, the corresponding predicate r j will have little effect on the value of its head r l i , which is in contrast to existing T-norms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 926,
            "end": 1118,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_90@7",
            "content": "The final value for q(s, a) is computed via",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_90",
            "start": 1120,
            "end": 1162,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_91@0",
            "content": "\u00b5(q(s, a))= max 1\u2264i\u2264H exp s i log([\u00b5 0 ; ...; \u00b5 L ] + \u03f5) ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_91",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_92@0",
            "content": "which selects the maximum score over H final clauses that define q(s, a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_92",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_92@1",
            "content": "We use the crossentropy loss over \u00b5(q(s, a)) as the final objective to train the entire model (except the word embeddings which are kept fixed) in an end-to-end manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_92",
            "start": 74,
            "end": 241,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_92@2",
            "content": "Here we organize the dataset according to subject-candidate pairs: (s, a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_92",
            "start": 243,
            "end": 316,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_92@3",
            "content": "We associate the ground-truth label y = 1 with (s, a) if a is the correct answer, otherwise, y = 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_92",
            "start": 318,
            "end": 416,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_93@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_93",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@0",
            "content": "We conduct experiments on two multi-hop reading comprehension datasets, namely WikiHop and MedHop (Welbl et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@1",
            "content": "The WikiHop dataset contains 43,738 training and 5,129 development instances ranging over 277 query relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 120,
            "end": 229,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@2",
            "content": "MedHop is a medical dataset containing 1,620 training and 342 development instances with a unique query relation, i.e., \"interact with\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 231,
            "end": 366,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@3",
            "content": "For WikiHop, we experiment with both non-contextual (follow (Weber et al., 2019)) named as DILR and contextual word embeddings (BERT (Devlin et al., 2019)) named as DILR-BERT to demonstrate our model's generalization ability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 368,
            "end": 592,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@4",
            "content": "For MedHop, we use the same setting following (Weber et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 594,
            "end": 660,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@5",
            "content": "We define M = 10 relations as existential predicates and M l = 5 invented predicates for each hop with (Weber et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 662,
            "end": 785,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@6",
            "content": "Clearly, DILR gives the best performances across all the baselines, demonstrating the advantage of combining deep attentive learning with logic reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 787,
            "end": 940,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@7",
            "content": "Though NLProlog also conducts logic reasoning, it is limited by the model's capacity and relies on the extraction accuracy of the NER tool.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 942,
            "end": 1080,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_94@8",
            "content": "Even with well-trained contextualized word embeddings (DILR-BERT), our model still brings consistent performance gains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_94",
            "start": 1082,
            "end": 1200,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_95@0",
            "content": "For a more thorough analysis, we take the entire WikiHop dataset and group the query relations in terms of the number of training instances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_95",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_95@1",
            "content": "As shown in and 4,462 development instances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_95",
            "start": 141,
            "end": 184,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_95@2",
            "content": "We report the micro-average accuracy scores over all the domains within each data group and their combinations in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_95",
            "start": 186,
            "end": 307,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_95@3",
            "content": "Clearly, our model achieves the best performances over all data groups.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_95",
            "start": 309,
            "end": 379,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_95@4",
            "content": "The margin is larger for D1 and D3, demonstrating the consistency of our proposed model with varying data sizes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_95",
            "start": 381,
            "end": 492,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_95@5",
            "content": "In fact, ILP could be beneficial when training data is not sufficient via learning of generalized rules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_95",
            "start": 494,
            "end": 597,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_96@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_96",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_97@0",
            "content": "To provide detailed analysis, we conduct ablation experiments on 6 datasets as shown in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_97",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_97@1",
            "content": "For fair demonstration, we pick one relation in D3 (Located), 2 relations in D2 (Occupation and Record) and 3 relations in D1 (Publisher, Producer, Country).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_97",
            "start": 97,
            "end": 253,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_97@2",
            "content": "The first four rows reflect the accuracies by varying the maximum allowed number of reasoning hops (L).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_97",
            "start": 255,
            "end": 357,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_97@3",
            "content": "Clearly, \u2264 0 Hop and \u2264 3 Hop produce lower accuracies because \u2264 0 Hop fails to model the bridging entities and \u2264 3 Hop could overfit the model given most of the questions only involve at most 2 reasoning hops.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_97",
            "start": 359,
            "end": 567,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@0",
            "content": "The middle part of Table 3 reflects the effect of each element of DILR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@1",
            "content": "Specifically, \u2212PI removes the invented predicates: remove ( 5), ( 6), ( 12) and replace U l with U in (7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 72,
            "end": 177,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@2",
            "content": "\u2212ILP removes the reasoner and uses a classifier on top of the attentive reader to produce the final predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 179,
            "end": 290,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@3",
            "content": "\u2212AR removes the attentive reader and uses NER tools to extract entities for reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 292,
            "end": 377,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@4",
            "content": "\u2212Rel only computes binary relations that decide whether two constants are related or not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 379,
            "end": 467,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@5",
            "content": "This demonstrates the effect of relational reasoning considering different relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 469,
            "end": 553,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@6",
            "content": "By comparison, it is evident that removing any component will suffer from non-trivial prediction loss, especially for ILP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 555,
            "end": 676,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@7",
            "content": "To verify the effect of the neural logic operator (NLO), we compare it with two T-norm operators, namely \"prod-T\" for product T-norm and \"min-T\" for minimum T-norm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 678,
            "end": 841,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_98@8",
            "content": "Clearly, NLO produces the best performances across all the experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_98",
            "start": 843,
            "end": 913,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@0",
            "content": "To provide a concrete view of how the attentive reader filters relevant information and how the generated clauses look like, we list three examples as shown in Table 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@1",
            "content": "The underlined texts have the maximum attention weights learned from the attentive reader.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 169,
            "end": 258,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@2",
            "content": "The bold texts indicate the query subject and the correct answer for each query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 260,
            "end": 339,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@3",
            "content": "Clearly, the attentive reader is able to select bridging entities relevant to the answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 341,
            "end": 429,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@4",
            "content": "The third column lists some learned clauses from the reasoner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 431,
            "end": 492,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@5",
            "content": "The first row of each example shows the clauses that define an invented predicate and the second row shows the final clause that entails the query relation 4 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 494,
            "end": 652,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@6",
            "content": "We use ab- 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 654,
            "end": 666,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@7",
            "content": "Hockey is a family of sports ... breviated entities as the constants in each grounded atom (e.g., \"CC\" is short for \"Chris Church\").",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 668,
            "end": 799,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_99@8",
            "content": "The two clauses for the first example could be read as: if Chris Church and Massachusetts has relation r 7 , and Massachusetts and United States has relation r 2 , then the country of Chris Church is United States.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_99",
            "start": 801,
            "end": 1014,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_100@0",
            "content": "We further demonstrate the robustness of DILR by varying model parameters, as shown in Figure 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_100",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_100@1",
            "content": "The top subplots reveal the accuracies on MedHop and Country datasets when changing the number of final clauses H (left) and the number of existential predicates M (right).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_100",
            "start": 97,
            "end": 268,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_100@2",
            "content": "The subplot in the bottom depicts the accuracies when varying the number of instantiations K of the bridging contexts for Genre dataset under both DILR and BERT-DILR models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_100",
            "start": 270,
            "end": 442,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_100@3",
            "content": "We shall observe that the performances are relatively stable given that the total number of testing examples are less than 400 for each dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_100",
            "start": 444,
            "end": 587,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_101@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_101",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_102@0",
            "content": "We propose an end-to-end model DILR to solve the problem of multi-hop reading comprehension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_102",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_102@1",
            "content": "DILR smoothly connects a hierarchical attentive reader with a multi-hop reasoner to conduct automatic information extraction and complex reasonkeeping those predicates with scores higher than 0.4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_102",
            "start": 93,
            "end": 288,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_102@2",
            "content": "ing. We also introduce differentiable logic operators to induce valid clauses with smooth and stable gradient-based learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_102",
            "start": 290,
            "end": 414,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_102@3",
            "content": "Extensive experiments reveal consistent improvements brought by DILR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_102",
            "start": 416,
            "end": 484,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_103@0",
            "content": "UNKNOWN, None, , Massachusetts is the most populous state in, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_103",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_104@0",
            "content": "UNKNOWN, None, , Massachusetts. r7(CC, M ) \u2227 r2, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_104",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_105@0",
            "content": "Jacob References, Marcus Andreas, Trevor Rohrbach, Dan Darrell,  Klein, Neural module networks, 2016-06-27, 2016 IEEE Conference on Computer Vision and Pattern Recognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_105",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_106@0",
            "content": "UNKNOWN, None, 2018, Logical rule induction and theory learning using neural theorem proving, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_106",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_107@0",
            "content": "UNKNOWN, None, 1910, Multi-hop question answering via reasoning chains. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_107",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_108@0",
            "content": "Xinyun Chen, Chen Liang, Adams Yu, Denny Zhou, Dawn Song, V Quoc,  Le, Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_108",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_109@0",
            "content": "Christopher Clark, Matt Gardner, Simple and effective multi-paragraph reading comprehension, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_109",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_110@0",
            "content": "UNKNOWN, None, 2016, Tensorlog: A differentiable deductive database, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_110",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_111@0",
            "content": "Nicola De Cao, Wilker Aziz, Ivan Titov, Question answering by reasoning across documents with graph convolutional networks, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_111",
            "start": 0,
            "end": 274,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_112@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_112",
            "start": 0,
            "end": 294,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_113@0",
            "content": "Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William Cohen, Ruslan Salakhutdinov, Neural models for reasoning over multiple mentions using coreference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_113",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_114@0",
            "content": "Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, William Cohen, Differentiable reasoning over a virtual knowledge base, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_114",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_115@0",
            "content": "Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang, Cognitive graph for multi-hop reading comprehension at scale, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_115",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_116@0",
            "content": "Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, Denny Zhou, Neural logic machines, 2019-05-06, 7th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_116",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_117@0",
            "content": "Richard Evans, Edward Grefenstette, Learning explanatory rules from noisy data, 2018, J. Artif. Intelligent Res, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_117",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_118@0",
            "content": "V Manoel, Gerson Fran\u00e7a, Artur Zaverucha,  D'avila Garcez, Fast relational learning using bottom clause propositionalization with artificial neural networks, 2014, Mach. Learn, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_118",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_119@0",
            "content": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, Li Guo, Jointly embedding knowledge graphs and logical rules, 2016, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_119",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_120@0",
            "content": "Nitish Gupta, Kevin Lin, Dan Roth, Sameer Singh, Matt Gardner, Neural module networks for reasoning over text, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_120",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_121@0",
            "content": "Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric Xing, Harnessing deep neural networks with logic rules, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_121",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_122@0",
            "content": "Yichen Jiang, Mohit Bansal, Self-assembling modular networks for interpretable multi-hop reasoning, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_122",
            "start": 0,
            "end": 283,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_123@0",
            "content": "Yichen Jiang, Nitish Joshi, Yen-Chun Chen, Mohit Bansal, Explore, propose, and assemble: An interpretable model for multi-hop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_123",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_124@0",
            "content": "UNKNOWN, None, 2013, Triangular norms, Springer Science and Business Media.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_124",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_125@0",
            "content": "Souvik Kundu, Tushar Khot, Ashish Sabharwal, Peter Clark, Exploiting explicit paths for multihop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_125",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_126@0",
            "content": "Tao Li, Vivek Srikumar, Augmenting neural networks with first-order logic, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_126",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_127@0",
            "content": "Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt, Deepproblog: Neural probabilistic logic programming, 2018-12-03, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_127",
            "start": 0,
            "end": 265,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_128@0",
            "content": "F Andr\u00e9, Ram\u00f3n Martins,  Fernandez Astudillo, From softmax to sparsemax: A sparse model of attention and multi-label classification, 2016-06-19, Proceedings of the 33nd International Conference on Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_128",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_129@0",
            "content": "Sewon Min, Victor Zhong, Luke Zettlemoyer, Hannaneh Hajishirzi, Multi-hop reading comprehension through question decomposition and rescoring, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_129",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_130@0",
            "content": "Pasquale Minervini, Matko Bosnjak, Tim Rockt\u00e4schel, Sebastian Riedel, Edward Grefenstette, Differentiable reasoning on large knowledge bases and natural language, 2020, AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_130",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_131@0",
            "content": "Pasquale Minervini, Thomas Demeester, Tim Rockt\u00e4schel, Sebastian Riedel, Adversarial sets for regularised neural link predictors, 2017, UAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_131",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_132@0",
            "content": "Stephen Muggleton, Inductive logic programming, 1991, New Generation Computing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_132",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_133@0",
            "content": "Lin Qiu, Yunxuan Xiao, Yanru Qu, Hao Zhou, Lei Li, Weinan Zhang, Yong Yu, Dynamically fused graph network for multi-hop reasoning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_133",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_134@0",
            "content": "Meng Qu, Jian Tang, Probabilistic logic neural networks for reasoning, 2019-12-08, Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_134",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_135@0",
            "content": "Tim Rockt\u00e4schel, Sebastian Riedel, End-toend differentiable proving, 2017-12-04, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_135",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_136@0",
            "content": "UNKNOWN, None, 2018, Exploring graph-structured passage representation for multihop reading comprehension with graph neural networks, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_136",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_137@0",
            "content": "Zeyun Tang, Yongliang Shen, Xinyin Ma, Wei Xu, Jiale Yu, Weiming Lu, Multi-hop reading comprehension across documents with path-based graph convolutional network, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_137",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_138@0",
            "content": "Ming Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, Bowen Zhou, Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_138",
            "start": 0,
            "end": 264,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_139@0",
            "content": "Po-Wei Wang, Priya Donti, Bryan Wilder, J Kolter, Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver, 2019-06, Proceedings of the 36th International Conference on Machine Learning, ICML 2019, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_139",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_140@0",
            "content": "Wenya Wang,  Sinno Jialin Pan, Integrating deep learning with logic fusion for information extraction, 2020, AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_140",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_141@0",
            "content": "Yizhong Wang, Kai Liu, Jing Liu, Wei He, Yajuan Lyu, Hua Wu, Sujian Li, Haifeng Wang, Multipassage machine reading comprehension with crosspassage answer verification, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_141",
            "start": 0,
            "end": 274,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_142@0",
            "content": "Leon Weber, Pasquale Minervini, Jannes M\u00fcnchmeyer, Ulf Leser, Tim Rockt\u00e4schel, NLProlog: Reasoning with weak unification for question answering in natural language, 2019, Proceedings of the 57th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_142",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_143@0",
            "content": "UNKNOWN, None, , Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_143",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_144@0",
            "content": "Johannes Welbl, Pontus Stenetorp, Sebastian Riedel, Constructing datasets for multi-hop reading comprehension across documents, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_144",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_145@0",
            "content": "Meixi Wu, Wenya Wang, Sinno Jialin Pan, Deep Weighted MaxSAT for Aspect-based Opinion Extraction, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_145",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_146@0",
            "content": "Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van Den Broeck, A semantic loss function for deep learning with symbolic knowledge, 2018-07-10, Proceedings of the 35th International Conference on Machine Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_146",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_147@0",
            "content": "Fan Yang, Zhilin Yang, William Cohen, Differentiable learning of logical rules for knowledge base reasoning, 2017-12-04, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_147",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_148@0",
            "content": "Yuan Yang, Le Song, Learn to explain efficiently via neural logic inductive learning, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_148",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_149@0",
            "content": "Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher, Coarse-grain fine-grain coattention network for multi-evidence question answering, 2019-05-06, 7th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_149",
            "start": 0,
            "end": 221,
            "label": {}
        },
        {
            "ix": "141-ARR_v2_150@0",
            "content": "Yimeng Zhuang, Huadong Wang, Token-level dynamic self-attention network for multi-passage reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v2_150",
            "start": 0,
            "end": 208,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_1",
            "tgt_ix": "141-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_1",
            "tgt_ix": "141-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_2",
            "tgt_ix": "141-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_4",
            "tgt_ix": "141-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_5",
            "tgt_ix": "141-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_6",
            "tgt_ix": "141-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_7",
            "tgt_ix": "141-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_10",
            "tgt_ix": "141-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_11",
            "tgt_ix": "141-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_12",
            "tgt_ix": "141-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_15",
            "tgt_ix": "141-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_13",
            "tgt_ix": "141-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_13",
            "tgt_ix": "141-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_13",
            "tgt_ix": "141-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_13",
            "tgt_ix": "141-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_16",
            "tgt_ix": "141-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_18",
            "tgt_ix": "141-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_19",
            "tgt_ix": "141-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_20",
            "tgt_ix": "141-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_21",
            "tgt_ix": "141-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_22",
            "tgt_ix": "141-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_23",
            "tgt_ix": "141-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_24",
            "tgt_ix": "141-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_25",
            "tgt_ix": "141-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_26",
            "tgt_ix": "141-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_27",
            "tgt_ix": "141-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_30",
            "tgt_ix": "141-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_30",
            "tgt_ix": "141-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_31",
            "tgt_ix": "141-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_33",
            "tgt_ix": "141-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_34",
            "tgt_ix": "141-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_35",
            "tgt_ix": "141-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_36",
            "tgt_ix": "141-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_37",
            "tgt_ix": "141-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_38",
            "tgt_ix": "141-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_39",
            "tgt_ix": "141-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_40",
            "tgt_ix": "141-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_41",
            "tgt_ix": "141-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_43",
            "tgt_ix": "141-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_44",
            "tgt_ix": "141-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_45",
            "tgt_ix": "141-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_46",
            "tgt_ix": "141-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_47",
            "tgt_ix": "141-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_48",
            "tgt_ix": "141-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_49",
            "tgt_ix": "141-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_50",
            "tgt_ix": "141-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_51",
            "tgt_ix": "141-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_52",
            "tgt_ix": "141-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_53",
            "tgt_ix": "141-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_53",
            "tgt_ix": "141-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_54",
            "tgt_ix": "141-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_57",
            "tgt_ix": "141-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_58",
            "tgt_ix": "141-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_59",
            "tgt_ix": "141-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_60",
            "tgt_ix": "141-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_61",
            "tgt_ix": "141-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_62",
            "tgt_ix": "141-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_63",
            "tgt_ix": "141-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_64",
            "tgt_ix": "141-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_67",
            "tgt_ix": "141-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_68",
            "tgt_ix": "141-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_69",
            "tgt_ix": "141-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_70",
            "tgt_ix": "141-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_71",
            "tgt_ix": "141-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_72",
            "tgt_ix": "141-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_73",
            "tgt_ix": "141-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_74",
            "tgt_ix": "141-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_75",
            "tgt_ix": "141-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_76",
            "tgt_ix": "141-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_77",
            "tgt_ix": "141-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_78",
            "tgt_ix": "141-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_79",
            "tgt_ix": "141-ARR_v2_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_80",
            "tgt_ix": "141-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_81",
            "tgt_ix": "141-ARR_v2_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_82",
            "tgt_ix": "141-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_83",
            "tgt_ix": "141-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_84",
            "tgt_ix": "141-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_85",
            "tgt_ix": "141-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_86",
            "tgt_ix": "141-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_87",
            "tgt_ix": "141-ARR_v2_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_88",
            "tgt_ix": "141-ARR_v2_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_89",
            "tgt_ix": "141-ARR_v2_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_91",
            "tgt_ix": "141-ARR_v2_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_92",
            "tgt_ix": "141-ARR_v2_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_93",
            "tgt_ix": "141-ARR_v2_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_93",
            "tgt_ix": "141-ARR_v2_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_93",
            "tgt_ix": "141-ARR_v2_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_93",
            "tgt_ix": "141-ARR_v2_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_95",
            "tgt_ix": "141-ARR_v2_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_97",
            "tgt_ix": "141-ARR_v2_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_99",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_100",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_96",
            "tgt_ix": "141-ARR_v2_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_96",
            "tgt_ix": "141-ARR_v2_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_96",
            "tgt_ix": "141-ARR_v2_99",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_96",
            "tgt_ix": "141-ARR_v2_100",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_96",
            "tgt_ix": "141-ARR_v2_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_101",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_100",
            "tgt_ix": "141-ARR_v2_101",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_101",
            "tgt_ix": "141-ARR_v2_102",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_101",
            "tgt_ix": "141-ARR_v2_102",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v2_0",
            "tgt_ix": "141-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_1",
            "tgt_ix": "141-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_2",
            "tgt_ix": "141-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_2",
            "tgt_ix": "141-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_2",
            "tgt_ix": "141-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_2",
            "tgt_ix": "141-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_2",
            "tgt_ix": "141-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_2",
            "tgt_ix": "141-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_3",
            "tgt_ix": "141-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_4",
            "tgt_ix": "141-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_4",
            "tgt_ix": "141-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_4",
            "tgt_ix": "141-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_5",
            "tgt_ix": "141-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_6",
            "tgt_ix": "141-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_7",
            "tgt_ix": "141-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_8",
            "tgt_ix": "141-ARR_v2_8@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_9",
            "tgt_ix": "141-ARR_v2_9@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_10",
            "tgt_ix": "141-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_10",
            "tgt_ix": "141-ARR_v2_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_10",
            "tgt_ix": "141-ARR_v2_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_10",
            "tgt_ix": "141-ARR_v2_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_10",
            "tgt_ix": "141-ARR_v2_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_11",
            "tgt_ix": "141-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_12",
            "tgt_ix": "141-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_12",
            "tgt_ix": "141-ARR_v2_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_13",
            "tgt_ix": "141-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_14@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_14",
            "tgt_ix": "141-ARR_v2_14@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_15",
            "tgt_ix": "141-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_15",
            "tgt_ix": "141-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_15",
            "tgt_ix": "141-ARR_v2_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_16",
            "tgt_ix": "141-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_16",
            "tgt_ix": "141-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_16",
            "tgt_ix": "141-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_16",
            "tgt_ix": "141-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_16",
            "tgt_ix": "141-ARR_v2_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_17",
            "tgt_ix": "141-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_18",
            "tgt_ix": "141-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_18",
            "tgt_ix": "141-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_18",
            "tgt_ix": "141-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_18",
            "tgt_ix": "141-ARR_v2_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_19",
            "tgt_ix": "141-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_19",
            "tgt_ix": "141-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_20",
            "tgt_ix": "141-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_21",
            "tgt_ix": "141-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_21",
            "tgt_ix": "141-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_21",
            "tgt_ix": "141-ARR_v2_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_21",
            "tgt_ix": "141-ARR_v2_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_21",
            "tgt_ix": "141-ARR_v2_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_21",
            "tgt_ix": "141-ARR_v2_21@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_22",
            "tgt_ix": "141-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_22",
            "tgt_ix": "141-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_23",
            "tgt_ix": "141-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_24",
            "tgt_ix": "141-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_25",
            "tgt_ix": "141-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_26",
            "tgt_ix": "141-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_26",
            "tgt_ix": "141-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_26",
            "tgt_ix": "141-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_26",
            "tgt_ix": "141-ARR_v2_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_26",
            "tgt_ix": "141-ARR_v2_26@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_27",
            "tgt_ix": "141-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_28",
            "tgt_ix": "141-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_29",
            "tgt_ix": "141-ARR_v2_29@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_30",
            "tgt_ix": "141-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_31",
            "tgt_ix": "141-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_31",
            "tgt_ix": "141-ARR_v2_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_31",
            "tgt_ix": "141-ARR_v2_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_31",
            "tgt_ix": "141-ARR_v2_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_32",
            "tgt_ix": "141-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_33",
            "tgt_ix": "141-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_33",
            "tgt_ix": "141-ARR_v2_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_33",
            "tgt_ix": "141-ARR_v2_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_34",
            "tgt_ix": "141-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_35",
            "tgt_ix": "141-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_35",
            "tgt_ix": "141-ARR_v2_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_35",
            "tgt_ix": "141-ARR_v2_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_36",
            "tgt_ix": "141-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_37",
            "tgt_ix": "141-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_37",
            "tgt_ix": "141-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_37",
            "tgt_ix": "141-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_38",
            "tgt_ix": "141-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_38",
            "tgt_ix": "141-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_39",
            "tgt_ix": "141-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_40",
            "tgt_ix": "141-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_40",
            "tgt_ix": "141-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_40",
            "tgt_ix": "141-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_41",
            "tgt_ix": "141-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_42",
            "tgt_ix": "141-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_43",
            "tgt_ix": "141-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_43",
            "tgt_ix": "141-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_44",
            "tgt_ix": "141-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_45",
            "tgt_ix": "141-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_46",
            "tgt_ix": "141-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_47",
            "tgt_ix": "141-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_47",
            "tgt_ix": "141-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_47",
            "tgt_ix": "141-ARR_v2_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_48",
            "tgt_ix": "141-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_49",
            "tgt_ix": "141-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_49",
            "tgt_ix": "141-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_49",
            "tgt_ix": "141-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_49",
            "tgt_ix": "141-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_49",
            "tgt_ix": "141-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_50",
            "tgt_ix": "141-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_51",
            "tgt_ix": "141-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_52",
            "tgt_ix": "141-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_53",
            "tgt_ix": "141-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_54",
            "tgt_ix": "141-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_54",
            "tgt_ix": "141-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_54",
            "tgt_ix": "141-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_54",
            "tgt_ix": "141-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_54",
            "tgt_ix": "141-ARR_v2_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_55",
            "tgt_ix": "141-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_56@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_56@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_56",
            "tgt_ix": "141-ARR_v2_56@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_57",
            "tgt_ix": "141-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_58",
            "tgt_ix": "141-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_59",
            "tgt_ix": "141-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_59",
            "tgt_ix": "141-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_59",
            "tgt_ix": "141-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_59",
            "tgt_ix": "141-ARR_v2_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_59",
            "tgt_ix": "141-ARR_v2_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_60",
            "tgt_ix": "141-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_61",
            "tgt_ix": "141-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_61",
            "tgt_ix": "141-ARR_v2_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_61",
            "tgt_ix": "141-ARR_v2_61@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_61",
            "tgt_ix": "141-ARR_v2_61@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_62",
            "tgt_ix": "141-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_62",
            "tgt_ix": "141-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_62",
            "tgt_ix": "141-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_63",
            "tgt_ix": "141-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_64",
            "tgt_ix": "141-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_64",
            "tgt_ix": "141-ARR_v2_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_64",
            "tgt_ix": "141-ARR_v2_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_64",
            "tgt_ix": "141-ARR_v2_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_65",
            "tgt_ix": "141-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_66@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_66@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_66",
            "tgt_ix": "141-ARR_v2_66@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_67",
            "tgt_ix": "141-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_68",
            "tgt_ix": "141-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_68",
            "tgt_ix": "141-ARR_v2_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_68",
            "tgt_ix": "141-ARR_v2_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_69",
            "tgt_ix": "141-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_70",
            "tgt_ix": "141-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_71",
            "tgt_ix": "141-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_72",
            "tgt_ix": "141-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_72",
            "tgt_ix": "141-ARR_v2_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_72",
            "tgt_ix": "141-ARR_v2_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_72",
            "tgt_ix": "141-ARR_v2_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_73",
            "tgt_ix": "141-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_74",
            "tgt_ix": "141-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_75",
            "tgt_ix": "141-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_76",
            "tgt_ix": "141-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_77",
            "tgt_ix": "141-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_77",
            "tgt_ix": "141-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_78",
            "tgt_ix": "141-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_79",
            "tgt_ix": "141-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_80",
            "tgt_ix": "141-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_81",
            "tgt_ix": "141-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_82",
            "tgt_ix": "141-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_83",
            "tgt_ix": "141-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_84",
            "tgt_ix": "141-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_85",
            "tgt_ix": "141-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_85",
            "tgt_ix": "141-ARR_v2_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_85",
            "tgt_ix": "141-ARR_v2_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_85",
            "tgt_ix": "141-ARR_v2_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_85",
            "tgt_ix": "141-ARR_v2_85@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_86",
            "tgt_ix": "141-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_86",
            "tgt_ix": "141-ARR_v2_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_87",
            "tgt_ix": "141-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_88",
            "tgt_ix": "141-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_88",
            "tgt_ix": "141-ARR_v2_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_88",
            "tgt_ix": "141-ARR_v2_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_89",
            "tgt_ix": "141-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_90",
            "tgt_ix": "141-ARR_v2_90@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_91",
            "tgt_ix": "141-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_92",
            "tgt_ix": "141-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_92",
            "tgt_ix": "141-ARR_v2_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_92",
            "tgt_ix": "141-ARR_v2_92@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_92",
            "tgt_ix": "141-ARR_v2_92@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_93",
            "tgt_ix": "141-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_94",
            "tgt_ix": "141-ARR_v2_94@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_95",
            "tgt_ix": "141-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_95",
            "tgt_ix": "141-ARR_v2_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_95",
            "tgt_ix": "141-ARR_v2_95@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_95",
            "tgt_ix": "141-ARR_v2_95@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_95",
            "tgt_ix": "141-ARR_v2_95@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_95",
            "tgt_ix": "141-ARR_v2_95@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_96",
            "tgt_ix": "141-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_97",
            "tgt_ix": "141-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_97",
            "tgt_ix": "141-ARR_v2_97@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_97",
            "tgt_ix": "141-ARR_v2_97@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_97",
            "tgt_ix": "141-ARR_v2_97@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_98",
            "tgt_ix": "141-ARR_v2_98@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_99",
            "tgt_ix": "141-ARR_v2_99@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_100",
            "tgt_ix": "141-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_100",
            "tgt_ix": "141-ARR_v2_100@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_100",
            "tgt_ix": "141-ARR_v2_100@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_100",
            "tgt_ix": "141-ARR_v2_100@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_101",
            "tgt_ix": "141-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_102",
            "tgt_ix": "141-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_102",
            "tgt_ix": "141-ARR_v2_102@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_102",
            "tgt_ix": "141-ARR_v2_102@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_102",
            "tgt_ix": "141-ARR_v2_102@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_103",
            "tgt_ix": "141-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_104",
            "tgt_ix": "141-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_105",
            "tgt_ix": "141-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_106",
            "tgt_ix": "141-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_107",
            "tgt_ix": "141-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_108",
            "tgt_ix": "141-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_109",
            "tgt_ix": "141-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_110",
            "tgt_ix": "141-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_111",
            "tgt_ix": "141-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_112",
            "tgt_ix": "141-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_113",
            "tgt_ix": "141-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_114",
            "tgt_ix": "141-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_115",
            "tgt_ix": "141-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_116",
            "tgt_ix": "141-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_117",
            "tgt_ix": "141-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_118",
            "tgt_ix": "141-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_119",
            "tgt_ix": "141-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_120",
            "tgt_ix": "141-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_121",
            "tgt_ix": "141-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_122",
            "tgt_ix": "141-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_123",
            "tgt_ix": "141-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_124",
            "tgt_ix": "141-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_125",
            "tgt_ix": "141-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_126",
            "tgt_ix": "141-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_127",
            "tgt_ix": "141-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_128",
            "tgt_ix": "141-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_129",
            "tgt_ix": "141-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_130",
            "tgt_ix": "141-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_131",
            "tgt_ix": "141-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_132",
            "tgt_ix": "141-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_133",
            "tgt_ix": "141-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_134",
            "tgt_ix": "141-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_135",
            "tgt_ix": "141-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_136",
            "tgt_ix": "141-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_137",
            "tgt_ix": "141-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_138",
            "tgt_ix": "141-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_139",
            "tgt_ix": "141-ARR_v2_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_140",
            "tgt_ix": "141-ARR_v2_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_141",
            "tgt_ix": "141-ARR_v2_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_142",
            "tgt_ix": "141-ARR_v2_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_143",
            "tgt_ix": "141-ARR_v2_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_144",
            "tgt_ix": "141-ARR_v2_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_145",
            "tgt_ix": "141-ARR_v2_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_146",
            "tgt_ix": "141-ARR_v2_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_147",
            "tgt_ix": "141-ARR_v2_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_148",
            "tgt_ix": "141-ARR_v2_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_149",
            "tgt_ix": "141-ARR_v2_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v2_150",
            "tgt_ix": "141-ARR_v2_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 951,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "141-ARR",
        "version": 2
    }
}