{
    "nodes": [
        {
            "ix": "141-ARR_v1_0",
            "content": "Deep Inductive Logic Reasoning for Multi-Hop Reading Comprehension",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_2",
            "content": "Multi-hop reading comprehension requires the ability to reason across multiple documents. On the one hand, deep learning approaches only implicitly encode query-related information into distributed embeddings which fail to uncover the discrete relational reasoning process to infer the correct answer. On the other hand, logic-based approaches provide interpretable rules to infer the target answer, but mostly work on structured data where entities and relations are well-defined. In this paper, we propose a deep-learning based inductive logic reasoning method that firstly extracts query-related (candidate-related) information, and then conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation. The reasoning process is accomplished via attentive memories with novel differentiable logic operators. To demonstrate the effectiveness of our model, we evaluate it on two reading comprehension datasets, namely WikiHop and MedHop.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "141-ARR_v1_4",
            "content": "Reasoning has been extensively studied in the structured domain, e.g., knowledge base completion which infers missing facts given background entities and relations. However, when the background knowledge is expressed in natural languages, as shown in the multi-hop reading comprehension problem with triplet-form questions (Welbl et al., 2018), it becomes difficult to conduct complex reasoning. For example, consider the question \"country(Moonhole, ?)\", given the following documents:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_5",
            "content": "\"Moonhole is a private community on the island of Bequia. Moonhole was founded by Thomas and Gladys Johnston in the 1960s.\" \"Gladys Johnston was born in United States.\"",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_6",
            "content": "\"Bequia is an island and is part of the country of Saint Vincent and the Grenadines\"",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_7",
            "content": "The correct answer should be Saint Vincent and the Grenadines instead of United States although both entities have co-occurring contexts with Moonhole.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_8",
            "content": "Deep learning methods for multi-hop reading comprehension (RC) can be categorized as: 1) Memory-based models Zhuang and Wang, 2019) that learn to generate query-aware context representations. 2) Graph-based approaches (Song et al., 2018;De Cao et al., 2019) that use graph neural networks to propagate information based on pre-constructed entity (context) graphs. 3) Neural Module networks (Andreas et al., 2016) that decompose the question into a series of action modules Min et al., 2019). However, DNNs only implicitly encode relevant contexts but fail to explicitly uncover the underlying relational compositions for complex inference. With the above example, DNNs may encode Bequia and Gladys Johnson into 1-hop features, given both entities co-occur with the query Moonhole. As a result, the model may predict United States by linking it with Gladys Johnson instead of the correct answer Saint Vincent and the Grenadines. However, a human would easily produce the correct answer given the knowledge \"if A is in B and B is part of country C, then A is in country C\" and by examining the relations between each entity pair co-occurred in the context.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_9",
            "content": "Inductive logic programming (ILP) (Muggleton, 1991) aligns with human reasoning by inducing interpretable rules to entail positive but not negative examples. To answer the previous query, ILP could generate this rule: located_in(X, Z)\u2227 country(Z, Y ) \u21d2 country(X, Y ). Combining deep learning with ILP is a promising direction to benefit from both worlds (Evans and Grefenstette, 2018;Dong et al., 2019). Deep logic models have been proposed for structured knowledge base completion (Minervini et al., 2017(Minervini et al., , 2020Yang and Song, 2020;Yang et al., 2017). However, it becomes much more challenging when dealing with natural language inputs, as in the case of multi-hop reading comprehension. Weber et al. (2019) proposed to combine a symbolic reasoner: prolog, with weak unifications based on distributed embeddings as a backwardchaining theorem prover to induce feasible rules for multi-hop reasoning. However, their work relies on the accuracies of pre-extracted NERs and is limited by the number of rule templates.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_10",
            "content": "To address these limitations, we propose a novel end-to-end combination of deep learning and logic reasoning termed Deep Inductive Logic Reasoning (DILR). It consists of two components: 1) a hierarchical attentive reader that filters query-related and candidate-related information from given documents; 2) a multi-hop reasoner that conducts inductive logic reasoning by attentively selecting proper predicates to form candidate rules and refines them upon given examples. We introduce novel differentiable logic operators combined with attention mechanisms for smooth back-propagation. Compared to existing deep logic models, we build connections between raw text inputs and the symbolic domain by mapping high-level semantic representations to logic predicates and instantiating logic variables with neural representations to conduct relational reasoning. We also parameterize the entire process for end-to-end differentiable learning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_11",
            "content": "The contributions of this work include: 1) We introduce a novel smooth connection between deep representation learning with logic reasoning by associating distributed representations with discrete logic predicates and their probabilistic evaluations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_12",
            "content": "2) We propose deep-learning-based inductive logic programming via attentive memories and differentiable logic operators for the task of multi-hop reading comprehension considering the number of reasoning steps. 3) We provide comprehensive evaluations of our model on two benchmark datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_13",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "141-ARR_v1_14",
            "content": "Multi-Hop Reading Comprehension Recent works for multi-hop RC include memory-based methods which apply attentions to iteratively update query and context representations considering their interactions (Dhingra et al., 2018;Clark and Gardner, 2018;Zhuang and Wang, 2019;Yichen Jiang and Bansal, 2019). To explicitly incorporate entity connections, De Cao et al. ( 2019), Ding et al. (2019), Qiu et al. (2019), Tang et al. (2020), Song et al. (2018) and Tu et al. (2019) build entity graphs and apply Graph Neural Networks for information propagation. Kundu et al. (2019) formalizes reasoning as a path-finding problem with neural encoding to rank candidate paths. Path modeling is also adopted in using pointer networks. However, these approaches only focus on local information without the ability to generalize, and some of them rely on NER tools. Dhingra et al. (2020) converts texts into a virtual knowledge based for retrieval, but requires an entity database. Another category uses neural module networks Min et al., 2019;Gupta et al., 2020;Chen et al., 2020) to decompose the question into a series of actions, each parameterized with a neural module, which also fail to explicitly uncover the underlying logic for reasoning. Deep Learning with Logic Reasoning Neurosymbolic learning aims to integrate deep learning's ability on dealing with uncertainty and logic programming's ability on reasoning. Deep neural networks have been used to parameterize discrete logic operators and logic atoms (Fran\u00e7a et al., 2014;Hu et al., 2016;Manhaeve et al., 2018;Xu et al., 2018;Li and Srikumar, 2019;Wu et al., 2020) given the logic rules. A more challenging direction is inductive logic programming that automatically learns rules through representation learning and differentiable backpropagation (Evans and Grefenstette, 2018;Dong et al., 2019;Yang and Song, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_15",
            "content": "Neuro-symbolic learning has been applied to knowledge-base completion through logic embeddings (Guo et al., 2016), tensor operations (Cohen, 2016;, adversarial learning (Minervini et al., 2017), variational learning (Qu and Tang, 2019) or attentions (Yang and Song, 2020). Differentiable theorem proving has also been proposed with weak unifications and backward chaining Campero et al., 2018;Minervini et al., 2020). However, unlike multi-hop RC, knowledge-base completion only takes structured inputs without the need to address language ambiguity. The most related work to ours is NLProlog (Weber et al., 2019), a neural theorem prover for multi-hop RC by converting language utterances to distributed embeddings. However, NLProlog relies on a NER tool to extract entities and its expressiveness is limited by the number of rule templates.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_16",
            "content": "Background",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "141-ARR_v1_17",
            "content": "We focus on multi-hop reading comprehension tasks containing explicit query types which align with the standard ILP setting. Formally, for each RC problem, we are given a set of documents D = {D 1 , ..., D n }, a structured query in the form of a relational triplet (s, q, ?) where s denotes the subject of the relation q, and a list of candidate answers A = {a 1 , ..., a m }. The task is to select an answer a \u2208 A such that q(s, a) is satisfied, i.e., a is the object of relation q given the subject s. For example, country(M oonhole, ?) is a query asking for the country where Moonhole is located. This task could be converted into an ILP problem with the formal definition as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_18",
            "content": "Definition 3.1 (Inductive Logic Programming). Given a logic theory B representing the background knowledge (facts), a set of positive examples E + and a set of negative examples E \u2212 , an ILP system aims to derive a hypothesis H which entails all the positive and none of the negative examples:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_19",
            "content": "B \u2227 H |= \u03b3 for \u03b3 \u2208 E + . B \u2227 H \u0338 |= \u03b3 for \u03b3 \u2208 E \u2212 .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_20",
            "content": "The hypothesis H is a logic program consisting of definite clauses b 1 \u2227 ... \u2227 b k \u21d2 h where b 1 , ..., b k and h are logic atoms. The LHS of \"\u21d2\" is the clause body and h is the head. An atom is composed of a predicate and its arguments, e.g., h = located_in(X, Y ) with predicate \"located_in\" and arguments X, Y . A ground atom is obtained by instantiating variables in the arguments with constants, e.g., X = \"US\". We use \u00b5(\u2022) to denote the value of an atom or a clause. For smooth optimization, we assign \u00b5(\u2022) \u2208 [0, 1] which indicates the probability of the atom or clause being true.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_21",
            "content": "For multi-hop reading comprehension, we treat the query relation q(X, Y ) as the head atom of the clauses to be induced. The correct answer a + i from each problem forms the set of positive examples",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_22",
            "content": "E + ={q(s i , a + i )} N + i=1 ,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_23",
            "content": "and the incorrect answer a \u2212 j forms the set of negative examples",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_24",
            "content": "E \u2212 ={q(s j , a \u2212 j )} N \u2212 j=1 .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_25",
            "content": "Here we use lower cases: s i , a + i , a \u2212 j to represent constants and upper cases: X, Y to represent variables. The predicates in the logic domain correspond to pairwise relations between two entities 1 . To differentiate the number of inference steps, we define a l-hop reasoning clause as F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 )\u21d2r(X 0 , X l+1 ) with l denoting the number of extra arguments as bridging entities in the rule body except those in the head atom. Here each subclause F t (X t , X t+1 ) can be one or a conjunction (\u2227) of 2-ary atoms 1 We restrict each atom as a 2-ary atom that takes exactly 2 arguments, analogical to relations in the knowledge base.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_26",
            "content": "taking only X t and X t+1 as arguments, e.g.,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_27",
            "content": "F t (X t , X t+1 ) = r 1 (X t , X t+1 ) \u2227 r 2 (X t , X t+1 ).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_28",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "141-ARR_v1_29",
            "content": "Overall, DILR simulates multi-hop reasoning processes considering different number of inference steps. It is an end-to-end framework consisting of two components: a Hierarchical Attentive Reader and a Multi-hop Reasoner. The attentive reader learns to select relevant information from the given documents to produce query-aware, candidateaware and bridging entity representations. These representations are passed to the multi-hop reasoner to instantiate logic atoms in order to generate and evaluate clauses that are relevant to the query relation. The multi-hop reasoner conducts rule induction via attentive memories that softly select atoms to form new clauses and novel differentiable logic operators that produce probabilistic values for generated clauses. The final loss can be backpropagated smoothly to update the attentive reader for more accurate selections. Next, we illustrate each component with more details.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_30",
            "content": "Hierarchical Attentive Reader",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "141-ARR_v1_31",
            "content": "To avoid inevitable errors brought by the NER tools for named entity extraction, we propose to learn to extract relevant information using an attentive reader. Since multiple documents (contexts) are involved for each question, we design a 2-level hierarchical attention network to progressively filter token-level and context-level information. Specifically, the token-level attentions aim to select lhop (l = 0, ..., L) relevant entities in each context. Then the context-level attentions produce the final representations by softly attending to each context considering different number of reasoning hops.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_32",
            "content": "Token-Level Attention",
            "ntype": "title",
            "meta": {
                "section": "4.1.1"
            }
        },
        {
            "ix": "141-ARR_v1_33",
            "content": "Given a query subject s with n s tokens, a candidate a with n a tokens, and a context c of length n c , we denote by S \u2208 R ns\u00d7D , A \u2208 R na\u00d7D and C \u2208 R nc\u00d7D as their word features after a biGRU layer, respectively. For multi-hop reasoning, we use different attentions for finding or relocating target tokens in each context, inspired by (Gupta et al., 2020). Firstly, a subject-to-context attention is adopted to find similar tokens as the subject in each context:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_34",
            "content": "B s ij = w \u22a4 s [S i ; C j ; S i \u2022 C j ]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_35",
            "content": "where w s is a learnable transformation vector and [; ] denotes concatenations. We obtain the normalized similarity score \u03b1 s ij between i-th token in the subject and j-th token in the context via a softmax operation on each row of B s . Then a subject-aware (0-hop) context representation is produced as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_36",
            "content": "h s = nc j=1 \u1fb1s j C j , with \u1fb1s j = ns i=1 \u03b1 s ij \u03b2 s i (1)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_37",
            "content": "where \u03b2 s i weighs the contribution of each subject token via a self-attention: \u03b2 s = softmax( w\u22a4 s S + b s ). Similarly, we produce an attention score \u03b1 a ij for the j-th context token w.r.t. the i-th candidate token and a candidate-aware context representation h a . We denote by s = \u03b2 s S, and a = \u03b2 a A the query subject and candidate representations, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_38",
            "content": "For (l + 1)-hop reasoning (l \u2265 0), it is desired to relocate to intermediate (bridging) entities related to the l-hop entities. Hence, we adopt context-tocontext attentions",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_39",
            "content": "B l+1 ij = w \u22a4 l [C i + h l ; C j ; (C i + h l )\u2022C j ]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_40",
            "content": "given the l-hop representation h l where h 0 = h s . We use \u03b1 l+1 ij to denote a normalized attention score between i-th and j-th context tokens after applying a softmax operator over each row of B l+1 . With \u1fb10 j = \u1fb1s j , the (l + 1)-hop bridging context representation becomes",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_41",
            "content": "h l+1 = nc j=1 \u1fb1l+1 j C j , with \u1fb1l+1 j = nc i=1 \u03b1 l+1 ij \u1fb1l i . (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_42",
            "content": "Context-Level Attention",
            "ntype": "title",
            "meta": {
                "section": "4.1.2"
            }
        },
        {
            "ix": "141-ARR_v1_43",
            "content": "With multiple contexts (documents) available, we use a context-level attention to produce the final l-hop feature representations. When l = 0, the model softly attends to each context to produce context-attended subject representation as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_44",
            "content": "h s = K k=1 \u03b3s k h s,k ,(3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_45",
            "content": "where \u03b3s k is the attention weight of context c k obtained by normalizing over a score vector \u03b3 s with entries",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_46",
            "content": "\u03b3 s k = v \u22a4 s [s; h s,k ; s \u2022 h s,k ].",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_47",
            "content": "Here h s,k is the subject-aware context representation computed in (1) corresponding to the k-th context c k . The final subject representation is produced as hs = W s [s; h s ; s \u2022 h s ] incorporating both original features and attended information. Similar procedure applies to each candidate entity to produce ha . We treat hs and ha as 0-hop subject and candidate representations, respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_48",
            "content": "When l > 0, the context-level attention aims to produce the probability of each context being",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_49",
            "content": "r 1 (s, a) r M (s, a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 1 k , a) r M (c 1 k , a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 2 k , a) r M (c 2 k , a) r 1 (c 1 k , c 2 k ) r M (c 1 k , c 2 k ) r 0 1 (s, a) r 0 M0 (s, a) r 1 1 (s, a) r 1 M1 (s, a) r 2 1 (s, a) r 2 M2 (s, a) c 1 1 c 1 K c 1 1 c 1 K q(s, a) 0-hop 1-hop 2-hop c 2 1 c 2 K Figure 1:",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_50",
            "content": "An example of multi-hop ILP. The existential predicates r 1 , ..., r M are used to define invented predicates r l 1 , ..., r l M l through attentions. The invented predicates will produce the final clauses to define q.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_51",
            "content": "chosen as a bridging entity using",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_52",
            "content": "p l k = \u03c3(v \u22a4 l [ hs ; h l k ; hs \u2022 h l k ]),(4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_53",
            "content": "where \u03c3(\u2022) is the sigmoid function, h l k is the l-hop intermediate entity representation for context c k computed using (2).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_54",
            "content": "Multi-Hop Reasoner",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "141-ARR_v1_55",
            "content": "The multi-hop reasoner aims to conduct complex reasoning by first generating probable logic clauses and then evaluating each clause by instantiating the variables. The clause generation process is parameterized by attentive memories which compute the probability of selecting each atom to form a relevant clause to entail the query relation. An illustration of the procedure is shown in Figure 1 and will be elaborated in the next section. Then the clause evaluation process will ground each atom with query subjects, candidate entities or bridging entities. The outputs from the attentive reader, i.e., hs , ha and {h l k }'s (l > 0), can be regarded as these constant representations to compute the atom scores for clause evaluation and updates.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_56",
            "content": "Clause Generation",
            "ntype": "title",
            "meta": {
                "section": "4.2.1"
            }
        },
        {
            "ix": "141-ARR_v1_57",
            "content": "A definite clause is composed of atoms defined over relational predicates. Since there are no explicit relations given in this task, we pre-define a fixed set of relations for each corpus, named as existential predicates: P E ={r 1 , ..., r M }, e.g., \"located_in\", \"next_to\". For expressiveness, we further create a set of invented predicates P I =\u222a L l=0 P l I defined from the existential predicates, inspired by (Evans and Grefenstette, 2018). Specifically, P l I = {r l 1 , ..., r l M l } consists of invented predicates r l m defined using l-hop reasoning clauses F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 ) \u21d2 r l m (X 0 , X l+1 ). For example, located_in(X 0 , X 1 ) \u2227 next_to(X 1 , X 2 ) \u21d2 outside(X 0 , X 2 ) defines a 1-hop invented predicate \"outside\". Here L is the maximum hop number. The final clauses defining the query relation will be produced by learning to select relevant invented predicates, e.g., r l 1 i (X, Y ) \u2227 ... \u2227 r ln j (X, Y ) \u21d2 q(X, Y ) with 0 \u2264 l 1 \u2264 ... \u2264 l n \u2264 L. The number of actual inference steps l n to answer q is flexibly decided by the model itself (will be discussed later).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_58",
            "content": "The clause generation process is divided into two stages: 1) generate clauses defining invented predicates using only the existential predicates; 2) generate final clauses defining query relation using only the invented predicates. To allow for smooth optimization, we parameterize both stages by computing an attention weight for each predicate indicating its probability to appear in the clause body. Specifically, we assign each predicate a learnable embedding to indicate its semantics. Let U \u2208 R D\u00d7M denote the embedding matrix for M existential predicates and U l \u2208 R D\u00d7M l (l \u2208 {0, 1, ..., L}) denote the embedding matrix for l-hop invented predicates. In the first stage, we use attentive memories to generate",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_59",
            "content": "S l t = sparsemax((W l t U l t ) \u22a4 (W l b U)), (5) U l t+1 = U l t + S l t \u2022 (W l v U),(6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_60",
            "content": "where U l 0 = U l . W l t and W l b are transformation matrices for invented predicates (queries) and existential predicates (keys), respectively. We use sparsemax which is a sparse version of softmax (Martins and Astudillo, 2016) to select only a small number of predicates. Intuitively, to learn to define a l-hop invented predicate r l m , ( 5) and (6) will sequentially produce F t (X t , X t+1 ) at each step t \u2208 {0, ..., l} to form the clause body by attending over all the existential predicates with attention weight S l t . For example, when l = 1, (5) first attends to the existential predicate r i to generate F 0 (X 0 , X 1 ) = r i (X 0 , X 1 ) at step t = 0, and then attends to another predicate r j to generate",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_61",
            "content": "F 1 (X 1 , X 2 ) = r j (X 1 , X 2 ) at step t = 1. The resulting clause r i (X 0 , X 1 ) \u2227 r j (X 1 , X 2 ) \u21d2 r 1 m (X 0 , X 2 ) defines the invented predicate r 1",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_62",
            "content": "m . In the second stage, we produce H final clauses taking invented predicates to define the target atom q(X, Y ). Given an embedding u q \u2208 R D for the target relation q, we use a multi-head attention mechanism to compute a probability distribution s i over all the invented predicates for each head i \u2208 {1, ..., H} to produce the i-th final clause:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_63",
            "content": "s i =sparsemax{(W i q u q ) \u22a4 (W i h [U 0 ;...;U L ])} (7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_64",
            "content": "where s i is a sparse selective distribution over P I = {r 0 1 , ..., r L M L }. For example, if s i selects r 0 1 and r 1 2 , the final clause becomes r 0 1 (X, Y ) \u2227 r 1 2 (X, Y ) \u21d2 q(X, Y ), which involves at most 1 inference step (r 12 ). This completes the recursive rule generation step with multi-hop inference. To this end, we generate H clauses that can be used to define q(X, Y ).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_65",
            "content": "Clause Evaluation",
            "ntype": "title",
            "meta": {
                "section": "4.2.2"
            }
        },
        {
            "ix": "141-ARR_v1_66",
            "content": "Instantiation The clauses generated using the attentive memories will be tested and refined against the given positive and negative examples, known as learning from entailment that tries to maximize the truth probabilities of positive examples and minimize those of negative examples. The positive examples correspond to q(s, a) and the negative examples correspond to {q(s, a j )}'s, where s, a and a j refers to the query subject, correct answer and incorrect candidate, respectively. To obtain the truth probabilities of these atoms, we first instantiate the variables for each generated clause, e.g., X = s and Y = a (or Y = a j ) in q(X, Y ). The bridging variables X 1 , ..., X l are instantiated using the bridging contexts selected via the attentive reader as introduced in 4.1. To avoid inaccurate selection, for each X l , we pick K contexts {c l 1 , ..., c l K } with highest probabilities according to p l k in (4). Neural Logic Operator Given a definite clause b 1 \u2227 ... \u2227 b K \u21d2 h consisting of grounded atoms (e.g., b 1 = r 1 (s, a)), we could obtain the value for its head atom as \u00b5(h) = \u00b5(b 1 \u2227 ... \u2227 b k ). To compute the RHS involving logic operators (\u2227, \u2228), T-norm (Klement et al., 2013) is usually adopted:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_67",
            "content": "T : [0, 1] \u00d7 [0, 1] \u2192 [0, 1]. For example, mini- mum t-norm defines T \u2227 (\u00b5 1 , \u00b5 2 ) = min(\u00b5 1 , \u00b5 2 ), T \u2228 (\u00b5 1 , \u00b5 2 ) = max(\u00b5 1 , \u00b5 2 ). Product t-norm de- fines T \u2227 (\u00b5 1 , \u00b5 2 ) = \u00b5 1 \u2022 \u00b5 2 , T \u2228 (\u00b5 1 , \u00b5 2 ) = 1 \u2212 (1 \u2212 \u00b5 1 )\u2022(1\u2212\u00b5 2 ).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_68",
            "content": "Here \u00b5 1 , \u00b5 2 \u2208 [0, 1] refer to the value for the body atoms. However, minimum t-norm is prone to learning plateau because the gradient only flows through one of the inputs. Product t-norm is less stable and is prone to exponential decay when the number of atoms in the clause grows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_69",
            "content": "To address these limitations, we propose a novel neural logic operator G defined as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_70",
            "content": "G \u2228 (\u00b5 1 , ..., \u00b5 K )=1\u2212exp K k=1 log(1 \u2212 \u00b5 k + \u03f5) 1 K G \u2227 (\u00b5 1 , ..., \u00b5 K )=exp K k=1 log(\u00b5 k + \u03f5) 1 K , (8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_71",
            "content": "where \u00b5 1 , ..., \u00b5 K \u2208 [0, 1] refer to the probabilistic values of all the atoms in the conjunctive (\u2227) or disjunctive (\u2228) clause. \u03f5 is a small value to guarantee the validity for logarithm. The operator G has the following property that is ideal for logic semantics: 1) , where min refers to the index of the minimum value among {\u00b5 1 , ..., \u00b5 K }.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_72",
            "content": "Proposition 1. When \u2200\u00b5 k \u2192 1 with 1 \u2264 k \u2264 K, G \u2227 (\u00b5 1 , ..., \u00b5 K ) \u2192 1, aligning with logic \"AND\". When \u2203\u00b5 k \u2192 1, G \u2228 (\u00b5 1 , ..., \u00b5 K ) \u2192 1, aligning with logic \"OR\". Proposition 2. 0 \u2264 G \u2227 (\u00b5 1 , ..., \u00b5 K ) \u2212 \u00b5 min \u2264 (K 1/(1\u2212K) \u2212 K K/(1\u2212K) )( k\u0338 =min \u00b5 k ) 1/(K\u2212",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_73",
            "content": "In other words, the difference between G \u2227 and \u00b5 min is bounded. When K = 2, the RHS of the inequality equals to 1/4 \u2022 \u00b5 k\u0338 =min , which makes G \u2227 closer to \u00b5 min when \u00b5 k\u0338 =min is smaller. The proof can be found in the Appendix. This formulation results in a more stable and smooth gradient flow compared to minimum t-norm. Moreover, It avoids exponential decay in the output when K > 1. It also facilitates neural learning when the exact clause is parameterized with attention scores. Evaluation With the neural logic operator defined above, the value for the head atom can be inferred once the value for each body atom is given. For grounded atoms over existential predicates, e.g., r m (s, a), we directly generate its value using a relational network F : R d \u00d7 R d \u2192 R M that takes the features of two constant arguments as input to produce a probability distribution over all the existential predicates r 1 , ..., r M : F( hs , ha ) = softmax(W r tanh[ hs ; ha ; hs \u2212 ha ; hs \u2022 ha ]). Then \u00b5(r m (s, a)) takes the m-th entry of F( hs , ha ). Here hs and ha are the outputs from the attentive reader. Similarly, h l k can be regarded as the feature of c l k generated from the attentive reader which is used to compute atom values with bridging entities, e.g., \u00b5(r m (s, c l k )). For l-hop grounded atoms over invented predicates {r l 1 (s, a), ..., r l M l (s, a)}, we compute their values according to the value of the clause body that defines them, e.g., \u00b5(F 0 (s, c 1 ) \u2227 ... \u2227 F l (c l , a)) using neural logic operators:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_74",
            "content": "\u00b5 l = max z\u2208Z l exp l t=0 S l t log(\u00b5 (zt,z t+1 ) +\u03f5) 1 (l+1) (9)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_75",
            "content": "Here \u00b5 l = [\u00b5(r l 1 (s, a)), ..., \u00b5(r l M l (s, a))] \u22a4 denotes the vector of the atom values formed by those l-hop invented predicates. We denote by Z l = {(s, c 1 k , ..., c l k , a)} 1\u2264k\u2264K the set for all possible instantiations for l-hop reasoning and denote by z t the tth constant of z \u2208 Z l . \u00b5 (zt,z t+1 ) = [\u00b5(r 1 (z t , z t+1 )), ..., \u00b5(r M (z t , z t+1 ))] \u22a4 is a vector of values for grounded atoms over existential predicates. exp(\u2022) thus gives a neural approximation of logic conjunctions as shown in (8) over {F t (z t , z t+1 )} 0\u2264t\u2264l , each of which is a sparse selection of existential predicates using S l t . We use a max operator to generate the maximum score over all possible bridging entities to represent the final truth probability of each invented predicate. Intuitively, a relation between two entities should be satisfied as long as there is at least one instantiation that follows the rule. Also note that (9) has the effect that when S l t [i, j] \u2248 0, the corresponding predicate r j will have little effect on the value of its head r l i , which is in contrast to existing T-norms. The final value for q(s, a) is similarly computed:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_76",
            "content": "\u00b5(q(s, a))= max 1\u2264i\u2264H exp s i log([\u00b5 0 ; ...; \u00b5 L ] + \u03f5) .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_77",
            "content": "We use the cross-entropy loss over \u00b5(q(s, a)) as the final objective to train the entire model (except the word embeddings which are kept fixed) in an endto-end manner. Here we organize the dataset according to subject-candidate pairs: (s n , a n ). We associate the ground-truth label y n = 1 with (s n , a n ) if a n is the correct answer, otherwise, y n = 0.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_78",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "141-ARR_v1_79",
            "content": "We conduct experiments on two multi-hop reading comprehension datasets, namely WikiHop and MedHop (Welbl et al., 2018). The WikiHop dataset contains 43,738 training and 5,129 development instances ranging over 277 query relations. MedHop is a medical dataset containing 1,620 training and 342 development instances with a unique query relation, i.e., \"interact with\". For WikiHop, we experiment with both non-contextual (follow (Weber et al., 2019)) named as DILR and contextual word embeddings (BERT (Devlin et al., 2019)) named as DILR-BERT to demonstrate our model's generalization ability. For MedHop, we use the same setting following (Weber et al., 2019). We define M = 10 relations as existential predicates and M l = 5 invented predicates for each hop with l = 0, 1, 2. The number of final clauses to define the query relation is H = 5 and the number of candidate bridging contexts for each hop is set to K = 5. The dimension of predicate embeddings and biGRU layer is 100 and 200, respectively. For training, we adopt Adam optimization with learning rate initialized at 0.001. The batch size is set to 10. For all the experiments, we use the development dataset to evaluate the results because the test data is not publicly available.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_80",
            "content": "Experimental Result",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "141-ARR_v1_81",
            "content": "Weber et al. ( 2019) only selects four different query relations from WikiHop, namely Publisher, Developer, Country and Record_label, to evaluate their model. For fair comparison, we first follow their setting to compare on these specific domains. Besides BIDAF (Seo et al., 2017) and FastQA (Weissenborn et al., 2017), we also consider another three representative deep learning baselines : EPAr (Yichen Jiang and Bansal, 2019), HDEG (Tu et al., 2019), DynSAN (Zhuang and Wang, 2019) 2 , and a differentiable reasoning model DrMD adapted from (Dhingra et al., 2020). HDEG is a graph-based DNN. EPAr and DynSAN are memory-based DNNs. DrMD is implemented following (Dhingra et al., 2020), except that we remove pre-defined entities and only consider mention interactions given our settings. BERT is a baseline model that concatenates query subject (or a candidate entity) with each context in the form of we feed the hidden representations corresponding to the query subject (or candidates) into an attention model to generate a single vector to be fed into a classifier. For all the baselines, we train the models on each query relation separately to test the reasoning capability, same as our setting. Table 1 lists the results for MedHop and four query relations from WikiHop according to (Weber et al., 2019). Clearly, DILR substantially outperforms all the baselines on MedHop, demonstrating the importance of the reasoning capabilities for interaction-intensive medical dataset. On the four query relations from WikiHop, we still obtain the best performances. Though NLProlog also conducts logic reasoning, it is limited by the model's capacity and relies on the extraction accuracy of the NER tool. Furthermore, we also evaluate on all the other valid query relations 3 in WikiHop for a more complete analysis. The results in terms of accuracy are shown in Table 2. For a more thorough analysis, we group the query relations in terms of the number of training instances. As shown in Table 2, there are 38 relations (D1) containing less than 1,000 training examples, 7 relations (D2) with training examples ranging from 1,000 to 4,000 and 2 relations (D3) having more than 4,000 training examples. We report the micro-average accuracy scores over all the domains within each data group and their combinations in Table 2. Our model achieves the best performances over all data groups, demonstrating the advantage of combining deep attentive learning with logic reasoning. The margin is larger for D1 and D3, demonstrating the consistency of our proposed model with varying data sizes. In fact, ILP could be beneficial when training data is not sufficient via learning of generalized rules. Even with well-trained contextualized word embeddings, DILR still brings consistent performance gains. The Detailed comparison on each query relation can be found in Appendix.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_82",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "141-ARR_v1_83",
            "content": "To provide detailed analysis, we conduct ablation experiments on 6 datasets as shown in Table 3. For fair demonstration, we pick one relation in D3 (Located), 2 relations in D2 (Occupation and Record) and 3 relations in D1 (Publisher, Producer, Country). The first four rows reflect the accuracies by varying the maximum allowed number of reasoning hops (L). Clearly, \u2264 0 Hop and \u2264 3 Hop produce lower accuracies due to either missing bridging entities or overfitting with excessive inference steps.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_84",
            "content": "The middle part of Table 3 reflects the effect of each element of DILR. Specifically, \u2212PI removes the invented predicates: remove (5), ( 6), ( 9) and replace U l with U in (7). \u2212ILP removes the reasoner and uses a classifier on top of the attentive reader to produce the final predictions. \u2212AR removes the attentive reader and uses NER tools to extract entities for reasoning. \u2212Rel only computes binary relations that decide whether two constants are related or not. This demonstrates the effect of relational reasoning considering different relations. By comparison, it is evident that removing any component will suffer from non-trivial prediction loss, especially for ILP. To verify the effect of the neural logic operator (NLO), we compare it with two T-norm operators, namely \"prod-T\" for product T-norm and \"min-T\" for minimum T-norm. Clearly, NLO produces the best performances across all the experiments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_85",
            "content": "To provide a concrete view of how the attentive reader filters relevant information and how the generated clauses look like, we list three examples as shown in Table 4. The underlined texts have the maximum attention weights learned from the attentive reader. The bold texts indicate the query subject and the correct answer for each query. Clearly, the attentive reader is able to select bridging entities relevant to the answer. The third column lists some learned clauses from the reasoner. The first row of each example shows the clauses that define an invented predicate and the second row shows the final clause that entails the query relation 4 . We use abbreviated entities as the constants in each grounded atom (e.g., \"CC\" is short for \"Chris Church\") due to space limitations. The two clauses for the first example could be read as: if Chris Church and Massachusetts has relation r 7 , and Massachusetts and United States has relation r 2 , then the country of Chris Church is United States.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_86",
            "content": "We further demonstrate the robustness of DILR by varying model parameters, as shown in Figure 2. The top subplots reveal the accuracies on MedHop and Country datasets when changing the number of final clauses H (left) and the number of existential predicates M (right). The subplot in the bottom depicts the accuracies when varying the number of instantiations K of the bridging contexts for Genre dataset under both DILR and BERT-DILR models. We shall observe that the performances are relatively stable given that the total number of testing examples are less than 400 for each dataset.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_87",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "141-ARR_v1_88",
            "content": "We propose an end-to-end model DILR to solve the problem of multi-hop reading comprehension. DILR smoothly connects a hierarchical attentive reader with a multi-hop reasoner to conduct automatic information extraction and complex reasoning. We also introduce differentiable logic operators to induce valid clauses with smooth and stable gradient-based learning. Extensive experiments reveal consistent improvements brought by DILR.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_89",
            "content": "Proof.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_90",
            "content": "G \u2227 (\u00b5 1 , ..., \u00b5 K ) \u2212 \u00b5 min = exp( K k=1 log \u00b5 k + \u03f5) 1/K \u2212 \u00b5 min \u2248 K k=1 \u00b5 1/K k \u2212 \u00b5 min(10)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_91",
            "content": "Without loss of generality, assume the minimum value is \u00b5 min = \u00b5 1 . By fixing \u00b5 2 , ..., \u00b5 K as constants, we obtain the gradient for (10) w.r.t. \u00b5 1 as",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_92",
            "content": "1 K \u00b5 (1\u2212K)/K 1 K k=2 \u00b5 1/K k \u2212 1.(11)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_93",
            "content": "Then ( 10) is concave and has a maximum value obtained when (11) equals to 0, resulting in",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_94",
            "content": "\u00b5 1 = K K/(1\u2212K) K k=2 \u00b5 1/(K\u22121) k . (12",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "141-ARR_v1_95",
            "content": "UNKNOWN, None, , Massachusetts is the most populous state in, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Massachusetts is the most populous state in",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_96",
            "content": "UNKNOWN, None, , Massachusetts. r7(CC, M ) \u2227 r2, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Massachusetts. r7(CC, M ) \u2227 r2",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_97",
            "content": "J References, M Andreas, T Rohrbach, D Darrell,  Klein, Neural module networks, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "J References",
                    "M Andreas",
                    "T Rohrbach",
                    "D Darrell",
                    " Klein"
                ],
                "title": "Neural module networks",
                "pub_date": "2016",
                "pub_title": "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_98",
            "content": "UNKNOWN, None, 2018, Logical rule induction and theory learning using neural theorem proving, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Logical rule induction and theory learning using neural theorem proving",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_99",
            "content": "UNKNOWN, None, 1910, Multi-hop question answering via reasoning chains. CoRR, abs, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": null,
                "title": null,
                "pub_date": "1910",
                "pub_title": "Multi-hop question answering via reasoning chains. CoRR, abs",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_100",
            "content": "Xinyun Chen, Chen Liang, Adams Yu, Denny Zhou, Dawn Song, V Quoc,  Le, Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Xinyun Chen",
                    "Chen Liang",
                    "Adams Yu",
                    "Denny Zhou",
                    "Dawn Song",
                    "V Quoc",
                    " Le"
                ],
                "title": "Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension",
                "pub_date": "2020-04-26",
                "pub_title": "8th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_101",
            "content": "Christopher Clark, Matt Gardner, Simple and effective multi-paragraph reading comprehension, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Christopher Clark",
                    "Matt Gardner"
                ],
                "title": "Simple and effective multi-paragraph reading comprehension",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "141-ARR_v1_102",
            "content": "UNKNOWN, None, 2016, Tensorlog: A differentiable deductive database, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Tensorlog: A differentiable deductive database",
                "pub": "CoRR"
            }
        },
        {
            "ix": "141-ARR_v1_103",
            "content": "Nicola De Cao, Wilker Aziz, Ivan Titov, Question answering by reasoning across documents with graph convolutional networks, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Nicola De Cao",
                    "Wilker Aziz",
                    "Ivan Titov"
                ],
                "title": "Question answering by reasoning across documents with graph convolutional networks",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_104",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, NAACL-HLT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "NAACL-HLT",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_105",
            "content": "Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William Cohen, Ruslan Salakhutdinov, Neural models for reasoning over multiple mentions using coreference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Bhuwan Dhingra",
                    "Qiao Jin",
                    "Zhilin Yang",
                    "William Cohen",
                    "Ruslan Salakhutdinov"
                ],
                "title": "Neural models for reasoning over multiple mentions using coreference",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_106",
            "content": "Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, William Cohen, Differentiable reasoning over a virtual knowledge base, 2020, ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Bhuwan Dhingra",
                    "Manzil Zaheer",
                    "Vidhisha Balachandran",
                    "Graham Neubig",
                    "Ruslan Salakhutdinov",
                    "William Cohen"
                ],
                "title": "Differentiable reasoning over a virtual knowledge base",
                "pub_date": "2020",
                "pub_title": "ICLR",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_107",
            "content": "Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang, Cognitive graph for multi-hop reading comprehension at scale, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Ming Ding",
                    "Chang Zhou",
                    "Qibin Chen",
                    "Hongxia Yang",
                    "Jie Tang"
                ],
                "title": "Cognitive graph for multi-hop reading comprehension at scale",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_108",
            "content": "Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, Denny Zhou, Neural logic machines, 2019, ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Honghua Dong",
                    "Jiayuan Mao",
                    "Tian Lin",
                    "Chong Wang",
                    "Lihong Li",
                    "Denny Zhou"
                ],
                "title": "Neural logic machines",
                "pub_date": "2019",
                "pub_title": "ICLR",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_109",
            "content": "Richard Evans, Edward Grefenstette, Learning explanatory rules from noisy data, 2018, J. Artif. Intelligent Res, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Richard Evans",
                    "Edward Grefenstette"
                ],
                "title": "Learning explanatory rules from noisy data",
                "pub_date": "2018",
                "pub_title": "J. Artif. Intelligent Res",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_110",
            "content": "V Manoel, Gerson Fran\u00e7a, Artur Zaverucha,  D'avila Garcez, Fast relational learning using bottom clause propositionalization with artificial neural networks, 2014, Mach. Learn, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "V Manoel",
                    "Gerson Fran\u00e7a",
                    "Artur Zaverucha",
                    " D'avila Garcez"
                ],
                "title": "Fast relational learning using bottom clause propositionalization with artificial neural networks",
                "pub_date": "2014",
                "pub_title": "Mach. Learn",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_111",
            "content": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, Li Guo, Jointly embedding knowledge graphs and logical rules, 2016, EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Shu Guo",
                    "Quan Wang",
                    "Lihong Wang",
                    "Bin Wang",
                    "Li Guo"
                ],
                "title": "Jointly embedding knowledge graphs and logical rules",
                "pub_date": "2016",
                "pub_title": "EMNLP",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_112",
            "content": "UNKNOWN, None, 2020, Neural module networks for reasoning over text. ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Neural module networks for reasoning over text. ICLR",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_113",
            "content": "Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric Xing, Harnessing deep neural networks with logic rules, 2016, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Zhiting Hu",
                    "Xuezhe Ma",
                    "Zhengzhong Liu",
                    "Eduard Hovy",
                    "Eric Xing"
                ],
                "title": "Harnessing deep neural networks with logic rules",
                "pub_date": "2016",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_114",
            "content": "Yichen Jiang, Mohit Bansal, Self-assembling modular networks for interpretable multi-hop reasoning, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Yichen Jiang",
                    "Mohit Bansal"
                ],
                "title": "Self-assembling modular networks for interpretable multi-hop reasoning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_115",
            "content": "UNKNOWN, None, 2013, Triangular norms, Springer Science and Business Media.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": null,
                "title": null,
                "pub_date": "2013",
                "pub_title": "Triangular norms",
                "pub": "Springer Science and Business Media"
            }
        },
        {
            "ix": "141-ARR_v1_116",
            "content": "Souvik Kundu, Tushar Khot, Ashish Sabharwal, Peter Clark, Exploiting explicit paths for multihop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Souvik Kundu",
                    "Tushar Khot",
                    "Ashish Sabharwal",
                    "Peter Clark"
                ],
                "title": "Exploiting explicit paths for multihop reading comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_117",
            "content": "Tao Li, Vivek Srikumar, Augmenting neural networks with first-order logic, 2019, ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Tao Li",
                    "Vivek Srikumar"
                ],
                "title": "Augmenting neural networks with first-order logic",
                "pub_date": "2019",
                "pub_title": "ACL",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_118",
            "content": "Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt, Deepproblog: Neural probabilistic logic programming, 2018, NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Robin Manhaeve",
                    "Sebastijan Dumancic",
                    "Angelika Kimmig",
                    "Thomas Demeester",
                    "Luc De Raedt"
                ],
                "title": "Deepproblog: Neural probabilistic logic programming",
                "pub_date": "2018",
                "pub_title": "NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_119",
            "content": "Andre Martins, Ramon Astudillo, From softmax to sparsemax: A sparse model of attention and multi-label classification, 2016, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Andre Martins",
                    "Ramon Astudillo"
                ],
                "title": "From softmax to sparsemax: A sparse model of attention and multi-label classification",
                "pub_date": "2016",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_120",
            "content": "Sewon Min, Victor Zhong, Luke Zettlemoyer, Hannaneh Hajishirzi, Multi-hop reading comprehension through question decomposition and rescoring, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Sewon Min",
                    "Victor Zhong",
                    "Luke Zettlemoyer",
                    "Hannaneh Hajishirzi"
                ],
                "title": "Multi-hop reading comprehension through question decomposition and rescoring",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_121",
            "content": "Pasquale Minervini, Matko Bosnjak, Tim Rockt\u00e4schel, Sebastian Riedel, Edward Grefenstette, Differentiable reasoning on large knowledge bases and natural language, 2020, AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Pasquale Minervini",
                    "Matko Bosnjak",
                    "Tim Rockt\u00e4schel",
                    "Sebastian Riedel",
                    "Edward Grefenstette"
                ],
                "title": "Differentiable reasoning on large knowledge bases and natural language",
                "pub_date": "2020",
                "pub_title": "AAAI",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_122",
            "content": "Pasquale Minervini, Thomas Demeester, Tim Rockt\u00e4schel, Sebastian Riedel, Adversarial sets for regularised neural link predictors, 2017, UAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Pasquale Minervini",
                    "Thomas Demeester",
                    "Tim Rockt\u00e4schel",
                    "Sebastian Riedel"
                ],
                "title": "Adversarial sets for regularised neural link predictors",
                "pub_date": "2017",
                "pub_title": "UAI",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_123",
            "content": "Stephen Muggleton, Inductive logic programming, 1991, New Generation Computing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    " Stephen Muggleton"
                ],
                "title": "Inductive logic programming",
                "pub_date": "1991",
                "pub_title": "New Generation Computing",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_124",
            "content": "Lin Qiu, Yunxuan Xiao, Yanru Qu, Hao Zhou, Lei Li, Weinan Zhang, Yong Yu, Dynamically fused graph network for multi-hop reasoning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Lin Qiu",
                    "Yunxuan Xiao",
                    "Yanru Qu",
                    "Hao Zhou",
                    "Lei Li",
                    "Weinan Zhang",
                    "Yong Yu"
                ],
                "title": "Dynamically fused graph network for multi-hop reasoning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_125",
            "content": "Meng Qu, Jian Tang, Probabilistic logic neural networks for reasoning, 2019, NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Meng Qu",
                    "Jian Tang"
                ],
                "title": "Probabilistic logic neural networks for reasoning",
                "pub_date": "2019",
                "pub_title": "NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_126",
            "content": "Tim Rockt\u00e4schel, Sebastian Riedel, End-toend differentiable proving, 2017, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Tim Rockt\u00e4schel",
                    "Sebastian Riedel"
                ],
                "title": "End-toend differentiable proving",
                "pub_date": "2017",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_127",
            "content": "UNKNOWN, None, 2017, Query-reduction networks for question answering, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Query-reduction networks for question answering",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_128",
            "content": "UNKNOWN, None, 2018, Exploring graph-structured passage representation for multihop reading comprehension with graph neural networks, CoRR.",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Exploring graph-structured passage representation for multihop reading comprehension with graph neural networks",
                "pub": "CoRR"
            }
        },
        {
            "ix": "141-ARR_v1_129",
            "content": "Zeyun Tang, Yongliang Shen, Xinyin Ma, Wei Xu, Jiale Yu, Weiming Lu, Multi-hop reading comprehension across documents with path-based graph convolutional network, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Zeyun Tang",
                    "Yongliang Shen",
                    "Xinyin Ma",
                    "Wei Xu",
                    "Jiale Yu",
                    "Weiming Lu"
                ],
                "title": "Multi-hop reading comprehension across documents with path-based graph convolutional network",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_130",
            "content": "Ming Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, Bowen Zhou, Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Ming Tu",
                    "Guangtao Wang",
                    "Jing Huang",
                    "Yun Tang",
                    "Xiaodong He",
                    "Bowen Zhou"
                ],
                "title": "Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_131",
            "content": "Po-Wei Wang, Priya Donti, Bryan Wilder, J Kolter, Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver, 2019, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Po-Wei Wang",
                    "Priya Donti",
                    "Bryan Wilder",
                    "J Kolter"
                ],
                "title": "Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver",
                "pub_date": "2019",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_132",
            "content": "Wenya Wang,  Sinno Jialin Pan, Integrating deep learning with logic fusion for information extraction, 2020, AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Wenya Wang",
                    " Sinno Jialin Pan"
                ],
                "title": "Integrating deep learning with logic fusion for information extraction",
                "pub_date": "2020",
                "pub_title": "AAAI",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_133",
            "content": "Yizhong Wang, Kai Liu, Jing Liu, Wei He, Yajuan Lyu, Hua Wu, Sujian Li, Haifeng Wang, Multipassage machine reading comprehension with crosspassage answer verification, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Yizhong Wang",
                    "Kai Liu",
                    "Jing Liu",
                    "Wei He",
                    "Yajuan Lyu",
                    "Hua Wu",
                    "Sujian Li",
                    "Haifeng Wang"
                ],
                "title": "Multipassage machine reading comprehension with crosspassage answer verification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "141-ARR_v1_134",
            "content": "Leon Weber, Pasquale Minervini, Jannes M\u00fcnchmeyer, Ulf Leser, Tim Rockt\u00e4schel, NLProlog: Reasoning with weak unification for question answering in natural language, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Leon Weber",
                    "Pasquale Minervini",
                    "Jannes M\u00fcnchmeyer",
                    "Ulf Leser",
                    "Tim Rockt\u00e4schel"
                ],
                "title": "NLProlog: Reasoning with weak unification for question answering in natural language",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_135",
            "content": "UNKNOWN, None, 2017, Fastqa: A simple and efficient neural architecture for question answering. arXiv: Computation and Language, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Fastqa: A simple and efficient neural architecture for question answering. arXiv: Computation and Language",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_136",
            "content": "Johannes Welbl, Pontus Stenetorp, Sebastian Riedel, Constructing datasets for multi-hop reading comprehension across documents, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Johannes Welbl",
                    "Pontus Stenetorp",
                    "Sebastian Riedel"
                ],
                "title": "Constructing datasets for multi-hop reading comprehension across documents",
                "pub_date": "2018",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_137",
            "content": "Meixi Wu, Wenya Wang, Sinno Jialin Pan, Deep Weighted MaxSAT for Aspect-based Opinion Extraction, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Meixi Wu",
                    "Wenya Wang",
                    "Sinno Jialin Pan"
                ],
                "title": "Deep Weighted MaxSAT for Aspect-based Opinion Extraction",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_138",
            "content": "Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van Den Broeck, A semantic loss function for deep learning with symbolic knowledge, 2018, ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Jingyi Xu",
                    "Zilu Zhang",
                    "Tal Friedman",
                    "Yitao Liang",
                    "Guy Van Den Broeck"
                ],
                "title": "A semantic loss function for deep learning with symbolic knowledge",
                "pub_date": "2018",
                "pub_title": "ICML",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_139",
            "content": "Fan Yang, Zhilin Yang, William Cohen, Differentiable learning of logical rules for knowledge base reasoning, 2017, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Fan Yang",
                    "Zhilin Yang",
                    "William Cohen"
                ],
                "title": "Differentiable learning of logical rules for knowledge base reasoning",
                "pub_date": "2017",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_140",
            "content": "UNKNOWN, None, 2020, Learn to explain efficiently via neural logic inductive learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Learn to explain efficiently via neural logic inductive learning",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_141",
            "content": "Yen-Chun Chen Yichen Jiang, Nitish Joshi, Mohit Bansal, Explore, propose, and assemble: An interpretable model for multi-hop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Yen-Chun Chen Yichen Jiang",
                    "Nitish Joshi",
                    "Mohit Bansal"
                ],
                "title": "Explore, propose, and assemble: An interpretable model for multi-hop reading comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_142",
            "content": "Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher, Coarse-grain fine-grain coattention network for multi-evidence question answering, 2019, 7th International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Victor Zhong",
                    "Caiming Xiong",
                    "Nitish Shirish Keskar",
                    "Richard Socher"
                ],
                "title": "Coarse-grain fine-grain coattention network for multi-evidence question answering",
                "pub_date": "2019",
                "pub_title": "7th International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "141-ARR_v1_143",
            "content": "Yimeng Zhuang, Huadong Wang, Token-level dynamic self-attention network for multi-passage reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Yimeng Zhuang",
                    "Huadong Wang"
                ],
                "title": "Token-level dynamic self-attention network for multi-passage reading comprehension",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "141-ARR_v1_0@0",
            "content": "Deep Inductive Logic Reasoning for Multi-Hop Reading Comprehension",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_0",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_2@0",
            "content": "Multi-hop reading comprehension requires the ability to reason across multiple documents.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_2",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_2@1",
            "content": "On the one hand, deep learning approaches only implicitly encode query-related information into distributed embeddings which fail to uncover the discrete relational reasoning process to infer the correct answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_2",
            "start": 90,
            "end": 300,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_2@2",
            "content": "On the other hand, logic-based approaches provide interpretable rules to infer the target answer, but mostly work on structured data where entities and relations are well-defined.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_2",
            "start": 302,
            "end": 480,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_2@3",
            "content": "In this paper, we propose a deep-learning based inductive logic reasoning method that firstly extracts query-related (candidate-related) information, and then conducts logic reasoning among the filtered information by inducing feasible rules that entail the target relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_2",
            "start": 482,
            "end": 755,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_2@4",
            "content": "The reasoning process is accomplished via attentive memories with novel differentiable logic operators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_2",
            "start": 757,
            "end": 859,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_2@5",
            "content": "To demonstrate the effectiveness of our model, we evaluate it on two reading comprehension datasets, namely WikiHop and MedHop.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_2",
            "start": 861,
            "end": 987,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_4@0",
            "content": "Reasoning has been extensively studied in the structured domain, e.g., knowledge base completion which infers missing facts given background entities and relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_4",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_4@1",
            "content": "However, when the background knowledge is expressed in natural languages, as shown in the multi-hop reading comprehension problem with triplet-form questions (Welbl et al., 2018), it becomes difficult to conduct complex reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_4",
            "start": 165,
            "end": 394,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_4@2",
            "content": "For example, consider the question \"country(Moonhole, ?)\", given the following documents:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_4",
            "start": 396,
            "end": 484,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_5@0",
            "content": "\"Moonhole is a private community on the island of Bequia. Moonhole was founded by Thomas and Gladys Johnston in the 1960s.\" \"Gladys Johnston was born in United States.\"",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_5",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_6@0",
            "content": "\"Bequia is an island and is part of the country of Saint Vincent and the Grenadines\"",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_6",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_7@0",
            "content": "The correct answer should be Saint Vincent and the Grenadines instead of United States although both entities have co-occurring contexts with Moonhole.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_7",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_8@0",
            "content": "Deep learning methods for multi-hop reading comprehension (RC) can be categorized as: 1) Memory-based models Zhuang and Wang, 2019) that learn to generate query-aware context representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_8",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_8@1",
            "content": "2) Graph-based approaches (Song et al., 2018;De Cao et al., 2019) that use graph neural networks to propagate information based on pre-constructed entity (context) graphs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_8",
            "start": 192,
            "end": 362,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_8@2",
            "content": "3) Neural Module networks (Andreas et al., 2016) that decompose the question into a series of action modules Min et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_8",
            "start": 364,
            "end": 490,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_8@3",
            "content": "However, DNNs only implicitly encode relevant contexts but fail to explicitly uncover the underlying relational compositions for complex inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_8",
            "start": 492,
            "end": 638,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_8@4",
            "content": "With the above example, DNNs may encode Bequia and Gladys Johnson into 1-hop features, given both entities co-occur with the query Moonhole.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_8",
            "start": 640,
            "end": 779,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_8@5",
            "content": "As a result, the model may predict United States by linking it with Gladys Johnson instead of the correct answer Saint Vincent and the Grenadines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_8",
            "start": 781,
            "end": 926,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_8@6",
            "content": "However, a human would easily produce the correct answer given the knowledge \"if A is in B and B is part of country C, then A is in country C\" and by examining the relations between each entity pair co-occurred in the context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_8",
            "start": 928,
            "end": 1153,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_9@0",
            "content": "Inductive logic programming (ILP) (Muggleton, 1991) aligns with human reasoning by inducing interpretable rules to entail positive but not negative examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_9",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_9@1",
            "content": "To answer the previous query, ILP could generate this rule: located_in(X, Z)\u2227 country(Z, Y ) \u21d2 country(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_9",
            "start": 158,
            "end": 267,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_9@2",
            "content": "Combining deep learning with ILP is a promising direction to benefit from both worlds (Evans and Grefenstette, 2018;Dong et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_9",
            "start": 269,
            "end": 403,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_9@3",
            "content": "Deep logic models have been proposed for structured knowledge base completion (Minervini et al., 2017(Minervini et al., , 2020Yang and Song, 2020;Yang et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_9",
            "start": 405,
            "end": 569,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_9@4",
            "content": "However, it becomes much more challenging when dealing with natural language inputs, as in the case of multi-hop reading comprehension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_9",
            "start": 571,
            "end": 705,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_9@5",
            "content": "Weber et al. (2019) proposed to combine a symbolic reasoner: prolog, with weak unifications based on distributed embeddings as a backwardchaining theorem prover to induce feasible rules for multi-hop reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_9",
            "start": 707,
            "end": 916,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_9@6",
            "content": "However, their work relies on the accuracies of pre-extracted NERs and is limited by the number of rule templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_9",
            "start": 918,
            "end": 1031,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_10@0",
            "content": "To address these limitations, we propose a novel end-to-end combination of deep learning and logic reasoning termed Deep Inductive Logic Reasoning (DILR).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_10",
            "start": 0,
            "end": 153,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_10@1",
            "content": "It consists of two components: 1) a hierarchical attentive reader that filters query-related and candidate-related information from given documents; 2) a multi-hop reasoner that conducts inductive logic reasoning by attentively selecting proper predicates to form candidate rules and refines them upon given examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_10",
            "start": 155,
            "end": 471,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_10@2",
            "content": "We introduce novel differentiable logic operators combined with attention mechanisms for smooth back-propagation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_10",
            "start": 473,
            "end": 585,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_10@3",
            "content": "Compared to existing deep logic models, we build connections between raw text inputs and the symbolic domain by mapping high-level semantic representations to logic predicates and instantiating logic variables with neural representations to conduct relational reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_10",
            "start": 587,
            "end": 856,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_10@4",
            "content": "We also parameterize the entire process for end-to-end differentiable learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_10",
            "start": 858,
            "end": 936,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_11@0",
            "content": "The contributions of this work include: 1) We introduce a novel smooth connection between deep representation learning with logic reasoning by associating distributed representations with discrete logic predicates and their probabilistic evaluations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_11",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_12@0",
            "content": "2) We propose deep-learning-based inductive logic programming via attentive memories and differentiable logic operators for the task of multi-hop reading comprehension considering the number of reasoning steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_12",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_12@1",
            "content": "3) We provide comprehensive evaluations of our model on two benchmark datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_12",
            "start": 211,
            "end": 289,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_13@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_13",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@0",
            "content": "Multi-Hop Reading Comprehension Recent works for multi-hop RC include memory-based methods which apply attentions to iteratively update query and context representations considering their interactions (Dhingra et al., 2018;Clark and Gardner, 2018;Zhuang and Wang, 2019;Yichen Jiang and Bansal, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 0,
            "end": 299,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@1",
            "content": "To explicitly incorporate entity connections, De Cao et al. ( 2019), Ding et al. (2019), Qiu et al. (2019), Tang et al. (2020), Song et al. (2018) and Tu et al. (2019) build entity graphs and apply Graph Neural Networks for information propagation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 301,
            "end": 548,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@2",
            "content": "Kundu et al. (2019) formalizes reasoning as a path-finding problem with neural encoding to rank candidate paths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 550,
            "end": 661,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@3",
            "content": "Path modeling is also adopted in using pointer networks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 663,
            "end": 718,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@4",
            "content": "However, these approaches only focus on local information without the ability to generalize, and some of them rely on NER tools.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 720,
            "end": 847,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@5",
            "content": "Dhingra et al. (2020) converts texts into a virtual knowledge based for retrieval, but requires an entity database.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 849,
            "end": 963,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@6",
            "content": "Another category uses neural module networks Min et al., 2019;Gupta et al., 2020;Chen et al., 2020) to decompose the question into a series of actions, each parameterized with a neural module, which also fail to explicitly uncover the underlying logic for reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 965,
            "end": 1230,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@7",
            "content": "Deep Learning with Logic Reasoning Neurosymbolic learning aims to integrate deep learning's ability on dealing with uncertainty and logic programming's ability on reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 1232,
            "end": 1404,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@8",
            "content": "Deep neural networks have been used to parameterize discrete logic operators and logic atoms (Fran\u00e7a et al., 2014;Hu et al., 2016;Manhaeve et al., 2018;Xu et al., 2018;Li and Srikumar, 2019;Wu et al., 2020) given the logic rules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 1406,
            "end": 1634,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_14@9",
            "content": "A more challenging direction is inductive logic programming that automatically learns rules through representation learning and differentiable backpropagation (Evans and Grefenstette, 2018;Dong et al., 2019;Yang and Song, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_14",
            "start": 1636,
            "end": 1863,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_15@0",
            "content": "Neuro-symbolic learning has been applied to knowledge-base completion through logic embeddings (Guo et al., 2016), tensor operations (Cohen, 2016;, adversarial learning (Minervini et al., 2017), variational learning (Qu and Tang, 2019) or attentions (Yang and Song, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_15",
            "start": 0,
            "end": 271,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_15@1",
            "content": "Differentiable theorem proving has also been proposed with weak unifications and backward chaining Campero et al., 2018;Minervini et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_15",
            "start": 273,
            "end": 416,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_15@2",
            "content": "However, unlike multi-hop RC, knowledge-base completion only takes structured inputs without the need to address language ambiguity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_15",
            "start": 418,
            "end": 549,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_15@3",
            "content": "The most related work to ours is NLProlog (Weber et al., 2019), a neural theorem prover for multi-hop RC by converting language utterances to distributed embeddings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_15",
            "start": 551,
            "end": 715,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_15@4",
            "content": "However, NLProlog relies on a NER tool to extract entities and its expressiveness is limited by the number of rule templates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_15",
            "start": 717,
            "end": 841,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_16@0",
            "content": "Background",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_16",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_17@0",
            "content": "We focus on multi-hop reading comprehension tasks containing explicit query types which align with the standard ILP setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_17",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_17@1",
            "content": "Formally, for each RC problem, we are given a set of documents D = {D 1 , ..., D n }, a structured query in the form of a relational triplet (s, q, ?) where s denotes the subject of the relation q, and a list of candidate answers A = {a 1 , ..., a m }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_17",
            "start": 125,
            "end": 376,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_17@2",
            "content": "The task is to select an answer a \u2208 A such that q(s, a) is satisfied, i.e., a is the object of relation q given the subject s. For example, country(M oonhole, ?) is a query asking for the country where Moonhole is located.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_17",
            "start": 378,
            "end": 599,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_17@3",
            "content": "This task could be converted into an ILP problem with the formal definition as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_17",
            "start": 601,
            "end": 687,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_18@0",
            "content": "Definition 3.1 (Inductive Logic Programming).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_18",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_18@1",
            "content": "Given a logic theory B representing the background knowledge (facts), a set of positive examples E + and a set of negative examples E \u2212 , an ILP system aims to derive a hypothesis H which entails all the positive and none of the negative examples:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_18",
            "start": 46,
            "end": 292,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_19@0",
            "content": "B \u2227 H |= \u03b3 for \u03b3 \u2208 E + . B \u2227 H \u0338 |= \u03b3 for \u03b3 \u2208 E \u2212 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_19",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_20@0",
            "content": "The hypothesis H is a logic program consisting of definite clauses b 1 \u2227 ... \u2227 b k \u21d2 h where b 1 , ..., b k and h are logic atoms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_20",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_20@1",
            "content": "The LHS of \"\u21d2\" is the clause body and h is the head.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_20",
            "start": 131,
            "end": 182,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_20@2",
            "content": "An atom is composed of a predicate and its arguments, e.g., h = located_in(X, Y ) with predicate \"located_in\" and arguments X, Y .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_20",
            "start": 184,
            "end": 313,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_20@3",
            "content": "A ground atom is obtained by instantiating variables in the arguments with constants, e.g., X = \"US\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_20",
            "start": 315,
            "end": 415,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_20@4",
            "content": "We use \u00b5(\u2022) to denote the value of an atom or a clause.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_20",
            "start": 417,
            "end": 471,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_20@5",
            "content": "For smooth optimization, we assign \u00b5(\u2022) \u2208 [0, 1] which indicates the probability of the atom or clause being true.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_20",
            "start": 473,
            "end": 586,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_21@0",
            "content": "For multi-hop reading comprehension, we treat the query relation q(X, Y ) as the head atom of the clauses to be induced.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_21",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_21@1",
            "content": "The correct answer a + i from each problem forms the set of positive examples",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_21",
            "start": 121,
            "end": 197,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_22@0",
            "content": "E + ={q(s i , a + i )} N + i=1 ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_22",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_23@0",
            "content": "and the incorrect answer a \u2212 j forms the set of negative examples",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_23",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_24@0",
            "content": "E \u2212 ={q(s j , a \u2212 j )} N \u2212 j=1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_24",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_25@0",
            "content": "Here we use lower cases: s i , a + i , a \u2212 j to represent constants and upper cases: X, Y to represent variables.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_25",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_25@1",
            "content": "The predicates in the logic domain correspond to pairwise relations between two entities 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_25",
            "start": 114,
            "end": 205,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_25@2",
            "content": "To differentiate the number of inference steps, we define a l-hop reasoning clause as F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 )\u21d2r(X 0 , X l+1 ) with l denoting the number of extra arguments as bridging entities in the rule body except those in the head atom.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_25",
            "start": 207,
            "end": 466,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_25@3",
            "content": "Here each subclause F t (X t , X t+1 ) can be one or a conjunction (\u2227) of 2-ary atoms 1 We restrict each atom as a 2-ary atom that takes exactly 2 arguments, analogical to relations in the knowledge base.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_25",
            "start": 468,
            "end": 671,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_26@0",
            "content": "taking only X t and X t+1 as arguments, e.g.,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_26",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_27@0",
            "content": "F t (X t , X t+1 ) = r 1 (X t , X t+1 ) \u2227 r 2 (X t , X t+1 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_27",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_28@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_28",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_29@0",
            "content": "Overall, DILR simulates multi-hop reasoning processes considering different number of inference steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_29",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_29@1",
            "content": "It is an end-to-end framework consisting of two components: a Hierarchical Attentive Reader and a Multi-hop Reasoner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_29",
            "start": 103,
            "end": 219,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_29@2",
            "content": "The attentive reader learns to select relevant information from the given documents to produce query-aware, candidateaware and bridging entity representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_29",
            "start": 221,
            "end": 379,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_29@3",
            "content": "These representations are passed to the multi-hop reasoner to instantiate logic atoms in order to generate and evaluate clauses that are relevant to the query relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_29",
            "start": 381,
            "end": 548,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_29@4",
            "content": "The multi-hop reasoner conducts rule induction via attentive memories that softly select atoms to form new clauses and novel differentiable logic operators that produce probabilistic values for generated clauses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_29",
            "start": 550,
            "end": 761,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_29@5",
            "content": "The final loss can be backpropagated smoothly to update the attentive reader for more accurate selections.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_29",
            "start": 763,
            "end": 868,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_29@6",
            "content": "Next, we illustrate each component with more details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_29",
            "start": 870,
            "end": 922,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_30@0",
            "content": "Hierarchical Attentive Reader",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_30",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_31@0",
            "content": "To avoid inevitable errors brought by the NER tools for named entity extraction, we propose to learn to extract relevant information using an attentive reader.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_31",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_31@1",
            "content": "Since multiple documents (contexts) are involved for each question, we design a 2-level hierarchical attention network to progressively filter token-level and context-level information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_31",
            "start": 160,
            "end": 344,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_31@2",
            "content": "Specifically, the token-level attentions aim to select lhop (l = 0, ..., L) relevant entities in each context.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_31",
            "start": 346,
            "end": 455,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_31@3",
            "content": "Then the context-level attentions produce the final representations by softly attending to each context considering different number of reasoning hops.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_31",
            "start": 457,
            "end": 607,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_32@0",
            "content": "Token-Level Attention",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_32",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_33@0",
            "content": "Given a query subject s with n s tokens, a candidate a with n a tokens, and a context c of length n c , we denote by S \u2208 R ns\u00d7D , A \u2208 R na\u00d7D and C \u2208 R nc\u00d7D as their word features after a biGRU layer, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_33",
            "start": 0,
            "end": 212,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_33@1",
            "content": "For multi-hop reasoning, we use different attentions for finding or relocating target tokens in each context, inspired by (Gupta et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_33",
            "start": 214,
            "end": 356,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_33@2",
            "content": "Firstly, a subject-to-context attention is adopted to find similar tokens as the subject in each context:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_33",
            "start": 358,
            "end": 462,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_34@0",
            "content": "B s ij = w \u22a4 s [S i ; C j ; S i \u2022 C j ]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_34",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_35@0",
            "content": "where w s is a learnable transformation vector and [; ] denotes concatenations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_35",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_35@1",
            "content": "We obtain the normalized similarity score \u03b1 s ij between i-th token in the subject and j-th token in the context via a softmax operation on each row of B s .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_35",
            "start": 80,
            "end": 236,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_35@2",
            "content": "Then a subject-aware (0-hop) context representation is produced as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_35",
            "start": 238,
            "end": 303,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_36@0",
            "content": "h s = nc j=1 \u1fb1s j C j , with \u1fb1s j = ns i=1 \u03b1 s ij \u03b2 s i (1)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_36",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_37@0",
            "content": "where \u03b2 s i weighs the contribution of each subject token via a self-attention: \u03b2 s = softmax( w\u22a4 s S + b s ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_37",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_37@1",
            "content": "Similarly, we produce an attention score \u03b1 a ij for the j-th context token w.r.t. the i-th candidate token and a candidate-aware context representation h a .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_37",
            "start": 111,
            "end": 267,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_37@2",
            "content": "We denote by s = \u03b2 s S, and a = \u03b2 a A the query subject and candidate representations, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_37",
            "start": 269,
            "end": 368,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_38@0",
            "content": "For (l + 1)-hop reasoning (l \u2265 0), it is desired to relocate to intermediate (bridging) entities related to the l-hop entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_38",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_38@1",
            "content": "Hence, we adopt context-tocontext attentions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_38",
            "start": 128,
            "end": 171,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_39@0",
            "content": "B l+1 ij = w \u22a4 l [C i + h l ; C j ; (C i + h l )\u2022C j ]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_39",
            "start": 0,
            "end": 53,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_40@0",
            "content": "given the l-hop representation h l where h 0 = h s .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_40",
            "start": 0,
            "end": 51,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_40@1",
            "content": "We use \u03b1 l+1 ij to denote a normalized attention score between i-th and j-th context tokens after applying a softmax operator over each row of B l+1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_40",
            "start": 53,
            "end": 202,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_40@2",
            "content": "With \u1fb10 j = \u1fb1s j , the (l + 1)-hop bridging context representation becomes",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_40",
            "start": 204,
            "end": 277,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_41@0",
            "content": "h l+1 = nc j=1 \u1fb1l+1 j C j , with \u1fb1l+1 j = nc i=1 \u03b1 l+1 ij \u1fb1l i . (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_41",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_42@0",
            "content": "Context-Level Attention",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_42",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_43@0",
            "content": "With multiple contexts (documents) available, we use a context-level attention to produce the final l-hop feature representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_43",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_43@1",
            "content": "When l = 0, the model softly attends to each context to produce context-attended subject representation as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_43",
            "start": 131,
            "end": 236,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_44@0",
            "content": "h s = K k=1 \u03b3s k h s,k ,(3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_44",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_45@0",
            "content": "where \u03b3s k is the attention weight of context c k obtained by normalizing over a score vector \u03b3 s with entries",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_45",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_46@0",
            "content": "\u03b3 s k = v \u22a4 s [s; h s,k ; s \u2022 h s,k ].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_46",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_47@0",
            "content": "Here h s,k is the subject-aware context representation computed in (1) corresponding to the k-th context c k .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_47",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_47@1",
            "content": "The final subject representation is produced as hs = W s [s; h s ; s \u2022 h s ] incorporating both original features and attended information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_47",
            "start": 111,
            "end": 249,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_47@2",
            "content": "Similar procedure applies to each candidate entity to produce ha .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_47",
            "start": 251,
            "end": 316,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_47@3",
            "content": "We treat hs and ha as 0-hop subject and candidate representations, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_47",
            "start": 318,
            "end": 397,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_48@0",
            "content": "When l > 0, the context-level attention aims to produce the probability of each context being",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_48",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_49@0",
            "content": "r 1 (s, a) r M (s, a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 1 k , a) r M (c 1 k , a) r 1 (s, c 1 k ) r M (s, c 1 k ) r 1 (c 2 k , a) r M (c 2 k , a) r 1 (c 1 k , c 2 k ) r M (c 1 k , c 2 k ) r 0 1 (s, a) r 0 M0 (s, a) r 1 1 (s, a) r 1 M1 (s, a) r 2 1 (s, a) r 2 M2 (s, a) c 1 1 c 1 K c 1 1 c 1 K q(s, a) 0-hop 1-hop 2-hop c 2 1 c 2 K Figure 1:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_49",
            "start": 0,
            "end": 343,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_50@0",
            "content": "An example of multi-hop ILP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_50",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_50@1",
            "content": "The existential predicates r 1 , ..., r M are used to define invented predicates r l 1 , ..., r l M l through attentions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_50",
            "start": 29,
            "end": 149,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_50@2",
            "content": "The invented predicates will produce the final clauses to define q.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_50",
            "start": 151,
            "end": 217,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_51@0",
            "content": "chosen as a bridging entity using",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_51",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_52@0",
            "content": "p l k = \u03c3(v \u22a4 l [ hs ; h l k ; hs \u2022 h l k ]),(4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_52",
            "start": 0,
            "end": 47,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_53@0",
            "content": "where \u03c3(\u2022) is the sigmoid function, h l k is the l-hop intermediate entity representation for context c k computed using (2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_53",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_54@0",
            "content": "Multi-Hop Reasoner",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_54",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_55@0",
            "content": "The multi-hop reasoner aims to conduct complex reasoning by first generating probable logic clauses and then evaluating each clause by instantiating the variables.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_55",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_55@1",
            "content": "The clause generation process is parameterized by attentive memories which compute the probability of selecting each atom to form a relevant clause to entail the query relation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_55",
            "start": 164,
            "end": 340,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_55@2",
            "content": "An illustration of the procedure is shown in Figure 1 and will be elaborated in the next section.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_55",
            "start": 342,
            "end": 438,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_55@3",
            "content": "Then the clause evaluation process will ground each atom with query subjects, candidate entities or bridging entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_55",
            "start": 440,
            "end": 557,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_55@4",
            "content": "The outputs from the attentive reader, i.e., hs , ha and {h l k }'s (l > 0), can be regarded as these constant representations to compute the atom scores for clause evaluation and updates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_55",
            "start": 559,
            "end": 746,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_56@0",
            "content": "Clause Generation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_56",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_57@0",
            "content": "A definite clause is composed of atoms defined over relational predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_57",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_57@1",
            "content": "Since there are no explicit relations given in this task, we pre-define a fixed set of relations for each corpus, named as existential predicates: P E ={r 1 , ..., r M }, e.g., \"located_in\", \"next_to\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_57",
            "start": 75,
            "end": 275,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_57@2",
            "content": "For expressiveness, we further create a set of invented predicates P I =\u222a L l=0 P l I defined from the existential predicates, inspired by (Evans and Grefenstette, 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_57",
            "start": 277,
            "end": 446,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_57@3",
            "content": "Specifically, P l I = {r l 1 , ..., r l M l } consists of invented predicates r l m defined using l-hop reasoning clauses F 0 (X 0 , X 1 ) \u2227 ... \u2227 F l (X l , X l+1 ) \u21d2 r l m (X 0 , X l+1 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_57",
            "start": 448,
            "end": 636,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_57@4",
            "content": "For example, located_in(X 0 , X 1 ) \u2227 next_to(X 1 , X 2 ) \u21d2 outside(X 0 , X 2 ) defines a 1-hop invented predicate \"outside\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_57",
            "start": 638,
            "end": 762,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_57@5",
            "content": "Here L is the maximum hop number.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_57",
            "start": 764,
            "end": 796,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_57@6",
            "content": "The final clauses defining the query relation will be produced by learning to select relevant invented predicates, e.g., r l 1 i (X, Y ) \u2227 ... \u2227 r ln j (X, Y ) \u21d2 q(X, Y ) with 0 \u2264 l 1 \u2264 ... \u2264 l n \u2264 L. The number of actual inference steps l n to answer q is flexibly decided by the model itself (will be discussed later).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_57",
            "start": 798,
            "end": 1117,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_58@0",
            "content": "The clause generation process is divided into two stages: 1) generate clauses defining invented predicates using only the existential predicates; 2) generate final clauses defining query relation using only the invented predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_58",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_58@1",
            "content": "To allow for smooth optimization, we parameterize both stages by computing an attention weight for each predicate indicating its probability to appear in the clause body.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_58",
            "start": 232,
            "end": 401,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_58@2",
            "content": "Specifically, we assign each predicate a learnable embedding to indicate its semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_58",
            "start": 403,
            "end": 489,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_58@3",
            "content": "Let U \u2208 R D\u00d7M denote the embedding matrix for M existential predicates and U l \u2208 R D\u00d7M l (l \u2208 {0, 1, ..., L}) denote the embedding matrix for l-hop invented predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_58",
            "start": 491,
            "end": 658,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_58@4",
            "content": "In the first stage, we use attentive memories to generate",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_58",
            "start": 660,
            "end": 716,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_59@0",
            "content": "S l t = sparsemax((W l t U l t ) \u22a4 (W l b U)), (5) U l t+1 = U l t + S l t \u2022 (W l v U),(6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_59",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_60@0",
            "content": "where U l 0 = U l .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_60",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_60@1",
            "content": "W l t and W l b are transformation matrices for invented predicates (queries) and existential predicates (keys), respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_60",
            "start": 20,
            "end": 145,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_60@2",
            "content": "We use sparsemax which is a sparse version of softmax (Martins and Astudillo, 2016) to select only a small number of predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_60",
            "start": 147,
            "end": 274,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_60@3",
            "content": "Intuitively, to learn to define a l-hop invented predicate r l m , ( 5) and (6) will sequentially produce F t (X t , X t+1 ) at each step t \u2208 {0, ..., l} to form the clause body by attending over all the existential predicates with attention weight S l t .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_60",
            "start": 276,
            "end": 531,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_60@4",
            "content": "For example, when l = 1, (5) first attends to the existential predicate r i to generate F 0 (X 0 , X 1 ) = r i (X 0 , X 1 ) at step t = 0, and then attends to another predicate r j to generate",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_60",
            "start": 533,
            "end": 724,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_61@0",
            "content": "F 1 (X 1 , X 2 ) = r j (X 1 , X 2 ) at step t = 1. The resulting clause r i (X 0 , X 1 ) \u2227 r j (X 1 , X 2 ) \u21d2 r 1 m (X 0 , X 2 ) defines the invented predicate r 1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_61",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_62@0",
            "content": "m .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_62",
            "start": 0,
            "end": 2,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_62@1",
            "content": "In the second stage, we produce H final clauses taking invented predicates to define the target atom q(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_62",
            "start": 4,
            "end": 113,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_62@2",
            "content": "Given an embedding u q \u2208 R D for the target relation q, we use a multi-head attention mechanism to compute a probability distribution s i over all the invented predicates for each head i \u2208 {1, ..., H} to produce the i-th final clause:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_62",
            "start": 115,
            "end": 348,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_63@0",
            "content": "s i =sparsemax{(W i q u q ) \u22a4 (W i h [U 0 ;...;U L ])} (7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_63",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_64@0",
            "content": "where s i is a sparse selective distribution over P I = {r 0 1 , ..., r L M L }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_64",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_64@1",
            "content": "For example, if s i selects r 0 1 and r 1 2 , the final clause becomes r 0 1 (X, Y ) \u2227 r 1 2 (X, Y ) \u21d2 q(X, Y ), which involves at most 1 inference step (r 12 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_64",
            "start": 81,
            "end": 241,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_64@2",
            "content": "This completes the recursive rule generation step with multi-hop inference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_64",
            "start": 243,
            "end": 317,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_64@3",
            "content": "To this end, we generate H clauses that can be used to define q(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_64",
            "start": 319,
            "end": 389,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_65@0",
            "content": "Clause Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_65",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_66@0",
            "content": "Instantiation The clauses generated using the attentive memories will be tested and refined against the given positive and negative examples, known as learning from entailment that tries to maximize the truth probabilities of positive examples and minimize those of negative examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_66",
            "start": 0,
            "end": 283,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_66@1",
            "content": "The positive examples correspond to q(s, a) and the negative examples correspond to {q(s, a j )}'s, where s, a and a j refers to the query subject, correct answer and incorrect candidate, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_66",
            "start": 285,
            "end": 485,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_66@2",
            "content": "To obtain the truth probabilities of these atoms, we first instantiate the variables for each generated clause, e.g., X = s and Y = a (or Y = a j ) in q(X, Y ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_66",
            "start": 487,
            "end": 646,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_66@3",
            "content": "The bridging variables X 1 , ..., X l are instantiated using the bridging contexts selected via the attentive reader as introduced in 4.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_66",
            "start": 648,
            "end": 785,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_66@4",
            "content": "To avoid inaccurate selection, for each X l , we pick K contexts {c l 1 , ..., c l K } with highest probabilities according to p l k in (4).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_66",
            "start": 787,
            "end": 926,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_66@5",
            "content": "Neural Logic Operator Given a definite clause b 1 \u2227 ... \u2227 b K \u21d2 h consisting of grounded atoms (e.g., b 1 = r 1 (s, a)), we could obtain the value for its head atom as \u00b5(h) = \u00b5(b 1 \u2227 ... \u2227 b k ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_66",
            "start": 928,
            "end": 1122,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_66@6",
            "content": "To compute the RHS involving logic operators (\u2227, \u2228), T-norm (Klement et al., 2013) is usually adopted:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_66",
            "start": 1124,
            "end": 1225,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_67@0",
            "content": "T : [0, 1] \u00d7 [0, 1] \u2192 [0, 1]. For example, mini- mum t-norm defines T \u2227 (\u00b5 1 , \u00b5 2 ) = min(\u00b5 1 , \u00b5 2 ), T \u2228 (\u00b5 1 , \u00b5 2 ) = max(\u00b5 1 , \u00b5 2 ). Product t-norm de- fines T \u2227 (\u00b5 1 , \u00b5 2 ) = \u00b5 1 \u2022 \u00b5 2 , T \u2228 (\u00b5 1 , \u00b5 2 ) = 1 \u2212 (1 \u2212 \u00b5 1 )\u2022(1\u2212\u00b5 2 ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_67",
            "start": 0,
            "end": 238,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_68@0",
            "content": "Here \u00b5 1 , \u00b5 2 \u2208 [0, 1] refer to the value for the body atoms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_68",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_68@1",
            "content": "However, minimum t-norm is prone to learning plateau because the gradient only flows through one of the inputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_68",
            "start": 63,
            "end": 173,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_68@2",
            "content": "Product t-norm is less stable and is prone to exponential decay when the number of atoms in the clause grows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_68",
            "start": 175,
            "end": 283,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_69@0",
            "content": "To address these limitations, we propose a novel neural logic operator G defined as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_69",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_70@0",
            "content": "G \u2228 (\u00b5 1 , ..., \u00b5 K )=1\u2212exp K k=1 log(1 \u2212 \u00b5 k + \u03f5) 1 K G \u2227 (\u00b5 1 , ..., \u00b5 K )=exp K k=1 log(\u00b5 k + \u03f5) 1 K , (8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_70",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_71@0",
            "content": "where \u00b5 1 , ..., \u00b5 K \u2208 [0, 1] refer to the probabilistic values of all the atoms in the conjunctive (\u2227) or disjunctive (\u2228) clause.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_71",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_71@1",
            "content": "\u03f5 is a small value to guarantee the validity for logarithm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_71",
            "start": 131,
            "end": 189,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_71@2",
            "content": "The operator G has the following property that is ideal for logic semantics: 1) , where min refers to the index of the minimum value among {\u00b5 1 , ..., \u00b5 K }.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_71",
            "start": 191,
            "end": 347,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_72@0",
            "content": "Proposition 1. When \u2200\u00b5 k \u2192 1 with 1 \u2264 k \u2264 K, G \u2227 (\u00b5 1 , ..., \u00b5 K ) \u2192 1, aligning with logic \"AND\". When \u2203\u00b5 k \u2192 1, G \u2228 (\u00b5 1 , ..., \u00b5 K ) \u2192 1, aligning with logic \"OR\". Proposition 2. 0 \u2264 G \u2227 (\u00b5 1 , ..., \u00b5 K ) \u2212 \u00b5 min \u2264 (K 1/(1\u2212K) \u2212 K K/(1\u2212K) )( k\u0338 =min \u00b5 k ) 1/(K\u2212",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_72",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@0",
            "content": "In other words, the difference between G \u2227 and \u00b5 min is bounded.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@1",
            "content": "When K = 2, the RHS of the inequality equals to 1/4 \u2022 \u00b5 k\u0338 =min , which makes G \u2227 closer to \u00b5 min when \u00b5 k\u0338 =min is smaller.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 65,
            "end": 188,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@2",
            "content": "The proof can be found in the Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 190,
            "end": 228,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@3",
            "content": "This formulation results in a more stable and smooth gradient flow compared to minimum t-norm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 230,
            "end": 323,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@4",
            "content": "Moreover, It avoids exponential decay in the output when K > 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 325,
            "end": 387,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@5",
            "content": "It also facilitates neural learning when the exact clause is parameterized with attention scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 389,
            "end": 485,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@6",
            "content": "Evaluation With the neural logic operator defined above, the value for the head atom can be inferred once the value for each body atom is given.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 487,
            "end": 630,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@7",
            "content": "For grounded atoms over existential predicates, e.g., r m (s, a), we directly generate its value using a relational network F : R d \u00d7 R d \u2192 R M that takes the features of two constant arguments as input to produce a probability distribution over all the existential predicates r 1 , ..., r M : F( hs , ha ) = softmax(W r tanh[ hs ; ha ; hs \u2212 ha ; hs \u2022 ha ]).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 632,
            "end": 989,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@8",
            "content": "Then \u00b5(r m (s, a)) takes the m-th entry of F( hs , ha ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 991,
            "end": 1046,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@9",
            "content": "Here hs and ha are the outputs from the attentive reader.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 1048,
            "end": 1104,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@10",
            "content": "Similarly, h l k can be regarded as the feature of c l k generated from the attentive reader which is used to compute atom values with bridging entities, e.g., \u00b5(r m (s, c l k )).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 1106,
            "end": 1284,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_73@11",
            "content": "For l-hop grounded atoms over invented predicates {r l 1 (s, a), ..., r l M l (s, a)}, we compute their values according to the value of the clause body that defines them, e.g., \u00b5(F 0 (s, c 1 ) \u2227 ... \u2227 F l (c l , a)) using neural logic operators:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_73",
            "start": 1286,
            "end": 1531,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_74@0",
            "content": "\u00b5 l = max z\u2208Z l exp l t=0 S l t log(\u00b5 (zt,z t+1 ) +\u03f5) 1 (l+1) (9)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_74",
            "start": 0,
            "end": 64,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@0",
            "content": "Here \u00b5 l = [\u00b5(r l 1 (s, a)), ..., \u00b5(r l M l (s, a))] \u22a4 denotes the vector of the atom values formed by those l-hop invented predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@1",
            "content": "We denote by Z l = {(s, c 1 k , ..., c l k , a)} 1\u2264k\u2264K the set for all possible instantiations for l-hop reasoning and denote by z t the tth constant of z \u2208 Z l .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 136,
            "end": 297,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@2",
            "content": "\u00b5 (zt,z t+1 ) = [\u00b5(r 1 (z t , z t+1 )), ..., \u00b5(r M (z t , z t+1 ))] \u22a4 is a vector of values for grounded atoms over existential predicates.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 299,
            "end": 437,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@3",
            "content": "exp(\u2022) thus gives a neural approximation of logic conjunctions as shown in (8) over {F t (z t , z t+1 )} 0\u2264t\u2264l , each of which is a sparse selection of existential predicates using S l t .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 439,
            "end": 626,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@4",
            "content": "We use a max operator to generate the maximum score over all possible bridging entities to represent the final truth probability of each invented predicate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 628,
            "end": 783,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@5",
            "content": "Intuitively, a relation between two entities should be satisfied as long as there is at least one instantiation that follows the rule.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 785,
            "end": 918,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@6",
            "content": "Also note that (9) has the effect that when S l t [i, j] \u2248 0, the corresponding predicate r j will have little effect on the value of its head r l i , which is in contrast to existing T-norms.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 920,
            "end": 1111,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_75@7",
            "content": "The final value for q(s, a) is similarly computed:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_75",
            "start": 1113,
            "end": 1162,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_76@0",
            "content": "\u00b5(q(s, a))= max 1\u2264i\u2264H exp s i log([\u00b5 0 ; ...; \u00b5 L ] + \u03f5) .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_76",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_77@0",
            "content": "We use the cross-entropy loss over \u00b5(q(s, a)) as the final objective to train the entire model (except the word embeddings which are kept fixed) in an endto-end manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_77",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_77@1",
            "content": "Here we organize the dataset according to subject-candidate pairs: (s n , a n ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_77",
            "start": 169,
            "end": 248,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_77@2",
            "content": "We associate the ground-truth label y n = 1 with (s n , a n ) if a n is the correct answer, otherwise, y n = 0.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_77",
            "start": 250,
            "end": 360,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_78@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_78",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@0",
            "content": "We conduct experiments on two multi-hop reading comprehension datasets, namely WikiHop and MedHop (Welbl et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@1",
            "content": "The WikiHop dataset contains 43,738 training and 5,129 development instances ranging over 277 query relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 120,
            "end": 229,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@2",
            "content": "MedHop is a medical dataset containing 1,620 training and 342 development instances with a unique query relation, i.e., \"interact with\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 231,
            "end": 366,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@3",
            "content": "For WikiHop, we experiment with both non-contextual (follow (Weber et al., 2019)) named as DILR and contextual word embeddings (BERT (Devlin et al., 2019)) named as DILR-BERT to demonstrate our model's generalization ability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 368,
            "end": 592,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@4",
            "content": "For MedHop, we use the same setting following (Weber et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 594,
            "end": 660,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@5",
            "content": "We define M = 10 relations as existential predicates and M l = 5 invented predicates for each hop with l = 0, 1, 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 662,
            "end": 776,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@6",
            "content": "The number of final clauses to define the query relation is H = 5 and the number of candidate bridging contexts for each hop is set to K = 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 778,
            "end": 918,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@7",
            "content": "The dimension of predicate embeddings and biGRU layer is 100 and 200, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 920,
            "end": 1002,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@8",
            "content": "For training, we adopt Adam optimization with learning rate initialized at 0.001.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 1004,
            "end": 1084,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@9",
            "content": "The batch size is set to 10.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 1086,
            "end": 1113,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_79@10",
            "content": "For all the experiments, we use the development dataset to evaluate the results because the test data is not publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_79",
            "start": 1115,
            "end": 1242,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_80@0",
            "content": "Experimental Result",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_80",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@0",
            "content": "Weber et al. ( 2019) only selects four different query relations from WikiHop, namely Publisher, Developer, Country and Record_label, to evaluate their model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@1",
            "content": "For fair comparison, we first follow their setting to compare on these specific domains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 159,
            "end": 246,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@2",
            "content": "Besides BIDAF (Seo et al., 2017) and FastQA (Weissenborn et al., 2017), we also consider another three representative deep learning baselines : EPAr (Yichen Jiang and Bansal, 2019), HDEG (Tu et al., 2019), DynSAN (Zhuang and Wang, 2019) 2 , and a differentiable reasoning model DrMD adapted from (Dhingra et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 248,
            "end": 566,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@3",
            "content": "HDEG is a graph-based DNN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 568,
            "end": 593,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@4",
            "content": "EPAr and DynSAN are memory-based DNNs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 595,
            "end": 632,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@5",
            "content": "DrMD is implemented following (Dhingra et al., 2020), except that we remove pre-defined entities and only consider mention interactions given our settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 634,
            "end": 788,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@6",
            "content": "BERT is a baseline model that concatenates query subject (or a candidate entity) with each context in the form of we feed the hidden representations corresponding to the query subject (or candidates) into an attention model to generate a single vector to be fed into a classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 790,
            "end": 1069,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@7",
            "content": "For all the baselines, we train the models on each query relation separately to test the reasoning capability, same as our setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1071,
            "end": 1201,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@8",
            "content": "Table 1 lists the results for MedHop and four query relations from WikiHop according to (Weber et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1203,
            "end": 1311,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@9",
            "content": "Clearly, DILR substantially outperforms all the baselines on MedHop, demonstrating the importance of the reasoning capabilities for interaction-intensive medical dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1313,
            "end": 1482,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@10",
            "content": "On the four query relations from WikiHop, we still obtain the best performances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1484,
            "end": 1563,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@11",
            "content": "Though NLProlog also conducts logic reasoning, it is limited by the model's capacity and relies on the extraction accuracy of the NER tool.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1565,
            "end": 1703,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@12",
            "content": "Furthermore, we also evaluate on all the other valid query relations 3 in WikiHop for a more complete analysis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1705,
            "end": 1815,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@13",
            "content": "The results in terms of accuracy are shown in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1817,
            "end": 1870,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@14",
            "content": "For a more thorough analysis, we group the query relations in terms of the number of training instances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1872,
            "end": 1975,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@15",
            "content": "As shown in Table 2, there are 38 relations (D1) containing less than 1,000 training examples, 7 relations (D2) with training examples ranging from 1,000 to 4,000 and 2 relations (D3) having more than 4,000 training examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 1977,
            "end": 2201,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@16",
            "content": "We report the micro-average accuracy scores over all the domains within each data group and their combinations in Table 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 2203,
            "end": 2324,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@17",
            "content": "Our model achieves the best performances over all data groups, demonstrating the advantage of combining deep attentive learning with logic reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 2326,
            "end": 2474,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@18",
            "content": "The margin is larger for D1 and D3, demonstrating the consistency of our proposed model with varying data sizes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 2476,
            "end": 2587,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@19",
            "content": "In fact, ILP could be beneficial when training data is not sufficient via learning of generalized rules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 2589,
            "end": 2692,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@20",
            "content": "Even with well-trained contextualized word embeddings, DILR still brings consistent performance gains.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 2694,
            "end": 2795,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_81@21",
            "content": "The Detailed comparison on each query relation can be found in Appendix.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_81",
            "start": 2797,
            "end": 2868,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_82@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_82",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_83@0",
            "content": "To provide detailed analysis, we conduct ablation experiments on 6 datasets as shown in Table 3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_83",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_83@1",
            "content": "For fair demonstration, we pick one relation in D3 (Located), 2 relations in D2 (Occupation and Record) and 3 relations in D1 (Publisher, Producer, Country).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_83",
            "start": 97,
            "end": 253,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_83@2",
            "content": "The first four rows reflect the accuracies by varying the maximum allowed number of reasoning hops (L).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_83",
            "start": 255,
            "end": 357,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_83@3",
            "content": "Clearly, \u2264 0 Hop and \u2264 3 Hop produce lower accuracies due to either missing bridging entities or overfitting with excessive inference steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_83",
            "start": 359,
            "end": 498,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@0",
            "content": "The middle part of Table 3 reflects the effect of each element of DILR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@1",
            "content": "Specifically, \u2212PI removes the invented predicates: remove (5), ( 6), ( 9) and replace U l with U in (7).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 72,
            "end": 175,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@2",
            "content": "\u2212ILP removes the reasoner and uses a classifier on top of the attentive reader to produce the final predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 177,
            "end": 288,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@3",
            "content": "\u2212AR removes the attentive reader and uses NER tools to extract entities for reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 290,
            "end": 375,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@4",
            "content": "\u2212Rel only computes binary relations that decide whether two constants are related or not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 377,
            "end": 465,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@5",
            "content": "This demonstrates the effect of relational reasoning considering different relations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 467,
            "end": 551,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@6",
            "content": "By comparison, it is evident that removing any component will suffer from non-trivial prediction loss, especially for ILP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 553,
            "end": 674,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@7",
            "content": "To verify the effect of the neural logic operator (NLO), we compare it with two T-norm operators, namely \"prod-T\" for product T-norm and \"min-T\" for minimum T-norm.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 676,
            "end": 839,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_84@8",
            "content": "Clearly, NLO produces the best performances across all the experiments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_84",
            "start": 841,
            "end": 911,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@0",
            "content": "To provide a concrete view of how the attentive reader filters relevant information and how the generated clauses look like, we list three examples as shown in Table 4.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@1",
            "content": "The underlined texts have the maximum attention weights learned from the attentive reader.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 169,
            "end": 258,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@2",
            "content": "The bold texts indicate the query subject and the correct answer for each query.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 260,
            "end": 339,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@3",
            "content": "Clearly, the attentive reader is able to select bridging entities relevant to the answer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 341,
            "end": 429,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@4",
            "content": "The third column lists some learned clauses from the reasoner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 431,
            "end": 492,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@5",
            "content": "The first row of each example shows the clauses that define an invented predicate and the second row shows the final clause that entails the query relation 4 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 494,
            "end": 652,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@6",
            "content": "We use abbreviated entities as the constants in each grounded atom (e.g., \"CC\" is short for \"Chris Church\") due to space limitations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 654,
            "end": 786,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_85@7",
            "content": "The two clauses for the first example could be read as: if Chris Church and Massachusetts has relation r 7 , and Massachusetts and United States has relation r 2 , then the country of Chris Church is United States.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_85",
            "start": 788,
            "end": 1001,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_86@0",
            "content": "We further demonstrate the robustness of DILR by varying model parameters, as shown in Figure 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_86",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_86@1",
            "content": "The top subplots reveal the accuracies on MedHop and Country datasets when changing the number of final clauses H (left) and the number of existential predicates M (right).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_86",
            "start": 97,
            "end": 268,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_86@2",
            "content": "The subplot in the bottom depicts the accuracies when varying the number of instantiations K of the bridging contexts for Genre dataset under both DILR and BERT-DILR models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_86",
            "start": 270,
            "end": 442,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_86@3",
            "content": "We shall observe that the performances are relatively stable given that the total number of testing examples are less than 400 for each dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_86",
            "start": 444,
            "end": 587,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_87@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_87",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_88@0",
            "content": "We propose an end-to-end model DILR to solve the problem of multi-hop reading comprehension.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_88",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_88@1",
            "content": "DILR smoothly connects a hierarchical attentive reader with a multi-hop reasoner to conduct automatic information extraction and complex reasoning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_88",
            "start": 93,
            "end": 239,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_88@2",
            "content": "We also introduce differentiable logic operators to induce valid clauses with smooth and stable gradient-based learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_88",
            "start": 241,
            "end": 360,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_88@3",
            "content": "Extensive experiments reveal consistent improvements brought by DILR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_88",
            "start": 362,
            "end": 430,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_89@0",
            "content": "Proof.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_89",
            "start": 0,
            "end": 5,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_90@0",
            "content": "G \u2227 (\u00b5 1 , ..., \u00b5 K ) \u2212 \u00b5 min = exp( K k=1 log \u00b5 k + \u03f5) 1/K \u2212 \u00b5 min \u2248 K k=1 \u00b5 1/K k \u2212 \u00b5 min(10)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_90",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_91@0",
            "content": "Without loss of generality, assume the minimum value is \u00b5 min = \u00b5 1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_91",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_91@1",
            "content": "By fixing \u00b5 2 , ..., \u00b5 K as constants, we obtain the gradient for (10) w.r.t. \u00b5 1 as",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_91",
            "start": 70,
            "end": 153,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_92@0",
            "content": "1 K \u00b5 (1\u2212K)/K 1 K k=2 \u00b5 1/K k \u2212 1.(11)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_92",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_93@0",
            "content": "Then ( 10) is concave and has a maximum value obtained when (11) equals to 0, resulting in",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_93",
            "start": 0,
            "end": 89,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_94@0",
            "content": "\u00b5 1 = K K/(1\u2212K) K k=2 \u00b5 1/(K\u22121) k . (12",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_94",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_95@0",
            "content": "UNKNOWN, None, , Massachusetts is the most populous state in, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_95",
            "start": 0,
            "end": 62,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_96@0",
            "content": "UNKNOWN, None, , Massachusetts. r7(CC, M ) \u2227 r2, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_96",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_97@0",
            "content": "J References, M Andreas, T Rohrbach, D Darrell,  Klein, Neural module networks, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_97",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_98@0",
            "content": "UNKNOWN, None, 2018, Logical rule induction and theory learning using neural theorem proving, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_98",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_99@0",
            "content": "UNKNOWN, None, 1910, Multi-hop question answering via reasoning chains. CoRR, abs, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_99",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_100@0",
            "content": "Xinyun Chen, Chen Liang, Adams Yu, Denny Zhou, Dawn Song, V Quoc,  Le, Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension, 2020-04-26, 8th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_100",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_101@0",
            "content": "Christopher Clark, Matt Gardner, Simple and effective multi-paragraph reading comprehension, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_101",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_102@0",
            "content": "UNKNOWN, None, 2016, Tensorlog: A differentiable deductive database, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_102",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_103@0",
            "content": "Nicola De Cao, Wilker Aziz, Ivan Titov, Question answering by reasoning across documents with graph convolutional networks, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_103",
            "start": 0,
            "end": 274,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_104@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, NAACL-HLT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_104",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_105@0",
            "content": "Bhuwan Dhingra, Qiao Jin, Zhilin Yang, William Cohen, Ruslan Salakhutdinov, Neural models for reasoning over multiple mentions using coreference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_105",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_106@0",
            "content": "Bhuwan Dhingra, Manzil Zaheer, Vidhisha Balachandran, Graham Neubig, Ruslan Salakhutdinov, William Cohen, Differentiable reasoning over a virtual knowledge base, 2020, ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_106",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_107@0",
            "content": "Ming Ding, Chang Zhou, Qibin Chen, Hongxia Yang, Jie Tang, Cognitive graph for multi-hop reading comprehension at scale, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_107",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_108@0",
            "content": "Honghua Dong, Jiayuan Mao, Tian Lin, Chong Wang, Lihong Li, Denny Zhou, Neural logic machines, 2019, ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_108",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_109@0",
            "content": "Richard Evans, Edward Grefenstette, Learning explanatory rules from noisy data, 2018, J. Artif. Intelligent Res, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_109",
            "start": 0,
            "end": 113,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_110@0",
            "content": "V Manoel, Gerson Fran\u00e7a, Artur Zaverucha,  D'avila Garcez, Fast relational learning using bottom clause propositionalization with artificial neural networks, 2014, Mach. Learn, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_110",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_111@0",
            "content": "Shu Guo, Quan Wang, Lihong Wang, Bin Wang, Li Guo, Jointly embedding knowledge graphs and logical rules, 2016, EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_111",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_112@0",
            "content": "UNKNOWN, None, 2020, Neural module networks for reasoning over text. ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_112",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_113@0",
            "content": "Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard Hovy, Eric Xing, Harnessing deep neural networks with logic rules, 2016, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_113",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_114@0",
            "content": "Yichen Jiang, Mohit Bansal, Self-assembling modular networks for interpretable multi-hop reasoning, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_114",
            "start": 0,
            "end": 283,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_115@0",
            "content": "UNKNOWN, None, 2013, Triangular norms, Springer Science and Business Media.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_115",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_116@0",
            "content": "Souvik Kundu, Tushar Khot, Ashish Sabharwal, Peter Clark, Exploiting explicit paths for multihop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_116",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_117@0",
            "content": "Tao Li, Vivek Srikumar, Augmenting neural networks with first-order logic, 2019, ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_117",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_118@0",
            "content": "Robin Manhaeve, Sebastijan Dumancic, Angelika Kimmig, Thomas Demeester, Luc De Raedt, Deepproblog: Neural probabilistic logic programming, 2018, NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_118",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_119@0",
            "content": "Andre Martins, Ramon Astudillo, From softmax to sparsemax: A sparse model of attention and multi-label classification, 2016, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_119",
            "start": 0,
            "end": 131,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_120@0",
            "content": "Sewon Min, Victor Zhong, Luke Zettlemoyer, Hannaneh Hajishirzi, Multi-hop reading comprehension through question decomposition and rescoring, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_120",
            "start": 0,
            "end": 237,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_121@0",
            "content": "Pasquale Minervini, Matko Bosnjak, Tim Rockt\u00e4schel, Sebastian Riedel, Edward Grefenstette, Differentiable reasoning on large knowledge bases and natural language, 2020, AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_121",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_122@0",
            "content": "Pasquale Minervini, Thomas Demeester, Tim Rockt\u00e4schel, Sebastian Riedel, Adversarial sets for regularised neural link predictors, 2017, UAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_122",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_123@0",
            "content": "Stephen Muggleton, Inductive logic programming, 1991, New Generation Computing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_123",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_124@0",
            "content": "Lin Qiu, Yunxuan Xiao, Yanru Qu, Hao Zhou, Lei Li, Weinan Zhang, Yong Yu, Dynamically fused graph network for multi-hop reasoning, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_124",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_125@0",
            "content": "Meng Qu, Jian Tang, Probabilistic logic neural networks for reasoning, 2019, NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_125",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_126@0",
            "content": "Tim Rockt\u00e4schel, Sebastian Riedel, End-toend differentiable proving, 2017, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_126",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_127@0",
            "content": "UNKNOWN, None, 2017, Query-reduction networks for question answering, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_127",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_128@0",
            "content": "UNKNOWN, None, 2018, Exploring graph-structured passage representation for multihop reading comprehension with graph neural networks, CoRR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_128",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_129@0",
            "content": "Zeyun Tang, Yongliang Shen, Xinyin Ma, Wei Xu, Jiale Yu, Weiming Lu, Multi-hop reading comprehension across documents with path-based graph convolutional network, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_129",
            "start": 0,
            "end": 270,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_130@0",
            "content": "Ming Tu, Guangtao Wang, Jing Huang, Yun Tang, Xiaodong He, Bowen Zhou, Multi-hop reading comprehension across multiple documents by reasoning over heterogeneous graphs, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_130",
            "start": 0,
            "end": 264,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_131@0",
            "content": "Po-Wei Wang, Priya Donti, Bryan Wilder, J Kolter, Satnet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver, 2019, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_131",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_132@0",
            "content": "Wenya Wang,  Sinno Jialin Pan, Integrating deep learning with logic fusion for information extraction, 2020, AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_132",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_133@0",
            "content": "Yizhong Wang, Kai Liu, Jing Liu, Wei He, Yajuan Lyu, Hua Wu, Sujian Li, Haifeng Wang, Multipassage machine reading comprehension with crosspassage answer verification, 2018, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_133",
            "start": 0,
            "end": 274,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_134@0",
            "content": "Leon Weber, Pasquale Minervini, Jannes M\u00fcnchmeyer, Ulf Leser, Tim Rockt\u00e4schel, NLProlog: Reasoning with weak unification for question answering in natural language, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_134",
            "start": 0,
            "end": 260,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_135@0",
            "content": "UNKNOWN, None, 2017, Fastqa: A simple and efficient neural architecture for question answering. arXiv: Computation and Language, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_135",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_136@0",
            "content": "Johannes Welbl, Pontus Stenetorp, Sebastian Riedel, Constructing datasets for multi-hop reading comprehension across documents, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_136",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_137@0",
            "content": "Meixi Wu, Wenya Wang, Sinno Jialin Pan, Deep Weighted MaxSAT for Aspect-based Opinion Extraction, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_137",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_138@0",
            "content": "Jingyi Xu, Zilu Zhang, Tal Friedman, Yitao Liang, Guy Van Den Broeck, A semantic loss function for deep learning with symbolic knowledge, 2018, ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_138",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_139@0",
            "content": "Fan Yang, Zhilin Yang, William Cohen, Differentiable learning of logical rules for knowledge base reasoning, 2017, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_139",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_140@0",
            "content": "UNKNOWN, None, 2020, Learn to explain efficiently via neural logic inductive learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_140",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_141@0",
            "content": "Yen-Chun Chen Yichen Jiang, Nitish Joshi, Mohit Bansal, Explore, propose, and assemble: An interpretable model for multi-hop reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_141",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_142@0",
            "content": "Victor Zhong, Caiming Xiong, Nitish Shirish Keskar, Richard Socher, Coarse-grain fine-grain coattention network for multi-evidence question answering, 2019, 7th International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_142",
            "start": 0,
            "end": 215,
            "label": {}
        },
        {
            "ix": "141-ARR_v1_143@0",
            "content": "Yimeng Zhuang, Huadong Wang, Token-level dynamic self-attention network for multi-passage reading comprehension, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "141-ARR_v1_143",
            "start": 0,
            "end": 208,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_1",
            "tgt_ix": "141-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_1",
            "tgt_ix": "141-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_2",
            "tgt_ix": "141-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_4",
            "tgt_ix": "141-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_5",
            "tgt_ix": "141-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_6",
            "tgt_ix": "141-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_7",
            "tgt_ix": "141-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_10",
            "tgt_ix": "141-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_11",
            "tgt_ix": "141-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_12",
            "tgt_ix": "141-ARR_v1_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_13",
            "tgt_ix": "141-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_13",
            "tgt_ix": "141-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_13",
            "tgt_ix": "141-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_15",
            "tgt_ix": "141-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_17",
            "tgt_ix": "141-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_18",
            "tgt_ix": "141-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_19",
            "tgt_ix": "141-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_20",
            "tgt_ix": "141-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_21",
            "tgt_ix": "141-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_22",
            "tgt_ix": "141-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_23",
            "tgt_ix": "141-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_24",
            "tgt_ix": "141-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_25",
            "tgt_ix": "141-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_26",
            "tgt_ix": "141-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_27",
            "tgt_ix": "141-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_30",
            "tgt_ix": "141-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_30",
            "tgt_ix": "141-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_31",
            "tgt_ix": "141-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_33",
            "tgt_ix": "141-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_34",
            "tgt_ix": "141-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_35",
            "tgt_ix": "141-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_36",
            "tgt_ix": "141-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_37",
            "tgt_ix": "141-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_38",
            "tgt_ix": "141-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_39",
            "tgt_ix": "141-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_40",
            "tgt_ix": "141-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_41",
            "tgt_ix": "141-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_43",
            "tgt_ix": "141-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_44",
            "tgt_ix": "141-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_45",
            "tgt_ix": "141-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_46",
            "tgt_ix": "141-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_47",
            "tgt_ix": "141-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_48",
            "tgt_ix": "141-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_49",
            "tgt_ix": "141-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_50",
            "tgt_ix": "141-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_51",
            "tgt_ix": "141-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_52",
            "tgt_ix": "141-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_53",
            "tgt_ix": "141-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_54",
            "tgt_ix": "141-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_54",
            "tgt_ix": "141-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_55",
            "tgt_ix": "141-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_58",
            "tgt_ix": "141-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_59",
            "tgt_ix": "141-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_60",
            "tgt_ix": "141-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_61",
            "tgt_ix": "141-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_62",
            "tgt_ix": "141-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_63",
            "tgt_ix": "141-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_64",
            "tgt_ix": "141-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_67",
            "tgt_ix": "141-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_68",
            "tgt_ix": "141-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_69",
            "tgt_ix": "141-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_70",
            "tgt_ix": "141-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_71",
            "tgt_ix": "141-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_72",
            "tgt_ix": "141-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_74",
            "tgt_ix": "141-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_76",
            "tgt_ix": "141-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_77",
            "tgt_ix": "141-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_78",
            "tgt_ix": "141-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_78",
            "tgt_ix": "141-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_78",
            "tgt_ix": "141-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_80",
            "tgt_ix": "141-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_80",
            "tgt_ix": "141-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_78",
            "tgt_ix": "141-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_83",
            "tgt_ix": "141-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_82",
            "tgt_ix": "141-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_82",
            "tgt_ix": "141-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_82",
            "tgt_ix": "141-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_82",
            "tgt_ix": "141-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_82",
            "tgt_ix": "141-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_86",
            "tgt_ix": "141-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_89",
            "tgt_ix": "141-ARR_v1_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_90",
            "tgt_ix": "141-ARR_v1_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_91",
            "tgt_ix": "141-ARR_v1_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_92",
            "tgt_ix": "141-ARR_v1_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_93",
            "tgt_ix": "141-ARR_v1_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_88",
            "tgt_ix": "141-ARR_v1_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "141-ARR_v1_0",
            "tgt_ix": "141-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_1",
            "tgt_ix": "141-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_2",
            "tgt_ix": "141-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_2",
            "tgt_ix": "141-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_2",
            "tgt_ix": "141-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_2",
            "tgt_ix": "141-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_2",
            "tgt_ix": "141-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_2",
            "tgt_ix": "141-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_3",
            "tgt_ix": "141-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_4",
            "tgt_ix": "141-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_4",
            "tgt_ix": "141-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_4",
            "tgt_ix": "141-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_5",
            "tgt_ix": "141-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_6",
            "tgt_ix": "141-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_7",
            "tgt_ix": "141-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_8@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_8",
            "tgt_ix": "141-ARR_v1_8@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_9",
            "tgt_ix": "141-ARR_v1_9@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_10",
            "tgt_ix": "141-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_10",
            "tgt_ix": "141-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_10",
            "tgt_ix": "141-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_10",
            "tgt_ix": "141-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_10",
            "tgt_ix": "141-ARR_v1_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_11",
            "tgt_ix": "141-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_12",
            "tgt_ix": "141-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_12",
            "tgt_ix": "141-ARR_v1_12@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_13",
            "tgt_ix": "141-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_14",
            "tgt_ix": "141-ARR_v1_14@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_15",
            "tgt_ix": "141-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_15",
            "tgt_ix": "141-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_15",
            "tgt_ix": "141-ARR_v1_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_15",
            "tgt_ix": "141-ARR_v1_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_15",
            "tgt_ix": "141-ARR_v1_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_16",
            "tgt_ix": "141-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_17",
            "tgt_ix": "141-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_17",
            "tgt_ix": "141-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_17",
            "tgt_ix": "141-ARR_v1_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_17",
            "tgt_ix": "141-ARR_v1_17@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_18",
            "tgt_ix": "141-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_18",
            "tgt_ix": "141-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_19",
            "tgt_ix": "141-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_20",
            "tgt_ix": "141-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_20",
            "tgt_ix": "141-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_20",
            "tgt_ix": "141-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_20",
            "tgt_ix": "141-ARR_v1_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_20",
            "tgt_ix": "141-ARR_v1_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_20",
            "tgt_ix": "141-ARR_v1_20@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_21",
            "tgt_ix": "141-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_21",
            "tgt_ix": "141-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_22",
            "tgt_ix": "141-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_23",
            "tgt_ix": "141-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_24",
            "tgt_ix": "141-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_25",
            "tgt_ix": "141-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_25",
            "tgt_ix": "141-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_25",
            "tgt_ix": "141-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_25",
            "tgt_ix": "141-ARR_v1_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_26",
            "tgt_ix": "141-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_27",
            "tgt_ix": "141-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_28",
            "tgt_ix": "141-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_29",
            "tgt_ix": "141-ARR_v1_29@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_30",
            "tgt_ix": "141-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_31",
            "tgt_ix": "141-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_31",
            "tgt_ix": "141-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_31",
            "tgt_ix": "141-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_31",
            "tgt_ix": "141-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_32",
            "tgt_ix": "141-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_33",
            "tgt_ix": "141-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_33",
            "tgt_ix": "141-ARR_v1_33@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_33",
            "tgt_ix": "141-ARR_v1_33@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_34",
            "tgt_ix": "141-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_35",
            "tgt_ix": "141-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_35",
            "tgt_ix": "141-ARR_v1_35@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_35",
            "tgt_ix": "141-ARR_v1_35@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_36",
            "tgt_ix": "141-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_37",
            "tgt_ix": "141-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_37",
            "tgt_ix": "141-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_37",
            "tgt_ix": "141-ARR_v1_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_38",
            "tgt_ix": "141-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_38",
            "tgt_ix": "141-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_39",
            "tgt_ix": "141-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_40",
            "tgt_ix": "141-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_40",
            "tgt_ix": "141-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_40",
            "tgt_ix": "141-ARR_v1_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_41",
            "tgt_ix": "141-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_42",
            "tgt_ix": "141-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_43",
            "tgt_ix": "141-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_43",
            "tgt_ix": "141-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_44",
            "tgt_ix": "141-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_45",
            "tgt_ix": "141-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_46",
            "tgt_ix": "141-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_47",
            "tgt_ix": "141-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_47",
            "tgt_ix": "141-ARR_v1_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_47",
            "tgt_ix": "141-ARR_v1_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_47",
            "tgt_ix": "141-ARR_v1_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_48",
            "tgt_ix": "141-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_49",
            "tgt_ix": "141-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_50",
            "tgt_ix": "141-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_50",
            "tgt_ix": "141-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_50",
            "tgt_ix": "141-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_51",
            "tgt_ix": "141-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_52",
            "tgt_ix": "141-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_53",
            "tgt_ix": "141-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_54",
            "tgt_ix": "141-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_55",
            "tgt_ix": "141-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_55",
            "tgt_ix": "141-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_55",
            "tgt_ix": "141-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_55",
            "tgt_ix": "141-ARR_v1_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_55",
            "tgt_ix": "141-ARR_v1_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_56",
            "tgt_ix": "141-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_57@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_57@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_57",
            "tgt_ix": "141-ARR_v1_57@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_58",
            "tgt_ix": "141-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_58",
            "tgt_ix": "141-ARR_v1_58@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_58",
            "tgt_ix": "141-ARR_v1_58@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_58",
            "tgt_ix": "141-ARR_v1_58@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_58",
            "tgt_ix": "141-ARR_v1_58@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_59",
            "tgt_ix": "141-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_60",
            "tgt_ix": "141-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_60",
            "tgt_ix": "141-ARR_v1_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_60",
            "tgt_ix": "141-ARR_v1_60@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_60",
            "tgt_ix": "141-ARR_v1_60@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_60",
            "tgt_ix": "141-ARR_v1_60@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_61",
            "tgt_ix": "141-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_62",
            "tgt_ix": "141-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_62",
            "tgt_ix": "141-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_62",
            "tgt_ix": "141-ARR_v1_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_63",
            "tgt_ix": "141-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_64",
            "tgt_ix": "141-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_64",
            "tgt_ix": "141-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_64",
            "tgt_ix": "141-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_64",
            "tgt_ix": "141-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_65",
            "tgt_ix": "141-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_66@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_66@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_66@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_66",
            "tgt_ix": "141-ARR_v1_66@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_67",
            "tgt_ix": "141-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_68",
            "tgt_ix": "141-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_68",
            "tgt_ix": "141-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_68",
            "tgt_ix": "141-ARR_v1_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_69",
            "tgt_ix": "141-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_70",
            "tgt_ix": "141-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_71",
            "tgt_ix": "141-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_71",
            "tgt_ix": "141-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_71",
            "tgt_ix": "141-ARR_v1_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_72",
            "tgt_ix": "141-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_73",
            "tgt_ix": "141-ARR_v1_73@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_74",
            "tgt_ix": "141-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_75",
            "tgt_ix": "141-ARR_v1_75@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_76",
            "tgt_ix": "141-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_77",
            "tgt_ix": "141-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_77",
            "tgt_ix": "141-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_77",
            "tgt_ix": "141-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_78",
            "tgt_ix": "141-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_79",
            "tgt_ix": "141-ARR_v1_79@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_80",
            "tgt_ix": "141-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@19",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@20",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_81",
            "tgt_ix": "141-ARR_v1_81@21",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_82",
            "tgt_ix": "141-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_83",
            "tgt_ix": "141-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_83",
            "tgt_ix": "141-ARR_v1_83@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_83",
            "tgt_ix": "141-ARR_v1_83@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_83",
            "tgt_ix": "141-ARR_v1_83@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_84",
            "tgt_ix": "141-ARR_v1_84@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_85",
            "tgt_ix": "141-ARR_v1_85@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_86",
            "tgt_ix": "141-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_86",
            "tgt_ix": "141-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_86",
            "tgt_ix": "141-ARR_v1_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_86",
            "tgt_ix": "141-ARR_v1_86@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_87",
            "tgt_ix": "141-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_88",
            "tgt_ix": "141-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_88",
            "tgt_ix": "141-ARR_v1_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_88",
            "tgt_ix": "141-ARR_v1_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_88",
            "tgt_ix": "141-ARR_v1_88@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_89",
            "tgt_ix": "141-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_90",
            "tgt_ix": "141-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_91",
            "tgt_ix": "141-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_91",
            "tgt_ix": "141-ARR_v1_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_92",
            "tgt_ix": "141-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_93",
            "tgt_ix": "141-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_94",
            "tgt_ix": "141-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_95",
            "tgt_ix": "141-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_96",
            "tgt_ix": "141-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_97",
            "tgt_ix": "141-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_98",
            "tgt_ix": "141-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_99",
            "tgt_ix": "141-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_100",
            "tgt_ix": "141-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_101",
            "tgt_ix": "141-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_102",
            "tgt_ix": "141-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_103",
            "tgt_ix": "141-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_104",
            "tgt_ix": "141-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_105",
            "tgt_ix": "141-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_106",
            "tgt_ix": "141-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_107",
            "tgt_ix": "141-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_108",
            "tgt_ix": "141-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_109",
            "tgt_ix": "141-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_110",
            "tgt_ix": "141-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_111",
            "tgt_ix": "141-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_112",
            "tgt_ix": "141-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_113",
            "tgt_ix": "141-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_114",
            "tgt_ix": "141-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_115",
            "tgt_ix": "141-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_116",
            "tgt_ix": "141-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_117",
            "tgt_ix": "141-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_118",
            "tgt_ix": "141-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_119",
            "tgt_ix": "141-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_120",
            "tgt_ix": "141-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_121",
            "tgt_ix": "141-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_122",
            "tgt_ix": "141-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_123",
            "tgt_ix": "141-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_124",
            "tgt_ix": "141-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_125",
            "tgt_ix": "141-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_126",
            "tgt_ix": "141-ARR_v1_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_127",
            "tgt_ix": "141-ARR_v1_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_128",
            "tgt_ix": "141-ARR_v1_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_129",
            "tgt_ix": "141-ARR_v1_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_130",
            "tgt_ix": "141-ARR_v1_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_131",
            "tgt_ix": "141-ARR_v1_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_132",
            "tgt_ix": "141-ARR_v1_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_133",
            "tgt_ix": "141-ARR_v1_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_134",
            "tgt_ix": "141-ARR_v1_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_135",
            "tgt_ix": "141-ARR_v1_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_136",
            "tgt_ix": "141-ARR_v1_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_137",
            "tgt_ix": "141-ARR_v1_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_138",
            "tgt_ix": "141-ARR_v1_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_139",
            "tgt_ix": "141-ARR_v1_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_140",
            "tgt_ix": "141-ARR_v1_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_141",
            "tgt_ix": "141-ARR_v1_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_142",
            "tgt_ix": "141-ARR_v1_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "141-ARR_v1_143",
            "tgt_ix": "141-ARR_v1_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1399,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "141-ARR",
        "version": 1
    }
}