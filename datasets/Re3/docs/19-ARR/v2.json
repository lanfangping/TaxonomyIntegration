{
    "nodes": [
        {
            "ix": "19-ARR_v2_0",
            "content": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_2",
            "content": "Natural language processing researchers have identified limitations of evaluation methodology for generation tasks, with new questions raised about the validity of automatic metrics and of crowdworker judgments. Meanwhile, efforts to improve generation models tend to depend on simple n-gram overlap metrics (e.g., BLEU, ROUGE). We argue that new advances on models and metrics should each more directly benefit and inform the other. We therefore propose a generalization of leaderboards, bidimensional leaderboards (BILLBOARDs), that simultaneously tracks progress in language generation models and metrics for their evaluation. Unlike conventional unidimensional leaderboards that sort submitted systems by predetermined metrics, a BILLBOARD accepts both generators and evaluation metrics as competing entries. A BILLBOARD automatically creates an ensemble metric that selects and linearly combines a few metrics based on a global analysis across generators. Further, metrics are ranked based on their correlation with human judgments. We release four BILLBOARDs for machine translation, summarization, and image captioning. 1 We demonstrate that a linear ensemble of a few diverse metrics sometimes substantially outperforms existing metrics in isolation. Our mixed-effects model analysis shows that most automatic metrics, especially the reference-based ones, overrate machine over human generation, demonstrating the importance of updating metrics as generation models become stronger (and perhaps more similar to humans) in the future.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "19-ARR_v2_4",
            "content": "Recent modeling advances have led to improved natural language generation in applications such as machine translation and summarization (Ng et al., Figure 1: Bidimensional leaderboard (BILLBOARD). When a generator developer submits output text (output.txt), BILLBOARD computes all metric scores. When a metric developer submits an executable program (e.g., metric.py), BILLBOARD computes correlation with the human judgments, updates the ensemble metric ( \u00a72.2), and measures how much the metric overrates machines ( \u00a72.3).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_5",
            "content": "2019; Raffel et al., 2020;Brown et al., 2020, inter alia). This progress is typically measured with automatic scores, such as BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004), executed by modeling researchers themselves. These metrics allow for fast, inexpensive development cycles. They were adopted based on reported correlations with human judgments at the time the metrics were introduced, but it has since been established that the correspondence can collapse when models of different types are compared (Callison-Burch et al., 2006) or models become increasingly powerful (Ma et al., 2019;Edunov et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_6",
            "content": "Meanwhile, many evaluation metrics that improve correlation with human judgments have been proposed (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but this progress has yet to be broadly adopted by the community of researchers focused on advancing models. Indeed, consistent with prior metaevaluations (Marie et al., 2021), we found that 68% of the machine translation papers from NAACL and ACL 2021 evaluated their models solely by BLEU, and only 5% measured the performance using recent metrics with contextual representations such as COMET (Rei et al., 2020). Similarly, automatic evaluation in 66% of the summarization papers was done only in terms of ROUGE. 2 We believe this separation between generation modeling and automatic evaluation represents a missed opportunity for each subcommunity to more rapidly benefit from the advances of the other.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_7",
            "content": "We therefore propose an abstraction of conventional leaderboards, bidimensional leaderboards (BILLBOARDs), that simultaneously facilitates progress in natural language generation and its evaluation (Fig. 1). A BILLBOARD accepts two types of submissions related to a given task and dataset: generators and metrics. Unlike conventional leaderboards, model ranking is not tied to a predetermined set of metrics; the generators are ranked based on the metric that currently correlates best with human judgments. Metric submissions are ranked by their correlations to human judgments, and each is stored as an executable program, which will then be used to evaluate future generation submissions. Our BILLBOARD includes a sparse regression that selects and linearly combines three existing metrics, revealing complementary strengths. All leaderboard scores are readily reproducible, allowing research on generation models and automatic metrics to benefit from each other.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_8",
            "content": "We release four BILLBOARD interfaces (https://nlp.cs.washington.edu/ billboard/) spanning three generation tasks: the WMT20 EN-DE and WMT20 ZH-EN machine translation tasks (Barrault et al., 2020), the CNNDM summarization task (Hermann et al., 2015), and the MSCOCO image captioning task (Lin et al., 2014).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_9",
            "content": "Key Findings Using the collective analyses of BILLBOARDs, our main findings are as follows.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_10",
            "content": "\u2022 A simple linear combination of a few (diverse) metrics can sometimes improve correlation. This finding quantifies complementary effects of different metrics and encourages metric developers to seek out aspects of generated text quality not yet measured by existing metrics. \u2022 Using linear mixed-effects models, we find that most automatic metrics, especially conventional, reference-based ones such as BLEU and ROUGE, overrate machines over humans in all tasks. This result provides further support for the claim that the metrics should be continually evaluated and updated as our generation models become stronger (and perhaps, closer to humans). \u2022 When only one reference is available per instance, COMET-QE (a strong referenceless metric with crosslingual contextual representations; Rei et al., 2020) achieves higher correlation with human judgments than all reference-based metrics. This raises a concern about the current standard evaluation practice in machine translation and summarization that uses reference-based metrics with a single reference per instance. \u2022 Our findings confirm many others who report that recent metrics achieve substantially higher correlation with human judgments than popular metrics like BLEU and ROUGE in BILLBOARDs.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_11",
            "content": "We believe these older metrics continue to be used mainly because modeling researchers value consistency and accessibility of evaluation practice over long periods of time. BILLBOARDs provide a way to maintain long-term comparability of system output while also drawing better conclusions about system quality, using advances in evaluation. All generators continue to be evaluated with new metrics on BILLBOARDs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_12",
            "content": "Bidimensional Leaderboards",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "19-ARR_v2_13",
            "content": "We propose BILLBOARDs to simultaneously drive progress in natural language generation and its evaluation, which are often disconnected in current research. We first describe the general framework ( \u00a72.1) and the automatic analyses they provide ( \u00a72.2-2.3). We then discuss our design choices ( \u00a72.4) and the rubric-based, human judgment data necessary to initialize BILLBOARDs ( \u00a72.5).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_14",
            "content": "BILLBOARD Framework",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "19-ARR_v2_15",
            "content": "The leaderboard paradigm has driven research on state-of-the-art model performance on many tasks in various fields (e.g., ImageNet, Russakovsky et al., 2015;SQuAD, Rajpurkar et al., 2016). As applications and tasks become more diverse, however, the conventional leaderboard paradigm presents a serious challenge: the assumption becomes too strong that predetermined, automatic metrics can reliably score the system performance over time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_16",
            "content": "In particular, scores from automatic metrics often diverge from human judgments in language generation tasks, especially when models become increasingly powerful (Ma et al., 2019). Much recent work proposed new evaluation metrics that improve correlations with human judgments in certain generation tasks (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but most developers of generation models are not benefiting from them (See Appendix A for our analysis of papers from NAACL/ACL 2021). From the perspective of generation model developers, it is not clear which of these many metrics in the literature is most reliable in which generation task or dataset, resulting in community-wide overuse of long-standing metrics like BLEU and ROUGE. Developers of evaluation metrics, on the other hand, are missing the opportunity to apply their metrics to new generation models and compare them with the existing ones. We propose BILLBOARDs that bridge this gap between generation modeling and evaluation development.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_17",
            "content": "Generators, Metrics, and Scores A BILL-BOARD for a language generation task consists of sets of generators and evaluation metrics:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_18",
            "content": "G = {G i } I i=1 , M = {M j } J j=1 .",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_19",
            "content": "Each generator G i takes as input X k (e.g., source text in machine translation) and generates text: Y i,k = G i (X k ). A metric M j assigns a score to each generated text given the generation input and the corresponding set of references R k : s i,j,k = M j (Y i,k , R k , X k ). The last two arguments to the function are optional; some metrics do not require references (i.e., referenceless or quality estimation metrics) or the generation input (e.g., BLEU). We then compute the aggregate score s i,j by averaging s i,j,k over K test examples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_20",
            "content": "Rankings In contrast to standard leaderboards, BILLBOARDs have a dynamic set of evaluation metrics, and generators are not ranked by a predefined metric. We first rank the metrics by measuring their correlations to human judgments as commonly done in the generation evaluation literature (Zhang et al., 2020b;Sellam et al., 2020). Let h i,k be a human score for Y i,k (i.e., output from generator G i on input X k ). We compute the instance-level Pearson correlation for every metric M j between h i,k and s i,j,k (M j score for Y i,k ). All metrics are ranked by their correlations. We then use the top metric M j * to rank the generators in the descending order of s i,j * . We defer our discussions on alternative design choices ( \u00a72.4) and human evaluations ( \u00a72.5). We note, however, that the overall framework of BILLBOARDs still holds regardless of these decisions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_21",
            "content": "Ensemble of Metrics",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "19-ARR_v2_22",
            "content": "So far, we have assumed that metrics are used individually in isolation, but BILLBOARDs provide a unique opportunity to examine metrics collectively. Different metrics can capture different aspects of generation quality; even if a metric is not sufficiently informative in isolation, it might reflect an important aspect of text quality that the existing metrics overlook. Here we consider a straightforward and interpretable ensemble of metrics using a regression model with \u2113 1 regularization (Tibshirani, 1994). Let the ensemble's score be",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_23",
            "content": "\u0125i,k = J j=1 w j \u2022 s i,j,k ,",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_24",
            "content": "where w j is a scalar coefficient associated with the jth metric and the intercept term is suppressed. We optimize the vector of coefficients w with the pairs of output text and a human score {Y i,k , h i,k } K k=1 from the test data:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_25",
            "content": "w * = arg min w K k=1 h i,k \u2212 \u0125i,k 2 + \u03bb\u2225w\u2225 1",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_26",
            "content": "The \u2113 1 regularization produces sparse coefficients and improves interpretability by removing highly correlated metrics. Moreover, it avoids the need for practitioners to run many metrics to obtain an ensemble score when used outside our BILLBOARDs. Our goal for the ensemble is to provide a useful signal to the research community, rather than to achieve the best possible correlation with human judges at a given time; we tune \u03bb to get three nonzero coefficients. Every metric is standardized by its mean and standard deviation on the test data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_27",
            "content": "Similar to the individual metrics, we rank this ensemble metric by its correlation to the human judgments. To make fair comparisons, we simulate situations where the ensemble is applied to a newly submitted generator that has no human evaluations. Specifically, we perform cross validation that holds out the human judgments for each generator G i and runs regression on the rest; we then apply these I regression models to the corresponding held-out data and calculate the overall correlation. We will see that the ensemble metric outperforms all individual metrics in some cases, suggesting that different metrics can capture different aspects.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_28",
            "content": "Reproduciblity The ensemble metric is updated every time a new metric is submitted (Fig. 1). For reproducibility, we keep track of every past ensemble metric with a signature that indicates its coefficients, \u03bb, and input metrics in the backend. Similar to SACREBLEU (Post, 2018), model developers can report the signature for easy replication of their scores from the ensemble metric. 3 Further, all generation outputs are saved on the leaderboards, so model developers can download outputs from all past models and compare in any way.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_29",
            "content": "Mixed-Effects Model Analysis",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "19-ARR_v2_30",
            "content": "Recent work (Kasai et al., 2022) observed that automatic metrics tend to overrate machine-generated text over human one on the MSCOCO image captioning task (Chen et al., 2015). This problem is particularly severe in conventional metrics that are based on n-gram overlap such as BLEU and CIDEr . This raises a significant concern about the continuous use of these conventional metrics in generation tasks as models become increasingly powerful (and more similar to humans); those metrics unintentionally discourage researchers from developing human-like, strong generation models. To quantify this undesirable property, we propose a linear mixed-effects model that compares the two groups of machineand human-generated text. The underlying model assumes that s i,j,k , the score from metric M j for generator G i and test example k, can be expressed as (the intercept term is suppressed for brevity):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_31",
            "content": "s i,j,k = \u03b2 j 0 1{G i is machine}+\u03b2 j 1 h i,k +\u03b3 k +\u03f5 i,j,k",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_32",
            "content": "where \u03b3 k is the random effect for example k, and \u03f5 i,j,k is Gaussian noise. Intuitively, \u03b2 j 0 measures how much metric M j overrates machine generation over human one, compared against the human judgment h i,k . \u03b2 j 0 = 0 means being neutral, and indeed we will find that \u03b2 j 0 is significantly positive in most cases ( \u00a74). We standardize all metric scores over the test samples to compare the size of \u03b2 j 0 . We apply the lme4 package (Bates et al., 2015).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_33",
            "content": "Design Choices and Discussion",
            "ntype": "title",
            "meta": {
                "section": "2.4"
            }
        },
        {
            "ix": "19-ARR_v2_34",
            "content": "In our current setup, we make several design choices for metrics and their rankings:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_35",
            "content": "\u2022 M.1 Metrics are expected to positively correlate with the generation output quality. \u2022 M.2 By default, metrics are ranked based on their instance-level Pearson correlations with human judgments. We also compute and present their system-level Kendall rank correlations. \u2022 M.3 When available, reference-based metrics use multiple references per instance.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_36",
            "content": "M.1 implies that we need to take the negative of metric scores that are intended to negatively correlate (e.g., TER, Snover et al., 2006). This normalization is also done in WMT metric competitions , 2008.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_37",
            "content": "While instance-level correlations are commonly used to evaluate and compare automatic metrics for various language generation tasks (Sellam et al., 2020;Fabbri et al., 2021;Hessel et al., 2021, inter alia), there are several alternatives to M.2. For example, Pearson, Spearman's rank, or Kendall rank correlations can be used on a system (i.e., generator) level Mach\u00e1\u010dek and Bojar, 2014;Mathur et al., 2020b). However, such system-level correlations would substantially reduce data points to compare automatic scores, resulting in many ties in the ranking. Spearman's and Kendall rank correlations become brittle when multiple generators are similar in overall output quality; penalizing a metric for swapping two similar generators is misleading (Mach\u00e1\u010dek and Bojar, 2014). Moreover, if a metric can perform well on an instance level, it can be used to augment human judgments by, for example, flagging likely wrong ratings (Mathur et al., 2020b). Thus, we encourage researchers to develop metrics that correlate well with human judgments on an instance level. Prior work also points out other problems in ranking metrics like outlier effects where outlier systems have a disproportionately large effect on the overall correlation (Mathur et al., 2020a,b). We therefore assume M.2 in the current version of BILLBOARDs, but this can be modified in a future version. M.3 is supported by our experimental results in \u00a74 that multiple references substantially improve reference-based metrics, and a single reference is often insufficient to outperform strong referenceless metrics. Some metrics have specifications for multiple references (e.g., BLEU, CIDEr). In the other cases, we evaluate outputs against every reference and take the maximum score, following prior work on image captioning evaluation (Zhang et",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_38",
            "content": "Xining will implement the Xining Civilized Behavior Promotion Regulations from October 1st, which focus on 15 types of uncivilized behavior, such as pedestrians who do not follow the traffic lights and throw objects from buildings. Generated Translation Xining City will implement the \"Xining City Civilized Behavior Promotion Regulation\" from October 1, focusing on 15 types of uncivilized behaviors such as pedestrians not passing traffic lights and throwing objects from buildings.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_39",
            "content": "Human Evaluation",
            "ntype": "title",
            "meta": {
                "section": "2.5"
            }
        },
        {
            "ix": "19-ARR_v2_40",
            "content": "Human evaluations are required to initialize BILL-BOARDs; they are used to rank metrics, train the metric ensembling model, and assess how much each metric overrates machines. Recent work, however, points out problems when evaluations are done by crowdworkers even when extensive quality controls are performed (Gillick and Liu, 2010;Toral et al., 2018;Freitag et al., 2021;Clark et al., 2021). Freitag et al. (2021) show that rubric-based machine translation evaluations by professional translators led to substantially different generator rankings from the crowdsource evaluations in WMT 2020 (Barrault et al., 2020), where WMT participants or Amazon Mechanical Turkers directly assess each translation's adequacy by a single score (direct assessment). These crowdworker evaluations depend highly on individual annotators' discretion and understanding of the annotation scheme (Freitag et al., 2021;Clark et al., 2021), making it difficult to decompose, interpret, and validate (Kasai et al., 2022). Moreover, these direct assessment scores make it difficult to interpret evaluation results for downstream applications where some aspects are particularly important (e.g., accessibility for people with visual impairments in image captioning, Gleason et al., 2020; gender bias in machine translation, Stanovsky et al., 2019). Motivated by this line of work, we perform metaevaluations to compare crowdsourced and rubricbased expert evaluations. Fig. 2 plots overall scores for test examples from WMT20 ZH-EN (Barrault et al., 2020;Freitag et al., 2021) and CNNDM summarization (Fabbri et al., 2021). Each instance is evaluated by averaging the same number of crowdworkers and expert scores for fair comparisons. We see that substantially many instances fall into disagreement: crowdworkers give much higher scores than experts (lower right square) or the reverse (upper left square). We sample and shuffle 20/25 examples from either type and ask a meta-evaluator to make a binary decision (good or bad quality ). 5 Meta-evaluations agree more with the expert evaluations (e.g., 22 and 0 in the upper left and lower right squares for CNNDM, respectively).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_41",
            "content": "In the examples on the left, crowdworkers fail to properly assess a valid translation with different structure than the reference (posted a video to celebrate vs. congratulated via video) or a summary that combines information from different parts of the article. The examples on the right illustrate that crowdworkers can be fooled by inaccurate yet fluent generations (does not know the reason vs. does not know if Sanchez decided). Given this result, we decide to initialize our BILLBOARDs with rubricbased expert evaluations for all generation tasks. We still encourage future work to explore ways to improve crowdsourced evaluations for scalability.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_42",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "19-ARR_v2_43",
            "content": "Having established the framework, we set up BILL-BOARDs for three natural language generation tasks: machine translation, summarization, and image captioning. To maximize the performance of reference-based metrics, we use as many references as possible for each task. See \u00a74 for an analysis on the effect of varying numbers of references.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_44",
            "content": "Tasks",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "19-ARR_v2_45",
            "content": "Machine Translation We experiment with two language pairs from the WMT 2020 news translation task (Barrault et al., 2020): Chinese\u2192English (WMT20 ZH-EN) and English\u2192German (WMT20 EN-DE). We use outputs from all submitted translation systems. 6 These two language pairs have expert, rubric-based scores (MQM) from Freitag et al. (2021) for a subset of 10 submitted systems, including the top-performing systems and human translations. Each output sentence is evaluated by three professional translators. Following Freitag et al. (2021), the three scores are averaged to get an instance-level score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_46",
            "content": "We use all human translations available as a reference set for reference-based metrics. Concretely, every test instance in WMT20 ZH-EN has two translations provided by different human translation services: Human-A and Human-B ( Barrault et al., 2020). In addition to Human-A and Human-B, WMT20 EN-DE provides a translation that is created by linguists who are asked to paraphrase Human-A and Human-B as much as possible (Human-P, Freitag et al., 2020). These paraphrased translations are shown to increase correlations with human judgments by mitigating the translationese effect and diversifying the reference when the generation quality is measured by reference-based metrics (Freitag et al., 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_47",
            "content": "Along with all submitted generators in WMT20 ZH-EN and WMT20 EN-DE, we train three transformer baselines with the fairseq library and place them in our BILL-BOARDs: transformer-base, transformer-large, and transformer-large-ensemble with similar hyperparameters (e.g., 6-layer encoder and decoder) to the ones trained on the WMT16 EN-DE data in Vaswani et al. (2017). 7 These baselines allow researchers to compare their translation models without resource-intensive techniques such as backtranslation (Sennrich et al., 2016a), model ensembling, and deep encoders (Kasai et al., 2021a). These techniques are all used in top-performing systems of WMT20 (Wu et al., 2020a;Kiyono et al., 2020) but might be infeasible in many research settings. See Appendix B for a list of all hyperparameters for the baselines.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_48",
            "content": "Summarization We use the CNN/DailyMail corpus (CNNDM, Hermann et al., 2015;Nallapati et al., 2016). We use the standard train/dev./test split and 24 models from Fabbri et al. (2021). 100 test articles are annotated with 10 summaries written by humans (Kryscinski et al., 2019). For those 100 articles, rubric-based, expert evaluations for 18 generators, including human-written highlights, are provided by Fabbri et al. (2021). 8 Each output summary is evaluated by three experts along four dimensions: coherence (collective quality of all summary sentences), consistency (factual alignment with the article, penalizing for hallucinations), fluency (quality of the individual sentences), and relevance (selection of important content). An instancelevel score is computed by averaging scores over all these categories and the three experts. Note that this aggregation method can be modified, depending on the downstream task of interest (Kasai et al., 2022). All 10 human-written summaries are used as the reference set for reference-based metrics. 9",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_49",
            "content": "Image Captioning We use the MSCOCO dataset (Lin et al., 2014) that consists of everydayscene photos sampled from Flickr. Every image is annotated with five captions written by crowdworkers (Chen et al., 2015). We apply the standard Karpathy split (Karpathy and Fei-Fei, 2015). For each of 500 test images, rubric-based evaluations (THUMB 1.0) are available for five systems, including one caption from a crowdworker (Kasai et al., 2022). Similar to machine translation and summarization, we use all five crowdworker captions as a reference set for reference-based metrics.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_50",
            "content": "Mixed-Effects Models",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "19-ARR_v2_51",
            "content": "Our mixed-effects model analyzes how much every automatic metric overrates machines over humans ( \u00a72.3). This means that we need to free up one human generation per instance to measure its scores in the reference-based metrics. For machine translation, we score Human-B using the reference set of Human-A (WMT20 ZH-EN) or Human-A and Human-P (WMT20 EN-DE). For CNNDM, we use concatenated highlights as human-generated summaries and use the 10 human-written summaries from Kryscinski et al. (2019) as the reference. We follow Kasai et al. (2022) for MSCOCO and score their randomly-selected Human caption using the other four as the reference. As the distinction between the reference and human generation (e.g., Human-A vs. Human B on WMT20 ZH-EN) is arbitrary, we found that swapping the roles would still lead to similar results (See Appendix E).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_52",
            "content": "9 Prior work used a concatenation of author-written highlights as a reference, but here we do not add it to the reference set. This is because these highlights are sometimes noisy (e.g., containing URLs) or lack coherence (Fabbri et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_53",
            "content": "Results and Analysis",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "19-ARR_v2_54",
            "content": "Here we discuss the current results and make several key observations about the state of language generation evaluation. Table 1 summarizes the four BILLBOARDs. It is particularly noteworthy that COMET, a metric designed for machine translation, achieves the best correlation on the CNNDM summarization task as well. COMET evaluates the similarity between the crosslingual representations from XLM-RoBERTa (Conneau et al., 2020) for input text and its translation candidate. But these crosslingual representations can, of course, be used monolingually for English summarization. This illustrates an additional benefit of BILLBOARDs that centralize different generation tasks and find surprising task transferability of learning-based metrics. See Appendices B and C for lists of all participating generators and metrics.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_55",
            "content": "The rightmost section of Table 1 shows the chosen metrics and their coefficients in the ensemble ( \u00a72.2). On the machine translation tasks, the ensemble metric outperforms the top individual metric. 10 In particular, we see a substantial gain of 0.06 points in WMT20 ZH-EN. The referenceless metric of COMET-QE is selected both for WMT20 ZH-EN and WMT20 EN-DE, suggesting complementary effects of diverse metrics. To further test this hypothesis, we perform ablations that drop one out of the three metrics at a time (Table 2). We see that only dropping COMET-QE would result in a decrease in the correlation score. This implies that the reference-less metric provides important information that the others do not. Mixed-Effects Models Seen in Table 3 are the results from our analysis that measures how much metrics overrate machines over humans ( \u00a72.3). We see that the fixed-effect coefficient \u03b2 0 is significantly positive in most cases. Referenceless metrics tend to have smaller coefficients. This can be due to the more diverse nature of human text than machine-generated text; reference-based metrics give a low score to human text that differs from the references even if it is of high quality. The conventional n-gram overlap-based metrics (BLEU, ROUGE, and CIDEr) have particularly large coefficients. These results suggest that the evaluation practice should be regularly updated as our generation models become stronger (and perhaps, more similar to human generation) in the future. Note that unlike the other tasks, \"human-generated text\" for CNNDM summarization is an automatic concatenation of author highlights, which contains substantial noise (Fabbri et al., 2021). This might explain the neutral and negative coefficients. Table 3: \u03b2 0 fixed-effect coefficients from the linear mixed-effects models, quantifying how much automatic metrics overrate machines over humans, relative to human raters. \u03b2 0 = 0 is neutral, and statistical significance is indicated by red (positive) or blue text (negative). The subscripts indicate 90% confidence intervals. Three metrics that correlate best with the human judgments are shown as well as one popular metric. COMET-QE and CLIP-S are referenceless. See \u00a7E for the other metrics. Effects of the Number of References Fig. 3 plots correlations over varying numbers of references. COMET was the top-performing referencebased metric regardless of the number of references, but we observe that it underperforms the refererenceless metric when only one reference is given. Model performance in machine translation and summarization is commonly measured by applying reference-based metrics against one reference per instance in the research community. Our finding thus raises a further concern about the current evaluation practice. Finally, we see that popular choices of BLEU and ROUGE metrics have much lower correlations than the recent metrics over various numbers of references, in line with the recent studies (Mathur et al., 2020a, inter alia).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_56",
            "content": "Related and Future Work",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "19-ARR_v2_57",
            "content": "Related Benchmarks WMT organizes the metric competition track in parallel with the translation task every year (Mathur et al., 2020b;Barrault et al., 2020, inter alia). Participants submit automatic scores for the translation outputs from the parallel translation task. Unfortunately, most of these new metrics are not used by subsequent machine translation work, perhaps because they are tested solely against the concurrent translation submissions and it is up to model developers to execute or even implement new metrics. The GEM workshop (Gehrmann et al., 2021) conducts extensive analysis of models and evaluation methods over a wide set of generation tasks. BILLBOARDs ease the burden through standard leaderboard experience where generator developers only need to upload generation outputs for the test split. BILL-BOARDs also offer automatic ensembling of metrics and quantify the diversity that a new metric adds. The human-in-the-loop GENIE leaderboard (Khashabi et al., 2021) , 2021). There are ongoing modeling and benchmarking efforts especially for efficient machine translation (Heafield et al., 2020;Peng et al., 2021;Kasai et al., 2021b, inter alia). We leave this extension to future work and specifically target the gap between generation modeling and evaluation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_58",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "19-ARR_v2_59",
            "content": "We introduced BILLBOARDs, a simple yet powerful generalization of leaderboards that bridges the gap between generation modeling and evaluation research. We established and released four BILL-BOARDs on machine translation, summarization, and image captioning tasks. We demonstrated that their built-in analysis of metric ensembling and mixed-effects modeling revealed key insights into the current state of natural language generation and its evaluation methods. BILLBOARDs allow for a standard leaderboard experience both on the modeling and evaluation sides. We invite submissions from researchers through our website.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_60",
            "content": "Dan Gillick and Yang Liu. 2010. Non-expert evaluation",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_61",
            "content": "A Case Studies of Evaluation Practice Fig. 4 depicts breakdowns of evaluation metrics used in the papers on machine translation and summarization from NAACL and ACL 2021. We examined all papers whose title contains \"machine translation\" and \"summarization.\" We see the clear gap between generation modeling and evaluation research; most researchers do not take advantage of recent metrics that correlate better with human judgments.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_62",
            "content": "Here we list the generators submitted in the initial BILLBOARDs. We use all 16 submissions for the WMT20 ZH-EN task (Barrault et al., 2020) 11 as well as our own three transformer baselines that were implemented in fairseq . Our baselines allow researchers to compare their translation models without resource-intensive techniques such as backtranslation (Sennrich et al., 2016a), model ensembling, and deep encoders (Kasai et al., 2021a). Tables 4 and 5 list the hyperprameters. We generally follow the setting from Vaswani et al. (2017). We use newstest-2019 as the dev. set and the official training data. 12 We apply Moses tokenization and BPE with 32K operations (Sennrich et al., 2016b) to English text. We tokenize Chinese text with the Jieba package, 13 following Hassan et al. (2018). Separately from English, BPE with 32K operations is then applied to Chinese. The decoder input and output embeddings are tied. Moses detokenization is applied to get the final outputs in the last step. We make the three models and preprocessed train/dev. data publicly available. 14 Table 6 lists all generators and their automatic evaluation scores from the top-performing metric (ensemble in this case).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_63",
            "content": "Similar to WMT20 ZH-EN, we use all 14 submissions for the WMT20 EN-DE task along with our three transformer baselines. The same hyperparameters are chosen as in WMT20 ZH-EN (Tables 4 and 5). We preprocess both English and German text by the Moses tokenizer and joint BPE with 32K operations. All embeddings are shared. We apply the Moses detokenizer to get the final outputs. We examined all papers whose title contains \"machine translation\" and \"summarization\" and disregarded papers primarily on evaluation metrics. \"QA\" metrics use a QA system to evaluate summaries (e.g., Eyal et al., 2019). \"Specialized\" indicates specialized evaluation in a particular dimension, rather than the overall generation quality, such as document-level evaluations on contrastive sets (Voita et al., 2019). Bawden et al. (2020) 73.89 Table 6: WMT20 ZH-EN generators and reference papers. The score column indicates the score from the metric that currently correlates best with the human judgments (ensemble).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_64",
            "content": "Table 7 shows the generators and their automatic evaluation scores from the top-performing metric (ensemble).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_65",
            "content": "We submit all 26 models from Fabbri et al. (2021). 15 Table 8 shows all models and their automatic evaluation scores from the top-performing metric (COMET).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_66",
            "content": "We submit the four strong models from the literature (Kasai et al., 2022). 16 They share similar pipeline structure but vary in model architecture, (pre)training data, model size, and (pre)training objective. Table 9 shows the models with their papers and automatic scores from the top-performing metric (RefCLIP-S).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_67",
            "content": "Table 12 presents fixed-effect coefficients that measure how much each automatic metric overrates machines over humans ( \u00a72.3). With some exceptions in CNNDM summarization, almost all automatic metrics underrate human generations (significantly positive coefficients). Table 13 swaps the roles of human-generated text, but we still see similar patterns: almost all metrics overrate machines over humans, but the problem is mitigated in COMET-QE, a referenceless, quality estimation metric. This confirms that our findings hold independently of the design choice.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_68",
            "content": "Seen in Table 14 are examples where crowdworker evaluators (Barrault et al., 2020) and professional translators (Freitag et al., 2021) disagree: crowdworkers give lower scores to the human-generated translations than the machine-generated ones. The first case requires document-level context to properly evaluate. Document-level context and diversity in high-quality human translations can mislead crowdworkers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "19-ARR_v2_69",
            "content": "Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould, SPICE: semantic propositional image caption evaluation, 2016, Proc. of ECCV, .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Peter Anderson",
                    "Basura Fernando",
                    "Mark Johnson",
                    "Stephen Gould"
                ],
                "title": "SPICE: semantic propositional image caption evaluation",
                "pub_date": "2016",
                "pub_title": "Proc. of ECCV",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_70",
            "content": "Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, Lei Zhang, Bottom-up and top-down attention for image captioning and visual question answering, 2018, Proc. of CVPR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Peter Anderson",
                    "Xiaodong He",
                    "Chris Buehler",
                    "Damien Teney",
                    "Mark Johnson",
                    "Stephen Gould",
                    "Lei Zhang"
                ],
                "title": "Bottom-up and top-down attention for image captioning and visual question answering",
                "pub_date": "2018",
                "pub_title": "Proc. of CVPR",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_71",
            "content": "Satanjeev Banerjee, Alon Lavie, METEOR: An automatic metric for MT evaluation with improved correlation with human judgments, 2005, Proc. of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Satanjeev Banerjee",
                    "Alon Lavie"
                ],
                "title": "METEOR: An automatic metric for MT evaluation with improved correlation with human judgments",
                "pub_date": "2005",
                "pub_title": "Proc. of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_72",
            "content": "UNKNOWN, None, , Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (WMT20). In Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (WMT20). In Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_73",
            "content": "Douglas Bates, Martin M\u00e4chler, Ben Bolker, Steve Walker, Fitting linear mixed-effects models using lme4, 2015, Journal of Statistical Software, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Douglas Bates",
                    "Martin M\u00e4chler",
                    "Ben Bolker",
                    "Steve Walker"
                ],
                "title": "Fitting linear mixed-effects models using lme4",
                "pub_date": "2015",
                "pub_title": "Journal of Statistical Software",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_74",
            "content": "UNKNOWN, None, , Dina Wiemann, and Lana Yeganova. 2020. Findings of the WMT 2020 biomedical translation shared task: Basque, Italian and Russian as new additional languages, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Dina Wiemann, and Lana Yeganova. 2020. Findings of the WMT 2020 biomedical translation shared task: Basque, Italian and Russian as new additional languages",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_75",
            "content": "UNKNOWN, None, 2009, Natural Language Processing with Python, Cambridge University Press.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": "2009",
                "pub_title": "Natural Language Processing with Python",
                "pub": "Cambridge University Press"
            }
        },
        {
            "ix": "19-ARR_v2_76",
            "content": "Florian B\u00f6hm, Yang Gao, Christian Meyer, Ori Shapira, Ido Dagan, Iryna Gurevych, Better rewards yield better summaries: Learning to summarise without references, 2019, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Florian B\u00f6hm",
                    "Yang Gao",
                    "Christian Meyer",
                    "Ori Shapira",
                    "Ido Dagan",
                    "Iryna Gurevych"
                ],
                "title": "Better rewards yield better summaries: Learning to summarise without references",
                "pub_date": "2019",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_77",
            "content": "L\u00e9o Bouscarrat, Antoine Bonnefoy, Thomas Peel, C\u00e9cile Pereira, STRASS: A light and effective method for extractive summarization based on sentence embeddings, 2019, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "L\u00e9o Bouscarrat",
                    "Antoine Bonnefoy",
                    "Thomas Peel",
                    "C\u00e9cile Pereira"
                ],
                "title": "STRASS: A light and effective method for extractive summarization based on sentence embeddings",
                "pub_date": "2019",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_78",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_79",
            "content": "Sandhini Askell, Ariel Agarwal, Gretchen Herbert-Voss, Tom Krueger, Rewon Henighan, Aditya Child, Daniel Ramesh, Jeffrey Ziegler, Clemens Wu, Chris Winter, Mark Hesse, Eric Chen, Mateusz Sigler,  Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Proc. of NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Sandhini Askell",
                    "Ariel Agarwal",
                    "Gretchen Herbert-Voss",
                    "Tom Krueger",
                    "Rewon Henighan",
                    "Aditya Child",
                    "Daniel Ramesh",
                    "Jeffrey Ziegler",
                    "Clemens Wu",
                    "Chris Winter",
                    "Mark Hesse",
                    "Eric Chen",
                    "Mateusz Sigler",
                    " Litwin"
                ],
                "title": "Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners",
                "pub_date": null,
                "pub_title": "Proc. of NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_80",
            "content": "Chris Callison, - Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, Josh Schroeder, meta-) evaluation of machine translation, 2007, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Chris Callison",
                    "- Burch",
                    "Cameron Fordyce",
                    "Philipp Koehn",
                    "Christof Monz",
                    "Josh Schroeder"
                ],
                "title": "meta-) evaluation of machine translation",
                "pub_date": "2007",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_81",
            "content": "Chris Callison, - Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, Josh Schroeder, Further meta-evaluation of machine translation, 2008, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Chris Callison",
                    "- Burch",
                    "Cameron Fordyce",
                    "Philipp Koehn",
                    "Christof Monz",
                    "Josh Schroeder"
                ],
                "title": "Further meta-evaluation of machine translation",
                "pub_date": "2008",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_82",
            "content": "Chris Callison, - Burch, Miles Osborne, Philipp Koehn, Re-evaluating the role of Bleu in machine translation research, 2006, Proc. of EACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Chris Callison",
                    "- Burch",
                    "Miles Osborne",
                    "Philipp Koehn"
                ],
                "title": "Re-evaluating the role of Bleu in machine translation research",
                "pub_date": "2006",
                "pub_title": "Proc. of EACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_83",
            "content": "Tanfang Chen, Weiwei Wang, Wenyang Wei, Xing Shi, Xiangang Li, Jieping Ye, and Kevin Knight. 2020. DiDi's machine translation system for WMT2020, , Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Tanfang Chen",
                    "Weiwei Wang",
                    "Wenyang Wei",
                    "Xing Shi",
                    "Xiangang Li"
                ],
                "title": "Jieping Ye, and Kevin Knight. 2020. DiDi's machine translation system for WMT2020",
                "pub_date": null,
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_84",
            "content": "UNKNOWN, None, 2015, Microsoft COCO captions: Data collection and evaluation server, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": null,
                "title": null,
                "pub_date": "2015",
                "pub_title": "Microsoft COCO captions: Data collection and evaluation server",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_85",
            "content": "Yen-Chun Chen, Mohit Bansal, Fast abstractive summarization with reinforce-selected sentence rewriting, 2018, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Yen-Chun Chen",
                    "Mohit Bansal"
                ],
                "title": "Fast abstractive summarization with reinforce-selected sentence rewriting",
                "pub_date": "2018",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_86",
            "content": "Elizabeth Clark, Tal August, Sofia Serrano, Nikita Haduong, Suchin Gururangan, Noah Smith, All that's 'human' is not gold: Evaluating human evaluation of generated text, 2021, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Elizabeth Clark",
                    "Tal August",
                    "Sofia Serrano",
                    "Nikita Haduong",
                    "Suchin Gururangan",
                    "Noah Smith"
                ],
                "title": "All that's 'human' is not gold: Evaluating human evaluation of generated text",
                "pub_date": "2021",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_87",
            "content": "Elizabeth Clark, Asli Celikyilmaz, Noah Smith, Sentence mover's similarity: Automatic evaluation for multi-sentence texts, 2019, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Elizabeth Clark",
                    "Asli Celikyilmaz",
                    "Noah Smith"
                ],
                "title": "Sentence mover's similarity: Automatic evaluation for multi-sentence texts",
                "pub_date": "2019",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_88",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Alexis Conneau",
                    "Kartikay Khandelwal",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Guillaume Wenzek",
                    "Francisco Guzm\u00e1n",
                    "Edouard Grave",
                    "Myle Ott",
                    "Luke Zettlemoyer",
                    "Veselin Stoyanov"
                ],
                "title": "Unsupervised cross-lingual representation learning at scale",
                "pub_date": "2020",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_89",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proc. of NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proc. of NAACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_90",
            "content": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon, Unified language model pre-training for natural language understanding and generation, 2019, Proc. of NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Li Dong",
                    "Nan Yang",
                    "Wenhui Wang",
                    "Furu Wei",
                    "Xiaodong Liu",
                    "Yu Wang",
                    "Jianfeng Gao",
                    "Ming Zhou",
                    "Hsiao-Wuen Hon"
                ],
                "title": "Unified language model pre-training for natural language understanding and generation",
                "pub_date": "2019",
                "pub_title": "Proc. of NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_91",
            "content": "Yue Dong, Yikang Shen, Eric Crawford, BanditSum: Extractive summarization as a contextual bandit, 2018, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Yue Dong",
                    "Yikang Shen",
                    "Eric Crawford"
                ],
                "title": "BanditSum: Extractive summarization as a contextual bandit",
                "pub_date": "2018",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_92",
            "content": "Sergey Edunov, Myle Ott, Marc'aurelio Ranzato, Michael Auli, On the evaluation of machine translation systems trained with back-translation, 2020, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Sergey Edunov",
                    "Myle Ott",
                    "Marc'aurelio Ranzato",
                    "Michael Auli"
                ],
                "title": "On the evaluation of machine translation systems trained with back-translation",
                "pub_date": "2020",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_93",
            "content": "Kawin Ethayarajh, Dan Jurafsky, Utility is in the eye of the user: A critique of NLP leaderboards, 2020, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Kawin Ethayarajh",
                    "Dan Jurafsky"
                ],
                "title": "Utility is in the eye of the user: A critique of NLP leaderboards",
                "pub_date": "2020",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_94",
            "content": "Matan Eyal, Tal Baumel, Michael Elhadad, Question answering as an automatic evaluation metric for news article summarization, 2019, Proc. of NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Matan Eyal",
                    "Tal Baumel",
                    "Michael Elhadad"
                ],
                "title": "Question answering as an automatic evaluation metric for news article summarization",
                "pub_date": "2019",
                "pub_title": "Proc. of NAACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_95",
            "content": "UNKNOWN, None, 2021, SummEval: Re-evaluating summarization evaluation, TACL.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "SummEval: Re-evaluating summarization evaluation",
                "pub": "TACL"
            }
        },
        {
            "ix": "19-ARR_v2_96",
            "content": "UNKNOWN, None, , Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. Experts, errors, and context: A large-scale study of human evaluation for machine translation, TACL.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. Experts, errors, and context: A large-scale study of human evaluation for machine translation",
                "pub": "TACL"
            }
        },
        {
            "ix": "19-ARR_v2_97",
            "content": "Markus Freitag, David Grangier, Isaac Caswell, BLEU might be guilty but references are not innocent, 2020, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Markus Freitag",
                    "David Grangier",
                    "Isaac Caswell"
                ],
                "title": "BLEU might be guilty but references are not innocent",
                "pub_date": "2020",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_98",
            "content": "UNKNOWN, None, , Proc. of GEM, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Proc. of GEM",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_99",
            "content": "Sebastian Gehrmann, Yuntian Deng, Alexander Rush, Bottom-up abstractive summarization, 2018, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Sebastian Gehrmann",
                    "Yuntian Deng",
                    "Alexander Rush"
                ],
                "title": "Bottom-up abstractive summarization",
                "pub_date": "2018",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_100",
            "content": "Ulrich Germann, The University of Edinburgh's submission to the German-to-English and English-to-German tracks in the WMT 2020 news translation and zero-shot translation robustness tasks, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Ulrich Germann"
                ],
                "title": "The University of Edinburgh's submission to the German-to-English and English-to-German tracks in the WMT 2020 news translation and zero-shot translation robustness tasks",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_101",
            "content": "Wan-Ting Hsu, Chieh-Kai Lin, Ming-Ying Lee, Kerui Min, A unified model for extractive and abstractive summarization using inconsistency loss, 2018, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Wan-Ting Hsu",
                    "Chieh-Kai Lin",
                    "Ming-Ying Lee",
                    "Kerui Min"
                ],
                "title": "A unified model for extractive and abstractive summarization using inconsistency loss",
                "pub_date": "2018",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_102",
            "content": "Yichen Jiang, Mohit Bansal, Closed-book training to improve summarization encoder memory, 2018, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Yichen Jiang",
                    "Mohit Bansal"
                ],
                "title": "Closed-book training to improve summarization encoder memory",
                "pub_date": "2018",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_103",
            "content": "Andrej Karpathy, Li Fei-Fei, Deep visualsemantic alignments for generating image descriptions, 2015, Proc. of CVPR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Andrej Karpathy",
                    "Li Fei-Fei"
                ],
                "title": "Deep visualsemantic alignments for generating image descriptions",
                "pub_date": "2015",
                "pub_title": "Proc. of CVPR",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_104",
            "content": "Jungo Kasai, Nikolaos Pappas, Hao Peng, James Cross, Noah Smith, Deep encoder, shallow decoder: Reevaluating non-autoregressive machine translation, 2021, Proc. of ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Jungo Kasai",
                    "Nikolaos Pappas",
                    "Hao Peng",
                    "James Cross",
                    "Noah Smith"
                ],
                "title": "Deep encoder, shallow decoder: Reevaluating non-autoregressive machine translation",
                "pub_date": "2021",
                "pub_title": "Proc. of ICLR",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_105",
            "content": "Jungo Kasai, Hao Peng, Yizhe Zhang, Dani Yogatama, Gabriel Ilharco, Nikolaos Pappas, Yi Mao, Weizhu Chen, Noah Smith, Finetuning pretrained transformers into RNNs, 2021, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Jungo Kasai",
                    "Hao Peng",
                    "Yizhe Zhang",
                    "Dani Yogatama",
                    "Gabriel Ilharco",
                    "Nikolaos Pappas",
                    "Yi Mao",
                    "Weizhu Chen",
                    "Noah Smith"
                ],
                "title": "Finetuning pretrained transformers into RNNs",
                "pub_date": "2021",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_106",
            "content": "Jungo Kasai, Keisuke Sakaguchi, Lavinia Dunagan, Jacob Morrison, Yejin Ronan Le Bras, Noah Choi,  Smith, 2022. Transparent human evaluation for image captioning, , Proc. of NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Jungo Kasai",
                    "Keisuke Sakaguchi",
                    "Lavinia Dunagan",
                    "Jacob Morrison",
                    "Yejin Ronan Le Bras",
                    "Noah Choi",
                    " Smith"
                ],
                "title": "2022. Transparent human evaluation for image captioning",
                "pub_date": null,
                "pub_title": "Proc. of NAACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_107",
            "content": "UNKNOWN, None, 2021, GENIE: A leaderboard for human-in-the-loop evaluation of text generation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": null,
                "title": null,
                "pub_date": "2021",
                "pub_title": "GENIE: A leaderboard for human-in-the-loop evaluation of text generation",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_108",
            "content": "Shun Kiyono, Takumi Ito, Ryuto Konno, Tohoku-AIP-NTT at WMT 2020 news translation task, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Shun Kiyono",
                    "Takumi Ito",
                    "Ryuto Konno"
                ],
                "title": "Tohoku-AIP-NTT at WMT 2020 news translation task",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_109",
            "content": "Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond\u0159ej Bojar, Alexandra Constantin, Evan Herbst, Moses: Open source toolkit for statistical machine translation, 2007, Proc. of ACL Demo and Poster Sessions, .",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Philipp Koehn",
                    "Hieu Hoang",
                    "Alexandra Birch",
                    "Chris Callison-Burch",
                    "Marcello Federico",
                    "Nicola Bertoldi",
                    "Brooke Cowan",
                    "Wade Shen",
                    "Christine Moran",
                    "Richard Zens",
                    "Chris Dyer",
                    "Ond\u0159ej Bojar",
                    "Alexandra Constantin",
                    "Evan Herbst"
                ],
                "title": "Moses: Open source toolkit for statistical machine translation",
                "pub_date": "2007",
                "pub_title": "Proc. of ACL Demo and Poster Sessions",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_110",
            "content": "Wojciech Kryscinski, Nitish Shirish Keskar, Bryan Mc-Cann, Caiming Xiong, Richard Socher, Neural text summarization: A critical evaluation, 2019, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Wojciech Kryscinski",
                    "Nitish Shirish Keskar",
                    "Bryan Mc-Cann",
                    "Caiming Xiong",
                    "Richard Socher"
                ],
                "title": "Neural text summarization: A critical evaluation",
                "pub_date": "2019",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_111",
            "content": "Wojciech Kry\u015bci\u0144ski, Romain Paulus, Caiming Xiong, Richard Socher, Improving abstraction in text summarization, 2018, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Wojciech Kry\u015bci\u0144ski",
                    "Romain Paulus",
                    "Caiming Xiong",
                    "Richard Socher"
                ],
                "title": "Improving abstraction in text summarization",
                "pub_date": "2018",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_112",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Mike Lewis",
                    "Yinhan Liu",
                    "Naman Goyal",
                    "Marjan Ghazvininejad",
                    "Abdelrahman Mohamed",
                    "Omer Levy",
                    "Veselin Stoyanov",
                    "Luke Zettlemoyer"
                ],
                "title": "BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension",
                "pub_date": "2020",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_113",
            "content": "Zuchao Li, Hai Zhao, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita, SJTU-NICT's supervised and unsupervised neural machine translation systems for the WMT20 news translation task, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Zuchao Li",
                    "Hai Zhao",
                    "Rui Wang",
                    "Kehai Chen",
                    "Masao Utiyama",
                    "Eiichiro Sumita"
                ],
                "title": "SJTU-NICT's supervised and unsupervised neural machine translation systems for the WMT20 news translation task",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_114",
            "content": "Chin-Yew Lin, ROUGE: A package for automatic evaluation of summaries, 2004, Proc. of Text Summarization Branches Out, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "Chin-Yew Lin"
                ],
                "title": "ROUGE: A package for automatic evaluation of summaries",
                "pub_date": "2004",
                "pub_title": "Proc. of Text Summarization Branches Out",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_115",
            "content": "Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Zitnick, Microsoft COCO: common objects in context, 2014, Proc. of ECCV, .",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Tsung-Yi Lin",
                    "Michael Maire",
                    "Serge Belongie",
                    "Lubomir Bourdev",
                    "Ross Girshick",
                    "James Hays",
                    "Pietro Perona",
                    "Deva Ramanan",
                    "Piotr Doll\u00e1r",
                    "C Zitnick"
                ],
                "title": "Microsoft COCO: common objects in context",
                "pub_date": "2014",
                "pub_title": "Proc. of ECCV",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_116",
            "content": "Yang Liu, Mirella Lapata, Text summarization with pretrained encoders, 2019, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "Yang Liu",
                    "Mirella Lapata"
                ],
                "title": "Text summarization with pretrained encoders",
                "pub_date": "2019",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_117",
            "content": "Qingsong Ma, Johnny Wei, Ond\u0159ej Bojar, Yvette Graham, Results of the WMT19 metrics shared task: Segment-level and strong MT systems pose big challenges, 2019, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Qingsong Ma",
                    "Johnny Wei",
                    "Ond\u0159ej Bojar",
                    "Yvette Graham"
                ],
                "title": "Results of the WMT19 metrics shared task: Segment-level and strong MT systems pose big challenges",
                "pub_date": "2019",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_118",
            "content": "Matou\u0161 Mach\u00e1\u010dek, Ond\u0159ej Bojar, Results of the WMT14 metrics shared task, 2014, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": [
                    "Matou\u0161 Mach\u00e1\u010dek",
                    "Ond\u0159ej Bojar"
                ],
                "title": "Results of the WMT14 metrics shared task",
                "pub_date": "2014",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_119",
            "content": "Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, David Mc-Closky, The Stanford CoreNLP natural language processing toolkit, 2014, Proc. of ACL System Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": [
                    "Christopher Manning",
                    "Mihai Surdeanu",
                    "John Bauer",
                    "Jenny Finkel",
                    "Steven Bethard",
                    "David Mc-Closky"
                ],
                "title": "The Stanford CoreNLP natural language processing toolkit",
                "pub_date": "2014",
                "pub_title": "Proc. of ACL System Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_120",
            "content": "Benjamin Marie, Atsushi Fujita, Raphael Rubino, Scientific credibility of machine translation research: A meta-evaluation of 769 papers, 2021, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": [
                    "Benjamin Marie",
                    "Atsushi Fujita",
                    "Raphael Rubino"
                ],
                "title": "Scientific credibility of machine translation research: A meta-evaluation of 769 papers",
                "pub_date": "2021",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_121",
            "content": "Nitika Mathur, Timothy Baldwin, Trevor Cohn, Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics, 2020, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": [
                    "Nitika Mathur",
                    "Timothy Baldwin",
                    "Trevor Cohn"
                ],
                "title": "Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics",
                "pub_date": "2020",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_122",
            "content": "Nitika Mathur, Johnny Wei, Markus Freitag, Qingsong Ma, Ond\u0159ej Bojar, Results of the WMT20 metrics shared task, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b53",
                "authors": [
                    "Nitika Mathur",
                    "Johnny Wei",
                    "Markus Freitag",
                    "Qingsong Ma",
                    "Ond\u0159ej Bojar"
                ],
                "title": "Results of the WMT20 metrics shared task",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_123",
            "content": "Fandong Meng, Jianhao Yan, Yijin Liu, Yuan Gao, Xianfeng Zeng, Qinsong Zeng, Peng Li, Ming Chen, Jie Zhou, Sifan Liu, Hao Zhou, WeChat neural machine translation systems for WMT20, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b54",
                "authors": [
                    "Fandong Meng",
                    "Jianhao Yan",
                    "Yijin Liu",
                    "Yuan Gao",
                    "Xianfeng Zeng",
                    "Qinsong Zeng",
                    "Peng Li",
                    "Ming Chen",
                    "Jie Zhou",
                    "Sifan Liu",
                    "Hao Zhou"
                ],
                "title": "WeChat neural machine translation systems for WMT20",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_124",
            "content": "Swaroop Mishra, Anjana Arunkumar, How robust are model rankings : A leaderboard customization approach for equitable evaluation, 2021, Proc. of AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b55",
                "authors": [
                    "Swaroop Mishra",
                    "Anjana Arunkumar"
                ],
                "title": "How robust are model rankings : A leaderboard customization approach for equitable evaluation",
                "pub_date": "2021",
                "pub_title": "Proc. of AAAI",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_125",
            "content": "Alexander Molchanov, PROMT systems for WMT 2020 shared news translation task, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b56",
                "authors": [
                    "Alexander Molchanov"
                ],
                "title": "PROMT systems for WMT 2020 shared news translation task",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_126",
            "content": "Ramesh Nallapati, Bowen Zhou, Abstractive text summarization using sequence-tosequence RNNs and beyond, 2016, Proc. of CoNLL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b57",
                "authors": [
                    "Ramesh Nallapati",
                    "Bowen Zhou"
                ],
                "title": "Abstractive text summarization using sequence-tosequence RNNs and beyond",
                "pub_date": "2016",
                "pub_title": "Proc. of CoNLL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_127",
            "content": "Shashi Narayan, Shay Cohen, Mirella Lapata, Ranking sentences for extractive summarization with reinforcement learning, 2018, Proc. of NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b58",
                "authors": [
                    "Shashi Narayan",
                    "Shay Cohen",
                    "Mirella Lapata"
                ],
                "title": "Ranking sentences for extractive summarization with reinforcement learning",
                "pub_date": "2018",
                "pub_title": "Proc. of NAACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_128",
            "content": "Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, Sergey Edunov, Facebook FAIR's WMT19 news translation task submission, 2019, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b59",
                "authors": [
                    "Nathan Ng",
                    "Kyra Yee",
                    "Alexei Baevski",
                    "Myle Ott",
                    "Michael Auli",
                    "Sergey Edunov"
                ],
                "title": "Facebook FAIR's WMT19 news translation task submission",
                "pub_date": "2019",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_129",
            "content": "Csaba Oravecz, Katina Bontcheva, L\u00e1szl\u00f3 Tihanyi, David Kolovratnik, Bhavani Bhaskar, Adrien Lardilleux, Szymon Klocek, and Andreas Eisele. 2020. eTranslation's submissions to the WMT 2020 news translation task, , Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b60",
                "authors": [
                    "Csaba Oravecz",
                    "Katina Bontcheva",
                    "L\u00e1szl\u00f3 Tihanyi",
                    "David Kolovratnik",
                    "Bhavani Bhaskar",
                    "Adrien Lardilleux"
                ],
                "title": "Szymon Klocek, and Andreas Eisele. 2020. eTranslation's submissions to the WMT 2020 news translation task",
                "pub_date": null,
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_130",
            "content": "Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli, fairseq: A fast, extensible toolkit for sequence modeling, 2019, Proc. of NAACL Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b61",
                "authors": [
                    "Myle Ott",
                    "Sergey Edunov",
                    "Alexei Baevski",
                    "Angela Fan",
                    "Sam Gross",
                    "Nathan Ng",
                    "David Grangier",
                    "Michael Auli"
                ],
                "title": "fairseq: A fast, extensible toolkit for sequence modeling",
                "pub_date": "2019",
                "pub_title": "Proc. of NAACL Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_131",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, BLEU: a method for automatic evaluation of machine translation, 2002, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b62",
                "authors": [
                    "Kishore Papineni",
                    "Salim Roukos",
                    "Todd Ward",
                    "Wei-Jing Zhu"
                ],
                "title": "BLEU: a method for automatic evaluation of machine translation",
                "pub_date": "2002",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_132",
            "content": "Ramakanth Pasunuru, Mohit Bansal, Multireward reinforced summarization with saliency and entailment, 2018, Proc. of NAACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b63",
                "authors": [
                    "Ramakanth Pasunuru",
                    "Mohit Bansal"
                ],
                "title": "Multireward reinforced summarization with saliency and entailment",
                "pub_date": "2018",
                "pub_title": "Proc. of NAACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_133",
            "content": "Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah Smith, Lingpeng Kong, Random feature attention, 2021, Proc. of ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b64",
                "authors": [
                    "Hao Peng",
                    "Nikolaos Pappas",
                    "Dani Yogatama",
                    "Roy Schwartz",
                    "Noah Smith",
                    "Lingpeng Kong"
                ],
                "title": "Random feature attention",
                "pub_date": "2021",
                "pub_title": "Proc. of ICLR",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_134",
            "content": "Maja Popovi\u0107, chrF: character n-gram F-score for automatic MT evaluation, 2015, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b65",
                "authors": [
                    "Maja Popovi\u0107"
                ],
                "title": "chrF: character n-gram F-score for automatic MT evaluation",
                "pub_date": "2015",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_135",
            "content": "Maja Popovi\u0107, chrF++: words helping character n-grams, 2017, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b66",
                "authors": [
                    "Maja Popovi\u0107"
                ],
                "title": "chrF++: words helping character n-grams",
                "pub_date": "2017",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_136",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b67",
                "authors": [
                    "Matt Post"
                ],
                "title": "A call for clarity in reporting BLEU scores",
                "pub_date": "2018",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_137",
            "content": "Alec Radford, Jong Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, , Gretchen Krueger, and Ilya Sutskever. 2021. Learning transferable visual models from natural language supervision, .",
            "ntype": "ref",
            "meta": {
                "xid": "b68",
                "authors": [
                    "Alec Radford",
                    "Jong Kim",
                    "Chris Hallacy",
                    "Aditya Ramesh",
                    "Gabriel Goh",
                    "Sandhini Agarwal"
                ],
                "title": "Girish Sastry",
                "pub_date": null,
                "pub_title": "Gretchen Krueger, and Ilya Sutskever. 2021. Learning transferable visual models from natural language supervision",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_138",
            "content": "UNKNOWN, None, 2020, Exploring the limits of transfer learning with a unified text-to-text transformer, JLMR.",
            "ntype": "ref",
            "meta": {
                "xid": "b69",
                "authors": null,
                "title": null,
                "pub_date": "2020",
                "pub_title": "Exploring the limits of transfer learning with a unified text-to-text transformer",
                "pub": "JLMR"
            }
        },
        {
            "ix": "19-ARR_v2_139",
            "content": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, SQuAD: 100,000+ questions for machine comprehension of text, 2016, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b70",
                "authors": [
                    "Pranav Rajpurkar",
                    "Jian Zhang",
                    "Konstantin Lopyrev",
                    "Percy Liang"
                ],
                "title": "SQuAD: 100,000+ questions for machine comprehension of text",
                "pub_date": "2016",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_140",
            "content": "Ricardo Rei, Craig Stewart, Ana Farinha, Alon Lavie, COMET: A neural framework for MT evaluation, 2020, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b71",
                "authors": [
                    "Ricardo Rei",
                    "Craig Stewart",
                    "Ana Farinha",
                    "Alon Lavie"
                ],
                "title": "COMET: A neural framework for MT evaluation",
                "pub_date": "2020",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_141",
            "content": "UNKNOWN, None, 2015, , .",
            "ntype": "ref",
            "meta": {
                "xid": "b72",
                "authors": null,
                "title": null,
                "pub_date": "2015",
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_142",
            "content": "Thomas Scialom, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano, Answers unite! unsupervised metrics for reinforced summarization models, 2019, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b73",
                "authors": [
                    "Thomas Scialom",
                    "Sylvain Lamprier",
                    "Benjamin Piwowarski",
                    "Jacopo Staiano"
                ],
                "title": "Answers unite! unsupervised metrics for reinforced summarization models",
                "pub_date": "2019",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_143",
            "content": "Abigail See, J Peter, Christopher Liu,  Manning, Get to the point: Summarization with pointergenerator networks, 2017, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b74",
                "authors": [
                    "Abigail See",
                    "J Peter",
                    "Christopher Liu",
                    " Manning"
                ],
                "title": "Get to the point: Summarization with pointergenerator networks",
                "pub_date": "2017",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_144",
            "content": "Thibault Sellam, Dipanjan Das, Ankur P Parikh, BLEURT: Learning robust metrics for text generation, 2020, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b75",
                "authors": [
                    "Thibault Sellam",
                    "Dipanjan Das",
                    "Ankur P Parikh"
                ],
                "title": "BLEURT: Learning robust metrics for text generation",
                "pub_date": "2020",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_145",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Improving neural machine translation models with monolingual data, 2016, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b76",
                "authors": [
                    "Rico Sennrich",
                    "Barry Haddow",
                    "Alexandra Birch"
                ],
                "title": "Improving neural machine translation models with monolingual data",
                "pub_date": "2016",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_146",
            "content": "Eva Sharma, Luyang Huang, Zhe Hu, Lu Wang, An entity-driven framework for abstractive summarization, 2019, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b77",
                "authors": [
                    "Eva Sharma",
                    "Luyang Huang",
                    "Zhe Hu",
                    "Lu Wang"
                ],
                "title": "An entity-driven framework for abstractive summarization",
                "pub_date": "2019",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_147",
            "content": "Tingxun Shi, Shiyu Zhao, Xiaopu Li, Xiaoxue Wang, Qian Zhang, Di Ai, Dawei Dang, Xue Zhengshan, Jie Hao, OPPO's machine translation systems for WMT20, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b78",
                "authors": [
                    "Tingxun Shi",
                    "Shiyu Zhao",
                    "Xiaopu Li",
                    "Xiaoxue Wang",
                    "Qian Zhang",
                    "Di Ai",
                    "Dawei Dang",
                    "Xue Zhengshan",
                    "Jie Hao"
                ],
                "title": "OPPO's machine translation systems for WMT20",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_148",
            "content": "Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea Micciulla, John Makhoul, A study of translation edit rate with targeted human annotation, 2006, Proc. of AMTA, .",
            "ntype": "ref",
            "meta": {
                "xid": "b79",
                "authors": [
                    "Matthew Snover",
                    "Bonnie Dorr",
                    "Rich Schwartz",
                    "Linnea Micciulla",
                    "John Makhoul"
                ],
                "title": "A study of translation edit rate with targeted human annotation",
                "pub_date": "2006",
                "pub_title": "Proc. of AMTA",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_149",
            "content": "Gabriel Stanovsky, Noah Smith, Luke Zettlemoyer, Evaluating gender bias in machine translation, 2019, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b80",
                "authors": [
                    "Gabriel Stanovsky",
                    "Noah Smith",
                    "Luke Zettlemoyer"
                ],
                "title": "Evaluating gender bias in machine translation",
                "pub_date": "2019",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_150",
            "content": "Brian Thompson, Matt Post, Automatic machine translation evaluation in many languages via zero-shot paraphrasing, 2020, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b81",
                "authors": [
                    "Brian Thompson",
                    "Matt Post"
                ],
                "title": "Automatic machine translation evaluation in many languages via zero-shot paraphrasing",
                "pub_date": "2020",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_151",
            "content": "Robert Tibshirani, Regression shrinkage and selection via the Lasso, 1994, Journal of the Royal Statistical Society, Series B, .",
            "ntype": "ref",
            "meta": {
                "xid": "b82",
                "authors": [
                    "Robert Tibshirani"
                ],
                "title": "Regression shrinkage and selection via the Lasso",
                "pub_date": "1994",
                "pub_title": "Journal of the Royal Statistical Society, Series B",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_152",
            "content": "Antonio Toral, Sheila Castilho, Ke Hu, Andy Way, Attaining the unattainable? reassessing claims of human parity in neural machine translation, 2018, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b83",
                "authors": [
                    "Antonio Toral",
                    "Sheila Castilho",
                    "Ke Hu",
                    "Andy Way"
                ],
                "title": "Attaining the unattainable? reassessing claims of human parity in neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_153",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proc. of NeurIPS, .",
            "ntype": "ref",
            "meta": {
                "xid": "b84",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Proc. of NeurIPS",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_154",
            "content": "C Ramakrishna Vedantam, Devi Zitnick,  Parikh, CIDEr: Consensus-based image description evaluation, 2015, Proc. of CVPR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b85",
                "authors": [
                    "C Ramakrishna Vedantam",
                    "Devi Zitnick",
                    " Parikh"
                ],
                "title": "CIDEr: Consensus-based image description evaluation",
                "pub_date": "2015",
                "pub_title": "Proc. of CVPR",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_155",
            "content": "Elena Voita, Rico Sennrich, Ivan Titov, When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion, 2019, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b86",
                "authors": [
                    "Elena Voita",
                    "Rico Sennrich",
                    "Ivan Titov"
                ],
                "title": "When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion",
                "pub_date": "2019",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_156",
            "content": "Weiyue Wang, Jan-Thorsten Peter, Hendrik Rosendahl, Hermann Ney, CharacTer: Translation edit rate on character level, 2016, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b87",
                "authors": [
                    "Weiyue Wang",
                    "Jan-Thorsten Peter",
                    "Hendrik Rosendahl",
                    "Hermann Ney"
                ],
                "title": "CharacTer: Translation edit rate on character level",
                "pub_date": "2016",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_157",
            "content": "Daimeng Wei, Hengchao Shang, Zhanglin Wu, Zhengzhe Yu, Liangyou Li, Jiaxin Guo, Minghan Wang, Hao Yang, Lizhi Lei, Ying Qin, and Shiliang Sun. 2020. HW-TSC's participation in the WMT 2020 news translation shared task, , Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b88",
                "authors": [
                    "Daimeng Wei",
                    "Hengchao Shang",
                    "Zhanglin Wu",
                    "Zhengzhe Yu",
                    "Liangyou Li",
                    "Jiaxin Guo",
                    "Minghan Wang",
                    "Hao Yang",
                    "Lizhi Lei"
                ],
                "title": "Ying Qin, and Shiliang Sun. 2020. HW-TSC's participation in the WMT 2020 news translation shared task",
                "pub_date": null,
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_158",
            "content": "Liwei Wu, Xiao Pan, Zehui Lin, Yaoming Zhu, Mingxuan Wang, Lei Li, The Volctrans machine translation system for WMT20, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b89",
                "authors": [
                    "Liwei Wu",
                    "Xiao Pan",
                    "Zehui Lin",
                    "Yaoming Zhu",
                    "Mingxuan Wang",
                    "Lei Li"
                ],
                "title": "The Volctrans machine translation system for WMT20",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_159",
            "content": "Shuangzhi Wu, Xing Wang, Longyue Wang, Fangxu Liu, Jun Xie, Zhaopeng Tu, Shuming Shi, Mu Li, Tencent neural machine translation systems for the WMT20 news translation task, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b90",
                "authors": [
                    "Shuangzhi Wu",
                    "Xing Wang",
                    "Longyue Wang",
                    "Fangxu Liu",
                    "Jun Xie",
                    "Zhaopeng Tu",
                    "Shuming Shi",
                    "Mu Li"
                ],
                "title": "Tencent neural machine translation systems for the WMT20 news translation task",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_160",
            "content": "Yuxiang Wu, Baotian Hu, Learning to extract coherent summary via deep reinforcement learning, 2018, Proc. of AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b91",
                "authors": [
                    "Yuxiang Wu",
                    "Baotian Hu"
                ],
                "title": "Learning to extract coherent summary via deep reinforcement learning",
                "pub_date": "2018",
                "pub_title": "Proc. of AAAI",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_161",
            "content": "Jiacheng Xu, Greg Durrett, Neural extractive text summarization with syntactic compression, 2019, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b92",
                "authors": [
                    "Jiacheng Xu",
                    "Greg Durrett"
                ],
                "title": "Neural extractive text summarization with syntactic compression",
                "pub_date": "2019",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_162",
            "content": "Lei Yu, Laurent Sartran, Po-Sen Huang, Wojciech Stokowiec, Domenic Donato, Srivatsan Srinivasan, Alek Andreev, Wang Ling, The DeepMind Chinese-English document translation system at WMT2020, 2020, Proc. of WMT, .",
            "ntype": "ref",
            "meta": {
                "xid": "b93",
                "authors": [
                    "Lei Yu",
                    "Laurent Sartran",
                    "Po-Sen Huang",
                    "Wojciech Stokowiec",
                    "Domenic Donato",
                    "Srivatsan Srinivasan",
                    "Alek Andreev",
                    "Wang Ling"
                ],
                "title": "The DeepMind Chinese-English document translation system at WMT2020",
                "pub_date": "2020",
                "pub_title": "Proc. of WMT",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_163",
            "content": "Jingqing Zhang, Yao Zhao, Mohammad Saleh, Peter Liu, PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization, 2020, Proc. of ICML, .",
            "ntype": "ref",
            "meta": {
                "xid": "b94",
                "authors": [
                    "Jingqing Zhang",
                    "Yao Zhao",
                    "Mohammad Saleh",
                    "Peter Liu"
                ],
                "title": "PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization",
                "pub_date": "2020",
                "pub_title": "Proc. of ICML",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_164",
            "content": "Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang, Yejin Choi, Jianfeng Gao, VinVL: Making visual representations matter in vision-language models, 2021, Proc. of CVPR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b95",
                "authors": [
                    "Pengchuan Zhang",
                    "Xiujun Li",
                    "Xiaowei Hu",
                    "Jianwei Yang",
                    "Lei Zhang",
                    "Lijuan Wang",
                    "Yejin Choi",
                    "Jianfeng Gao"
                ],
                "title": "VinVL: Making visual representations matter in vision-language models",
                "pub_date": "2021",
                "pub_title": "Proc. of CVPR",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_165",
            "content": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Weinberger, Yoav Artzi, BERTScore: Evaluating text generation with BERT, 2020, Proc. of ICLR, .",
            "ntype": "ref",
            "meta": {
                "xid": "b96",
                "authors": [
                    "Tianyi Zhang",
                    "Varsha Kishore",
                    "Felix Wu",
                    "Kilian Weinberger",
                    "Yoav Artzi"
                ],
                "title": "BERTScore: Evaluating text generation with BERT",
                "pub_date": "2020",
                "pub_title": "Proc. of ICLR",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_166",
            "content": "Xingxing Zhang, Mirella Lapata, Furu Wei, Ming Zhou, Neural latent extractive document summarization, 2018, Proc. of EMNLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b97",
                "authors": [
                    "Xingxing Zhang",
                    "Mirella Lapata",
                    "Furu Wei",
                    "Ming Zhou"
                ],
                "title": "Neural latent extractive document summarization",
                "pub_date": "2018",
                "pub_title": "Proc. of EMNLP",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_167",
            "content": "Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Jason Corso, Jianfeng Gao, Unified vision-language pre-training for image captioning and VQA, 2020, Proc. of AAAI, .",
            "ntype": "ref",
            "meta": {
                "xid": "b98",
                "authors": [
                    "Luowei Zhou",
                    "Hamid Palangi",
                    "Lei Zhang",
                    "Houdong Hu",
                    "Jason Corso",
                    "Jianfeng Gao"
                ],
                "title": "Unified vision-language pre-training for image captioning and VQA",
                "pub_date": "2020",
                "pub_title": "Proc. of AAAI",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_168",
            "content": "Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang, Ming Zhou, Tiejun Zhao, Neural document summarization by jointly learning to score and select sentences, 2018, Proc. of ACL, .",
            "ntype": "ref",
            "meta": {
                "xid": "b99",
                "authors": [
                    "Qingyu Zhou",
                    "Nan Yang",
                    "Furu Wei",
                    "Shaohan Huang",
                    "Ming Zhou",
                    "Tiejun Zhao"
                ],
                "title": "Neural document summarization by jointly learning to score and select sentences",
                "pub_date": "2018",
                "pub_title": "Proc. of ACL",
                "pub": null
            }
        },
        {
            "ix": "19-ARR_v2_169",
            "content": "UNKNOWN, None, 2019, Fine-tuning language models from human preferences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b100",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Fine-tuning language models from human preferences",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "19-ARR_v2_0@0",
            "content": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_0",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@0",
            "content": "Natural language processing researchers have identified limitations of evaluation methodology for generation tasks, with new questions raised about the validity of automatic metrics and of crowdworker judgments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@1",
            "content": "Meanwhile, efforts to improve generation models tend to depend on simple n-gram overlap metrics (e.g., BLEU, ROUGE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 212,
            "end": 327,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@2",
            "content": "We argue that new advances on models and metrics should each more directly benefit and inform the other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 329,
            "end": 432,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@3",
            "content": "We therefore propose a generalization of leaderboards, bidimensional leaderboards (BILLBOARDs), that simultaneously tracks progress in language generation models and metrics for their evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 434,
            "end": 628,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@4",
            "content": "Unlike conventional unidimensional leaderboards that sort submitted systems by predetermined metrics, a BILLBOARD accepts both generators and evaluation metrics as competing entries.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 630,
            "end": 811,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@5",
            "content": "A BILLBOARD automatically creates an ensemble metric that selects and linearly combines a few metrics based on a global analysis across generators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 813,
            "end": 959,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@6",
            "content": "Further, metrics are ranked based on their correlation with human judgments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 961,
            "end": 1036,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@7",
            "content": "We release four BILLBOARDs for machine translation, summarization, and image captioning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 1038,
            "end": 1125,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@8",
            "content": "1 We demonstrate that a linear ensemble of a few diverse metrics sometimes substantially outperforms existing metrics in isolation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 1127,
            "end": 1257,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_2@9",
            "content": "Our mixed-effects model analysis shows that most automatic metrics, especially the reference-based ones, overrate machine over human generation, demonstrating the importance of updating metrics as generation models become stronger (and perhaps more similar to humans) in the future.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_2",
            "start": 1259,
            "end": 1540,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_4@0",
            "content": "Recent modeling advances have led to improved natural language generation in applications such as machine translation and summarization (Ng et al., Figure 1: Bidimensional leaderboard (BILLBOARD).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_4",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_4@1",
            "content": "When a generator developer submits output text (output.txt), BILLBOARD computes all metric scores.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_4",
            "start": 197,
            "end": 294,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_4@2",
            "content": "When a metric developer submits an executable program (e.g., metric.py), BILLBOARD computes correlation with the human judgments, updates the ensemble metric ( \u00a72.2), and measures how much the metric overrates machines ( \u00a72.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_4",
            "start": 296,
            "end": 522,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_5@0",
            "content": "2019; Raffel et al., 2020;Brown et al., 2020, inter alia).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_5",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_5@1",
            "content": "This progress is typically measured with automatic scores, such as BLEU (Papineni et al., 2002) and ROUGE (Lin, 2004), executed by modeling researchers themselves.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_5",
            "start": 59,
            "end": 221,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_5@2",
            "content": "These metrics allow for fast, inexpensive development cycles.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_5",
            "start": 223,
            "end": 283,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_5@3",
            "content": "They were adopted based on reported correlations with human judgments at the time the metrics were introduced, but it has since been established that the correspondence can collapse when models of different types are compared (Callison-Burch et al., 2006) or models become increasingly powerful (Ma et al., 2019;Edunov et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_5",
            "start": 285,
            "end": 617,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_6@0",
            "content": "Meanwhile, many evaluation metrics that improve correlation with human judgments have been proposed (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but this progress has yet to be broadly adopted by the community of researchers focused on advancing models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_6",
            "start": 0,
            "end": 301,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_6@1",
            "content": "Indeed, consistent with prior metaevaluations (Marie et al., 2021), we found that 68% of the machine translation papers from NAACL and ACL 2021 evaluated their models solely by BLEU, and only 5% measured the performance using recent metrics with contextual representations such as COMET (Rei et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_6",
            "start": 303,
            "end": 608,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_6@2",
            "content": "Similarly, automatic evaluation in 66% of the summarization papers was done only in terms of ROUGE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_6",
            "start": 610,
            "end": 708,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_6@3",
            "content": "2 We believe this separation between generation modeling and automatic evaluation represents a missed opportunity for each subcommunity to more rapidly benefit from the advances of the other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_6",
            "start": 710,
            "end": 900,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_7@0",
            "content": "We therefore propose an abstraction of conventional leaderboards, bidimensional leaderboards (BILLBOARDs), that simultaneously facilitates progress in natural language generation and its evaluation (Fig. 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_7",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_7@1",
            "content": "A BILLBOARD accepts two types of submissions related to a given task and dataset: generators and metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_7",
            "start": 208,
            "end": 312,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_7@2",
            "content": "Unlike conventional leaderboards, model ranking is not tied to a predetermined set of metrics; the generators are ranked based on the metric that currently correlates best with human judgments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_7",
            "start": 314,
            "end": 506,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_7@3",
            "content": "Metric submissions are ranked by their correlations to human judgments, and each is stored as an executable program, which will then be used to evaluate future generation submissions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_7",
            "start": 508,
            "end": 690,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_7@4",
            "content": "Our BILLBOARD includes a sparse regression that selects and linearly combines three existing metrics, revealing complementary strengths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_7",
            "start": 692,
            "end": 827,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_7@5",
            "content": "All leaderboard scores are readily reproducible, allowing research on generation models and automatic metrics to benefit from each other.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_7",
            "start": 829,
            "end": 965,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_8@0",
            "content": "We release four BILLBOARD interfaces (https://nlp.cs.washington.edu/ billboard/) spanning three generation tasks: the WMT20 EN-DE and WMT20 ZH-EN machine translation tasks (Barrault et al., 2020), the CNNDM summarization task (Hermann et al., 2015), and the MSCOCO image captioning task (Lin et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_8",
            "start": 0,
            "end": 305,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_9@0",
            "content": "Key Findings Using the collective analyses of BILLBOARDs, our main findings are as follows.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_9",
            "start": 0,
            "end": 90,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_10@0",
            "content": "\u2022 A simple linear combination of a few (diverse) metrics can sometimes improve correlation. This finding quantifies complementary effects of different metrics and encourages metric developers to seek out aspects of generated text quality not yet measured by existing metrics. \u2022 Using linear mixed-effects models, we find that most automatic metrics, especially conventional, reference-based ones such as BLEU and ROUGE, overrate machines over humans in all tasks. This result provides further support for the claim that the metrics should be continually evaluated and updated as our generation models become stronger (and perhaps, closer to humans). \u2022 When only one reference is available per instance, COMET-QE (a strong referenceless metric with crosslingual contextual representations; Rei et al., 2020) achieves higher correlation with human judgments than all reference-based metrics. This raises a concern about the current standard evaluation practice in machine translation and summarization that uses reference-based metrics with a single reference per instance. \u2022 Our findings confirm many others who report that recent metrics achieve substantially higher correlation with human judgments than popular metrics like BLEU and ROUGE in BILLBOARDs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_10",
            "start": 0,
            "end": 1254,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_11@0",
            "content": "We believe these older metrics continue to be used mainly because modeling researchers value consistency and accessibility of evaluation practice over long periods of time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_11",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_11@1",
            "content": "BILLBOARDs provide a way to maintain long-term comparability of system output while also drawing better conclusions about system quality, using advances in evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_11",
            "start": 173,
            "end": 339,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_11@2",
            "content": "All generators continue to be evaluated with new metrics on BILLBOARDs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_11",
            "start": 341,
            "end": 411,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_12@0",
            "content": "Bidimensional Leaderboards",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_12",
            "start": 0,
            "end": 25,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_13@0",
            "content": "We propose BILLBOARDs to simultaneously drive progress in natural language generation and its evaluation, which are often disconnected in current research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_13",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_13@1",
            "content": "We first describe the general framework ( \u00a72.1) and the automatic analyses they provide ( \u00a72.2-2.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_13",
            "start": 156,
            "end": 255,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_13@2",
            "content": "We then discuss our design choices ( \u00a72.4) and the rubric-based, human judgment data necessary to initialize BILLBOARDs ( \u00a72.5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_13",
            "start": 257,
            "end": 384,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_14@0",
            "content": "BILLBOARD Framework",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_14",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_15@0",
            "content": "The leaderboard paradigm has driven research on state-of-the-art model performance on many tasks in various fields (e.g., ImageNet, Russakovsky et al., 2015;SQuAD, Rajpurkar et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_15",
            "start": 0,
            "end": 187,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_15@1",
            "content": "As applications and tasks become more diverse, however, the conventional leaderboard paradigm presents a serious challenge: the assumption becomes too strong that predetermined, automatic metrics can reliably score the system performance over time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_15",
            "start": 189,
            "end": 436,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_16@0",
            "content": "In particular, scores from automatic metrics often diverge from human judgments in language generation tasks, especially when models become increasingly powerful (Ma et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_16",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_16@1",
            "content": "Much recent work proposed new evaluation metrics that improve correlations with human judgments in certain generation tasks (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but most developers of generation models are not benefiting from them (See Appendix A for our analysis of papers from NAACL/ACL 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_16",
            "start": 181,
            "end": 532,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_16@2",
            "content": "From the perspective of generation model developers, it is not clear which of these many metrics in the literature is most reliable in which generation task or dataset, resulting in community-wide overuse of long-standing metrics like BLEU and ROUGE.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_16",
            "start": 534,
            "end": 783,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_16@3",
            "content": "Developers of evaluation metrics, on the other hand, are missing the opportunity to apply their metrics to new generation models and compare them with the existing ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_16",
            "start": 785,
            "end": 953,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_16@4",
            "content": "We propose BILLBOARDs that bridge this gap between generation modeling and evaluation development.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_16",
            "start": 955,
            "end": 1052,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_17@0",
            "content": "Generators, Metrics, and Scores A BILL-BOARD for a language generation task consists of sets of generators and evaluation metrics:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_17",
            "start": 0,
            "end": 129,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_18@0",
            "content": "G = {G i } I i=1 , M = {M j } J j=1 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_18",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_19@0",
            "content": "Each generator G i takes as input X k (e.g., source text in machine translation) and generates text: Y i,k = G i (X k ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_19",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_19@1",
            "content": "A metric M j assigns a score to each generated text given the generation input and the corresponding set of references R k : s i,j,k = M j (Y i,k , R k , X k ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_19",
            "start": 121,
            "end": 280,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_19@2",
            "content": "The last two arguments to the function are optional; some metrics do not require references (i.e., referenceless or quality estimation metrics) or the generation input (e.g., BLEU).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_19",
            "start": 282,
            "end": 462,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_19@3",
            "content": "We then compute the aggregate score s i,j by averaging s i,j,k over K test examples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_19",
            "start": 464,
            "end": 547,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@0",
            "content": "Rankings In contrast to standard leaderboards, BILLBOARDs have a dynamic set of evaluation metrics, and generators are not ranked by a predefined metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@1",
            "content": "We first rank the metrics by measuring their correlations to human judgments as commonly done in the generation evaluation literature (Zhang et al., 2020b;Sellam et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 154,
            "end": 329,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@2",
            "content": "Let h i,k be a human score for Y i,k (i.e., output from generator G i on input X k ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 331,
            "end": 415,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@3",
            "content": "We compute the instance-level Pearson correlation for every metric M j between h i,k and s i,j,k (M j score for Y i,k ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 417,
            "end": 536,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@4",
            "content": "All metrics are ranked by their correlations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 538,
            "end": 582,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@5",
            "content": "We then use the top metric M j * to rank the generators in the descending order of s i,j * .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 584,
            "end": 675,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@6",
            "content": "We defer our discussions on alternative design choices ( \u00a72.4) and human evaluations ( \u00a72.5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 677,
            "end": 769,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_20@7",
            "content": "We note, however, that the overall framework of BILLBOARDs still holds regardless of these decisions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_20",
            "start": 771,
            "end": 871,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_21@0",
            "content": "Ensemble of Metrics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_21",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_22@0",
            "content": "So far, we have assumed that metrics are used individually in isolation, but BILLBOARDs provide a unique opportunity to examine metrics collectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_22",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_22@1",
            "content": "Different metrics can capture different aspects of generation quality; even if a metric is not sufficiently informative in isolation, it might reflect an important aspect of text quality that the existing metrics overlook.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_22",
            "start": 150,
            "end": 371,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_22@2",
            "content": "Here we consider a straightforward and interpretable ensemble of metrics using a regression model with \u2113 1 regularization (Tibshirani, 1994).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_22",
            "start": 373,
            "end": 513,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_22@3",
            "content": "Let the ensemble's score be",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_22",
            "start": 515,
            "end": 541,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_23@0",
            "content": "\u0125i,k = J j=1 w j \u2022 s i,j,k ,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_23",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_24@0",
            "content": "where w j is a scalar coefficient associated with the jth metric and the intercept term is suppressed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_24",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_24@1",
            "content": "We optimize the vector of coefficients w with the pairs of output text and a human score {Y i,k , h i,k } K k=1 from the test data:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_24",
            "start": 103,
            "end": 233,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_25@0",
            "content": "w * = arg min w K k=1 h i,k \u2212 \u0125i,k 2 + \u03bb\u2225w\u2225 1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_25",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_26@0",
            "content": "The \u2113 1 regularization produces sparse coefficients and improves interpretability by removing highly correlated metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_26",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_26@1",
            "content": "Moreover, it avoids the need for practitioners to run many metrics to obtain an ensemble score when used outside our BILLBOARDs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_26",
            "start": 121,
            "end": 248,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_26@2",
            "content": "Our goal for the ensemble is to provide a useful signal to the research community, rather than to achieve the best possible correlation with human judges at a given time; we tune \u03bb to get three nonzero coefficients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_26",
            "start": 250,
            "end": 464,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_26@3",
            "content": "Every metric is standardized by its mean and standard deviation on the test data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_26",
            "start": 466,
            "end": 546,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_27@0",
            "content": "Similar to the individual metrics, we rank this ensemble metric by its correlation to the human judgments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_27",
            "start": 0,
            "end": 105,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_27@1",
            "content": "To make fair comparisons, we simulate situations where the ensemble is applied to a newly submitted generator that has no human evaluations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_27",
            "start": 107,
            "end": 246,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_27@2",
            "content": "Specifically, we perform cross validation that holds out the human judgments for each generator G i and runs regression on the rest; we then apply these I regression models to the corresponding held-out data and calculate the overall correlation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_27",
            "start": 248,
            "end": 493,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_27@3",
            "content": "We will see that the ensemble metric outperforms all individual metrics in some cases, suggesting that different metrics can capture different aspects.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_27",
            "start": 495,
            "end": 645,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_28@0",
            "content": "Reproduciblity The ensemble metric is updated every time a new metric is submitted (Fig. 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_28",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_28@1",
            "content": "For reproducibility, we keep track of every past ensemble metric with a signature that indicates its coefficients, \u03bb, and input metrics in the backend.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_28",
            "start": 93,
            "end": 243,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_28@2",
            "content": "Similar to SACREBLEU (Post, 2018), model developers can report the signature for easy replication of their scores from the ensemble metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_28",
            "start": 245,
            "end": 383,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_28@3",
            "content": "3 Further, all generation outputs are saved on the leaderboards, so model developers can download outputs from all past models and compare in any way.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_28",
            "start": 385,
            "end": 534,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_29@0",
            "content": "Mixed-Effects Model Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_29",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_30@0",
            "content": "Recent work (Kasai et al., 2022) observed that automatic metrics tend to overrate machine-generated text over human one on the MSCOCO image captioning task (Chen et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_30",
            "start": 0,
            "end": 175,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_30@1",
            "content": "This problem is particularly severe in conventional metrics that are based on n-gram overlap such as BLEU and CIDEr .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_30",
            "start": 177,
            "end": 293,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_30@2",
            "content": "This raises a significant concern about the continuous use of these conventional metrics in generation tasks as models become increasingly powerful (and more similar to humans); those metrics unintentionally discourage researchers from developing human-like, strong generation models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_30",
            "start": 295,
            "end": 578,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_30@3",
            "content": "To quantify this undesirable property, we propose a linear mixed-effects model that compares the two groups of machineand human-generated text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_30",
            "start": 580,
            "end": 722,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_30@4",
            "content": "The underlying model assumes that s i,j,k , the score from metric M j for generator G i and test example k, can be expressed as (the intercept term is suppressed for brevity):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_30",
            "start": 724,
            "end": 898,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_31@0",
            "content": "s i,j,k = \u03b2 j 0 1{G i is machine}+\u03b2 j 1 h i,k +\u03b3 k +\u03f5 i,j,k",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_31",
            "start": 0,
            "end": 58,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_32@0",
            "content": "where \u03b3 k is the random effect for example k, and \u03f5 i,j,k is Gaussian noise.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_32",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_32@1",
            "content": "Intuitively, \u03b2 j 0 measures how much metric M j overrates machine generation over human one, compared against the human judgment h i,k .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_32",
            "start": 77,
            "end": 212,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_32@2",
            "content": "\u03b2 j 0 = 0 means being neutral, and indeed we will find that \u03b2 j 0 is significantly positive in most cases ( \u00a74).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_32",
            "start": 214,
            "end": 325,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_32@3",
            "content": "We standardize all metric scores over the test samples to compare the size of \u03b2 j 0 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_32",
            "start": 327,
            "end": 411,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_32@4",
            "content": "We apply the lme4 package (Bates et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_32",
            "start": 413,
            "end": 459,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_33@0",
            "content": "Design Choices and Discussion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_33",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_34@0",
            "content": "In our current setup, we make several design choices for metrics and their rankings:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_34",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_35@0",
            "content": "\u2022 M.1 Metrics are expected to positively correlate with the generation output quality. \u2022 M.2 By default, metrics are ranked based on their instance-level Pearson correlations with human judgments. We also compute and present their system-level Kendall rank correlations. \u2022 M.3 When available, reference-based metrics use multiple references per instance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_35",
            "start": 0,
            "end": 353,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_36@0",
            "content": "M.1 implies that we need to take the negative of metric scores that are intended to negatively correlate (e.g., TER, Snover et al., 2006).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_36",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_36@1",
            "content": "This normalization is also done in WMT metric competitions , 2008.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_36",
            "start": 139,
            "end": 204,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@0",
            "content": "While instance-level correlations are commonly used to evaluate and compare automatic metrics for various language generation tasks (Sellam et al., 2020;Fabbri et al., 2021;Hessel et al., 2021, inter alia), there are several alternatives to M.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@1",
            "content": "For example, Pearson, Spearman's rank, or Kendall rank correlations can be used on a system (i.e., generator) level Mach\u00e1\u010dek and Bojar, 2014;Mathur et al., 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 246,
            "end": 408,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@2",
            "content": "However, such system-level correlations would substantially reduce data points to compare automatic scores, resulting in many ties in the ranking.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 410,
            "end": 555,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@3",
            "content": "Spearman's and Kendall rank correlations become brittle when multiple generators are similar in overall output quality; penalizing a metric for swapping two similar generators is misleading (Mach\u00e1\u010dek and Bojar, 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 557,
            "end": 773,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@4",
            "content": "Moreover, if a metric can perform well on an instance level, it can be used to augment human judgments by, for example, flagging likely wrong ratings (Mathur et al., 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 775,
            "end": 947,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@5",
            "content": "Thus, we encourage researchers to develop metrics that correlate well with human judgments on an instance level.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 949,
            "end": 1060,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@6",
            "content": "Prior work also points out other problems in ranking metrics like outlier effects where outlier systems have a disproportionately large effect on the overall correlation (Mathur et al., 2020a,b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 1062,
            "end": 1256,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@7",
            "content": "We therefore assume M.2 in the current version of BILLBOARDs, but this can be modified in a future version.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 1258,
            "end": 1364,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@8",
            "content": "M.3 is supported by our experimental results in \u00a74 that multiple references substantially improve reference-based metrics, and a single reference is often insufficient to outperform strong referenceless metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 1366,
            "end": 1576,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@9",
            "content": "Some metrics have specifications for multiple references (e.g., BLEU, CIDEr).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 1578,
            "end": 1654,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_37@10",
            "content": "In the other cases, we evaluate outputs against every reference and take the maximum score, following prior work on image captioning evaluation (Zhang et",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_37",
            "start": 1656,
            "end": 1808,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_38@0",
            "content": "Xining will implement the Xining Civilized Behavior Promotion Regulations from October 1st, which focus on 15 types of uncivilized behavior, such as pedestrians who do not follow the traffic lights and throw objects from buildings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_38",
            "start": 0,
            "end": 230,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_38@1",
            "content": "Generated Translation Xining City will implement the \"Xining City Civilized Behavior Promotion Regulation\" from October 1, focusing on 15 types of uncivilized behaviors such as pedestrians not passing traffic lights and throwing objects from buildings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_38",
            "start": 232,
            "end": 483,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_39@0",
            "content": "Human Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_39",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@0",
            "content": "Human evaluations are required to initialize BILL-BOARDs; they are used to rank metrics, train the metric ensembling model, and assess how much each metric overrates machines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@1",
            "content": "Recent work, however, points out problems when evaluations are done by crowdworkers even when extensive quality controls are performed (Gillick and Liu, 2010;Toral et al., 2018;Freitag et al., 2021;Clark et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 176,
            "end": 393,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@2",
            "content": "Freitag et al. (2021) show that rubric-based machine translation evaluations by professional translators led to substantially different generator rankings from the crowdsource evaluations in WMT 2020 (Barrault et al., 2020), where WMT participants or Amazon Mechanical Turkers directly assess each translation's adequacy by a single score (direct assessment).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 395,
            "end": 753,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@3",
            "content": "These crowdworker evaluations depend highly on individual annotators' discretion and understanding of the annotation scheme (Freitag et al., 2021;Clark et al., 2021), making it difficult to decompose, interpret, and validate (Kasai et al., 2022).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 755,
            "end": 1000,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@4",
            "content": "Moreover, these direct assessment scores make it difficult to interpret evaluation results for downstream applications where some aspects are particularly important (e.g., accessibility for people with visual impairments in image captioning, Gleason et al., 2020; gender bias in machine translation, Stanovsky et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 1002,
            "end": 1325,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@5",
            "content": "Motivated by this line of work, we perform metaevaluations to compare crowdsourced and rubricbased expert evaluations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 1327,
            "end": 1444,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@6",
            "content": "Fig. 2 plots overall scores for test examples from WMT20 ZH-EN (Barrault et al., 2020;Freitag et al., 2021) and CNNDM summarization (Fabbri et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 1446,
            "end": 1599,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@7",
            "content": "Each instance is evaluated by averaging the same number of crowdworkers and expert scores for fair comparisons.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 1601,
            "end": 1711,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@8",
            "content": "We see that substantially many instances fall into disagreement: crowdworkers give much higher scores than experts (lower right square) or the reverse (upper left square).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 1713,
            "end": 1883,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@9",
            "content": "We sample and shuffle 20/25 examples from either type and ask a meta-evaluator to make a binary decision (good or bad quality ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 1885,
            "end": 2012,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_40@10",
            "content": "5 Meta-evaluations agree more with the expert evaluations (e.g., 22 and 0 in the upper left and lower right squares for CNNDM, respectively).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_40",
            "start": 2014,
            "end": 2154,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_41@0",
            "content": "In the examples on the left, crowdworkers fail to properly assess a valid translation with different structure than the reference (posted a video to celebrate vs. congratulated via video) or a summary that combines information from different parts of the article.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_41",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_41@1",
            "content": "The examples on the right illustrate that crowdworkers can be fooled by inaccurate yet fluent generations (does not know the reason vs. does not know if Sanchez decided).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_41",
            "start": 264,
            "end": 433,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_41@2",
            "content": "Given this result, we decide to initialize our BILLBOARDs with rubricbased expert evaluations for all generation tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_41",
            "start": 435,
            "end": 553,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_41@3",
            "content": "We still encourage future work to explore ways to improve crowdsourced evaluations for scalability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_41",
            "start": 555,
            "end": 653,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_42@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_42",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_43@0",
            "content": "Having established the framework, we set up BILL-BOARDs for three natural language generation tasks: machine translation, summarization, and image captioning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_43",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_43@1",
            "content": "To maximize the performance of reference-based metrics, we use as many references as possible for each task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_43",
            "start": 159,
            "end": 266,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_43@2",
            "content": "See \u00a74 for an analysis on the effect of varying numbers of references.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_43",
            "start": 268,
            "end": 337,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_44@0",
            "content": "Tasks",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_44",
            "start": 0,
            "end": 4,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_45@0",
            "content": "Machine Translation We experiment with two language pairs from the WMT 2020 news translation task (Barrault et al., 2020): Chinese\u2192English (WMT20 ZH-EN) and English\u2192German (WMT20 EN-DE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_45",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_45@1",
            "content": "We use outputs from all submitted translation systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_45",
            "start": 187,
            "end": 240,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_45@2",
            "content": "6 These two language pairs have expert, rubric-based scores (MQM) from Freitag et al. (2021) for a subset of 10 submitted systems, including the top-performing systems and human translations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_45",
            "start": 242,
            "end": 432,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_45@3",
            "content": "Each output sentence is evaluated by three professional translators.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_45",
            "start": 434,
            "end": 501,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_45@4",
            "content": "Following Freitag et al. (2021), the three scores are averaged to get an instance-level score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_45",
            "start": 503,
            "end": 596,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_46@0",
            "content": "We use all human translations available as a reference set for reference-based metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_46",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_46@1",
            "content": "Concretely, every test instance in WMT20 ZH-EN has two translations provided by different human translation services: Human-A and Human-B ( Barrault et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_46",
            "start": 88,
            "end": 250,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_46@2",
            "content": "In addition to Human-A and Human-B, WMT20 EN-DE provides a translation that is created by linguists who are asked to paraphrase Human-A and Human-B as much as possible (Human-P, Freitag et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_46",
            "start": 252,
            "end": 451,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_46@3",
            "content": "These paraphrased translations are shown to increase correlations with human judgments by mitigating the translationese effect and diversifying the reference when the generation quality is measured by reference-based metrics (Freitag et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_46",
            "start": 453,
            "end": 700,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_47@0",
            "content": "Along with all submitted generators in WMT20 ZH-EN and WMT20 EN-DE, we train three transformer baselines with the fairseq library and place them in our BILL-BOARDs: transformer-base, transformer-large, and transformer-large-ensemble with similar hyperparameters (e.g., 6-layer encoder and decoder) to the ones trained on the WMT16 EN-DE data in Vaswani et al. (2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_47",
            "start": 0,
            "end": 366,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_47@1",
            "content": "7 These baselines allow researchers to compare their translation models without resource-intensive techniques such as backtranslation (Sennrich et al., 2016a), model ensembling, and deep encoders (Kasai et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_47",
            "start": 368,
            "end": 585,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_47@2",
            "content": "These techniques are all used in top-performing systems of WMT20 (Wu et al., 2020a;Kiyono et al., 2020) but might be infeasible in many research settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_47",
            "start": 587,
            "end": 740,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_47@3",
            "content": "See Appendix B for a list of all hyperparameters for the baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_47",
            "start": 742,
            "end": 808,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@0",
            "content": "Summarization We use the CNN/DailyMail corpus (CNNDM, Hermann et al., 2015;Nallapati et al., 2016). We use the standard train/dev./test split and 24 models from Fabbri et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@1",
            "content": "100 test articles are annotated with 10 summaries written by humans (Kryscinski et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 183,
            "end": 276,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@2",
            "content": "For those 100 articles, rubric-based, expert evaluations for 18 generators, including human-written highlights, are provided by Fabbri et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 278,
            "end": 426,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@3",
            "content": "8 Each output summary is evaluated by three experts along four dimensions: coherence (collective quality of all summary sentences), consistency (factual alignment with the article, penalizing for hallucinations), fluency (quality of the individual sentences), and relevance (selection of important content).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 428,
            "end": 734,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@4",
            "content": "An instancelevel score is computed by averaging scores over all these categories and the three experts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 736,
            "end": 838,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@5",
            "content": "Note that this aggregation method can be modified, depending on the downstream task of interest (Kasai et al., 2022).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 840,
            "end": 956,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@6",
            "content": "All 10 human-written summaries are used as the reference set for reference-based metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 958,
            "end": 1046,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_48@7",
            "content": "9",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_48",
            "start": 1048,
            "end": 1048,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_49@0",
            "content": "Image Captioning We use the MSCOCO dataset (Lin et al., 2014) that consists of everydayscene photos sampled from Flickr.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_49",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_49@1",
            "content": "Every image is annotated with five captions written by crowdworkers (Chen et al., 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_49",
            "start": 121,
            "end": 208,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_49@2",
            "content": "We apply the standard Karpathy split (Karpathy and Fei-Fei, 2015).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_49",
            "start": 210,
            "end": 275,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_49@3",
            "content": "For each of 500 test images, rubric-based evaluations (THUMB 1.0) are available for five systems, including one caption from a crowdworker (Kasai et al., 2022).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_49",
            "start": 277,
            "end": 436,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_49@4",
            "content": "Similar to machine translation and summarization, we use all five crowdworker captions as a reference set for reference-based metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_49",
            "start": 438,
            "end": 571,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_50@0",
            "content": "Mixed-Effects Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_50",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_51@0",
            "content": "Our mixed-effects model analyzes how much every automatic metric overrates machines over humans ( \u00a72.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_51",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_51@1",
            "content": "This means that we need to free up one human generation per instance to measure its scores in the reference-based metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_51",
            "start": 105,
            "end": 226,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_51@2",
            "content": "For machine translation, we score Human-B using the reference set of Human-A (WMT20 ZH-EN) or Human-A and Human-P (WMT20 EN-DE).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_51",
            "start": 228,
            "end": 355,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_51@3",
            "content": "For CNNDM, we use concatenated highlights as human-generated summaries and use the 10 human-written summaries from Kryscinski et al. (2019) as the reference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_51",
            "start": 357,
            "end": 513,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_51@4",
            "content": "We follow Kasai et al. (2022) for MSCOCO and score their randomly-selected Human caption using the other four as the reference.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_51",
            "start": 515,
            "end": 641,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_51@5",
            "content": "As the distinction between the reference and human generation (e.g., Human-A vs. Human B on WMT20 ZH-EN) is arbitrary, we found that swapping the roles would still lead to similar results (See Appendix E).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_51",
            "start": 643,
            "end": 847,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_52@0",
            "content": "9 Prior work used a concatenation of author-written highlights as a reference, but here we do not add it to the reference set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_52",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_52@1",
            "content": "This is because these highlights are sometimes noisy (e.g., containing URLs) or lack coherence (Fabbri et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_52",
            "start": 127,
            "end": 243,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_53@0",
            "content": "Results and Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_53",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_54@0",
            "content": "Here we discuss the current results and make several key observations about the state of language generation evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_54",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_54@1",
            "content": "Table 1 summarizes the four BILLBOARDs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_54",
            "start": 121,
            "end": 159,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_54@2",
            "content": "It is particularly noteworthy that COMET, a metric designed for machine translation, achieves the best correlation on the CNNDM summarization task as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_54",
            "start": 161,
            "end": 315,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_54@3",
            "content": "COMET evaluates the similarity between the crosslingual representations from XLM-RoBERTa (Conneau et al., 2020) for input text and its translation candidate. But these crosslingual representations can, of course, be used monolingually for English summarization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_54",
            "start": 317,
            "end": 577,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_54@4",
            "content": "This illustrates an additional benefit of BILLBOARDs that centralize different generation tasks and find surprising task transferability of learning-based metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_54",
            "start": 579,
            "end": 741,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_54@5",
            "content": "See Appendices B and C for lists of all participating generators and metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_54",
            "start": 743,
            "end": 819,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@0",
            "content": "The rightmost section of Table 1 shows the chosen metrics and their coefficients in the ensemble ( \u00a72.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@1",
            "content": "On the machine translation tasks, the ensemble metric outperforms the top individual metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 106,
            "end": 197,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@2",
            "content": "10 In particular, we see a substantial gain of 0.06 points in WMT20 ZH-EN.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 199,
            "end": 272,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@3",
            "content": "The referenceless metric of COMET-QE is selected both for WMT20 ZH-EN and WMT20 EN-DE, suggesting complementary effects of diverse metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 274,
            "end": 412,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@4",
            "content": "To further test this hypothesis, we perform ablations that drop one out of the three metrics at a time (Table 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 414,
            "end": 526,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@5",
            "content": "We see that only dropping COMET-QE would result in a decrease in the correlation score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 528,
            "end": 614,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@6",
            "content": "This implies that the reference-less metric provides important information that the others do not.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 616,
            "end": 713,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@7",
            "content": "Mixed-Effects Models Seen in Table 3 are the results from our analysis that measures how much metrics overrate machines over humans ( \u00a72.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 715,
            "end": 854,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@8",
            "content": "We see that the fixed-effect coefficient \u03b2 0 is significantly positive in most cases.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 856,
            "end": 940,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@9",
            "content": "Referenceless metrics tend to have smaller coefficients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 942,
            "end": 997,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@10",
            "content": "This can be due to the more diverse nature of human text than machine-generated text; reference-based metrics give a low score to human text that differs from the references even if it is of high quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 999,
            "end": 1202,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@11",
            "content": "The conventional n-gram overlap-based metrics (BLEU, ROUGE, and CIDEr) have particularly large coefficients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 1204,
            "end": 1311,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@12",
            "content": "These results suggest that the evaluation practice should be regularly updated as our generation models become stronger (and perhaps, more similar to human generation) in the future.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 1313,
            "end": 1494,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@13",
            "content": "Note that unlike the other tasks, \"human-generated text\" for CNNDM summarization is an automatic concatenation of author highlights, which contains substantial noise (Fabbri et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 1496,
            "end": 1683,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@14",
            "content": "This might explain the neutral and negative coefficients.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 1685,
            "end": 1741,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@15",
            "content": "Table 3: \u03b2 0 fixed-effect coefficients from the linear mixed-effects models, quantifying how much automatic metrics overrate machines over humans, relative to human raters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 1743,
            "end": 1914,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@16",
            "content": "\u03b2 0 = 0 is neutral, and statistical significance is indicated by red (positive) or blue text (negative).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 1916,
            "end": 2019,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@17",
            "content": "The subscripts indicate 90% confidence intervals.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2021,
            "end": 2069,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@18",
            "content": "Three metrics that correlate best with the human judgments are shown as well as one popular metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2071,
            "end": 2169,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@19",
            "content": "COMET-QE and CLIP-S are referenceless.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2171,
            "end": 2208,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@20",
            "content": "See \u00a7E for the other metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2210,
            "end": 2238,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@21",
            "content": "Effects of the Number of References Fig. 3 plots correlations over varying numbers of references.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2240,
            "end": 2336,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@22",
            "content": "COMET was the top-performing referencebased metric regardless of the number of references, but we observe that it underperforms the refererenceless metric when only one reference is given.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2338,
            "end": 2525,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@23",
            "content": "Model performance in machine translation and summarization is commonly measured by applying reference-based metrics against one reference per instance in the research community.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2527,
            "end": 2703,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@24",
            "content": "Our finding thus raises a further concern about the current evaluation practice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2705,
            "end": 2784,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_55@25",
            "content": "Finally, we see that popular choices of BLEU and ROUGE metrics have much lower correlations than the recent metrics over various numbers of references, in line with the recent studies (Mathur et al., 2020a, inter alia).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_55",
            "start": 2786,
            "end": 3004,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_56@0",
            "content": "Related and Future Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_56",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@0",
            "content": "Related Benchmarks WMT organizes the metric competition track in parallel with the translation task every year (Mathur et al., 2020b;Barrault et al., 2020, inter alia).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@1",
            "content": "Participants submit automatic scores for the translation outputs from the parallel translation task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 169,
            "end": 268,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@2",
            "content": "Unfortunately, most of these new metrics are not used by subsequent machine translation work, perhaps because they are tested solely against the concurrent translation submissions and it is up to model developers to execute or even implement new metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 270,
            "end": 523,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@3",
            "content": "The GEM workshop (Gehrmann et al., 2021) conducts extensive analysis of models and evaluation methods over a wide set of generation tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 525,
            "end": 662,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@4",
            "content": "BILLBOARDs ease the burden through standard leaderboard experience where generator developers only need to upload generation outputs for the test split.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 664,
            "end": 815,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@5",
            "content": "BILL-BOARDs also offer automatic ensembling of metrics and quantify the diversity that a new metric adds.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 817,
            "end": 921,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@6",
            "content": "The human-in-the-loop GENIE leaderboard (Khashabi et al., 2021) , 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 923,
            "end": 994,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@7",
            "content": "There are ongoing modeling and benchmarking efforts especially for efficient machine translation (Heafield et al., 2020;Peng et al., 2021;Kasai et al., 2021b, inter alia).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 996,
            "end": 1166,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_57@8",
            "content": "We leave this extension to future work and specifically target the gap between generation modeling and evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_57",
            "start": 1168,
            "end": 1281,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_58@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_58",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_59@0",
            "content": "We introduced BILLBOARDs, a simple yet powerful generalization of leaderboards that bridges the gap between generation modeling and evaluation research.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_59",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_59@1",
            "content": "We established and released four BILL-BOARDs on machine translation, summarization, and image captioning tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_59",
            "start": 153,
            "end": 263,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_59@2",
            "content": "We demonstrated that their built-in analysis of metric ensembling and mixed-effects modeling revealed key insights into the current state of natural language generation and its evaluation methods.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_59",
            "start": 265,
            "end": 460,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_59@3",
            "content": "BILLBOARDs allow for a standard leaderboard experience both on the modeling and evaluation sides.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_59",
            "start": 462,
            "end": 558,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_59@4",
            "content": "We invite submissions from researchers through our website.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_59",
            "start": 560,
            "end": 618,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_60@0",
            "content": "Dan Gillick and Yang Liu. 2010.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_60",
            "start": 0,
            "end": 30,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_60@1",
            "content": "Non-expert evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_60",
            "start": 32,
            "end": 52,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_61@0",
            "content": "A Case Studies of Evaluation Practice Fig. 4 depicts breakdowns of evaluation metrics used in the papers on machine translation and summarization from NAACL and ACL 2021.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_61",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_61@1",
            "content": "We examined all papers whose title contains \"machine translation\" and \"summarization.\" We see the clear gap between generation modeling and evaluation research; most researchers do not take advantage of recent metrics that correlate better with human judgments.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_61",
            "start": 171,
            "end": 431,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@0",
            "content": "Here we list the generators submitted in the initial BILLBOARDs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@1",
            "content": "We use all 16 submissions for the WMT20 ZH-EN task (Barrault et al., 2020) 11 as well as our own three transformer baselines that were implemented in fairseq .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 65,
            "end": 223,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@2",
            "content": "Our baselines allow researchers to compare their translation models without resource-intensive techniques such as backtranslation (Sennrich et al., 2016a), model ensembling, and deep encoders (Kasai et al., 2021a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 225,
            "end": 438,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@3",
            "content": "Tables 4 and 5 list the hyperprameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 440,
            "end": 478,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@4",
            "content": "We generally follow the setting from Vaswani et al. (2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 480,
            "end": 538,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@5",
            "content": "We use newstest-2019 as the dev.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 540,
            "end": 571,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@6",
            "content": "set and the official training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 573,
            "end": 607,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@7",
            "content": "12 We apply Moses tokenization and BPE with 32K operations (Sennrich et al., 2016b) to English text.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 609,
            "end": 708,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@8",
            "content": "We tokenize Chinese text with the Jieba package, 13 following Hassan et al. (2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 710,
            "end": 792,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@9",
            "content": "Separately from English, BPE with 32K operations is then applied to Chinese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 794,
            "end": 869,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@10",
            "content": "The decoder input and output embeddings are tied.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 871,
            "end": 919,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@11",
            "content": "Moses detokenization is applied to get the final outputs in the last step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 921,
            "end": 994,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@12",
            "content": "We make the three models and preprocessed train/dev.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 996,
            "end": 1047,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@13",
            "content": "data publicly available.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 1049,
            "end": 1072,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_62@14",
            "content": "14 Table 6 lists all generators and their automatic evaluation scores from the top-performing metric (ensemble in this case).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_62",
            "start": 1074,
            "end": 1198,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@0",
            "content": "Similar to WMT20 ZH-EN, we use all 14 submissions for the WMT20 EN-DE task along with our three transformer baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@1",
            "content": "The same hyperparameters are chosen as in WMT20 ZH-EN (Tables 4 and 5).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 119,
            "end": 189,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@2",
            "content": "We preprocess both English and German text by the Moses tokenizer and joint BPE with 32K operations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 191,
            "end": 290,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@3",
            "content": "All embeddings are shared.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 292,
            "end": 317,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@4",
            "content": "We apply the Moses detokenizer to get the final outputs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 319,
            "end": 374,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@5",
            "content": "We examined all papers whose title contains \"machine translation\" and \"summarization\" and disregarded papers primarily on evaluation metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 376,
            "end": 516,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@6",
            "content": "\"QA\" metrics use a QA system to evaluate summaries (e.g., Eyal et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 518,
            "end": 594,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@7",
            "content": "\"Specialized\" indicates specialized evaluation in a particular dimension, rather than the overall generation quality, such as document-level evaluations on contrastive sets (Voita et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 596,
            "end": 789,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@8",
            "content": "Bawden et al. (2020) 73.89 Table 6: WMT20 ZH-EN generators and reference papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 791,
            "end": 870,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_63@9",
            "content": "The score column indicates the score from the metric that currently correlates best with the human judgments (ensemble).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_63",
            "start": 872,
            "end": 991,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_64@0",
            "content": "Table 7 shows the generators and their automatic evaluation scores from the top-performing metric (ensemble).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_64",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_65@0",
            "content": "We submit all 26 models from Fabbri et al. (2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_65",
            "start": 0,
            "end": 49,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_65@1",
            "content": "15 Table 8 shows all models and their automatic evaluation scores from the top-performing metric (COMET).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_65",
            "start": 51,
            "end": 155,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_66@0",
            "content": "We submit the four strong models from the literature (Kasai et al., 2022).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_66",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_66@1",
            "content": "16 They share similar pipeline structure but vary in model architecture, (pre)training data, model size, and (pre)training objective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_66",
            "start": 75,
            "end": 207,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_66@2",
            "content": "Table 9 shows the models with their papers and automatic scores from the top-performing metric (RefCLIP-S).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_66",
            "start": 209,
            "end": 315,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_67@0",
            "content": "Table 12 presents fixed-effect coefficients that measure how much each automatic metric overrates machines over humans ( \u00a72.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_67",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_67@1",
            "content": "With some exceptions in CNNDM summarization, almost all automatic metrics underrate human generations (significantly positive coefficients).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_67",
            "start": 128,
            "end": 267,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_67@2",
            "content": "Table 13 swaps the roles of human-generated text, but we still see similar patterns: almost all metrics overrate machines over humans, but the problem is mitigated in COMET-QE, a referenceless, quality estimation metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_67",
            "start": 269,
            "end": 488,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_67@3",
            "content": "This confirms that our findings hold independently of the design choice.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_67",
            "start": 490,
            "end": 561,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_68@0",
            "content": "Seen in Table 14 are examples where crowdworker evaluators (Barrault et al., 2020) and professional translators (Freitag et al., 2021) disagree: crowdworkers give lower scores to the human-generated translations than the machine-generated ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_68",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_68@1",
            "content": "The first case requires document-level context to properly evaluate.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_68",
            "start": 245,
            "end": 312,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_68@2",
            "content": "Document-level context and diversity in high-quality human translations can mislead crowdworkers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_68",
            "start": 314,
            "end": 410,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_69@0",
            "content": "Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould, SPICE: semantic propositional image caption evaluation, 2016, Proc. of ECCV, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_69",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_70@0",
            "content": "Peter Anderson, Xiaodong He, Chris Buehler, Damien Teney, Mark Johnson, Stephen Gould, Lei Zhang, Bottom-up and top-down attention for image captioning and visual question answering, 2018, Proc. of CVPR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_70",
            "start": 0,
            "end": 204,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_71@0",
            "content": "Satanjeev Banerjee, Alon Lavie, METEOR: An automatic metric for MT evaluation with improved correlation with human judgments, 2005, Proc. of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_71",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_72@0",
            "content": "UNKNOWN, None, , Santanu Pal, Matt Post, and Marcos Zampieri. 2020. Findings of the 2020 conference on machine translation (WMT20). In Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_72",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_73@0",
            "content": "Douglas Bates, Martin M\u00e4chler, Ben Bolker, Steve Walker, Fitting linear mixed-effects models using lme4, 2015, Journal of Statistical Software, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_73",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_74@0",
            "content": "UNKNOWN, None, , Dina Wiemann, and Lana Yeganova. 2020. Findings of the WMT 2020 biomedical translation shared task: Basque, Italian and Russian as new additional languages, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_74",
            "start": 0,
            "end": 174,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_75@0",
            "content": "UNKNOWN, None, 2009, Natural Language Processing with Python, Cambridge University Press.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_75",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_76@0",
            "content": "Florian B\u00f6hm, Yang Gao, Christian Meyer, Ori Shapira, Ido Dagan, Iryna Gurevych, Better rewards yield better summaries: Learning to summarise without references, 2019, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_76",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_77@0",
            "content": "L\u00e9o Bouscarrat, Antoine Bonnefoy, Thomas Peel, C\u00e9cile Pereira, STRASS: A light and effective method for extractive summarization based on sentence embeddings, 2019, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_77",
            "start": 0,
            "end": 179,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_78@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_78",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_79@0",
            "content": "Sandhini Askell, Ariel Agarwal, Gretchen Herbert-Voss, Tom Krueger, Rewon Henighan, Aditya Child, Daniel Ramesh, Jeffrey Ziegler, Clemens Wu, Chris Winter, Mark Hesse, Eric Chen, Mateusz Sigler,  Litwin, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners, , Proc. of NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_79",
            "start": 0,
            "end": 303,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_80@0",
            "content": "Chris Callison, - Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, Josh Schroeder, meta-) evaluation of machine translation, 2007, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_80",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_81@0",
            "content": "Chris Callison, - Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, Josh Schroeder, Further meta-evaluation of machine translation, 2008, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_81",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_82@0",
            "content": "Chris Callison, - Burch, Miles Osborne, Philipp Koehn, Re-evaluating the role of Bleu in machine translation research, 2006, Proc. of EACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_82",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_83@0",
            "content": "Tanfang Chen, Weiwei Wang, Wenyang Wei, Xing Shi, Xiangang Li, Jieping Ye, and Kevin Knight. 2020. DiDi's machine translation system for WMT2020, , Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_83",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_84@0",
            "content": "UNKNOWN, None, 2015, Microsoft COCO captions: Data collection and evaluation server, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_84",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_85@0",
            "content": "Yen-Chun Chen, Mohit Bansal, Fast abstractive summarization with reinforce-selected sentence rewriting, 2018, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_85",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_86@0",
            "content": "Elizabeth Clark, Tal August, Sofia Serrano, Nikita Haduong, Suchin Gururangan, Noah Smith, All that's 'human' is not gold: Evaluating human evaluation of generated text, 2021, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_86",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_87@0",
            "content": "Elizabeth Clark, Asli Celikyilmaz, Noah Smith, Sentence mover's similarity: Automatic evaluation for multi-sentence texts, 2019, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_87",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_88@0",
            "content": "Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, Francisco Guzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettlemoyer, Veselin Stoyanov, Unsupervised cross-lingual representation learning at scale, 2020, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_88",
            "start": 0,
            "end": 247,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_89@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proc. of NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_89",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_90@0",
            "content": "Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon, Unified language model pre-training for natural language understanding and generation, 2019, Proc. of NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_90",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_91@0",
            "content": "Yue Dong, Yikang Shen, Eric Crawford, BanditSum: Extractive summarization as a contextual bandit, 2018, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_91",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_92@0",
            "content": "Sergey Edunov, Myle Ott, Marc'aurelio Ranzato, Michael Auli, On the evaluation of machine translation systems trained with back-translation, 2020, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_92",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_93@0",
            "content": "Kawin Ethayarajh, Dan Jurafsky, Utility is in the eye of the user: A critique of NLP leaderboards, 2020, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_93",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_94@0",
            "content": "Matan Eyal, Tal Baumel, Michael Elhadad, Question answering as an automatic evaluation metric for news article summarization, 2019, Proc. of NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_94",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_95@0",
            "content": "UNKNOWN, None, 2021, SummEval: Re-evaluating summarization evaluation, TACL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_95",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_96@0",
            "content": "UNKNOWN, None, , Viresh Ratnakar, Qijun Tan, and Wolfgang Macherey. 2021. Experts, errors, and context: A large-scale study of human evaluation for machine translation, TACL.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_96",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_97@0",
            "content": "Markus Freitag, David Grangier, Isaac Caswell, BLEU might be guilty but references are not innocent, 2020, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_97",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_98@0",
            "content": "UNKNOWN, None, , Proc. of GEM, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_98",
            "start": 0,
            "end": 31,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_99@0",
            "content": "Sebastian Gehrmann, Yuntian Deng, Alexander Rush, Bottom-up abstractive summarization, 2018, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_99",
            "start": 0,
            "end": 109,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_100@0",
            "content": "Ulrich Germann, The University of Edinburgh's submission to the German-to-English and English-to-German tracks in the WMT 2020 news translation and zero-shot translation robustness tasks, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_100",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_101@0",
            "content": "Wan-Ting Hsu, Chieh-Kai Lin, Ming-Ying Lee, Kerui Min, A unified model for extractive and abstractive summarization using inconsistency loss, 2018, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_101",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_102@0",
            "content": "Yichen Jiang, Mohit Bansal, Closed-book training to improve summarization encoder memory, 2018, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_102",
            "start": 0,
            "end": 112,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_103@0",
            "content": "Andrej Karpathy, Li Fei-Fei, Deep visualsemantic alignments for generating image descriptions, 2015, Proc. of CVPR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_103",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_104@0",
            "content": "Jungo Kasai, Nikolaos Pappas, Hao Peng, James Cross, Noah Smith, Deep encoder, shallow decoder: Reevaluating non-autoregressive machine translation, 2021, Proc. of ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_104",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_105@0",
            "content": "Jungo Kasai, Hao Peng, Yizhe Zhang, Dani Yogatama, Gabriel Ilharco, Nikolaos Pappas, Yi Mao, Weizhu Chen, Noah Smith, Finetuning pretrained transformers into RNNs, 2021, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_105",
            "start": 0,
            "end": 186,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_106@0",
            "content": "Jungo Kasai, Keisuke Sakaguchi, Lavinia Dunagan, Jacob Morrison, Yejin Ronan Le Bras, Noah Choi,  Smith, 2022. Transparent human evaluation for image captioning, , Proc. of NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_106",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_107@0",
            "content": "UNKNOWN, None, 2021, GENIE: A leaderboard for human-in-the-loop evaluation of text generation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_107",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_108@0",
            "content": "Shun Kiyono, Takumi Ito, Ryuto Konno, Tohoku-AIP-NTT at WMT 2020 news translation task, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_108",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_109@0",
            "content": "Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond\u0159ej Bojar, Alexandra Constantin, Evan Herbst, Moses: Open source toolkit for statistical machine translation, 2007, Proc. of ACL Demo and Poster Sessions, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_109",
            "start": 0,
            "end": 328,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_110@0",
            "content": "Wojciech Kryscinski, Nitish Shirish Keskar, Bryan Mc-Cann, Caiming Xiong, Richard Socher, Neural text summarization: A critical evaluation, 2019, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_110",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_111@0",
            "content": "Wojciech Kry\u015bci\u0144ski, Romain Paulus, Caiming Xiong, Richard Socher, Improving abstraction in text summarization, 2018, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_111",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_112@0",
            "content": "Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer Levy, Veselin Stoyanov, Luke Zettlemoyer, BART: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension, 2020, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_112",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_113@0",
            "content": "Zuchao Li, Hai Zhao, Rui Wang, Kehai Chen, Masao Utiyama, Eiichiro Sumita, SJTU-NICT's supervised and unsupervised neural machine translation systems for the WMT20 news translation task, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_113",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_114@0",
            "content": "Chin-Yew Lin, ROUGE: A package for automatic evaluation of summaries, 2004, Proc. of Text Summarization Branches Out, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_114",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_115@0",
            "content": "Tsung-Yi Lin, Michael Maire, Serge Belongie, Lubomir Bourdev, Ross Girshick, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Zitnick, Microsoft COCO: common objects in context, 2014, Proc. of ECCV, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_115",
            "start": 0,
            "end": 207,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_116@0",
            "content": "Yang Liu, Mirella Lapata, Text summarization with pretrained encoders, 2019, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_116",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_117@0",
            "content": "Qingsong Ma, Johnny Wei, Ond\u0159ej Bojar, Yvette Graham, Results of the WMT19 metrics shared task: Segment-level and strong MT systems pose big challenges, 2019, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_117",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_118@0",
            "content": "Matou\u0161 Mach\u00e1\u010dek, Ond\u0159ej Bojar, Results of the WMT14 metrics shared task, 2014, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_118",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_119@0",
            "content": "Christopher Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven Bethard, David Mc-Closky, The Stanford CoreNLP natural language processing toolkit, 2014, Proc. of ACL System Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_119",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_120@0",
            "content": "Benjamin Marie, Atsushi Fujita, Raphael Rubino, Scientific credibility of machine translation research: A meta-evaluation of 769 papers, 2021, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_120",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_121@0",
            "content": "Nitika Mathur, Timothy Baldwin, Trevor Cohn, Tangled up in BLEU: Reevaluating the evaluation of automatic machine translation evaluation metrics, 2020, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_121",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_122@0",
            "content": "Nitika Mathur, Johnny Wei, Markus Freitag, Qingsong Ma, Ond\u0159ej Bojar, Results of the WMT20 metrics shared task, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_122",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_123@0",
            "content": "Fandong Meng, Jianhao Yan, Yijin Liu, Yuan Gao, Xianfeng Zeng, Qinsong Zeng, Peng Li, Ming Chen, Jie Zhou, Sifan Liu, Hao Zhou, WeChat neural machine translation systems for WMT20, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_123",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_124@0",
            "content": "Swaroop Mishra, Anjana Arunkumar, How robust are model rankings : A leaderboard customization approach for equitable evaluation, 2021, Proc. of AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_124",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_125@0",
            "content": "Alexander Molchanov, PROMT systems for WMT 2020 shared news translation task, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_125",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_126@0",
            "content": "Ramesh Nallapati, Bowen Zhou, Abstractive text summarization using sequence-tosequence RNNs and beyond, 2016, Proc. of CoNLL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_126",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_127@0",
            "content": "Shashi Narayan, Shay Cohen, Mirella Lapata, Ranking sentences for extractive summarization with reinforcement learning, 2018, Proc. of NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_127",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_128@0",
            "content": "Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, Sergey Edunov, Facebook FAIR's WMT19 news translation task submission, 2019, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_128",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_129@0",
            "content": "Csaba Oravecz, Katina Bontcheva, L\u00e1szl\u00f3 Tihanyi, David Kolovratnik, Bhavani Bhaskar, Adrien Lardilleux, Szymon Klocek, and Andreas Eisele. 2020. eTranslation's submissions to the WMT 2020 news translation task, , Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_129",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_130@0",
            "content": "Myle Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, Nathan Ng, David Grangier, Michael Auli, fairseq: A fast, extensible toolkit for sequence modeling, 2019, Proc. of NAACL Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_130",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_131@0",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, BLEU: a method for automatic evaluation of machine translation, 2002, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_131",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_132@0",
            "content": "Ramakanth Pasunuru, Mohit Bansal, Multireward reinforced summarization with saliency and entailment, 2018, Proc. of NAACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_132",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_133@0",
            "content": "Hao Peng, Nikolaos Pappas, Dani Yogatama, Roy Schwartz, Noah Smith, Lingpeng Kong, Random feature attention, 2021, Proc. of ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_133",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_134@0",
            "content": "Maja Popovi\u0107, chrF: character n-gram F-score for automatic MT evaluation, 2015, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_134",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_135@0",
            "content": "Maja Popovi\u0107, chrF++: words helping character n-grams, 2017, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_135",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_136@0",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_136",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_137@0",
            "content": "Alec Radford, Jong Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, , Gretchen Krueger, and Ilya Sutskever. 2021. Learning transferable visual models from natural language supervision, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_137",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_138@0",
            "content": "UNKNOWN, None, 2020, Exploring the limits of transfer learning with a unified text-to-text transformer, JLMR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_138",
            "start": 0,
            "end": 108,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_139@0",
            "content": "Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, SQuAD: 100,000+ questions for machine comprehension of text, 2016, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_139",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_140@0",
            "content": "Ricardo Rei, Craig Stewart, Ana Farinha, Alon Lavie, COMET: A neural framework for MT evaluation, 2020, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_140",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_141@0",
            "content": "UNKNOWN, None, 2015, , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_141",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_142@0",
            "content": "Thomas Scialom, Sylvain Lamprier, Benjamin Piwowarski, Jacopo Staiano, Answers unite! unsupervised metrics for reinforced summarization models, 2019, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_142",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_143@0",
            "content": "Abigail See, J Peter, Christopher Liu,  Manning, Get to the point: Summarization with pointergenerator networks, 2017, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_143",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_144@0",
            "content": "Thibault Sellam, Dipanjan Das, Ankur P Parikh, BLEURT: Learning robust metrics for text generation, 2020, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_144",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_145@0",
            "content": "Rico Sennrich, Barry Haddow, Alexandra Birch, Improving neural machine translation models with monolingual data, 2016, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_145",
            "start": 0,
            "end": 133,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_146@0",
            "content": "Eva Sharma, Luyang Huang, Zhe Hu, Lu Wang, An entity-driven framework for abstractive summarization, 2019, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_146",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_147@0",
            "content": "Tingxun Shi, Shiyu Zhao, Xiaopu Li, Xiaoxue Wang, Qian Zhang, Di Ai, Dawei Dang, Xue Zhengshan, Jie Hao, OPPO's machine translation systems for WMT20, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_147",
            "start": 0,
            "end": 171,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_148@0",
            "content": "Matthew Snover, Bonnie Dorr, Rich Schwartz, Linnea Micciulla, John Makhoul, A study of translation edit rate with targeted human annotation, 2006, Proc. of AMTA, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_148",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_149@0",
            "content": "Gabriel Stanovsky, Noah Smith, Luke Zettlemoyer, Evaluating gender bias in machine translation, 2019, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_149",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_150@0",
            "content": "Brian Thompson, Matt Post, Automatic machine translation evaluation in many languages via zero-shot paraphrasing, 2020, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_150",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_151@0",
            "content": "Robert Tibshirani, Regression shrinkage and selection via the Lasso, 1994, Journal of the Royal Statistical Society, Series B, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_151",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_152@0",
            "content": "Antonio Toral, Sheila Castilho, Ke Hu, Andy Way, Attaining the unattainable? reassessing claims of human parity in neural machine translation, 2018, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_152",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_153@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Proc. of NeurIPS, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_153",
            "start": 0,
            "end": 170,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_154@0",
            "content": "C Ramakrishna Vedantam, Devi Zitnick,  Parikh, CIDEr: Consensus-based image description evaluation, 2015, Proc. of CVPR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_154",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_155@0",
            "content": "Elena Voita, Rico Sennrich, Ivan Titov, When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion, 2019, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_155",
            "start": 0,
            "end": 191,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_156@0",
            "content": "Weiyue Wang, Jan-Thorsten Peter, Hendrik Rosendahl, Hermann Ney, CharacTer: Translation edit rate on character level, 2016, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_156",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_157@0",
            "content": "Daimeng Wei, Hengchao Shang, Zhanglin Wu, Zhengzhe Yu, Liangyou Li, Jiaxin Guo, Minghan Wang, Hao Yang, Lizhi Lei, Ying Qin, and Shiliang Sun. 2020. HW-TSC's participation in the WMT 2020 news translation shared task, , Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_157",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_158@0",
            "content": "Liwei Wu, Xiao Pan, Zehui Lin, Yaoming Zhu, Mingxuan Wang, Lei Li, The Volctrans machine translation system for WMT20, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_158",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_159@0",
            "content": "Shuangzhi Wu, Xing Wang, Longyue Wang, Fangxu Liu, Jun Xie, Zhaopeng Tu, Shuming Shi, Mu Li, Tencent neural machine translation systems for the WMT20 news translation task, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_159",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_160@0",
            "content": "Yuxiang Wu, Baotian Hu, Learning to extract coherent summary via deep reinforcement learning, 2018, Proc. of AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_160",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_161@0",
            "content": "Jiacheng Xu, Greg Durrett, Neural extractive text summarization with syntactic compression, 2019, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_161",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_162@0",
            "content": "Lei Yu, Laurent Sartran, Po-Sen Huang, Wojciech Stokowiec, Domenic Donato, Srivatsan Srinivasan, Alek Andreev, Wang Ling, The DeepMind Chinese-English document translation system at WMT2020, 2020, Proc. of WMT, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_162",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_163@0",
            "content": "Jingqing Zhang, Yao Zhao, Mohammad Saleh, Peter Liu, PEGASUS: Pre-training with extracted gap-sentences for abstractive summarization, 2020, Proc. of ICML, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_163",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_164@0",
            "content": "Pengchuan Zhang, Xiujun Li, Xiaowei Hu, Jianwei Yang, Lei Zhang, Lijuan Wang, Yejin Choi, Jianfeng Gao, VinVL: Making visual representations matter in vision-language models, 2021, Proc. of CVPR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_164",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_165@0",
            "content": "Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Weinberger, Yoav Artzi, BERTScore: Evaluating text generation with BERT, 2020, Proc. of ICLR, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_165",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_166@0",
            "content": "Xingxing Zhang, Mirella Lapata, Furu Wei, Ming Zhou, Neural latent extractive document summarization, 2018, Proc. of EMNLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_166",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_167@0",
            "content": "Luowei Zhou, Hamid Palangi, Lei Zhang, Houdong Hu, Jason Corso, Jianfeng Gao, Unified vision-language pre-training for image captioning and VQA, 2020, Proc. of AAAI, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_167",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_168@0",
            "content": "Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang, Ming Zhou, Tiejun Zhao, Neural document summarization by jointly learning to score and select sentences, 2018, Proc. of ACL, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_168",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "19-ARR_v2_169@0",
            "content": "UNKNOWN, None, 2019, Fine-tuning language models from human preferences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "19-ARR_v2_169",
            "start": 0,
            "end": 73,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_1",
            "tgt_ix": "19-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_1",
            "tgt_ix": "19-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_4",
            "tgt_ix": "19-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_5",
            "tgt_ix": "19-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_6",
            "tgt_ix": "19-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_7",
            "tgt_ix": "19-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_8",
            "tgt_ix": "19-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_9",
            "tgt_ix": "19-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_11",
            "tgt_ix": "19-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_13",
            "tgt_ix": "19-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_15",
            "tgt_ix": "19-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_16",
            "tgt_ix": "19-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_17",
            "tgt_ix": "19-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_18",
            "tgt_ix": "19-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_19",
            "tgt_ix": "19-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_22",
            "tgt_ix": "19-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_23",
            "tgt_ix": "19-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_24",
            "tgt_ix": "19-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_25",
            "tgt_ix": "19-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_26",
            "tgt_ix": "19-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_27",
            "tgt_ix": "19-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_28",
            "tgt_ix": "19-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_30",
            "tgt_ix": "19-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_31",
            "tgt_ix": "19-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_29",
            "tgt_ix": "19-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_29",
            "tgt_ix": "19-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_29",
            "tgt_ix": "19-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_29",
            "tgt_ix": "19-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_32",
            "tgt_ix": "19-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_34",
            "tgt_ix": "19-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_36",
            "tgt_ix": "19-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_33",
            "tgt_ix": "19-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_33",
            "tgt_ix": "19-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_33",
            "tgt_ix": "19-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_33",
            "tgt_ix": "19-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_33",
            "tgt_ix": "19-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_33",
            "tgt_ix": "19-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_38",
            "tgt_ix": "19-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_39",
            "tgt_ix": "19-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_39",
            "tgt_ix": "19-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_39",
            "tgt_ix": "19-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_41",
            "tgt_ix": "19-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_42",
            "tgt_ix": "19-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_42",
            "tgt_ix": "19-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_42",
            "tgt_ix": "19-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_43",
            "tgt_ix": "19-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_45",
            "tgt_ix": "19-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_46",
            "tgt_ix": "19-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_47",
            "tgt_ix": "19-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_44",
            "tgt_ix": "19-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_44",
            "tgt_ix": "19-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_44",
            "tgt_ix": "19-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_44",
            "tgt_ix": "19-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_44",
            "tgt_ix": "19-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_44",
            "tgt_ix": "19-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_42",
            "tgt_ix": "19-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_49",
            "tgt_ix": "19-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_51",
            "tgt_ix": "19-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_50",
            "tgt_ix": "19-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_50",
            "tgt_ix": "19-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_50",
            "tgt_ix": "19-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_52",
            "tgt_ix": "19-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_53",
            "tgt_ix": "19-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_53",
            "tgt_ix": "19-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_53",
            "tgt_ix": "19-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_54",
            "tgt_ix": "19-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_56",
            "tgt_ix": "19-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_56",
            "tgt_ix": "19-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_59",
            "tgt_ix": "19-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_60",
            "tgt_ix": "19-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_61",
            "tgt_ix": "19-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_64",
            "tgt_ix": "19-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_66",
            "tgt_ix": "19-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_67",
            "tgt_ix": "19-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "19-ARR_v2_0",
            "tgt_ix": "19-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_1",
            "tgt_ix": "19-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_2",
            "tgt_ix": "19-ARR_v2_2@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_3",
            "tgt_ix": "19-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_4",
            "tgt_ix": "19-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_4",
            "tgt_ix": "19-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_4",
            "tgt_ix": "19-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_5",
            "tgt_ix": "19-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_5",
            "tgt_ix": "19-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_5",
            "tgt_ix": "19-ARR_v2_5@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_5",
            "tgt_ix": "19-ARR_v2_5@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_6",
            "tgt_ix": "19-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_6",
            "tgt_ix": "19-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_6",
            "tgt_ix": "19-ARR_v2_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_6",
            "tgt_ix": "19-ARR_v2_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_7",
            "tgt_ix": "19-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_7",
            "tgt_ix": "19-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_7",
            "tgt_ix": "19-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_7",
            "tgt_ix": "19-ARR_v2_7@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_7",
            "tgt_ix": "19-ARR_v2_7@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_7",
            "tgt_ix": "19-ARR_v2_7@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_8",
            "tgt_ix": "19-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_9",
            "tgt_ix": "19-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_10",
            "tgt_ix": "19-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_11",
            "tgt_ix": "19-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_11",
            "tgt_ix": "19-ARR_v2_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_11",
            "tgt_ix": "19-ARR_v2_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_12",
            "tgt_ix": "19-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_13",
            "tgt_ix": "19-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_13",
            "tgt_ix": "19-ARR_v2_13@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_13",
            "tgt_ix": "19-ARR_v2_13@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_14",
            "tgt_ix": "19-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_15",
            "tgt_ix": "19-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_15",
            "tgt_ix": "19-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_16",
            "tgt_ix": "19-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_16",
            "tgt_ix": "19-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_16",
            "tgt_ix": "19-ARR_v2_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_16",
            "tgt_ix": "19-ARR_v2_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_16",
            "tgt_ix": "19-ARR_v2_16@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_17",
            "tgt_ix": "19-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_18",
            "tgt_ix": "19-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_19",
            "tgt_ix": "19-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_19",
            "tgt_ix": "19-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_19",
            "tgt_ix": "19-ARR_v2_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_19",
            "tgt_ix": "19-ARR_v2_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_20",
            "tgt_ix": "19-ARR_v2_20@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_21",
            "tgt_ix": "19-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_22",
            "tgt_ix": "19-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_22",
            "tgt_ix": "19-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_22",
            "tgt_ix": "19-ARR_v2_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_22",
            "tgt_ix": "19-ARR_v2_22@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_23",
            "tgt_ix": "19-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_24",
            "tgt_ix": "19-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_24",
            "tgt_ix": "19-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_25",
            "tgt_ix": "19-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_26",
            "tgt_ix": "19-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_26",
            "tgt_ix": "19-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_26",
            "tgt_ix": "19-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_26",
            "tgt_ix": "19-ARR_v2_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_27",
            "tgt_ix": "19-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_27",
            "tgt_ix": "19-ARR_v2_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_27",
            "tgt_ix": "19-ARR_v2_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_27",
            "tgt_ix": "19-ARR_v2_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_28",
            "tgt_ix": "19-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_28",
            "tgt_ix": "19-ARR_v2_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_28",
            "tgt_ix": "19-ARR_v2_28@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_28",
            "tgt_ix": "19-ARR_v2_28@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_29",
            "tgt_ix": "19-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_30",
            "tgt_ix": "19-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_30",
            "tgt_ix": "19-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_30",
            "tgt_ix": "19-ARR_v2_30@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_30",
            "tgt_ix": "19-ARR_v2_30@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_30",
            "tgt_ix": "19-ARR_v2_30@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_31",
            "tgt_ix": "19-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_32",
            "tgt_ix": "19-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_32",
            "tgt_ix": "19-ARR_v2_32@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_32",
            "tgt_ix": "19-ARR_v2_32@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_32",
            "tgt_ix": "19-ARR_v2_32@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_32",
            "tgt_ix": "19-ARR_v2_32@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_33",
            "tgt_ix": "19-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_34",
            "tgt_ix": "19-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_35",
            "tgt_ix": "19-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_36",
            "tgt_ix": "19-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_36",
            "tgt_ix": "19-ARR_v2_36@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_37",
            "tgt_ix": "19-ARR_v2_37@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_38",
            "tgt_ix": "19-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_38",
            "tgt_ix": "19-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_39",
            "tgt_ix": "19-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_40",
            "tgt_ix": "19-ARR_v2_40@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_41",
            "tgt_ix": "19-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_41",
            "tgt_ix": "19-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_41",
            "tgt_ix": "19-ARR_v2_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_41",
            "tgt_ix": "19-ARR_v2_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_42",
            "tgt_ix": "19-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_43",
            "tgt_ix": "19-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_43",
            "tgt_ix": "19-ARR_v2_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_43",
            "tgt_ix": "19-ARR_v2_43@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_44",
            "tgt_ix": "19-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_45",
            "tgt_ix": "19-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_45",
            "tgt_ix": "19-ARR_v2_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_45",
            "tgt_ix": "19-ARR_v2_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_45",
            "tgt_ix": "19-ARR_v2_45@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_45",
            "tgt_ix": "19-ARR_v2_45@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_46",
            "tgt_ix": "19-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_46",
            "tgt_ix": "19-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_46",
            "tgt_ix": "19-ARR_v2_46@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_46",
            "tgt_ix": "19-ARR_v2_46@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_47",
            "tgt_ix": "19-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_47",
            "tgt_ix": "19-ARR_v2_47@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_47",
            "tgt_ix": "19-ARR_v2_47@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_47",
            "tgt_ix": "19-ARR_v2_47@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_48",
            "tgt_ix": "19-ARR_v2_48@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_49",
            "tgt_ix": "19-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_49",
            "tgt_ix": "19-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_49",
            "tgt_ix": "19-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_49",
            "tgt_ix": "19-ARR_v2_49@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_49",
            "tgt_ix": "19-ARR_v2_49@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_50",
            "tgt_ix": "19-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_51",
            "tgt_ix": "19-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_51",
            "tgt_ix": "19-ARR_v2_51@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_51",
            "tgt_ix": "19-ARR_v2_51@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_51",
            "tgt_ix": "19-ARR_v2_51@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_51",
            "tgt_ix": "19-ARR_v2_51@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_51",
            "tgt_ix": "19-ARR_v2_51@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_52",
            "tgt_ix": "19-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_52",
            "tgt_ix": "19-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_53",
            "tgt_ix": "19-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_54",
            "tgt_ix": "19-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_54",
            "tgt_ix": "19-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_54",
            "tgt_ix": "19-ARR_v2_54@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_54",
            "tgt_ix": "19-ARR_v2_54@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_54",
            "tgt_ix": "19-ARR_v2_54@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_54",
            "tgt_ix": "19-ARR_v2_54@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@15",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@16",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@17",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@18",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@19",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@20",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@21",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@22",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@23",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@24",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_55",
            "tgt_ix": "19-ARR_v2_55@25",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_56",
            "tgt_ix": "19-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_57",
            "tgt_ix": "19-ARR_v2_57@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_58",
            "tgt_ix": "19-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_59",
            "tgt_ix": "19-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_59",
            "tgt_ix": "19-ARR_v2_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_59",
            "tgt_ix": "19-ARR_v2_59@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_59",
            "tgt_ix": "19-ARR_v2_59@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_59",
            "tgt_ix": "19-ARR_v2_59@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_60",
            "tgt_ix": "19-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_60",
            "tgt_ix": "19-ARR_v2_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_61",
            "tgt_ix": "19-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_61",
            "tgt_ix": "19-ARR_v2_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@13",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_62",
            "tgt_ix": "19-ARR_v2_62@14",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_63",
            "tgt_ix": "19-ARR_v2_63@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_64",
            "tgt_ix": "19-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_65",
            "tgt_ix": "19-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_65",
            "tgt_ix": "19-ARR_v2_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_66",
            "tgt_ix": "19-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_66",
            "tgt_ix": "19-ARR_v2_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_66",
            "tgt_ix": "19-ARR_v2_66@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_67",
            "tgt_ix": "19-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_67",
            "tgt_ix": "19-ARR_v2_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_67",
            "tgt_ix": "19-ARR_v2_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_67",
            "tgt_ix": "19-ARR_v2_67@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_68",
            "tgt_ix": "19-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_68",
            "tgt_ix": "19-ARR_v2_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_68",
            "tgt_ix": "19-ARR_v2_68@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_69",
            "tgt_ix": "19-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_70",
            "tgt_ix": "19-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_71",
            "tgt_ix": "19-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_72",
            "tgt_ix": "19-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_73",
            "tgt_ix": "19-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_74",
            "tgt_ix": "19-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_75",
            "tgt_ix": "19-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_76",
            "tgt_ix": "19-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_77",
            "tgt_ix": "19-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_78",
            "tgt_ix": "19-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_79",
            "tgt_ix": "19-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_80",
            "tgt_ix": "19-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_81",
            "tgt_ix": "19-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_82",
            "tgt_ix": "19-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_83",
            "tgt_ix": "19-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_84",
            "tgt_ix": "19-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_85",
            "tgt_ix": "19-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_86",
            "tgt_ix": "19-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_87",
            "tgt_ix": "19-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_88",
            "tgt_ix": "19-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_89",
            "tgt_ix": "19-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_90",
            "tgt_ix": "19-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_91",
            "tgt_ix": "19-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_92",
            "tgt_ix": "19-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_93",
            "tgt_ix": "19-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_94",
            "tgt_ix": "19-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_95",
            "tgt_ix": "19-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_96",
            "tgt_ix": "19-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_97",
            "tgt_ix": "19-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_98",
            "tgt_ix": "19-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_99",
            "tgt_ix": "19-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_100",
            "tgt_ix": "19-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_101",
            "tgt_ix": "19-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_102",
            "tgt_ix": "19-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_103",
            "tgt_ix": "19-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_104",
            "tgt_ix": "19-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_105",
            "tgt_ix": "19-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_106",
            "tgt_ix": "19-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_107",
            "tgt_ix": "19-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_108",
            "tgt_ix": "19-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_109",
            "tgt_ix": "19-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_110",
            "tgt_ix": "19-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_111",
            "tgt_ix": "19-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_112",
            "tgt_ix": "19-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_113",
            "tgt_ix": "19-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_114",
            "tgt_ix": "19-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_115",
            "tgt_ix": "19-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_116",
            "tgt_ix": "19-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_117",
            "tgt_ix": "19-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_118",
            "tgt_ix": "19-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_119",
            "tgt_ix": "19-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_120",
            "tgt_ix": "19-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_121",
            "tgt_ix": "19-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_122",
            "tgt_ix": "19-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_123",
            "tgt_ix": "19-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_124",
            "tgt_ix": "19-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_125",
            "tgt_ix": "19-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_126",
            "tgt_ix": "19-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_127",
            "tgt_ix": "19-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_128",
            "tgt_ix": "19-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_129",
            "tgt_ix": "19-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_130",
            "tgt_ix": "19-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_131",
            "tgt_ix": "19-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_132",
            "tgt_ix": "19-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_133",
            "tgt_ix": "19-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_134",
            "tgt_ix": "19-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_135",
            "tgt_ix": "19-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_136",
            "tgt_ix": "19-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_137",
            "tgt_ix": "19-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_138",
            "tgt_ix": "19-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_139",
            "tgt_ix": "19-ARR_v2_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_140",
            "tgt_ix": "19-ARR_v2_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_141",
            "tgt_ix": "19-ARR_v2_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_142",
            "tgt_ix": "19-ARR_v2_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_143",
            "tgt_ix": "19-ARR_v2_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_144",
            "tgt_ix": "19-ARR_v2_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_145",
            "tgt_ix": "19-ARR_v2_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_146",
            "tgt_ix": "19-ARR_v2_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_147",
            "tgt_ix": "19-ARR_v2_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_148",
            "tgt_ix": "19-ARR_v2_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_149",
            "tgt_ix": "19-ARR_v2_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_150",
            "tgt_ix": "19-ARR_v2_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_151",
            "tgt_ix": "19-ARR_v2_151@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_152",
            "tgt_ix": "19-ARR_v2_152@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_153",
            "tgt_ix": "19-ARR_v2_153@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_154",
            "tgt_ix": "19-ARR_v2_154@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_155",
            "tgt_ix": "19-ARR_v2_155@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_156",
            "tgt_ix": "19-ARR_v2_156@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_157",
            "tgt_ix": "19-ARR_v2_157@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_158",
            "tgt_ix": "19-ARR_v2_158@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_159",
            "tgt_ix": "19-ARR_v2_159@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_160",
            "tgt_ix": "19-ARR_v2_160@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_161",
            "tgt_ix": "19-ARR_v2_161@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_162",
            "tgt_ix": "19-ARR_v2_162@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_163",
            "tgt_ix": "19-ARR_v2_163@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_164",
            "tgt_ix": "19-ARR_v2_164@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_165",
            "tgt_ix": "19-ARR_v2_165@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_166",
            "tgt_ix": "19-ARR_v2_166@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_167",
            "tgt_ix": "19-ARR_v2_167@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_168",
            "tgt_ix": "19-ARR_v2_168@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "19-ARR_v2_169",
            "tgt_ix": "19-ARR_v2_169@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1091,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "19-ARR",
        "version": 2
    }
}