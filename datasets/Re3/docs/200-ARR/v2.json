{
    "nodes": [
        {
            "ix": "200-ARR_v2_0",
            "content": "Reducing Disambiguation Biases in NMT by Leveraging Explicit Word Sense Information",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_2",
            "content": "Recent studies have shed some light on a common pitfall of Neural Machine Translation (NMT) models, stemming from their struggle to disambiguate polysemous words without lapsing into their most frequently occurring senses in the training corpus. In this paper, we first provide a novel approach for automatically creating high-precision sense-annotated parallel corpora, and then put forward a specifically tailored fine-tuning strategy for exploiting these sense annotations during training without introducing any additional requirement at inference time. The use of explicit senses proved to be beneficial to reduce the disambiguation bias of a baseline NMT model, while, at the same time, leading our system to attain higher BLEU scores than its vanilla counterpart in 3 language pairs.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "200-ARR_v2_4",
            "content": "Translating a sentence requires the underlying meaning to be captured and then expressed in the target language. Nonetheless, only little attention has been devoted to studying the actual capabilities of Neural Machine Translation (NMT) approaches of modeling different senses of ambiguous words, with recent work showing that systems tend to be biased towards the most frequent meanings found within the training corpus (Emelin et al., 2020). This phenomenon is hard to measure through classical evaluation metrics, such as the BLEU score (Papineni et al., 2002), as they often rely on word-matching heuristics that fail to capture the disambiguation capabilities of the evaluated systems. Therefore, several efforts have been recently devoted to shed some light and create test beds (Rios Gonzales et al., 2017;Raganato et al., 2019;Emelin et al., 2020;Campolungo et al., 2022) to challenge NMT models. Results show that these models still struggle to deal with highly polysemous words, especially when used to express least frequent senses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_5",
            "content": "For example, given the sentence \"The energy comes from a distant plant.\", both Google Translate and DeepL disambiguate 1 plant to its sense of organism when translating into Italian, and produce the following incorrect sentence \"L'energia proviene da una pianta lontana.\", rather than \"L'energia proviene da un impianto lontano.\", where impianto is the translation for the factory meaning of plant. This suggests that, even when adequate context is provided (energy should be enough to correctly infer the right sense of plant), state-of-the-art models might still be biased towards the most frequent meanings found within training data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_6",
            "content": "Some recent studies have explored how to leverage explicit sense information within NMT models (Rios Gonzales et al., 2017;Pu et al., 2018a;Nguyen et al., 2018). Nevertheless, including such information is not trivial for three main reasons: i) sense-tagged parallel data is scarce; ii) Word Sense Disambiguation (WSD) systems have not been accurate enough until very recently (Blevins and Zettlemoyer, 2020;; and iii) how explicit senses should be incorporated within neural models is not straightforward.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_7",
            "content": "In this paper, we first introduce a novel approach to make up for the paucity of sense annotations in parallel corpora, leveraging a multilingual WSD system to tag parallel sentences and refine its predictions by means of cross-lingual word alignments and information from a multilingual knowledge base. Then, we fine-tune our baseline models on our sense-tagged corpora via a specifically designed loss function, allowing the injection of wordlevel semantics into the architecture. We evaluate our approach on standard and challenge test sets, showing that it does indeed improve translation accuracy and mitigates the most frequent sense bias.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_8",
            "content": "To summarize, our contributions are manifold:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_9",
            "content": "1. We put forward a novel approach to produce high-precision sense annotations for parallel data, which we apply to three language pairs. 2. We propose a fine-tuning strategy that lets us inject word-level explicit semantics into Neural Machine Translation models, without introducing any additional requirement at inference time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_10",
            "content": "3. We show that employing explicit sense tags is beneficial in order both to mitigate the sense bias and to improve the translation quality in terms of BLEU score on standard benchmarks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_11",
            "content": "4. We present a case study on how a state-of-theart WSD system compares to an NMT model on disambiguating words within a challenging set for detecting sense bias in MT.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_12",
            "content": "We make all the generated datasets, the code of the model and for the experiments available at https://github.com/sapienzanlp/ reducing-wsd-bias-in-nmt.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_13",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "200-ARR_v2_14",
            "content": "Word Sense Disambiguation was first formulated as a computational task by Weaver (1949) in the context of Machine Translation. The two fields then followed parallel paths, with more or less successful attempts over the years to join them back together (Carpuat and Wu, 2005;Vickrey et al., 2005;Carpuat and Wu, 2007). Indeed, while Carpuat and Wu (2005) reported negative results when trying to integrate the prediction of a supervised WSD approach into a Statistical Machine Translation (SMT) model, the same authors, two years later, successfully improved the performance of a phrase-based SMT approach by leveraging a new phrase-based WSD model (Carpuat and Wu, 2007). More recently, Pu et al. (2018a) and Nguyen et al. (2018) proposed systems that successfully leverage sense information in NMT models, although they introduced a heavy requirement, i.e., that of disambiguating the ambiguous words in the sentence prior to generating a translation, which makes them unfeasible in many real-world settings. Lately, contextualized word embeddings have been employed to produce additional back-translated parallel training data via mining sense-specific target sentences, in order to improve handling of infrequent senses (Hangya et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_15",
            "content": "Nevertheless, the proper treatment of lexical ambiguity is still an open problem, with neural models struggling to translate least frequent senses and often relying on spurious correlations among words (Emelin et al., 2020;Raganato et al., 2019;Rios Gonzales et al., 2017). Thus, the disambiguation bias topic has received renewed interest, and several benchmarks have been introduced in the most recent years with the goal of directly measuring the extent to which neural architectures are able to capture word semantics. One of the first of this kind was ContraWSD (Rios Gonzales et al., 2017). In this first attempt to evaluate WSD capabilities of NMT models, the authors built an adversarial test set where source sentences containing an ambiguous word were associated with a correct translation and several incorrect alternatives. These latter were built by replacing the reference translation for the ambiguous word with the translation of one of its other possible meanings. The task measured whether a model ranked the correct translation higher, i.e., it assigned it a higher probability than the adversarial ones. This study provided evaluation data for two language pairs only, i.e., German\u2192English and German\u2192French, and within a few years it became outdated as modern NMT models could easily attain high performances (Emelin et al., 2019). Thus, MuCoW (Raganato et al., 2019) took things a step further and leveraged BabelNet (Navigli and Ponzetto, 2012;) -a large multilingual knowledge base -and sense embeddings (Camacho-Collados et al., 2016;Mancini et al., 2017) in order to automatically create adversarial translations for five language pairs while also increasing the difficulty of the task itself; however, the fully automatic nature of these challenge sets made them noisy and prone to containing irrelevant challenge samples.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_16",
            "content": "More recently, Emelin et al. (2020) proposed two challenge sets for the English\u2192German pair, one measuring the model sensitivity to most frequent senses and the other estimating, through adversarial injections, its susceptibility to changing a correct sense to a wrong one. In contrast to previous studies, these challenge sets were based on correlations among words in the training set and relied on manually-refined sense clusters, providing an excellent test bed for measuring semantic bias.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_17",
            "content": "Finally, Campolungo et al. (2022) proposed DIBIMT, the first fully manually annotated test set for measuring the disambiguation bias of neural machine translation models, covering five language combinations, namely, from English to German, Spanish, Italian, Russian and Chinese. In their work, the authors showed that open neural models still exhibit strong semantic biases towards frequent senses, confirming once again the suspicions about this under-explored issue.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_18",
            "content": "Despite all the effort made in putting forward challenging sets of data to test WSD capabilities of NMT models, to the best of our knowledge, only a few approaches (Rios Gonzales et al., 2017;Liu et al., 2018) have been proposed to mitigate this issue, and none of these is effective with modern Transformer-based architectures. Furthermore, while parallel corpora have been exploited to produce sense annotations in the past (Bonansinga and Bond, 2016;Delli Bovi et al., 2017), they were built by utilizing outdated disambiguation approaches that have recently been surpassed by more advanced neural architectures. Indeed, the Word Sense Disambiguation field has received much attention in the last few years, with several supervised approaches Blevins and Zettlemoyer, 2020; and sense embedding models (Loureiro and Jorge, 2019;Scarlini et al., 2020a,b;Wang et al., 2020) performing close to the upper bound limit of the inter-annotator agreement, which finally makes them feasible for inclusion in other downstream tasks, e.g., Machine Translation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_19",
            "content": "Thus, differently from previous studies in the literature, we focus on closing the gap between these two fields, i.e., Neural Machine Translation and Word Sense Disambiguation, by putting the recent advances in WSD at the service of NMT models. We propose a novel approach, similar to that introduced in Luan et al. (2020), for creating high-quality sense-annotated parallel corpora, and we use this semantic information to regularize an NMT model, making it less biased and capable of producing higher-quality translations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_20",
            "content": "Reducing the Disambiguation Bias in NMT",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "200-ARR_v2_21",
            "content": "Neural Machine Translation models are typically trained end-to-end to produce a target translation given a source sentence and, thus, they can only rely on the input context to resolve the ambiguity of polysemous words therein. Being pattern recognition algorithms at heart, these models fall prey to the inherent bias carried by the frequency of co-occurrence of words within parallel sentences, and thus tend to disambiguate words to the sense they most frequently encountered during training, even when the sentence does provide enough context to identify the correct sense. At the same time, Word Sense Disambiguation models, i.e., models specialized in associating a word in context with one of the meanings within a given sense inventory, have recently displayed remarkable results across different benchmarks and languages . The time may now therefore be ripe for them to be successfully included into downstream applications such as Neural Machine Translation. However, data that would allow these two worlds to be brought together, i.e., parallel corpora where words are associated with semantic labels, are currently still produced automatically by leveraging outdated approaches to WSD (Delli Bovi et al., 2017).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_22",
            "content": "In what follows, we first provide some preliminary information about resources and tools that we employ in our method ( \u00a7 3.1); then, we introduce a new approach for automatically annotating tokens within parallel sentences with sense annotations, i.e., labels explicitly defining their meanings ( \u00a7 3.2); finally, we propose a fine-tuning objective for leveraging such annotations in order to mitigate the sense bias while also improving the translation quality overall ( \u00a7 3.3). The intuition behind our work is that fixed sense labels describing word senses would help NMT models better encode the underlying meaning of the input sentence, thus generating less biased and overall better translations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_23",
            "content": "Preliminaries",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "200-ARR_v2_24",
            "content": "We draw sense labels from BabelNet (Navigli and Ponzetto, 2012), a multilingual knowledge base created by merging several semantic resources in different languages such as WordNet (Miller et al., 1990), Wikipedia, Wikidata, etc. BabelNet is structured in synsets, i.e., sets of synonymous senses in different languages. For instance, the synset of plant organism contains the following lexicalizations: plant EN , pianta IT , Pflanze DE , among others. Additionally, BabelNet provides lemma-tosynsets mappings. For example, the English noun plant belongs to the following nominal synsets: organism, industrial plant, actor in the audience and something placed secretly. 2 Since BabelNet contains millions of synsets, which may make the computation too expensive, we restrict the vocabulary to just those containing at least one English sense from WordNet, as is also done in several other works (Barba et al., 2020;Scarlini et al., 2020b;Bevilacqua and Navigli, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_25",
            "content": "Building a Sense-Annotated Parallel Corpus",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "200-ARR_v2_26",
            "content": "Let us assume that our running example sentence \"The energy comes from a distant plant.\" appears within a parallel corpus paired with the following Italian translation: \"L'energia viene da un impianto lontano.\". As we said, by considering the English sentence alone, the word plant could take several meanings, among which organism and power plant. However, among these, only one is shared with its translation impianto, i.e., the power plant meaning. Therefore, considering the cross-lingual alignment of words may drastically reduce the set of valid meanings, making the disambiguation task much easier. Based on this intuition, given a parallel corpus, we perform the following two steps:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_27",
            "content": "1. Sense Scoring, where we employ a WSD system to assign to each content word a distribution over its possible meanings;",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_28",
            "content": "2. Annotation Refinement, where we compute cross-lingual word alignments to reduce lexical ambiguity and finally assign the most suitable sense to each content word.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_29",
            "content": "Sense Scoring In this step, our goal is to assign to every content word within a sentence a distribution over its possible senses in BabelNet. To this end, given as input a sentence s 3 from a parallel corpus C, we first apply Part-of-Speech tagging and lemmatization to it, then pass it through our WSD system, which returns a distribution over its possible meanings. Formally, let w i be a content word in a sentence s = [w 1 , . . . , w n ], and \u03c3(w i ) the set of synsets associated with w i in BabelNet. The WSD system assigns a score c(S|w i , s) to each synset S \u2208 \u03c3(w i ); we denote the synset of w i with the highest confidence as S * w i . As a result, each content word in a source or target sentence is associated with a sense distribution. However, applying a WSD system alone may not be sufficient to ensure high-quality 3 s can be either a source or a target sentence.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_30",
            "content": "annotations, as the application domain may be different from the one of its training set. Therefore, in the next step we take advantage of the translation each sentence is paired with to refine sense annotations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_31",
            "content": "We produce word-level cross-lingual alignments between the source and the target sentences of the parallel corpus: given a pair of parallel sentences (s, t), we compute a list of alignments A = {(w s i , w t j )|w s i \u2208 s, w t j \u2208 t}. Thus, given an aligned word pair P = (w s i , w t j ) \u2208 A, let \u03c3(P ) = \u03c3(w s i ) \u2229 \u03c3(w t j ), i.e., the intersection of synsets that the two words may denote according to BabelNet: we discard annotations for any word pair such that \u03c3(P",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_32",
            "content": ") = \u2205 \u2228 |\u03c3(w s i )| < 2.",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_33",
            "content": "In other words, we retain all the aligned pairs (w s i , w t j ) such that the source word is polysemous and the intersection of their senses is non-empty, thus ensuring higher annotation precision by leveraging the parallelism of words.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_34",
            "content": "Finally, we assign the same synset S * to both words (w s i , w t j ) in P as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_35",
            "content": "S * = S * w s i = S * w t j = argmax S\u2208\u03c3(P ) c(S|w s i , s) Z s + c(S|w t j , t) Z t Z s = S\u2208\u03c3(P ) c(S|w s i , s) Z t = S\u2208\u03c3(P ) c(S|w t j , t)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_36",
            "content": "that is, the synset with the highest combined confidence score after normalizing over \u03c3(P ), where Z s and Z t represent the normalization factors of the probability distributions associated with the synsets of w s i and w t j , respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_37",
            "content": "Semantic Injection",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "200-ARR_v2_38",
            "content": "Now that we can generate high-quality sense annotations, we describe our fine-tuning method to inject word-level semantics into a Neural Machine Translation model. Ideally, we want the model to benefit from such annotations during training, while not being dependent on them at inference time. To satisfy both these desiderata, we adapt the model's vocabulary to handle synsets as well as subwords, and propose a specific loss that exploits the injected senses to improve the base model's handling of ambiguous words.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_39",
            "content": "Pre-trained NMT Model",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_40",
            "content": "The energy comes from a distant plant .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_41",
            "content": "The energy comes from a distant plant. Semantically Enhancing Sentences In order to work with concepts, we need a way to represent them. Let us consider once more the sentence \"The energy comes from a distant plant.\": we rewrite it in order to also include the exact meaning for plant, which we computed as described in \u00a7 3.2: \"The energy comes from a distant plant plant factory \". Formally, given a source sentence s and a word w i annotated with sense S * w i , we simply represent w i as its standard segmentation followed by S * w i , represented by its sense embedding 4 passed through a linear projection layer (as shown in Figure 2). Additionally, to enforce the connection between the tagged word and its sense annotation, we set the position ids for the word and the sense embedding to the same value, as if they were a single token. This encoding scheme gracefully extends to the whole sentence, yielding the sense-enhanced input representation for a given sentence s.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_42",
            "content": "We hereby propose the Semantic Consistency Regularization (SCR) objective, inspired by MVR (Wang et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_43",
            "content": "Formally, let x \u2032 and x \u2032\u2032 be two encodings (plain and sense-enhanced) of the same input sentence x and let y be the target sentence, we define SCR as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_44",
            "content": "SCR(\u03b8) = \u2212 log P \u03b8 (y|x \u2032 ) \u2212 log P \u03b8 (y|x \u2032\u2032 ) + D KL (P \u03b8 (y|x \u2032 ) || P \u03b8 (y|x \u2032\u2032 ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_45",
            "content": "where \u03b8 is the set of trainable weights, D KL is the unidirectional Kullback-Leibler divergence (Kullback and Leibler, 1951) and P \u03b8 (y|x) represents an output distribution (a visual representation of SCR is reported in Figure 1).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_46",
            "content": "With this formulation, SCR jointly uses the same sentence with and without sense annotations as two separate inputs: while we train the model to be able to translate both plain and sense-enhanced sentences, by minimizing the divergence between the output distributions we also force the model to transfer the sense information from the senseenhanced input to the plain input, much like in a self-distillation process. At the same time, we still maintain the model's capability of translating without sense annotations, thus dropping their requirement at inference time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_47",
            "content": "Experimental Setup",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "200-ARR_v2_48",
            "content": "Our Model",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "200-ARR_v2_49",
            "content": "We employ as underlying model the standard Transformer architecture (Vaswani et al., 2017), with 6 encoder and 6 decoder layers. 5 Note that, while SCR can be applied to any pre-trained model, we retrain one from scratch because most of the other models available online use part of our test data as their training data (see \u00a7 4.2). Additional details about training configuration and hyperparameters are provided in \u00a7 A.3.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_50",
            "content": "Fine-tuning with SCR Additionally, to jumpstart the model's capabilities, we encode synsets not as randomly initialized learnable vectors (e.g., by extending the vocabulary), but with frozen pre-trained sense embeddings projected into the model's input space by means of a linear layer, the only additional learnable component of the model (Projection in Figure 2), which is dropped after the fine-tuning stage. As pre-trained sense embeddings we use ARES (Scarlini et al., 2020b), since they provide multilingual representations for each synset in our vocabulary. We study the impact of this choice in \u00a7 5.5. To perform token-level alignments, we use MultiMirror (Procopio et al., 2021). 6",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_51",
            "content": "Datasets",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "200-ARR_v2_52",
            "content": "We experiment on three distinct language pairs: EN\u2192DE, EN\u2192ES and EN\u2192FR. Following (Emelin et al., 2020), we gather the data from WMT14 for German and French and WMT13 for Spanish, considering only sentences coming from either CommonCrawl, News Commentary or Europarl, to maintain similar order of magnitudes among language pairs (and to contain pre-processing and training times). As validation sets, we employ newstest2014 for EN\u2192DE, newstest2013 for EN\u2192FR and newstest2012 for EN\u2192ES. All datasets employed in this work are freely available for research purposes.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_53",
            "content": "We process each parallel sentence of the considered corpora with the procedure described in \u00a7 3.2, taking into account only content words whose Partof-Speech tag is noun, as the challenge sets we evaluate upon only target nominal words. 7 For POS-tagging and lemmatization we use Stanza (Qi et al., 2020). As disambiguation system, we use EWISER (Bevilacqua and Navigli, 2020), a neural WSD model based on BERT (Devlin et al., 2019), which has attained state-of-the-art performances on English as well as other languages. EWISER has been trained on SemCor (Miller et al., 1993) -the standard training set for WSD -and the WordNet Gloss corpus (Langone et al., 2004) -a semi-automatically annotated dataset featuring sense definitions. Detailed statistics of the base and parallel corpora produced are provided in \u00a7 A.5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_54",
            "content": "We evaluate standard translation quality through the newstest datasets available in the specific WMT year (i.e., WMTXX corresponds to new-stest20XX). The standard evaluation is carried out by means of SacreBLEU (Post, 2018), with signature BLEU+case.mixed+numrefs.1 +smooth.exp+tok.13a+version.1.5.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_55",
            "content": "To measure the disambiguation bias of each model we employ the challenge sets introduced by Emelin et al. ( 2020), composed of sentences reserved from the WMT14 English\u2192German corpus. These challenge sets are based on sense clusters built by automatically merging together BabelNet synsets, which then are manually refined to ensure their correctness. Each sense cluster contains an English polysemous word and a set of German monosemous terms, which uniquely identify a certain meaning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_56",
            "content": "These clusters are used to create the following two challenge sets: WSD Bias and Adversarial. The former quantifies the intrinsic bias the model learned during training, while the latter measures how sensitive the model is to the insertion of terms that are usually associated with another sense cluster during training. Both challenge sets evaluate in terms of accuracy of correct disambiguation. A more detailed description of these datasets and their evaluation process is provided in \u00a7 A.1.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_57",
            "content": "DIBIMT We also evaluate on the German and Spanish portions of DIBIMT (Campolungo et al., 2022), a recent fully-manually annotated disambiguation bias challenge set, where models are asked to translate English sentences containing ambiguous words, and their translations are checked for either correct or incorrect translation equivalents, which, in contrast to previous benchmarks, are annotated manually and depend on the context of the sentence instead of relying solely on the sense of the source word.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_58",
            "content": "Comparison Systems",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "200-ARR_v2_59",
            "content": "We compare our sense-enhanced model with the following architectures: In what follows we refer to our model fine-tuned with SCR as Baseline+SCR.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_60",
            "content": "We note that, due to the way in which the WSD Bias Challenge Sets were constructed (i.e., by using sentences reserved from WMT14, see \u00a7 4.2), any fair evaluation against OPUS and MBart-50 is to be considered impossible, as such models have seen the sentences in the challenge sets during training. We therefore evaluate these two models only on standard BLEU, and point out that the resulting scores should only be regarded as references for our models' competence in the translation task.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_61",
            "content": "Results",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "200-ARR_v2_62",
            "content": "In what follows, first, we show that our model attains BLEU scores in the same ballpark as state-ofthe-art approaches such as OPUS and MBart-50, despite the large gap in terms of parameters or training data. Then, we focus our evaluation on the WSD Bias, and compare our full-fledged model (Baseline+SCR) against its baseline variant.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_63",
            "content": "General Translation Quality",
            "ntype": "title",
            "meta": {
                "section": "5.1"
            }
        },
        {
            "ix": "200-ARR_v2_64",
            "content": "In Table 1 we observe that the trained baselines are more than competent in the translation task: indeed, when considering average BLEU scores, they place between OPUS, which is trained on much more data but has the same parameter count, and MBart-50 (Tang et al., 2021), which is ~8 times larger but is capable of translating English to 50 languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_65",
            "content": "In contrast to common debiasing techniques, which often observe a degradation in performance on standard benchmarks (Clark et al., 2019;He et al., 2019), we report consistent BLEU improvements on all language pairs, all of which are statistically significant at different p-values (Table 1), providing empirical proof that the proposed method does not hurt the model's general translation capability, while at the same time it helps models generate less biased translations (as will be discussed in the upcoming sections).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_66",
            "content": "Disambiguation Bias",
            "ntype": "title",
            "meta": {
                "section": "5.2"
            }
        },
        {
            "ix": "200-ARR_v2_67",
            "content": "Results on the Disambiguation Bias Challenge Sets ( \u00a7 4.2) are reported in Table 2, for both of which we show improvements: on the WSD Bias Challenge Set, the bias is reduced, significantly, by more than 1%; similarly, on the Adversarial Challenge Set, we see a reduction of homographs mistakenly disambiguated due to the injection of adversarial adjectives of 0.27%. We attribute this lower impact to the artificial nature of the adversarial sentences, some of which, by manual inspection, display poor grammatical fluency.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_68",
            "content": "WSD Performance",
            "ntype": "title",
            "meta": {
                "section": "5.3"
            }
        },
        {
            "ix": "200-ARR_v2_69",
            "content": "We conduct an analysis of the performance of EWISER on the English sentences of the WSD Bias Challenge Set, to see how it fares in comparison with our NMT models. Unfortunately, as the sense clusters are not directly associated with BabelNet synsets, we reconstruct this association automatically and manage to retrieve only 1847 of the 3000 sentences in the challenge set.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_70",
            "content": "Having retrieved BabelNet synsets for the target terms, we can apply EWISER and check whether the disambiguated synset matches one of the synsets retrieved for the sense cluster of the challenge sentence. Let us consider our running example, \"The energy comes from a distant plant.\", one last time: if EWISER disambiguates the term plant to its sense of organism, we count it as a mistake, similarly to the case where our NMT model translates it as pianta instead of impianto (i.e., its sense of factory). With this in mind, we evaluate EWISER, Baseline and Baseline+SCR on the aforementioned subset of sentences; we report the results of this evaluation in Table 2 (bottom).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_71",
            "content": "The results indicate that, for this setting, both NMT models actually perform quite a lot better than a pre-trained disambiguation system. One reason for this might be the different distributions the models are trained on: by design, the challenge sentences follow a distribution similar to the corpus used to train the NMT model, whereas EWISER is trained on sentences coming from news corpora from the 1960s and dictionary-like definitions. Moreover, in theory, if we were to apply the refinement process described in \u00a7 3.2 to disambiguate the challenge sentences, we would achieve a perfect score, as the target German lemmas are monosemous and thus the disambiguation is implicitly solved. The results of using EWISER's raw annotations are discussed in \u00a7 5.5. Finally, we choose not to perform a similar comparison on the Adversarial Challenge Set, as its examples are designed to specifically target NMT models via adversarial injections; we leave studying their impact in WSD systems as future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_72",
            "content": "System Examples",
            "ntype": "title",
            "meta": {
                "section": "5.4"
            }
        },
        {
            "ix": "200-ARR_v2_73",
            "content": "In Table 3, we report some examples of disambiguation corrected by our model according to the WSD Bias Challenge Set. The baseline is translating the terms to their most frequent sense (column Wrong sense), instead of the correct one (column Target sense). Moreover, the third example shows that this is not only a word matching task, as the improved model is able choose the correct subword and can capture the nuances of meaning in more uncommon senses.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_74",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "5.5"
            }
        },
        {
            "ix": "200-ARR_v2_75",
            "content": "Ablation on SCR To measure the importance of the KL term in the loss, we fine-tune the model without including it in the SCR objective ( \u00a7 3.3) and report the results in Tables 1 and 2 (row Baseline+SCR \u2212KL ). We observe that, without KL, the model struggles to leverage the double inputs efficiently; indeed, its translation performance drops around 1 BLEU point on average, while the error rates increase by roughly 1% on both bias challenge sets. These results back our intuition that the KL divergence helps to distill sense information from the sense-enhanced inputs, and is indeed a crucial component to our formulation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_76",
            "content": "Ablation on ARES We also test our system replacing the pre-trained sense embeddings provided by ARES with randomly initialized learnable embeddings and report this result in Tables 1 and 2 (row Baseline+SCR \u2212ARES ). As expected, both translation quality and disambiguation bias drop consistently. Indeed, learning sense embeddings from scratch is much harder than learning a mapping between a fixed space and a trainable one.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_77",
            "content": "We evaluate our sense Annotation Refinement process ( \u00a7 3.2) by fine-tuning the model on the unconstrained sense annotations provided by EWISER (Baseline+SCR \u2212AR ), i.e., by considering the synset with the highest confidence on the source word as the correct one, instead of S * . In the bias evaluation (Table 2), the performances on both challenge sets drop significantly (p < 0.001), which is in line with EWISER's performance on this challenge set ( \u00a7 5.3). Furthermore, the BLEU scores drop too, although not as significantly (Table 1), but still always under-performing with respect to Baseline+SCR.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_78",
            "content": "Ablation on Sense Annotations Finally, we test whether the sense annotations have an impact by replacing them with random senses for the specific word, drawn from the sense vocabulary with uniform probability, during the fine-tuning stage (Baseline+SCR RAND ). 9 As expected, we observe that randomly injecting senses is detrimental, with important performance drops in both the standard and the bias evaluation benchmarks.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_79",
            "content": "Evaluation on DIBIMT",
            "ntype": "title",
            "meta": {
                "section": "5.6"
            }
        },
        {
            "ix": "200-ARR_v2_80",
            "content": "In Table 4 we report the results obtained on DIBIMT (Campolungo et al., 2022). For the sake of conciseness, we only report accuracy scores as a proxy for the general disambiguation bias dis-9 Due to time constraints, we only perform this ablation on the English\u2192German model. played by our models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_81",
            "content": "While on English\u2192German we observe an improvement of 1%, the performance on English\u2192Spanish decreases by around 0.6%. We hypothesize that our English\u2192Spanish model might be undertrained, as its accuracy differs by around 10% from OPUS, its direct comparison, while on English\u2192German the difference is only of around 3%. We leave further investigation of this issue, including training larger, more capable models, as future work.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_82",
            "content": "Conclusions",
            "ntype": "title",
            "meta": {
                "section": "6"
            }
        },
        {
            "ix": "200-ARR_v2_83",
            "content": "In this paper, we presented a fine-tuning strategy that, by leveraging the explicit sense annotations produced by a novel high-precision technique, effectively reduces the disambiguation bias of a baseline Neural Machine Translation model while at the same time also strengthening translation performances, without introducing any requirement at inference time.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_84",
            "content": "Our analysis on a strong disambiguation system showed that its ability to disambiguate polysemous nouns is worse than that of a baseline NMT model, at least in the studied out-of-domain setting.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_85",
            "content": "We believe that this work paves the way for better bias reduction techniques in MT, while also fostering interest in the issue represented by the disambiguation bias. As future work, we plan to further study the ability of NMT models to perform Word Sense Disambiguation and to strengthen research at the intersection of these two fields, with a view to building stronger and more reliable models. sense, whereas its adversarial counterpart is flipped to the sense cluster the adjective points to. The goal of this task is to measure how sensitive the model is to the insertion of terms that are usually associated with another sense cluster during training.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_86",
            "content": "Our work is based on the assumption that providing a neural model with sense annotations for ambiguous words helps in disambiguating them. While this is rather intuitive, and has been shown to be the case in previous works (Nguyen et al., 2018;Pu et al., 2018b), we test this hypothesis in our setting by training an NMT model, from scratch, with sense-enhanced sentences only (see \u00a7 3.3 for details). We train a model comparable with the Baseline (i.e., same architecture and hyperparameters) on the English\u2192German training set ( \u00a7 4.2), and observe that it achieves higher BLEU scores than the Baseline (which is trained on the same data but with plain sentences). For instance, the senseenhanced model achieves a BLEU score of 27.22 on WMT14 and 36.79 on WMT19, with the first being a statistically significant improvement. This confirms, once again, that sense-enhanced NMT models are on par or better than plain NMT models, although they introduce the heavy requirement of WSD at inference time, which our work aims at dropping.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_87",
            "content": "Preprocessing Times The preprocessing of the datasets needed to apply Annotation Refinement (lemmatization, Part-of-Speech tagging and then disambiguation through EWISER) required around 4 days in total on an RTX 2080 Ti (roughly 3M sentences per day).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_88",
            "content": "Training infrastructure and duration All our experiments were carried out on either an NVIDIA RTX 2080 Ti or a RTX 3090, depending on availability.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_89",
            "content": "Model training required on average 4 days on a 3090, 7 days on a 2080 Ti. Fine-tuning epochs required around 10 hours each (on a 3090), with most finishing due to early stopping before the end of the second epoch.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_90",
            "content": "MarianMT models available on Hugging-Face Transformers (Wolf et al., 2020) (e.g., for EN\u2192DE, the model name is Helsinki-NLP/opus-mt-en-de).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_91",
            "content": "For For the fine-tuning stage we added ARES (frozen), thus adding a number of parameters equal to ARES's size (1536) times the number of unique synsets in the dataset (refer to Table 6 for approximate numbers). We also added a trainable projection layer of size 1536 * 512 (512 is the Transformer's hidden dimension), thus adding 786k trainable parameters (which we drop after the finetuning).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_92",
            "content": "Model training hyperparameters Similarly to (Emelin et al., 2020), we trained it on the entire dataset for a max of 100,000 steps with approximately 24k tokens per batch, label smoothing at 0.1 and an inverse square root learning rate scheduler with 4000 warmup steps. As optimizer, we used Adam (Kingma and Ba, 2015) with betas (0.99, 0.98) and learning rate 7 \u2022 10 \u22124 , additionally employing an early stopping strategy with patience 5, monitoring the BLEU score on a validation set. We produced translations at inference time using a beam size of 5.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_93",
            "content": "Fine-tuning hyperparameters For the finetuning, we resumed training using the weights of the baseline models, changed the learning to 1 \u2022 10 \u22125 and reduced the warmup to 1000 steps; additionally, we evaluated the model every 10% of the fine-tuning steps rather than after each epoch, as we observed fast convergence during fine-tuning and multiple epochs were superfluous.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_94",
            "content": "Table 5 reports the same results displayed in the paper, but includes the percentage of Correct translations for both challenge sets as well as the percentage of errors made from sentences that, after the injection of the adversarial adjectives, were translated into a sense that was neither the correct one, nor the one targeted by the adversarial injection (i.e., other).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_95",
            "content": "Our work focuses on reducing the disambiguation biases picked up by NMT models during training. We acknowledge some limitations in our work:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_96",
            "content": "1. Due to limited computational budget and the large number of resources required to train and fine-tune NMT models from scratch, we had to limit ourselves to one run per experiment, though, despite this, the consistency across languages seems to point to the empirical correctness of the claims.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_97",
            "content": "2. We evaluated the bias reduction explicitly only on the English\u2192German language pair. The reason for this was twofold: first, the datasets introduced by Emelin et al. (2020) only cover said pair, and require the accompanying training data be used in order to fully exploit the co-occurrences (and hence the biases) that the model is evaluated upon; second, upon manual inspection, we found that MuCoW (Raganato et al., 2019) contains many irrelevant candidates in its translation suite, and is in general very strongly affected by the noisy nature of BabelNet.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_98",
            "content": "3. Our pipeline is strictly tied to both the accuracy of the multilingual WSD system employed and by the coverage of the underlying sense inventory. While EWISER and Babel-Net work reasonably well for high-resource languages, the quality of the annotated corpus might decrease for low-resource ones.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "200-ARR_v2_99",
            "content": "Edoardo Barba, Tommaso Pasini, Roberto Navigli, ESC: Redesigning WSD with extractive sense comprehension, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Edoardo Barba",
                    "Tommaso Pasini",
                    "Roberto Navigli"
                ],
                "title": "ESC: Redesigning WSD with extractive sense comprehension",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_100",
            "content": "Edoardo Barba, Luigi Procopio, Niccol\u00f2 Campolungo, Tommaso Pasini, Roberto Navigli, Mu-LaN: Multilingual label propagatioN for word sense disambiguation, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Edoardo Barba",
                    "Luigi Procopio",
                    "Niccol\u00f2 Campolungo",
                    "Tommaso Pasini",
                    "Roberto Navigli"
                ],
                "title": "Mu-LaN: Multilingual label propagatioN for word sense disambiguation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_101",
            "content": "Michele Bevilacqua, Roberto Navigli, Breaking through the 80% glass ceiling: Raising the state of the art in word sense disambiguation by incorporating knowledge graph information, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Michele Bevilacqua",
                    "Roberto Navigli"
                ],
                "title": "Breaking through the 80% glass ceiling: Raising the state of the art in word sense disambiguation by incorporating knowledge graph information",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_102",
            "content": "Michele Bevilacqua, Tommaso Pasini, Alessandro Raganato, Roberto Navigli, Recent trends in word sense disambiguation: A survey, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Michele Bevilacqua",
                    "Tommaso Pasini",
                    "Alessandro Raganato",
                    "Roberto Navigli"
                ],
                "title": "Recent trends in word sense disambiguation: A survey",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_103",
            "content": "Terra Blevins, Luke Zettlemoyer, Moving down the long tail of word sense disambiguation with gloss informed bi-encoders, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Terra Blevins",
                    "Luke Zettlemoyer"
                ],
                "title": "Moving down the long tail of word sense disambiguation with gloss informed bi-encoders",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_104",
            "content": "Giulia Bonansinga, Francis Bond, Multilingual sense intersection in a parallel corpus with diverse language families, 2016, Proceedings of the 8th, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Giulia Bonansinga",
                    "Francis Bond"
                ],
                "title": "Multilingual sense intersection in a parallel corpus with diverse language families",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 8th",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_105",
            "content": "UNKNOWN, None, , Global WordNet Conference (GWC), Global Wordnet Association.",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Global WordNet Conference (GWC)",
                "pub": "Global Wordnet Association"
            }
        },
        {
            "ix": "200-ARR_v2_106",
            "content": "Jos\u00e9 Camacho-Collados, Mohammad Taher Pilehvar, Roberto Navigli, NASARI: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entities, 2016, Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Jos\u00e9 Camacho-Collados",
                    "Mohammad Taher Pilehvar",
                    "Roberto Navigli"
                ],
                "title": "NASARI: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entities",
                "pub_date": "2016",
                "pub_title": "Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_107",
            "content": "Niccol\u00f2 Campolungo, Federico Martelli, Francesco Saina, Roberto Navigli, DiBiMT: A Novel Benchmark for Measuring Word Sense Disambiguation Biases in Machine Translation, 2022, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, Ireland. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Niccol\u00f2 Campolungo",
                    "Federico Martelli",
                    "Francesco Saina",
                    "Roberto Navigli"
                ],
                "title": "DiBiMT: A Novel Benchmark for Measuring Word Sense Disambiguation Biases in Machine Translation",
                "pub_date": "2022",
                "pub_title": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Ireland. Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_108",
            "content": "Marine Carpuat, Dekai Wu, Word sense disambiguation vs. statistical machine translation, 2005, Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Marine Carpuat",
                    "Dekai Wu"
                ],
                "title": "Word sense disambiguation vs. statistical machine translation",
                "pub_date": "2005",
                "pub_title": "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_109",
            "content": "Marine Carpuat, Dekai Wu, Improving statistical machine translation using word sense disambiguation, 2007, Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Marine Carpuat",
                    "Dekai Wu"
                ],
                "title": "Improving statistical machine translation using word sense disambiguation",
                "pub_date": "2007",
                "pub_title": "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_110",
            "content": "Christopher Clark, Mark Yatskar, Luke Zettlemoyer, Don't take the easy way out: Ensemble based methods for avoiding known dataset biases, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Christopher Clark",
                    "Mark Yatskar",
                    "Luke Zettlemoyer"
                ],
                "title": "Don't take the easy way out: Ensemble based methods for avoiding known dataset biases",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_111",
            "content": "Simone Conia, Roberto Navigli, Framing word sense disambiguation as a multi-label problem for model-agnostic knowledge integration, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Simone Conia",
                    "Roberto Navigli"
                ],
                "title": "Framing word sense disambiguation as a multi-label problem for model-agnostic knowledge integration",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_112",
            "content": "Claudio Bovi, Jose Camacho-Collados, Alessandro Raganato, Roberto Navigli, Eu-roSense: Automatic harvesting of multilingual sense annotations from parallel text, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Claudio Bovi",
                    "Jose Camacho-Collados",
                    "Alessandro Raganato",
                    "Roberto Navigli"
                ],
                "title": "Eu-roSense: Automatic harvesting of multilingual sense annotations from parallel text",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Short Papers"
            }
        },
        {
            "ix": "200-ARR_v2_113",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_114",
            "content": "Chris Dyer, Victor Chahuneau, Noah Smith, A simple, fast, and effective reparameterization of IBM model 2, 2013, Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Chris Dyer",
                    "Victor Chahuneau",
                    "Noah Smith"
                ],
                "title": "A simple, fast, and effective reparameterization of IBM model 2",
                "pub_date": "2013",
                "pub_title": "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_115",
            "content": "Denis Emelin, Ivan Titov, Rico Sennrich, Widening the representation bottleneck in neural machine translation with lexical shortcuts, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Denis Emelin",
                    "Ivan Titov",
                    "Rico Sennrich"
                ],
                "title": "Widening the representation bottleneck in neural machine translation with lexical shortcuts",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_116",
            "content": "Denis Emelin, Ivan Titov, Rico Sennrich, Detecting word sense disambiguation biases in machine translation for model-agnostic adversarial attacks, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Denis Emelin",
                    "Ivan Titov",
                    "Rico Sennrich"
                ],
                "title": "Detecting word sense disambiguation biases in machine translation for model-agnostic adversarial attacks",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_117",
            "content": "Viktor Hangya, Qianchu Liu, Dario Stojanovski, Alexander Fraser, Anna Korhonen, Improving machine translation of rare and unseen word senses, 2021, Proceedings of the Sixth Conference on Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Viktor Hangya",
                    "Qianchu Liu",
                    "Dario Stojanovski",
                    "Alexander Fraser",
                    "Anna Korhonen"
                ],
                "title": "Improving machine translation of rare and unseen word senses",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Sixth Conference on Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_118",
            "content": "He He, Sheng Zha, Haohan Wang, Unlearn dataset bias in natural language inference by fitting the residual, 2019, Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "He He",
                    "Sheng Zha",
                    "Haohan Wang"
                ],
                "title": "Unlearn dataset bias in natural language inference by fitting the residual",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_119",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015-05-07, 3rd International Conference on Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "P Diederik",
                    "Jimmy Kingma",
                    " Ba"
                ],
                "title": "Adam: A method for stochastic optimization",
                "pub_date": "2015-05-07",
                "pub_title": "3rd International Conference on Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_120",
            "content": "Philipp Koehn, Statistical significance tests for machine translation evaluation, 2004, Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Philipp Koehn"
                ],
                "title": "Statistical significance tests for machine translation evaluation",
                "pub_date": "2004",
                "pub_title": "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_121",
            "content": "UNKNOWN, None, 1951, On information and sufficiency. The annals of mathematical statistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "1951",
                "pub_title": "On information and sufficiency. The annals of mathematical statistics",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_122",
            "content": "Helen Langone, Benjamin Haskell, George Miller, Annotating WordNet, 2004, Proceedings of the Workshop Frontiers in Corpus Annotation at HLT-NAACL 2004, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Helen Langone",
                    "Benjamin Haskell",
                    "George Miller"
                ],
                "title": "Annotating WordNet",
                "pub_date": "2004",
                "pub_title": "Proceedings of the Workshop Frontiers in Corpus Annotation at HLT-NAACL 2004",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_123",
            "content": "Frederick Liu, Han Lu, Graham Neubig, Handling homographs in neural machine translation, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Frederick Liu",
                    "Han Lu",
                    "Graham Neubig"
                ],
                "title": "Handling homographs in neural machine translation",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "200-ARR_v2_124",
            "content": "Daniel Loureiro, Al\u00edpio Jorge, Language modelling makes sense: Propagating representations through WordNet for full-coverage word sense disambiguation, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Daniel Loureiro",
                    "Al\u00edpio Jorge"
                ],
                "title": "Language modelling makes sense: Propagating representations through WordNet for full-coverage word sense disambiguation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_125",
            "content": "Yixing Luan, Bradley Hauer, Lili Mou, Grzegorz Kondrak, Improving word sense disambiguation with translations, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Yixing Luan",
                    "Bradley Hauer",
                    "Lili Mou",
                    "Grzegorz Kondrak"
                ],
                "title": "Improving word sense disambiguation with translations",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_126",
            "content": "Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci, Roberto Navigli, Embedding words and senses together via joint knowledgeenhanced training, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": [
                    "Massimiliano Mancini",
                    "Jose Camacho-Collados",
                    "Ignacio Iacobacci",
                    "Roberto Navigli"
                ],
                "title": "Embedding words and senses together via joint knowledgeenhanced training",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 21st Conference on Computational Natural Language Learning",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_127",
            "content": "Quinn Mcnemar, Note on the sampling error of the difference between correlated proportions or percentages, 1947, Psychometrika, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Quinn Mcnemar"
                ],
                "title": "Note on the sampling error of the difference between correlated proportions or percentages",
                "pub_date": "1947",
                "pub_title": "Psychometrika",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_128",
            "content": "George Miller, R Beckwith, Christiane Fellbaum, D Gross, K Miller, WordNet: an online lexical database, 1990, Int. J. Lexicogr, .",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "George Miller",
                    "R Beckwith",
                    "Christiane Fellbaum",
                    "D Gross",
                    "K Miller"
                ],
                "title": "WordNet: an online lexical database",
                "pub_date": "1990",
                "pub_title": "Int. J. Lexicogr",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_129",
            "content": "George Miller, Claudia Leacock, Randee Tengi, Ross Bunker, A semantic concordance, 1993, Proc. of the Workshop on Human Language Technology, .",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "George Miller",
                    "Claudia Leacock",
                    "Randee Tengi",
                    "Ross Bunker"
                ],
                "title": "A semantic concordance",
                "pub_date": "1993",
                "pub_title": "Proc. of the Workshop on Human Language Technology",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_130",
            "content": "Roberto Navigli, Michele Bevilacqua, Simone Conia, Dario Montagnini, Francesco Cecconi, Ten years of BabelNet: A survey, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": [
                    "Roberto Navigli",
                    "Michele Bevilacqua",
                    "Simone Conia",
                    "Dario Montagnini",
                    "Francesco Cecconi"
                ],
                "title": "Ten years of BabelNet: A survey",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_131",
            "content": "Roberto Navigli, Simone Ponzetto, Ba-belNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network, 2012, Artificial intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "Roberto Navigli",
                    "Simone Ponzetto"
                ],
                "title": "Ba-belNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network",
                "pub_date": "2012",
                "pub_title": "Artificial intelligence",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_132",
            "content": "Quang-Phuoc Nguyen, Anh-Dung Vo, Joon-Choul Shin, Cheol-Young Ock, Effect of word sense disambiguation on neural machine translation: A case study in korean, 2018, IEEE Access, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Quang-Phuoc Nguyen",
                    "Anh-Dung Vo",
                    "Joon-Choul Shin",
                    "Cheol-Young Ock"
                ],
                "title": "Effect of word sense disambiguation on neural machine translation: A case study in korean",
                "pub_date": "2018",
                "pub_title": "IEEE Access",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_133",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Kishore Papineni",
                    "Salim Roukos",
                    "Todd Ward",
                    "Wei-Jing Zhu"
                ],
                "title": "Bleu: a method for automatic evaluation of machine translation",
                "pub_date": "2002",
                "pub_title": "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_134",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Matt Post"
                ],
                "title": "A call for clarity in reporting BLEU scores",
                "pub_date": "2018",
                "pub_title": "Proceedings of the Third Conference on Machine Translation: Research Papers",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_135",
            "content": "Luigi Procopio, Edoardo Barba, Federico Martelli, Roberto Navigli, MultiMirror: Neural crosslingual word alignment for multilingual word sense disambiguation, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Luigi Procopio",
                    "Edoardo Barba",
                    "Federico Martelli",
                    "Roberto Navigli"
                ],
                "title": "MultiMirror: Neural crosslingual word alignment for multilingual word sense disambiguation",
                "pub_date": "2021",
                "pub_title": "Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_136",
            "content": "Xiao Pu, Nikolaos Pappas, James Henderson, Andrei Popescu-Belis, Integrating weakly supervised word sense disambiguation into neural machine translation, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b37",
                "authors": [
                    "Xiao Pu",
                    "Nikolaos Pappas",
                    "James Henderson",
                    "Andrei Popescu-Belis"
                ],
                "title": "Integrating weakly supervised word sense disambiguation into neural machine translation",
                "pub_date": "2018",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_137",
            "content": "Xiao Pu, Nikolaos Pappas, James Henderson, Andrei Popescu-Belis, Integrating weakly supervised word sense disambiguation into neural machine translation, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b38",
                "authors": [
                    "Xiao Pu",
                    "Nikolaos Pappas",
                    "James Henderson",
                    "Andrei Popescu-Belis"
                ],
                "title": "Integrating weakly supervised word sense disambiguation into neural machine translation",
                "pub_date": "2018",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_138",
            "content": "Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher Manning, Stanza: A python natural language processing toolkit for many human languages, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b39",
                "authors": [
                    "Peng Qi",
                    "Yuhao Zhang",
                    "Yuhui Zhang",
                    "Jason Bolton",
                    "Christopher Manning"
                ],
                "title": "Stanza: A python natural language processing toolkit for many human languages",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_139",
            "content": "Alessandro Raganato, Yves Scherrer, J\u00f6rg Tiedemann, The MuCoW test suite at WMT 2019: Automatically harvested multilingual contrastive word sense disambiguation test sets for machine translation, 2019, Proceedings of the Fourth Conference on Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b40",
                "authors": [
                    "Alessandro Raganato",
                    "Yves Scherrer",
                    "J\u00f6rg Tiedemann"
                ],
                "title": "The MuCoW test suite at WMT 2019: Automatically harvested multilingual contrastive word sense disambiguation test sets for machine translation",
                "pub_date": "2019",
                "pub_title": "Proceedings of the Fourth Conference on Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_140",
            "content": "Annette Rios Gonzales, Laura Mascarell, Rico Sennrich, Improving word sense disambiguation in neural machine translation with sense embeddings, 2017, Proceedings of the Second Conference on Machine Translation, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b41",
                "authors": [
                    "Annette Rios Gonzales",
                    "Laura Mascarell",
                    "Rico Sennrich"
                ],
                "title": "Improving word sense disambiguation in neural machine translation with sense embeddings",
                "pub_date": "2017",
                "pub_title": "Proceedings of the Second Conference on Machine Translation",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_141",
            "content": "Bianca Scarlini, Tommaso Pasini, Roberto Navigli, Sense-annotated corpora for word sense disambiguation in multiple languages and domains, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, European Language Resources Association.",
            "ntype": "ref",
            "meta": {
                "xid": "b42",
                "authors": [
                    "Bianca Scarlini",
                    "Tommaso Pasini",
                    "Roberto Navigli"
                ],
                "title": "Sense-annotated corpora for word sense disambiguation in multiple languages and domains",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 12th Language Resources and Evaluation Conference",
                "pub": "European Language Resources Association"
            }
        },
        {
            "ix": "200-ARR_v2_142",
            "content": "Bianca Scarlini, Tommaso Pasini, Roberto Navigli, With more contexts comes better performance: Contextualized sense embeddings for allround word sense disambiguation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b43",
                "authors": [
                    "Bianca Scarlini",
                    "Tommaso Pasini",
                    "Roberto Navigli"
                ],
                "title": "With more contexts comes better performance: Contextualized sense embeddings for allround word sense disambiguation",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_143",
            "content": "Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan, Multilingual translation from denoising pre-training, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "ref",
            "meta": {
                "xid": "b44",
                "authors": [
                    "Yuqing Tang",
                    "Chau Tran",
                    "Xian Li",
                    "Peng-Jen Chen",
                    "Naman Goyal",
                    "Vishrav Chaudhary",
                    "Jiatao Gu",
                    "Angela Fan"
                ],
                "title": "Multilingual translation from denoising pre-training",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_144",
            "content": "J\u00f6rg Tiedemann, Santhosh Thottingal, OPUS-MT -building open translation services for the world, 2020, Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b45",
                "authors": [
                    "J\u00f6rg Tiedemann",
                    "Santhosh Thottingal"
                ],
                "title": "OPUS-MT -building open translation services for the world",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 22nd Annual Conference of the European Association for Machine Translation",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_145",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Illia Kaiser,  Polosukhin, Attention is all you need, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "ref",
            "meta": {
                "xid": "b46",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "Illia Kaiser",
                    " Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Curran Associates, Inc"
            }
        },
        {
            "ix": "200-ARR_v2_146",
            "content": "David Vickrey, Luke Biewald, Marc Teyssier, Daphne Koller, Word-sense disambiguation for machine translation, 2005, Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b47",
                "authors": [
                    "David Vickrey",
                    "Luke Biewald",
                    "Marc Teyssier",
                    "Daphne Koller"
                ],
                "title": "Word-sense disambiguation for machine translation",
                "pub_date": "2005",
                "pub_title": "Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "200-ARR_v2_147",
            "content": "Xinyi Wang, Sebastian Ruder, Graham Neubig, Multi-view subword regularization, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b48",
                "authors": [
                    "Xinyi Wang",
                    "Sebastian Ruder",
                    "Graham Neubig"
                ],
                "title": "Multi-view subword regularization",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_148",
            "content": "Zikang Wang, Linjing Li, Daniel Zeng, Knowledge-enhanced natural language inference based on knowledge graphs, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b49",
                "authors": [
                    "Zikang Wang",
                    "Linjing Li",
                    "Daniel Zeng"
                ],
                "title": "Knowledge-enhanced natural language inference based on knowledge graphs",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 28th International Conference on Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_149",
            "content": "UNKNOWN, None, 1949, Translation. Machine Translation of Languages: Fourteen Essays, .",
            "ntype": "ref",
            "meta": {
                "xid": "b50",
                "authors": null,
                "title": null,
                "pub_date": "1949",
                "pub_title": "Translation. Machine Translation of Languages: Fourteen Essays",
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_150",
            "content": "UNKNOWN, None, , , .",
            "ntype": "ref",
            "meta": {
                "xid": "b51",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": null,
                "pub": null
            }
        },
        {
            "ix": "200-ARR_v2_151",
            "content": "UNKNOWN, None, , Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b52",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
                "pub": "Online. Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "200-ARR_v2_0@0",
            "content": "Reducing Disambiguation Biases in NMT by Leveraging Explicit Word Sense Information",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_0",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_2@0",
            "content": "Recent studies have shed some light on a common pitfall of Neural Machine Translation (NMT) models, stemming from their struggle to disambiguate polysemous words without lapsing into their most frequently occurring senses in the training corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_2",
            "start": 0,
            "end": 244,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_2@1",
            "content": "In this paper, we first provide a novel approach for automatically creating high-precision sense-annotated parallel corpora, and then put forward a specifically tailored fine-tuning strategy for exploiting these sense annotations during training without introducing any additional requirement at inference time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_2",
            "start": 246,
            "end": 556,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_2@2",
            "content": "The use of explicit senses proved to be beneficial to reduce the disambiguation bias of a baseline NMT model, while, at the same time, leading our system to attain higher BLEU scores than its vanilla counterpart in 3 language pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_2",
            "start": 558,
            "end": 789,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_4@0",
            "content": "Translating a sentence requires the underlying meaning to be captured and then expressed in the target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_4",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_4@1",
            "content": "Nonetheless, only little attention has been devoted to studying the actual capabilities of Neural Machine Translation (NMT) approaches of modeling different senses of ambiguous words, with recent work showing that systems tend to be biased towards the most frequent meanings found within the training corpus (Emelin et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_4",
            "start": 113,
            "end": 442,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_4@2",
            "content": "This phenomenon is hard to measure through classical evaluation metrics, such as the BLEU score (Papineni et al., 2002), as they often rely on word-matching heuristics that fail to capture the disambiguation capabilities of the evaluated systems.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_4",
            "start": 444,
            "end": 689,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_4@3",
            "content": "Therefore, several efforts have been recently devoted to shed some light and create test beds (Rios Gonzales et al., 2017;Raganato et al., 2019;Emelin et al., 2020;Campolungo et al., 2022) to challenge NMT models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_4",
            "start": 691,
            "end": 903,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_4@4",
            "content": "Results show that these models still struggle to deal with highly polysemous words, especially when used to express least frequent senses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_4",
            "start": 905,
            "end": 1042,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_5@0",
            "content": "For example, given the sentence \"The energy comes from a distant plant.\", both Google Translate and DeepL disambiguate 1 plant to its sense of organism when translating into Italian, and produce the following incorrect sentence \"L'energia proviene da una pianta lontana.\", rather than \"L'energia proviene da un impianto lontano.\", where impianto is the translation for the factory meaning of plant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_5",
            "start": 0,
            "end": 397,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_5@1",
            "content": "This suggests that, even when adequate context is provided (energy should be enough to correctly infer the right sense of plant), state-of-the-art models might still be biased towards the most frequent meanings found within training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_5",
            "start": 399,
            "end": 636,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_6@0",
            "content": "Some recent studies have explored how to leverage explicit sense information within NMT models (Rios Gonzales et al., 2017;Pu et al., 2018a;Nguyen et al., 2018).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_6",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_6@1",
            "content": "Nevertheless, including such information is not trivial for three main reasons: i) sense-tagged parallel data is scarce; ii) Word Sense Disambiguation (WSD) systems have not been accurate enough until very recently (Blevins and Zettlemoyer, 2020;; and iii) how explicit senses should be incorporated within neural models is not straightforward.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_6",
            "start": 162,
            "end": 505,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_7@0",
            "content": "In this paper, we first introduce a novel approach to make up for the paucity of sense annotations in parallel corpora, leveraging a multilingual WSD system to tag parallel sentences and refine its predictions by means of cross-lingual word alignments and information from a multilingual knowledge base.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_7",
            "start": 0,
            "end": 302,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_7@1",
            "content": "Then, we fine-tune our baseline models on our sense-tagged corpora via a specifically designed loss function, allowing the injection of wordlevel semantics into the architecture.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_7",
            "start": 304,
            "end": 481,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_7@2",
            "content": "We evaluate our approach on standard and challenge test sets, showing that it does indeed improve translation accuracy and mitigates the most frequent sense bias.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_7",
            "start": 483,
            "end": 644,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_8@0",
            "content": "To summarize, our contributions are manifold:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_8",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_9@0",
            "content": "1. We put forward a novel approach to produce high-precision sense annotations for parallel data, which we apply to three language pairs.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_9",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_9@1",
            "content": "2. We propose a fine-tuning strategy that lets us inject word-level explicit semantics into Neural Machine Translation models, without introducing any additional requirement at inference time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_9",
            "start": 138,
            "end": 329,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_10@0",
            "content": "3. We show that employing explicit sense tags is beneficial in order both to mitigate the sense bias and to improve the translation quality in terms of BLEU score on standard benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_10",
            "start": 0,
            "end": 185,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_11@0",
            "content": "4. We present a case study on how a state-of-theart WSD system compares to an NMT model on disambiguating words within a challenging set for detecting sense bias in MT.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_11",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_12@0",
            "content": "We make all the generated datasets, the code of the model and for the experiments available at https://github.com/sapienzanlp/ reducing-wsd-bias-in-nmt.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_12",
            "start": 0,
            "end": 151,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_13@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_13",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_14@0",
            "content": "Word Sense Disambiguation was first formulated as a computational task by Weaver (1949) in the context of Machine Translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_14",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_14@1",
            "content": "The two fields then followed parallel paths, with more or less successful attempts over the years to join them back together (Carpuat and Wu, 2005;Vickrey et al., 2005;Carpuat and Wu, 2007).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_14",
            "start": 127,
            "end": 316,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_14@2",
            "content": "Indeed, while Carpuat and Wu (2005) reported negative results when trying to integrate the prediction of a supervised WSD approach into a Statistical Machine Translation (SMT) model, the same authors, two years later, successfully improved the performance of a phrase-based SMT approach by leveraging a new phrase-based WSD model (Carpuat and Wu, 2007).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_14",
            "start": 318,
            "end": 670,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_14@3",
            "content": "More recently, Pu et al. (2018a) and Nguyen et al. (2018) proposed systems that successfully leverage sense information in NMT models, although they introduced a heavy requirement, i.e., that of disambiguating the ambiguous words in the sentence prior to generating a translation, which makes them unfeasible in many real-world settings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_14",
            "start": 672,
            "end": 1008,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_14@4",
            "content": "Lately, contextualized word embeddings have been employed to produce additional back-translated parallel training data via mining sense-specific target sentences, in order to improve handling of infrequent senses (Hangya et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_14",
            "start": 1010,
            "end": 1244,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@0",
            "content": "Nevertheless, the proper treatment of lexical ambiguity is still an open problem, with neural models struggling to translate least frequent senses and often relying on spurious correlations among words (Emelin et al., 2020;Raganato et al., 2019;Rios Gonzales et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@1",
            "content": "Thus, the disambiguation bias topic has received renewed interest, and several benchmarks have been introduced in the most recent years with the goal of directly measuring the extent to which neural architectures are able to capture word semantics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 274,
            "end": 521,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@2",
            "content": "One of the first of this kind was ContraWSD (Rios Gonzales et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 523,
            "end": 595,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@3",
            "content": "In this first attempt to evaluate WSD capabilities of NMT models, the authors built an adversarial test set where source sentences containing an ambiguous word were associated with a correct translation and several incorrect alternatives.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 597,
            "end": 834,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@4",
            "content": "These latter were built by replacing the reference translation for the ambiguous word with the translation of one of its other possible meanings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 836,
            "end": 980,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@5",
            "content": "The task measured whether a model ranked the correct translation higher, i.e., it assigned it a higher probability than the adversarial ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 982,
            "end": 1122,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@6",
            "content": "This study provided evaluation data for two language pairs only, i.e., German\u2192English and German\u2192French, and within a few years it became outdated as modern NMT models could easily attain high performances (Emelin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 1124,
            "end": 1351,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_15@7",
            "content": "Thus, MuCoW (Raganato et al., 2019) took things a step further and leveraged BabelNet (Navigli and Ponzetto, 2012;) -a large multilingual knowledge base -and sense embeddings (Camacho-Collados et al., 2016;Mancini et al., 2017) in order to automatically create adversarial translations for five language pairs while also increasing the difficulty of the task itself; however, the fully automatic nature of these challenge sets made them noisy and prone to containing irrelevant challenge samples.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_15",
            "start": 1353,
            "end": 1848,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_16@0",
            "content": "More recently, Emelin et al. (2020) proposed two challenge sets for the English\u2192German pair, one measuring the model sensitivity to most frequent senses and the other estimating, through adversarial injections, its susceptibility to changing a correct sense to a wrong one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_16",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_16@1",
            "content": "In contrast to previous studies, these challenge sets were based on correlations among words in the training set and relied on manually-refined sense clusters, providing an excellent test bed for measuring semantic bias.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_16",
            "start": 274,
            "end": 493,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_17@0",
            "content": "Finally, Campolungo et al. (2022) proposed DIBIMT, the first fully manually annotated test set for measuring the disambiguation bias of neural machine translation models, covering five language combinations, namely, from English to German, Spanish, Italian, Russian and Chinese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_17",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_17@1",
            "content": "In their work, the authors showed that open neural models still exhibit strong semantic biases towards frequent senses, confirming once again the suspicions about this under-explored issue.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_17",
            "start": 279,
            "end": 467,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_18@0",
            "content": "Despite all the effort made in putting forward challenging sets of data to test WSD capabilities of NMT models, to the best of our knowledge, only a few approaches (Rios Gonzales et al., 2017;Liu et al., 2018) have been proposed to mitigate this issue, and none of these is effective with modern Transformer-based architectures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_18",
            "start": 0,
            "end": 327,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_18@1",
            "content": "Furthermore, while parallel corpora have been exploited to produce sense annotations in the past (Bonansinga and Bond, 2016;Delli Bovi et al., 2017), they were built by utilizing outdated disambiguation approaches that have recently been surpassed by more advanced neural architectures.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_18",
            "start": 329,
            "end": 614,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_18@2",
            "content": "Indeed, the Word Sense Disambiguation field has received much attention in the last few years, with several supervised approaches Blevins and Zettlemoyer, 2020; and sense embedding models (Loureiro and Jorge, 2019;Scarlini et al., 2020a,b;Wang et al., 2020) performing close to the upper bound limit of the inter-annotator agreement, which finally makes them feasible for inclusion in other downstream tasks, e.g., Machine Translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_18",
            "start": 616,
            "end": 1050,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_19@0",
            "content": "Thus, differently from previous studies in the literature, we focus on closing the gap between these two fields, i.e., Neural Machine Translation and Word Sense Disambiguation, by putting the recent advances in WSD at the service of NMT models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_19",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_19@1",
            "content": "We propose a novel approach, similar to that introduced in Luan et al. (2020), for creating high-quality sense-annotated parallel corpora, and we use this semantic information to regularize an NMT model, making it less biased and capable of producing higher-quality translations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_19",
            "start": 245,
            "end": 523,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_20@0",
            "content": "Reducing the Disambiguation Bias in NMT",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_20",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_21@0",
            "content": "Neural Machine Translation models are typically trained end-to-end to produce a target translation given a source sentence and, thus, they can only rely on the input context to resolve the ambiguity of polysemous words therein.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_21",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_21@1",
            "content": "Being pattern recognition algorithms at heart, these models fall prey to the inherent bias carried by the frequency of co-occurrence of words within parallel sentences, and thus tend to disambiguate words to the sense they most frequently encountered during training, even when the sentence does provide enough context to identify the correct sense.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_21",
            "start": 228,
            "end": 576,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_21@2",
            "content": "At the same time, Word Sense Disambiguation models, i.e., models specialized in associating a word in context with one of the meanings within a given sense inventory, have recently displayed remarkable results across different benchmarks and languages .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_21",
            "start": 578,
            "end": 830,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_21@3",
            "content": "The time may now therefore be ripe for them to be successfully included into downstream applications such as Neural Machine Translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_21",
            "start": 832,
            "end": 967,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_21@4",
            "content": "However, data that would allow these two worlds to be brought together, i.e., parallel corpora where words are associated with semantic labels, are currently still produced automatically by leveraging outdated approaches to WSD (Delli Bovi et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_21",
            "start": 969,
            "end": 1222,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_22@0",
            "content": "In what follows, we first provide some preliminary information about resources and tools that we employ in our method ( \u00a7 3.1); then, we introduce a new approach for automatically annotating tokens within parallel sentences with sense annotations, i.e., labels explicitly defining their meanings ( \u00a7 3.2); finally, we propose a fine-tuning objective for leveraging such annotations in order to mitigate the sense bias while also improving the translation quality overall ( \u00a7 3.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_22",
            "start": 0,
            "end": 479,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_22@1",
            "content": "The intuition behind our work is that fixed sense labels describing word senses would help NMT models better encode the underlying meaning of the input sentence, thus generating less biased and overall better translations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_22",
            "start": 481,
            "end": 702,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_23@0",
            "content": "Preliminaries",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_23",
            "start": 0,
            "end": 12,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_24@0",
            "content": "We draw sense labels from BabelNet (Navigli and Ponzetto, 2012), a multilingual knowledge base created by merging several semantic resources in different languages such as WordNet (Miller et al., 1990), Wikipedia, Wikidata, etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_24",
            "start": 0,
            "end": 227,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_24@1",
            "content": "BabelNet is structured in synsets, i.e., sets of synonymous senses in different languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_24",
            "start": 229,
            "end": 318,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_24@2",
            "content": "For instance, the synset of plant organism contains the following lexicalizations: plant EN , pianta IT , Pflanze DE , among others.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_24",
            "start": 320,
            "end": 451,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_24@3",
            "content": "Additionally, BabelNet provides lemma-tosynsets mappings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_24",
            "start": 453,
            "end": 509,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_24@4",
            "content": "For example, the English noun plant belongs to the following nominal synsets: organism, industrial plant, actor in the audience and something placed secretly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_24",
            "start": 511,
            "end": 668,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_24@5",
            "content": "2 Since BabelNet contains millions of synsets, which may make the computation too expensive, we restrict the vocabulary to just those containing at least one English sense from WordNet, as is also done in several other works (Barba et al., 2020;Scarlini et al., 2020b;Bevilacqua and Navigli, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_24",
            "start": 670,
            "end": 967,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_25@0",
            "content": "Building a Sense-Annotated Parallel Corpus",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_25",
            "start": 0,
            "end": 41,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_26@0",
            "content": "Let us assume that our running example sentence \"The energy comes from a distant plant.\" appears within a parallel corpus paired with the following Italian translation: \"L'energia viene da un impianto lontano.\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_26",
            "start": 0,
            "end": 210,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_26@1",
            "content": "As we said, by considering the English sentence alone, the word plant could take several meanings, among which organism and power plant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_26",
            "start": 212,
            "end": 347,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_26@2",
            "content": "However, among these, only one is shared with its translation impianto, i.e., the power plant meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_26",
            "start": 349,
            "end": 450,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_26@3",
            "content": "Therefore, considering the cross-lingual alignment of words may drastically reduce the set of valid meanings, making the disambiguation task much easier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_26",
            "start": 452,
            "end": 604,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_26@4",
            "content": "Based on this intuition, given a parallel corpus, we perform the following two steps:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_26",
            "start": 606,
            "end": 690,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_27@0",
            "content": "1. Sense Scoring, where we employ a WSD system to assign to each content word a distribution over its possible meanings;",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_27",
            "start": 0,
            "end": 119,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_28@0",
            "content": "2. Annotation Refinement, where we compute cross-lingual word alignments to reduce lexical ambiguity and finally assign the most suitable sense to each content word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_28",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_29@0",
            "content": "Sense Scoring In this step, our goal is to assign to every content word within a sentence a distribution over its possible senses in BabelNet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_29",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_29@1",
            "content": "To this end, given as input a sentence s 3 from a parallel corpus C, we first apply Part-of-Speech tagging and lemmatization to it, then pass it through our WSD system, which returns a distribution over its possible meanings.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_29",
            "start": 143,
            "end": 367,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_29@2",
            "content": "Formally, let w i be a content word in a sentence s = [w 1 , . . . , w n ], and \u03c3(w i ) the set of synsets associated with w i in BabelNet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_29",
            "start": 369,
            "end": 507,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_29@3",
            "content": "The WSD system assigns a score c(S|w i , s) to each synset S \u2208 \u03c3(w i ); we denote the synset of w i with the highest confidence as S * w i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_29",
            "start": 509,
            "end": 648,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_29@4",
            "content": "As a result, each content word in a source or target sentence is associated with a sense distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_29",
            "start": 650,
            "end": 751,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_29@5",
            "content": "However, applying a WSD system alone may not be sufficient to ensure high-quality 3 s can be either a source or a target sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_29",
            "start": 753,
            "end": 882,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_30@0",
            "content": "annotations, as the application domain may be different from the one of its training set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_30",
            "start": 0,
            "end": 88,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_30@1",
            "content": "Therefore, in the next step we take advantage of the translation each sentence is paired with to refine sense annotations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_30",
            "start": 90,
            "end": 211,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_31@0",
            "content": "We produce word-level cross-lingual alignments between the source and the target sentences of the parallel corpus: given a pair of parallel sentences (s, t), we compute a list of alignments A = {(w s i , w t j )|w s i \u2208 s, w t j \u2208 t}. Thus, given an aligned word pair P = (w s i , w t j ) \u2208 A, let \u03c3(P ) = \u03c3(w s i ) \u2229 \u03c3(w t j ), i.e., the intersection of synsets that the two words may denote according to BabelNet: we discard annotations for any word pair such that \u03c3(P",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_31",
            "start": 0,
            "end": 469,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_32@0",
            "content": ") = \u2205 \u2228 |\u03c3(w s i )| < 2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_32",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_33@0",
            "content": "In other words, we retain all the aligned pairs (w s i , w t j ) such that the source word is polysemous and the intersection of their senses is non-empty, thus ensuring higher annotation precision by leveraging the parallelism of words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_33",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_34@0",
            "content": "Finally, we assign the same synset S * to both words (w s i , w t j ) in P as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_34",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_35@0",
            "content": "S * = S * w s i = S * w t j = argmax S\u2208\u03c3(P ) c(S|w s i , s) Z s + c(S|w t j , t) Z t Z s = S\u2208\u03c3(P ) c(S|w s i , s) Z t = S\u2208\u03c3(P ) c(S|w t j , t)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_35",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_36@0",
            "content": "that is, the synset with the highest combined confidence score after normalizing over \u03c3(P ), where Z s and Z t represent the normalization factors of the probability distributions associated with the synsets of w s i and w t j , respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_36",
            "start": 0,
            "end": 241,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_37@0",
            "content": "Semantic Injection",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_37",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_38@0",
            "content": "Now that we can generate high-quality sense annotations, we describe our fine-tuning method to inject word-level semantics into a Neural Machine Translation model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_38",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_38@1",
            "content": "Ideally, we want the model to benefit from such annotations during training, while not being dependent on them at inference time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_38",
            "start": 164,
            "end": 292,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_38@2",
            "content": "To satisfy both these desiderata, we adapt the model's vocabulary to handle synsets as well as subwords, and propose a specific loss that exploits the injected senses to improve the base model's handling of ambiguous words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_38",
            "start": 294,
            "end": 516,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_39@0",
            "content": "Pre-trained NMT Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_39",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_40@0",
            "content": "The energy comes from a distant plant .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_40",
            "start": 0,
            "end": 38,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_41@0",
            "content": "The energy comes from a distant plant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_41",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_41@1",
            "content": "Semantically Enhancing Sentences In order to work with concepts, we need a way to represent them. Let us consider once more the sentence \"The energy comes from a distant plant.\": we rewrite it in order to also include the exact meaning for plant, which we computed as described in \u00a7 3.2: \"The energy comes from a distant plant plant factory \".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_41",
            "start": 39,
            "end": 381,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_41@2",
            "content": "Formally, given a source sentence s and a word w i annotated with sense S * w i , we simply represent w i as its standard segmentation followed by S * w i , represented by its sense embedding 4 passed through a linear projection layer (as shown in Figure 2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_41",
            "start": 383,
            "end": 640,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_41@3",
            "content": "Additionally, to enforce the connection between the tagged word and its sense annotation, we set the position ids for the word and the sense embedding to the same value, as if they were a single token.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_41",
            "start": 642,
            "end": 842,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_41@4",
            "content": "This encoding scheme gracefully extends to the whole sentence, yielding the sense-enhanced input representation for a given sentence s.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_41",
            "start": 844,
            "end": 978,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_42@0",
            "content": "We hereby propose the Semantic Consistency Regularization (SCR) objective, inspired by MVR (Wang et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_42",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_43@0",
            "content": "Formally, let x \u2032 and x \u2032\u2032 be two encodings (plain and sense-enhanced) of the same input sentence x and let y be the target sentence, we define SCR as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_43",
            "start": 0,
            "end": 150,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_44@0",
            "content": "SCR(\u03b8) = \u2212 log P \u03b8 (y|x \u2032 ) \u2212 log P \u03b8 (y|x \u2032\u2032 ) + D KL (P \u03b8 (y|x \u2032 ) || P \u03b8 (y|x \u2032\u2032 ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_44",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_45@0",
            "content": "where \u03b8 is the set of trainable weights, D KL is the unidirectional Kullback-Leibler divergence (Kullback and Leibler, 1951) and P \u03b8 (y|x) represents an output distribution (a visual representation of SCR is reported in Figure 1).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_45",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_46@0",
            "content": "With this formulation, SCR jointly uses the same sentence with and without sense annotations as two separate inputs: while we train the model to be able to translate both plain and sense-enhanced sentences, by minimizing the divergence between the output distributions we also force the model to transfer the sense information from the senseenhanced input to the plain input, much like in a self-distillation process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_46",
            "start": 0,
            "end": 416,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_46@1",
            "content": "At the same time, we still maintain the model's capability of translating without sense annotations, thus dropping their requirement at inference time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_46",
            "start": 418,
            "end": 568,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_47@0",
            "content": "Experimental Setup",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_47",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_48@0",
            "content": "Our Model",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_48",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_49@0",
            "content": "We employ as underlying model the standard Transformer architecture (Vaswani et al., 2017), with 6 encoder and 6 decoder layers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_49",
            "start": 0,
            "end": 127,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_49@1",
            "content": "5 Note that, while SCR can be applied to any pre-trained model, we retrain one from scratch because most of the other models available online use part of our test data as their training data (see \u00a7 4.2).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_49",
            "start": 129,
            "end": 331,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_49@2",
            "content": "Additional details about training configuration and hyperparameters are provided in \u00a7 A.3.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_49",
            "start": 333,
            "end": 422,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_50@0",
            "content": "Fine-tuning with SCR Additionally, to jumpstart the model's capabilities, we encode synsets not as randomly initialized learnable vectors (e.g., by extending the vocabulary), but with frozen pre-trained sense embeddings projected into the model's input space by means of a linear layer, the only additional learnable component of the model (Projection in Figure 2), which is dropped after the fine-tuning stage.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_50",
            "start": 0,
            "end": 410,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_50@1",
            "content": "As pre-trained sense embeddings we use ARES (Scarlini et al., 2020b), since they provide multilingual representations for each synset in our vocabulary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_50",
            "start": 412,
            "end": 563,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_50@2",
            "content": "We study the impact of this choice in \u00a7 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_50",
            "start": 565,
            "end": 608,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_50@3",
            "content": "To perform token-level alignments, we use MultiMirror (Procopio et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_50",
            "start": 610,
            "end": 687,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_50@4",
            "content": "6",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_50",
            "start": 689,
            "end": 689,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_51@0",
            "content": "Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_51",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_52@0",
            "content": "We experiment on three distinct language pairs: EN\u2192DE, EN\u2192ES and EN\u2192FR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_52",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_52@1",
            "content": "Following (Emelin et al., 2020), we gather the data from WMT14 for German and French and WMT13 for Spanish, considering only sentences coming from either CommonCrawl, News Commentary or Europarl, to maintain similar order of magnitudes among language pairs (and to contain pre-processing and training times).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_52",
            "start": 72,
            "end": 379,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_52@2",
            "content": "As validation sets, we employ newstest2014 for EN\u2192DE, newstest2013 for EN\u2192FR and newstest2012 for EN\u2192ES.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_52",
            "start": 381,
            "end": 484,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_52@3",
            "content": "All datasets employed in this work are freely available for research purposes.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_52",
            "start": 486,
            "end": 563,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_53@0",
            "content": "We process each parallel sentence of the considered corpora with the procedure described in \u00a7 3.2, taking into account only content words whose Partof-Speech tag is noun, as the challenge sets we evaluate upon only target nominal words.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_53",
            "start": 0,
            "end": 235,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_53@1",
            "content": "7 For POS-tagging and lemmatization we use Stanza (Qi et al., 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_53",
            "start": 237,
            "end": 304,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_53@2",
            "content": "As disambiguation system, we use EWISER (Bevilacqua and Navigli, 2020), a neural WSD model based on BERT (Devlin et al., 2019), which has attained state-of-the-art performances on English as well as other languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_53",
            "start": 306,
            "end": 520,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_53@3",
            "content": "EWISER has been trained on SemCor (Miller et al., 1993) -the standard training set for WSD -and the WordNet Gloss corpus (Langone et al., 2004) -a semi-automatically annotated dataset featuring sense definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_53",
            "start": 522,
            "end": 733,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_53@4",
            "content": "Detailed statistics of the base and parallel corpora produced are provided in \u00a7 A.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_53",
            "start": 735,
            "end": 818,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_54@0",
            "content": "We evaluate standard translation quality through the newstest datasets available in the specific WMT year (i.e., WMTXX corresponds to new-stest20XX).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_54",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_54@1",
            "content": "The standard evaluation is carried out by means of SacreBLEU (Post, 2018), with signature BLEU+case.mixed+numrefs.1 +smooth.exp+tok.13a+version.1.5.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_54",
            "start": 150,
            "end": 299,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_55@0",
            "content": "To measure the disambiguation bias of each model we employ the challenge sets introduced by Emelin et al. ( 2020), composed of sentences reserved from the WMT14 English\u2192German corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_55",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_55@1",
            "content": "These challenge sets are based on sense clusters built by automatically merging together BabelNet synsets, which then are manually refined to ensure their correctness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_55",
            "start": 184,
            "end": 350,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_55@2",
            "content": "Each sense cluster contains an English polysemous word and a set of German monosemous terms, which uniquely identify a certain meaning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_55",
            "start": 352,
            "end": 486,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_56@0",
            "content": "These clusters are used to create the following two challenge sets: WSD Bias and Adversarial.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_56",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_56@1",
            "content": "The former quantifies the intrinsic bias the model learned during training, while the latter measures how sensitive the model is to the insertion of terms that are usually associated with another sense cluster during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_56",
            "start": 94,
            "end": 319,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_56@2",
            "content": "Both challenge sets evaluate in terms of accuracy of correct disambiguation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_56",
            "start": 321,
            "end": 396,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_56@3",
            "content": "A more detailed description of these datasets and their evaluation process is provided in \u00a7 A.1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_56",
            "start": 398,
            "end": 493,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_57@0",
            "content": "DIBIMT We also evaluate on the German and Spanish portions of DIBIMT (Campolungo et al., 2022), a recent fully-manually annotated disambiguation bias challenge set, where models are asked to translate English sentences containing ambiguous words, and their translations are checked for either correct or incorrect translation equivalents, which, in contrast to previous benchmarks, are annotated manually and depend on the context of the sentence instead of relying solely on the sense of the source word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_57",
            "start": 0,
            "end": 504,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_58@0",
            "content": "Comparison Systems",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_58",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_59@0",
            "content": "We compare our sense-enhanced model with the following architectures: In what follows we refer to our model fine-tuned with SCR as Baseline+SCR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_59",
            "start": 0,
            "end": 143,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_60@0",
            "content": "We note that, due to the way in which the WSD Bias Challenge Sets were constructed (i.e., by using sentences reserved from WMT14, see \u00a7 4.2), any fair evaluation against OPUS and MBart-50 is to be considered impossible, as such models have seen the sentences in the challenge sets during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_60",
            "start": 0,
            "end": 296,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_60@1",
            "content": "We therefore evaluate these two models only on standard BLEU, and point out that the resulting scores should only be regarded as references for our models' competence in the translation task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_60",
            "start": 298,
            "end": 488,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_61@0",
            "content": "Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_61",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_62@0",
            "content": "In what follows, first, we show that our model attains BLEU scores in the same ballpark as state-ofthe-art approaches such as OPUS and MBart-50, despite the large gap in terms of parameters or training data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_62",
            "start": 0,
            "end": 206,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_62@1",
            "content": "Then, we focus our evaluation on the WSD Bias, and compare our full-fledged model (Baseline+SCR) against its baseline variant.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_62",
            "start": 208,
            "end": 333,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_63@0",
            "content": "General Translation Quality",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_63",
            "start": 0,
            "end": 26,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_64@0",
            "content": "In Table 1 we observe that the trained baselines are more than competent in the translation task: indeed, when considering average BLEU scores, they place between OPUS, which is trained on much more data but has the same parameter count, and MBart-50 (Tang et al., 2021), which is ~8 times larger but is capable of translating English to 50 languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_64",
            "start": 0,
            "end": 350,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_65@0",
            "content": "In contrast to common debiasing techniques, which often observe a degradation in performance on standard benchmarks (Clark et al., 2019;He et al., 2019), we report consistent BLEU improvements on all language pairs, all of which are statistically significant at different p-values (Table 1), providing empirical proof that the proposed method does not hurt the model's general translation capability, while at the same time it helps models generate less biased translations (as will be discussed in the upcoming sections).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_65",
            "start": 0,
            "end": 521,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_66@0",
            "content": "Disambiguation Bias",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_66",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_67@0",
            "content": "Results on the Disambiguation Bias Challenge Sets ( \u00a7 4.2) are reported in Table 2, for both of which we show improvements: on the WSD Bias Challenge Set, the bias is reduced, significantly, by more than 1%; similarly, on the Adversarial Challenge Set, we see a reduction of homographs mistakenly disambiguated due to the injection of adversarial adjectives of 0.27%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_67",
            "start": 0,
            "end": 366,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_67@1",
            "content": "We attribute this lower impact to the artificial nature of the adversarial sentences, some of which, by manual inspection, display poor grammatical fluency.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_67",
            "start": 368,
            "end": 523,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_68@0",
            "content": "WSD Performance",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_68",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_69@0",
            "content": "We conduct an analysis of the performance of EWISER on the English sentences of the WSD Bias Challenge Set, to see how it fares in comparison with our NMT models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_69",
            "start": 0,
            "end": 161,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_69@1",
            "content": "Unfortunately, as the sense clusters are not directly associated with BabelNet synsets, we reconstruct this association automatically and manage to retrieve only 1847 of the 3000 sentences in the challenge set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_69",
            "start": 163,
            "end": 372,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_70@0",
            "content": "Having retrieved BabelNet synsets for the target terms, we can apply EWISER and check whether the disambiguated synset matches one of the synsets retrieved for the sense cluster of the challenge sentence. Let us consider our running example, \"The energy comes from a distant plant.\", one last time: if EWISER disambiguates the term plant to its sense of organism, we count it as a mistake, similarly to the case where our NMT model translates it as pianta instead of impianto (i.e., its sense of factory).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_70",
            "start": 0,
            "end": 504,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_70@1",
            "content": "With this in mind, we evaluate EWISER, Baseline and Baseline+SCR on the aforementioned subset of sentences; we report the results of this evaluation in Table 2 (bottom).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_70",
            "start": 506,
            "end": 674,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_71@0",
            "content": "The results indicate that, for this setting, both NMT models actually perform quite a lot better than a pre-trained disambiguation system.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_71",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_71@1",
            "content": "One reason for this might be the different distributions the models are trained on: by design, the challenge sentences follow a distribution similar to the corpus used to train the NMT model, whereas EWISER is trained on sentences coming from news corpora from the 1960s and dictionary-like definitions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_71",
            "start": 139,
            "end": 441,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_71@2",
            "content": "Moreover, in theory, if we were to apply the refinement process described in \u00a7 3.2 to disambiguate the challenge sentences, we would achieve a perfect score, as the target German lemmas are monosemous and thus the disambiguation is implicitly solved.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_71",
            "start": 443,
            "end": 692,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_71@3",
            "content": "The results of using EWISER's raw annotations are discussed in \u00a7 5.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_71",
            "start": 694,
            "end": 762,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_71@4",
            "content": "Finally, we choose not to perform a similar comparison on the Adversarial Challenge Set, as its examples are designed to specifically target NMT models via adversarial injections; we leave studying their impact in WSD systems as future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_71",
            "start": 764,
            "end": 1004,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_72@0",
            "content": "System Examples",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_72",
            "start": 0,
            "end": 14,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_73@0",
            "content": "In Table 3, we report some examples of disambiguation corrected by our model according to the WSD Bias Challenge Set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_73",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_73@1",
            "content": "The baseline is translating the terms to their most frequent sense (column Wrong sense), instead of the correct one (column Target sense).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_73",
            "start": 118,
            "end": 255,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_73@2",
            "content": "Moreover, the third example shows that this is not only a word matching task, as the improved model is able choose the correct subword and can capture the nuances of meaning in more uncommon senses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_73",
            "start": 257,
            "end": 454,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_74@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_74",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_75@0",
            "content": "Ablation on SCR To measure the importance of the KL term in the loss, we fine-tune the model without including it in the SCR objective ( \u00a7 3.3) and report the results in Tables 1 and 2 (row Baseline+SCR \u2212KL ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_75",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_75@1",
            "content": "We observe that, without KL, the model struggles to leverage the double inputs efficiently; indeed, its translation performance drops around 1 BLEU point on average, while the error rates increase by roughly 1% on both bias challenge sets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_75",
            "start": 210,
            "end": 448,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_75@2",
            "content": "These results back our intuition that the KL divergence helps to distill sense information from the sense-enhanced inputs, and is indeed a crucial component to our formulation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_75",
            "start": 450,
            "end": 625,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_76@0",
            "content": "Ablation on ARES We also test our system replacing the pre-trained sense embeddings provided by ARES with randomly initialized learnable embeddings and report this result in Tables 1 and 2 (row Baseline+SCR \u2212ARES ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_76",
            "start": 0,
            "end": 214,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_76@1",
            "content": "As expected, both translation quality and disambiguation bias drop consistently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_76",
            "start": 216,
            "end": 295,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_76@2",
            "content": "Indeed, learning sense embeddings from scratch is much harder than learning a mapping between a fixed space and a trainable one.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_76",
            "start": 297,
            "end": 424,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_77@0",
            "content": "We evaluate our sense Annotation Refinement process ( \u00a7 3.2) by fine-tuning the model on the unconstrained sense annotations provided by EWISER (Baseline+SCR \u2212AR ), i.e., by considering the synset with the highest confidence on the source word as the correct one, instead of S * .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_77",
            "start": 0,
            "end": 279,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_77@1",
            "content": "In the bias evaluation (Table 2), the performances on both challenge sets drop significantly (p < 0.001), which is in line with EWISER's performance on this challenge set ( \u00a7 5.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_77",
            "start": 281,
            "end": 460,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_77@2",
            "content": "Furthermore, the BLEU scores drop too, although not as significantly (Table 1), but still always under-performing with respect to Baseline+SCR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_77",
            "start": 462,
            "end": 604,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_78@0",
            "content": "Ablation on Sense Annotations Finally, we test whether the sense annotations have an impact by replacing them with random senses for the specific word, drawn from the sense vocabulary with uniform probability, during the fine-tuning stage (Baseline+SCR RAND ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_78",
            "start": 0,
            "end": 259,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_78@1",
            "content": "9 As expected, we observe that randomly injecting senses is detrimental, with important performance drops in both the standard and the bias evaluation benchmarks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_78",
            "start": 261,
            "end": 422,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_79@0",
            "content": "Evaluation on DIBIMT",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_79",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_80@0",
            "content": "In Table 4 we report the results obtained on DIBIMT (Campolungo et al., 2022).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_80",
            "start": 0,
            "end": 77,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_80@1",
            "content": "For the sake of conciseness, we only report accuracy scores as a proxy for the general disambiguation bias dis-9 Due to time constraints, we only perform this ablation on the English\u2192German model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_80",
            "start": 79,
            "end": 274,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_80@2",
            "content": "played by our models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_80",
            "start": 276,
            "end": 296,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_81@0",
            "content": "While on English\u2192German we observe an improvement of 1%, the performance on English\u2192Spanish decreases by around 0.6%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_81",
            "start": 0,
            "end": 116,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_81@1",
            "content": "We hypothesize that our English\u2192Spanish model might be undertrained, as its accuracy differs by around 10% from OPUS, its direct comparison, while on English\u2192German the difference is only of around 3%.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_81",
            "start": 118,
            "end": 318,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_81@2",
            "content": "We leave further investigation of this issue, including training larger, more capable models, as future work.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_81",
            "start": 320,
            "end": 428,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_82@0",
            "content": "Conclusions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_82",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_83@0",
            "content": "In this paper, we presented a fine-tuning strategy that, by leveraging the explicit sense annotations produced by a novel high-precision technique, effectively reduces the disambiguation bias of a baseline Neural Machine Translation model while at the same time also strengthening translation performances, without introducing any requirement at inference time.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_83",
            "start": 0,
            "end": 360,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_84@0",
            "content": "Our analysis on a strong disambiguation system showed that its ability to disambiguate polysemous nouns is worse than that of a baseline NMT model, at least in the studied out-of-domain setting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_84",
            "start": 0,
            "end": 193,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_85@0",
            "content": "We believe that this work paves the way for better bias reduction techniques in MT, while also fostering interest in the issue represented by the disambiguation bias.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_85",
            "start": 0,
            "end": 165,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_85@1",
            "content": "As future work, we plan to further study the ability of NMT models to perform Word Sense Disambiguation and to strengthen research at the intersection of these two fields, with a view to building stronger and more reliable models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_85",
            "start": 167,
            "end": 396,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_85@2",
            "content": "sense, whereas its adversarial counterpart is flipped to the sense cluster the adjective points to.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_85",
            "start": 398,
            "end": 496,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_85@3",
            "content": "The goal of this task is to measure how sensitive the model is to the insertion of terms that are usually associated with another sense cluster during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_85",
            "start": 498,
            "end": 657,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_86@0",
            "content": "Our work is based on the assumption that providing a neural model with sense annotations for ambiguous words helps in disambiguating them.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_86",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_86@1",
            "content": "While this is rather intuitive, and has been shown to be the case in previous works (Nguyen et al., 2018;Pu et al., 2018b), we test this hypothesis in our setting by training an NMT model, from scratch, with sense-enhanced sentences only (see \u00a7 3.3 for details).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_86",
            "start": 139,
            "end": 400,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_86@2",
            "content": "We train a model comparable with the Baseline (i.e., same architecture and hyperparameters) on the English\u2192German training set ( \u00a7 4.2), and observe that it achieves higher BLEU scores than the Baseline (which is trained on the same data but with plain sentences).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_86",
            "start": 402,
            "end": 665,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_86@3",
            "content": "For instance, the senseenhanced model achieves a BLEU score of 27.22 on WMT14 and 36.79 on WMT19, with the first being a statistically significant improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_86",
            "start": 667,
            "end": 825,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_86@4",
            "content": "This confirms, once again, that sense-enhanced NMT models are on par or better than plain NMT models, although they introduce the heavy requirement of WSD at inference time, which our work aims at dropping.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_86",
            "start": 827,
            "end": 1032,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_87@0",
            "content": "Preprocessing Times The preprocessing of the datasets needed to apply Annotation Refinement (lemmatization, Part-of-Speech tagging and then disambiguation through EWISER) required around 4 days in total on an RTX 2080 Ti (roughly 3M sentences per day).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_87",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_88@0",
            "content": "Training infrastructure and duration All our experiments were carried out on either an NVIDIA RTX 2080 Ti or a RTX 3090, depending on availability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_88",
            "start": 0,
            "end": 146,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_89@0",
            "content": "Model training required on average 4 days on a 3090, 7 days on a 2080 Ti.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_89",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_89@1",
            "content": "Fine-tuning epochs required around 10 hours each (on a 3090), with most finishing due to early stopping before the end of the second epoch.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_89",
            "start": 74,
            "end": 212,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_90@0",
            "content": "MarianMT models available on Hugging-Face Transformers (Wolf et al., 2020) (e.g., for EN\u2192DE, the model name is Helsinki-NLP/opus-mt-en-de).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_90",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_91@0",
            "content": "For For the fine-tuning stage we added ARES (frozen), thus adding a number of parameters equal to ARES's size (1536) times the number of unique synsets in the dataset (refer to Table 6 for approximate numbers).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_91",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_91@1",
            "content": "We also added a trainable projection layer of size 1536 * 512 (512 is the Transformer's hidden dimension), thus adding 786k trainable parameters (which we drop after the finetuning).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_91",
            "start": 211,
            "end": 392,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_92@0",
            "content": "Model training hyperparameters Similarly to (Emelin et al., 2020), we trained it on the entire dataset for a max of 100,000 steps with approximately 24k tokens per batch, label smoothing at 0.1 and an inverse square root learning rate scheduler with 4000 warmup steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_92",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_92@1",
            "content": "As optimizer, we used Adam (Kingma and Ba, 2015) with betas (0.99, 0.98) and learning rate 7 \u2022 10 \u22124 , additionally employing an early stopping strategy with patience 5, monitoring the BLEU score on a validation set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_92",
            "start": 269,
            "end": 484,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_92@2",
            "content": "We produced translations at inference time using a beam size of 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_92",
            "start": 486,
            "end": 551,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_93@0",
            "content": "Fine-tuning hyperparameters For the finetuning, we resumed training using the weights of the baseline models, changed the learning to 1 \u2022 10 \u22125 and reduced the warmup to 1000 steps; additionally, we evaluated the model every 10% of the fine-tuning steps rather than after each epoch, as we observed fast convergence during fine-tuning and multiple epochs were superfluous.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_93",
            "start": 0,
            "end": 371,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_94@0",
            "content": "Table 5 reports the same results displayed in the paper, but includes the percentage of Correct translations for both challenge sets as well as the percentage of errors made from sentences that, after the injection of the adversarial adjectives, were translated into a sense that was neither the correct one, nor the one targeted by the adversarial injection (i.e., other).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_94",
            "start": 0,
            "end": 372,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_95@0",
            "content": "Our work focuses on reducing the disambiguation biases picked up by NMT models during training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_95",
            "start": 0,
            "end": 94,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_95@1",
            "content": "We acknowledge some limitations in our work:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_95",
            "start": 96,
            "end": 139,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_96@0",
            "content": "1. Due to limited computational budget and the large number of resources required to train and fine-tune NMT models from scratch, we had to limit ourselves to one run per experiment, though, despite this, the consistency across languages seems to point to the empirical correctness of the claims.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_96",
            "start": 0,
            "end": 295,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_97@0",
            "content": "2. We evaluated the bias reduction explicitly only on the English\u2192German language pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_97",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_97@1",
            "content": "The reason for this was twofold: first, the datasets introduced by Emelin et al. (2020) only cover said pair, and require the accompanying training data be used in order to fully exploit the co-occurrences (and hence the biases) that the model is evaluated upon; second, upon manual inspection, we found that MuCoW (Raganato et al., 2019) contains many irrelevant candidates in its translation suite, and is in general very strongly affected by the noisy nature of BabelNet.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_97",
            "start": 88,
            "end": 561,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_98@0",
            "content": "3. Our pipeline is strictly tied to both the accuracy of the multilingual WSD system employed and by the coverage of the underlying sense inventory.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_98",
            "start": 0,
            "end": 147,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_98@1",
            "content": "While EWISER and Babel-Net work reasonably well for high-resource languages, the quality of the annotated corpus might decrease for low-resource ones.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_98",
            "start": 149,
            "end": 298,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_99@0",
            "content": "Edoardo Barba, Tommaso Pasini, Roberto Navigli, ESC: Redesigning WSD with extractive sense comprehension, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_99",
            "start": 0,
            "end": 305,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_100@0",
            "content": "Edoardo Barba, Luigi Procopio, Niccol\u00f2 Campolungo, Tommaso Pasini, Roberto Navigli, Mu-LaN: Multilingual label propagatioN for word sense disambiguation, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_100",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_101@0",
            "content": "Michele Bevilacqua, Roberto Navigli, Breaking through the 80% glass ceiling: Raising the state of the art in word sense disambiguation by incorporating knowledge graph information, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_101",
            "start": 0,
            "end": 317,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_102@0",
            "content": "Michele Bevilacqua, Tommaso Pasini, Alessandro Raganato, Roberto Navigli, Recent trends in word sense disambiguation: A survey, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_102",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_103@0",
            "content": "Terra Blevins, Luke Zettlemoyer, Moving down the long tail of word sense disambiguation with gloss informed bi-encoders, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_103",
            "start": 0,
            "end": 265,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_104@0",
            "content": "Giulia Bonansinga, Francis Bond, Multilingual sense intersection in a parallel corpus with diverse language families, 2016, Proceedings of the 8th, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_104",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_105@0",
            "content": "UNKNOWN, None, , Global WordNet Conference (GWC), Global Wordnet Association.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_105",
            "start": 0,
            "end": 76,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_106@0",
            "content": "Jos\u00e9 Camacho-Collados, Mohammad Taher Pilehvar, Roberto Navigli, NASARI: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entities, 2016, Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_106",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_107@0",
            "content": "Niccol\u00f2 Campolungo, Federico Martelli, Francesco Saina, Roberto Navigli, DiBiMT: A Novel Benchmark for Measuring Word Sense Disambiguation Biases in Machine Translation, 2022, Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics, Ireland. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_107",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_108@0",
            "content": "Marine Carpuat, Dekai Wu, Word sense disambiguation vs. statistical machine translation, 2005, Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL'05), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_108",
            "start": 0,
            "end": 234,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_109@0",
            "content": "Marine Carpuat, Dekai Wu, Improving statistical machine translation using word sense disambiguation, 2007, Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_109",
            "start": 0,
            "end": 300,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_110@0",
            "content": "Christopher Clark, Mark Yatskar, Luke Zettlemoyer, Don't take the easy way out: Ensemble based methods for avoiding known dataset biases, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_110",
            "start": 0,
            "end": 362,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_111@0",
            "content": "Simone Conia, Roberto Navigli, Framing word sense disambiguation as a multi-label problem for model-agnostic knowledge integration, 2021, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_111",
            "start": 0,
            "end": 309,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_112@0",
            "content": "Claudio Bovi, Jose Camacho-Collados, Alessandro Raganato, Roberto Navigli, Eu-roSense: Automatic harvesting of multilingual sense annotations from parallel text, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_112",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_113@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_113",
            "start": 0,
            "end": 335,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_114@0",
            "content": "Chris Dyer, Victor Chahuneau, Noah Smith, A simple, fast, and effective reparameterization of IBM model 2, 2013, Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_114",
            "start": 0,
            "end": 298,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_115@0",
            "content": "Denis Emelin, Ivan Titov, Rico Sennrich, Widening the representation bottleneck in neural machine translation with lexical shortcuts, 2019, Proceedings of the Fourth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_115",
            "start": 0,
            "end": 201,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_116@0",
            "content": "Denis Emelin, Ivan Titov, Rico Sennrich, Detecting word sense disambiguation biases in machine translation for model-agnostic adversarial attacks, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_116",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_117@0",
            "content": "Viktor Hangya, Qianchu Liu, Dario Stojanovski, Alexander Fraser, Anna Korhonen, Improving machine translation of rare and unseen word senses, 2021, Proceedings of the Sixth Conference on Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_117",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_118@0",
            "content": "He He, Sheng Zha, Haohan Wang, Unlearn dataset bias in natural language inference by fitting the residual, 2019, Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_118",
            "start": 0,
            "end": 236,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_119@0",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2015-05-07, 3rd International Conference on Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_119",
            "start": 0,
            "end": 145,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_120@0",
            "content": "Philipp Koehn, Statistical significance tests for machine translation evaluation, 2004, Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_120",
            "start": 0,
            "end": 217,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_121@0",
            "content": "UNKNOWN, None, 1951, On information and sufficiency. The annals of mathematical statistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_121",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_122@0",
            "content": "Helen Langone, Benjamin Haskell, George Miller, Annotating WordNet, 2004, Proceedings of the Workshop Frontiers in Corpus Annotation at HLT-NAACL 2004, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_122",
            "start": 0,
            "end": 152,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_123@0",
            "content": "Frederick Liu, Han Lu, Graham Neubig, Handling homographs in neural machine translation, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_123",
            "start": 0,
            "end": 250,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_124@0",
            "content": "Daniel Loureiro, Al\u00edpio Jorge, Language modelling makes sense: Propagating representations through WordNet for full-coverage word sense disambiguation, 2019, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_124",
            "start": 0,
            "end": 288,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_125@0",
            "content": "Yixing Luan, Bradley Hauer, Lili Mou, Grzegorz Kondrak, Improving word sense disambiguation with translations, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_125",
            "start": 0,
            "end": 254,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_126@0",
            "content": "Massimiliano Mancini, Jose Camacho-Collados, Ignacio Iacobacci, Roberto Navigli, Embedding words and senses together via joint knowledgeenhanced training, 2017, Proceedings of the 21st Conference on Computational Natural Language Learning, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_126",
            "start": 0,
            "end": 281,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_127@0",
            "content": "Quinn Mcnemar, Note on the sampling error of the difference between correlated proportions or percentages, 1947, Psychometrika, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_127",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_128@0",
            "content": "George Miller, R Beckwith, Christiane Fellbaum, D Gross, K Miller, WordNet: an online lexical database, 1990, Int. J. Lexicogr, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_128",
            "start": 0,
            "end": 128,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_129@0",
            "content": "George Miller, Claudia Leacock, Randee Tengi, Ross Bunker, A semantic concordance, 1993, Proc. of the Workshop on Human Language Technology, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_129",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_130@0",
            "content": "Roberto Navigli, Michele Bevilacqua, Simone Conia, Dario Montagnini, Francesco Cecconi, Ten years of BabelNet: A survey, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_130",
            "start": 0,
            "end": 225,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_131@0",
            "content": "Roberto Navigli, Simone Ponzetto, Ba-belNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network, 2012, Artificial intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_131",
            "start": 0,
            "end": 181,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_132@0",
            "content": "Quang-Phuoc Nguyen, Anh-Dung Vo, Joon-Choul Shin, Cheol-Young Ock, Effect of word sense disambiguation on neural machine translation: A case study in korean, 2018, IEEE Access, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_132",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_133@0",
            "content": "Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Bleu: a method for automatic evaluation of machine translation, 2002, Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_133",
            "start": 0,
            "end": 257,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_134@0",
            "content": "Matt Post, A call for clarity in reporting BLEU scores, 2018, Proceedings of the Third Conference on Machine Translation: Research Papers, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_134",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_135@0",
            "content": "Luigi Procopio, Edoardo Barba, Federico Martelli, Roberto Navigli, MultiMirror: Neural crosslingual word alignment for multilingual word sense disambiguation, 2021, Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence, IJCAI-21, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_135",
            "start": 0,
            "end": 263,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_136@0",
            "content": "Xiao Pu, Nikolaos Pappas, James Henderson, Andrei Popescu-Belis, Integrating weakly supervised word sense disambiguation into neural machine translation, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_136",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_137@0",
            "content": "Xiao Pu, Nikolaos Pappas, James Henderson, Andrei Popescu-Belis, Integrating weakly supervised word sense disambiguation into neural machine translation, 2018, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_137",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_138@0",
            "content": "Peng Qi, Yuhao Zhang, Yuhui Zhang, Jason Bolton, Christopher Manning, Stanza: A python natural language processing toolkit for many human languages, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_138",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_139@0",
            "content": "Alessandro Raganato, Yves Scherrer, J\u00f6rg Tiedemann, The MuCoW test suite at WMT 2019: Automatically harvested multilingual contrastive word sense disambiguation test sets for machine translation, 2019, Proceedings of the Fourth Conference on Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_139",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_140@0",
            "content": "Annette Rios Gonzales, Laura Mascarell, Rico Sennrich, Improving word sense disambiguation in neural machine translation with sense embeddings, 2017, Proceedings of the Second Conference on Machine Translation, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_140",
            "start": 0,
            "end": 252,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_141@0",
            "content": "Bianca Scarlini, Tommaso Pasini, Roberto Navigli, Sense-annotated corpora for word sense disambiguation in multiple languages and domains, 2020, Proceedings of the 12th Language Resources and Evaluation Conference, European Language Resources Association.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_141",
            "start": 0,
            "end": 254,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_142@0",
            "content": "Bianca Scarlini, Tommaso Pasini, Roberto Navigli, With more contexts comes better performance: Contextualized sense embeddings for allround word sense disambiguation, 2020, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_142",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_143@0",
            "content": "Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary, Jiatao Gu, Angela Fan, Multilingual translation from denoising pre-training, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_143",
            "start": 0,
            "end": 239,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_144@0",
            "content": "J\u00f6rg Tiedemann, Santhosh Thottingal, OPUS-MT -building open translation services for the world, 2020, Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_144",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_145@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, Illia Kaiser,  Polosukhin, Attention is all you need, 2017, Advances in Neural Information Processing Systems, Curran Associates, Inc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_145",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_146@0",
            "content": "David Vickrey, Luke Biewald, Marc Teyssier, Daphne Koller, Word-sense disambiguation for machine translation, 2005, Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_146",
            "start": 0,
            "end": 277,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_147@0",
            "content": "Xinyi Wang, Sebastian Ruder, Graham Neubig, Multi-view subword regularization, 2021, Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_147",
            "start": 0,
            "end": 229,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_148@0",
            "content": "Zikang Wang, Linjing Li, Daniel Zeng, Knowledge-enhanced natural language inference based on knowledge graphs, 2020, Proceedings of the 28th International Conference on Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_148",
            "start": 0,
            "end": 196,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_149@0",
            "content": "UNKNOWN, None, 1949, Translation. Machine Translation of Languages: Fourteen Essays, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_149",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_150@0",
            "content": "UNKNOWN, None, , , .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_150",
            "start": 0,
            "end": 19,
            "label": {}
        },
        {
            "ix": "200-ARR_v2_151@0",
            "content": "UNKNOWN, None, , Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "200-ARR_v2_151",
            "start": 0,
            "end": 177,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_1",
            "tgt_ix": "200-ARR_v2_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_1",
            "tgt_ix": "200-ARR_v2_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_2",
            "tgt_ix": "200-ARR_v2_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_4",
            "tgt_ix": "200-ARR_v2_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_5",
            "tgt_ix": "200-ARR_v2_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_6",
            "tgt_ix": "200-ARR_v2_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_7",
            "tgt_ix": "200-ARR_v2_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_8",
            "tgt_ix": "200-ARR_v2_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_9",
            "tgt_ix": "200-ARR_v2_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_10",
            "tgt_ix": "200-ARR_v2_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_11",
            "tgt_ix": "200-ARR_v2_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_12",
            "tgt_ix": "200-ARR_v2_13",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_14",
            "tgt_ix": "200-ARR_v2_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_16",
            "tgt_ix": "200-ARR_v2_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_17",
            "tgt_ix": "200-ARR_v2_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_18",
            "tgt_ix": "200-ARR_v2_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_19",
            "tgt_ix": "200-ARR_v2_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_21",
            "tgt_ix": "200-ARR_v2_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_20",
            "tgt_ix": "200-ARR_v2_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_20",
            "tgt_ix": "200-ARR_v2_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_20",
            "tgt_ix": "200-ARR_v2_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_20",
            "tgt_ix": "200-ARR_v2_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_22",
            "tgt_ix": "200-ARR_v2_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_23",
            "tgt_ix": "200-ARR_v2_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_23",
            "tgt_ix": "200-ARR_v2_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_20",
            "tgt_ix": "200-ARR_v2_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_24",
            "tgt_ix": "200-ARR_v2_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_26",
            "tgt_ix": "200-ARR_v2_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_27",
            "tgt_ix": "200-ARR_v2_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_28",
            "tgt_ix": "200-ARR_v2_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_29",
            "tgt_ix": "200-ARR_v2_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_31",
            "tgt_ix": "200-ARR_v2_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_32",
            "tgt_ix": "200-ARR_v2_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_33",
            "tgt_ix": "200-ARR_v2_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_34",
            "tgt_ix": "200-ARR_v2_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_35",
            "tgt_ix": "200-ARR_v2_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_30",
            "tgt_ix": "200-ARR_v2_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_20",
            "tgt_ix": "200-ARR_v2_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_36",
            "tgt_ix": "200-ARR_v2_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_39",
            "tgt_ix": "200-ARR_v2_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_40",
            "tgt_ix": "200-ARR_v2_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_38",
            "tgt_ix": "200-ARR_v2_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_42",
            "tgt_ix": "200-ARR_v2_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_43",
            "tgt_ix": "200-ARR_v2_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_44",
            "tgt_ix": "200-ARR_v2_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_45",
            "tgt_ix": "200-ARR_v2_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_41",
            "tgt_ix": "200-ARR_v2_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_46",
            "tgt_ix": "200-ARR_v2_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_47",
            "tgt_ix": "200-ARR_v2_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_47",
            "tgt_ix": "200-ARR_v2_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_49",
            "tgt_ix": "200-ARR_v2_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_48",
            "tgt_ix": "200-ARR_v2_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_48",
            "tgt_ix": "200-ARR_v2_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_48",
            "tgt_ix": "200-ARR_v2_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_47",
            "tgt_ix": "200-ARR_v2_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_50",
            "tgt_ix": "200-ARR_v2_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_52",
            "tgt_ix": "200-ARR_v2_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_53",
            "tgt_ix": "200-ARR_v2_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_55",
            "tgt_ix": "200-ARR_v2_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_56",
            "tgt_ix": "200-ARR_v2_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_54",
            "tgt_ix": "200-ARR_v2_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_47",
            "tgt_ix": "200-ARR_v2_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_57",
            "tgt_ix": "200-ARR_v2_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_59",
            "tgt_ix": "200-ARR_v2_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_58",
            "tgt_ix": "200-ARR_v2_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_58",
            "tgt_ix": "200-ARR_v2_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_58",
            "tgt_ix": "200-ARR_v2_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_60",
            "tgt_ix": "200-ARR_v2_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_62",
            "tgt_ix": "200-ARR_v2_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_64",
            "tgt_ix": "200-ARR_v2_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_63",
            "tgt_ix": "200-ARR_v2_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_63",
            "tgt_ix": "200-ARR_v2_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_63",
            "tgt_ix": "200-ARR_v2_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_65",
            "tgt_ix": "200-ARR_v2_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_66",
            "tgt_ix": "200-ARR_v2_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_66",
            "tgt_ix": "200-ARR_v2_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_67",
            "tgt_ix": "200-ARR_v2_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_69",
            "tgt_ix": "200-ARR_v2_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_70",
            "tgt_ix": "200-ARR_v2_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_68",
            "tgt_ix": "200-ARR_v2_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_68",
            "tgt_ix": "200-ARR_v2_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_68",
            "tgt_ix": "200-ARR_v2_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_68",
            "tgt_ix": "200-ARR_v2_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_71",
            "tgt_ix": "200-ARR_v2_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_72",
            "tgt_ix": "200-ARR_v2_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_72",
            "tgt_ix": "200-ARR_v2_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_73",
            "tgt_ix": "200-ARR_v2_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_75",
            "tgt_ix": "200-ARR_v2_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_74",
            "tgt_ix": "200-ARR_v2_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_74",
            "tgt_ix": "200-ARR_v2_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_74",
            "tgt_ix": "200-ARR_v2_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_77",
            "tgt_ix": "200-ARR_v2_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_74",
            "tgt_ix": "200-ARR_v2_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_74",
            "tgt_ix": "200-ARR_v2_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_76",
            "tgt_ix": "200-ARR_v2_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_78",
            "tgt_ix": "200-ARR_v2_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_80",
            "tgt_ix": "200-ARR_v2_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_79",
            "tgt_ix": "200-ARR_v2_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_79",
            "tgt_ix": "200-ARR_v2_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_79",
            "tgt_ix": "200-ARR_v2_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_81",
            "tgt_ix": "200-ARR_v2_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_83",
            "tgt_ix": "200-ARR_v2_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_84",
            "tgt_ix": "200-ARR_v2_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_85",
            "tgt_ix": "200-ARR_v2_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_87",
            "tgt_ix": "200-ARR_v2_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_88",
            "tgt_ix": "200-ARR_v2_89",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_89",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_86",
            "tgt_ix": "200-ARR_v2_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_90",
            "tgt_ix": "200-ARR_v2_91",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_91",
            "tgt_ix": "200-ARR_v2_92",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_92",
            "tgt_ix": "200-ARR_v2_93",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_90",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_91",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_92",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_93",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_89",
            "tgt_ix": "200-ARR_v2_90",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_94",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_93",
            "tgt_ix": "200-ARR_v2_94",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_95",
            "tgt_ix": "200-ARR_v2_96",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_96",
            "tgt_ix": "200-ARR_v2_97",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_97",
            "tgt_ix": "200-ARR_v2_98",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_95",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_96",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_97",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_98",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_94",
            "tgt_ix": "200-ARR_v2_95",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "200-ARR_v2_0",
            "tgt_ix": "200-ARR_v2_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_1",
            "tgt_ix": "200-ARR_v2_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_2",
            "tgt_ix": "200-ARR_v2_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_2",
            "tgt_ix": "200-ARR_v2_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_2",
            "tgt_ix": "200-ARR_v2_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_3",
            "tgt_ix": "200-ARR_v2_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_4",
            "tgt_ix": "200-ARR_v2_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_4",
            "tgt_ix": "200-ARR_v2_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_4",
            "tgt_ix": "200-ARR_v2_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_4",
            "tgt_ix": "200-ARR_v2_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_4",
            "tgt_ix": "200-ARR_v2_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_5",
            "tgt_ix": "200-ARR_v2_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_5",
            "tgt_ix": "200-ARR_v2_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_6",
            "tgt_ix": "200-ARR_v2_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_6",
            "tgt_ix": "200-ARR_v2_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_7",
            "tgt_ix": "200-ARR_v2_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_7",
            "tgt_ix": "200-ARR_v2_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_7",
            "tgt_ix": "200-ARR_v2_7@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_8",
            "tgt_ix": "200-ARR_v2_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_9",
            "tgt_ix": "200-ARR_v2_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_9",
            "tgt_ix": "200-ARR_v2_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_10",
            "tgt_ix": "200-ARR_v2_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_11",
            "tgt_ix": "200-ARR_v2_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_12",
            "tgt_ix": "200-ARR_v2_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_13",
            "tgt_ix": "200-ARR_v2_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_14",
            "tgt_ix": "200-ARR_v2_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_14",
            "tgt_ix": "200-ARR_v2_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_14",
            "tgt_ix": "200-ARR_v2_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_14",
            "tgt_ix": "200-ARR_v2_14@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_14",
            "tgt_ix": "200-ARR_v2_14@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_15",
            "tgt_ix": "200-ARR_v2_15@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_16",
            "tgt_ix": "200-ARR_v2_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_16",
            "tgt_ix": "200-ARR_v2_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_17",
            "tgt_ix": "200-ARR_v2_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_17",
            "tgt_ix": "200-ARR_v2_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_18",
            "tgt_ix": "200-ARR_v2_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_18",
            "tgt_ix": "200-ARR_v2_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_18",
            "tgt_ix": "200-ARR_v2_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_19",
            "tgt_ix": "200-ARR_v2_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_19",
            "tgt_ix": "200-ARR_v2_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_20",
            "tgt_ix": "200-ARR_v2_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_21",
            "tgt_ix": "200-ARR_v2_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_21",
            "tgt_ix": "200-ARR_v2_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_21",
            "tgt_ix": "200-ARR_v2_21@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_21",
            "tgt_ix": "200-ARR_v2_21@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_21",
            "tgt_ix": "200-ARR_v2_21@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_22",
            "tgt_ix": "200-ARR_v2_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_22",
            "tgt_ix": "200-ARR_v2_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_23",
            "tgt_ix": "200-ARR_v2_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_24",
            "tgt_ix": "200-ARR_v2_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_24",
            "tgt_ix": "200-ARR_v2_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_24",
            "tgt_ix": "200-ARR_v2_24@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_24",
            "tgt_ix": "200-ARR_v2_24@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_24",
            "tgt_ix": "200-ARR_v2_24@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_24",
            "tgt_ix": "200-ARR_v2_24@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_25",
            "tgt_ix": "200-ARR_v2_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_26",
            "tgt_ix": "200-ARR_v2_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_26",
            "tgt_ix": "200-ARR_v2_26@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_26",
            "tgt_ix": "200-ARR_v2_26@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_26",
            "tgt_ix": "200-ARR_v2_26@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_26",
            "tgt_ix": "200-ARR_v2_26@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_27",
            "tgt_ix": "200-ARR_v2_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_28",
            "tgt_ix": "200-ARR_v2_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_29",
            "tgt_ix": "200-ARR_v2_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_29",
            "tgt_ix": "200-ARR_v2_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_29",
            "tgt_ix": "200-ARR_v2_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_29",
            "tgt_ix": "200-ARR_v2_29@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_29",
            "tgt_ix": "200-ARR_v2_29@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_29",
            "tgt_ix": "200-ARR_v2_29@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_30",
            "tgt_ix": "200-ARR_v2_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_30",
            "tgt_ix": "200-ARR_v2_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_31",
            "tgt_ix": "200-ARR_v2_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_32",
            "tgt_ix": "200-ARR_v2_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_33",
            "tgt_ix": "200-ARR_v2_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_34",
            "tgt_ix": "200-ARR_v2_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_35",
            "tgt_ix": "200-ARR_v2_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_36",
            "tgt_ix": "200-ARR_v2_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_37",
            "tgt_ix": "200-ARR_v2_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_38",
            "tgt_ix": "200-ARR_v2_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_38",
            "tgt_ix": "200-ARR_v2_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_38",
            "tgt_ix": "200-ARR_v2_38@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_39",
            "tgt_ix": "200-ARR_v2_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_40",
            "tgt_ix": "200-ARR_v2_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_41",
            "tgt_ix": "200-ARR_v2_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_41",
            "tgt_ix": "200-ARR_v2_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_41",
            "tgt_ix": "200-ARR_v2_41@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_41",
            "tgt_ix": "200-ARR_v2_41@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_41",
            "tgt_ix": "200-ARR_v2_41@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_42",
            "tgt_ix": "200-ARR_v2_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_43",
            "tgt_ix": "200-ARR_v2_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_44",
            "tgt_ix": "200-ARR_v2_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_45",
            "tgt_ix": "200-ARR_v2_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_46",
            "tgt_ix": "200-ARR_v2_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_46",
            "tgt_ix": "200-ARR_v2_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_47",
            "tgt_ix": "200-ARR_v2_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_48",
            "tgt_ix": "200-ARR_v2_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_49",
            "tgt_ix": "200-ARR_v2_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_49",
            "tgt_ix": "200-ARR_v2_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_49",
            "tgt_ix": "200-ARR_v2_49@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_50",
            "tgt_ix": "200-ARR_v2_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_50",
            "tgt_ix": "200-ARR_v2_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_50",
            "tgt_ix": "200-ARR_v2_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_50",
            "tgt_ix": "200-ARR_v2_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_50",
            "tgt_ix": "200-ARR_v2_50@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_51",
            "tgt_ix": "200-ARR_v2_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_52",
            "tgt_ix": "200-ARR_v2_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_52",
            "tgt_ix": "200-ARR_v2_52@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_52",
            "tgt_ix": "200-ARR_v2_52@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_52",
            "tgt_ix": "200-ARR_v2_52@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_53",
            "tgt_ix": "200-ARR_v2_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_53",
            "tgt_ix": "200-ARR_v2_53@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_53",
            "tgt_ix": "200-ARR_v2_53@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_53",
            "tgt_ix": "200-ARR_v2_53@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_53",
            "tgt_ix": "200-ARR_v2_53@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_54",
            "tgt_ix": "200-ARR_v2_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_54",
            "tgt_ix": "200-ARR_v2_54@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_55",
            "tgt_ix": "200-ARR_v2_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_55",
            "tgt_ix": "200-ARR_v2_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_55",
            "tgt_ix": "200-ARR_v2_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_56",
            "tgt_ix": "200-ARR_v2_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_56",
            "tgt_ix": "200-ARR_v2_56@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_56",
            "tgt_ix": "200-ARR_v2_56@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_56",
            "tgt_ix": "200-ARR_v2_56@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_57",
            "tgt_ix": "200-ARR_v2_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_58",
            "tgt_ix": "200-ARR_v2_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_59",
            "tgt_ix": "200-ARR_v2_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_60",
            "tgt_ix": "200-ARR_v2_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_60",
            "tgt_ix": "200-ARR_v2_60@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_61",
            "tgt_ix": "200-ARR_v2_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_62",
            "tgt_ix": "200-ARR_v2_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_62",
            "tgt_ix": "200-ARR_v2_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_63",
            "tgt_ix": "200-ARR_v2_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_64",
            "tgt_ix": "200-ARR_v2_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_65",
            "tgt_ix": "200-ARR_v2_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_66",
            "tgt_ix": "200-ARR_v2_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_67",
            "tgt_ix": "200-ARR_v2_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_67",
            "tgt_ix": "200-ARR_v2_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_68",
            "tgt_ix": "200-ARR_v2_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_69",
            "tgt_ix": "200-ARR_v2_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_69",
            "tgt_ix": "200-ARR_v2_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_70",
            "tgt_ix": "200-ARR_v2_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_70",
            "tgt_ix": "200-ARR_v2_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_71",
            "tgt_ix": "200-ARR_v2_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_71",
            "tgt_ix": "200-ARR_v2_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_71",
            "tgt_ix": "200-ARR_v2_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_71",
            "tgt_ix": "200-ARR_v2_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_71",
            "tgt_ix": "200-ARR_v2_71@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_72",
            "tgt_ix": "200-ARR_v2_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_73",
            "tgt_ix": "200-ARR_v2_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_73",
            "tgt_ix": "200-ARR_v2_73@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_73",
            "tgt_ix": "200-ARR_v2_73@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_74",
            "tgt_ix": "200-ARR_v2_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_75",
            "tgt_ix": "200-ARR_v2_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_75",
            "tgt_ix": "200-ARR_v2_75@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_75",
            "tgt_ix": "200-ARR_v2_75@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_76",
            "tgt_ix": "200-ARR_v2_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_76",
            "tgt_ix": "200-ARR_v2_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_76",
            "tgt_ix": "200-ARR_v2_76@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_77",
            "tgt_ix": "200-ARR_v2_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_77",
            "tgt_ix": "200-ARR_v2_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_77",
            "tgt_ix": "200-ARR_v2_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_78",
            "tgt_ix": "200-ARR_v2_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_78",
            "tgt_ix": "200-ARR_v2_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_79",
            "tgt_ix": "200-ARR_v2_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_80",
            "tgt_ix": "200-ARR_v2_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_80",
            "tgt_ix": "200-ARR_v2_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_80",
            "tgt_ix": "200-ARR_v2_80@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_81",
            "tgt_ix": "200-ARR_v2_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_81",
            "tgt_ix": "200-ARR_v2_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_81",
            "tgt_ix": "200-ARR_v2_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_82",
            "tgt_ix": "200-ARR_v2_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_83",
            "tgt_ix": "200-ARR_v2_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_84",
            "tgt_ix": "200-ARR_v2_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_85",
            "tgt_ix": "200-ARR_v2_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_85",
            "tgt_ix": "200-ARR_v2_85@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_85",
            "tgt_ix": "200-ARR_v2_85@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_85",
            "tgt_ix": "200-ARR_v2_85@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_86",
            "tgt_ix": "200-ARR_v2_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_86",
            "tgt_ix": "200-ARR_v2_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_86",
            "tgt_ix": "200-ARR_v2_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_86",
            "tgt_ix": "200-ARR_v2_86@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_86",
            "tgt_ix": "200-ARR_v2_86@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_87",
            "tgt_ix": "200-ARR_v2_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_88",
            "tgt_ix": "200-ARR_v2_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_89",
            "tgt_ix": "200-ARR_v2_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_89",
            "tgt_ix": "200-ARR_v2_89@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_90",
            "tgt_ix": "200-ARR_v2_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_91",
            "tgt_ix": "200-ARR_v2_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_91",
            "tgt_ix": "200-ARR_v2_91@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_92",
            "tgt_ix": "200-ARR_v2_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_92",
            "tgt_ix": "200-ARR_v2_92@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_92",
            "tgt_ix": "200-ARR_v2_92@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_93",
            "tgt_ix": "200-ARR_v2_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_94",
            "tgt_ix": "200-ARR_v2_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_95",
            "tgt_ix": "200-ARR_v2_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_95",
            "tgt_ix": "200-ARR_v2_95@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_96",
            "tgt_ix": "200-ARR_v2_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_97",
            "tgt_ix": "200-ARR_v2_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_97",
            "tgt_ix": "200-ARR_v2_97@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_98",
            "tgt_ix": "200-ARR_v2_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_98",
            "tgt_ix": "200-ARR_v2_98@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_99",
            "tgt_ix": "200-ARR_v2_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_100",
            "tgt_ix": "200-ARR_v2_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_101",
            "tgt_ix": "200-ARR_v2_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_102",
            "tgt_ix": "200-ARR_v2_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_103",
            "tgt_ix": "200-ARR_v2_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_104",
            "tgt_ix": "200-ARR_v2_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_105",
            "tgt_ix": "200-ARR_v2_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_106",
            "tgt_ix": "200-ARR_v2_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_107",
            "tgt_ix": "200-ARR_v2_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_108",
            "tgt_ix": "200-ARR_v2_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_109",
            "tgt_ix": "200-ARR_v2_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_110",
            "tgt_ix": "200-ARR_v2_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_111",
            "tgt_ix": "200-ARR_v2_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_112",
            "tgt_ix": "200-ARR_v2_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_113",
            "tgt_ix": "200-ARR_v2_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_114",
            "tgt_ix": "200-ARR_v2_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_115",
            "tgt_ix": "200-ARR_v2_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_116",
            "tgt_ix": "200-ARR_v2_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_117",
            "tgt_ix": "200-ARR_v2_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_118",
            "tgt_ix": "200-ARR_v2_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_119",
            "tgt_ix": "200-ARR_v2_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_120",
            "tgt_ix": "200-ARR_v2_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_121",
            "tgt_ix": "200-ARR_v2_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_122",
            "tgt_ix": "200-ARR_v2_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_123",
            "tgt_ix": "200-ARR_v2_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_124",
            "tgt_ix": "200-ARR_v2_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_125",
            "tgt_ix": "200-ARR_v2_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_126",
            "tgt_ix": "200-ARR_v2_126@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_127",
            "tgt_ix": "200-ARR_v2_127@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_128",
            "tgt_ix": "200-ARR_v2_128@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_129",
            "tgt_ix": "200-ARR_v2_129@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_130",
            "tgt_ix": "200-ARR_v2_130@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_131",
            "tgt_ix": "200-ARR_v2_131@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_132",
            "tgt_ix": "200-ARR_v2_132@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_133",
            "tgt_ix": "200-ARR_v2_133@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_134",
            "tgt_ix": "200-ARR_v2_134@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_135",
            "tgt_ix": "200-ARR_v2_135@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_136",
            "tgt_ix": "200-ARR_v2_136@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_137",
            "tgt_ix": "200-ARR_v2_137@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_138",
            "tgt_ix": "200-ARR_v2_138@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_139",
            "tgt_ix": "200-ARR_v2_139@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_140",
            "tgt_ix": "200-ARR_v2_140@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_141",
            "tgt_ix": "200-ARR_v2_141@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_142",
            "tgt_ix": "200-ARR_v2_142@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_143",
            "tgt_ix": "200-ARR_v2_143@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_144",
            "tgt_ix": "200-ARR_v2_144@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_145",
            "tgt_ix": "200-ARR_v2_145@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_146",
            "tgt_ix": "200-ARR_v2_146@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_147",
            "tgt_ix": "200-ARR_v2_147@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_148",
            "tgt_ix": "200-ARR_v2_148@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_149",
            "tgt_ix": "200-ARR_v2_149@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_150",
            "tgt_ix": "200-ARR_v2_150@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "200-ARR_v2_151",
            "tgt_ix": "200-ARR_v2_151@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 909,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "doc_id": "200-ARR",
        "version": 2
    }
}