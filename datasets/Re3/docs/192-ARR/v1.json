{
    "nodes": [
        {
            "ix": "192-ARR_v1_0",
            "content": "An Unsupervised Multiple-Task and Multiple-Teacher Model for Cross-lingual Named Entity Recognition",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_2",
            "content": "Cross-lingual named entity recognition task is one of the critical problem for evaluating the potential transfer learning techniques on low resource languages. Knowledge distillation using pre-trained multilingual language models between source and target languages have shown their superiority. However, existing cross-lingual distillation models merely consider the potential transferability between two identical single tasks across both domain. Other possible auxiliary tasks to improve the learning performance have not been fully investigated. In this study, based on the knowledge distillation framework and multitask learning, we introduce the similarity metric model as an auxiliary task to improve the cross-lingual NER performance on target domain. Specifically, an entity recognizer and a similarity evaluator teachers are first trained in parallel from the source domain. Then, two tasks in the student model are supervised by the two teachers simultaneously. Empirical studies on the datasets across 7 different languages confirm the effectiveness of the proposed model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "192-ARR_v1_4",
            "content": "Named entity recognition, NER in short, refers to identifying entity types, i.e. location, person, organization, etc., in a given sentence. The exploiting of deep neural networks, such as Bi-LSTM-CRF (Lample et al., 2016), Bi-LSTM-CNN (Chiu and Nichols, 2016) make this task achieves significant performances. However, since deep neural networks highly relies on a large amount of labelled training data, the annotation acquiring process is expensive and time consuming. This situation is more severe for low-resource languages. With the help of transfer learning (Ruder et al., 2019) and multilingual BERT (short as mBERT) (Devlin et al., 2019), it is possible to transfer the annotated train- NER / NER tea : learned NER model for source language; NER stu : learned NER model for target language; SIM tea learned similarity model for source language; {X, Y } src : labeled data in source language; {X} tgt : unlabeled data in target language; {X, P } tgt : labeled data in target language with probability; {X, S} tgt : labeled data in target language with entity similarity score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_5",
            "content": "ing samples or trained models from a rich-resource domain to a low-resource domain.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_6",
            "content": "Many studies have been done to solve this crosslanguage NER problem. Existing models can be separated into three categories, shared feature space based, translation based and knowledge distillation based. Shared feature space based models exploit language-independent features, which lacks the domain specific features for target language (Tsai et al., 2016;Wu and Dredze, 2019;Keung et al., 2019). Translation based models generate pseudo labeled target language data to train the cross-lingual NER model, but the noise from translation process restrains its performance. (Mayhew et al., 2017;Xie et al., 2018;Wu et al., 2020b). Knowledge distillation based models train a student model using soft labels of the target language (Wu et al., 2020a,b;Liang et al., 2021). Our model is developed on the basis of (Wu et al., 2020a).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_7",
            "content": "Although above mentioned models solve the cross-lingual NER problem in some extent, the auxiliary tasks, as in the multi-task learning, have not been studied in this problem. Due to the distributed representation of natural languages, the relatedness among the embedding of target languages, which is measured by the similarity, can be utilized to further boost the learned encoder and improve the final NER performance on target language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_8",
            "content": "Here we give a concrete example to illustrate the importance of similarity between every two tokens under the situation when only the English data is labeled. Given a Spanish sentence \"Ar\u00e9valo (Avila), 23 may (EFE).\", the token \"Ar\u00e9valo\" is recognized as ORG type using the learned model from English domain. In the meantime, the token \"Ar\u00e9valo\" has high similarity scores with the Spanish tokens \"Viena\" from sentence \"Viena, 23 may (EFE).\", and \"Madrid\" from sentence \"Madrid, 23 may (EFE).\". Also, the tokens \"Viena\" and \"Madrid\" are recognized correctly as LOC type using the same English model mentioned above. Then \"Ar\u00e9valo\" can be recognized correctly as LOC type under the supervisory signal using the similarity between \"Viena\" and \"Madrid\".",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_9",
            "content": "To leverage the similarity between the tokens of the source languages, we design an multiple-task and multiple-teacher model (short as MTMT, as shown in Figure 1), which helps the NER learning process on the target languages. Specifically, we first introduce the knowledge distillation to build entity recognizer and similarity evaluator teachers in the source language and transfer the learned patterns to the student in the target language. In the student model, we then borrow the idea of multitask learning to incorporate a similarity evaluation task as an auxiliary task into the entity recognition classifier. During the student learning process, we input unlabelled samples from the target languages into the entity recognizer and evaluator, and take output pesudo labels as supervisory signals for these two tasks in the student model. Note that a weighting strategy is also provide therein to take into consideration of the reliability of the teachers.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_10",
            "content": "We validate the model performance on the three commonly-used datasets across 7 languages and the experimental results shows the superiority our presented MTMT model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_11",
            "content": "Our main contributions are as follows:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_12",
            "content": "\u2022 We propose an unsupervised knowledge distillation framework for cross-language named entity recognition and develop a teaching and learning procedure under this framework. \u2022 We present a novel multiple-task and multipleteacher model that introduces a entity similarity evaluator to boost the performance of student recognizer on target languages. \u2022 We conduct extensive experiments on seven languages compared with state-of-the-art baselines and the results confirm the effectiveness of the presented model.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_13",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "192-ARR_v1_14",
            "content": "Our approach is closely related to the existing works on cross-lingual NER, knowledge distillation and siamese network.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_15",
            "content": "Cross-Lingual NER aims to extract entities from a target language but assumes only source language is annotated. The existing models can be categorized to: a) Shared feature space based models, b) Translation based models, c) Knowledge distillation based models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_16",
            "content": "Shared feature space based models generally train a language-independent encoder using source and target language data (Tsai et al., 2016). Recently, the pre-trained multilingual language models mBERT is effective to address the challenge (Devlin et al., 2019). Moreover, some research introduces new components on top of the mBERT by directly transferring the model learned from labeled source language to that of target languages (Keung et al., 2019). The performance is still weak due to the lack of annotations of target languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_17",
            "content": "Translation based models generally generate pesudo labeled target data to alleviate target data scarcity. For example, (Wu et al., 2020b;Zhang et al., 2021) gain a improvement by translating the labeled source language to the target language word-by-word. Our model achieves considerable improvement by learning entity similarity in target language data without translation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_18",
            "content": "Knowledge distillation based models includes a teacher model and a student model (Wu et al., 2020c). The teacher model is trained on labeled source language. The student model learns from the soft label predicted by teacher model on unlabeled target language data. Therefore, the student model can capture the extra knowledge about target languages. In our work, the student model not only learns the recognizer teacher knowledge, but also learns the entity similarity knowledge inspired by multi-task learning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_19",
            "content": "Siamese Network is originally introduced by (Bromley et al., 1994) to treat signature verification as a matching problem. It has been successfully applied to transfer learning such as one-shot image recognition (Koch et al., 2015), text similarity (Neculoiu et al., 2016). However, there is a dilemma to adapt siamese network to token-level recognition tasks such as NER. Siamese network assumes the input is a pair, and the output is a similarity score. To handle this issue, we reconstruct the data to pair format. To the best of our knowledge, we are the first to learn the entity similarity by siamese network.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_20",
            "content": "Framework",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "192-ARR_v1_21",
            "content": "In this section, we introduce our framework and its detailed implementation. Our framework is consist of two models: teacher training model learned from source language and teacher-student distillation learning model learned from target language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_22",
            "content": "In the teacher training model, there are two submodels, i.e. an entity recognizer teacher and a similarity evaluator teacher. These two models are two parallel tasks, wherein the entity recognition teacher focuses on identifying the named entities and the similarity evaluator teacher is to decide if two tokens are in the same type.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_23",
            "content": "We then present a teacher-student distillation learning model to learn from the two learned teacher models simultaneously. We note that, in this learning process, such a knowledge distillation makes the student model combine the advantages of both source language patterns of entity recognition and entity similarity evaluation. During the learning process, the samples from target language are fed into the teacher model and the outputs are taken as the supervisory signal for two tasks in the student model. To guarantee the student learning performance, we assign weights for each supervisory signal correspond to the output confidence of teacher sub-models. We argue that the student entity recognition task and the student entity similarity evaluation task improve the representation learning of the student encoder in the siamese structure.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_24",
            "content": "Problem Definition",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "192-ARR_v1_25",
            "content": "Following standard practice, we formulate crosslingual NER as a sequence labeling task. Given a , where x i is the i-th token and y i is the corresponding label of x i . In the source language, we denote the labeled training data as D S train = {(x, y)} and test data as D S test . In the target language, we denote the unlabeled train data as D T train = {x} and the test data as D T test . Formally, our goal is to train a model with D S train and D T train to perform well on D T test .",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_26",
            "content": "Teacher Models",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "192-ARR_v1_27",
            "content": "Here we first consider the training of two teacher models. For every two tokens, we define Entity Similarity Metric as a score which is the probability that two tokens belong to the same entity type. We aim to find entity similarity to help the cross-lingual NER model in target language. It is a non-trivial task since we lack golden labels to help us distinguish target named entities. To address this challenge, we propose a binary classifier called similarity teacher to leverage the labeled source language data for similarity prediction. Our similarity teacher model, inspired by siamese network (Koch et al., 2015), are able to acquires more powerful features via capturing the invariances to transformation in the input space. Figure 2 illustrated the two teacher models training. The following subsections will illustrate the two teacher models sequentially.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_28",
            "content": "Entity Recognizer Teacher",
            "ntype": "title",
            "meta": {
                "section": "3.2.1"
            }
        },
        {
            "ix": "192-ARR_v1_29",
            "content": "Since the cross-lingual NER task, we unitize multilingual mBERT (Wu and Dredze, 2019) as basic sequence feature extractor backbone to derive the sequence embedding representation throughout this paper. And a linear classifier with softmax upon the pre-trained mBERT output. The model network structure could be formulated as,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_30",
            "content": "h = mBERT(x) \u0177i = softmax(W h i + b)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_31",
            "content": "where h = {h i } L i=1 and h i denotes the output of the pretrained mBERT that corresponds to the input token x i . \u0177i denotes the predicted probability distribution for x i . W and b are trainable parameters. For some sentence sample (x, y) \u2208 D S train and an entity token query index i, the loss function is,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_32",
            "content": "L ER (x, y, i) = L CE (y i , \u0177i )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_33",
            "content": "We train this entity recognition teacher model on the source lingual training corpus D S train = {(x, y)} directly.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_34",
            "content": "Siamese Entity Similarity Evaluator",
            "ntype": "title",
            "meta": {
                "section": "3.2.2"
            }
        },
        {
            "ix": "192-ARR_v1_35",
            "content": "In order to leverage the entity similarity to boost the unsupervised cross-lingual NER performance, we will present our entity pairs construction method and the siamese network model in the following.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_36",
            "content": "Entity Similarity Pairs Construction According to entity labels, we randomly select sentences pair < x, x > with their some token pair < x i , x j > and associated labels < y i , y j > in D S train , to form the siamese supervision training dataset, D S\u2212siam train = {(x, x , i, j, t)} where the target t = 1 indicates y i = y j , and 0 otherwise. And the testing entity pairs D S\u2212siam test is constructed likewisely.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_37",
            "content": "Siamese Entity Similarity Network Our similarity backbone model is a siamese neural network with mBERT as feature extraction layer. Wherein h and h represent latent sequences encoding features derived by the two symmetric twins with respect to input sentence x and x respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_38",
            "content": "The inter-entities similarity is measured on the tokens hidden representations h i and h j , queried by the entity indices < i, j > on the sequences representations. The cosine function operator is added to compute on the entity token latent vectors' distance, so as to measure the similarity between each siamese twin, which is fed into a single sigmoid output unit for target t estimation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_39",
            "content": "More precisely, for a specific entity pair (x, x , i, j, t) \u2208 D S\u2212siam train , the siamese network could be formulated as, where cos is the cosine similarity metric function, \u03c3 is the sigmoid activation function, t \u2208 [\u03c3(\u22121), \u03c3(1)] denotes the predicted similarity of two queried tokens pair < x i , x j >. Larger t value indicates higher similarity between the two queried entities tokens.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_40",
            "content": "h =mBERT(x), h = mBERT(x ) t(x, x , i, j) = \u03c3(cos(h i , h j ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_41",
            "content": "The loss function of the similarity prediction can be formulate as,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_42",
            "content": "L SIM (x, x , i, j, t) = L BCE (t, t).",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_43",
            "content": "Finally, we can train the siamese entity similarity evaluator on D S\u2212siam train , and evaluate the performance on test dataset D S\u2212siam test . Together with entity recognizer model, this entity similarity evaluator are used as teachers in following knowledge distillation learning process, and transfer knowledge from source to target lingual corpus.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_44",
            "content": "Teacher Student Distillation Learning",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "192-ARR_v1_45",
            "content": "In this section, we consider to transfer the named entity type and similarity knowledge learned on labeled source language corpus to unlabeled target language NER task. To this end, we propose a knowledge distillation learning process to train a target language student NER model with its supervisory signals mimicked by the entity type prediction probability by the entity recognizer teacher model and entity representation similarity target by the entity siamese similarity evaluator teacher model. Based on the original unlabeled target sentence training data D T train , we again construct unlabeled target-language siamese pairwise entity data D T \u2212sim train = {(x T , x T , i, j)}, with the sentence pair < x T , x T > randomly sample from D T train and the entity token indices pair < i, j > uniformly sampled from the sentences therein.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_46",
            "content": "The multi-lingual BERT is also used as encoder for the sentence siamese pair, and the entity token feature queried from the latent sequence encoding representation. Specifically, for a sentence pair (x T , x T , i, j) \u2208 D T \u2212sim train , the student model transform them as follows,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_47",
            "content": "h T = mBERT(x T ) \u0177T i = softmax(W h T i + b) h T = mBERT(x T ) \u0177 T j = softmax(W h T j + b) tT (x T ,x T , i, j) = \u03c3(cos(h T i , h T j ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_48",
            "content": "Then for a specific sentence pair sample in the target siamese dataset, the student loss function has three breaches, L ER (x T , y S , i), L ER (x T , y S , j), and L SIM (x T , x T , i, j, tS ). Note that supervision information y S , y S , and tS are taught by the three teacher models. Summering over all the samples in D T \u2212sim train = {(x T , x T , i, j)}, the total student model training loss takes form,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_49",
            "content": "L = \u03b3 (x T ,x T ,i,j)\u2208D T \u2212sim train (\u03b1 1 L ER (x T , y S , i) +\u03b1 2 L ER (x T , y S , j) +\u03b2L BCE ( tT (x T , x T , i, j), tS ))",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_50",
            "content": "where \u03b1 1 , \u03b1 2 , \u03b2 and \u03b3 are weights in loss function which are set to make the student model learns less noisy knowledge from teachers. The weights are set as follows: \u03b1 1 (\u03b1 2 ) is an increasing function with respect to the output of the entity recognizer teacher as shown in Figure .4. And \u03b2 is set such that it is high when the output of the entity similarity teacher is close to 0 or 1, and it is low when the output is close to 0.5. \u03b3 indicates consistency level between the outputs from two teacher models, e.g. for two input tokens, if the output from entity similarity teacher is high, and the similarity level computed from the outputs of the entity recognizer teacher is low, then their consistency level is low. We want the student model to learn from the two teachers as follows: the higher the prediction of the entity recognizer teacher is (the further away from 0.5 the prediction of the entity similarity teacher is, the higher the consistency level is), the more accurate the prediction is, thus the more attention the student model pays attention to the input tokens, and vice versa. Therefore, we heuristically devises the three weights scheduling as functions of the inputs,",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_51",
            "content": "\u03b1 (\u2022) = (max(\u0177 T i )) 2 \u03b2 = (2 tT (x T , x T , i, j) \u2212 1) 2 \u03b3 = 1 \u2212 |\u03c3(cos(\u0177 T i , \u0177 T j )) \u2212 tT (x T , x T , i, j)|",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_52",
            "content": "Experiment",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "192-ARR_v1_53",
            "content": "In this section, we evaluate our multiple-task and multiple-teacher model for cross-lingual NER and compare our model with a series of state-of-the-art models.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_54",
            "content": "Dataset",
            "ntype": "title",
            "meta": {
                "section": "4.1"
            }
        },
        {
            "ix": "192-ARR_v1_55",
            "content": "We conducted experiments on three benchmark datasets: CoNLL2002 (Tjong Kim Sang, 2002), CoNLL2003 (Tjong Kim Sang and De Meulder, 2003) and WikiAnn (Pan et al., 2017). CoNLL2002 includes Spanish and Dutch, CoNLL2003 includes English and German, and WikiAnn includes English and three non-western languages: Arabic, Hindi, and Chinese. Each language is divided into a training set, a development set and a test set. All datasets were annotated with four entity types: LOC, MISC, ORG, and PER. Following (Wu and Dredze, 2019), all datasets are annotated using the BIO entity labelling scheme. To imitate the zero-resource cross lingual NER case, following (Wu and Dredze, 2019), we used English as the source language and other languages as the target language. In cross-lingual NER, the training set without entity label of the target language is also available when training the model. We trained the model with the labeled training set of the source language and evaluated the model on the test set of each target language. Table 1 and 2 shows the statistics of all datasets.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_56",
            "content": "Implementation Details",
            "ntype": "title",
            "meta": {
                "section": "4.2"
            }
        },
        {
            "ix": "192-ARR_v1_57",
            "content": "We use PyTorch 1. We set our hyperparameters empirically following (Wu et al., 2020c) with some modifications. We do not freeze any layers and we use the output of the last layer as our hidden feature vector. We set batch size to be 32, maximum sequence length to be 128, dropout rate to be 0.2, and we use Adam as optimizer (Kingma and Ba, 2014). For the training of recognition teacher model and similarity teacher model, we set the learning rate to be 1e-5 and 5e-6 separately. For knowledge distillation, we use a learning rate of 1e-6 for the student models training. Note that if a word is divided into several subwords after tokenization, then only the first subword is considered in the loss function. Following (Tjong Kim Sang, 2002), we use the entity level F1-score as the evaluation metric. Moreover, we conduct each experiment 5 times and report the mean F1-score.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_58",
            "content": "Comparison",
            "ntype": "title",
            "meta": {
                "section": "4.3"
            }
        },
        {
            "ix": "192-ARR_v1_59",
            "content": "Table 3 and 4 report the zero-resource cross-lingual NER results of different models on 6 target languages.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_60",
            "content": "Unitrans (Wu et al., 2020b) unifies a data transfer and model transfer for cross-lingual NER.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_61",
            "content": "AdvPicker proposes a adversarial discriminator for cross-lingual NER. RIKD (Liang et al., 2021) develops a reinforced iterative knowledge distillation for cross-lingual NER.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_62",
            "content": "TOF (Zhang et al., 2021) transfers knowledge from three aspects for cross-lingual NER.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_63",
            "content": "It can be seen that our model outperforms the state-of-the-arts. Specifically, compared with the remarkable RIKD, AdvPicker and Unitrans, which also use knowledge distillation but ignore the entity similarity knowledge, our model obtains significant and consistent improvements in F1-score ranging from 0.23 for German[de] to 6.81 for Arabic [ar]. That demonstrates the benefits of our proposed MTMT model, compared to direct model transfer (Wu and Dredze, 2019).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_64",
            "content": "Note that Bert-f performs better than our model on Chinese dataset due to their re-tokenization of the dataset. Moreover, compared with the latest model TOF, RIKD, Unitrans, our model requires much lower computational costs for both translation and iterative knowledge distillation, meanwhile reaching superior performance. For a fair comparison, we compare our model against the version of TOF w/o continual learning (Zhang et 2021), RIKD w/o IKD (Liang et al., 2021) and Unitrans w/o translation (Wu et al., 2020b) as reported in their paper.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_65",
            "content": "Ablation Study",
            "ntype": "title",
            "meta": {
                "section": "4.4"
            }
        },
        {
            "ix": "192-ARR_v1_66",
            "content": "To demonstrate the effectiveness of our approach, we designed the following ablation studies. Table 5 presents the results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_67",
            "content": "(1) MTST, which combines the multiple-teacher to single-teacher. That is, both of the teacher and student have the same neural network structure. This causes a performance drop across all languages due to two single teachers cannot make a difference with combination.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_68",
            "content": "(2) MTMT w/o weighting, which set the \u03b1 1 ,\u03b1 2 , \u03b2 and \u03b3 all to be 1 in the loss of student model learning. It can be seen that the performance decrease in terms of F1-score ranges from 0.45 for Dutch(nl) to 0.98 for Spanish(es), which validates that weighting loss can bring more confident knowledge to student model.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_69",
            "content": "(3) MTMT w/o similarity, which removes the similarity teacher model. In this case, our approach degrades into the Single Teacher-Student learning model as in TSL (Wu et al., 2020a). Without the similarity knowledge fed into the student model, the performance drops significantly.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_70",
            "content": "Case Study",
            "ntype": "title",
            "meta": {
                "section": "4.5"
            }
        },
        {
            "ix": "192-ARR_v1_71",
            "content": "We give a case study to show that the failed cases of baseline models can be corrected by our model. We try to bring up insights on why the proposed multiple-task and multiple-teacher model works.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_72",
            "content": "The proposed MTMT model can help to correct labels using the Entity Similarity defined in section 3.2. Specifically, if there is a set of tokens in which every two of them have high Entity Similarity score, and one of the tokens is predicted to have a distinct label while other tokens have identical labels, then the one with the distinct label is predicted wrongly and is corrected by the student model to have the label of all other tokens. As shown in Table 6, in example #1, the entity recognizer teacher fails to identify \"Ar\u00e9valo\" as B-ORG type, while the student model can correctly predict it. The reason lies in that the entity recognizer teacher predicts \"Viena\"('Madrid\") as B-LOC type correctly, and the similarity evaluator teacher predicts \"Viena\"(\"Madrid\") to have a high similarity score(0.7157, 0.7156) with \"Ar\u00e9valo\". The student learns from both teachers and predict the correct label for \"Ar\u00e9valo\". Examples #2 and #3 present the same results with different sentences.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_73",
            "content": "Embeddings Distribution",
            "ntype": "title",
            "meta": {
                "section": "4.6"
            }
        },
        {
            "ix": "192-ARR_v1_74",
            "content": "This section investigates the effect of embeddings of the two different teacher models. It can be seen that the embeddings distribution of student model is close to similarity evaluator teacher, as illustrated in Figure 5. We conjecture that the student model captures similarity knowledge from the similarity evaluator teacher, i.e. the same class of examples tend to cluster and the different class of examples tend to segregate in the embeddings distribution. This validates the proposed MTMT model not only transfers cross-lingual NER knowledge from source language, but also learns the similarity knowledge of target language data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_75",
            "content": "Effect of Weights",
            "ntype": "title",
            "meta": {
                "section": "4.7"
            }
        },
        {
            "ix": "192-ARR_v1_76",
            "content": "In the section, we evaluate the effectiveness of the weighting loss in student learning from quantitative perspective. All of the following experiments are conducted on Spanish(es) data.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_77",
            "content": "For \u03b1 analysis, we calculate the F1-score in different probability intervals of entity recognizer teacher, we find that the recognizer teacher tends to predict more correct in higher probability interval, as illustrated in Figure 6a. Therefore, the student model is better suited to target language with learning less low-confidence misrecognitions for the target language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_78",
            "content": "For \u03b2 analysis, we observe that F1-score are increasing with the entity similarity score from 0.5 to both sides 0 and 1 in Figure 6b. The encoder of student model obtains the clustering information of the target language with the help of \u03b2.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_79",
            "content": "For \u03b3 analysis, we consider the consistency of recognition results and similarity score by teachers. The F1-score and similarity score of teachers are all higher in the higher \u03b3 intervals, as shown in Figure 6c. The student model learns less from unreasonable results, and it can make more accuracy entity recognition for the target language.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_80",
            "content": "Conclusion",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "192-ARR_v1_81",
            "content": "In this paper, we propose an unsupervised multipletask and multiple-teacher model for cross-lingual NER. The student model learns two source language patterns of entity recognition and entity similarity evaluation. Moreover, in order to guarantee the student learning performance, we also propose a weighting strategy to take consideration of the reliability of the teachers. Our experimental results show that the proposed model yields significant improvements on six target language datasets and outperforms the existing state-of-the-art approaches.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "192-ARR_v1_82",
            "content": "Jane Bromley, Isabelle Guyon, Yann Lecun, Eduard S\u00e4ckinger, Roopak Shah, Signature verification using a \"siamese\" time delay neural network, 1994, Advances in Neural Information Processing Systems, Morgan-Kaufmann.",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Jane Bromley",
                    "Isabelle Guyon",
                    "Yann Lecun",
                    "Eduard S\u00e4ckinger",
                    "Roopak Shah"
                ],
                "title": "Signature verification using a \"siamese\" time delay neural network",
                "pub_date": "1994",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": "Morgan-Kaufmann"
            }
        },
        {
            "ix": "192-ARR_v1_83",
            "content": "Weile Chen, Huiqiang Jiang, Qianhui Wu, B\u00f6rje Karlsson, Yi Guan, AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Weile Chen",
                    "Huiqiang Jiang",
                    "Qianhui Wu",
                    "B\u00f6rje Karlsson",
                    "Yi Guan"
                ],
                "title": "AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_84",
            "content": "UNKNOWN, None, 2016, Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_85",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Jacob Devlin",
                    "Ming-Wei Chang",
                    "Kenton Lee",
                    "Kristina Toutanova"
                ],
                "title": "BERT: Pre-training of deep bidirectional transformers for language understanding",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "192-ARR_v1_86",
            "content": "Alankar Jain, Bhargavi Paranjape, Zachary , Entity projection via machine translation for cross-lingual NER, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Alankar Jain",
                    "Bhargavi Paranjape",
                    "Zachary "
                ],
                "title": "Entity projection via machine translation for cross-lingual NER",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "192-ARR_v1_87",
            "content": "Phillip Keung, Yichao Lu, Vikas Bhardwaj, Adversarial learning with contextual embeddings for zero-resource cross-lingual classification and NER, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": [
                    "Phillip Keung",
                    "Yichao Lu",
                    "Vikas Bhardwaj"
                ],
                "title": "Adversarial learning with contextual embeddings for zero-resource cross-lingual classification and NER",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_88",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2014, the 3rd International Conference for Learning Representations, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "P Diederik",
                    "Jimmy Kingma",
                    " Ba"
                ],
                "title": "Adam: A method for stochastic optimization",
                "pub_date": "2014",
                "pub_title": "the 3rd International Conference for Learning Representations",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_89",
            "content": "Gregory Koch, Richard Zemel, Ruslan Salakhutdinov, Siamese neural networks for one-shot image recognition, 2015, ICML deep learning workshop, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Gregory Koch",
                    "Richard Zemel",
                    "Ruslan Salakhutdinov"
                ],
                "title": "Siamese neural networks for one-shot image recognition",
                "pub_date": "2015",
                "pub_title": "ICML deep learning workshop",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_90",
            "content": "UNKNOWN, None, 2016, Neural architectures for named entity recognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Neural architectures for named entity recognition",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_91",
            "content": "UNKNOWN, None, , Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": null,
                "title": null,
                "pub_date": null,
                "pub_title": "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "192-ARR_v1_92",
            "content": "Shining Liang, Ming Gong, Jian Pei, Linjun Shou, Wanli Zuo, Xianglin Zuo, Daxin Jiang, Reinforced iterative knowledge distillation for crosslingual named entity recognition, 2021, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery amp; Data Mining, KDD '21, Association for Computing Machinery.",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Shining Liang",
                    "Ming Gong",
                    "Jian Pei",
                    "Linjun Shou",
                    "Wanli Zuo",
                    "Xianglin Zuo",
                    "Daxin Jiang"
                ],
                "title": "Reinforced iterative knowledge distillation for crosslingual named entity recognition",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery amp; Data Mining, KDD '21",
                "pub": "Association for Computing Machinery"
            }
        },
        {
            "ix": "192-ARR_v1_93",
            "content": "Stephen Mayhew, Chen-Tse Tsai, Dan Roth, Cheap translation for cross-lingual named entity recognition, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Stephen Mayhew",
                    "Chen-Tse Tsai",
                    "Dan Roth"
                ],
                "title": "Cheap translation for cross-lingual named entity recognition",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_94",
            "content": "Paul Neculoiu, Maarten Versteegh, Mihai Rotaru, Learning text similarity with Siamese recurrent networks, 2016, Proceedings of the 1st Workshop on Representation Learning for NLP, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "Paul Neculoiu",
                    "Maarten Versteegh",
                    "Mihai Rotaru"
                ],
                "title": "Learning text similarity with Siamese recurrent networks",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 1st Workshop on Representation Learning for NLP",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_95",
            "content": "Jian Ni, Georgiana Dinu, Radu Florian, Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Vancouver.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Jian Ni",
                    "Georgiana Dinu",
                    "Radu Florian"
                ],
                "title": "Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Vancouver"
            }
        },
        {
            "ix": "192-ARR_v1_96",
            "content": "Xiaoman Pan, Boliang Zhang, Jonathan May, Joel Nothman, Kevin Knight, Heng Ji, Crosslingual name tagging and linking for 282 languages, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": [
                    "Xiaoman Pan",
                    "Boliang Zhang",
                    "Jonathan May",
                    "Joel Nothman",
                    "Kevin Knight",
                    "Heng Ji"
                ],
                "title": "Crosslingual name tagging and linking for 282 languages",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "192-ARR_v1_97",
            "content": "Sebastian Ruder, Matthew Peters, Swabha Swayamdipta, Thomas Wolf, Transfer learning in natural language processing, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Sebastian Ruder",
                    "Matthew Peters",
                    "Swabha Swayamdipta",
                    "Thomas Wolf"
                ],
                "title": "Transfer learning in natural language processing",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_98",
            "content": "Erik , Tjong Kim Sang, Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition, 2002, COLING-02: The 6th Conference on Natural Language Learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Erik ",
                    "Tjong Kim Sang"
                ],
                "title": "Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition",
                "pub_date": "2002",
                "pub_title": "COLING-02: The 6th Conference on Natural Language Learning",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_99",
            "content": "Erik Tjong, Kim Sang, Fien De Meulder, Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": [
                    "Erik Tjong",
                    "Kim Sang",
                    "Fien De Meulder"
                ],
                "title": "Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition",
                "pub_date": "2003",
                "pub_title": "Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_100",
            "content": "Chen-Tse Tsai, Stephen Mayhew, Dan Roth, Cross-lingual named entity recognition via wikification, 2016, Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Chen-Tse Tsai",
                    "Stephen Mayhew",
                    "Dan Roth"
                ],
                "title": "Cross-lingual named entity recognition via wikification",
                "pub_date": "2016",
                "pub_title": "Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "192-ARR_v1_101",
            "content": "Qianhui Wu, Zijia Lin, B\u00f6rje Karlsson, Jian-Guang Lou, Biqing Huang, Single-/multisource cross-lingual NER via teacher-student learning on unlabeled data in target language, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": [
                    "Qianhui Wu",
                    "Zijia Lin",
                    "B\u00f6rje Karlsson",
                    "Jian-Guang Lou",
                    "Biqing Huang"
                ],
                "title": "Single-/multisource cross-lingual NER via teacher-student learning on unlabeled data in target language",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_102",
            "content": "Qianhui Wu, Zijia Lin, F B\u00f6rje, Biqing Karlsson, Jian-Guang Huang,  Lou, Unitrans : Unifying model transfer and data transfer for cross-lingual named entity recognition with unlabeled data, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, .",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Qianhui Wu",
                    "Zijia Lin",
                    "F B\u00f6rje",
                    "Biqing Karlsson",
                    "Jian-Guang Huang",
                    " Lou"
                ],
                "title": "Unitrans : Unifying model transfer and data transfer for cross-lingual named entity recognition with unlabeled data",
                "pub_date": "2020",
                "pub_title": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_103",
            "content": "Qianhui Wu, Zijia Lin, Guoxin Wang, Hui Chen, F B\u00f6rje, Biqing Karlsson, Chin-Yew Huang,  Lin, Enhanced meta-learning for cross-lingual named entity recognition with minimal resources, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Qianhui Wu",
                    "Zijia Lin",
                    "Guoxin Wang",
                    "Hui Chen",
                    "F B\u00f6rje",
                    "Biqing Karlsson",
                    "Chin-Yew Huang",
                    " Lin"
                ],
                "title": "Enhanced meta-learning for cross-lingual named entity recognition with minimal resources",
                "pub_date": "2020",
                "pub_title": "Proceedings of the AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_104",
            "content": "Shijie Wu, Mark Dredze, Beto, bentz, becas: The surprising cross-lingual effectiveness of BERT, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": [
                    "Shijie Wu",
                    "Mark Dredze"
                ],
                "title": "Beto, bentz, becas: The surprising cross-lingual effectiveness of BERT",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
                "pub": null
            }
        },
        {
            "ix": "192-ARR_v1_105",
            "content": "Jiateng Xie, Zhilin Yang, Graham Neubig, Noah Smith, Jaime Carbonell, Neural crosslingual named entity recognition with minimal resources, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": [
                    "Jiateng Xie",
                    "Zhilin Yang",
                    "Graham Neubig",
                    "Noah Smith",
                    "Jaime Carbonell"
                ],
                "title": "Neural crosslingual named entity recognition with minimal resources",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": "Association for Computational Linguistics"
            }
        },
        {
            "ix": "192-ARR_v1_106",
            "content": "Ying Zhang, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou, Target-oriented fine-tuning for zero-resource named entity recognition, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Ying Zhang",
                    "Fandong Meng",
                    "Yufeng Chen",
                    "Jinan Xu",
                    "Jie Zhou"
                ],
                "title": "Target-oriented fine-tuning for zero-resource named entity recognition",
                "pub_date": "2021",
                "pub_title": "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021",
                "pub": "Online. Association for Computational Linguistics"
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "192-ARR_v1_0@0",
            "content": "An Unsupervised Multiple-Task and Multiple-Teacher Model for Cross-lingual Named Entity Recognition",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_0",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@0",
            "content": "Cross-lingual named entity recognition task is one of the critical problem for evaluating the potential transfer learning techniques on low resource languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@1",
            "content": "Knowledge distillation using pre-trained multilingual language models between source and target languages have shown their superiority.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 160,
            "end": 294,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@2",
            "content": "However, existing cross-lingual distillation models merely consider the potential transferability between two identical single tasks across both domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 296,
            "end": 447,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@3",
            "content": "Other possible auxiliary tasks to improve the learning performance have not been fully investigated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 449,
            "end": 548,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@4",
            "content": "In this study, based on the knowledge distillation framework and multitask learning, we introduce the similarity metric model as an auxiliary task to improve the cross-lingual NER performance on target domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 550,
            "end": 758,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@5",
            "content": "Specifically, an entity recognizer and a similarity evaluator teachers are first trained in parallel from the source domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 760,
            "end": 883,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@6",
            "content": "Then, two tasks in the student model are supervised by the two teachers simultaneously.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 885,
            "end": 971,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_2@7",
            "content": "Empirical studies on the datasets across 7 different languages confirm the effectiveness of the proposed model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_2",
            "start": 973,
            "end": 1083,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_4@0",
            "content": "Named entity recognition, NER in short, refers to identifying entity types, i.e. location, person, organization, etc., in a given sentence.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_4",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_4@1",
            "content": "The exploiting of deep neural networks, such as Bi-LSTM-CRF (Lample et al., 2016), Bi-LSTM-CNN (Chiu and Nichols, 2016) make this task achieves significant performances.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_4",
            "start": 140,
            "end": 308,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_4@2",
            "content": "However, since deep neural networks highly relies on a large amount of labelled training data, the annotation acquiring process is expensive and time consuming.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_4",
            "start": 310,
            "end": 469,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_4@3",
            "content": "This situation is more severe for low-resource languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_4",
            "start": 471,
            "end": 527,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_4@4",
            "content": "With the help of transfer learning (Ruder et al., 2019) and multilingual BERT (short as mBERT) (Devlin et al., 2019), it is possible to transfer the annotated train- NER / NER tea : learned NER model for source language; NER stu : learned NER model for target language; SIM tea learned similarity model for source language; {X, Y } src : labeled data in source language; {X} tgt : unlabeled data in target language; {X, P } tgt : labeled data in target language with probability; {X, S} tgt : labeled data in target language with entity similarity score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_4",
            "start": 529,
            "end": 1082,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_5@0",
            "content": "ing samples or trained models from a rich-resource domain to a low-resource domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_5",
            "start": 0,
            "end": 82,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_6@0",
            "content": "Many studies have been done to solve this crosslanguage NER problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_6",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_6@1",
            "content": "Existing models can be separated into three categories, shared feature space based, translation based and knowledge distillation based.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_6",
            "start": 69,
            "end": 203,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_6@2",
            "content": "Shared feature space based models exploit language-independent features, which lacks the domain specific features for target language (Tsai et al., 2016;Wu and Dredze, 2019;Keung et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_6",
            "start": 205,
            "end": 397,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_6@3",
            "content": "Translation based models generate pseudo labeled target language data to train the cross-lingual NER model, but the noise from translation process restrains its performance. (Mayhew et al., 2017;Xie et al., 2018;Wu et al., 2020b).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_6",
            "start": 399,
            "end": 628,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_6@4",
            "content": "Knowledge distillation based models train a student model using soft labels of the target language (Wu et al., 2020a,b;Liang et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_6",
            "start": 630,
            "end": 768,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_6@5",
            "content": "Our model is developed on the basis of (Wu et al., 2020a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_6",
            "start": 770,
            "end": 827,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_7@0",
            "content": "Although above mentioned models solve the cross-lingual NER problem in some extent, the auxiliary tasks, as in the multi-task learning, have not been studied in this problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_7",
            "start": 0,
            "end": 173,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_7@1",
            "content": "Due to the distributed representation of natural languages, the relatedness among the embedding of target languages, which is measured by the similarity, can be utilized to further boost the learned encoder and improve the final NER performance on target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_7",
            "start": 175,
            "end": 438,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_8@0",
            "content": "Here we give a concrete example to illustrate the importance of similarity between every two tokens under the situation when only the English data is labeled.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_8",
            "start": 0,
            "end": 157,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_8@1",
            "content": "Given a Spanish sentence \"Ar\u00e9valo (Avila), 23 may (EFE).\", the token \"Ar\u00e9valo\" is recognized as ORG type using the learned model from English domain.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_8",
            "start": 159,
            "end": 307,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_8@2",
            "content": "In the meantime, the token \"Ar\u00e9valo\" has high similarity scores with the Spanish tokens \"Viena\" from sentence \"Viena, 23 may (EFE).\", and \"Madrid\" from sentence \"Madrid, 23 may (EFE).\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_8",
            "start": 309,
            "end": 493,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_8@3",
            "content": "Also, the tokens \"Viena\" and \"Madrid\" are recognized correctly as LOC type using the same English model mentioned above.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_8",
            "start": 495,
            "end": 614,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_8@4",
            "content": "Then \"Ar\u00e9valo\" can be recognized correctly as LOC type under the supervisory signal using the similarity between \"Viena\" and \"Madrid\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_8",
            "start": 616,
            "end": 749,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_9@0",
            "content": "To leverage the similarity between the tokens of the source languages, we design an multiple-task and multiple-teacher model (short as MTMT, as shown in Figure 1), which helps the NER learning process on the target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_9",
            "start": 0,
            "end": 224,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_9@1",
            "content": "Specifically, we first introduce the knowledge distillation to build entity recognizer and similarity evaluator teachers in the source language and transfer the learned patterns to the student in the target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_9",
            "start": 226,
            "end": 441,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_9@2",
            "content": "In the student model, we then borrow the idea of multitask learning to incorporate a similarity evaluation task as an auxiliary task into the entity recognition classifier.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_9",
            "start": 443,
            "end": 614,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_9@3",
            "content": "During the student learning process, we input unlabelled samples from the target languages into the entity recognizer and evaluator, and take output pesudo labels as supervisory signals for these two tasks in the student model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_9",
            "start": 616,
            "end": 842,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_9@4",
            "content": "Note that a weighting strategy is also provide therein to take into consideration of the reliability of the teachers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_9",
            "start": 844,
            "end": 960,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_10@0",
            "content": "We validate the model performance on the three commonly-used datasets across 7 languages and the experimental results shows the superiority our presented MTMT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_10",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_11@0",
            "content": "Our main contributions are as follows:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_11",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_12@0",
            "content": "\u2022 We propose an unsupervised knowledge distillation framework for cross-language named entity recognition and develop a teaching and learning procedure under this framework. \u2022 We present a novel multiple-task and multipleteacher model that introduces a entity similarity evaluator to boost the performance of student recognizer on target languages. \u2022 We conduct extensive experiments on seven languages compared with state-of-the-art baselines and the results confirm the effectiveness of the presented model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_12",
            "start": 0,
            "end": 508,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_13@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_13",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_14@0",
            "content": "Our approach is closely related to the existing works on cross-lingual NER, knowledge distillation and siamese network.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_14",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_15@0",
            "content": "Cross-Lingual NER aims to extract entities from a target language but assumes only source language is annotated.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_15",
            "start": 0,
            "end": 111,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_15@1",
            "content": "The existing models can be categorized to: a) Shared feature space based models, b) Translation based models, c) Knowledge distillation based models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_15",
            "start": 113,
            "end": 261,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_16@0",
            "content": "Shared feature space based models generally train a language-independent encoder using source and target language data (Tsai et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_16",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_16@1",
            "content": "Recently, the pre-trained multilingual language models mBERT is effective to address the challenge (Devlin et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_16",
            "start": 140,
            "end": 260,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_16@2",
            "content": "Moreover, some research introduces new components on top of the mBERT by directly transferring the model learned from labeled source language to that of target languages (Keung et al., 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_16",
            "start": 262,
            "end": 452,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_16@3",
            "content": "The performance is still weak due to the lack of annotations of target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_16",
            "start": 454,
            "end": 534,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_17@0",
            "content": "Translation based models generally generate pesudo labeled target data to alleviate target data scarcity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_17",
            "start": 0,
            "end": 104,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_17@1",
            "content": "For example, (Wu et al., 2020b;Zhang et al., 2021) gain a improvement by translating the labeled source language to the target language word-by-word.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_17",
            "start": 106,
            "end": 254,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_17@2",
            "content": "Our model achieves considerable improvement by learning entity similarity in target language data without translation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_17",
            "start": 256,
            "end": 373,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_18@0",
            "content": "Knowledge distillation based models includes a teacher model and a student model (Wu et al., 2020c).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_18",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_18@1",
            "content": "The teacher model is trained on labeled source language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_18",
            "start": 101,
            "end": 156,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_18@2",
            "content": "The student model learns from the soft label predicted by teacher model on unlabeled target language data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_18",
            "start": 158,
            "end": 263,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_18@3",
            "content": "Therefore, the student model can capture the extra knowledge about target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_18",
            "start": 265,
            "end": 348,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_18@4",
            "content": "In our work, the student model not only learns the recognizer teacher knowledge, but also learns the entity similarity knowledge inspired by multi-task learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_18",
            "start": 350,
            "end": 510,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_19@0",
            "content": "Siamese Network is originally introduced by (Bromley et al., 1994) to treat signature verification as a matching problem.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_19",
            "start": 0,
            "end": 120,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_19@1",
            "content": "It has been successfully applied to transfer learning such as one-shot image recognition (Koch et al., 2015), text similarity (Neculoiu et al., 2016).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_19",
            "start": 122,
            "end": 271,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_19@2",
            "content": "However, there is a dilemma to adapt siamese network to token-level recognition tasks such as NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_19",
            "start": 273,
            "end": 370,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_19@3",
            "content": "Siamese network assumes the input is a pair, and the output is a similarity score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_19",
            "start": 372,
            "end": 453,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_19@4",
            "content": "To handle this issue, we reconstruct the data to pair format.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_19",
            "start": 455,
            "end": 515,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_19@5",
            "content": "To the best of our knowledge, we are the first to learn the entity similarity by siamese network.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_19",
            "start": 517,
            "end": 613,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_20@0",
            "content": "Framework",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_20",
            "start": 0,
            "end": 8,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_21@0",
            "content": "In this section, we introduce our framework and its detailed implementation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_21",
            "start": 0,
            "end": 75,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_21@1",
            "content": "Our framework is consist of two models: teacher training model learned from source language and teacher-student distillation learning model learned from target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_21",
            "start": 77,
            "end": 245,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_22@0",
            "content": "In the teacher training model, there are two submodels, i.e. an entity recognizer teacher and a similarity evaluator teacher.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_22",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_22@1",
            "content": "These two models are two parallel tasks, wherein the entity recognition teacher focuses on identifying the named entities and the similarity evaluator teacher is to decide if two tokens are in the same type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_22",
            "start": 126,
            "end": 332,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_23@0",
            "content": "We then present a teacher-student distillation learning model to learn from the two learned teacher models simultaneously.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_23",
            "start": 0,
            "end": 121,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_23@1",
            "content": "We note that, in this learning process, such a knowledge distillation makes the student model combine the advantages of both source language patterns of entity recognition and entity similarity evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_23",
            "start": 123,
            "end": 327,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_23@2",
            "content": "During the learning process, the samples from target language are fed into the teacher model and the outputs are taken as the supervisory signal for two tasks in the student model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_23",
            "start": 329,
            "end": 508,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_23@3",
            "content": "To guarantee the student learning performance, we assign weights for each supervisory signal correspond to the output confidence of teacher sub-models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_23",
            "start": 510,
            "end": 660,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_23@4",
            "content": "We argue that the student entity recognition task and the student entity similarity evaluation task improve the representation learning of the student encoder in the siamese structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_23",
            "start": 662,
            "end": 845,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_24@0",
            "content": "Problem Definition",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_24",
            "start": 0,
            "end": 17,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_25@0",
            "content": "Following standard practice, we formulate crosslingual NER as a sequence labeling task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_25",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_25@1",
            "content": "Given a , where x i is the i-th token and y i is the corresponding label of x i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_25",
            "start": 88,
            "end": 168,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_25@2",
            "content": "In the source language, we denote the labeled training data as D S train = {(x, y)} and test data as D S test .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_25",
            "start": 170,
            "end": 280,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_25@3",
            "content": "In the target language, we denote the unlabeled train data as D T train = {x} and the test data as D T test .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_25",
            "start": 282,
            "end": 390,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_25@4",
            "content": "Formally, our goal is to train a model with D S train and D T train to perform well on D T test .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_25",
            "start": 392,
            "end": 488,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_26@0",
            "content": "Teacher Models",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_26",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@0",
            "content": "Here we first consider the training of two teacher models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 0,
            "end": 57,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@1",
            "content": "For every two tokens, we define Entity Similarity Metric as a score which is the probability that two tokens belong to the same entity type.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 59,
            "end": 198,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@2",
            "content": "We aim to find entity similarity to help the cross-lingual NER model in target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 200,
            "end": 287,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@3",
            "content": "It is a non-trivial task since we lack golden labels to help us distinguish target named entities.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 289,
            "end": 386,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@4",
            "content": "To address this challenge, we propose a binary classifier called similarity teacher to leverage the labeled source language data for similarity prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 388,
            "end": 542,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@5",
            "content": "Our similarity teacher model, inspired by siamese network (Koch et al., 2015), are able to acquires more powerful features via capturing the invariances to transformation in the input space.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 544,
            "end": 733,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@6",
            "content": "Figure 2 illustrated the two teacher models training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 735,
            "end": 787,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_27@7",
            "content": "The following subsections will illustrate the two teacher models sequentially.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_27",
            "start": 789,
            "end": 866,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_28@0",
            "content": "Entity Recognizer Teacher",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_28",
            "start": 0,
            "end": 24,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_29@0",
            "content": "Since the cross-lingual NER task, we unitize multilingual mBERT (Wu and Dredze, 2019) as basic sequence feature extractor backbone to derive the sequence embedding representation throughout this paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_29",
            "start": 0,
            "end": 200,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_29@1",
            "content": "And a linear classifier with softmax upon the pre-trained mBERT output.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_29",
            "start": 202,
            "end": 272,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_29@2",
            "content": "The model network structure could be formulated as,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_29",
            "start": 274,
            "end": 324,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_30@0",
            "content": "h = mBERT(x) \u0177i = softmax(W h i + b)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_30",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_31@0",
            "content": "where h = {h i } L i=1 and h i denotes the output of the pretrained mBERT that corresponds to the input token x i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_31",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_31@1",
            "content": "\u0177i denotes the predicted probability distribution for x i .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_31",
            "start": 116,
            "end": 174,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_31@2",
            "content": "W and b are trainable parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_31",
            "start": 176,
            "end": 208,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_31@3",
            "content": "For some sentence sample (x, y) \u2208 D S train and an entity token query index i, the loss function is,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_31",
            "start": 210,
            "end": 309,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_32@0",
            "content": "L ER (x, y, i) = L CE (y i , \u0177i )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_32",
            "start": 0,
            "end": 32,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_33@0",
            "content": "We train this entity recognition teacher model on the source lingual training corpus D S train = {(x, y)} directly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_33",
            "start": 0,
            "end": 114,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_34@0",
            "content": "Siamese Entity Similarity Evaluator",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_34",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_35@0",
            "content": "In order to leverage the entity similarity to boost the unsupervised cross-lingual NER performance, we will present our entity pairs construction method and the siamese network model in the following.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_35",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_36@0",
            "content": "Entity Similarity Pairs Construction According to entity labels, we randomly select sentences pair < x, x > with their some token pair < x i , x j > and associated labels < y i , y j > in D S train , to form the siamese supervision training dataset, D S\u2212siam train = {(x, x , i, j, t)} where the target t = 1 indicates y i = y j , and 0 otherwise. And the testing entity pairs D S\u2212siam test is constructed likewisely.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_36",
            "start": 0,
            "end": 416,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_37@0",
            "content": "Siamese Entity Similarity Network Our similarity backbone model is a siamese neural network with mBERT as feature extraction layer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_37",
            "start": 0,
            "end": 130,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_37@1",
            "content": "Wherein h and h represent latent sequences encoding features derived by the two symmetric twins with respect to input sentence x and x respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_37",
            "start": 132,
            "end": 279,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_38@0",
            "content": "The inter-entities similarity is measured on the tokens hidden representations h i and h j , queried by the entity indices < i, j > on the sequences representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_38",
            "start": 0,
            "end": 164,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_38@1",
            "content": "The cosine function operator is added to compute on the entity token latent vectors' distance, so as to measure the similarity between each siamese twin, which is fed into a single sigmoid output unit for target t estimation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_38",
            "start": 166,
            "end": 390,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_39@0",
            "content": "More precisely, for a specific entity pair (x, x , i, j, t) \u2208 D S\u2212siam train , the siamese network could be formulated as, where cos is the cosine similarity metric function, \u03c3 is the sigmoid activation function, t \u2208 [\u03c3(\u22121), \u03c3(1)] denotes the predicted similarity of two queried tokens pair < x i , x j >.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_39",
            "start": 0,
            "end": 304,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_39@1",
            "content": "Larger t value indicates higher similarity between the two queried entities tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_39",
            "start": 306,
            "end": 388,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_40@0",
            "content": "h =mBERT(x), h = mBERT(x ) t(x, x , i, j) = \u03c3(cos(h i , h j ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_40",
            "start": 0,
            "end": 61,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_41@0",
            "content": "The loss function of the similarity prediction can be formulate as,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_41",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_42@0",
            "content": "L SIM (x, x , i, j, t) = L BCE (t, t).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_42",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_43@0",
            "content": "Finally, we can train the siamese entity similarity evaluator on D S\u2212siam train , and evaluate the performance on test dataset D S\u2212siam test .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_43",
            "start": 0,
            "end": 141,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_43@1",
            "content": "Together with entity recognizer model, this entity similarity evaluator are used as teachers in following knowledge distillation learning process, and transfer knowledge from source to target lingual corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_43",
            "start": 143,
            "end": 349,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_44@0",
            "content": "Teacher Student Distillation Learning",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_44",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_45@0",
            "content": "In this section, we consider to transfer the named entity type and similarity knowledge learned on labeled source language corpus to unlabeled target language NER task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_45",
            "start": 0,
            "end": 167,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_45@1",
            "content": "To this end, we propose a knowledge distillation learning process to train a target language student NER model with its supervisory signals mimicked by the entity type prediction probability by the entity recognizer teacher model and entity representation similarity target by the entity siamese similarity evaluator teacher model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_45",
            "start": 169,
            "end": 499,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_45@2",
            "content": "Based on the original unlabeled target sentence training data D T train , we again construct unlabeled target-language siamese pairwise entity data D T \u2212sim train = {(x T , x T , i, j)}, with the sentence pair < x T , x T > randomly sample from D T train and the entity token indices pair < i, j > uniformly sampled from the sentences therein.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_45",
            "start": 501,
            "end": 843,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_46@0",
            "content": "The multi-lingual BERT is also used as encoder for the sentence siamese pair, and the entity token feature queried from the latent sequence encoding representation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_46",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_46@1",
            "content": "Specifically, for a sentence pair (x T , x T , i, j) \u2208 D T \u2212sim train , the student model transform them as follows,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_46",
            "start": 165,
            "end": 280,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_47@0",
            "content": "h T = mBERT(x T ) \u0177T i = softmax(W h T i + b) h T = mBERT(x T ) \u0177 T j = softmax(W h T j + b) tT (x T ,x T , i, j) = \u03c3(cos(h T i , h T j ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_47",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_48@0",
            "content": "Then for a specific sentence pair sample in the target siamese dataset, the student loss function has three breaches, L ER (x T , y S , i), L ER (x T , y S , j), and L SIM (x T , x T , i, j, tS ).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_48",
            "start": 0,
            "end": 195,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_48@1",
            "content": "Note that supervision information y S , y S , and tS are taught by the three teacher models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_48",
            "start": 197,
            "end": 288,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_48@2",
            "content": "Summering over all the samples in D T \u2212sim train = {(x T , x T , i, j)}, the total student model training loss takes form,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_48",
            "start": 290,
            "end": 411,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_49@0",
            "content": "L = \u03b3 (x T ,x T ,i,j)\u2208D T \u2212sim train (\u03b1 1 L ER (x T , y S , i) +\u03b1 2 L ER (x T , y S , j) +\u03b2L BCE ( tT (x T , x T , i, j), tS ))",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_49",
            "start": 0,
            "end": 126,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_50@0",
            "content": "where \u03b1 1 , \u03b1 2 , \u03b2 and \u03b3 are weights in loss function which are set to make the student model learns less noisy knowledge from teachers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_50",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_50@1",
            "content": "The weights are set as follows: \u03b1 1 (\u03b1 2 ) is an increasing function with respect to the output of the entity recognizer teacher as shown in Figure .4. And \u03b2 is set such that it is high when the output of the entity similarity teacher is close to 0 or 1, and it is low when the output is close to 0.5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_50",
            "start": 138,
            "end": 438,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_50@2",
            "content": "\u03b3 indicates consistency level between the outputs from two teacher models, e.g. for two input tokens, if the output from entity similarity teacher is high, and the similarity level computed from the outputs of the entity recognizer teacher is low, then their consistency level is low.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_50",
            "start": 440,
            "end": 723,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_50@3",
            "content": "We want the student model to learn from the two teachers as follows: the higher the prediction of the entity recognizer teacher is (the further away from 0.5 the prediction of the entity similarity teacher is, the higher the consistency level is), the more accurate the prediction is, thus the more attention the student model pays attention to the input tokens, and vice versa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_50",
            "start": 725,
            "end": 1102,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_50@4",
            "content": "Therefore, we heuristically devises the three weights scheduling as functions of the inputs,",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_50",
            "start": 1104,
            "end": 1195,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_51@0",
            "content": "\u03b1 (\u2022) = (max(\u0177 T i )) 2 \u03b2 = (2 tT (x T , x T , i, j) \u2212 1) 2 \u03b3 = 1 \u2212 |\u03c3(cos(\u0177 T i , \u0177 T j )) \u2212 tT (x T , x T , i, j)|",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_51",
            "start": 0,
            "end": 115,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_52@0",
            "content": "Experiment",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_52",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_53@0",
            "content": "In this section, we evaluate our multiple-task and multiple-teacher model for cross-lingual NER and compare our model with a series of state-of-the-art models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_53",
            "start": 0,
            "end": 158,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_54@0",
            "content": "Dataset",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_54",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@0",
            "content": "We conducted experiments on three benchmark datasets: CoNLL2002 (Tjong Kim Sang, 2002), CoNLL2003 (Tjong Kim Sang and De Meulder, 2003) and WikiAnn (Pan et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@1",
            "content": "CoNLL2002 includes Spanish and Dutch, CoNLL2003 includes English and German, and WikiAnn includes English and three non-western languages: Arabic, Hindi, and Chinese.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 168,
            "end": 333,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@2",
            "content": "Each language is divided into a training set, a development set and a test set.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 335,
            "end": 413,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@3",
            "content": "All datasets were annotated with four entity types: LOC, MISC, ORG, and PER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 415,
            "end": 490,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@4",
            "content": "Following (Wu and Dredze, 2019), all datasets are annotated using the BIO entity labelling scheme.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 492,
            "end": 589,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@5",
            "content": "To imitate the zero-resource cross lingual NER case, following (Wu and Dredze, 2019), we used English as the source language and other languages as the target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 591,
            "end": 758,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@6",
            "content": "In cross-lingual NER, the training set without entity label of the target language is also available when training the model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 760,
            "end": 884,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@7",
            "content": "We trained the model with the labeled training set of the source language and evaluated the model on the test set of each target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 886,
            "end": 1023,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_55@8",
            "content": "Table 1 and 2 shows the statistics of all datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_55",
            "start": 1025,
            "end": 1075,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_56@0",
            "content": "Implementation Details",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_56",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@0",
            "content": "We use PyTorch 1.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@1",
            "content": "We set our hyperparameters empirically following (Wu et al., 2020c) with some modifications.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 18,
            "end": 109,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@2",
            "content": "We do not freeze any layers and we use the output of the last layer as our hidden feature vector.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 111,
            "end": 207,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@3",
            "content": "We set batch size to be 32, maximum sequence length to be 128, dropout rate to be 0.2, and we use Adam as optimizer (Kingma and Ba, 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 209,
            "end": 346,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@4",
            "content": "For the training of recognition teacher model and similarity teacher model, we set the learning rate to be 1e-5 and 5e-6 separately.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 348,
            "end": 479,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@5",
            "content": "For knowledge distillation, we use a learning rate of 1e-6 for the student models training.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 481,
            "end": 571,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@6",
            "content": "Note that if a word is divided into several subwords after tokenization, then only the first subword is considered in the loss function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 573,
            "end": 708,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@7",
            "content": "Following (Tjong Kim Sang, 2002), we use the entity level F1-score as the evaluation metric.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 710,
            "end": 801,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_57@8",
            "content": "Moreover, we conduct each experiment 5 times and report the mean F1-score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_57",
            "start": 803,
            "end": 876,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_58@0",
            "content": "Comparison",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_58",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_59@0",
            "content": "Table 3 and 4 report the zero-resource cross-lingual NER results of different models on 6 target languages.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_59",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_60@0",
            "content": "Unitrans (Wu et al., 2020b) unifies a data transfer and model transfer for cross-lingual NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_60",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_61@0",
            "content": "AdvPicker proposes a adversarial discriminator for cross-lingual NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_61",
            "start": 0,
            "end": 68,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_61@1",
            "content": "RIKD (Liang et al., 2021) develops a reinforced iterative knowledge distillation for cross-lingual NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_61",
            "start": 70,
            "end": 172,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_62@0",
            "content": "TOF (Zhang et al., 2021) transfers knowledge from three aspects for cross-lingual NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_62",
            "start": 0,
            "end": 85,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_63@0",
            "content": "It can be seen that our model outperforms the state-of-the-arts.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_63",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_63@1",
            "content": "Specifically, compared with the remarkable RIKD, AdvPicker and Unitrans, which also use knowledge distillation but ignore the entity similarity knowledge, our model obtains significant and consistent improvements in F1-score ranging from 0.23 for German[de] to 6.81 for Arabic [ar].",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_63",
            "start": 65,
            "end": 346,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_63@2",
            "content": "That demonstrates the benefits of our proposed MTMT model, compared to direct model transfer (Wu and Dredze, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_63",
            "start": 348,
            "end": 462,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_64@0",
            "content": "Note that Bert-f performs better than our model on Chinese dataset due to their re-tokenization of the dataset.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_64",
            "start": 0,
            "end": 110,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_64@1",
            "content": "Moreover, compared with the latest model TOF, RIKD, Unitrans, our model requires much lower computational costs for both translation and iterative knowledge distillation, meanwhile reaching superior performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_64",
            "start": 112,
            "end": 322,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_64@2",
            "content": "For a fair comparison, we compare our model against the version of TOF w/o continual learning (Zhang et 2021), RIKD w/o IKD (Liang et al., 2021) and Unitrans w/o translation (Wu et al., 2020b) as reported in their paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_64",
            "start": 324,
            "end": 543,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_65@0",
            "content": "Ablation Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_65",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_66@0",
            "content": "To demonstrate the effectiveness of our approach, we designed the following ablation studies.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_66",
            "start": 0,
            "end": 92,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_66@1",
            "content": "Table 5 presents the results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_66",
            "start": 94,
            "end": 122,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_67@0",
            "content": "(1) MTST, which combines the multiple-teacher to single-teacher.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_67",
            "start": 0,
            "end": 63,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_67@1",
            "content": "That is, both of the teacher and student have the same neural network structure.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_67",
            "start": 65,
            "end": 144,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_67@2",
            "content": "This causes a performance drop across all languages due to two single teachers cannot make a difference with combination.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_67",
            "start": 146,
            "end": 266,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_68@0",
            "content": "(2) MTMT w/o weighting, which set the \u03b1 1 ,\u03b1 2 , \u03b2 and \u03b3 all to be 1 in the loss of student model learning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_68",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_68@1",
            "content": "It can be seen that the performance decrease in terms of F1-score ranges from 0.45 for Dutch(nl) to 0.98 for Spanish(es), which validates that weighting loss can bring more confident knowledge to student model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_68",
            "start": 108,
            "end": 317,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_69@0",
            "content": "(3) MTMT w/o similarity, which removes the similarity teacher model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_69",
            "start": 0,
            "end": 67,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_69@1",
            "content": "In this case, our approach degrades into the Single Teacher-Student learning model as in TSL (Wu et al., 2020a).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_69",
            "start": 69,
            "end": 180,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_69@2",
            "content": "Without the similarity knowledge fed into the student model, the performance drops significantly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_69",
            "start": 182,
            "end": 278,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_70@0",
            "content": "Case Study",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_70",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_71@0",
            "content": "We give a case study to show that the failed cases of baseline models can be corrected by our model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_71",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_71@1",
            "content": "We try to bring up insights on why the proposed multiple-task and multiple-teacher model works.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_71",
            "start": 101,
            "end": 195,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_72@0",
            "content": "The proposed MTMT model can help to correct labels using the Entity Similarity defined in section 3.2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_72",
            "start": 0,
            "end": 101,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_72@1",
            "content": "Specifically, if there is a set of tokens in which every two of them have high Entity Similarity score, and one of the tokens is predicted to have a distinct label while other tokens have identical labels, then the one with the distinct label is predicted wrongly and is corrected by the student model to have the label of all other tokens.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_72",
            "start": 103,
            "end": 442,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_72@2",
            "content": "As shown in Table 6, in example #1, the entity recognizer teacher fails to identify \"Ar\u00e9valo\" as B-ORG type, while the student model can correctly predict it.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_72",
            "start": 444,
            "end": 601,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_72@3",
            "content": "The reason lies in that the entity recognizer teacher predicts \"Viena\"('Madrid\") as B-LOC type correctly, and the similarity evaluator teacher predicts \"Viena\"(\"Madrid\") to have a high similarity score(0.7157, 0.7156) with \"Ar\u00e9valo\". The student learns from both teachers and predict the correct label for \"Ar\u00e9valo\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_72",
            "start": 603,
            "end": 918,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_72@4",
            "content": "Examples #2 and #3 present the same results with different sentences.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_72",
            "start": 920,
            "end": 988,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_73@0",
            "content": "Embeddings Distribution",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_73",
            "start": 0,
            "end": 22,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_74@0",
            "content": "This section investigates the effect of embeddings of the two different teacher models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_74",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_74@1",
            "content": "It can be seen that the embeddings distribution of student model is close to similarity evaluator teacher, as illustrated in Figure 5.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_74",
            "start": 88,
            "end": 221,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_74@2",
            "content": "We conjecture that the student model captures similarity knowledge from the similarity evaluator teacher, i.e. the same class of examples tend to cluster and the different class of examples tend to segregate in the embeddings distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_74",
            "start": 223,
            "end": 461,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_74@3",
            "content": "This validates the proposed MTMT model not only transfers cross-lingual NER knowledge from source language, but also learns the similarity knowledge of target language data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_74",
            "start": 463,
            "end": 635,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_75@0",
            "content": "Effect of Weights",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_75",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_76@0",
            "content": "In the section, we evaluate the effectiveness of the weighting loss in student learning from quantitative perspective.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_76",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_76@1",
            "content": "All of the following experiments are conducted on Spanish(es) data.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_76",
            "start": 119,
            "end": 185,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_77@0",
            "content": "For \u03b1 analysis, we calculate the F1-score in different probability intervals of entity recognizer teacher, we find that the recognizer teacher tends to predict more correct in higher probability interval, as illustrated in Figure 6a.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_77",
            "start": 0,
            "end": 232,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_77@1",
            "content": "Therefore, the student model is better suited to target language with learning less low-confidence misrecognitions for the target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_77",
            "start": 234,
            "end": 372,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_78@0",
            "content": "For \u03b2 analysis, we observe that F1-score are increasing with the entity similarity score from 0.5 to both sides 0 and 1 in Figure 6b.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_78",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_78@1",
            "content": "The encoder of student model obtains the clustering information of the target language with the help of \u03b2.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_78",
            "start": 134,
            "end": 239,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_79@0",
            "content": "For \u03b3 analysis, we consider the consistency of recognition results and similarity score by teachers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_79",
            "start": 0,
            "end": 99,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_79@1",
            "content": "The F1-score and similarity score of teachers are all higher in the higher \u03b3 intervals, as shown in Figure 6c.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_79",
            "start": 101,
            "end": 210,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_79@2",
            "content": "The student model learns less from unreasonable results, and it can make more accuracy entity recognition for the target language.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_79",
            "start": 212,
            "end": 341,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_80@0",
            "content": "Conclusion",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_80",
            "start": 0,
            "end": 9,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_81@0",
            "content": "In this paper, we propose an unsupervised multipletask and multiple-teacher model for cross-lingual NER.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_81",
            "start": 0,
            "end": 103,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_81@1",
            "content": "The student model learns two source language patterns of entity recognition and entity similarity evaluation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_81",
            "start": 105,
            "end": 213,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_81@2",
            "content": "Moreover, in order to guarantee the student learning performance, we also propose a weighting strategy to take consideration of the reliability of the teachers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_81",
            "start": 215,
            "end": 374,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_81@3",
            "content": "Our experimental results show that the proposed model yields significant improvements on six target language datasets and outperforms the existing state-of-the-art approaches.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_81",
            "start": 376,
            "end": 550,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_82@0",
            "content": "Jane Bromley, Isabelle Guyon, Yann Lecun, Eduard S\u00e4ckinger, Roopak Shah, Signature verification using a \"siamese\" time delay neural network, 1994, Advances in Neural Information Processing Systems, Morgan-Kaufmann.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_82",
            "start": 0,
            "end": 213,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_83@0",
            "content": "Weile Chen, Huiqiang Jiang, Qianhui Wu, B\u00f6rje Karlsson, Yi Guan, AdvPicker: Effectively Leveraging Unlabeled Data via Adversarial Discriminator for Cross-Lingual NER, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_83",
            "start": 0,
            "end": 337,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_84@0",
            "content": "UNKNOWN, None, 2016, Named entity recognition with bidirectional LSTM-CNNs. Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_84",
            "start": 0,
            "end": 139,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_85@0",
            "content": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, BERT: Pre-training of deep bidirectional transformers for language understanding, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_85",
            "start": 0,
            "end": 315,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_86@0",
            "content": "Alankar Jain, Bhargavi Paranjape, Zachary , Entity projection via machine translation for cross-lingual NER, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_86",
            "start": 0,
            "end": 333,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_87@0",
            "content": "Phillip Keung, Yichao Lu, Vikas Bhardwaj, Adversarial learning with contextual embeddings for zero-resource cross-lingual classification and NER, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_87",
            "start": 0,
            "end": 329,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_88@0",
            "content": "P Diederik, Jimmy Kingma,  Ba, Adam: A method for stochastic optimization, 2014, the 3rd International Conference for Learning Representations, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_88",
            "start": 0,
            "end": 144,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_89@0",
            "content": "Gregory Koch, Richard Zemel, Ruslan Salakhutdinov, Siamese neural networks for one-shot image recognition, 2015, ICML deep learning workshop, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_89",
            "start": 0,
            "end": 142,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_90@0",
            "content": "UNKNOWN, None, 2016, Neural architectures for named entity recognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_90",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_91@0",
            "content": "UNKNOWN, None, , Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_91",
            "start": 0,
            "end": 202,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_92@0",
            "content": "Shining Liang, Ming Gong, Jian Pei, Linjun Shou, Wanli Zuo, Xianglin Zuo, Daxin Jiang, Reinforced iterative knowledge distillation for crosslingual named entity recognition, 2021, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery amp; Data Mining, KDD '21, Association for Computing Machinery.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_92",
            "start": 0,
            "end": 311,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_93@0",
            "content": "Stephen Mayhew, Chen-Tse Tsai, Dan Roth, Cheap translation for cross-lingual named entity recognition, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_93",
            "start": 0,
            "end": 197,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_94@0",
            "content": "Paul Neculoiu, Maarten Versteegh, Mihai Rotaru, Learning text similarity with Siamese recurrent networks, 2016, Proceedings of the 1st Workshop on Representation Learning for NLP, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_94",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_95@0",
            "content": "Jian Ni, Georgiana Dinu, Radu Florian, Weakly supervised cross-lingual named entity recognition via effective annotation and representation projection, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Vancouver.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_95",
            "start": 0,
            "end": 256,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_96@0",
            "content": "Xiaoman Pan, Boliang Zhang, Jonathan May, Joel Nothman, Kevin Knight, Heng Ji, Crosslingual name tagging and linking for 282 languages, 2017, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_96",
            "start": 0,
            "end": 272,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_97@0",
            "content": "Sebastian Ruder, Matthew Peters, Swabha Swayamdipta, Thomas Wolf, Transfer learning in natural language processing, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Tutorials, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_97",
            "start": 0,
            "end": 248,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_98@0",
            "content": "Erik , Tjong Kim Sang, Introduction to the CoNLL-2002 shared task: Language-independent named entity recognition, 2002, COLING-02: The 6th Conference on Natural Language Learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_98",
            "start": 0,
            "end": 180,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_99@0",
            "content": "Erik Tjong, Kim Sang, Fien De Meulder, Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition, 2003, Proceedings of the Seventh Conference on Natural Language Learning at HLT-NAACL 2003, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_99",
            "start": 0,
            "end": 222,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_100@0",
            "content": "Chen-Tse Tsai, Stephen Mayhew, Dan Roth, Cross-lingual named entity recognition via wikification, 2016, Proceedings of The 20th SIGNLL Conference on Computational Natural Language Learning, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_100",
            "start": 0,
            "end": 231,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_101@0",
            "content": "Qianhui Wu, Zijia Lin, B\u00f6rje Karlsson, Jian-Guang Lou, Biqing Huang, Single-/multisource cross-lingual NER via teacher-student learning on unlabeled data in target language, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_101",
            "start": 0,
            "end": 269,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_102@0",
            "content": "Qianhui Wu, Zijia Lin, F B\u00f6rje, Biqing Karlsson, Jian-Guang Huang,  Lou, Unitrans : Unifying model transfer and data transfer for cross-lingual named entity recognition with unlabeled data, 2020, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI-20, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_102",
            "start": 0,
            "end": 297,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_103@0",
            "content": "Qianhui Wu, Zijia Lin, Guoxin Wang, Hui Chen, F B\u00f6rje, Biqing Karlsson, Chin-Yew Huang,  Lin, Enhanced meta-learning for cross-lingual named entity recognition with minimal resources, 2020, Proceedings of the AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_103",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_104@0",
            "content": "Shijie Wu, Mark Dredze, Beto, bentz, becas: The surprising cross-lingual effectiveness of BERT, 2019, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_104",
            "start": 0,
            "end": 279,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_105@0",
            "content": "Jiateng Xie, Zhilin Yang, Graham Neubig, Noah Smith, Jaime Carbonell, Neural crosslingual named entity recognition with minimal resources, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_105",
            "start": 0,
            "end": 274,
            "label": {}
        },
        {
            "ix": "192-ARR_v1_106@0",
            "content": "Ying Zhang, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou, Target-oriented fine-tuning for zero-resource named entity recognition, 2021, Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "192-ARR_v1_106",
            "start": 0,
            "end": 262,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_1",
            "tgt_ix": "192-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_1",
            "tgt_ix": "192-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_4",
            "tgt_ix": "192-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_5",
            "tgt_ix": "192-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_6",
            "tgt_ix": "192-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_7",
            "tgt_ix": "192-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_8",
            "tgt_ix": "192-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_9",
            "tgt_ix": "192-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_10",
            "tgt_ix": "192-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_11",
            "tgt_ix": "192-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_14",
            "tgt_ix": "192-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_15",
            "tgt_ix": "192-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_16",
            "tgt_ix": "192-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_17",
            "tgt_ix": "192-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_18",
            "tgt_ix": "192-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_19",
            "tgt_ix": "192-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_21",
            "tgt_ix": "192-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_22",
            "tgt_ix": "192-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_23",
            "tgt_ix": "192-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_24",
            "tgt_ix": "192-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_24",
            "tgt_ix": "192-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_25",
            "tgt_ix": "192-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_26",
            "tgt_ix": "192-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_26",
            "tgt_ix": "192-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_29",
            "tgt_ix": "192-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_30",
            "tgt_ix": "192-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_31",
            "tgt_ix": "192-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_32",
            "tgt_ix": "192-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_28",
            "tgt_ix": "192-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_28",
            "tgt_ix": "192-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_28",
            "tgt_ix": "192-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_28",
            "tgt_ix": "192-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_28",
            "tgt_ix": "192-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_28",
            "tgt_ix": "192-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_33",
            "tgt_ix": "192-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_35",
            "tgt_ix": "192-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_36",
            "tgt_ix": "192-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_37",
            "tgt_ix": "192-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_38",
            "tgt_ix": "192-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_39",
            "tgt_ix": "192-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_40",
            "tgt_ix": "192-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_41",
            "tgt_ix": "192-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_42",
            "tgt_ix": "192-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_43",
            "tgt_ix": "192-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_45",
            "tgt_ix": "192-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_46",
            "tgt_ix": "192-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_47",
            "tgt_ix": "192-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_48",
            "tgt_ix": "192-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_49",
            "tgt_ix": "192-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_50",
            "tgt_ix": "192-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_51",
            "tgt_ix": "192-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_53",
            "tgt_ix": "192-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_54",
            "tgt_ix": "192-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_54",
            "tgt_ix": "192-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_56",
            "tgt_ix": "192-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_56",
            "tgt_ix": "192-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_60",
            "tgt_ix": "192-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_61",
            "tgt_ix": "192-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_62",
            "tgt_ix": "192-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_63",
            "tgt_ix": "192-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_64",
            "tgt_ix": "192-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_66",
            "tgt_ix": "192-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_67",
            "tgt_ix": "192-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_68",
            "tgt_ix": "192-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_65",
            "tgt_ix": "192-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_65",
            "tgt_ix": "192-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_65",
            "tgt_ix": "192-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_65",
            "tgt_ix": "192-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_65",
            "tgt_ix": "192-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_69",
            "tgt_ix": "192-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_71",
            "tgt_ix": "192-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_70",
            "tgt_ix": "192-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_70",
            "tgt_ix": "192-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_70",
            "tgt_ix": "192-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_72",
            "tgt_ix": "192-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_73",
            "tgt_ix": "192-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_73",
            "tgt_ix": "192-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_74",
            "tgt_ix": "192-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_76",
            "tgt_ix": "192-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_77",
            "tgt_ix": "192-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_78",
            "tgt_ix": "192-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_75",
            "tgt_ix": "192-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_75",
            "tgt_ix": "192-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_75",
            "tgt_ix": "192-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_75",
            "tgt_ix": "192-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_75",
            "tgt_ix": "192-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_79",
            "tgt_ix": "192-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_80",
            "tgt_ix": "192-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_80",
            "tgt_ix": "192-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "192-ARR_v1_0",
            "tgt_ix": "192-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_1",
            "tgt_ix": "192-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_2",
            "tgt_ix": "192-ARR_v1_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_3",
            "tgt_ix": "192-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_4",
            "tgt_ix": "192-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_4",
            "tgt_ix": "192-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_4",
            "tgt_ix": "192-ARR_v1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_4",
            "tgt_ix": "192-ARR_v1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_4",
            "tgt_ix": "192-ARR_v1_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_5",
            "tgt_ix": "192-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_6",
            "tgt_ix": "192-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_6",
            "tgt_ix": "192-ARR_v1_6@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_6",
            "tgt_ix": "192-ARR_v1_6@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_6",
            "tgt_ix": "192-ARR_v1_6@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_6",
            "tgt_ix": "192-ARR_v1_6@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_6",
            "tgt_ix": "192-ARR_v1_6@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_7",
            "tgt_ix": "192-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_7",
            "tgt_ix": "192-ARR_v1_7@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_8",
            "tgt_ix": "192-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_8",
            "tgt_ix": "192-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_8",
            "tgt_ix": "192-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_8",
            "tgt_ix": "192-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_8",
            "tgt_ix": "192-ARR_v1_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_9",
            "tgt_ix": "192-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_9",
            "tgt_ix": "192-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_9",
            "tgt_ix": "192-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_9",
            "tgt_ix": "192-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_9",
            "tgt_ix": "192-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_10",
            "tgt_ix": "192-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_11",
            "tgt_ix": "192-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_12",
            "tgt_ix": "192-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_13",
            "tgt_ix": "192-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_14",
            "tgt_ix": "192-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_15",
            "tgt_ix": "192-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_15",
            "tgt_ix": "192-ARR_v1_15@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_16",
            "tgt_ix": "192-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_16",
            "tgt_ix": "192-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_16",
            "tgt_ix": "192-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_16",
            "tgt_ix": "192-ARR_v1_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_17",
            "tgt_ix": "192-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_17",
            "tgt_ix": "192-ARR_v1_17@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_17",
            "tgt_ix": "192-ARR_v1_17@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_18",
            "tgt_ix": "192-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_18",
            "tgt_ix": "192-ARR_v1_18@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_18",
            "tgt_ix": "192-ARR_v1_18@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_18",
            "tgt_ix": "192-ARR_v1_18@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_18",
            "tgt_ix": "192-ARR_v1_18@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_19",
            "tgt_ix": "192-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_19",
            "tgt_ix": "192-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_19",
            "tgt_ix": "192-ARR_v1_19@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_19",
            "tgt_ix": "192-ARR_v1_19@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_19",
            "tgt_ix": "192-ARR_v1_19@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_19",
            "tgt_ix": "192-ARR_v1_19@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_20",
            "tgt_ix": "192-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_21",
            "tgt_ix": "192-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_21",
            "tgt_ix": "192-ARR_v1_21@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_22",
            "tgt_ix": "192-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_22",
            "tgt_ix": "192-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_23",
            "tgt_ix": "192-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_23",
            "tgt_ix": "192-ARR_v1_23@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_23",
            "tgt_ix": "192-ARR_v1_23@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_23",
            "tgt_ix": "192-ARR_v1_23@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_23",
            "tgt_ix": "192-ARR_v1_23@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_24",
            "tgt_ix": "192-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_25",
            "tgt_ix": "192-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_25",
            "tgt_ix": "192-ARR_v1_25@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_25",
            "tgt_ix": "192-ARR_v1_25@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_25",
            "tgt_ix": "192-ARR_v1_25@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_25",
            "tgt_ix": "192-ARR_v1_25@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_26",
            "tgt_ix": "192-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_27",
            "tgt_ix": "192-ARR_v1_27@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_28",
            "tgt_ix": "192-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_29",
            "tgt_ix": "192-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_29",
            "tgt_ix": "192-ARR_v1_29@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_29",
            "tgt_ix": "192-ARR_v1_29@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_30",
            "tgt_ix": "192-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_31",
            "tgt_ix": "192-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_31",
            "tgt_ix": "192-ARR_v1_31@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_31",
            "tgt_ix": "192-ARR_v1_31@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_31",
            "tgt_ix": "192-ARR_v1_31@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_32",
            "tgt_ix": "192-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_33",
            "tgt_ix": "192-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_34",
            "tgt_ix": "192-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_35",
            "tgt_ix": "192-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_36",
            "tgt_ix": "192-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_37",
            "tgt_ix": "192-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_37",
            "tgt_ix": "192-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_38",
            "tgt_ix": "192-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_38",
            "tgt_ix": "192-ARR_v1_38@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_39",
            "tgt_ix": "192-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_39",
            "tgt_ix": "192-ARR_v1_39@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_40",
            "tgt_ix": "192-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_41",
            "tgt_ix": "192-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_42",
            "tgt_ix": "192-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_43",
            "tgt_ix": "192-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_43",
            "tgt_ix": "192-ARR_v1_43@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_44",
            "tgt_ix": "192-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_45",
            "tgt_ix": "192-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_45",
            "tgt_ix": "192-ARR_v1_45@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_45",
            "tgt_ix": "192-ARR_v1_45@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_46",
            "tgt_ix": "192-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_46",
            "tgt_ix": "192-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_47",
            "tgt_ix": "192-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_48",
            "tgt_ix": "192-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_48",
            "tgt_ix": "192-ARR_v1_48@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_48",
            "tgt_ix": "192-ARR_v1_48@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_49",
            "tgt_ix": "192-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_50",
            "tgt_ix": "192-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_50",
            "tgt_ix": "192-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_50",
            "tgt_ix": "192-ARR_v1_50@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_50",
            "tgt_ix": "192-ARR_v1_50@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_50",
            "tgt_ix": "192-ARR_v1_50@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_51",
            "tgt_ix": "192-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_52",
            "tgt_ix": "192-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_53",
            "tgt_ix": "192-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_54",
            "tgt_ix": "192-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_55",
            "tgt_ix": "192-ARR_v1_55@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_56",
            "tgt_ix": "192-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_57",
            "tgt_ix": "192-ARR_v1_57@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_58",
            "tgt_ix": "192-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_59",
            "tgt_ix": "192-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_60",
            "tgt_ix": "192-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_61",
            "tgt_ix": "192-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_61",
            "tgt_ix": "192-ARR_v1_61@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_62",
            "tgt_ix": "192-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_63",
            "tgt_ix": "192-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_63",
            "tgt_ix": "192-ARR_v1_63@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_63",
            "tgt_ix": "192-ARR_v1_63@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_64",
            "tgt_ix": "192-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_64",
            "tgt_ix": "192-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_64",
            "tgt_ix": "192-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_65",
            "tgt_ix": "192-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_66",
            "tgt_ix": "192-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_66",
            "tgt_ix": "192-ARR_v1_66@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_67",
            "tgt_ix": "192-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_67",
            "tgt_ix": "192-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_67",
            "tgt_ix": "192-ARR_v1_67@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_68",
            "tgt_ix": "192-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_68",
            "tgt_ix": "192-ARR_v1_68@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_69",
            "tgt_ix": "192-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_69",
            "tgt_ix": "192-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_69",
            "tgt_ix": "192-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_70",
            "tgt_ix": "192-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_71",
            "tgt_ix": "192-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_71",
            "tgt_ix": "192-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_72",
            "tgt_ix": "192-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_72",
            "tgt_ix": "192-ARR_v1_72@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_72",
            "tgt_ix": "192-ARR_v1_72@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_72",
            "tgt_ix": "192-ARR_v1_72@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_72",
            "tgt_ix": "192-ARR_v1_72@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_73",
            "tgt_ix": "192-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_74",
            "tgt_ix": "192-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_74",
            "tgt_ix": "192-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_74",
            "tgt_ix": "192-ARR_v1_74@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_74",
            "tgt_ix": "192-ARR_v1_74@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_75",
            "tgt_ix": "192-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_76",
            "tgt_ix": "192-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_76",
            "tgt_ix": "192-ARR_v1_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_77",
            "tgt_ix": "192-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_77",
            "tgt_ix": "192-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_78",
            "tgt_ix": "192-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_78",
            "tgt_ix": "192-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_79",
            "tgt_ix": "192-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_79",
            "tgt_ix": "192-ARR_v1_79@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_79",
            "tgt_ix": "192-ARR_v1_79@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_80",
            "tgt_ix": "192-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_81",
            "tgt_ix": "192-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_81",
            "tgt_ix": "192-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_81",
            "tgt_ix": "192-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_81",
            "tgt_ix": "192-ARR_v1_81@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_82",
            "tgt_ix": "192-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_83",
            "tgt_ix": "192-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_84",
            "tgt_ix": "192-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_85",
            "tgt_ix": "192-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_86",
            "tgt_ix": "192-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_87",
            "tgt_ix": "192-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_88",
            "tgt_ix": "192-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_89",
            "tgt_ix": "192-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_90",
            "tgt_ix": "192-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_91",
            "tgt_ix": "192-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_92",
            "tgt_ix": "192-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_93",
            "tgt_ix": "192-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_94",
            "tgt_ix": "192-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_95",
            "tgt_ix": "192-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_96",
            "tgt_ix": "192-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_97",
            "tgt_ix": "192-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_98",
            "tgt_ix": "192-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_99",
            "tgt_ix": "192-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_100",
            "tgt_ix": "192-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_101",
            "tgt_ix": "192-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_102",
            "tgt_ix": "192-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_103",
            "tgt_ix": "192-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_104",
            "tgt_ix": "192-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_105",
            "tgt_ix": "192-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "192-ARR_v1_106",
            "tgt_ix": "192-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1208,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "192-ARR",
        "version": 1
    }
}