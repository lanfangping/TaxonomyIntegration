{
    "nodes": [
        {
            "ix": "86-ARR_v1_0",
            "content": "MPII: Multi-Level Mutual Promotion for Inference and Interpretation",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_1",
            "content": "Abstract",
            "ntype": "abstract",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_2",
            "content": "In order to better understand the rationale behind model behavior, recent works have exploited providing interpretation to support the inference prediction. However, existing methods tend to provide human-unfriendly interpretation, and are prone to sub-optimal performance due to one-side promotion, i.e. either inference promotion with interpretation or vice versa. In this paper, we propose a multi-level Mutual Promotion mechanism for self-evolved Inference and sentence-level Interpretation (MPII). Specifically, from the modellevel, we propose a Step-wise Integration Mechanism to jointly perform and deeply integrate inference and interpretation in an autoregressive manner. From the optimization-level, we propose an Adversarial Fidelity Regularization to improve the fidelity between inference and interpretation with the Adversarial Mutual Information training strategy. Extensive experiments on NLI and CQA tasks reveal that the proposed MPII approach can significantly outperform baseline models for both the inference performance and the interpretation quality.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_3",
            "content": "Introduction",
            "ntype": "title",
            "meta": {
                "section": "1"
            }
        },
        {
            "ix": "86-ARR_v1_4",
            "content": "Recently, the interpretability of neural networks has been of increasing concern. In order to break the black-box of neural networks, many works explore the interpretability of neural networks through providing interpretation to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2018;Thorne et al., 2019;Kumar and Talukdar, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_5",
            "content": "Although prior works have made some progress towards interpretable NLP, they tend to provide interpretations that lack human-readability. Existing interpretable models usually extract prominent features or select input key words as explanations, such as attention distribution (Xu et al., 2015), heatmap (Samek et al., 2017), alignment rationale (Jiang et al., 2021), gradients (Li et al., Token-level Explanation:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_6",
            "content": "Passengers, through, walk, down, car",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_7",
            "content": "Figure 1: Comparison of different interpretations: heatmap explanation, alignment rationale, token-level NL explanation, and sentence-level NL explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_8",
            "content": "2016), magnitude of hidden states (Linzen et al., 2016), etc. Considering readability and comprehensibleness for human, some works turn to generate token-level explanations (Liu et al., 2018;Thorne et al., 2019), which nevertheless prone to cause ambiguity. Figure 1 shows some prevalent forms of interpretations in NLI task. Obviously, human language interpretations seem more acceptable than those chaotic maps, whether it is heatmap or alignment map. As for the token-level interpretation, several discrete tokens without any logical links are vague and ambiguous. Moreover, Thorne et al. (2019) observed that token-level methods tend to predict common tokens (e.g. people, man, dog) rather than keywords. Intuitively, human language sentence-level interpretations containing reasoning logic is the best form for human to understand.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_9",
            "content": "With the annotated natural language interpretation datasets available (Camburu et al., 2018;Rajani et al., 2019), methods of generating sentencelevel interpretation have been explored recently. Camburu et al. (2018) proposed to first generate interpretation and then predict the label only based on the generated interpretation. Kumar and Talukdar (2020) proposed to first generate sentence-level interpretation with deep pre-trained language models (such as BERT and GPT), then fed those interpretation as extra knowledge to help improve inference performance. We notice that these methods only include one-side promotion: utilizing information contained in interpretation to improve inference, while ignoring the other-side promotion: using inference logic to enhance interpretation. As claimed in Kumar and Talukdar (2020) that their one-side promotion improves predictions' faithfulness to generated interpretations, then the otherside should be able to improve interpretation's faithfulness to inference process. This has aroused our thinking: Can we deeply fuse these two relevant tasks with ingenious combination skills and achieve mutual promotion for inference and interpretation?",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_10",
            "content": "In this paper, we propose a multi-level Mutual Promotion mechanism for self-evolved Inference and sentence-level Interpretation (MPII). Specifically, from the model-level, we propose a Stepwise Integration Mechanism (SIM) to iteratively update the inference prediction and generate an interpretation token at each decoding step, and deeply integrate hidden representations of the prediction and the token with two fusion modules. In this way, the model learns to refine the inference conclusion as the interpretation proceeds, and the inference procedure can in turn guide the generation of interpretation at each decoding step. From the optimization-level, we propose an Adversarial Fidelity Regularization (AFiRe) to improve the fidelity between inference and interpretation with the Adversarial Mutual Information (AMI) method (Pan et al., 2020), which extends the maximum mutual information optimization objective with the idea of generative adversarial network (Goodfellow et al., 2014). With this training framework, the model is trained against a smart backward network that learns to reward the inference prediction and interpretation of fidelity, which ensures faithfulness and makes the derived interpretation depict the true profile of how the model works (Jiang et al., 2021).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_11",
            "content": "To verify the effectiveness of MPII, we conduct extensive experiments on two inference tasks: Natural Language Inference (NLI) task and Commonsense Question Answering (CQA) task. Experiment results reveal that compared with baseline models, our method can achieve mutual promotion on both model inference performance and sentencelevel interpretation quality. Meanwhile, through providing simultaneous inference prediction and human-comprehensible interpretation with deep integration mechanism and adversarial training strategy, our model can perform inference and interpretation of fidelity and generate more robust explanations. Main contributions of this work include:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_12",
            "content": "\u2022 Different from the previous works that only include one-side promotion, we mutually promote the inference and sentence-level interpretation from both the model-level and the optimization-level. \u2022 We propose a Stepwise Integration Mechanism to tightly fuse latent prediction and interpretation information at every decoding step, and an Adversarial Fidelity Regularization to further improve the fidelity with the adversarial training strategy. \u2022 Experiment results show that our method achieve significant improvement in both inference accuracy and interpretation quality compared with baseline models.",
            "ntype": "list",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_13",
            "content": "Methodology",
            "ntype": "title",
            "meta": {
                "section": "2"
            }
        },
        {
            "ix": "86-ARR_v1_14",
            "content": "In this section, we introduce Stepwise Integration Mechanism (SIM) and Adversarial Fidelity Regularization (AFiRe) in details. Utilizing the autoregressive nature of Transformer decoder, SIM allows deep interaction at every decoding step between inference and interpretation. With the adversarial training strategy, AFiRe allows further integration of latent semantic information between inference and interpretation, and also improves the quality of explanation sentences, bringing them closer to human expressions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_15",
            "content": "Task Description",
            "ntype": "title",
            "meta": {
                "section": "2.1"
            }
        },
        {
            "ix": "86-ARR_v1_16",
            "content": "Transformer model (Vaswani et al., 2017) The overall architecture of our model. Both prediction label and explanation token are generated at every decoding step. Two fusion gates are attached to enable deep interaction of their hidden representations. each decoding step, Transformer decoder takes the embedding of words generated by previous steps as input and predict the word for current step.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_17",
            "content": "With ground truth prediction L and explanation E from dataset annotated by human, the interpretable model is required to generate prediction L \u2032 and explanation sentence E \u2032 = {e \u2032 0 , e \u2032 1 , ..., e \u2032 n } simultaneously.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_18",
            "content": "Stepwise Integration Mechanism",
            "ntype": "title",
            "meta": {
                "section": "2.2"
            }
        },
        {
            "ix": "86-ARR_v1_19",
            "content": "Prevalent interpretable models share the same encoder and separately adopt a MLP and a decoder to generate predictions and explanations. We analogously adopt the standard Transformer encoder, but apply Stepwise Integration Mechanism to deeply integrate standard MLP and Transformer decoder at every decoding step to simultaneously produce predictions and explanations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_20",
            "content": "As depicted in Figure 2, at decoding step t, decoder takes the last generated token e \u2032 t\u22121 and the predicted label l \u2032 t\u22121 at previous step as input. At the first decoding step, we pass the encoder hidden state corresponding to [CLS] token into MLP to get the l \u2032 0 . We project the label l \u2032 t\u22121 with Multi-Layer Perceptrons (MLP) and obtain v p t\u22121 , which represents the previous step prediction information. We then fuse the prediction information v p t\u22121 and the explanation token e \u2032 t\u22121 with gate mechanism. The gate probability at t step is computed by:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_21",
            "content": "p \u2032 t = ReLU(W 1 [Emb l \u2032 t\u22121 ; Emb e \u2032 t\u22121 ] + b 1 ) (1) p t = \u03c3(W 2 p \u2032 t + b 2 ) (2)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_22",
            "content": "where \";\" means concatenation, W 1 , W 2 , b 1 and b 2 are trainable parameters. ReLU(.) here denotes the ReLU activation function (Nair and Hinton, 2010), \u03c3(.) represents the sigmoid function. We fuse the prediction and interpretation information as below:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_23",
            "content": "Emb t = p t Emb l \u2032 t\u22121 + (1 \u2212 p t )Emb e \u2032 t\u22121 (3)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_24",
            "content": "where Emb t contains the information of prediction and the overall explanation sub-sequence generated in all previous steps. We utilize the stack of masked self-attention layers f sa used in Transformer decoder to compute the decoder hidden states:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_25",
            "content": "{h 0 , h 1 , ..., h t } = f sa ({Emb 0 , Emb 1 , ..., Emb t }) (4)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_26",
            "content": "The attention vector referring to the source sequence is computed with multi-head attention:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_27",
            "content": "v t = f mha (H enc , h t )(5)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_28",
            "content": "where H enc represents the encoder hidden states, f mha denotes the multi-head attention module. The v t is further passed into a fully connected layer followed with softmax function to obtain the vocabulary distribution of generated explanation token e \u2032 t at t step:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_29",
            "content": "e \u2032 t = argmax(sof tmax(Wv t + b)) (6)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_30",
            "content": "where W and b are both trainable parameters. The gate mechanism is then used to integrate the explanation information to update the prediction information:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_31",
            "content": "p t = \u03c3(MLP 1 ([Emb l \u2032 t\u22121 ; MLP 2 (v t )])) (7)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_32",
            "content": "where the two MLP(.) use different parameters.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_33",
            "content": "Emb l \u2032 t = Emb l \u2032 t\u22121 + p t MLP 3 (v t )(8)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_34",
            "content": "We apply the residual connection (He et al., 2016) here, which is easier to optimize in the scenario of many decoding steps. This is similar to the gate mechanism used in Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) that learns to remember important information obtained on each decoding step. At the last decoding step, the model deduces the eventual decision:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_35",
            "content": "L \u2032 = argmax(sof tmax(Emb l \u2032 t )) (9",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_36",
            "content": ")",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_37",
            "content": "where n is the length of the generated explanation E \u2032 . With this setting, both prediction and explanation are updated at every decoding step.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_38",
            "content": "Step-by-step interpretation helps the model to better inference, stepwise inference in turn guides the generation of better explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_39",
            "content": "Adversarial Fidelity Regularization",
            "ntype": "title",
            "meta": {
                "section": "2.3"
            }
        },
        {
            "ix": "86-ARR_v1_40",
            "content": "From the level of optimization objective, we further introduce the Adversarial Fidelity Regularization (AFiRe) to improve the fidelity of inference and interpretation. We leverage the Adversarial Mutual Information (AMI) method (Pan et al., 2020) to extend the maximum mutual information objective among input, inference prediction and the generated explanation with the idea of generative adversarial network (Goodfellow et al., 2014).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_41",
            "content": "Compared to the maximum likelihood estimation (MLE) objective, maximum mutual information (MMI) objective encourages the model to generate the prediction and explanation that are more faithful to the input (Kinney and Atwal, 2014; Stratos, 2019). The mutual information I(X, L, E) among the input X, inference label L and explanation E is formulated as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_42",
            "content": "I(X, L, E) = E P (X,L,E) log P (X, L, E) P (X)P (L, E) = H(X) \u2212 H(X|L, E)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_43",
            "content": ", where H denotes the entropy.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_44",
            "content": "Because of the intractability of directly estimating the mutual information in high-dimensional space, we approximate the optimization objective with a Variational Information Maximization (Chen et al., 2016b;Zhang et al., 2018) lower bound (Poole et al., 2019):",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_45",
            "content": "I(X, L, E) = H(X) + E P (X,L,E) [logP (X|L, E)] = H(X) + E P (X,L,E) [logQ \u03d5 (X|L, E)] + E P (L,E) [KL(P (X|L, E)||Q \u03d5 (X|L, E))] \u2265 H(X) + E P (X) E P \u03b8 (L,E|X) [logQ \u03d5 (X|L, E)]",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_46",
            "content": ", where KL(\u2022||\u2022) denotes the Kullback-Leibler (KL) divergence between two distribution. P \u03b8 (L, E|X) and Q \u03d5 (X|L, E) denote the forward network (generating L, R conditioned on X) and the backward network (generating X conditioned on L, E) respectively.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_47",
            "content": "Since the entropy term H(X) associates with the training data and does not involve the parameters we optimize, the objective of MMI is equivalent as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_48",
            "content": "max \u03b8,\u03d5 E (L \u2032 ,E \u2032 )\u223cP \u03b8 (L \u2032 ,E \u2032 |X) logQ \u03d5 (X|L \u2032 , E \u2032 )",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_49",
            "content": ", where \u03b8 and \u03d5 are the parameters of the forward and backward network respectively. L \u2032 and E \u2032 represent the synthetic prediction label and explanation generated by the forward network.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_50",
            "content": "With the MMI optimization objective, the backward network is trained with only the synthetic label and explanation produced by the forward network, and prone to sub-optimal performance if the synthetic text is uninformative. Since the the backward network provides a reward for optimizing the forward network, a biased backward network may provide unreliable reward scores and mislead the forward network optimization.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_51",
            "content": "To remedy this problem, we leverage the Adversarial Mutual Information (AMI) method (Pan et al., 2020) to extend MMI with the idea of generative adversarial network (Goodfellow et al., 2014).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_52",
            "content": "Specifically, we first bring the min-max adversarial game into training procedure and add an additional objective term Q \u03d5 (X|L, E) to maximize the negative likelihood of Q \u03d5 when feeding it with the real data:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_53",
            "content": "min \u03d5 max \u03b8 E (L \u2032 ,E \u2032 )\u223cP \u03b8 (L \u2032 ,E \u2032 |X) logQ \u03d5 (X|L \u2032 , E \u2032 ) \u2212 Q \u03d5 (X|L, E)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_54",
            "content": "With this interactive training strategy and regularizing the backward network with both the synthetic data and real data, the forward network will be trained against a smarter backward network that only rewards prediction and explanation of fidelity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_55",
            "content": "We also add an objective term P \u03b8 (L, E|X) of maximum the negative likelihood of P \u03b8 to balance the positive samples as teacher-forcing algorithm (Li et al., 2017). The final optimization objective is formulated as:",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_56",
            "content": "min \u03d5 max \u03b8 P \u03b8 (L, E|X) + Mutual Information Adversarial Training E (L \u2032 ,E \u2032 )\u223cP\u03b8(L \u2032 ,E \u2032 |X) logQ \u03d5 (X|L \u2032 , E \u2032 ) \u2212 Q \u03d5 (X|L, E)",
            "ntype": "formula",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_57",
            "content": "As depicted in Fig 3, to encourage the forward network to learn a stronger connection between generated explanations and model predictions, we also add Q \u03d5 (X|L, E \u2032 ) as negative samples for backward network. This explicitly encourages the backward network to be capable of punishing the P \u03b8 when it generates unfaithful explanations.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_58",
            "content": "Experiments",
            "ntype": "title",
            "meta": {
                "section": "3"
            }
        },
        {
            "ix": "86-ARR_v1_59",
            "content": "We intend to verify the mutual promotion effect of SIM and AFiRe on the inference ability and interpretablity of model. We choose two tasks requiring inference ability: Natural Language Inference (NLI) and Commonsense Question Answering (CQA).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_60",
            "content": "Datasets",
            "ntype": "title",
            "meta": {
                "section": "3.1"
            }
        },
        {
            "ix": "86-ARR_v1_61",
            "content": "We use six datasets as our testbeds: SNLI (Bowman et al., 2015), e-SNLI (Camburu et al., 2018), CQA (Talmor et al., 2018), CoS-E (Rajani et al., 2019), MultiNLI (Williams et al., 2018), and SICK-E (Marelli et al., 2014).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_62",
            "content": "SNLI is a standard benchmark for NLI task, while e-SNLI extends it with human-annotated natural language explanations for each sentence pair. CoS-E 1 dataset extends CQA dataset with natural language explanations for each QA sample. MultiNLI is another large-scale NLI corpus, which includes a diverse range of genres. SICKe(Sentences Involving Compositional Knowledge for entailment) provides sentence pairs that are rich in the lexical, syntactic and semantic phenomena. The latter two datasets are used for out-of-domain test.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_63",
            "content": "Baselines NLI:",
            "ntype": "title",
            "meta": {
                "section": "3.2"
            }
        },
        {
            "ix": "86-ARR_v1_64",
            "content": "We use e-INFERSENT and Transformer as two baseline models for NLI task. The e-INFERSENT model adds a LSTM decoder into IN-FERSENT (Conneau et al., 2017) for explanations. The classification module and the explanation generation module are separated but share the same encoder. The Transformer model (Vaswani et al., 2017) adds a MLP layer for generating sentencelevel interpretations. With this baseline, we aim to test whether vanilla transformer without further interaction can achieve good results.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_65",
            "content": "CQA: We use CAGE (Rajani et al., 2019) as the baseline model for CQA task. CAGE adopts the explain-then-predict approach, which firstly finetunes a deep pretrained language model GPT (Radford et al., 2019) to generate explanations, then use a classifier to predict the inference label with the generated explanation and source text as the input.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_66",
            "content": "Metrics",
            "ntype": "title",
            "meta": {
                "section": "3.3"
            }
        },
        {
            "ix": "86-ARR_v1_67",
            "content": "To evaluate inference performance, we report Taskspecific Accuracy (NLI Accuracy and CQA Accuracy). To evaluate the quality of generated interpretation, we report BLEU (similarity between generation and ground truth), PPL (fluency of generated sentences), and Inter Repetition (diversity of generated explanations).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_68",
            "content": "Main Results",
            "ntype": "title",
            "meta": {
                "section": "3.4"
            }
        },
        {
            "ix": "86-ARR_v1_69",
            "content": "Table 1 shows automatic evaluation results on the SNLI and CQA datasets with the annotated explanation from the e-SNLI and CoS-E datasets. Compared with the baseline models, our MPII method can achieve significant performance improvement for both the inference and interpretation on two tasks. It indicates that the inference and interpretation process can be mutually promoted with our proposed method. With the ablation study, we notice a performance degradation of the inference and interpretation if we remove either of them, demonstrating the faithfulness between the generated explanation and the model's prediction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_70",
            "content": "Inference Promotion: We can achieve 11.73 and 2.06 absolute inference accuracy improvements compared to the baselines for the NLI and CQA task, respectively. For the NLI task, with our MPII framework, the Transformer baseline model can improve over 5 absolute accuracy score. The ablation study shows the contribution comes from not only the mutual interaction of inference and interpretation in the Stepwise Integration Mechanism (SIM), but also the adversarial mutual information training objective introduced in the Adversarial Fidelity Regularization (AFiRe). Moreover, with parameters initialized with the pretrained BART model, the accuracy can be further improved by a 4.53 absolute score. For the CQA task, we observe that better performance is still achieved compared with the CAGE baseline model. If we remove the AFiRe, a significant inference degradation would be witnessed. It also indicates the effectiveness of AFiRe for utilizing interpretability to improve the inference ability.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_71",
            "content": "Interpretation Promotion: The quality of generated interpretation can also be significantly improved with our mutual promotion method on both NLI and CQA tasks. For NLI task, combined with our MPII, the Transformer baseline model can provide more accurate, fluent and diverse interpretation with much better results in all metrics. Similar with the inference results, the ablation study shows that both SIM and AFiRe contribute to the performance improvement. With the pretrained BART model, we further improve the BLEU and Inter-Rep performance and get comparable PPL compared with the e-INFERSENT model. For CQA task, our method performs better in terms of BLEU score and the diversity of generated explanations. We notice that the BLEU scores are pretty low for CQA task, which may stem from the free form of expression for explanations in the dataset, i.e. several different explanations share the same commonsense knowledge. We observe that most of the explanations generated by our method are reasonable enough to interpret the predictions even though the BLEU scores are low. Our method also achieves a smaller Inter-Rep score, which shows that our model can provide more diverse explanations to reveal the inference process of making predictions.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_72",
            "content": "Out-of-Domain Evaluation",
            "ntype": "title",
            "meta": {
                "section": "3.5"
            }
        },
        {
            "ix": "86-ARR_v1_73",
            "content": "As shown in Table 2, we evaluate our method with the Transformer baseline model on two outof-domain datasets: MultiNLI and SICK-E. The results show that our mutual promotion method enables the Transformer model to be more robust, and achieve more than 3 accuracy improvement on both of the out-of-domain datasets without fine-tuning.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_74",
            "content": "It is because with our MPII method, the model can generate more reliable and domain-related interpretation, which helps to make more accurate inference prediction. The ablation results demonstrate the adversarial mutual information training strategy in AFiRe is very effective to improve the model's generalization and robustness.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_75",
            "content": "Fidelity Evaluation",
            "ntype": "title",
            "meta": {
                "section": "3.6"
            }
        },
        {
            "ix": "86-ARR_v1_76",
            "content": "We propose a model-based evaluation metric Critic-Score to evaluate the fidelity between model's inference predictions and interpretations. Inspired by Shen et al. (2017), which applied a trained model to automatically evaluate the text style transfer accuracy in the absence of parallel dataset, we pre-train a well-performed discriminator model to evaluate the fidelity between the predicted label and the generated explanation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_77",
            "content": "The discriminator is a binary classifier f : (X, L, E) \u2192 Y es/N o , which shares similar architecture with the backward network in our Adversarial Fidelity Regularization (Section 2.3). The training dataset is constructed based on the e-SNLI and CoS-E corpus. Given a sample \u27e8X i , L i , E i \u27e9 on e-SNLI that serves as a positive sample, we build the negative sample as \u27e8X i , L i , E j \u27e9, where explanation E j \u0338 = E i is selected from another e-SNLI sample that shares either the same premise or hypothesis. With this dataset, the discriminator model is trained to learn the intrinsic fidelity between the label and its corresponding explanation. The trained discriminator achieves 97% accuracy on its test set and is able to serve as a quantitative way of evaluating fidelity.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_78",
            "content": "As shown in Table 3, with our proposed mutual promotion method, the Transformer model can achieve significant improvement on Critic-Score between prediction and explanation. The ablation results confirm both the deep interaction design in Stepwise Integration Mechanism and the adversarial training strategy in Adversarial Mutual Information can contribute to the improvement of fidelity and faithfulness.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_79",
            "content": "Analysis",
            "ntype": "title",
            "meta": {
                "section": "3.7"
            }
        },
        {
            "ix": "86-ARR_v1_80",
            "content": "Mutual Promotion Visualization: like a peer or boardwalk [SEP] a couple hugging each other at the park\", of which the ground truth label is \"contradiction\". We observe that the model draws an initial conclusion that the entailment relationship between the premise and the hypothesis is not \"entailment\", and is not able to tell whether it is \"neutral\" or \"contradiction\". As the deliberation proceeds, our model comes to judge that it is \"contradiction\" with the generated interpretation \"a park does not have a peer or boardwalk\". From the clear split of the red and blue lines when 'does' and 'not' are generated, we can see that the prediction is very sensitive to explanation, which demonstrates the faithfulness (Kumar and Talukdar, 2020).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_81",
            "content": "To better evaluate the quality of generated explanations, we also measure the cosine similarity between generated explanations and human annotated explanations. The results are presented in Fig 5 . The cosine similarity of our method concentrates on 0.9 and achieves higher scores than CAGE, which demonstrates the effectiveness of our MPII for generating better interpretation that are closer to human expression.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_82",
            "content": "Case Study Table 4 shows randomly selected examples generated by different models in CQA task. For the first exapmle, CAGE makes wrong prediction, and generates explanation that obviously conflicts with common knowledge. In contrast, our method can make correct predictions and generate more reasonable explanations. Similarly for the second example, CAGE seems to directly copy words from the question that do not actually contain meaningful information. Our MPII still explains well, but fails to explain properly with AFiRe removed, even if the explanation contains the correct answer, which reveals the importance of AFiRe for Table 5: Human evaluation results on Fidelity-C(fidelity between correct prediction and corresponding interpretation), Fidelity-W(fidelity between wrong prediction and corresponding interpretation), LAcc(accuracy of selecting correct lables when only given the generated interpretations), Fluency(fluency of interpretation).",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_83",
            "content": "promotion of interpretation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_84",
            "content": "Human evaluation: We conduct human evaluation to further evaluate the effectiveness of MPII. We randomly selected 300 examples from the test set of e-SNLI, and asked 4 well-educated annotators to rate every sample with 4 metrics on a 1-5 Likert scale in a strictly blind fashion (Stent et al., 2005). As shown in Table 5, analogous to automatic evaluation results (Section 3.4), our MPII can generate interpretations with best quality and fidelity to corresponding inference predictions, whether correct or wrong.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_85",
            "content": "Related Work",
            "ntype": "title",
            "meta": {
                "section": "4"
            }
        },
        {
            "ix": "86-ARR_v1_86",
            "content": "With the great success of natual language inference, many recent works explore the interpretability of neural networks through providing interpretation to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2018;Thorne et al., 2019;Kumar and Talukdar, 2020). Three forms of interpretation are provided by these works: (1) feature-based interpretation (Chen et al., 2016a(Chen et al., , 2018Ribeiro et al., 2016Ribeiro et al., , 2018Li et al., 2016;Nguyen, 2018;Feng et al., 2018;Gururan-gan et al., 2018) such as attention distribution (Xu et al., 2015), heatmap (Samek et al., 2017), alignment rationale (Jiang et al., 2021), gradients (Li et al., 2016), magnitude of hidden states (Linzen et al., 2016), etc.; (2) token-level interpretation that relatively easy to comprehend but prone to ambiguity (Ribeiro et al., 2016;Liu et al., 2018;Thorne et al., 2019), and (3) sentence-level interpretation which has the best human-readability Camburu et al. ( 2018); Talmor et al. (2018); Kumar and Talukdar (2020). Different from the previous work which only include one-side promotion, we proposed the mutual promotion mechanism that can improve the performance of both inference and sentence-level interpretation.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_87",
            "content": "Conclusions",
            "ntype": "title",
            "meta": {
                "section": "5"
            }
        },
        {
            "ix": "86-ARR_v1_88",
            "content": "In this work, we propose to mutually promote model inference ability and interpretability from multi-levels. From the model-level, we propose Stepwise Integration Mechanism to enable the model to refine the prediction conclusion as the explaining proceeds and also to guide the generation of better explanation with the inference procedure of reaching prediction conclusion. From the optimization-level, we propose an Adversarial Fidelity Regularization, which leverages the Adversarial Mutual Information method to improve the fidelity between the inference and interpretation, which further guarantees faithfulness. Experiment results show the effectiveness of our proposed method on both NLI and CQA tasks. Future work will involve extending our approaches into other tasks of NLP. We hope that our work can encourage further research in this direction.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_89",
            "content": "Gabor Samuel R Bowman, Christopher Angeli, Christopher D Potts,  Manning, A large annotated corpus for learning natural language inference, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "ref",
            "meta": {
                "xid": "b0",
                "authors": [
                    "Gabor Samuel R Bowman",
                    "Christopher Angeli",
                    "Christopher D Potts",
                    " Manning"
                ],
                "title": "A large annotated corpus for learning natural language inference",
                "pub_date": "2015",
                "pub_title": "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_90",
            "content": "Oana-Maria Camburu, Tim Rockt\u00e4schel, Thomas Lukasiewicz, Phil Blunsom, e-snli: natural language inference with natural language explanations, 2018, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b1",
                "authors": [
                    "Oana-Maria Camburu",
                    "Tim Rockt\u00e4schel",
                    "Thomas Lukasiewicz",
                    "Phil Blunsom"
                ],
                "title": "e-snli: natural language inference with natural language explanations",
                "pub_date": "2018",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_91",
            "content": "Danqi Chen, Jason Bolton, Christopher D Manning, A thorough examination of the cnn/daily mail reading comprehension task, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b2",
                "authors": [
                    "Danqi Chen",
                    "Jason Bolton",
                    "Christopher D Manning"
                ],
                "title": "A thorough examination of the cnn/daily mail reading comprehension task",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "86-ARR_v1_92",
            "content": "Jianbo Chen, Le Song, Martin Wainwright, Michael Jordan, Learning to explain: An information-theoretic perspective on model interpretation, 2018-07-10, Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, .",
            "ntype": "ref",
            "meta": {
                "xid": "b3",
                "authors": [
                    "Jianbo Chen",
                    "Le Song",
                    "Martin Wainwright",
                    "Michael Jordan"
                ],
                "title": "Learning to explain: An information-theoretic perspective on model interpretation",
                "pub_date": "2018-07-10",
                "pub_title": "Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_93",
            "content": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel, Infogan: Interpretable representation learning by information maximizing generative adversarial nets, 2016, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b4",
                "authors": [
                    "Xi Chen",
                    "Yan Duan",
                    "Rein Houthooft",
                    "John Schulman",
                    "Ilya Sutskever",
                    "Pieter Abbeel"
                ],
                "title": "Infogan: Interpretable representation learning by information maximizing generative adversarial nets",
                "pub_date": "2016",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_94",
            "content": "UNKNOWN, None, 2017, Supervised learning of universal sentence representations from natural language inference data, .",
            "ntype": "ref",
            "meta": {
                "xid": "b5",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Supervised learning of universal sentence representations from natural language inference data",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_95",
            "content": "Eric Shi Feng, Alvin Wallace, I Grissom, Mohit Iyyer, Pedro Rodriguez, Jordan Boyd-Graber, Pathologies of neural models make interpretations difficult, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b6",
                "authors": [
                    "Eric Shi Feng",
                    "Alvin Wallace",
                    "I Grissom",
                    "Mohit Iyyer",
                    "Pedro Rodriguez",
                    "Jordan Boyd-Graber"
                ],
                "title": "Pathologies of neural models make interpretations difficult",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_96",
            "content": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Generative adversarial nets, 2014, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b7",
                "authors": [
                    "Ian Goodfellow",
                    "Jean Pouget-Abadie",
                    "Mehdi Mirza",
                    "Bing Xu",
                    "David Warde-Farley",
                    "Sherjil Ozair",
                    "Aaron Courville",
                    "Yoshua Bengio"
                ],
                "title": "Generative adversarial nets",
                "pub_date": "2014",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_97",
            "content": "Swabha Suchin Gururangan, Omer Swayamdipta, Roy Levy, Samuel Schwartz, Noah A Bowman,  Smith, Annotation artifacts in natural language inference data, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b8",
                "authors": [
                    "Swabha Suchin Gururangan",
                    "Omer Swayamdipta",
                    "Roy Levy",
                    "Samuel Schwartz",
                    "Noah A Bowman",
                    " Smith"
                ],
                "title": "Annotation artifacts in natural language inference data",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_98",
            "content": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep residual learning for image recognition, 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, .",
            "ntype": "ref",
            "meta": {
                "xid": "b9",
                "authors": [
                    "Kaiming He",
                    "Xiangyu Zhang",
                    "Shaoqing Ren",
                    "Jian Sun"
                ],
                "title": "Deep residual learning for image recognition",
                "pub_date": "2016",
                "pub_title": "Proceedings of the IEEE conference on computer vision and pattern recognition",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_99",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b10",
                "authors": [
                    "Sepp Hochreiter",
                    "J\u00fcrgen Schmidhuber"
                ],
                "title": "Long short-term memory",
                "pub_date": "1997",
                "pub_title": "Neural computation",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_100",
            "content": "Zhongtao Jiang, Yuanzhe Zhang, Zhao Yang, Jun Zhao, Kang Liu, Alignment rationale for natural language inference, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b11",
                "authors": [
                    "Zhongtao Jiang",
                    "Yuanzhe Zhang",
                    "Zhao Yang",
                    "Jun Zhao",
                    "Kang Liu"
                ],
                "title": "Alignment rationale for natural language inference",
                "pub_date": "2021",
                "pub_title": "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "86-ARR_v1_101",
            "content": "B Justin,  Kinney,  Gurinder, Equitability, mutual information, and the maximal information coefficient, 2014, Proceedings of the National Academy of Sciences, .",
            "ntype": "ref",
            "meta": {
                "xid": "b12",
                "authors": [
                    "B Justin",
                    " Kinney",
                    " Gurinder"
                ],
                "title": "Equitability, mutual information, and the maximal information coefficient",
                "pub_date": "2014",
                "pub_title": "Proceedings of the National Academy of Sciences",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_102",
            "content": "Sawan Kumar, Partha Talukdar, NILE : Natural language inference with faithful natural language explanations, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "ref",
            "meta": {
                "xid": "b13",
                "authors": [
                    "Sawan Kumar",
                    "Partha Talukdar"
                ],
                "title": "NILE : Natural language inference with faithful natural language explanations",
                "pub_date": "2020",
                "pub_title": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
                "pub": "Online. Association for Computational Linguistics"
            }
        },
        {
            "ix": "86-ARR_v1_103",
            "content": "UNKNOWN, None, 2016, Understanding neural networks through representation erasure, .",
            "ntype": "ref",
            "meta": {
                "xid": "b14",
                "authors": null,
                "title": null,
                "pub_date": "2016",
                "pub_title": "Understanding neural networks through representation erasure",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_104",
            "content": "Jiwei Li, Will Monroe, Tianlin Shi, S\u00e9bastien Jean, Alan Ritter, Dan Jurafsky, Adversarial learning for neural dialogue generation, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "ref",
            "meta": {
                "xid": "b15",
                "authors": [
                    "Jiwei Li",
                    "Will Monroe",
                    "Tianlin Shi",
                    "S\u00e9bastien Jean",
                    "Alan Ritter",
                    "Dan Jurafsky"
                ],
                "title": "Adversarial learning for neural dialogue generation",
                "pub_date": "2017",
                "pub_title": "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_105",
            "content": "Tal Linzen, Emmanuel Dupoux, Yoav Goldberg, Assessing the ability of lstms to learn syntaxsensitive dependencies, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "ref",
            "meta": {
                "xid": "b16",
                "authors": [
                    "Tal Linzen",
                    "Emmanuel Dupoux",
                    "Yoav Goldberg"
                ],
                "title": "Assessing the ability of lstms to learn syntaxsensitive dependencies",
                "pub_date": "2016",
                "pub_title": "Transactions of the Association for Computational Linguistics",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_106",
            "content": "UNKNOWN, None, 2018, Towards explainable nlp: A generative explanation framework for text classification, .",
            "ntype": "ref",
            "meta": {
                "xid": "b17",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Towards explainable nlp: A generative explanation framework for text classification",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_107",
            "content": "Marco Marelli, Luisa Bentivogli, Marco Baroni, Raffaella Bernardi, Stefano Menini, Roberto Zamparelli, Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment, 2014, Proceedings of the 8th international workshop on semantic evaluation, .",
            "ntype": "ref",
            "meta": {
                "xid": "b18",
                "authors": [
                    "Marco Marelli",
                    "Luisa Bentivogli",
                    "Marco Baroni",
                    "Raffaella Bernardi",
                    "Stefano Menini",
                    "Roberto Zamparelli"
                ],
                "title": "Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment",
                "pub_date": "2014",
                "pub_title": "Proceedings of the 8th international workshop on semantic evaluation",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_108",
            "content": "UNKNOWN, None, 2010, Rectified linear units improve restricted boltzmann machines, .",
            "ntype": "ref",
            "meta": {
                "xid": "b19",
                "authors": null,
                "title": null,
                "pub_date": "2010",
                "pub_title": "Rectified linear units improve restricted boltzmann machines",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_109",
            "content": "Dong Nguyen, Comparing automatic and human evaluation of local explanations for text classification, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b20",
                "authors": [
                    "Dong Nguyen"
                ],
                "title": "Comparing automatic and human evaluation of local explanations for text classification",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "86-ARR_v1_110",
            "content": "Yazheng Boyuan Pan, Kaizhao Yang, Bhavya Liang, Zhongming Kailkhura, Xian-Sheng Jin, Deng Hua, Bo Cai,  Li, Adversarial mutual information for text generation, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "ref",
            "meta": {
                "xid": "b21",
                "authors": [
                    "Yazheng Boyuan Pan",
                    "Kaizhao Yang",
                    "Bhavya Liang",
                    "Zhongming Kailkhura",
                    "Xian-Sheng Jin",
                    "Deng Hua",
                    "Bo Cai",
                    " Li"
                ],
                "title": "Adversarial mutual information for text generation",
                "pub_date": "2020",
                "pub_title": "International Conference on Machine Learning",
                "pub": "PMLR"
            }
        },
        {
            "ix": "86-ARR_v1_111",
            "content": "UNKNOWN, None, 2019, On variational bounds of mutual information, .",
            "ntype": "ref",
            "meta": {
                "xid": "b22",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "On variational bounds of mutual information",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_112",
            "content": "UNKNOWN, None, 2019, Language models are unsupervised multitask learners, .",
            "ntype": "ref",
            "meta": {
                "xid": "b23",
                "authors": null,
                "title": null,
                "pub_date": "2019",
                "pub_title": "Language models are unsupervised multitask learners",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_113",
            "content": "Bryan Nazneen Fatema Rajani, Caiming Mccann, Richard Xiong,  Socher, Explain yourself! leveraging language models for commonsense reasoning, 2019, Proceedings of the 2019 Conference of the Association for Computational Linguistics (ACL2019), .",
            "ntype": "ref",
            "meta": {
                "xid": "b24",
                "authors": [
                    "Bryan Nazneen Fatema Rajani",
                    "Caiming Mccann",
                    "Richard Xiong",
                    " Socher"
                ],
                "title": "Explain yourself! leveraging language models for commonsense reasoning",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the Association for Computational Linguistics (ACL2019)",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_114",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Why should i trust you?: Explaining the predictions of any classifier, 2016, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, ACM.",
            "ntype": "ref",
            "meta": {
                "xid": "b25",
                "authors": [
                    "Sameer Marco Tulio Ribeiro",
                    "Carlos Singh",
                    " Guestrin"
                ],
                "title": "Why should i trust you?: Explaining the predictions of any classifier",
                "pub_date": "2016",
                "pub_title": "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining",
                "pub": "ACM"
            }
        },
        {
            "ix": "86-ARR_v1_115",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Anchors: High-precision modelagnostic explanations, 2018, Thirty-Second AAAI Conference on Artificial Intelligence, .",
            "ntype": "ref",
            "meta": {
                "xid": "b26",
                "authors": [
                    "Sameer Marco Tulio Ribeiro",
                    "Carlos Singh",
                    " Guestrin"
                ],
                "title": "Anchors: High-precision modelagnostic explanations",
                "pub_date": "2018",
                "pub_title": "Thirty-Second AAAI Conference on Artificial Intelligence",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_116",
            "content": "UNKNOWN, None, 2017, Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models, .",
            "ntype": "ref",
            "meta": {
                "xid": "b27",
                "authors": null,
                "title": null,
                "pub_date": "2017",
                "pub_title": "Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_117",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b28",
                "authors": [
                    "Tianxiao Shen",
                    "Tao Lei",
                    "Regina Barzilay",
                    "Tommi Jaakkola"
                ],
                "title": "Style transfer from non-parallel text by cross-alignment",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_118",
            "content": "Amanda Stent, Matthew Marge, Mohit Singhai, Evaluating evaluation methods for generation in the presence of variation, 2005, international conference on intelligent text processing and computational linguistics, Springer.",
            "ntype": "ref",
            "meta": {
                "xid": "b29",
                "authors": [
                    "Amanda Stent",
                    "Matthew Marge",
                    "Mohit Singhai"
                ],
                "title": "Evaluating evaluation methods for generation in the presence of variation",
                "pub_date": "2005",
                "pub_title": "international conference on intelligent text processing and computational linguistics",
                "pub": "Springer"
            }
        },
        {
            "ix": "86-ARR_v1_119",
            "content": "Karl Stratos, Mutual information maximization for simple and accurate part-of-speech induction, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b30",
                "authors": [
                    "Karl Stratos"
                ],
                "title": "Mutual information maximization for simple and accurate part-of-speech induction",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long and Short Papers"
            }
        },
        {
            "ix": "86-ARR_v1_120",
            "content": "UNKNOWN, None, 2018, Commonsenseqa: A question answering challenge targeting commonsense knowledge, .",
            "ntype": "ref",
            "meta": {
                "xid": "b31",
                "authors": null,
                "title": null,
                "pub_date": "2018",
                "pub_title": "Commonsenseqa: A question answering challenge targeting commonsense knowledge",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_121",
            "content": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, Generating token-level explanations for natural language inference, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "ref",
            "meta": {
                "xid": "b32",
                "authors": [
                    "James Thorne",
                    "Andreas Vlachos",
                    "Christos Christodoulopoulos",
                    "Arpit Mittal"
                ],
                "title": "Generating token-level explanations for natural language inference",
                "pub_date": "2019",
                "pub_title": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_122",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b33",
                "authors": [
                    "Ashish Vaswani",
                    "Noam Shazeer",
                    "Niki Parmar",
                    "Jakob Uszkoreit",
                    "Llion Jones",
                    "Aidan Gomez",
                    "\u0141ukasz Kaiser",
                    "Illia Polosukhin"
                ],
                "title": "Attention is all you need",
                "pub_date": "2017",
                "pub_title": "Advances in neural information processing systems",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_123",
            "content": "Adina Williams, Nikita Nangia, Samuel Bowman, A broad-coverage challenge corpus for sentence understanding through inference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "ref",
            "meta": {
                "xid": "b34",
                "authors": [
                    "Adina Williams",
                    "Nikita Nangia",
                    "Samuel Bowman"
                ],
                "title": "A broad-coverage challenge corpus for sentence understanding through inference",
                "pub_date": "2018",
                "pub_title": "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies",
                "pub": "Long Papers"
            }
        },
        {
            "ix": "86-ARR_v1_124",
            "content": "Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, Yoshua Bengio, Show, attend and tell: Neural image caption generation with visual attention, 2015, International conference on machine learning, .",
            "ntype": "ref",
            "meta": {
                "xid": "b35",
                "authors": [
                    "Kelvin Xu",
                    "Jimmy Ba",
                    "Ryan Kiros",
                    "Kyunghyun Cho",
                    "Aaron Courville",
                    "Ruslan Salakhudinov",
                    "Rich Zemel",
                    "Yoshua Bengio"
                ],
                "title": "Show, attend and tell: Neural image caption generation with visual attention",
                "pub_date": "2015",
                "pub_title": "International conference on machine learning",
                "pub": null
            }
        },
        {
            "ix": "86-ARR_v1_125",
            "content": "Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett, Bill Dolan, Generating informative and diverse conversational responses via adversarial information maximization, 2018, Advances in Neural Information Processing Systems, .",
            "ntype": "ref",
            "meta": {
                "xid": "b36",
                "authors": [
                    "Yizhe Zhang",
                    "Michel Galley",
                    "Jianfeng Gao",
                    "Zhe Gan",
                    "Xiujun Li",
                    "Chris Brockett",
                    "Bill Dolan"
                ],
                "title": "Generating informative and diverse conversational responses via adversarial information maximization",
                "pub_date": "2018",
                "pub_title": "Advances in Neural Information Processing Systems",
                "pub": null
            }
        }
    ],
    "span_nodes": [
        {
            "ix": "86-ARR_v1_0@0",
            "content": "MPII: Multi-Level Mutual Promotion for Inference and Interpretation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_0",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_1@0",
            "content": "Abstract",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_1",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_2@0",
            "content": "In order to better understand the rationale behind model behavior, recent works have exploited providing interpretation to support the inference prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_2",
            "start": 0,
            "end": 155,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_2@1",
            "content": "However, existing methods tend to provide human-unfriendly interpretation, and are prone to sub-optimal performance due to one-side promotion, i.e. either inference promotion with interpretation or vice versa.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_2",
            "start": 157,
            "end": 365,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_2@2",
            "content": "In this paper, we propose a multi-level Mutual Promotion mechanism for self-evolved Inference and sentence-level Interpretation (MPII).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_2",
            "start": 367,
            "end": 501,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_2@3",
            "content": "Specifically, from the modellevel, we propose a Step-wise Integration Mechanism to jointly perform and deeply integrate inference and interpretation in an autoregressive manner.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_2",
            "start": 503,
            "end": 679,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_2@4",
            "content": "From the optimization-level, we propose an Adversarial Fidelity Regularization to improve the fidelity between inference and interpretation with the Adversarial Mutual Information training strategy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_2",
            "start": 681,
            "end": 878,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_2@5",
            "content": "Extensive experiments on NLI and CQA tasks reveal that the proposed MPII approach can significantly outperform baseline models for both the inference performance and the interpretation quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_2",
            "start": 880,
            "end": 1072,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_3@0",
            "content": "Introduction",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_3",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_4@0",
            "content": "Recently, the interpretability of neural networks has been of increasing concern.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_4",
            "start": 0,
            "end": 80,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_4@1",
            "content": "In order to break the black-box of neural networks, many works explore the interpretability of neural networks through providing interpretation to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2018;Thorne et al., 2019;Kumar and Talukdar, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_4",
            "start": 82,
            "end": 363,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_5@0",
            "content": "Although prior works have made some progress towards interpretable NLP, they tend to provide interpretations that lack human-readability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_5",
            "start": 0,
            "end": 136,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_5@1",
            "content": "Existing interpretable models usually extract prominent features or select input key words as explanations, such as attention distribution (Xu et al., 2015), heatmap (Samek et al., 2017), alignment rationale (Jiang et al., 2021), gradients (Li et al., Token-level Explanation:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_5",
            "start": 138,
            "end": 413,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_6@0",
            "content": "Passengers, through, walk, down, car",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_6",
            "start": 0,
            "end": 35,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_7@0",
            "content": "Figure 1: Comparison of different interpretations: heatmap explanation, alignment rationale, token-level NL explanation, and sentence-level NL explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_7",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_8@0",
            "content": "2016), magnitude of hidden states (Linzen et al., 2016), etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_8",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_8@1",
            "content": "Considering readability and comprehensibleness for human, some works turn to generate token-level explanations (Liu et al., 2018;Thorne et al., 2019), which nevertheless prone to cause ambiguity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_8",
            "start": 62,
            "end": 256,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_8@2",
            "content": "Figure 1 shows some prevalent forms of interpretations in NLI task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_8",
            "start": 258,
            "end": 324,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_8@3",
            "content": "Obviously, human language interpretations seem more acceptable than those chaotic maps, whether it is heatmap or alignment map.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_8",
            "start": 326,
            "end": 452,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_8@4",
            "content": "As for the token-level interpretation, several discrete tokens without any logical links are vague and ambiguous.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_8",
            "start": 454,
            "end": 566,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_8@5",
            "content": "Moreover, Thorne et al. (2019) observed that token-level methods tend to predict common tokens (e.g. people, man, dog) rather than keywords.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_8",
            "start": 568,
            "end": 707,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_8@6",
            "content": "Intuitively, human language sentence-level interpretations containing reasoning logic is the best form for human to understand.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_8",
            "start": 709,
            "end": 835,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_9@0",
            "content": "With the annotated natural language interpretation datasets available (Camburu et al., 2018;Rajani et al., 2019), methods of generating sentencelevel interpretation have been explored recently.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_9",
            "start": 0,
            "end": 192,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_9@1",
            "content": "Camburu et al. (2018) proposed to first generate interpretation and then predict the label only based on the generated interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_9",
            "start": 194,
            "end": 327,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_9@2",
            "content": "Kumar and Talukdar (2020) proposed to first generate sentence-level interpretation with deep pre-trained language models (such as BERT and GPT), then fed those interpretation as extra knowledge to help improve inference performance.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_9",
            "start": 329,
            "end": 560,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_9@3",
            "content": "We notice that these methods only include one-side promotion: utilizing information contained in interpretation to improve inference, while ignoring the other-side promotion: using inference logic to enhance interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_9",
            "start": 562,
            "end": 784,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_9@4",
            "content": "As claimed in Kumar and Talukdar (2020) that their one-side promotion improves predictions' faithfulness to generated interpretations, then the otherside should be able to improve interpretation's faithfulness to inference process.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_9",
            "start": 786,
            "end": 1016,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_9@5",
            "content": "This has aroused our thinking: Can we deeply fuse these two relevant tasks with ingenious combination skills and achieve mutual promotion for inference and interpretation?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_9",
            "start": 1018,
            "end": 1188,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_10@0",
            "content": "In this paper, we propose a multi-level Mutual Promotion mechanism for self-evolved Inference and sentence-level Interpretation (MPII).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_10",
            "start": 0,
            "end": 134,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_10@1",
            "content": "Specifically, from the model-level, we propose a Stepwise Integration Mechanism (SIM) to iteratively update the inference prediction and generate an interpretation token at each decoding step, and deeply integrate hidden representations of the prediction and the token with two fusion modules.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_10",
            "start": 136,
            "end": 428,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_10@2",
            "content": "In this way, the model learns to refine the inference conclusion as the interpretation proceeds, and the inference procedure can in turn guide the generation of interpretation at each decoding step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_10",
            "start": 430,
            "end": 627,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_10@3",
            "content": "From the optimization-level, we propose an Adversarial Fidelity Regularization (AFiRe) to improve the fidelity between inference and interpretation with the Adversarial Mutual Information (AMI) method (Pan et al., 2020), which extends the maximum mutual information optimization objective with the idea of generative adversarial network (Goodfellow et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_10",
            "start": 629,
            "end": 991,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_10@4",
            "content": "With this training framework, the model is trained against a smart backward network that learns to reward the inference prediction and interpretation of fidelity, which ensures faithfulness and makes the derived interpretation depict the true profile of how the model works (Jiang et al., 2021).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_10",
            "start": 993,
            "end": 1287,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_11@0",
            "content": "To verify the effectiveness of MPII, we conduct extensive experiments on two inference tasks: Natural Language Inference (NLI) task and Commonsense Question Answering (CQA) task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_11",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_11@1",
            "content": "Experiment results reveal that compared with baseline models, our method can achieve mutual promotion on both model inference performance and sentencelevel interpretation quality.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_11",
            "start": 179,
            "end": 357,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_11@2",
            "content": "Meanwhile, through providing simultaneous inference prediction and human-comprehensible interpretation with deep integration mechanism and adversarial training strategy, our model can perform inference and interpretation of fidelity and generate more robust explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_11",
            "start": 359,
            "end": 629,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_11@3",
            "content": "Main contributions of this work include:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_11",
            "start": 631,
            "end": 670,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_12@0",
            "content": "\u2022 Different from the previous works that only include one-side promotion, we mutually promote the inference and sentence-level interpretation from both the model-level and the optimization-level. \u2022 We propose a Stepwise Integration Mechanism to tightly fuse latent prediction and interpretation information at every decoding step, and an Adversarial Fidelity Regularization to further improve the fidelity with the adversarial training strategy. \u2022 Experiment results show that our method achieve significant improvement in both inference accuracy and interpretation quality compared with baseline models.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_12",
            "start": 0,
            "end": 603,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_13@0",
            "content": "Methodology",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_13",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_14@0",
            "content": "In this section, we introduce Stepwise Integration Mechanism (SIM) and Adversarial Fidelity Regularization (AFiRe) in details.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_14",
            "start": 0,
            "end": 125,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_14@1",
            "content": "Utilizing the autoregressive nature of Transformer decoder, SIM allows deep interaction at every decoding step between inference and interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_14",
            "start": 127,
            "end": 274,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_14@2",
            "content": "With the adversarial training strategy, AFiRe allows further integration of latent semantic information between inference and interpretation, and also improves the quality of explanation sentences, bringing them closer to human expressions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_14",
            "start": 276,
            "end": 515,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_15@0",
            "content": "Task Description",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_15",
            "start": 0,
            "end": 15,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_16@0",
            "content": "Transformer model (Vaswani et al., 2017) The overall architecture of our model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_16",
            "start": 0,
            "end": 78,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_16@1",
            "content": "Both prediction label and explanation token are generated at every decoding step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_16",
            "start": 80,
            "end": 160,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_16@2",
            "content": "Two fusion gates are attached to enable deep interaction of their hidden representations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_16",
            "start": 162,
            "end": 250,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_16@3",
            "content": "each decoding step, Transformer decoder takes the embedding of words generated by previous steps as input and predict the word for current step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_16",
            "start": 252,
            "end": 395,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_17@0",
            "content": "With ground truth prediction L and explanation E from dataset annotated by human, the interpretable model is required to generate prediction L \u2032 and explanation sentence E \u2032 = {e \u2032 0 , e \u2032 1 , ..., e \u2032 n } simultaneously.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_17",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_18@0",
            "content": "Stepwise Integration Mechanism",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_18",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_19@0",
            "content": "Prevalent interpretable models share the same encoder and separately adopt a MLP and a decoder to generate predictions and explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_19",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_19@1",
            "content": "We analogously adopt the standard Transformer encoder, but apply Stepwise Integration Mechanism to deeply integrate standard MLP and Transformer decoder at every decoding step to simultaneously produce predictions and explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_19",
            "start": 137,
            "end": 367,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_20@0",
            "content": "As depicted in Figure 2, at decoding step t, decoder takes the last generated token e \u2032 t\u22121 and the predicted label l \u2032 t\u22121 at previous step as input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_20",
            "start": 0,
            "end": 149,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_20@1",
            "content": "At the first decoding step, we pass the encoder hidden state corresponding to [CLS] token into MLP to get the l \u2032 0 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_20",
            "start": 151,
            "end": 267,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_20@2",
            "content": "We project the label l \u2032 t\u22121 with Multi-Layer Perceptrons (MLP) and obtain v p t\u22121 , which represents the previous step prediction information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_20",
            "start": 269,
            "end": 411,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_20@3",
            "content": "We then fuse the prediction information v p t\u22121 and the explanation token e \u2032 t\u22121 with gate mechanism.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_20",
            "start": 413,
            "end": 514,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_20@4",
            "content": "The gate probability at t step is computed by:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_20",
            "start": 516,
            "end": 561,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_21@0",
            "content": "p \u2032 t = ReLU(W 1 [Emb l \u2032 t\u22121 ; Emb e \u2032 t\u22121 ] + b 1 ) (1) p t = \u03c3(W 2 p \u2032 t + b 2 ) (2)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_21",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_22@0",
            "content": "where \";\" means concatenation, W 1 , W 2 , b 1 and b 2 are trainable parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_22",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_22@1",
            "content": "ReLU(.) here denotes the ReLU activation function (Nair and Hinton, 2010), \u03c3(.) represents the sigmoid function.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_22",
            "start": 81,
            "end": 192,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_22@2",
            "content": "We fuse the prediction and interpretation information as below:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_22",
            "start": 194,
            "end": 256,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_23@0",
            "content": "Emb t = p t Emb l \u2032 t\u22121 + (1 \u2212 p t )Emb e \u2032 t\u22121 (3)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_23",
            "start": 0,
            "end": 50,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_24@0",
            "content": "where Emb t contains the information of prediction and the overall explanation sub-sequence generated in all previous steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_24",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_24@1",
            "content": "We utilize the stack of masked self-attention layers f sa used in Transformer decoder to compute the decoder hidden states:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_24",
            "start": 125,
            "end": 247,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_25@0",
            "content": "{h 0 , h 1 , ..., h t } = f sa ({Emb 0 , Emb 1 , ..., Emb t }) (4)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_25",
            "start": 0,
            "end": 65,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_26@0",
            "content": "The attention vector referring to the source sequence is computed with multi-head attention:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_26",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_27@0",
            "content": "v t = f mha (H enc , h t )(5)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_27",
            "start": 0,
            "end": 28,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_28@0",
            "content": "where H enc represents the encoder hidden states, f mha denotes the multi-head attention module.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_28",
            "start": 0,
            "end": 95,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_28@1",
            "content": "The v t is further passed into a fully connected layer followed with softmax function to obtain the vocabulary distribution of generated explanation token e \u2032 t at t step:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_28",
            "start": 97,
            "end": 267,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_29@0",
            "content": "e \u2032 t = argmax(sof tmax(Wv t + b)) (6)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_29",
            "start": 0,
            "end": 37,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_30@0",
            "content": "where W and b are both trainable parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_30",
            "start": 0,
            "end": 43,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_30@1",
            "content": "The gate mechanism is then used to integrate the explanation information to update the prediction information:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_30",
            "start": 45,
            "end": 154,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_31@0",
            "content": "p t = \u03c3(MLP 1 ([Emb l \u2032 t\u22121 ; MLP 2 (v t )])) (7)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_31",
            "start": 0,
            "end": 48,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_32@0",
            "content": "where the two MLP(.) use different parameters.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_32",
            "start": 0,
            "end": 45,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_33@0",
            "content": "Emb l \u2032 t = Emb l \u2032 t\u22121 + p t MLP 3 (v t )(8)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_33",
            "start": 0,
            "end": 44,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_34@0",
            "content": "We apply the residual connection (He et al., 2016) here, which is easier to optimize in the scenario of many decoding steps.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_34",
            "start": 0,
            "end": 123,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_34@1",
            "content": "This is similar to the gate mechanism used in Long Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, 1997) that learns to remember important information obtained on each decoding step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_34",
            "start": 125,
            "end": 312,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_34@2",
            "content": "At the last decoding step, the model deduces the eventual decision:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_34",
            "start": 314,
            "end": 380,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_35@0",
            "content": "L \u2032 = argmax(sof tmax(Emb l \u2032 t )) (9",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_35",
            "start": 0,
            "end": 36,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_36@0",
            "content": ")",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_36",
            "start": 0,
            "end": 0,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_37@0",
            "content": "where n is the length of the generated explanation E \u2032 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_37",
            "start": 0,
            "end": 55,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_37@1",
            "content": "With this setting, both prediction and explanation are updated at every decoding step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_37",
            "start": 57,
            "end": 142,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_38@0",
            "content": "Step-by-step interpretation helps the model to better inference, stepwise inference in turn guides the generation of better explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_38",
            "start": 0,
            "end": 135,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_39@0",
            "content": "Adversarial Fidelity Regularization",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_39",
            "start": 0,
            "end": 34,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_40@0",
            "content": "From the level of optimization objective, we further introduce the Adversarial Fidelity Regularization (AFiRe) to improve the fidelity of inference and interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_40",
            "start": 0,
            "end": 166,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_40@1",
            "content": "We leverage the Adversarial Mutual Information (AMI) method (Pan et al., 2020) to extend the maximum mutual information objective among input, inference prediction and the generated explanation with the idea of generative adversarial network (Goodfellow et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_40",
            "start": 168,
            "end": 435,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_41@0",
            "content": "Compared to the maximum likelihood estimation (MLE) objective, maximum mutual information (MMI) objective encourages the model to generate the prediction and explanation that are more faithful to the input (Kinney and Atwal, 2014; Stratos, 2019).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_41",
            "start": 0,
            "end": 245,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_41@1",
            "content": "The mutual information I(X, L, E) among the input X, inference label L and explanation E is formulated as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_41",
            "start": 247,
            "end": 352,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_42@0",
            "content": "I(X, L, E) = E P (X,L,E) log P (X, L, E) P (X)P (L, E) = H(X) \u2212 H(X|L, E)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_42",
            "start": 0,
            "end": 72,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_43@0",
            "content": ", where H denotes the entropy.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_43",
            "start": 0,
            "end": 29,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_44@0",
            "content": "Because of the intractability of directly estimating the mutual information in high-dimensional space, we approximate the optimization objective with a Variational Information Maximization (Chen et al., 2016b;Zhang et al., 2018) lower bound (Poole et al., 2019):",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_44",
            "start": 0,
            "end": 261,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_45@0",
            "content": "I(X, L, E) = H(X) + E P (X,L,E) [logP (X|L, E)] = H(X) + E P (X,L,E) [logQ \u03d5 (X|L, E)] + E P (L,E) [KL(P (X|L, E)||Q \u03d5 (X|L, E))] \u2265 H(X) + E P (X) E P \u03b8 (L,E|X) [logQ \u03d5 (X|L, E)]",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_45",
            "start": 0,
            "end": 177,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_46@0",
            "content": ", where KL(\u2022||\u2022) denotes the Kullback-Leibler (KL) divergence between two distribution.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_46",
            "start": 0,
            "end": 86,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_46@1",
            "content": "P \u03b8 (L, E|X) and Q \u03d5 (X|L, E) denote the forward network (generating L, R conditioned on X) and the backward network (generating X conditioned on L, E) respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_46",
            "start": 88,
            "end": 252,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_47@0",
            "content": "Since the entropy term H(X) associates with the training data and does not involve the parameters we optimize, the objective of MMI is equivalent as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_47",
            "start": 0,
            "end": 148,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_48@0",
            "content": "max \u03b8,\u03d5 E (L \u2032 ,E \u2032 )\u223cP \u03b8 (L \u2032 ,E \u2032 |X) logQ \u03d5 (X|L \u2032 , E \u2032 )",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_48",
            "start": 0,
            "end": 60,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_49@0",
            "content": ", where \u03b8 and \u03d5 are the parameters of the forward and backward network respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_49",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_49@1",
            "content": "L \u2032 and E \u2032 represent the synthetic prediction label and explanation generated by the forward network.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_49",
            "start": 85,
            "end": 186,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_50@0",
            "content": "With the MMI optimization objective, the backward network is trained with only the synthetic label and explanation produced by the forward network, and prone to sub-optimal performance if the synthetic text is uninformative.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_50",
            "start": 0,
            "end": 223,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_50@1",
            "content": "Since the the backward network provides a reward for optimizing the forward network, a biased backward network may provide unreliable reward scores and mislead the forward network optimization.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_50",
            "start": 225,
            "end": 417,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_51@0",
            "content": "To remedy this problem, we leverage the Adversarial Mutual Information (AMI) method (Pan et al., 2020) to extend MMI with the idea of generative adversarial network (Goodfellow et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_51",
            "start": 0,
            "end": 190,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_52@0",
            "content": "Specifically, we first bring the min-max adversarial game into training procedure and add an additional objective term Q \u03d5 (X|L, E) to maximize the negative likelihood of Q \u03d5 when feeding it with the real data:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_52",
            "start": 0,
            "end": 209,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_53@0",
            "content": "min \u03d5 max \u03b8 E (L \u2032 ,E \u2032 )\u223cP \u03b8 (L \u2032 ,E \u2032 |X) logQ \u03d5 (X|L \u2032 , E \u2032 ) \u2212 Q \u03d5 (X|L, E)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_53",
            "start": 0,
            "end": 79,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_54@0",
            "content": "With this interactive training strategy and regularizing the backward network with both the synthetic data and real data, the forward network will be trained against a smarter backward network that only rewards prediction and explanation of fidelity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_54",
            "start": 0,
            "end": 249,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_55@0",
            "content": "We also add an objective term P \u03b8 (L, E|X) of maximum the negative likelihood of P \u03b8 to balance the positive samples as teacher-forcing algorithm (Li et al., 2017).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_55",
            "start": 0,
            "end": 163,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_55@1",
            "content": "The final optimization objective is formulated as:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_55",
            "start": 165,
            "end": 214,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_56@0",
            "content": "min \u03d5 max \u03b8 P \u03b8 (L, E|X) + Mutual Information Adversarial Training E (L \u2032 ,E \u2032 )\u223cP\u03b8(L \u2032 ,E \u2032 |X) logQ \u03d5 (X|L \u2032 , E \u2032 ) \u2212 Q \u03d5 (X|L, E)",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_56",
            "start": 0,
            "end": 132,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_57@0",
            "content": "As depicted in Fig 3, to encourage the forward network to learn a stronger connection between generated explanations and model predictions, we also add Q \u03d5 (X|L, E \u2032 ) as negative samples for backward network.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_57",
            "start": 0,
            "end": 208,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_57@1",
            "content": "This explicitly encourages the backward network to be capable of punishing the P \u03b8 when it generates unfaithful explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_57",
            "start": 210,
            "end": 334,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_58@0",
            "content": "Experiments",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_58",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_59@0",
            "content": "We intend to verify the mutual promotion effect of SIM and AFiRe on the inference ability and interpretablity of model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_59",
            "start": 0,
            "end": 118,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_59@1",
            "content": "We choose two tasks requiring inference ability: Natural Language Inference (NLI) and Commonsense Question Answering (CQA).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_59",
            "start": 120,
            "end": 242,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_60@0",
            "content": "Datasets",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_60",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_61@0",
            "content": "We use six datasets as our testbeds: SNLI (Bowman et al., 2015), e-SNLI (Camburu et al., 2018), CQA (Talmor et al., 2018), CoS-E (Rajani et al., 2019), MultiNLI (Williams et al., 2018), and SICK-E (Marelli et al., 2014).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_61",
            "start": 0,
            "end": 219,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_62@0",
            "content": "SNLI is a standard benchmark for NLI task, while e-SNLI extends it with human-annotated natural language explanations for each sentence pair.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_62",
            "start": 0,
            "end": 140,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_62@1",
            "content": "CoS-E 1 dataset extends CQA dataset with natural language explanations for each QA sample.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_62",
            "start": 142,
            "end": 231,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_62@2",
            "content": "MultiNLI is another large-scale NLI corpus, which includes a diverse range of genres.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_62",
            "start": 233,
            "end": 317,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_62@3",
            "content": "SICKe(Sentences Involving Compositional Knowledge for entailment) provides sentence pairs that are rich in the lexical, syntactic and semantic phenomena.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_62",
            "start": 319,
            "end": 471,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_62@4",
            "content": "The latter two datasets are used for out-of-domain test.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_62",
            "start": 473,
            "end": 528,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_63@0",
            "content": "Baselines NLI:",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_63",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_64@0",
            "content": "We use e-INFERSENT and Transformer as two baseline models for NLI task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_64",
            "start": 0,
            "end": 70,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_64@1",
            "content": "The e-INFERSENT model adds a LSTM decoder into IN-FERSENT (Conneau et al., 2017) for explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_64",
            "start": 72,
            "end": 169,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_64@2",
            "content": "The classification module and the explanation generation module are separated but share the same encoder.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_64",
            "start": 171,
            "end": 275,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_64@3",
            "content": "The Transformer model (Vaswani et al., 2017) adds a MLP layer for generating sentencelevel interpretations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_64",
            "start": 277,
            "end": 383,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_64@4",
            "content": "With this baseline, we aim to test whether vanilla transformer without further interaction can achieve good results.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_64",
            "start": 385,
            "end": 500,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_65@0",
            "content": "CQA: We use CAGE (Rajani et al., 2019) as the baseline model for CQA task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_65",
            "start": 0,
            "end": 73,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_65@1",
            "content": "CAGE adopts the explain-then-predict approach, which firstly finetunes a deep pretrained language model GPT (Radford et al., 2019) to generate explanations, then use a classifier to predict the inference label with the generated explanation and source text as the input.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_65",
            "start": 75,
            "end": 344,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_66@0",
            "content": "Metrics",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_66",
            "start": 0,
            "end": 6,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_67@0",
            "content": "To evaluate inference performance, we report Taskspecific Accuracy (NLI Accuracy and CQA Accuracy).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_67",
            "start": 0,
            "end": 98,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_67@1",
            "content": "To evaluate the quality of generated interpretation, we report BLEU (similarity between generation and ground truth), PPL (fluency of generated sentences), and Inter Repetition (diversity of generated explanations).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_67",
            "start": 100,
            "end": 314,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_68@0",
            "content": "Main Results",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_68",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_69@0",
            "content": "Table 1 shows automatic evaluation results on the SNLI and CQA datasets with the annotated explanation from the e-SNLI and CoS-E datasets.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_69",
            "start": 0,
            "end": 137,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_69@1",
            "content": "Compared with the baseline models, our MPII method can achieve significant performance improvement for both the inference and interpretation on two tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_69",
            "start": 139,
            "end": 292,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_69@2",
            "content": "It indicates that the inference and interpretation process can be mutually promoted with our proposed method.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_69",
            "start": 294,
            "end": 402,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_69@3",
            "content": "With the ablation study, we notice a performance degradation of the inference and interpretation if we remove either of them, demonstrating the faithfulness between the generated explanation and the model's prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_69",
            "start": 404,
            "end": 621,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_70@0",
            "content": "Inference Promotion: We can achieve 11.73 and 2.06 absolute inference accuracy improvements compared to the baselines for the NLI and CQA task, respectively.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_70",
            "start": 0,
            "end": 156,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_70@1",
            "content": "For the NLI task, with our MPII framework, the Transformer baseline model can improve over 5 absolute accuracy score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_70",
            "start": 158,
            "end": 274,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_70@2",
            "content": "The ablation study shows the contribution comes from not only the mutual interaction of inference and interpretation in the Stepwise Integration Mechanism (SIM), but also the adversarial mutual information training objective introduced in the Adversarial Fidelity Regularization (AFiRe).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_70",
            "start": 276,
            "end": 562,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_70@3",
            "content": "Moreover, with parameters initialized with the pretrained BART model, the accuracy can be further improved by a 4.53 absolute score.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_70",
            "start": 564,
            "end": 695,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_70@4",
            "content": "For the CQA task, we observe that better performance is still achieved compared with the CAGE baseline model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_70",
            "start": 697,
            "end": 805,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_70@5",
            "content": "If we remove the AFiRe, a significant inference degradation would be witnessed.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_70",
            "start": 807,
            "end": 885,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_70@6",
            "content": "It also indicates the effectiveness of AFiRe for utilizing interpretability to improve the inference ability.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_70",
            "start": 887,
            "end": 995,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@0",
            "content": "Interpretation Promotion: The quality of generated interpretation can also be significantly improved with our mutual promotion method on both NLI and CQA tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@1",
            "content": "For NLI task, combined with our MPII, the Transformer baseline model can provide more accurate, fluent and diverse interpretation with much better results in all metrics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 161,
            "end": 330,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@2",
            "content": "Similar with the inference results, the ablation study shows that both SIM and AFiRe contribute to the performance improvement.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 332,
            "end": 458,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@3",
            "content": "With the pretrained BART model, we further improve the BLEU and Inter-Rep performance and get comparable PPL compared with the e-INFERSENT model.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 460,
            "end": 604,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@4",
            "content": "For CQA task, our method performs better in terms of BLEU score and the diversity of generated explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 606,
            "end": 713,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@5",
            "content": "We notice that the BLEU scores are pretty low for CQA task, which may stem from the free form of expression for explanations in the dataset, i.e. several different explanations share the same commonsense knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 715,
            "end": 928,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@6",
            "content": "We observe that most of the explanations generated by our method are reasonable enough to interpret the predictions even though the BLEU scores are low.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 930,
            "end": 1081,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_71@7",
            "content": "Our method also achieves a smaller Inter-Rep score, which shows that our model can provide more diverse explanations to reveal the inference process of making predictions.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_71",
            "start": 1083,
            "end": 1253,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_72@0",
            "content": "Out-of-Domain Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_72",
            "start": 0,
            "end": 23,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_73@0",
            "content": "As shown in Table 2, we evaluate our method with the Transformer baseline model on two outof-domain datasets: MultiNLI and SICK-E. The results show that our mutual promotion method enables the Transformer model to be more robust, and achieve more than 3 accuracy improvement on both of the out-of-domain datasets without fine-tuning.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_73",
            "start": 0,
            "end": 332,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_74@0",
            "content": "It is because with our MPII method, the model can generate more reliable and domain-related interpretation, which helps to make more accurate inference prediction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_74",
            "start": 0,
            "end": 162,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_74@1",
            "content": "The ablation results demonstrate the adversarial mutual information training strategy in AFiRe is very effective to improve the model's generalization and robustness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_74",
            "start": 164,
            "end": 329,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_75@0",
            "content": "Fidelity Evaluation",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_75",
            "start": 0,
            "end": 18,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_76@0",
            "content": "We propose a model-based evaluation metric Critic-Score to evaluate the fidelity between model's inference predictions and interpretations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_76",
            "start": 0,
            "end": 138,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_76@1",
            "content": "Inspired by Shen et al. (2017), which applied a trained model to automatically evaluate the text style transfer accuracy in the absence of parallel dataset, we pre-train a well-performed discriminator model to evaluate the fidelity between the predicted label and the generated explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_76",
            "start": 140,
            "end": 429,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_77@0",
            "content": "The discriminator is a binary classifier f : (X, L, E) \u2192 Y es/N o , which shares similar architecture with the backward network in our Adversarial Fidelity Regularization (Section 2.3).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_77",
            "start": 0,
            "end": 184,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_77@1",
            "content": "The training dataset is constructed based on the e-SNLI and CoS-E corpus.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_77",
            "start": 186,
            "end": 258,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_77@2",
            "content": "Given a sample \u27e8X i , L i , E i \u27e9 on e-SNLI that serves as a positive sample, we build the negative sample as \u27e8X i , L i , E j \u27e9, where explanation E j \u0338 = E i is selected from another e-SNLI sample that shares either the same premise or hypothesis.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_77",
            "start": 260,
            "end": 508,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_77@3",
            "content": "With this dataset, the discriminator model is trained to learn the intrinsic fidelity between the label and its corresponding explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_77",
            "start": 510,
            "end": 647,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_77@4",
            "content": "The trained discriminator achieves 97% accuracy on its test set and is able to serve as a quantitative way of evaluating fidelity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_77",
            "start": 649,
            "end": 778,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_78@0",
            "content": "As shown in Table 3, with our proposed mutual promotion method, the Transformer model can achieve significant improvement on Critic-Score between prediction and explanation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_78",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_78@1",
            "content": "The ablation results confirm both the deep interaction design in Stepwise Integration Mechanism and the adversarial training strategy in Adversarial Mutual Information can contribute to the improvement of fidelity and faithfulness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_78",
            "start": 174,
            "end": 404,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_79@0",
            "content": "Analysis",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_79",
            "start": 0,
            "end": 7,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_80@0",
            "content": "Mutual Promotion Visualization: like a peer or boardwalk [SEP] a couple hugging each other at the park\", of which the ground truth label is \"contradiction\". We observe that the model draws an initial conclusion that the entailment relationship between the premise and the hypothesis is not \"entailment\", and is not able to tell whether it is \"neutral\" or \"contradiction\". As the deliberation proceeds, our model comes to judge that it is \"contradiction\" with the generated interpretation \"a park does not have a peer or boardwalk\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_80",
            "start": 0,
            "end": 530,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_80@1",
            "content": "From the clear split of the red and blue lines when 'does' and 'not' are generated, we can see that the prediction is very sensitive to explanation, which demonstrates the faithfulness (Kumar and Talukdar, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_80",
            "start": 532,
            "end": 743,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_81@0",
            "content": "To better evaluate the quality of generated explanations, we also measure the cosine similarity between generated explanations and human annotated explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_81",
            "start": 0,
            "end": 159,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_81@1",
            "content": "The results are presented in Fig 5 .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_81",
            "start": 161,
            "end": 196,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_81@2",
            "content": "The cosine similarity of our method concentrates on 0.9 and achieves higher scores than CAGE, which demonstrates the effectiveness of our MPII for generating better interpretation that are closer to human expression.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_81",
            "start": 198,
            "end": 413,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_82@0",
            "content": "Case Study Table 4 shows randomly selected examples generated by different models in CQA task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_82",
            "start": 0,
            "end": 93,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_82@1",
            "content": "For the first exapmle, CAGE makes wrong prediction, and generates explanation that obviously conflicts with common knowledge.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_82",
            "start": 95,
            "end": 219,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_82@2",
            "content": "In contrast, our method can make correct predictions and generate more reasonable explanations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_82",
            "start": 221,
            "end": 315,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_82@3",
            "content": "Similarly for the second example, CAGE seems to directly copy words from the question that do not actually contain meaningful information.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_82",
            "start": 317,
            "end": 454,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_82@4",
            "content": "Our MPII still explains well, but fails to explain properly with AFiRe removed, even if the explanation contains the correct answer, which reveals the importance of AFiRe for Table 5: Human evaluation results on Fidelity-C(fidelity between correct prediction and corresponding interpretation), Fidelity-W(fidelity between wrong prediction and corresponding interpretation), LAcc(accuracy of selecting correct lables when only given the generated interpretations), Fluency(fluency of interpretation).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_82",
            "start": 456,
            "end": 954,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_83@0",
            "content": "promotion of interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_83",
            "start": 0,
            "end": 27,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_84@0",
            "content": "Human evaluation: We conduct human evaluation to further evaluate the effectiveness of MPII.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_84",
            "start": 0,
            "end": 91,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_84@1",
            "content": "We randomly selected 300 examples from the test set of e-SNLI, and asked 4 well-educated annotators to rate every sample with 4 metrics on a 1-5 Likert scale in a strictly blind fashion (Stent et al., 2005).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_84",
            "start": 93,
            "end": 299,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_84@2",
            "content": "As shown in Table 5, analogous to automatic evaluation results (Section 3.4), our MPII can generate interpretations with best quality and fidelity to corresponding inference predictions, whether correct or wrong.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_84",
            "start": 301,
            "end": 512,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_85@0",
            "content": "Related Work",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_85",
            "start": 0,
            "end": 11,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_86@0",
            "content": "With the great success of natual language inference, many recent works explore the interpretability of neural networks through providing interpretation to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2018;Thorne et al., 2019;Kumar and Talukdar, 2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_86",
            "start": 0,
            "end": 289,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_86@1",
            "content": "Three forms of interpretation are provided by these works: (1) feature-based interpretation (Chen et al., 2016a(Chen et al., , 2018Ribeiro et al., 2016Ribeiro et al., , 2018Li et al., 2016;Nguyen, 2018;Feng et al., 2018;Gururan-gan et al., 2018) such as attention distribution (Xu et al., 2015), heatmap (Samek et al., 2017), alignment rationale (Jiang et al., 2021), gradients (Li et al., 2016), magnitude of hidden states (Linzen et al., 2016), etc.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_86",
            "start": 291,
            "end": 741,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_86@2",
            "content": "; (2) token-level interpretation that relatively easy to comprehend but prone to ambiguity (Ribeiro et al., 2016;Liu et al., 2018;Thorne et al., 2019), and (3) sentence-level interpretation which has the best human-readability Camburu et al. ( 2018); Talmor et al. (2018); Kumar and Talukdar (2020).",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_86",
            "start": 742,
            "end": 1040,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_86@3",
            "content": "Different from the previous work which only include one-side promotion, we proposed the mutual promotion mechanism that can improve the performance of both inference and sentence-level interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_86",
            "start": 1042,
            "end": 1241,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_87@0",
            "content": "Conclusions",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_87",
            "start": 0,
            "end": 10,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_88@0",
            "content": "In this work, we propose to mutually promote model inference ability and interpretability from multi-levels.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_88",
            "start": 0,
            "end": 107,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_88@1",
            "content": "From the model-level, we propose Stepwise Integration Mechanism to enable the model to refine the prediction conclusion as the explaining proceeds and also to guide the generation of better explanation with the inference procedure of reaching prediction conclusion.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_88",
            "start": 109,
            "end": 373,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_88@2",
            "content": "From the optimization-level, we propose an Adversarial Fidelity Regularization, which leverages the Adversarial Mutual Information method to improve the fidelity between the inference and interpretation, which further guarantees faithfulness.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_88",
            "start": 375,
            "end": 616,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_88@3",
            "content": "Experiment results show the effectiveness of our proposed method on both NLI and CQA tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_88",
            "start": 618,
            "end": 708,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_88@4",
            "content": "Future work will involve extending our approaches into other tasks of NLP.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_88",
            "start": 710,
            "end": 783,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_88@5",
            "content": "We hope that our work can encourage further research in this direction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_88",
            "start": 785,
            "end": 855,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_89@0",
            "content": "Gabor Samuel R Bowman, Christopher Angeli, Christopher D Potts,  Manning, A large annotated corpus for learning natural language inference, 2015, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_89",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_90@0",
            "content": "Oana-Maria Camburu, Tim Rockt\u00e4schel, Thomas Lukasiewicz, Phil Blunsom, e-snli: natural language inference with natural language explanations, 2018, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_90",
            "start": 0,
            "end": 199,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_91@0",
            "content": "Danqi Chen, Jason Bolton, Christopher D Manning, A thorough examination of the cnn/daily mail reading comprehension task, 2016, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_91",
            "start": 0,
            "end": 228,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_92@0",
            "content": "Jianbo Chen, Le Song, Martin Wainwright, Michael Jordan, Learning to explain: An information-theoretic perspective on model interpretation, 2018-07-10, Proceedings of the 35th International Conference on Machine Learning, ICML 2018, Stockholmsm\u00e4ssan, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_92",
            "start": 0,
            "end": 251,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_93@0",
            "content": "Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, Pieter Abbeel, Infogan: Interpretable representation learning by information maximizing generative adversarial nets, 2016, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_93",
            "start": 0,
            "end": 240,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_94@0",
            "content": "UNKNOWN, None, 2017, Supervised learning of universal sentence representations from natural language inference data, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_94",
            "start": 0,
            "end": 117,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_95@0",
            "content": "Eric Shi Feng, Alvin Wallace, I Grissom, Mohit Iyyer, Pedro Rodriguez, Jordan Boyd-Graber, Pathologies of neural models make interpretations difficult, 2018, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_95",
            "start": 0,
            "end": 246,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_96@0",
            "content": "Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Generative adversarial nets, 2014, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_96",
            "start": 0,
            "end": 211,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_97@0",
            "content": "Swabha Suchin Gururangan, Omer Swayamdipta, Roy Levy, Samuel Schwartz, Noah A Bowman,  Smith, Annotation artifacts in natural language inference data, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_97",
            "start": 0,
            "end": 301,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_98@0",
            "content": "Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep residual learning for image recognition, 2016, Proceedings of the IEEE conference on computer vision and pattern recognition, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_98",
            "start": 0,
            "end": 182,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_99@0",
            "content": "Sepp Hochreiter, J\u00fcrgen Schmidhuber, Long short-term memory, 1997, Neural computation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_99",
            "start": 0,
            "end": 87,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_100@0",
            "content": "Zhongtao Jiang, Yuanzhe Zhang, Zhao Yang, Jun Zhao, Kang Liu, Alignment rationale for natural language inference, 2021, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_100",
            "start": 0,
            "end": 333,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_101@0",
            "content": "B Justin,  Kinney,  Gurinder, Equitability, mutual information, and the maximal information coefficient, 2014, Proceedings of the National Academy of Sciences, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_101",
            "start": 0,
            "end": 160,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_102@0",
            "content": "Sawan Kumar, Partha Talukdar, NILE : Natural language inference with faithful natural language explanations, 2020, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Online. Association for Computational Linguistics.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_102",
            "start": 0,
            "end": 253,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_103@0",
            "content": "UNKNOWN, None, 2016, Understanding neural networks through representation erasure, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_103",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_104@0",
            "content": "Jiwei Li, Will Monroe, Tianlin Shi, S\u00e9bastien Jean, Alan Ritter, Dan Jurafsky, Adversarial learning for neural dialogue generation, 2017, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_104",
            "start": 0,
            "end": 226,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_105@0",
            "content": "Tal Linzen, Emmanuel Dupoux, Yoav Goldberg, Assessing the ability of lstms to learn syntaxsensitive dependencies, 2016, Transactions of the Association for Computational Linguistics, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_105",
            "start": 0,
            "end": 183,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_106@0",
            "content": "UNKNOWN, None, 2018, Towards explainable nlp: A generative explanation framework for text classification, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_106",
            "start": 0,
            "end": 106,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_107@0",
            "content": "Marco Marelli, Luisa Bentivogli, Marco Baroni, Raffaella Bernardi, Stefano Menini, Roberto Zamparelli, Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment, 2014, Proceedings of the 8th international workshop on semantic evaluation, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_107",
            "start": 0,
            "end": 330,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_108@0",
            "content": "UNKNOWN, None, 2010, Rectified linear units improve restricted boltzmann machines, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_108",
            "start": 0,
            "end": 83,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_109@0",
            "content": "Dong Nguyen, Comparing automatic and human evaluation of local explanations for text classification, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_109",
            "start": 0,
            "end": 262,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_110@0",
            "content": "Yazheng Boyuan Pan, Kaizhao Yang, Bhavya Liang, Zhongming Kailkhura, Xian-Sheng Jin, Deng Hua, Bo Cai,  Li, Adversarial mutual information for text generation, 2020, International Conference on Machine Learning, PMLR.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_110",
            "start": 0,
            "end": 216,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_111@0",
            "content": "UNKNOWN, None, 2019, On variational bounds of mutual information, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_111",
            "start": 0,
            "end": 66,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_112@0",
            "content": "UNKNOWN, None, 2019, Language models are unsupervised multitask learners, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_112",
            "start": 0,
            "end": 74,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_113@0",
            "content": "Bryan Nazneen Fatema Rajani, Caiming Mccann, Richard Xiong,  Socher, Explain yourself! leveraging language models for commonsense reasoning, 2019, Proceedings of the 2019 Conference of the Association for Computational Linguistics (ACL2019), .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_113",
            "start": 0,
            "end": 242,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_114@0",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Why should i trust you?: Explaining the predictions of any classifier, 2016, Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining, ACM.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_114",
            "start": 0,
            "end": 233,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_115@0",
            "content": "Sameer Marco Tulio Ribeiro, Carlos Singh,  Guestrin, Anchors: High-precision modelagnostic explanations, 2018, Thirty-Second AAAI Conference on Artificial Intelligence, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_115",
            "start": 0,
            "end": 169,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_116@0",
            "content": "UNKNOWN, None, 2017, Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_116",
            "start": 0,
            "end": 124,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_117@0",
            "content": "Tianxiao Shen, Tao Lei, Regina Barzilay, Tommi Jaakkola, Style transfer from non-parallel text by cross-alignment, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_117",
            "start": 0,
            "end": 172,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_118@0",
            "content": "Amanda Stent, Matthew Marge, Mohit Singhai, Evaluating evaluation methods for generation in the presence of variation, 2005, international conference on intelligent text processing and computational linguistics, Springer.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_118",
            "start": 0,
            "end": 220,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_119@0",
            "content": "Karl Stratos, Mutual information maximization for simple and accurate part-of-speech induction, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long and Short Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_119",
            "start": 0,
            "end": 267,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_120@0",
            "content": "UNKNOWN, None, 2018, Commonsenseqa: A question answering challenge targeting commonsense knowledge, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_120",
            "start": 0,
            "end": 100,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_121@0",
            "content": "James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, Generating token-level explanations for natural language inference, 2019, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_121",
            "start": 0,
            "end": 292,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_122@0",
            "content": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Attention is all you need, 2017, Advances in neural information processing systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_122",
            "start": 0,
            "end": 203,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_123@0",
            "content": "Adina Williams, Nikita Nangia, Samuel Bowman, A broad-coverage challenge corpus for sentence understanding through inference, 2018, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Long Papers.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_123",
            "start": 0,
            "end": 287,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_124@0",
            "content": "Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhudinov, Rich Zemel, Yoshua Bengio, Show, attend and tell: Neural image caption generation with visual attention, 2015, International conference on machine learning, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_124",
            "start": 0,
            "end": 243,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_125@0",
            "content": "Yizhe Zhang, Michel Galley, Jianfeng Gao, Zhe Gan, Xiujun Li, Chris Brockett, Bill Dolan, Generating informative and diverse conversational responses via adversarial information maximization, 2018, Advances in Neural Information Processing Systems, .",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_125",
            "start": 0,
            "end": 249,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_1",
            "tgt_ix": "86-ARR_v1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_1",
            "tgt_ix": "86-ARR_v1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_2",
            "tgt_ix": "86-ARR_v1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_4",
            "tgt_ix": "86-ARR_v1_5",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_5",
            "tgt_ix": "86-ARR_v1_6",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_6",
            "tgt_ix": "86-ARR_v1_7",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_7",
            "tgt_ix": "86-ARR_v1_8",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_9",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_9",
            "tgt_ix": "86-ARR_v1_10",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_10",
            "tgt_ix": "86-ARR_v1_11",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_11",
            "tgt_ix": "86-ARR_v1_12",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_5",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_6",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_7",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_8",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_9",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_10",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_11",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_12",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_13",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_13",
            "tgt_ix": "86-ARR_v1_14",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_13",
            "tgt_ix": "86-ARR_v1_14",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_13",
            "tgt_ix": "86-ARR_v1_15",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_14",
            "tgt_ix": "86-ARR_v1_15",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_16",
            "tgt_ix": "86-ARR_v1_17",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_15",
            "tgt_ix": "86-ARR_v1_16",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_15",
            "tgt_ix": "86-ARR_v1_17",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_15",
            "tgt_ix": "86-ARR_v1_16",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_13",
            "tgt_ix": "86-ARR_v1_18",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_17",
            "tgt_ix": "86-ARR_v1_18",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_19",
            "tgt_ix": "86-ARR_v1_20",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_20",
            "tgt_ix": "86-ARR_v1_21",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_21",
            "tgt_ix": "86-ARR_v1_22",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_22",
            "tgt_ix": "86-ARR_v1_23",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_23",
            "tgt_ix": "86-ARR_v1_24",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_24",
            "tgt_ix": "86-ARR_v1_25",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_25",
            "tgt_ix": "86-ARR_v1_26",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_26",
            "tgt_ix": "86-ARR_v1_27",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_27",
            "tgt_ix": "86-ARR_v1_28",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_28",
            "tgt_ix": "86-ARR_v1_29",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_29",
            "tgt_ix": "86-ARR_v1_30",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_30",
            "tgt_ix": "86-ARR_v1_31",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_31",
            "tgt_ix": "86-ARR_v1_32",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_32",
            "tgt_ix": "86-ARR_v1_33",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_33",
            "tgt_ix": "86-ARR_v1_34",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_34",
            "tgt_ix": "86-ARR_v1_35",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_35",
            "tgt_ix": "86-ARR_v1_36",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_36",
            "tgt_ix": "86-ARR_v1_37",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_37",
            "tgt_ix": "86-ARR_v1_38",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_19",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_20",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_21",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_22",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_23",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_24",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_25",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_26",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_27",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_28",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_29",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_30",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_31",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_32",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_33",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_34",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_35",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_36",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_37",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_38",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_19",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_13",
            "tgt_ix": "86-ARR_v1_39",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_38",
            "tgt_ix": "86-ARR_v1_39",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_40",
            "tgt_ix": "86-ARR_v1_41",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_41",
            "tgt_ix": "86-ARR_v1_42",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_42",
            "tgt_ix": "86-ARR_v1_43",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_43",
            "tgt_ix": "86-ARR_v1_44",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_44",
            "tgt_ix": "86-ARR_v1_45",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_45",
            "tgt_ix": "86-ARR_v1_46",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_46",
            "tgt_ix": "86-ARR_v1_47",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_47",
            "tgt_ix": "86-ARR_v1_48",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_48",
            "tgt_ix": "86-ARR_v1_49",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_49",
            "tgt_ix": "86-ARR_v1_50",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_50",
            "tgt_ix": "86-ARR_v1_51",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_51",
            "tgt_ix": "86-ARR_v1_52",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_52",
            "tgt_ix": "86-ARR_v1_53",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_53",
            "tgt_ix": "86-ARR_v1_54",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_54",
            "tgt_ix": "86-ARR_v1_55",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_55",
            "tgt_ix": "86-ARR_v1_56",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_56",
            "tgt_ix": "86-ARR_v1_57",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_40",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_41",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_42",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_43",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_44",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_45",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_46",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_47",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_48",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_49",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_50",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_51",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_52",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_53",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_54",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_55",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_56",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_57",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_40",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_58",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_57",
            "tgt_ix": "86-ARR_v1_58",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_59",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_59",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_60",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_59",
            "tgt_ix": "86-ARR_v1_60",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_61",
            "tgt_ix": "86-ARR_v1_62",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_60",
            "tgt_ix": "86-ARR_v1_61",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_60",
            "tgt_ix": "86-ARR_v1_62",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_60",
            "tgt_ix": "86-ARR_v1_61",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_63",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_62",
            "tgt_ix": "86-ARR_v1_63",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_64",
            "tgt_ix": "86-ARR_v1_65",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_63",
            "tgt_ix": "86-ARR_v1_64",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_63",
            "tgt_ix": "86-ARR_v1_65",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_63",
            "tgt_ix": "86-ARR_v1_64",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_66",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_65",
            "tgt_ix": "86-ARR_v1_66",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_66",
            "tgt_ix": "86-ARR_v1_67",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_66",
            "tgt_ix": "86-ARR_v1_67",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_68",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_67",
            "tgt_ix": "86-ARR_v1_68",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_69",
            "tgt_ix": "86-ARR_v1_70",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_71",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_68",
            "tgt_ix": "86-ARR_v1_69",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_68",
            "tgt_ix": "86-ARR_v1_70",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_68",
            "tgt_ix": "86-ARR_v1_71",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_68",
            "tgt_ix": "86-ARR_v1_69",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_72",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_72",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_73",
            "tgt_ix": "86-ARR_v1_74",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_72",
            "tgt_ix": "86-ARR_v1_73",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_72",
            "tgt_ix": "86-ARR_v1_74",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_72",
            "tgt_ix": "86-ARR_v1_73",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_75",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_74",
            "tgt_ix": "86-ARR_v1_75",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_76",
            "tgt_ix": "86-ARR_v1_77",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_77",
            "tgt_ix": "86-ARR_v1_78",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_75",
            "tgt_ix": "86-ARR_v1_76",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_75",
            "tgt_ix": "86-ARR_v1_77",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_75",
            "tgt_ix": "86-ARR_v1_78",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_75",
            "tgt_ix": "86-ARR_v1_76",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_79",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_78",
            "tgt_ix": "86-ARR_v1_79",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_79",
            "tgt_ix": "86-ARR_v1_80",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_79",
            "tgt_ix": "86-ARR_v1_80",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_81",
            "tgt_ix": "86-ARR_v1_82",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_82",
            "tgt_ix": "86-ARR_v1_83",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_83",
            "tgt_ix": "86-ARR_v1_84",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_79",
            "tgt_ix": "86-ARR_v1_81",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_79",
            "tgt_ix": "86-ARR_v1_82",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_79",
            "tgt_ix": "86-ARR_v1_83",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_79",
            "tgt_ix": "86-ARR_v1_84",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_80",
            "tgt_ix": "86-ARR_v1_81",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_85",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_84",
            "tgt_ix": "86-ARR_v1_85",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_85",
            "tgt_ix": "86-ARR_v1_86",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_85",
            "tgt_ix": "86-ARR_v1_86",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_87",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_86",
            "tgt_ix": "86-ARR_v1_87",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_87",
            "tgt_ix": "86-ARR_v1_88",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_87",
            "tgt_ix": "86-ARR_v1_88",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_0",
            "tgt_ix": "86-ARR_v1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_1",
            "tgt_ix": "86-ARR_v1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_2",
            "tgt_ix": "86-ARR_v1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_2",
            "tgt_ix": "86-ARR_v1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_2",
            "tgt_ix": "86-ARR_v1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_2",
            "tgt_ix": "86-ARR_v1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_2",
            "tgt_ix": "86-ARR_v1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_2",
            "tgt_ix": "86-ARR_v1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_3",
            "tgt_ix": "86-ARR_v1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_4",
            "tgt_ix": "86-ARR_v1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_4",
            "tgt_ix": "86-ARR_v1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_5",
            "tgt_ix": "86-ARR_v1_5@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_5",
            "tgt_ix": "86-ARR_v1_5@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_6",
            "tgt_ix": "86-ARR_v1_6@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_7",
            "tgt_ix": "86-ARR_v1_7@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_8@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_8@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_8@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_8@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_8@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_8@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_8",
            "tgt_ix": "86-ARR_v1_8@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_9",
            "tgt_ix": "86-ARR_v1_9@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_9",
            "tgt_ix": "86-ARR_v1_9@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_9",
            "tgt_ix": "86-ARR_v1_9@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_9",
            "tgt_ix": "86-ARR_v1_9@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_9",
            "tgt_ix": "86-ARR_v1_9@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_9",
            "tgt_ix": "86-ARR_v1_9@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_10",
            "tgt_ix": "86-ARR_v1_10@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_10",
            "tgt_ix": "86-ARR_v1_10@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_10",
            "tgt_ix": "86-ARR_v1_10@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_10",
            "tgt_ix": "86-ARR_v1_10@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_10",
            "tgt_ix": "86-ARR_v1_10@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_11",
            "tgt_ix": "86-ARR_v1_11@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_11",
            "tgt_ix": "86-ARR_v1_11@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_11",
            "tgt_ix": "86-ARR_v1_11@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_11",
            "tgt_ix": "86-ARR_v1_11@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_12",
            "tgt_ix": "86-ARR_v1_12@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_13",
            "tgt_ix": "86-ARR_v1_13@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_14",
            "tgt_ix": "86-ARR_v1_14@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_14",
            "tgt_ix": "86-ARR_v1_14@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_14",
            "tgt_ix": "86-ARR_v1_14@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_15",
            "tgt_ix": "86-ARR_v1_15@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_16",
            "tgt_ix": "86-ARR_v1_16@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_16",
            "tgt_ix": "86-ARR_v1_16@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_16",
            "tgt_ix": "86-ARR_v1_16@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_16",
            "tgt_ix": "86-ARR_v1_16@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_17",
            "tgt_ix": "86-ARR_v1_17@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_18",
            "tgt_ix": "86-ARR_v1_18@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_19",
            "tgt_ix": "86-ARR_v1_19@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_19",
            "tgt_ix": "86-ARR_v1_19@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_20",
            "tgt_ix": "86-ARR_v1_20@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_20",
            "tgt_ix": "86-ARR_v1_20@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_20",
            "tgt_ix": "86-ARR_v1_20@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_20",
            "tgt_ix": "86-ARR_v1_20@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_20",
            "tgt_ix": "86-ARR_v1_20@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_21",
            "tgt_ix": "86-ARR_v1_21@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_22",
            "tgt_ix": "86-ARR_v1_22@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_22",
            "tgt_ix": "86-ARR_v1_22@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_22",
            "tgt_ix": "86-ARR_v1_22@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_23",
            "tgt_ix": "86-ARR_v1_23@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_24",
            "tgt_ix": "86-ARR_v1_24@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_24",
            "tgt_ix": "86-ARR_v1_24@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_25",
            "tgt_ix": "86-ARR_v1_25@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_26",
            "tgt_ix": "86-ARR_v1_26@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_27",
            "tgt_ix": "86-ARR_v1_27@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_28",
            "tgt_ix": "86-ARR_v1_28@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_28",
            "tgt_ix": "86-ARR_v1_28@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_29",
            "tgt_ix": "86-ARR_v1_29@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_30",
            "tgt_ix": "86-ARR_v1_30@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_30",
            "tgt_ix": "86-ARR_v1_30@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_31",
            "tgt_ix": "86-ARR_v1_31@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_32",
            "tgt_ix": "86-ARR_v1_32@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_33",
            "tgt_ix": "86-ARR_v1_33@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_34",
            "tgt_ix": "86-ARR_v1_34@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_34",
            "tgt_ix": "86-ARR_v1_34@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_34",
            "tgt_ix": "86-ARR_v1_34@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_35",
            "tgt_ix": "86-ARR_v1_35@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_36",
            "tgt_ix": "86-ARR_v1_36@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_37",
            "tgt_ix": "86-ARR_v1_37@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_37",
            "tgt_ix": "86-ARR_v1_37@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_38",
            "tgt_ix": "86-ARR_v1_38@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_39",
            "tgt_ix": "86-ARR_v1_39@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_40",
            "tgt_ix": "86-ARR_v1_40@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_40",
            "tgt_ix": "86-ARR_v1_40@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_41",
            "tgt_ix": "86-ARR_v1_41@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_41",
            "tgt_ix": "86-ARR_v1_41@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_42",
            "tgt_ix": "86-ARR_v1_42@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_43",
            "tgt_ix": "86-ARR_v1_43@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_44",
            "tgt_ix": "86-ARR_v1_44@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_45",
            "tgt_ix": "86-ARR_v1_45@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_46",
            "tgt_ix": "86-ARR_v1_46@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_46",
            "tgt_ix": "86-ARR_v1_46@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_47",
            "tgt_ix": "86-ARR_v1_47@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_48",
            "tgt_ix": "86-ARR_v1_48@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_49",
            "tgt_ix": "86-ARR_v1_49@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_49",
            "tgt_ix": "86-ARR_v1_49@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_50",
            "tgt_ix": "86-ARR_v1_50@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_50",
            "tgt_ix": "86-ARR_v1_50@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_51",
            "tgt_ix": "86-ARR_v1_51@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_52",
            "tgt_ix": "86-ARR_v1_52@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_53",
            "tgt_ix": "86-ARR_v1_53@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_54",
            "tgt_ix": "86-ARR_v1_54@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_55",
            "tgt_ix": "86-ARR_v1_55@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_55",
            "tgt_ix": "86-ARR_v1_55@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_56",
            "tgt_ix": "86-ARR_v1_56@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_57",
            "tgt_ix": "86-ARR_v1_57@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_57",
            "tgt_ix": "86-ARR_v1_57@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_58",
            "tgt_ix": "86-ARR_v1_58@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_59",
            "tgt_ix": "86-ARR_v1_59@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_59",
            "tgt_ix": "86-ARR_v1_59@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_60",
            "tgt_ix": "86-ARR_v1_60@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_61",
            "tgt_ix": "86-ARR_v1_61@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_62",
            "tgt_ix": "86-ARR_v1_62@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_62",
            "tgt_ix": "86-ARR_v1_62@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_62",
            "tgt_ix": "86-ARR_v1_62@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_62",
            "tgt_ix": "86-ARR_v1_62@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_62",
            "tgt_ix": "86-ARR_v1_62@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_63",
            "tgt_ix": "86-ARR_v1_63@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_64",
            "tgt_ix": "86-ARR_v1_64@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_64",
            "tgt_ix": "86-ARR_v1_64@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_64",
            "tgt_ix": "86-ARR_v1_64@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_64",
            "tgt_ix": "86-ARR_v1_64@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_64",
            "tgt_ix": "86-ARR_v1_64@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_65",
            "tgt_ix": "86-ARR_v1_65@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_65",
            "tgt_ix": "86-ARR_v1_65@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_66",
            "tgt_ix": "86-ARR_v1_66@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_67",
            "tgt_ix": "86-ARR_v1_67@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_67",
            "tgt_ix": "86-ARR_v1_67@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_68",
            "tgt_ix": "86-ARR_v1_68@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_69",
            "tgt_ix": "86-ARR_v1_69@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_69",
            "tgt_ix": "86-ARR_v1_69@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_69",
            "tgt_ix": "86-ARR_v1_69@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_69",
            "tgt_ix": "86-ARR_v1_69@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_70@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_70@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_70@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_70@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_70@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_70@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_70",
            "tgt_ix": "86-ARR_v1_70@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_71",
            "tgt_ix": "86-ARR_v1_71@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_72",
            "tgt_ix": "86-ARR_v1_72@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_73",
            "tgt_ix": "86-ARR_v1_73@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_74",
            "tgt_ix": "86-ARR_v1_74@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_74",
            "tgt_ix": "86-ARR_v1_74@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_75",
            "tgt_ix": "86-ARR_v1_75@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_76",
            "tgt_ix": "86-ARR_v1_76@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_76",
            "tgt_ix": "86-ARR_v1_76@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_77",
            "tgt_ix": "86-ARR_v1_77@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_77",
            "tgt_ix": "86-ARR_v1_77@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_77",
            "tgt_ix": "86-ARR_v1_77@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_77",
            "tgt_ix": "86-ARR_v1_77@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_77",
            "tgt_ix": "86-ARR_v1_77@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_78",
            "tgt_ix": "86-ARR_v1_78@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_78",
            "tgt_ix": "86-ARR_v1_78@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_79",
            "tgt_ix": "86-ARR_v1_79@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_80",
            "tgt_ix": "86-ARR_v1_80@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_80",
            "tgt_ix": "86-ARR_v1_80@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_81",
            "tgt_ix": "86-ARR_v1_81@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_81",
            "tgt_ix": "86-ARR_v1_81@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_81",
            "tgt_ix": "86-ARR_v1_81@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_82",
            "tgt_ix": "86-ARR_v1_82@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_82",
            "tgt_ix": "86-ARR_v1_82@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_82",
            "tgt_ix": "86-ARR_v1_82@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_82",
            "tgt_ix": "86-ARR_v1_82@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_82",
            "tgt_ix": "86-ARR_v1_82@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_83",
            "tgt_ix": "86-ARR_v1_83@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_84",
            "tgt_ix": "86-ARR_v1_84@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_84",
            "tgt_ix": "86-ARR_v1_84@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_84",
            "tgt_ix": "86-ARR_v1_84@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_85",
            "tgt_ix": "86-ARR_v1_85@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_86",
            "tgt_ix": "86-ARR_v1_86@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_86",
            "tgt_ix": "86-ARR_v1_86@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_86",
            "tgt_ix": "86-ARR_v1_86@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_86",
            "tgt_ix": "86-ARR_v1_86@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_87",
            "tgt_ix": "86-ARR_v1_87@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_88",
            "tgt_ix": "86-ARR_v1_88@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_88",
            "tgt_ix": "86-ARR_v1_88@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_88",
            "tgt_ix": "86-ARR_v1_88@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_88",
            "tgt_ix": "86-ARR_v1_88@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_88",
            "tgt_ix": "86-ARR_v1_88@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_88",
            "tgt_ix": "86-ARR_v1_88@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_89",
            "tgt_ix": "86-ARR_v1_89@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_90",
            "tgt_ix": "86-ARR_v1_90@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_91",
            "tgt_ix": "86-ARR_v1_91@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_92",
            "tgt_ix": "86-ARR_v1_92@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_93",
            "tgt_ix": "86-ARR_v1_93@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_94",
            "tgt_ix": "86-ARR_v1_94@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_95",
            "tgt_ix": "86-ARR_v1_95@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_96",
            "tgt_ix": "86-ARR_v1_96@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_97",
            "tgt_ix": "86-ARR_v1_97@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_98",
            "tgt_ix": "86-ARR_v1_98@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_99",
            "tgt_ix": "86-ARR_v1_99@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_100",
            "tgt_ix": "86-ARR_v1_100@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_101",
            "tgt_ix": "86-ARR_v1_101@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_102",
            "tgt_ix": "86-ARR_v1_102@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_103",
            "tgt_ix": "86-ARR_v1_103@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_104",
            "tgt_ix": "86-ARR_v1_104@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_105",
            "tgt_ix": "86-ARR_v1_105@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_106",
            "tgt_ix": "86-ARR_v1_106@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_107",
            "tgt_ix": "86-ARR_v1_107@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_108",
            "tgt_ix": "86-ARR_v1_108@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_109",
            "tgt_ix": "86-ARR_v1_109@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_110",
            "tgt_ix": "86-ARR_v1_110@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_111",
            "tgt_ix": "86-ARR_v1_111@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_112",
            "tgt_ix": "86-ARR_v1_112@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_113",
            "tgt_ix": "86-ARR_v1_113@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_114",
            "tgt_ix": "86-ARR_v1_114@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_115",
            "tgt_ix": "86-ARR_v1_115@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_116",
            "tgt_ix": "86-ARR_v1_116@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_117",
            "tgt_ix": "86-ARR_v1_117@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_118",
            "tgt_ix": "86-ARR_v1_118@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_119",
            "tgt_ix": "86-ARR_v1_119@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_120",
            "tgt_ix": "86-ARR_v1_120@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_121",
            "tgt_ix": "86-ARR_v1_121@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_122",
            "tgt_ix": "86-ARR_v1_122@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_123",
            "tgt_ix": "86-ARR_v1_123@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_124",
            "tgt_ix": "86-ARR_v1_124@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_125",
            "tgt_ix": "86-ARR_v1_125@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "paper.tei",
    "meta": {
        "ix_counter": 1245,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy",
        "position_tag_type": "from_draft",
        "doc_id": "86-ARR",
        "version": 1
    }
}