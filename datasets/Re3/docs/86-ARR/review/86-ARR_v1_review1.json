{
    "nodes": [
        {
            "ix": "86-ARR_v1_review1_0",
            "content": "86-ARR_v1_review1",
            "ntype": "article-title",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_review1_1",
            "content": "paper_summary. This paper introduces a method to improve both interpretations and inference by training an end-to-end model to simultaneously generate explanations and labels for the NLI and CQA tasks. Compared to previous work which either produces explanations that are used to infer the label or vice-versa, this work introduces a framework that trains both tasks jointly. This is done by iteratively updating the predicted label at each explanation decoding step. The representations of the label and the explanation tokens are combined through gating mechanisms and used as input for the next timestep, enabling the model to use the explanation generated thus far to predict the label and the predicted label to guide the generation of the next explanation token. To improve the correlation between the inferred label and the generated interpretation, an additional adversarial regularization is used. Experiments show that this model shows improvements in both inference and interpretation compared to baselines.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_review1_2",
            "content": "summary_of_strengths. 1. The idea of jointly training inference and interpretation is interesting. It is intuitive that the inference and interpretation should guide each other and be dependent. \n2. Several experimental results are presented to show that the model improves over both generated explanations and predicted labels. \n3. Ablation results are presented to highlight the contributions of each component. \n4. Evaluation is conducted over out-of-domain data, and a metric is introduced to evaluate the fidelity between the inference predictions and generated interpretations. Visual analysis shows how the predicted label changes with the generated interpretation. Human evaluation is also conducted.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_review1_3",
            "content": "summary_of_weaknesses. 1. The Methodology section is very hard to follow. The model architecture description is rather confusing and sometimes uses inconsistent notation. For example, Section 2.2 introduces $v^p_{t-1}$ in the description which does not appear in the equations. Some of the notation pertaining to the labels ($l_0$, $l_{t-1}$) initially gives the impression that a sequence of tokens are being generated as the label, which is not the case. \n2. It is not clear why the baseline model considered for the NLI task is based on an older work (Conneau et al., 2017) and not the work by Kumar and Talukdar (2020), which seems more relevant to this work and is also cited in the paper. In addition, all the comparisons in the result section (and the delta numbers in Table 1) are made against a baseline vanilla Transformer model. \n3. Some of the numbers presented in Table 1 are confusing. It is not clear how a BLEU score of 22.51 is obtained by evaluating the ground truth dataset against itself for the NLI task. It is also not explained how the perplexity results are obtained. Are the numbers averaged across the dataset? Would that be a valid way to present these results? \n4. Some details like whether the results are averaged across multiple runs, and what the inter-annotator agreement was in the human evaluation are missing.",
            "ntype": "p",
            "meta": null
        },
        {
            "ix": "86-ARR_v1_review1_4",
            "content": "comments,_suggestions_and_typos. - In Section 2.1, the Transformer model is declared to have been established as the dominant approach for test generation. The next sentence immediately proceeds to the model description. This paragraph would flow better if there were a sentence linking the two parts and making it explicit that the Transformer model is being used. For example, \"We therefore adopt the Transformer model as our base model\" or something to that effect.\n-The description of the model architecture needs to be rephrased for clarity. See (1) under Weaknesses for some notation inconsistencies that can be improved as well.\n-In Section 2.3, Line 266 the description states $L$, $R$ are conditioned on $X$. Presumably it is meant to be $L$, $E$ since no $R$ is introduced anywhere.\n-In Section 3.2, the description of the Transformer baseline states that an MLP layer is added for generating sentence-level interpretations. This was perhaps meant to be predicted labels and not the interpretations, unless the decoder here is generating the labels - this needs clarification or correction.\n-In the results under \"Interpretation Promotion\", it is stated that \"most of the explanations generated by our method are reasonable even though the BLEU scores are low\". It might help to add an example here to make this more convincing.\n-Line 043: comprehensibleness -> comprehensibility  -Line 044: human -> humans -Line 046: which nevertheless -> which are nevertheless -Line 059: With the annotated -> With annotated -Line 135: method achieve -> method achieves -Line 163: dataset annotated by human -> human-annotated dataset -Line 169: a MLP -> an MLP -Line 233: to better inference -> to do better inference/to infer better -Line 264: two distribution -> two distributions -Line 303: maximum the negative likelihood -> maximize the negative likelihood -Line 493--494: the opening quotes are incorrectly formatted -Line 509: exapmle -> example",
            "ntype": "p",
            "meta": null
        }
    ],
    "span_nodes": [
        {
            "ix": "86-ARR_v1_review1_0@0",
            "content": "86-ARR_v1_review1",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_0",
            "start": 0,
            "end": 16,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_1@0",
            "content": "paper_summary.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_1",
            "start": 0,
            "end": 13,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_1@1",
            "content": "This paper introduces a method to improve both interpretations and inference by training an end-to-end model to simultaneously generate explanations and labels for the NLI and CQA tasks.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_1",
            "start": 15,
            "end": 200,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_1@2",
            "content": "Compared to previous work which either produces explanations that are used to infer the label or vice-versa, this work introduces a framework that trains both tasks jointly.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_1",
            "start": 202,
            "end": 374,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_1@3",
            "content": "This is done by iteratively updating the predicted label at each explanation decoding step.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_1",
            "start": 376,
            "end": 466,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_1@4",
            "content": "The representations of the label and the explanation tokens are combined through gating mechanisms and used as input for the next timestep, enabling the model to use the explanation generated thus far to predict the label and the predicted label to guide the generation of the next explanation token.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_1",
            "start": 468,
            "end": 767,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_1@5",
            "content": "To improve the correlation between the inferred label and the generated interpretation, an additional adversarial regularization is used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_1",
            "start": 769,
            "end": 905,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_1@6",
            "content": "Experiments show that this model shows improvements in both inference and interpretation compared to baselines.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_1",
            "start": 907,
            "end": 1017,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@0",
            "content": "summary_of_strengths.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 0,
            "end": 20,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@1",
            "content": "1. The idea of jointly training inference and interpretation is interesting.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 22,
            "end": 97,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@2",
            "content": "It is intuitive that the inference and interpretation should guide each other and be dependent. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 99,
            "end": 195,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@3",
            "content": "2. Several experimental results are presented to show that the model improves over both generated explanations and predicted labels. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 196,
            "end": 329,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@4",
            "content": "3. Ablation results are presented to highlight the contributions of each component. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 330,
            "end": 414,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@5",
            "content": "4. Evaluation is conducted over out-of-domain data, and a metric is introduced to evaluate the fidelity between the inference predictions and generated interpretations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 415,
            "end": 582,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@6",
            "content": "Visual analysis shows how the predicted label changes with the generated interpretation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 584,
            "end": 671,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_2@7",
            "content": "Human evaluation is also conducted.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_2",
            "start": 673,
            "end": 707,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@0",
            "content": "summary_of_weaknesses.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 0,
            "end": 21,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@1",
            "content": "1. The Methodology section is very hard to follow.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 23,
            "end": 72,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@2",
            "content": "The model architecture description is rather confusing and sometimes uses inconsistent notation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 74,
            "end": 169,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@3",
            "content": "For example, Section 2.2 introduces $v^p_{t-1}$ in the description which does not appear in the equations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 171,
            "end": 276,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@4",
            "content": "Some of the notation pertaining to the labels ($l_0$, $l_{t-1}$) initially gives the impression that a sequence of tokens are being generated as the label, which is not the case. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 278,
            "end": 457,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@5",
            "content": "2. It is not clear why the baseline model considered for the NLI task is based on an older work (Conneau et al., 2017) and not the work by Kumar and Talukdar (2020), which seems more relevant to this work and is also cited in the paper.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 458,
            "end": 693,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@6",
            "content": "In addition, all the comparisons in the result section (and the delta numbers in Table 1) are made against a baseline vanilla Transformer model. \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 695,
            "end": 840,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@7",
            "content": "3. Some of the numbers presented in Table 1 are confusing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 841,
            "end": 898,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@8",
            "content": "It is not clear how a BLEU score of 22.51 is obtained by evaluating the ground truth dataset against itself for the NLI task.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 900,
            "end": 1024,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@9",
            "content": "It is also not explained how the perplexity results are obtained.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 1026,
            "end": 1090,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@10",
            "content": "Are the numbers averaged across the dataset?",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 1092,
            "end": 1135,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@11",
            "content": "Would that be a valid way to present these results? \n",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 1137,
            "end": 1189,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_3@12",
            "content": "4. Some details like whether the results are averaged across multiple runs, and what the inter-annotator agreement was in the human evaluation are missing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_3",
            "start": 1190,
            "end": 1344,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@0",
            "content": "comments,_suggestions_and_typos. - In Section 2.1, the Transformer model is declared to have been established as the dominant approach for test generation.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 0,
            "end": 154,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@1",
            "content": "The next sentence immediately proceeds to the model description.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 156,
            "end": 219,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@2",
            "content": "This paragraph would flow better if there were a sentence linking the two parts and making it explicit that the Transformer model is being used.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 221,
            "end": 364,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@3",
            "content": "For example, \"We therefore adopt the Transformer model as our base model\" or something to that effect.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 366,
            "end": 467,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@4",
            "content": "\n-The description of the model architecture needs to be rephrased for clarity.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 468,
            "end": 545,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@5",
            "content": "See (1) under Weaknesses for some notation inconsistencies that can be improved as well.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 547,
            "end": 634,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@6",
            "content": "\n-In Section 2.3, Line 266 the description states $L$, $R$ are conditioned on $X$. Presumably it is meant to be $L$, $E$ since no $R$ is introduced anywhere.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 635,
            "end": 791,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@7",
            "content": "\n-In Section 3.2, the description of the Transformer baseline states that an MLP layer is added for generating sentence-level interpretations.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 792,
            "end": 933,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@8",
            "content": "This was perhaps meant to be predicted labels and not the interpretations, unless the decoder here is generating the labels - this needs clarification or correction.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 935,
            "end": 1099,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@9",
            "content": "\n-In the results under \"Interpretation Promotion\", it is stated that \"most of the explanations generated by our method are reasonable even though the BLEU scores are low\".",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 1100,
            "end": 1270,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@10",
            "content": "It might help to add an example here to make this more convincing.",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 1272,
            "end": 1337,
            "label": {}
        },
        {
            "ix": "86-ARR_v1_review1_4@11",
            "content": "\n-Line 043: comprehensibleness -> comprehensibility  -Line 044: human -> humans -Line 046: which nevertheless -> which are nevertheless -Line 059: With the annotated -> With annotated -Line 135: method achieve -> method achieves -Line 163: dataset annotated by human -> human-annotated dataset -Line 169: a MLP -> an MLP -Line 233: to better inference -> to do better inference/to infer better -Line 264: two distribution -> two distributions -Line 303: maximum the negative likelihood -> maximize the negative likelihood -Line 493--494: the opening quotes are incorrectly formatted -Line 509: exapmle -> example",
            "ntype": "s",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            },
            "src_ix": "86-ARR_v1_review1_4",
            "start": 1338,
            "end": 1949,
            "label": {}
        }
    ],
    "edges": [
        {
            "src_ix": "86-ARR_v1_review1_0",
            "tgt_ix": "86-ARR_v1_review1_1",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_0",
            "tgt_ix": "86-ARR_v1_review1_2",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_0",
            "tgt_ix": "86-ARR_v1_review1_3",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_0",
            "tgt_ix": "86-ARR_v1_review1_4",
            "etype": "parent",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_0",
            "tgt_ix": "86-ARR_v1_review1_1",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_2",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_3",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_4",
            "etype": "next",
            "meta": null
        },
        {
            "src_ix": "86-ARR_v1_review1_0",
            "tgt_ix": "86-ARR_v1_review1_0@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_1@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_1@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_1@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_1@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_1@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_1@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_1",
            "tgt_ix": "86-ARR_v1_review1_1@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_2",
            "tgt_ix": "86-ARR_v1_review1_2@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_3",
            "tgt_ix": "86-ARR_v1_review1_3@12",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@0",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@1",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@2",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@3",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@4",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@5",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@6",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@7",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@8",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@9",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@10",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        },
        {
            "src_ix": "86-ARR_v1_review1_4",
            "tgt_ix": "86-ARR_v1_review1_4@11",
            "etype": "link",
            "meta": {
                "created_by": "IntertextSentenceSplitter_all"
            }
        }
    ],
    "prefix": "86-ARR_v1_review1",
    "meta": {
        "ix_counter": 45,
        "sentence_split_type": "HybridSplitterLessAndLong",
        "sentence_split_model": "HybridSplitterLessAndLong_SciSpacy+Spacy"
    }
}