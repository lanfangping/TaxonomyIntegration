edit_index,doc_name,node_ix_src,node_ix_tgt,text_src,text_tgt,gold,label
0,10-ARR,10-ARR_v2_4@2,,"With this in mind, it is natural to consider how the advancement in natural language processing can be leveraged to help counseling.",,"Add,Claim",Claim
1,10-ARR,10-ARR_v2_5@1,,"Reflective listening asks the counselor not only to listen to the client carefully, but also to actively make a guess of what the client means.",,"Add,Claim",Claim
2,10-ARR,10-ARR_v2_5@3,,"However, people do not always say what they mean, which is especially the case for patients seeking mental support.",,"Add,Claim",Claim
3,10-ARR,10-ARR_v2_5@4,,"Reflection, as the response made based on reflective listening, sometimes needs to decode the client's meaning not explicitly expressed in words.",,"Add,Claim",Claim
4,10-ARR,10-ARR_v2_5@5,,"On the other hand, pressing the client to clarify the missing part may hinder them from expressing their own experience (Miller and Rollnick, 2012).",,"Add,Fact/Evidence",Fact/Evidence
5,10-ARR,10-ARR_v2_5@10,,All these cases pose challenges to state-of-the-art language models.,,"Add,Claim",Claim
6,10-ARR,10-ARR_v2_12@0,,Previous research has addressed the task of automating response generation in health care and counseling settings.,,"Add,Fact/Evidence",Fact/Evidence
7,10-ARR,10-ARR_v2_12@1,,Greer et al. (2019) used a decision tree to deliver pre-written scripts and guide the user to learn a set of positive emotion skills.,,"Add,Fact/Evidence",Fact/Evidence
8,10-ARR,10-ARR_v2_12@2,,V et al. (2019) identified medical entities and the client's intent to fetch an answer for cancer related questions.,,"Add,Fact/Evidence",Fact/Evidence
9,10-ARR,10-ARR_v2_12@3,,Almusharraf et al. (2020) classified client's responses to choose which question to ask next for smoking cessation.,,"Add,Fact/Evidence",Fact/Evidence
10,10-ARR,10-ARR_v2_12@4,,"There are also commercial systems like Woebot (Fitzpatrick et al., 2017) that detect mental health issues mentioned by the user and direct them to relevant information.",,"Add,Fact/Evidence",Fact/Evidence
11,10-ARR,10-ARR_v2_12@5,,"However, there is a limited amount of work on free-form generation as compared to the template-based approaches described above.",,"Add,Claim",Claim
12,10-ARR,10-ARR_v2_12@6,,Shen et al. (2020) focused on generating counseling reflections with GPT-2 based on the dialogue context and responses retrieved from similar counseling sessions.,,"Add,Fact/Evidence",Fact/Evidence
13,10-ARR,10-ARR_v2_12@8,,"To the best of our knowledge, the effect of knowledge in counseling response generation is not yet well studied.",,"Add,Claim",Claim
14,10-ARR,10-ARR_v2_35@4,,We use the original implementation 6 and the pretrained weights on ConceptNet.,,"Add,Fact/Evidence",Fact/Evidence
15,10-ARR,,10-ARR_v1_12@1,,"For instance, Mao et al. (2019) generates story with multitasking learning on commonsense QA datasets.","Delete,Fact/Evidence",Fact/Evidence
16,10-ARR,,10-ARR_v1_12@2,,Zhao et al. (2020) used BERT as a knowledge selection module for dialogue generation.,"Delete,Fact/Evidence",Fact/Evidence
17,10-ARR,,10-ARR_v1_12@3,,Chakrabarty et al. (2020) ranked knowledge generated from the COMET for sarcasm generation.,"Delete,Fact/Evidence",Fact/Evidence
18,10-ARR,,10-ARR_v1_12@4,,Ji et al. (2020) do multi-hop with a graph convolutional network on ConceptNet.,"Delete,Fact/Evidence",Fact/Evidence
19,10-ARR,10-ARR_v2_24@1,10-ARR_v1_22@3,Each entity types identified during the extraction has a set of eleven distinct query templates as shown in Table 1.,Each entity types identified during the extraction has a set of distinct query templates as shown in Table 1.,"Modify,Fact/Evidence",Fact/Evidence
20,10-ARR,10-ARR_v2_25@2,10-ARR_v1_23@2,4 The resulting sentences with medical concepts are then considered as knowledge candidates during our next step.,4 The resulting sentences are then considered as knowledge candidates during our next step.,"Modify,Fact/Evidence",Fact/Evidence
21,10-ARR,10-ARR_v2_26@2,10-ARR_v1_24@2,"The positive samples used for this classifier consist of 1,331 sentences with cause-effect relationships (e.g., He had chest pains and headaches from mold in the bedrooms) from the SemEval10 Task 8 dataset (Hendrickx et al., 2010) and an equal amount of negative samples randomly selected from sentences containing other types of semantic relationships in the same dataset.","The positive samples used for this classifier consist of 1,331 cause-effect relationships (e.g., He had chest pains and headaches from mold in the bedrooms) from the SemEval10 Task 8 dataset (Hendrickx et 2010) and an equal amount of negative samples randomly selected from sentences containing other types of semantic relationships in the same dataset.","Modify,Clarity",Clarity
22,10-ARR,10-ARR_v2_5@0,10-ARR_v1_4@2,"Across different counseling styles, reflective listening has always been a fundamental procedure underlying effective counseling practices (Katz and McNulty, 1994).","Effective counseling practice calls for reflective listening as an essential skill (Katz and McNulty, 1994).","Modify,Fact/Evidence",Fact/Evidence
23,10-ARR,10-ARR_v2_5@2,10-ARR_v1_4@3,"If carried out the right way, it gives the client a sense of being understood and facilitates further self-exploration.","It requires the counselor to perceive the other's need or problem, and respond in a way letting the other know he is being understood.","Modify,Claim",Claim
24,10-ARR,10-ARR_v2_36@1,10-ARR_v1_33@6,"Following the categorization in (Hwang et al., 2021), we limit the relationships to the commonsense subset to reduce noise and to limit the number of generated knowledge triplets.","Following the categorization in (Hwang et al., 2020), we limit the relationships to the commonsense subset to reduce noise and to limit the number of generated knowledge triplets.","Modify,Fact/Evidence",Fact/Evidence
25,10-ARR,10-ARR_v2_5@6,10-ARR_v1_4@4,"Thus, counseling frequently calls for counselors to make inferences based on their prior knowledge.","This process frequently involves making inferences based on the counselor's prior knowledge (Miller and Rollnick, 2012).","Modify,Clarity",Clarity
26,10-ARR,10-ARR_v2_5@7,10-ARR_v1_4@5,"For example, when the client says I had a really hard time sticking to my diet this week, a plausible reflection may be You're wondering whether you'll be able to lose weight this way, which relates diet with losing weight as an inference based on commonsense knowledge.","For example, the client says I had a really hard time sticking to my diet this week, a plausible reflection may be You're wondering whether you'll be able to lose weight this way, which relates diet with losing weight as an inference.","Modify,Claim",Claim
27,10-ARR,10-ARR_v2_5@9,10-ARR_v1_4@7,"For example, to understand the client in Figure 1, the counselor needs to know that smoking can be a possible cause of emphysema, and Chantix is a medication for smoke cessation.","For example, to understand the client in Figure 1, the counselor needs to know that smoking can be a possible cause of emphysema, and Chantix is a medication for quit smoking.","Modify,Clarity",Clarity
28,10-ARR,10-ARR_v2_51@3,10-ARR_v1_48@0,"The inplace method, which inserts the relation r and the generated e 2 next to e 1 , shows a significant improvement over the baseline.","The inplace method, which inserts the relation r and the generated e 2 next to e1, shows a significant improvement over the baseline.","Modify,Grammar",Grammar
29,10-ARR,10-ARR_v2_6@1,10-ARR_v1_5@1,"This extra knowledge is needed since existing pre-trained language models struggle to produce coherent and informative responses that capture relevant knowledge, even if they have acquired some knowledge during the pre-training phase (Petroni et al., 2019a).","This is a challenging task since existing pre-trained language models struggle to produce coherent and informative responses that capture relevant knowledge, even if they have acquired some knowledge during the pretraining (Petroni et al., 2019a) phase.","Modify,Claim",Claim
30,10-ARR,10-ARR_v2_60@0,10-ARR_v1_56@0,"We conduct a human evaluation where we ask annotators to indicate their preferences between our best performing models from both the retrieval and the generative settings, and a model without knowledge enhancement.","We conduct a human evaluation where we ask annotators to indicate their preferences between our best performing models from both the retrieval and the generative settings ,and a model without knowledge enhancement.","Modify,Grammar",Grammar
31,10-ARR,10-ARR_v2_62@2,10-ARR_v1_58@2,7 The annotators had no information on which model generated the the response being annotated.,7 The annotators have no information on which model generates the the response being annotated.,"Modify,Grammar",Grammar
32,10-ARR,10-ARR_v2_6@2,10-ARR_v1_5@2,A system that generates accurate counseling reflections can serve as a tool to aid counseling training or assist counselors during a session by providing alternative reflections in response to client's statements.,A system that generates good counseling reflections can serve as a tool to aid counseling training or assist counselors during a session by providing candidate responses.,"Modify,Clarity",Clarity
33,10-ARR,10-ARR_v2_66@3,10-ARR_v1_62@3,"Through an ablation study, we found that commonsense related to intentional and causal relationships is essential for the counseling domain.","Through an ablation study, we found that commonsense related to intentional and causal relationships are essential for the counseling domain.","Modify,Grammar",Grammar
34,10-ARR,10-ARR_v2_7@1,10-ARR_v1_6@1,"The first is retrieval, which acquires sentences containing relevant knowledge based on the vector representations of sentences from the dialogue and assertions in the knowledge base using a BERT-based model (Reimers and Gurevych, 2019a).","The first is retrieval, which acquires sentences containing relevant knowledge using a BERT-based model (Reimers and Gurevych, 2019a) to get vector representations of sentences from the dialogue and assertions in the knowledge base.","Modify,Clarity",Clarity
35,10-ARR,10-ARR_v2_7@2,10-ARR_v1_6@2,"The second strategy is generative, where we first extract key phrases from the dialogue, and query a COMET model for plausible knowledge triplets with a predefined set of relations (Bosselut et al., 2019).","The second strategy is generative, where we first extract key phrases from the dialogue, and query a COMET model for plausible knowledge triplets with a defined set of relations (Bosselut et al., 2019).","Modify,Clarity",Clarity
36,10-ARR,10-ARR_v2_12@7,10-ARR_v1_12@5,We address a similar task but enhance the generation process by infusing commonsense and domain specific knowledge to better emulate what counselors do in practice.,"Similarly, our work uses external knowledge sources, but with several different settings to enhance text generation for counseling conversations.","Modify,Claim",Claim
37,10-ARR,10-ARR_v2_13@4,10-ARR_v1_13@0,External knowledge resources have been found useful for enhancing language models.,"There are various types of knowledge resources that can be used to enhance language models, focusing on different aspects.","Modify,Claim",Claim
38,10-ARR,10-ARR_v2_13@5,10-ARR_v1_13@1,"For example, large-scale commonsense knowledge graphs (CSKG) that store structured commonsense knowledge in the form of knowledge triplets.","For example, large-scale commonsense knowledge graphs (CSKG) store structured commonsense knowledge in the form of knowledge triplets.","Modify,Grammar",Grammar
39,10-ARR,10-ARR_v2_18@0,10-ARR_v1_18@0,"In the following section, we describe the method to obtain relevant knowledge k c and the approach we use to incorporate knowledge into the language model.","In the following section, we describe the method to obtain relevant knowledge k c and the approach we use to incorporate knowledge in the language model.","Modify,Grammar",Grammar
40,10-ARR,10-ARR_v2_20@0,10-ARR_v1_20@0,"Despite their large size, existing commonsense knowledge bases contain a limited amount of information on domain-specific concepts, especially for causal relationships such as the reason to take a medicine or its side effects.","Despite their large size, existing commonsense knowledge bases contain a limited amount of information on some domain-specific concepts, especially causal relationships such as the reason to take a medicine or its side effects.","Modify,Clarity",Clarity
41,103-ARR,,103-ARR_v1_41@1,,"Table 3 reports our NLI system, including the median F1-Score and the standard deviation across 3 different runs of our implementations NLI and EM.","Delete,Fact/Evidence",Fact/Evidence
42,103-ARR,,103-ARR_v1_41@2,,On ACE our system is best on all comparable results.,"Delete,Fact/Evidence",Fact/Evidence
43,103-ARR,,103-ARR_v1_41@3,,"Note that RCEE_ER is better on 3 data splits, but unfortunately the splits are different.","Delete,Fact/Evidence",Fact/Evidence
44,103-ARR,103-ARR_v2_53@0,,"Our work paves the way for a new paradigm for IE, where the expert defines the schema using natural language and directly runs those specifications, annotating a handful of examples in the process, and allowing for quick trial-and-error iterations.",,"Add,Claim",Claim
45,103-ARR,103-ARR_v2_53@1,,Sainz et al. (2022) propose a user interface alongside this paradigm.,,"Add,Fact/Evidence",Fact/Evidence
46,103-ARR,103-ARR_v2_53@2,,"More generally, inference capability could be extended, acquired and applied from other tasks, in a research avenue where entailment and task performance improve in tandem.",,"Add,Claim",Claim
47,103-ARR,103-ARR_v2_55@0,,The fine-tuned models derived from this work will be uploaded to HuggingFace Models repository.,,"Add,Fact/Evidence",Fact/Evidence
48,103-ARR,103-ARR_v2_55@1,,Check the GitHub repository for updated information.,,"Add,Fact/Evidence",Fact/Evidence
49,103-ARR,103-ARR_v2_2@4,103-ARR_v1_2@4,"Thanks to the entailment, the multi-source transfer between ACE and WikiEvents further reduces annotation down to 10% and 5% (respectively) of the full training without transfer.","Thanks to entailment, the multi-source transfer between ACE and WikiEvents further reduces annotation down to 10% and 5% (respectively) of the full training without transfer.","Modify,Grammar",Grammar
50,103-ARR,103-ARR_v2_21@0,103-ARR_v1_22@0,"Inference takes into account three key factors to output the role label for an argument candidate: the entailment probabilities of each verbalization, the type constraints of the specific role, and a threshold.","Inference takes into account three key factors to output the role label for an argument candidate: the entailment probabilities of each verbalization, the type constraints of the specific role and a threshold.","Modify,Grammar",Grammar
51,103-ARR,103-ARR_v2_2@5,103-ARR_v1_2@5,Our analysis shows that the key to good results is the use of several entailment datasets to pre-train the entailment model.,Our analysis shows that key to good results is the use of several entailment datasets to pre-train the entailment model.,"Modify,Grammar",Grammar
52,103-ARR,103-ARR_v2_21@5,103-ARR_v1_23@2,"For this purpose, we convert the EAE training dataset into a NLI format, i.e we generate entailment, neutral and contradiction hypotheses heuristically from the data using the templates themselves.","For this purpose we convert the EAE training dataset into an NLI format, i.e we generate entailment, neutral and contradiction hypotheses heuristically from the data using the templates themselves.","Modify,Grammar",Grammar
53,103-ARR,103-ARR_v2_2@6,103-ARR_v1_2@6,"Similar to previous approaches, our method requires a small amount of effort for manual verbalization: only less than 15 minutes per event argument type is needed, and comparable results can be achieved with users with different level of expertise.","Similar to previous approaches, our method requires a small amount of effort for manual verbalization: only less than 15 minutes per event argument types is needed; comparable results can be achieved from users of different level of expertise.","Modify,Grammar",Grammar
54,103-ARR,103-ARR_v2_29@1,103-ARR_v1_31@1,"During the creation, the template developers had access to the guidelines that describe each of the roles (which can include one or two examples) and a NLI model that the developer could use to verify whether the generated verbalizations of these examples were entailed by the model.","During the creation, the template developers had access to the guidelines that describe each of the roles (which can include one or two examples) and an NLI model that the developer could use to verify whether the generated verbalizations of these examples are entailed by the model.","Modify,Grammar",Grammar
55,103-ARR,103-ARR_v2_31@3,103-ARR_v1_33@3,The WikiEvents dataset is instead more focused on document-level argument extraction task.,"The WikiEvents dataset instead, is more focused on document-level argument extraction task.","Modify,Clarity",Clarity
56,103-ARR,103-ARR_v2_4@0,103-ARR_v1_4@0,"Building Information Extraction (IE) systems for real-world applications is very costly and has suffered from data-scarcity problems, due in part to the expertise and time required to annotate training data at a large scale with sufficient consistency, but also due to poor transfer between domains: IE annotations depend on the schema used in each domain, and moving to new domains requires new schemas, new annotation guidelines and the manual annotation of new data.","Building Information Extraction (IE) systems for real-world applications is very costly and has suffered from data-scarcity problems, due in part to the expertise and time required to annotate training data at a large scale with sufficient consistency, but also due to poor transfer between domains: IE annotations depend on the schema used in each domain, and moving to new domains requires a new schemas, new annotation guidelines and manual annotation of new data.","Modify,Grammar",Grammar
57,103-ARR,103-ARR_v2_34@2,103-ARR_v1_36@2,"EM is a state-of-the-art (Zhou and Chen, 2021) model that uses ROBERTA LARGE as a backbone.",EM uses RoBERTa large.,"Modify,Fact/Evidence",Fact/Evidence
58,103-ARR,103-ARR_v2_2@0,103-ARR_v1_2@0,"Recent work has shown that NLP tasks such as Relation Extraction (RE) can be recasted as Textual Entailment tasks using verbalizations, with strong performance in zero-shot and fewshot settings thanks to pre-trained entailment models.","Recent work has shown that NLP tasks such as Relation Extraction (RE) can be recasted as a Textual Entailment tasks using verbalizations, with strong performance in zero-shot and few-shot settings thanks to pre-trained entailment models.","Modify,Grammar",Grammar
59,103-ARR,103-ARR_v2_37@2,103-ARR_v1_39@2,"In total, 464.56 hours (154.86 if only a single run is done) of computation time are required to reproduce all the experiments, that in our setting corresponds to 21.36 kgCO 2 eq carbon footprint 10 (roughly equivalent to the CO 2 emitted by 88.2 km driven by an average car).","In total, 464.56 hours (154.86 if only a single run is done) of computation time are required to reproduce all the experiments, that in our setting corresponds to 21.36 kgCO 2 eq carbon footprint 10 (roughly equivalent to the CO 2 emitted by 88.2Km driven by an average car).","Modify,Grammar",Grammar
60,103-ARR,103-ARR_v2_40@1,103-ARR_v1_42@1,"Sequentially fine-tuning our NLI model in TA-CRED and then in our target task shows small improvements on low-resource scenarios (0% split for ACE, 0% and 5% splits for WikiEvents).","Sequentially fine-tuning our NLI model in TA-CRED and then in our target task show small improvements on low-resource scenarios (0% split for ACE, 0% and 5% splits for WikiEvents).","Modify,Grammar",Grammar
61,103-ARR,103-ARR_v2_45@6,103-ARR_v1_47@5,"Our results suggest that new, more challenging NLI datasets, as well as NLI datasets automatically generated from other sources (as done in this work with WikiEvents and ACE) will yield more robust entailment models, and could further increase the performance of entailment-based EAE and IE.","Our results suggest that new, more challenging NLI datasets, as well as NLI datasets automatically generated from other sources (as done in this work with Wikievents and ACE) will yield more robust entailment models, and could further increase the performance of entailment-based EAE and IE.","Modify,Grammar",Grammar
62,103-ARR,103-ARR_v2_49@17,103-ARR_v1_51@17,"Based on our estimation, 9 hours would allow an annotator to annotate 5% of the dataset which yields a 37.5 F1 (Figure 5), while 5 hours of template building yields 40.6 F1-Score in the zero-shot setting.","Based on our estimation, 9 hours would allow an annotator to annotate 5% of the dataset which yields an 37.5 F1 (Figure 5), while 5 hours of template building yields 40.6 F1-Score in the zero-shot setting.","Modify,Grammar",Grammar
63,103-ARR,103-ARR_v2_49@19,103-ARR_v1_51@19,"Figure 5 plots the performance according to manual hours on ACE, showing the huge gains provided by the initial 5 hours writing templates, plus the reuse of WikiEvents annotations.","Figure 5 plots the performance according to manual hours on ACE, showing the huge gains provided by the initial 5 hours writing templates, plus the reuse of WikiEvent annotations.","Modify,Grammar",Grammar
64,103-ARR,103-ARR_v2_52@0,103-ARR_v1_54@0,"This paper shows the entailment-based approach for event argument extraction is extremely effective in zero-shot, few-shot and full train scenarios both on ACE and WikiEvents, outperforming previous methods.","This paper shows the entailment-base approach for event argument extraction is extremely effective in zero-shot, few-shot and full train scenarios both on ACE and WikiEvents, outperforming previous methods.","Modify,Grammar",Grammar
65,103-ARR,103-ARR_v2_54@4,103-ARR_v1_55@4,"For the future, we plan to test new hyperparameter sets that uses bigger batch-sizes, as recent works (Aribandi et al., 2022) suggest to be optimal for multi-task and -source learning experiments.","For the future, we plan to test new hyperparameter sets that uses bigger batch-sizes, as recent works (Aribandi et al., 2021) suggest to be optimal for multi-task and -source learning experiments.","Modify,Fact/Evidence",Fact/Evidence
66,103-ARR,103-ARR_v2_7@0,103-ARR_v1_7@0,"(1) We show that our method reduces schema dependency, as it improves the performance on the WikiEvents results using additional ACE training data and vice versa with no extra manual work.","(1) We show that our method reduces schema dependency, as it improves the performance on the Wikievents results using additional ACE training data and vice versa with no extra manual work.","Modify,Grammar",Grammar
67,103-ARR,103-ARR_v2_8@1,103-ARR_v1_8@1,"We make the code, templates and models publicly available.",We make the code and templates publicly available 2 .,"Modify,Fact/Evidence",Fact/Evidence
68,103-ARR,103-ARR_v2_2@2,103-ARR_v1_2@2,"In this work we show that entailment is also effective in Event Argument Extraction (EAE), reducing the need of manual annotation to 50% and 20% in ACE and WikiEvents respectively, while achieving the same performance as with full training.","In this work we show that entailment is also effective in Event Argument Extraction (EAE), reducing the need of manual annotation to 50% and 20% in ACE and WikiEvents, respectively, while achieving the same performance as with full training.","Modify,Grammar",Grammar
69,103-ARR,103-ARR_v2_12@0,103-ARR_v1_12@0,"Multi-task learning reformulates multiple tasks to a single and common task via prompting large pre-trained language models, leveraging multiple data sources to improve each task of interest.","Multi-task learning reformulates multiple tasks to a single and common task via prompting large pre-trained language models, leveraging multiple data sources to improve each tasks of interest.","Modify,Grammar",Grammar
70,103-ARR,103-ARR_v2_12@3,103-ARR_v1_13@2,Wei et al. (2021a) and Mishra et al. (2022) obtained contradictory results.,Wei et al. (2021a) and Mishra et al. (2021) obtained contradictory results.,"Modify,Fact/Evidence",Fact/Evidence
71,103-ARR,103-ARR_v2_12@5,103-ARR_v1_13@4,"In this work, we explore multi-source learning, where datasets from different or similar tasks are used to build a model for the target task.","In this work we explore multi-source learning, where datasets from different or similar tasks are used to build a model for the target task.","Modify,Grammar",Grammar
72,103-ARR,103-ARR_v2_13@0,103-ARR_v1_14@0,Event Argument Extraction is a sub-task of Event Extraction.,Event Argument Extraction (EAE) is a subtask of Event Extraction.,"Modify,Clarity",Clarity
73,103-ARR,103-ARR_v2_14@1,103-ARR_v1_15@1,"Lately, with the recent paradigm shift to prompt design learning (Min et al., 2021), several works reformulated the task as a Question Answering problem Feng et al., 2020;Du and Cardie, 2020b;Wei et al., 2021b;Lyu et al., 2021;Sulem et al., 2022) or as a Constrained Text Generation problem Du et al., 2021; using predefined prompts, questions or templates.","Lately, with the recent paradigm shift to prompt design learning (Min et al., 2021), several works reformulated the task as a Question Answering problem Feng et al., 2020;Du and Cardie, 2020b;Wei et al., 2021b;Lyu et al., 2021) or as a Constrained Text Generation problem Du et al., 2021; using predefined prompts, questions or templates.","Modify,Fact/Evidence",Fact/Evidence
74,103-ARR,103-ARR_v2_17@3,103-ARR_v1_18@2,"First, the possible roles are verbalized by means of predefined templates and the input, which comprises the context, trigger and argument candidate.","First, the possible roles are verbalized by means of predefined templates and the input, which comprises context, trigger and argument candidate.","Modify,Grammar",Grammar
75,110-ARR,,110-ARR_v1_37@0,,PLMs lack knowledge of antonyms.,"Delete,Claim",Claim
76,110-ARR,,110-ARR_v1_52@4,,Training details.,"Delete,Other",Other
77,110-ARR,,110-ARR_v1_59@0,,Catastrophic forgetting.,"Delete,Other",Other
78,110-ARR,110-ARR_v2_48@4,,"However, the representation hardly captures their semantic antonomy, e.g., gender.",,"Add,Claim",Claim
79,110-ARR,110-ARR_v2_53@1,,We multiply 100 to each value for a better readability.,,"Add,Fact/Evidence",Fact/Evidence
80,110-ARR,110-ARR_v2_53@2,,Note that the lower the values the better.,,"Add,Fact/Evidence",Fact/Evidence
81,110-ARR,110-ARR_v2_67@2,,We train the models for 10 epochs for each dataset and apply the early stopping technique where the patience number is set to 3.,,"Add,Fact/Evidence",Fact/Evidence
82,110-ARR,110-ARR_v2_67@3,,It is observed that the training is generally finished within 8 epochs for all the models.,,"Add,Fact/Evidence",Fact/Evidence
83,110-ARR,110-ARR_v2_67@4,,The batch size per GPU and learning rates used for each dataset are described in Table 8.,,"Add,Fact/Evidence",Fact/Evidence
84,110-ARR,110-ARR_v2_67@5,,"Datasets with large training set (e.g., MNLI, QNLI, and QQP) were not sensitive to the hyperparameters.",,"Add,Fact/Evidence",Fact/Evidence
85,110-ARR,110-ARR_v2_26@0,110-ARR_v1_27@0,"To reflect the prediction confidence score to the evaluation metric, we additionally define the weighted top-k hit rate (WHR@k) that uses the confidence score as weights.","To reflect the confidence score to the evaluation metric, we additionally define the weighted top-k hit rate (WHR@k) that uses the confidence score as weights.","Modify,Clarity",Clarity
86,110-ARR,110-ARR_v2_26@1,110-ARR_v1_27@1,It is worth to mention that lower metrics mean a better model performance in both cases as the metrics assess how likely the models make inaccurate answers that they must avoid.,It is worth to mention that lower metrics mean a better model performance in both cases.,"Modify,Fact/Evidence",Fact/Evidence
87,110-ARR,110-ARR_v2_30@2,110-ARR_v1_31@2,"We added the ELECTRA-small/base/large models (Clark et al., 2020) for the SAR task, but it is not used for the MKR-NQ and MWR experiments, as the discriminator of the ELECTRA models are trained with the replaced token prediction (RTP) training objective and have no MLM classifier.","We added the Electra-small/base/large models (Clark et al., 2020) for the SAR task, which are trained with the replaced token prediction (RTP) training objective.","Modify,Fact/Evidence",Fact/Evidence
88,110-ARR,110-ARR_v2_30@5,110-ARR_v1_31@5,"We use the AdamW optimiser (Loshchilov and Hutter, 2019) for training with a learning rate of 5e −6 and a batch size of 32.","We use the AdamW optimiser (Loshchilov and Hutter, 2017) for training with a learning rate of 5e −6 and a batch size of 32.","Modify,Fact/Evidence",Fact/Evidence
89,110-ARR,110-ARR_v2_4@0,110-ARR_v1_4@0,"Contemporary large-size PLMs, such as BERT (Devlin et al., 2019), ELECTRA (Clark et al., 2020), and GPT-2 and -3 (Radford et al., 2019;Brown et al., 2020), have shown excellent results in many downstream tasks, even performing better than humans in the GLUE (Wang et al., 2018) and Super-GLUE (Wang et al., 2019b) benchmark datasets.","Contemporary large-size PLMs, such as BERT (Devlin et al., 2019), Electra (Clark et al., 2020), and GPT-2 and -3 (Radford et al., 2019;Brown et al., 2020), have shown excellent results in many downstream tasks, even performing better than humans in the GLUE (Wang et al., 2018) and SuperGLUE (Wang et al., 2019b) benchmark datasets.","Modify,Grammar",Grammar
90,110-ARR,110-ARR_v2_42@2,110-ARR_v1_42@4,"However, the difference between the large and small encoderfixed models is insignificant, except for the ELEC-TRA models that exhibit only a marginal improvement.","However, the difference between the large and small encoder-fixed models is insignificant, except for the Electra models that exhibit only a marginal improvement.","Modify,Grammar",Grammar
91,110-ARR,110-ARR_v2_42@3,110-ARR_v1_42@5,"The two phenomenons suggest that PLMs' outstanding performance is predicated on updating many parameters to learn syntactic associations presented in training data (Niven and Kao, 2019;McCoy et al., 2019), but their contextualised representations do not carry abundant lexical meaning information.","The two phenomenons suggest that PLMs' outstanding performance is predicated on updating a great many parameters to learn syntactic associations presented in training data (Niven and Kao, 2019;McCoy et al., 2019), but their contextualised representations do not carry abundant lexical meaning information.","Modify,Clarity",Clarity
92,110-ARR,110-ARR_v2_48@0,110-ARR_v1_48@0,"However, the problem is that the distributional hypothesis has limitations in reflecting a word's semantic meanings, because words having different or even opposite semantic meanings can appear in similar or the same contexts.","However, the problem is that the distributional hypothesis does not consistently hold in natural language.","Merge+Modify,Claim",Claim
93,110-ARR,110-ARR_v2_48@0,110-ARR_v1_48@1,"However, the problem is that the distributional hypothesis has limitations in reflecting a word's semantic meanings, because words having different or even opposite semantic meanings can appear in similar or the same contexts.",Words having different meanings can appear in similar or even the same contexts.,"Merge+Modify,Claim",Claim
94,110-ARR,110-ARR_v2_48@2,110-ARR_v1_48@3,"We can readily imagine sentences in which the two words appear in the same context, e.g., ""the little boy/girl cuddled the teddy bear closely"".","Despite their antonymy, we can readily imagine sentences in which the two words appear in the same context, e.g., ""The little boy/girl cuddled the teddy bear closely."".","Modify,Clarity",Clarity
95,110-ARR,110-ARR_v2_48@3,110-ARR_v1_48@4,"As a result, a model can learn their common functional meanings, i.e., young human beings, and the vector representations would be very similar if they were trained based on the distributional hypothesis.","As a result, the meaning of the two words would become quite similar if they were trained based on the distributional hypothesis.","Modify,Claim",Claim
96,110-ARR,110-ARR_v2_48@6,110-ARR_v1_48@6,"As a result, models cannot effectively learn the semantic meaning of words and negation expressions, provided they leverage only the text forms.","As a result, models can not learn the true meaning of words and negation expressions, provided they leverage only the text forms.","Modify,Clarity",Clarity
97,110-ARR,110-ARR_v2_5@1,110-ARR_v1_5@1,"Many studies have conducted various probing tasks and observed that PLMs exhibit faulty behaviours, such as insensitiveness to sentence ordering (Pham et al., 2021;Gupta et al., 2021; Sinha et al., 2021b), incomprehension on number-related representations (Wallace et al., 2019;Lin et al., 2020;Nogueira et al., 2021), and lack of semantic content understanding (Ravichander et al., 2020;Elazar et al., 2021).","Many studies have conducted various probing tasks and observed that PLMs exhibit faulty behaviours, such as insensitiveness to sentence ordering (Pham et al., 2020;Gupta et al., 2021;Sinha et al., 2021b), incomprehension on number-related representations (Wallace et al., 2019;Lin et al., 2020;Nogueira et al., 2021), and lack of semantic content understanding (Ravichander et al., 2020;Elazar et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
98,110-ARR,110-ARR_v2_54@7,110-ARR_v1_52@12,"We conjecture that a leading cause is that the dataset contains many words with similar meanings, mostly derived from the same stem.","We conjecture a leading cause is that the dataset contains many words with similar meanings, mostly derived from the same stem.","Modify,Clarity",Clarity
99,110-ARR,110-ARR_v2_59@1,110-ARR_v1_57@1,"After the intermediate training, all models are fine-tuned on the SAR task with the same hyperparameters described in Section 3.","For training, we use the same hyperparameters as described in Section 3.","Modify,Fact/Evidence",Fact/Evidence
100,110-ARR,110-ARR_v2_59@6,110-ARR_v1_58@3,Our results show that the proposed approach assists PLMs to learn enhanced representations with more abundant lexical semantic information.,Our results show that the proposed approach assists PLMs to learn enhanced contextualised representations with more abundant lexical semantic information.,"Modify,Clarity",Clarity
101,110-ARR,110-ARR_v2_60@0,110-ARR_v1_59@1,"We find that small PLMs, such as ELECTRA-small and ALBERT models, show no significant increase in performance or are negatively impacted.","We find that small PLMs, such as Electra-small and ALBERT models, show no significant increase in performance or are negatively impacted.","Modify,Grammar",Grammar
102,110-ARR,110-ARR_v2_62@1,110-ARR_v1_61@1,"We observe that the parameters of the ELECTRA-small model, which is negatively impacted, are changed considerably compared to other PLMs having parameters more than 100M.","We observe that the parameters of the Electra-small model, which is negatively impacted, are changed considerably compared to other PLMs having parameters more than 100M.","Modify,Grammar",Grammar
103,110-ARR,110-ARR_v2_67@1,110-ARR_v1_66@1,"To confirm whether the issue occurs, we compare the performance of BERT, RoBERTa, and ELECTRA-large on 7 GLUE benchmark datasets (Wang et al., 2018) with their IM 2 counterparts.","To confirm whether the issue occurs, we compare the performance of BERT, RoBERTa, and Electra-large on 7 GLUE benchmark datasets (Wang et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
104,110-ARR,110-ARR_v2_68@1,110-ARR_v1_67@0,"We find no significant difference in performance for tasks with large datasets, such as MNLI, QNLI, QQP, and SST2.","We find no significant difference in performance for tasks with large datasets, such as the MNLI, QNLI, QQP, and SST2.","Modify,Grammar",Grammar
105,110-ARR,110-ARR_v2_68@2,110-ARR_v1_67@1,"On the contrary, tasks with small datasets, like MRPC and RTE, are slightly improved.","On the contrary, tasks with small datasets, like the MRPC and RTE, are slightly improved.","Modify,Grammar",Grammar
106,110-ARR,110-ARR_v2_68@5,110-ARR_v1_67@4,The result suggests that meaning-matching is a safe intermediate task that ensures a positive transfer with target downstream tasks.,The result suggests that the meaningmatching is a safe intermediate task that ensures positive transfer with target downstream tasks.,"Modify,Grammar",Grammar
107,110-ARR,110-ARR_v2_70@0,110-ARR_v1_69@0,"Finally, we conduct experiments on the NegNLI benchmark dataset (Hossain et al., 2020), where negation plays an important role for NLI tasks.","Finally, we conduct experiments on the NegNLI benchmark dataset (Hossain et al., 2020) where negation plays an important role for NLI tasks.","Modify,Grammar",Grammar
108,110-ARR,110-ARR_v2_71@0,110-ARR_v1_70@0,"For both SNLI and MNLI, we observe that our approach outperforms BERTNOT in the NegNLI datasets, while yielding a comparable performance in the original development datasets.","For both SNLI and MNLI, we observe that our approach outperforms BERTNOT in NegNLI datasets, while yielding a comparable performance in the original development datasets.","Modify,Grammar",Grammar
109,110-ARR,110-ARR_v2_73@3,110-ARR_v1_72@3,"Among the many findings of these probing tasks, PLMs have been found to be insensitive to the order of sentences when generating representations (Pham et al., 2021;Gupta et al., 2021;Sinha et al., 2021a), struggle to comprehend number-related representations (Wallace et al., 2019;Lin et al., 2020;Nogueira et al., 2021), and display a lack of semantic content understanding (Ravichander et al., 2020;Elazar et al., 2021).","Among the many findings of these probing tasks, PLMs have been found to be insensitive to the order of sentences when generating representations (Pham et al., 2020;Gupta et al., 2021;Sinha et al., 2021a), struggle to comprehend number-related representations (Wallace et al., 2019;Lin et al., 2020;Nogueira et al., 2021), and display a lack of semantic content understanding (Ravichander et al., 2020;Elazar et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
110,110-ARR,110-ARR_v2_74@1,110-ARR_v1_73@1,Ettinger (2020) check the ability of PLMs to understand the meaning of negation in given contexts.,Ettinger (2020) check the ability of PLMs to understand of the meaning of negation in given contexts.,"Modify,Grammar",Grammar
111,110-ARR,110-ARR_v2_75@1,110-ARR_v1_74@1,"In their remedy, they augment the language modelling objective with an unlikelihood objective (Welleck et al., 2020) based on negated sentences from the training corpus.","In their remedy, they augment the language modelling objective with an unlikelihood objective (Welleck et al., 2019) based on negated sentences from the training corpus.","Modify,Fact/Evidence",Fact/Evidence
112,110-ARR,110-ARR_v2_75@3,110-ARR_v1_74@3,"In this method, the dependency parse of the sentences, POS tags, and morphological information of each word are taken as input, and the negation of sentences is done using sets of dependency tree regular expression patterns, such as Semgrex (Chambers et al., 2007).","In this method, the dependency parse of the sentences, POS tags and morphological information of each word are taken as input and the negation of sentences is done using sets of dependency tree regular expression patterns, such as Semgrex (Chambers et al., 2007).","Modify,Grammar",Grammar
113,110-ARR,110-ARR_v2_76@0,110-ARR_v1_75@0,"Previous studies (e.g., Kassner and Schütze (2020)) have mostly limited the scope of the logical negation property only to the negation expressions (e.g., ""no"" and ""not"").","Previous studies, e.g., Kassner and Schütze (2020), have mostly limited the scope of the logical negation property only to the negation expressions (e.g., ""no"" and ""not"").","Modify,Grammar",Grammar
114,110-ARR,110-ARR_v2_76@1,110-ARR_v1_75@1,"However, the core spirit of this property is the opposite meaning, which is not only limited to the negation.","However, the core spirit of the property is opposite-meaning, which is not only limited to negation.","Modify,Grammar",Grammar
115,110-ARR,110-ARR_v2_76@2,110-ARR_v1_75@2,Welleck et al. (2020) consider negating sentences using dependency tree regular expression patterns.,Welleck et al. (2019) consider negating sentences using dependency tree regular expression patterns.,"Modify,Fact/Evidence",Fact/Evidence
116,110-ARR,110-ARR_v2_76@3,110-ARR_v1_75@3,"This widens the scope of negation, as it is not only limited to the negation expressions ""no"" and ""not"".","This widens the scope of negation, as it is not only limited to negation expressions ""no"" and ""not"".","Modify,Grammar",Grammar
117,110-ARR,110-ARR_v2_76@4,110-ARR_v1_75@4,"However, their approach relies on other components, such as Semgrex, and dependency and POS parsers, which could impact the quality of the data, hence impact the models' performance.","However, their approach relies on other components, such as Semgrex, and dependency and POS parsers which could impact the quality of the data, hence impact the models' performance.","Modify,Grammar",Grammar
118,110-ARR,110-ARR_v2_76@5,110-ARR_v1_75@5,"In this work, we consider other perturbation methods to generate the opposite-meaning sentences to investigate whether PLMs satisfy the logical negation property, and we propose a remedy, called intermediate-training on meaning-matching (IM 2 ), which hardly employs additional linguistic components.","In this work, we consider other perturbation methods to generate the opposite-meaning sentences to investigate whether PLMs satisfy the logical negation property, and we propose a remedy called intermediate-training on meaning-matching (IM 2 ) that hardly employs additional linguistic components.","Modify,Clarity",Clarity
119,110-ARR,110-ARR_v2_79@0,110-ARR_v1_78@0,We hypothesise that the distributional hypothesis is an insufficient basis for understanding the semantic meaning of texts.,We hypothesise that the distributional hypothesis results in PLMs' lack of understanding of the true meaning of texts.,"Modify,Clarity",Clarity
120,110-ARR,110-ARR_v2_8@1,110-ARR_v1_8@1,"Hosseini et al. (2021) recently employed data augmentation and unlikelihood training (Welleck et al., 2020) to prevent models from generating unwanted words, given the augmented negated data during masked language modelling (MLM).","Hosseini et al. (2021) recently employed data augmentation and unlikelihood training (Welleck et al., 2019) to prevent models from generating unwanted words, given the augmented negated data during masked language modelling (MLM).","Modify,Fact/Evidence",Fact/Evidence
121,110-ARR,110-ARR_v2_8@4,110-ARR_v1_8@4,"Second, the data augmentation method is contingent on many additional linguistic compo-nents, which causes the dependency of a model's performance on certain modules and precludes applying the method to other languages where such resources are unavailable.","Second, the data augmentation method is contingent on many additional linguistic components, which causes the dependency of model's performance on certain modules and precludes applying the method to other languages where such resources are unavailable.","Modify,Grammar",Grammar
122,110-ARR,110-ARR_v2_9@1,110-ARR_v1_10@0,"Next, we propose a remedy, called intermediate-training on meaning-matching (IM 2 ), which hardly employs additional linguistic components.","Next, we propose a remedy, called intermediatetraining on meaning-matching (IM 2 ), that hardly employs additional linguistic components.","Modify,Clarity",Clarity
123,110-ARR,110-ARR_v2_10@0,110-ARR_v1_11@0,"Our main contributions are as follows: (i) We extend the investigation of the LNP from negation to lexical semantics (Section 2), (ii) we reveal that PLMs are prone to violate the LNP (Section 3), (iii) we propose a novel remedy, named IM 2 , which is decoupled from the distributional hypothesis but learns meaning-text correspondence instead (Section 4), (iv) through experiments, we ascertain that the proposed approach improves the understanding of negation and lexical semantic information (Sections 5.1 and 5.2), and (v) we verify that meaningmatching is a stable and safe intermediate task that produces a similar or better performance in multiple downstream tasks (Sections 5.3 and 5.4).","Our main contributions are as follows: (i) We extend the investigation of the LNP from negation to lexical semantics (Section 2), (ii) we reveal that PLMs are prone to violate the LNP (Section 3), (iii) we propose a novel remedy named IM 2 that is decoupled from the distributional hypothesis but learns meaning-text correspondence instead (Section 4), (iv) through experiments, we ascertain that the proposed approach improves the understanding of negation and lexical semantic information (Sections 5.1 and 5.2), and (v) we verify that meaningmatching is a stable and safe intermediate task that produces a similar or better performance in multiple downstream tasks (Sections 5.3 and 5.4).","Modify,Clarity",Clarity
124,110-ARR,110-ARR_v2_2@5,110-ARR_v1_2@5,"To alleviate the issue, we propose a novel intermediate training task, named meaning-matching, designed to directly learn a meaning-text correspondence, instead of relying on the distributional hypothesis.","To alleviate the issue, we propose a novel intermediate training task, named meaningmatching, designed to directly learn a meaningtext correspondence, instead of relying on the distributional hypothesis.","Modify,Grammar",Grammar
125,111-ARR,111-ARR_v2_89@0,,Conclusion,,"Add,Other",Other
126,111-ARR,111-ARR_v2_116@3,,"In Table 9 we see a stronger correlation of human annotations with LaBSE compared to Sentence-BERT, especially for languages like Bengali, Kannada for which Sentence-BERT did not see parallel data.",,"Add,Fact/Evidence",Fact/Evidence
127,111-ARR,111-ARR_v2_117@1,,"Overall, LaBSE correlates more strongly than Sentence-BERT with our annotated data.",,"Add,Fact/Evidence",Fact/Evidence
128,111-ARR,111-ARR_v2_121@2,,"In As we increase the threshold L, we see this percentage substantially reduces, indicating our chosen thresholds are within the range of variation in LaBSE scores for semantically similar sentences.",,"Add,Fact/Evidence",Fact/Evidence
129,111-ARR,111-ARR_v2_125@1,,"20 A potential tool for fluency evaluation in future work is LAMBRE (Pratapa et al., 2021).",,"Add,Claim",Claim
130,111-ARR,111-ARR_v2_125@2,,"However, the original paper does not evaluate performance on Indic languages and the grammars for Indic languages would need to collected / built.",,"Add,Claim",Claim
131,111-ARR,111-ARR_v2_141@0,,"In Figure 9 we measure the lexical overlap between paraphrases used in our DIFFUR training strategy for six different languages (Hindi, Bengali, Kannada, Telugu, Swahili and Spanish).",,"Add,Fact/Evidence",Fact/Evidence
132,111-ARR,111-ARR_v2_141@1,,"The lexical overlap is measured using the unigram F1 score, using the implementation from the SQuAD evaluation script (Rajpurkar et al., 2016).",,"Add,Fact/Evidence",Fact/Evidence
133,111-ARR,111-ARR_v2_141@2,,The wide spread of the histogram and sufficient percentage of low overlap pairs confirm the lexical diversity of the paraphrases used.,,"Add,Fact/Evidence",Fact/Evidence
134,111-ARR,111-ARR_v2_141@3,,"As shown in prior work (Krishna et al., 2020), high lexical diversity of paraphrases is helpful for changing the input style.",,"Add,Fact/Evidence",Fact/Evidence
135,111-ARR,,111-ARR_v1_70@0,,We evaluate models on (1) formality transfer;,"Delete,Fact/Evidence",Fact/Evidence
136,111-ARR,,111-ARR_v1_71@0,,(2) increasing the amount of code-mixing with English.,"Delete,Fact/Evidence",Fact/Evidence
137,111-ARR,,111-ARR_v1_78@0,,"Multilingual style transfer is mostly unexplored in prior work: a 35 paper survey by Briakou et al. (2021b) found only one work in Chinese, Russian, Latvian, Estonian, French (Shang et al., 2019;Tikhonov and Yamshchikov, 2018;Korotkova et al., 2019;Niu et al., 2018).","Delete,Fact/Evidence",Fact/Evidence
138,111-ARR,,111-ARR_v1_78@1,,"Briakou et al. (2021b) further introduced XFORMAL, the first formality transfer evaluation dataset in French, Brazilian Portugese and Italian.","Delete,Fact/Evidence",Fact/Evidence
139,111-ARR,,111-ARR_v1_78@2,,"16 Hindi formality has been studied in linguistics, focusing on politeness (Kachru, 2006;Agnihotri, 2013;Kumar, 2014) and codemixing (Bali et al., 2014).","Delete,Fact/Evidence",Fact/Evidence
140,111-ARR,,111-ARR_v1_78@3,,"Due to its prevalence in India, English-Hindi code-mixing has seen work in language modeling (Pratapa et al., 2018;Samanta et al., 2019) and core NLP tasks (Khanuja et al., 2020).","Delete,Fact/Evidence",Fact/Evidence
141,111-ARR,,111-ARR_v1_78@4,,"To the best of our knowledge, we are the first to study style transfer for Indic languages.","Delete,Claim",Claim
142,111-ARR,,111-ARR_v1_91@0,,Results: Our results on Hindi are presented in Table 6 and other languages in Table 7.,"Delete,Fact/Evidence",Fact/Evidence
143,111-ARR,,111-ARR_v1_130@0,,"In the baseline Hindi UR model, we notice high COPY rates (45.4%), resulting in lower ACC scores.","Delete,Fact/Evidence",Fact/Evidence
144,111-ARR,,111-ARR_v1_131@3,,"Also see Figure 9 for a comparison across λ values, and Section 5 for detailed metric descriptions.","Delete,Fact/Evidence",Fact/Evidence
145,111-ARR,,111-ARR_v1_131@13,,"The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.","Delete,Fact/Evidence",Fact/Evidence
146,111-ARR,,111-ARR_v1_131@14,,"We see the DIFFUR models outperform other systems across the λ range, and get best performance with the DIFFUR-MLT variant.","Delete,Fact/Evidence",Fact/Evidence
147,111-ARR,,111-ARR_v1_131@15,,"We also see that DIFFUR models, especially with DIFFUR-MLT, lead to better style transfer control (bottom plot, closer to x = 1 is better), giving large style variation with λ without loss in semantics (X-axis).","Delete,Fact/Evidence",Fact/Evidence
148,111-ARR,,111-ARR_v1_131@17,,"The plots show overall style transfer performance, using the r-AGG (top-left) and a-AGG (top-right) metrics from Section 5.5.","Delete,Fact/Evidence",Fact/Evidence
149,111-ARR,,111-ARR_v1_131@18,,Note that Gujarati is a zero-shot language for DIFFUR models -no Gujarati paraphrase data was seen during training.,"Delete,Fact/Evidence",Fact/Evidence
150,111-ARR,,111-ARR_v1_131@19,,"We see that while the vanilla DIFFUR model performs poorly, the DIFFUR-INDIC is competitive with baselines and the DIFFUR-MLT variant significantly outperforms other systems.","Delete,Fact/Evidence",Fact/Evidence
151,111-ARR,,111-ARR_v1_131@20,,"We also see that the DIFFUR-MLT variant lead to better style transfer control (bottom plot, closer to x = 1 is better), giving style variation with λ without loss in semantics (X-axis).","Delete,Fact/Evidence",Fact/Evidence
152,111-ARR,111-ARR_v2_43@4,,In Appendix K we confirm that our backtranslated paraphrases are lexically diverse from the input.,,"Add,Fact/Evidence",Fact/Evidence
153,111-ARR,111-ARR_v2_49@0,,"3. The length of s diff acts as a proxy for the amount of style transfer, which is controlled using λ during inference (Section 3).",,"Add,Fact/Evidence",Fact/Evidence
154,111-ARR,,111-ARR_v1_19@0,,"Denoising: To learn a style extractor, the Universal Rewriter uses the idea that two non-overlapping spans of text in the same document are likely to have the same style.","Delete,Fact/Evidence",Fact/Evidence
155,111-ARR,111-ARR_v2_54@3,,"We initialize the model with the UR-INDIC checkpoint, and fine-tune it on these two losses together, giving each loss equal weight.",,"Add,Fact/Evidence",Fact/Evidence
156,111-ARR,111-ARR_v2_69@1,,"Since each of our individual metrics can only take values 0 or 1 at an instance level, our aggregation acts like a Boolean AND operation.",,"Add,Fact/Evidence",Fact/Evidence
157,111-ARR,111-ARR_v2_77@1,,"DIFFUR-MLT gives best overall performance (r-AGG / a-AGG), with a good trade-off between style accuracy (ACC), semantic similarity (SIM), langID score (LANG), and low input copy rates (COPY); metrics defined in Section 5, other language results in Appendix I.",,"Add,Fact/Evidence",Fact/Evidence
158,111-ARR,111-ARR_v2_79@0,,Experimental Setup,,"Add,Other",Other
159,111-ARR,111-ARR_v2_83@6,,"For code-mixing addition, we use Hindi/English code-mixed exemplars in Devanagari (shown in Appendix D).",,"Add,Fact/Evidence",Fact/Evidence
160,111-ARR,111-ARR_v2_84@0,,Main Results,,"Add,Other",Other
161,111-ARR,111-ARR_v2_85@0,,"Each proposed method improves over prior work, DIFFUR-MLT works best.",,"Add,Fact/Evidence",Fact/Evidence
162,111-ARR,111-ARR_v2_85@1,,"We present our On Gujarati, the DIFFUR-INDIC fails to get good performance (36.0 r-AGG) since it did not see Gujarati paraphrase data, but this performance is recovered using DIFFUR-MLT (75.0).",,"Add,Fact/Evidence",Fact/Evidence
163,111-ARR,111-ARR_v2_85@2,,In Table 4 we see human evaluations support our automatic evaluation for formality transfer.,,"Add,Fact/Evidence",Fact/Evidence
164,111-ARR,111-ARR_v2_85@3,,In Figure 4: Outputs and qualitative analysis of our best performing model for several attribute transfer tasks (λ is transfer magnitude).,,"Add,Fact/Evidence",Fact/Evidence
165,111-ARR,111-ARR_v2_85@4,,We notice lower quality qualitatively for ** marked styles; see Appendix J for more outputs.,,"Add,Fact/Evidence",Fact/Evidence
166,111-ARR,111-ARR_v2_86@0,,ACC scores.,,"Add,Other",Other
167,111-ARR,111-ARR_v2_87@1,,In Appendix I we show a breakdown by individual metrics for other languages and plot variations with λ.,,"Add,Fact/Evidence",Fact/Evidence
168,111-ARR,111-ARR_v2_31@6,111-ARR_v1_26@6,"Moreover, token-level noise does not differentiate between content or function words, and cannot do syntactic changes like content reordering (Goyal and Durrett, 2020).","Moreover, token-level noise does not differentiate between content / function words, and cannot do syntactic changes like content reordering (Goyal and Durrett, 2020).","Modify,Grammar",Grammar
169,111-ARR,111-ARR_v2_3@2,111-ARR_v1_3@2,"Moreover, our method is better at controlling the style transfer magnitude using an input scalar knob.","Moreover, our method is better able to control the amount of style transfer using an input scalar knob.","Modify,Clarity",Clarity
170,111-ARR,111-ARR_v2_31@11,111-ARR_v1_27@3,"This has also been observed recently in Kreutzer et al. (2022), who audit 100 sentences in each language, and report 50% sentences in Marathi and 20% sentences in Hindi have the wrong language.","This has also been observed recently in Caswell et al. (2021), who audit 100 sentences in each language, and report 50% sentences in Marathi and 20% sentences in Hindi have the wrong language.","Modify,Fact/Evidence",Fact/Evidence
171,111-ARR,111-ARR_v2_3@3,111-ARR_v1_3@3,"We report promising qualitative results for several attribute transfer tasks (sentiment transfer, simplification, gender neutralization, text anonymization) all without retraining the model.","We report promising qualitative results for several attribute transfer directions, including sentiment transfer, text simplification, gender neutralization and text anonymization, all without retraining the model.","Modify,Clarity",Clarity
172,111-ARR,111-ARR_v2_3@4,111-ARR_v1_3@4,"Finally, we find model evaluation to be difficult due to the lack of datasets and metrics for many languages.",Finally we found model evaluation to be difficult due to the lack of evaluation datasets and metrics for many languages.,"Modify,Clarity",Clarity
173,111-ARR,111-ARR_v2_42@0,111-ARR_v1_38@0,"Paraphrases as a ""noise"" function: Instead of using random token-level noise (Issue #1 in Section 3.1), we paraphrase sentences to ""noise"" them during training.","Paraphrases as a ""noise"" function: Instead of using random token-level noise (issue #1 in Section 3.1), we paraphrase sentences to ""noise"" them during training.","Modify,Grammar",Grammar
174,111-ARR,111-ARR_v2_44@0,111-ARR_v1_40@0,"Using style vector differences for control: To fix the training / inference mismatch for style extraction (Issue #2 in Section 3.1), we propose using style vector differences between the output and input as the stylistic control.","Using style vector differences for control: To fix the training / inference mismatch for style extraction (issue #2 in Section 3.1), we propose using style vector differences between the output and input as the stylistic control.","Modify,Grammar",Grammar
175,111-ARR,111-ARR_v2_3@5,111-ARR_v1_3@5,"To facilitate future research we crowdsource formality annotations for 4000 sentence pairs in four Indic languages, and use this data to design our automatic evaluations.","To facilitate further research in formality transfer for Indic languages, we crowdsource annotations for 4000 sentence pairs in four languages, and use this dataset 1 to design our automatic evaluation suite.","Modify,Fact/Evidence",Fact/Evidence
176,111-ARR,111-ARR_v2_2@0,111-ARR_v1_2@0,Style transfer is the task of rewriting a sentence into a target style while approximately preserving content.,Style transfer is the task of rewriting an input sentence into a target style while approximately preserving its content.,"Modify,Clarity",Clarity
177,111-ARR,111-ARR_v2_52@0,111-ARR_v1_46@0,"To address the issue of no translation data (Issue #4 in Section 3.1), we train Indic variants of our models.","To address the issue of no translation data (issue #4 in Section 3.1), we train Indic variants of our models.","Modify,Grammar",Grammar
178,111-ARR,111-ARR_v2_54@0,111-ARR_v1_48@0,One issue with our DIFFUR-INDIC setup is usage of a stop-grad(•) to avoid verbatim copying from the input.,"One issue with our DIFFUR-INDIC setup is usage of a stop-grad(•), to avoid verbatim copying from the input.","Modify,Grammar",Grammar
179,111-ARR,111-ARR_v2_54@2,111-ARR_v1_48@2,To prevent this we simply multi-task between the exemplardriven denoising UR objective (Section 3) and the DIFFUR objective.,"To prevent this from happening, we simply do multi-task learning between the original Universal Rewriter objective (Section 3) and our DIFFUR-INDIC objective, using an equal number of minibatches for each objective.","Modify,Fact/Evidence",Fact/Evidence
180,111-ARR,111-ARR_v2_0@0,111-ARR_v1_0@0,Few-shot Controllable Style Transfer for Low-Resource Multilingual Settings,Few-shot Controllable Style Transfer for Low-Resource Multilinugal Settings,"Modify,Grammar",Grammar
181,111-ARR,111-ARR_v2_70@0,111-ARR_v1_62@1,"In other words, we are measuring the fraction of outputs which simultaneously transfer style, have a semantic similarity of at least L (our threshold in Section 5.3), and have the same language as the input.","In other words, we measure the fraction of outputs which simultaneously transfer style, have a semantic similarity of at least L (our threshold in Section 5.3), and have the same language as the input.","Modify,Grammar",Grammar
183,111-ARR,111-ARR_v2_76@4,111-ARR_v1_68@3,"More experiment details (inter-annotator agreement, compensation, instructions) are provided in Appendix E.4.","This lets us evaluate r-ACC, SIM, r-AGG, CALIB with respect to human annotations instead of classifier predictions; details in Appendix E.4.","Split+Modify,Fact/Evidence",Fact/Evidence
185,111-ARR,111-ARR_v2_88@2,111-ARR_v1_72@1,More outputs are provided in Appendix J.,"Besides formality transfer and code-mixing addition, we transfer several other attributes: sentiment (Li et al., 2018), simplicity (Xu et al., 2015), anonymity (Anandan et al., 2012) and gender neutrality (Reddy and Knight, 2016); more outputs in Appendix J.","Split+Modify,Clarity",Clarity
186,111-ARR,111-ARR_v2_90@1,111-ARR_v1_73@1,"Our methods outperform prior work in formality transfer & code-mixing for 7 languages, with promising qualitative results for several other attribute transfer tasks.","Our methods outperform prior work in formality transfer & codemixing for 7 languages, with promising qualitative results.","Modify,Claim",Claim
187,111-ARR,111-ARR_v2_90@2,111-ARR_v1_73@2,"Future work includes further improving systems for some attributes, and studying style transfer for languages where little / no translation data is available.","Future work includes further improving systems for some attributes, and considering languages where little / no translation data is available.","Modify,Clarity",Clarity
188,111-ARR,111-ARR_v2_92@3,111-ARR_v1_75@3,"The Google 2020 environment report mentions, 15 ""TPUs are highly efficient chips which have been specifically designed for machine learning applications"".","The Google 2020 environment report mentions, 13 ""TPUs are highly efficient chips which have been specifically designed for machine learning applications"".","Modify,Fact/Evidence",Fact/Evidence
189,111-ARR,111-ARR_v2_80@0,111-ARR_v1_75@5,"In our experiments, we compare the following models (training details are provided Appendix A):",We compare the following models:,"Modify,Fact/Evidence",Fact/Evidence
190,111-ARR,111-ARR_v2_2@1,111-ARR_v1_2@1,"While most prior literature assumes access to a large style-labelled corpus, recent work (Riley et al., 2021) has attempted ""few-shot"" style transfer using just 3-10 sentences at inference for style extraction.","While most prior literature assumes access to large stylelabelled corpora, recent work (Riley et al., 2021) has attempted ""few-shot"" style transfer using only 3-10 sentences at inference for extracting the target style.","Modify,Clarity",Clarity
191,111-ARR,111-ARR_v2_16@0,111-ARR_v1_10@1,"Most prior work either assumes access to supervised data with parallel sentences between the two styles (Jhamtani et al., 2017), or access to a large corpus of unpaired sentences with style labels (Prabhumoye et al., 2018;Subramanian et al., 2019).","Most prior work either assumes access to supervised data with parallel sentences between the two styles (Jhamtani et al., 2017), or access to large corpus of unpaired sentences with style labels (Prabhumoye et al., 2018;Subramanian et al., 2019).","Modify,Grammar",Grammar
192,111-ARR,111-ARR_v2_16@5,111-ARR_v1_10@6,"In this work, we take the first steps studying style transfer in seven languages 2 with nearly 1.5 billion speakers in total.","In this work, we take the first steps studying style transfer in seven languages 2 with nearly 1.5 billion speakers.","Modify,Clarity",Clarity
193,111-ARR,111-ARR_v2_16@7,111-ARR_v1_10@8,"Unfortunately, we find it often copies the inputs verbatim (Section 3.1), without changing their style.","Unfortunately, we found it often copied input sentences verbatim (Section 3.1) without transferring their style.","Modify,Clarity",Clarity
194,111-ARR,111-ARR_v2_17@1,111-ARR_v1_11@1,"To further boost performance we propose DIFFUR, 3 a novel algorithm using the recent finding that paraphrasing leads to stylistic changes (Krishna et al., 2020).","To further boost performance we propose DIFFUR, 3 an algorithm using the recent finding that paraphrasing leads to stylistic changes (Krishna et al., 2020).","Modify,Clarity",Clarity
195,111-ARR,111-ARR_v2_136@1,111-ARR_v1_125@1,"Consistent with Krishna et al. (2020), we find that top-p decoding usually gets higher style accuracy (r-ACC, a-ACC) and output diversity (1-g, COPY) scores, but lower semantic similarity (SIM) scores.","Consistent with Krishna et al. (2020), we find that top-p decoding usually gets higher style accuracy (r-ACC, a-ACC) and output diversity (1-g, COPY) scores, but lower similarity (SIM) scores.","Modify,Clarity",Clarity
196,111-ARR,111-ARR_v2_86@2,111-ARR_v1_130@2,"We find the lowest COPY (and lowest 1-g) for models with +BT (1%), which is due to two translation steps.","We find the lowest COPY (and lowest 1-g) for models with +BT (1%), which is due to two steps of translation.","Modify,Clarity",Clarity
197,111-ARR,111-ARR_v2_86@3,111-ARR_v1_130@3,"However, this lowers semantic similarity (also seen in Table 4) lowering the overall score (60.0 vs 78.1) compared to DIFFUR-MLT.","However, this lowers semantic similarity (also seen in Table 3) lowering the overall score compared to DIFFUR-MLT (60.0 vs 78.1 r-AGG).","Modify,Fact/Evidence",Fact/Evidence
198,111-ARR,111-ARR_v2_2@2,111-ARR_v1_2@2,"In this work, we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available.",In this work we study a relevant low-resource setting: style transfer for languages where no style-labelled corpora are available.,"Modify,Grammar",Grammar
199,111-ARR,111-ARR_v2_2@3,111-ARR_v1_2@3,"We notice that existing few-shot methods perform this task poorly, often copying inputs verbatim.","We find that existing fewshot methods perform this task poorly, with a strong tendency to copy inputs verbatim.","Modify,Clarity",Clarity
200,111-ARR,111-ARR_v2_22@1,111-ARR_v1_16@1,"At a high level, the UR model extracts a style vector s from an exemplar sentence e, which reflects the desired target style.","The UR model extracts a style vector s from an exemplar sentence e, which reflects the desired target style.","Modify,Clarity",Clarity
201,111-ARR,111-ARR_v2_24@2,111-ARR_v1_19@1,"Concretely, let x 1 and x 2 be two non-overlapping spans.","Concretely, let x 1 and x 2 be two non-overlapping spans in mC4.","Modify,Fact/Evidence",Fact/Evidence
202,111-ARR,111-ARR_v2_3@1,111-ARR_v1_3@1,"When compared to prior work, our model achieves 2-3x better performance in formality transfer and code-mixing addition across seven languages.","When compared to prior work using automatic and human evaluations, our model achieves 2-3x better performance and output diversity in formality transfer and code-mixing addition across seven languages.","Modify,Claim",Claim
203,114-ARR,,114-ARR_v1_46@2,,"Given that trigger-dependent types often have indicative triggers, we build a mechanism called word saliency embeddings (WSEs) in the model for T trigger to capture such regularities.","Delete,Fact/Evidence",Fact/Evidence
204,114-ARR,,114-ARR_v1_46@3,,"Specifically, we first quantify each word's saliency value 3 as 0 or 1 based on λ, i.e., the threshold we used previously for distinguishing event types, and then use a separate embedding vector to distinguish 0 and 1, similar to word embeddings.","Delete,Fact/Evidence",Fact/Evidence
205,114-ARR,,114-ARR_v1_46@4,,Such embeddings are incorporated into the model 4 to capture a regularity that words with high saliency values are more likely to be triggers.,"Delete,Fact/Evidence",Fact/Evidence
206,114-ARR,,114-ARR_v1_46@5,,"Note WSEs are also incorporated in the model for the T context , which on the other hand seeks to learn the opposite regularity that words with high saliency values may not be triggers.","Delete,Fact/Evidence",Fact/Evidence
207,114-ARR,,114-ARR_v1_54@1,,"We use Adam (Kingma and Ba, 2015) with default hyper-parameters for parameter update.","Delete,Fact/Evidence",Fact/Evidence
208,114-ARR,,114-ARR_v1_55@0,,Experimental Setups,"Delete,Other",Other
209,114-ARR,,114-ARR_v1_56@0,,Datasets.,"Delete,Other",Other
210,114-ARR,,114-ARR_v1_56@1,,"We conduct experiments on ACE 2005 (LDC, 2005) and MAVEN documents.","Delete,Fact/Evidence",Fact/Evidence
211,114-ARR,,114-ARR_v1_56@2,,"We adopt a common split for evaluation following previous works (Li et al., 2013;Wadden et al., 2019).","Delete,Fact/Evidence",Fact/Evidence
212,114-ARR,,114-ARR_v1_56@3,,MAVEN is a newly released corpus defining 168 more fine-grained event types .,"Delete,Fact/Evidence",Fact/Evidence
213,114-ARR,,114-ARR_v1_56@4,,"Because the MAVEN test set is not publicly available and our study is concerned with per-type performance, we instead use the MAVEN development set for assessment and divide the original MAVEN training set as 9:1 for training and validating.","Delete,Fact/Evidence",Fact/Evidence
214,114-ARR,,114-ARR_v1_56@5,,Table 1 displays the comprehensive data statistics for the two datasets.,"Delete,Fact/Evidence",Fact/Evidence
215,114-ARR,,114-ARR_v1_57@0,,Evaluation Metrics.,"Delete,Other",Other
216,114-ARR,,114-ARR_v1_67@5,,"(SL), which only differentiates event types for training, outperforms BERTEns by 1.6% in F1.","Delete,Fact/Evidence",Fact/Evidence
217,114-ARR,114-ARR_v2_67@2,,"For example, we may further subdivide a CD type TRANSFER_MONEY into finergrained ones like LOAN and PURCHASE.",,"Add,Claim",Claim
218,114-ARR,114-ARR_v2_67@3,,"We provide linguistic/lexical insights by comparing the hierarchy levels of TD/CD types on WordNet (Miller, 1992).",,"Add,Fact/Evidence",Fact/Evidence
219,114-ARR,114-ARR_v2_4@0,114-ARR_v1_4@0,"Event detection (ED) is the first and a crucial step of event extraction, which aims to identify events of certain types in plain texts (Ahn, 2006;Nguyen and Grishman, 2015;Mitamura et al., 2017).","Event detection (ED), the first and a crucial step of event extraction, aims to identify events of certain types in texts (Ahn, 2006;Nguyen and Grishman, 2015;Mitamura et al., 2017).","Modify,Clarity",Clarity
220,114-ARR,114-ARR_v2_4@2,114-ARR_v1_4@2,"Tasking the ACE benchmark as an example, we note the state-of-the-art ED model (Wadden et al., 2019) can strike 90% in F1 for the type DIVORCE, yet only 50% for the type START-POSITION, and it is more surprising that the training set of DIVORCE is eight times smaller than that of START-POSITION.","Tasking the ACE benchmark as an example, we note the state-of-the-art ED model (Wadden et al., 2019) can strike 90% in F1 for the type DIVORCE, yet only 50% for the type START-POSITION; it is more surprising that the training set of DIVORCE is 8 times smaller than that of START-POSITION.","Modify,Clarity",Clarity
221,114-ARR,114-ARR_v2_52@3,114-ARR_v1_60@3,"After 5 epochs, it achieves 74.8% in F1 on the ACE 2005 development set, matching the state-of-the-art performance (Liu et al., 2019c).","After 5 epochs, it achieves 74.8% in F1 on the ACE 2005 development set, matching the state-of-the-art performance .","Modify,Fact/Evidence",Fact/Evidence
222,114-ARR,114-ARR_v2_52@7,114-ARR_v1_60@8,"To allow for further investigation, we have made our code publicly available at https://github.com/ jianliu-ml/SaliencyED.","To allow for further investigation, we have made our code publicly available at http://anomynous.","Modify,Fact/Evidence",Fact/Evidence
223,114-ARR,114-ARR_v2_5@0,114-ARR_v1_5@0,In this study we take a fresh look at above problem and for the first time attribute the skewed performance to the contextual patterns of events.,This study takes a fresh look at the problem by attributing the skewed performance to the contextual patterns of events.,"Modify,Clarity",Clarity
224,114-ARR,114-ARR_v2_5@2,114-ARR_v1_5@2,"Intuitively, they demonstrate distinct patterns: the DI-VORCE event is more trigger-dependent, and the trigger word (i.e., ""divorced"") is very indicative of the event's occurrence; by contrast, the START-POSITION event is more context-dependent -the event semantic is primarily expressed by contexts rather than the trigger ""become"", which is a merely light verb.","Intuitively, they have distinct patterns: the DI-VORCE event is more trigger-dependent, because the trigger word (divorced) is very indicative of the event's occurrence; by contrast, the START-POSITION event is more context-dependent -the event semantic is primarily expressed by contexts rather than the trigger (become), which is a merely light verb.","Modify,Clarity",Clarity
225,114-ARR,114-ARR_v2_6@0,114-ARR_v1_6@0,"To address the first question, we introduce a brandy new concept called trigger saliency attribution, which can explicitly quantify an event's contextual pattern.",We introduce a brandy new concept called trigger saliency attribution that can explicitly quantify an event's contextual pattern.,"Modify,Clarity",Clarity
226,114-ARR,114-ARR_v2_6@1,114-ARR_v1_6@1,"Figure 2 illustrates the key idea: to determine how much an event is trigger-dependent or context-dependent, we measure the trigger's contribution to expressing overall the event semantic.","As shown in Figure 2, to determine how much an event depends on triggers/contexts, the key notion is to measure the trigger's contribution to expressing overall the event semantic.","Modify,Clarity",Clarity
227,114-ARR,114-ARR_v2_6@2,114-ARR_v1_6@2,"Specifically, we first assign each sentence a global event label that represents the overall event semantic.","To this end, we first assign each sentence a global event label that represents the overall event semantic.","Modify,Clarity",Clarity
228,114-ARR,114-ARR_v2_6@3,114-ARR_v1_6@3,"Then, inspired by the feature attribution method (Simonyan et al., 2014;Sundararajan et al., 2017), we regard each word as a feature and compute its contribution (i.e., saliency value) for predicting the global event label.","Then, inspired by the feature attribution method (Simonyan et al., 2014;Sundararajan et al., 2017), we regard each word as a feature and compute its saliency value (i.e., contribution) for predicting the global event label.","Modify,Clarity",Clarity
229,114-ARR,114-ARR_v2_6@4,114-ARR_v1_6@4,"Finally, by examining the ground-truth trigger's saliency value, we can tell how much an event depends on triggers or contexts: a higher value, for example, indicates that the trigger contributes more to the event, implying the event is more trigger-dependent.","Finally, by examining the ground-truth trigger's saliency value, we can determine how much an event depends on triggers or contexts: a higher value, for example, indicates that the trigger contributes more to the event, implying the event is more trigger-dependent.","Modify,Clarity",Clarity
230,114-ARR,114-ARR_v2_7@0,114-ARR_v1_7@0,"To answer the second question, we develop a new training mechanism based on trigger saliency attribution, which uses saliency as evidence to enhance learning.","We also develop a new training mechanism based on trigger saliency attribution, which uses saliency as evidence to enhance learning.","Modify,Clarity",Clarity
231,114-ARR,114-ARR_v2_7@1,114-ARR_v1_7@1,"Our method is simple and straightforward -instead of using a single model to detect all event types, we group event types with similar patterns together (assessed by trigger saliency attribution) and develop separate models for each group.","Our method is simple yet effective -instead of using a single model to detect all event types, we group event types with similar patterns together (assessed by trigger saliency attribution) and develop separate models for each group.","Modify,Clarity",Clarity
233,114-ARR,114-ARR_v2_7@2,114-ARR_v1_7@3,"This strategy enables different models to capture distinct patterns -for example, the model for context-dependent type can focus on mining contextual information for learning.","The model for context-dependent types, for example, can focus on mining contextual information for learning.","Merge+Modify,Clarity",Clarity
234,114-ARR,114-ARR_v2_7@3,114-ARR_v1_7@4,"To further boost learning, we also propose two saliency-exploration strategy to augment the above framework, which can explicitly integrate saliency information into learning and produce improved performance particularly for context-dependent types ( § 6.2).","Furthermore, we augment the above framework with two saliency-exploration strategy, which can explicitly integrate saliency information into learning and produce improved performance particularly for context-dependent types ( § 6.2).","Modify,Clarity",Clarity
235,114-ARR,114-ARR_v2_8@0,114-ARR_v1_8@0,"To verify the effectiveness of our approach, we have conducted extensive experiments on two ED benchmarks (i.e., ACE 2005(LDC, 2005 and MAVEN ).","We have conducted extensive experiments on two ED benchmarks (i.e., ACE 2005(LDC, 2005 and MAVEN ) to verify the effectiveness of our approach.","Modify,Clarity",Clarity
236,114-ARR,114-ARR_v2_8@1,114-ARR_v1_8@1,"According to the results: (i) Our trigger saliency attribution method can capture the underlying pattern and well explain the skewed performance, obtaining Spearman's correlation coefficients of 0.72 and 0.61 with per-type F1 on ACE 2005 and MAVEN respectively; (ii) Our new training regime based on saliency demonstrates improved results on the two benchmarks.","From the results: (i) Our trigger saliency attribution method does capture the underlying pattern and can well explain the skewed performance, obtaining Spearman's correlation coefficients of 0.72 and 0.61 with per-type F1 on ACE 2005 and MAVEN respectively; (ii) Our new training regime based on saliency demonstrates improved results on the two benchmarks.","Modify,Clarity",Clarity
237,114-ARR,114-ARR_v2_8@3,114-ARR_v1_8@3,"Finally, in ablation studies, we compare and highlight many significant characteristics (e.g., linguistic and lexical patterns) of triggerdependent and context-dependent event types; our work may inspire future research into their patterns.","Finally, we compare and emphasize several significant aspects (e.g., linguistic and lexical patterns) of trigger-dependent and contextdependent event types, and our work may inspire future research into their differences.","Modify,Clarity",Clarity
238,114-ARR,114-ARR_v2_20@0,114-ARR_v1_19@0,"• We highlight several diverse patterns of trigger-dependent and context-dependent event types, and our findings may stimulate future research into their differences.","• We highlight many distinct patterns of triggerdependent and context-dependent event types, and our findings suggest that the traditional ""one model fits all types"" paradigm may need to be revised.","Modify,Claim",Claim
239,114-ARR,114-ARR_v2_27@0,114-ARR_v1_27@0,"FA have been used to interpret model predictions in applications including image classification (Simonyan et al., 2014), machine translation (Ding et al., 2017), text classification , and others (Bastings and Filippova, 2020).","FA have been used to interpret model predictions in applications including image classification (Simonyan et al., 2014), machine translation (Ding et al., 2017), text classification (Chen et al., 2018), and others (Bastings and Filippova, 2020).","Modify,Fact/Evidence",Fact/Evidence
240,115-ARR,,115-ARR_v1_65@0,,Dataset,"Delete,Other",Other
241,115-ARR,,115-ARR_v1_66@0,,We conduct experiments on a publicly available multi-modal sarcasm detection benchmark dataset collected by Cai et al. (2019).,"Delete,Fact/Evidence",Fact/Evidence
242,115-ARR,,115-ARR_v1_66@1,,This dataset contains English tweets expressing sarcasm as Positive examples and those expressing non-sarcasm as Negative examples.,"Delete,Fact/Evidence",Fact/Evidence
243,115-ARR,,115-ARR_v1_66@2,,Each example in the dataset consists of a text and an associated image.,"Delete,Fact/Evidence",Fact/Evidence
244,115-ARR,,115-ARR_v1_66@3,,The statistics of the dataset are shown in Table 1.,"Delete,Fact/Evidence",Fact/Evidence
245,115-ARR,115-ARR_v2_75@4,,"2) We conduct significance tests of our CMGCN over the baseline models, the results show that our CMGCN significantly outperforms the baseline models in terms of most of the evaluation metrics (with p−value < 0.05).",,"Add,Fact/Evidence",Fact/Evidence
246,115-ARR,115-ARR_v2_88@0,,"As described in Section 3.3, the weights of edges in the cross-modal graph are computed based on both word similarities and affective clues between textual words and the attribute-object pairs of the image regions, and the dependency tree of the textmodality.",,"Add,Fact/Evidence",Fact/Evidence
247,115-ARR,115-ARR_v2_88@1,,The approach can be easily generalized to other sentiment-related multi-modal learning scenarios.,,"Add,Claim",Claim
248,115-ARR,115-ARR_v2_88@2,,"Nevertheless, the cross-graph solution might not be generalized well to other multi-modal tasks or data genres, if there is a lack of affective knowledge or a difficulty in deriving dependency trees in low-resource settings.",,"Add,Claim",Claim
249,115-ARR,115-ARR_v2_88@3,,"Therefore, future research can consider exploiting alternatively approaches to automatically learn the weights of edges in the cross-modal graph without relying on external knowledge sources.",,"Add,Claim",Claim
250,115-ARR,,115-ARR_v1_14@1,,"Different from text-based sarcasm detection, multimodal sarcasm detection aims to identify the sarcastic expression among different modalities (Schifanella et al., 2016;Castro et al., 2019).","Delete,Fact/Evidence",Fact/Evidence
251,115-ARR,,115-ARR_v1_14@2,,Schifanella et al. (2016) firstly tackled the multi-modal sarcasm detection task with text and image modalities by manually designed features.,"Delete,Fact/Evidence",Fact/Evidence
252,115-ARR,,115-ARR_v1_14@3,,Cai et al. (2019) created a new dataset and proposed a hierarchical fusion model for multi-modal sarcasm detection.,"Delete,Fact/Evidence",Fact/Evidence
253,115-ARR,,115-ARR_v1_14@5,,Pan et al. (2020) proposed inter-modality attention and coattention to learn the contradiction of sarcasm.,"Delete,Fact/Evidence",Fact/Evidence
254,115-ARR,115-ARR_v2_68@0,115-ARR_v1_71@0,"2) Text-modality methods: These models use only textual information, including TextCNN (Kim, 2014), a deep learning model based on CNN for text classification; Bi-LSTM, a bidirectional LSTM network for text classification; SIARN (Tay et al., 2018), adopting inner-attention for textual sarcasm detection; SMSD (Xiong et al., 2019), exploring a self-matching network to capture textual incongruity information; and BERT (Devlin et al., 2019), the vanilla pre-trained uncased BERT-base taking '[CLS] text [SEP]' as input.","2) Text-modality methods These models use only textual information, including TextCNN (Kim, 2014), a deep learning model based on CNN for text classification; Bi-LSTM, a bidirectional LSTM network for text classification; SIARN (Tay et al., 2018), adopting inner-attention for textual sarcasm detection; SMSD (Xiong et al., 2019), exploring a self-matching network to capture textual incongruity information; and BERT (Devlin et al., 2019), the vanilla pre-trained uncased BERT-base taking '[CLS] text [SEP]' as input.","Modify,Grammar",Grammar
255,115-ARR,115-ARR_v2_69@0,115-ARR_v1_72@0,3) Multi-modal methods: These models take both text-and image-modality information.,3) Multi-modal methods These models take both text-and image-modality information.,"Modify,Grammar",Grammar
256,115-ARR,115-ARR_v2_69@1,115-ARR_v1_72@1,"Including HFM (Cai et al., 2019), a hierarchical multimodal features fusion model for multi-modal sarcasm detection; D&R Net (Xu et al., 2020), a Decomposition and Relation Network modeling both crossmodality contrast and semantic association; Res-BERT (Pan et al., 2020), concatenating image features and BERT-based text features for sarcasm prediction; Att- BERT (Pan et al., 2020), exploring an inter-modality attention and a co-attention to model the incongruity of multi-modal sarcasm detection; and InCrossMGs (Liang et al., 2021a), a graph-based model to leverage the sarcastic relations from both intra-and inter-modal perspectives.","Including HFM (Cai et al., 2019), a hierarchical multimodal features fusion model for multi-modal sarcasm detection; D&R Net , a Decomposition and Relation Network modeling both crossmodality contrast and semantic association; Res-BERT (Pan et al., 2020), concatenating image features and BERT-based text features for sarcasm prediction; Att- BERT (Pan et al., 2020), exploring an inter-modality attention and a co-attention to model the incongruity of multi-modal sarcasm detection; and InCrossMGs , a graph-based model to leverage the sarcastic relations from both intra-and inter-modal perspectives.","Modify,Fact/Evidence",Fact/Evidence
257,115-ARR,115-ARR_v2_5@4,115-ARR_v1_5@4,"This post however contains a sarcastic expression with negative sentiment, because it is accompanied by an image with ""thunderstorm clouds"".","This post however contains a sarcastic expression with negative sentiment, because it is accompanied by an image with thunderstorm clouds.","Modify,Grammar",Grammar
258,115-ARR,115-ARR_v2_86@0,115-ARR_v1_90@0,Conclusion and Future Work,Conclusion,"Modify,Other",Other
259,115-ARR,115-ARR_v2_87@1,115-ARR_v1_91@1,"Specifically, unlike previous research efforts that simply consider the visual information of the whole image, we attempt to recognize the important visual regions via object detection results, and further devise a novel cross-modal graph to explicitly establish the connections of scattered visual regions and the associated textual tokens.","Specifically, unlike previous research efforts that simply consider the visual information of the whole image, we attempt to recognize the important visual regions via object detection results.","Modify,Fact/Evidence",Fact/Evidence
260,115-ARR,115-ARR_v2_87@4,115-ARR_v1_91@4,"To the best of our knowledge, it is the first study of utilizing a cross-modal graph to extract intricate multi-modal sarcastic relations via object detection and sentiment cues from external knowledge bases.","To our knowledge, it is the first study of utilizing a cross-modal graph to extract intricate multi-modal sarcastic relations via object detection and sentiment cues from external knowledge bases.","Modify,Clarity",Clarity
261,115-ARR,115-ARR_v2_6@0,115-ARR_v1_6@0,"To perform multi-modal sarcasm detection on data composed of text and image, several related research efforts attempt to concatenate the textual and visual features to fuse sarcastic information (Schifanella et al., 2016), employ attention mechanism to implicitly fuse the features of different modalities based on external knowledge (Cai et al., 2019;Xu et al., 2020;Pan et al., 2020), or build interactive graphs to model the relations of different modalities (Liang et al., 2021a).","To perform multi-modal sarcasm detection on data composed of text and image, several related research efforts attempt to concatenate the textual and visual features to fuse sarcastic information (Schifanella et al., 2016), employ attention mechanism to implicitly fuse the features of different modalities based on external knowledge (Cai et al., 2019;Pan et al., 2020), or build interactive graphs to model the relations of different modalities .","Modify,Fact/Evidence",Fact/Evidence
262,115-ARR,115-ARR_v2_2@1,115-ARR_v1_2@1,"In this paper, we investigate multimodal sarcasm detection from a novel perspective by constructing a cross-modal graph for each instance to explicitly draw the ironic relations between textual and visual modalities.","Different from existing research efforts that either simply consider the visual cues from the whole image or implicitly extract the sarcastic relations between different modalities purely via attention mechanism, in this paper, we investigate multi-modal sarcasm detection from a novel perspective by constructing a cross-modal graph for each instance to explicitly draw the ironic relations between textual and visual modalities.","Modify,Claim",Claim
263,115-ARR,115-ARR_v2_6@5,115-ARR_v1_6@5,"As such, it is essential to focus on drawing the intricate sentiment connections between text and image modalities, allowing a good exploitation of the contradictory sentiment information between modalities for learning sarcastic clues.","As such, it is essential to focus on drawing the intricate sentiment connections between modalities, allowing a good exploitation of the contradictory sentiments between modalities for learning sarcastic clues.","Modify,Clarity",Clarity
264,115-ARR,115-ARR_v2_7@3,115-ARR_v1_7@3,"Then, we explore a novel solution to assign weights to the edges of the cross-modal graph by means of computing the word similarities between the object descriptors of the attribute-object pairs and textual words based on the WordNet (Miller, 1992).","Then, we explore a novel solution to assign weights to the edges of the cross-modal graph by means of computing the word similarities between the object descriptors of the attribute-object pairs and textual words based on the WordNet (Miller, 1995).","Modify,Fact/Evidence",Fact/Evidence
265,115-ARR,115-ARR_v2_14@1,115-ARR_v1_16@1,"Further, there are also some research studies explored graph models to deal with the multi-modal tasks, such as multi-modal sentiment detection (Yang et al., 2021), multi-modal named entity recognition , cross-modal video moment retrieval (Zeng et al., 2021), multi-modal neural machine translation (Yin et al., 2020), and multimodal sarcasm detection (Liang et al., 2021a).","Correspondingly, there are also some multi-modal studies, such as multi-modal sentiment detection , multi-modal named entity recognition , and multi-modal sarcasm detection .","Modify,Fact/Evidence",Fact/Evidence
266,115-ARR,115-ARR_v2_17@0,115-ARR_v1_19@0,"As demonstrated in Figure 2, the architecture of the proposed CMGCN contains four main components: 1) Text-modality representation, which employs the pre-trained uncased BERT-base model (Devlin et al., 2019) as the text encoder to capture the hidden representation of the text-modality; 2) Image-modality representation, which deploys the pre-trained Vision Transformer (ViT) (Dosovitskiy et al., 2021) as the image encoder to capture the hidden representation of the image-modality with respect to each bounding box (visual region); 3) Cross-modal graph, which constructs a crossmodal graph for each multi-modal example based on the external affective knowledge source and the hidden representations of text and image modalities; 4) Multi-modal fusion, which fuses the representations from image and text modalities to capture the sarcastic features by means of a GCN structure and an attention mechanism.","As demonstrated in Figure 2, the architecture of the proposed CMGCN contains four main components: 1) Text-modality representation, which employs the pre-trained uncased BERT-base model (Devlin et al., 2019) as the text encoder to capture the hidden representation of the text-modality; 2) Image-modality representation, which deploys the pre-trained Vision Transformer (ViT) (Dosovitskiy et al., 2021) as the image encoder to capture the hidden representation of the image-modality with respect to each bounding box (visual region); 3) Cross-modal graph, which constructs a crossmodal graph for each multi-modal example based on the hidden representations of text and image modalities; 4) Multi-modal fusion, which fuses the representations from image and text modalities to capture the sarcastic features by means of a GCN structure and an attention mechanism.","Modify,Fact/Evidence",Fact/Evidence
267,118-ARR,,118-ARR_v1_75@0,,"4. Conll03-Typos , which is generated from Conll2003 (Sang and De Meulder, 2003).","Delete,Fact/Evidence",Fact/Evidence
268,118-ARR,,118-ARR_v1_75@1,,"The entities in the test set is replaced by typos version(character modify, insert, and delete operation).","Delete,Fact/Evidence",Fact/Evidence
269,118-ARR,,118-ARR_v1_76@0,,"5. Conll03-OOV , which is generated from Conll2003 (Sang and De Meulder, 2003).","Delete,Fact/Evidence",Fact/Evidence
270,118-ARR,,118-ARR_v1_76@1,,The entities in the test set is replaced by another out-of-vocabulary entity in test set.,"Delete,Fact/Evidence",Fact/Evidence
271,118-ARR,,118-ARR_v1_77@0,,Table 2 reports the static results of the OOV problem on the test sets of each dataset.,"Delete,Fact/Evidence",Fact/Evidence
272,118-ARR,,118-ARR_v1_77@1,,"As shown in the table, the test set of these data sets comprises a substantial amount of OOV entities.","Delete,Fact/Evidence",Fact/Evidence
273,118-ARR,118-ARR_v2_8@3,,Our codes 1 are publicly available.,,"Add,Fact/Evidence",Fact/Evidence
274,118-ARR,118-ARR_v2_64@2,,The resulting Mutual Information based Named Entity Recognition model is visualized in Figure 1.,,"Add,Fact/Evidence",Fact/Evidence
275,118-ARR,118-ARR_v2_85@3,,The results are obtained by testing MINER (Bert large) on TwitterNER .,,"Add,Fact/Evidence",Fact/Evidence
276,118-ARR,118-ARR_v2_85@4,,"We fix β = 1e03, and the orange line is f1 score when γ = 0.",,"Add,Fact/Evidence",Fact/Evidence
277,118-ARR,118-ARR_v2_85@5,,The results are obtained by testing MINER (Bert large) on TwitterNER .,,"Add,Fact/Evidence",Fact/Evidence
278,118-ARR,118-ARR_v2_85@6,,"We fix γ = 1e04, and the orange line is f1 score when β = 0.",,"Add,Fact/Evidence",Fact/Evidence
279,118-ARR,118-ARR_v2_4@0,118-ARR_v1_4@0,"Named Entity Recognition (NER) aims to identify and classify entity mentions from unstructured text, e.g., extracting location mention ""Berlin"" from the sentence ""Berlin is wonderful in the winter"".","Named Entity Recognition(NER) aims to identify and classify entity mentions from unstructured text, e.g., extracting location mention ""Berlin"" from sentence ""Berlin is wonderful in the winter"".","Modify,Grammar",Grammar
280,118-ARR,118-ARR_v2_48@0,118-ARR_v1_47@0,"Motivated by IB (Tishby et al., 2000;Federici et al., 2020), we can subdivide I(X; Z) into two components by using the chain rule of mutual information(MI):","Motivated by IB (Tishby et al., 2000;Federici et al., 2020), we can subdividing I(X; Z) into two components by using the chain rule of mutual information(MI):","Modify,Grammar",Grammar
281,118-ARR,118-ARR_v2_72@0,118-ARR_v1_69@0,"In this section, we verify the performance of the proposed method on five OOV datasets, and compared it with other methods.","In this section, we verified the performance of the proposed method on five OOV datasets, and compared it with other methods.","Modify,Grammar",Grammar
282,118-ARR,118-ARR_v2_77@2,118-ARR_v1_78@2,"However, the work is neither open source nor reported on the same dataset, so this method cannot be compared with MINER.","However, the work is neither open source nor reported on the same data set, so this method is not compared with MINER.","Modify,Clarity",Clarity
283,118-ARR,118-ARR_v2_80@0,118-ARR_v1_81@0,"To verify the universality of our method, we measured its performance on various pre-trained models, i.e., Bert (Devlin et al., 2018), Roberta (Liu et al., 2019), Albert (Lan et al., 2019).","To verify the universality of our method, we measured its performance in various pre-trained models, i.e., Bert (Devlin et al., 2018), Roberta (Liu et al., 2019), Albert (Lan et al., 2019).","Modify,Grammar",Grammar
284,118-ARR,118-ARR_v2_82@2,118-ARR_v1_83@2,The output dim of the information bottleneck layer is 50.,The output dim of information bottleneck layer is 50.,"Modify,Grammar",Grammar
285,118-ARR,118-ARR_v2_82@4,118-ARR_v1_83@4,"On the other hand, we count the length distribution of entity length in different datasets, and finally choose 4 as the maximum enumerated entity length.","On the other hand, we count the length distribution of entity length in different datasets, and finally chose 4 as the maximum enumerated entity length.","Modify,Grammar",Grammar
286,118-ARR,118-ARR_v2_82@5,118-ARR_v1_83@5,The values of β and γ differ for different datasets.,The values of β and γ are different for different data sets.,"Modify,Clarity",Clarity
287,118-ARR,118-ARR_v2_82@7,118-ARR_v1_83@7,The model is trained in an NVIDIA GeForce RTX 2080Ti GPU.,The model is trained in a NVIDIA GeForce RTX 2080Ti GPU.,"Modify,Grammar",Grammar
288,118-ARR,118-ARR_v2_84@1,118-ARR_v1_85@1,"As shown in table 3, we conducted the following comparison and analysis:","As shown in table 3, we have the following observations and analysis:","Modify,Clarity",Clarity
289,118-ARR,118-ARR_v2_85@0,118-ARR_v1_86@0,"1) Our baseline model, i.e., SpanNER, does an excellent job of predicting OOV entities.","1) Our baseline model, i.e., SpanNER, does a good job at predicting OOV entities.","Modify,Other",Other
290,118-ARR,118-ARR_v2_90@4,118-ARR_v1_91@4,It probes the effectiveness of our proposed training objectives that enhances representation via deep understanding of context and entity surface forms and discourages representation from rote memorizing entity names or exploiting biased cues in data.,It probes the effectiveness of our proposed training objectives that enhances representation via deep understanding of context and entity surface forms and discourages representation from rotate memorizing entity names or exploiting biased cues in data.,"Modify,Grammar",Grammar
291,118-ARR,118-ARR_v2_90@5,118-ARR_v1_91@5,"As the coefficient rate increases continuously, the performance shows a declining trend, which means the over-constraint of L gi or L si will hurt the generalizing ability of predicting the OOV entities.","When the coefficient rate increases continuously, the performance shows a decline trend, which means the over-constraint of L gi or L si will hurt the generalizing ability of predicting the OOV entities.","Modify,Clarity",Clarity
292,118-ARR,118-ARR_v2_92@4,118-ARR_v1_93@4,"Take the attention weights of the entity ""State Street"" as an example, it is obvious that baseline model, i.e., SpanNER, focus on entity words themselves.","Take the attention weights of entity ""State Street"" as a example, it is obvious that baseline model, i.e., SpanNER, focus on entity words themselves.","Modify,Grammar",Grammar
293,118-ARR,118-ARR_v2_92@5,118-ARR_v1_93@5,"While the scores of our model are more average, it means that our method concerns more context information.","While the scores of our model is more average, means that our method concern more context information.","Modify,Grammar",Grammar
294,118-ARR,118-ARR_v2_95@0,118-ARR_v1_96@0,This group of methods makes it easier to predict OOV entities using external knowledge.,This of methods makes it easier to predict OOV entities using external knowledge.,"Modify,Grammar",Grammar
295,118-ARR,118-ARR_v2_95@1,118-ARR_v1_96@1,Zhang and Yang (2018) utilize a dictionary to list numerous entity mentions.,Zhang and Yang (2018) Use a dictionary to list numerous entity mentions.,"Modify,Clarity",Clarity
296,118-ARR,118-ARR_v2_95@3,118-ARR_v1_96@3,"To diminish the model's dependency on OOV embedding, introduce partof-speech tags.","To diminish the model's dependency on OOV embedding, introduces partof-speech tags.","Modify,Grammar",Grammar
297,118-ARR,118-ARR_v2_99@2,118-ARR_v1_100@2,Pre-trained models contextualized word embeddings via pretraining on large background corpora.,Pre-trained models contextualized word embbeddings via pretraining on large background corpora.,"Modify,Grammar",Grammar
298,118-ARR,118-ARR_v2_99@3,118-ARR_v1_100@3,"Furthermore, contextualized word embeddings can be provided by the pre-trained models, which are pre-trained on large background corpora (Peters et al., 2018;Devlin et al., 2018;Liu et al., 2019).","Furthermore, contextualized word embeddings can be provided by the pre-trained models which are pre-trained on large background corpora (Peters et al., 2018;Devlin et al., 2018;Liu et al., 2019).","Modify,Grammar",Grammar
299,118-ARR,118-ARR_v2_99@4,118-ARR_v1_100@4,Yan et al. (2021) shows that BERT is not always better at capturing context as compared to Gloe-based BiLSTM-CRFs.,Yan et al. (2021) shows that BERT are not always better at capturing context as compared to Gloe-based BiLSTM-CRFs.,"Modify,Grammar",Grammar
300,118-ARR,118-ARR_v2_99@5,118-ARR_v1_100@5,Their higher performance could be the result of learning the subword structure better.,Their higher performance could be the results of learning the subword structure better.,"Modify,Grammar",Grammar
301,118-ARR,118-ARR_v2_101@0,118-ARR_v1_102@0,"Based on the recent studies of NER, we analyze how to improve the OOV entity recognition.","Based on the recent studies of NER, we analyzed how to improve the OOV entity recognition.","Modify,Grammar",Grammar
302,118-ARR,118-ARR_v2_7@4,118-ARR_v1_7@4,"The strategy is learning a static OOV embedding representation, but not directly utilizing the context.","The strategy is learning a static OOV embedding representation, but not directly utilize the context.","Modify,Grammar",Grammar
303,118-ARR,118-ARR_v2_7@6,118-ARR_v1_7@6,"Unfortunately, Agarwal et al. (2021) shows that the higher performance of pretrained models could be the results of learning the subword structure better.","Unfortunately, Yan et al. (2021) shows that the higher performance of pretrained models could be the results of learning the subword structure better.","Modify,Fact/Evidence",Fact/Evidence
304,118-ARR,118-ARR_v2_8@2,118-ARR_v1_9@0,"Specifically, MINER contains two mutual information based learning objectives: i) generalizing information maximization, which aims to maximize the mutual information between representations and well-generalizing features, i.e., context and entity surface forms; ii) superfluous information minimization, which prevents the model from rote memorizing the entity names or exploiting biased cues via eliminating entity name information.","Specifically, MINER contains two mutual information based learning objectives: i) generalizing information maximization, which aims to maximize the mutual information between representations and well-generalizing features, i.e., context and entity surface forms; ii) superfluous information minimization, which prevents the model from rote memorizing the entity names or exploiting biased cus via eliminating entity name information.","Modify,Grammar",Grammar
305,118-ARR,118-ARR_v2_10@0,118-ARR_v1_11@0,"1. We propose a novel learning framework, i.e., MINER, from an information theory perspective, aiming to improve the robustness of entity changes by eliminating entity-specific and maximizing wellgeneralizing information.","1. We propose a novel learning framework, i.e., MINER, from an information theory perspective, aiming to improve the robustness of entity changes by eliminating entity-specific and maximize wellgeneralizing information.","Modify,Grammar",Grammar
306,118-ARR,118-ARR_v2_13@1,118-ARR_v1_14@1,"Subsequently, the analysis of possible issues was provided when applying it to OOV entity recognition.","Subsequently, the analysis of possible issues when applying it to OOV entity recognition was provided.","Modify,Clarity",Clarity
307,118-ARR,118-ARR_v2_14@1,118-ARR_v1_15@1,It formulates the goal of representation learning as an information trade-off between predictive power and representation compression.,It formulates the goal of representation learning as an information trade-off between representation compression and predictive power.,"Modify,Clarity",Clarity
308,118-ARR,118-ARR_v2_2@3,118-ARR_v1_2@3,"The proposed approach contains two mutual information-based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rote memorizing entity names or exploiting biased cues in data.","The proposed approach contains two mutual information based training objectives: i) generalizing information maximization, which enhances representation via deep understanding of context and entity surface forms; ii) superfluous information minimization, which discourages representation from rotate memorizing entity names or exploiting biased cues in data.","Modify,Grammar",Grammar
309,118-ARR,118-ARR_v2_16@1,118-ARR_v1_17@1,The trade-off between the two MI terms is controlled by the Lagrange multiplier β.,The trade-off between the two MI terms is controlled by a Lagrange multiplier β.,"Modify,Grammar",Grammar
310,118-ARR,118-ARR_v2_18@3,118-ARR_v1_19@3,"Consequently, neural networks tend to use any accessible signal to do so (Ilyas et al., 2019), which is referred to as a shortcut learning problem (Geirhos et al., 2020).","Consequently, neural networks tend to use any accessible signal to do so (Ilyas et al., 2019), which is referred to as a shotcut learning problem (Geirhos et al., 2020).","Modify,Grammar",Grammar
311,118-ARR,118-ARR_v2_19@1,118-ARR_v1_20@1,"In Section 4, we demonstrate how we extend IB to the NER task and address these issues.","In Section 4, we demonstrate how we extend BN to the NER task and address these issues.","Modify,Fact/Evidence",Fact/Evidence
312,118-ARR,118-ARR_v2_21@2,118-ARR_v1_23@1,"2) Compared with sequence labeling, SpanNER does better in sentences with more OOV words (Fu et al., 2021).","2) compared with sequence labeling, SpanNER does better in sentences with more OOV words (Fu et al., 2021).","Modify,Grammar",Grammar
357,124-ARR,,124-ARR_v1_29@0,,We also show explorations with other review combination methods in Appendix C.1.,"Delete,Fact/Evidence",Fact/Evidence
358,124-ARR,,124-ARR_v1_31@5,,"Hence, all our future usage of the word ""Transformers"" refers to bart-large-cnn in the Transformers library .","Delete,Fact/Evidence",Fact/Evidence
359,124-ARR,,124-ARR_v1_71@0,,We show category examples in Table 9.,"Delete,Fact/Evidence",Fact/Evidence
360,124-ARR,,124-ARR_v1_72@0,,"The additional rules for annotation are as follows: First, instead of only labeling the individual sentences per se, the annotators are given a complete paragraph of meta-review to label the sentences with context information.","Delete,Fact/Evidence",Fact/Evidence
361,124-ARR,,124-ARR_v1_72@1,,"For example, if the area chair writes a sentence providing some extra background knowledge in the discussion of the weakness of the submission, that sentence itself can be considered as ""misc"".","Delete,Fact/Evidence",Fact/Evidence
362,124-ARR,,124-ARR_v1_72@2,,"However, it should be labeled as ""weakness"" to be consistent in context.","Delete,Fact/Evidence",Fact/Evidence
363,124-ARR,,124-ARR_v1_72@3,,"Second, not every sentence can be strictly classified into a single category.","Delete,Fact/Evidence",Fact/Evidence
364,124-ARR,,124-ARR_v1_72@4,,"When a sentence contains information from multiple categories, the annotators should consider its main point and primary purpose.","Delete,Fact/Evidence",Fact/Evidence
365,124-ARR,,124-ARR_v1_73@0,,"Furthermore, there are still some cases where the main point of the sentence is hard to differentiate from multiple categories.","Delete,Fact/Evidence",Fact/Evidence
366,124-ARR,,124-ARR_v1_73@3,,"We use the sign "" ? ="" because there are some rare cases where a sentence contains both ""strength"" and ""weakness"" while there is no obvious emphasis on either, and it is hard to tell whether ""strength"" should have a priority over ""weakness"" or the other way round.","Delete,Fact/Evidence",Fact/Evidence
367,124-ARR,,124-ARR_v1_73@4,,"We then label this sentence based on the final decision: if this submission is accepted, we label the sentence as ""strength"", and vice versa.","Delete,Fact/Evidence",Fact/Evidence
368,124-ARR,,124-ARR_v1_74@0,,We further analyze the category distribution in borderline papers.,"Delete,Fact/Evidence",Fact/Evidence
369,124-ARR,,124-ARR_v1_74@1,,"As shown in Table 10, for submissions within the score range of [4.5,6), there are 713 accepted submissions and 2,588 rejected submissions.","Delete,Fact/Evidence",Fact/Evidence
370,124-ARR,,124-ARR_v1_74@2,,"One clear difference is the percentage of ""strength"" and ""weakness"".","Delete,Fact/Evidence",Fact/Evidence
371,124-ARR,,124-ARR_v1_74@3,,"Another difference is the percentage of ""ac disagreement"", where the accepted papers have four times the value than rejected ones.","Delete,Fact/Evidence",Fact/Evidence
372,124-ARR,,124-ARR_v1_74@4,,"This suggests that for the accepted borderline papers, the area chair tends to share different opinions with reviewers, and thus deciding to accept the borderline submissions.","Delete,Claim",Claim
373,124-ARR,,124-ARR_v1_75@0,,"We further analyze the occurrence of each category for accepted papers and rejected papers separately across different score ranges, as shown in Table 11.","Delete,Fact/Evidence",Fact/Evidence
374,124-ARR,,124-ARR_v1_75@1,,"For accepted papers, as the score increases, the percentage of meta-reviews having ""weakness"" and ""suggestion"" drops because the high-score submissions are more likely to be accepted.","Delete,Fact/Evidence",Fact/Evidence
375,124-ARR,,124-ARR_v1_75@2,,"Even the percentage of ""decision"" drops following the same trend.","Delete,Fact/Evidence",Fact/Evidence
376,124-ARR,,124-ARR_v1_76@1,,"For the concat, we simply concatenate all reviews one after another according to their reviewers' sequence.","Delete,Fact/Evidence",Fact/Evidence
377,124-ARR,,124-ARR_v1_76@2,,"For merge, we can obtain the merged content as follows: From all review inputs, we use the longest one as a backbone.","Delete,Fact/Evidence",Fact/Evidence
378,124-ARR,,124-ARR_v1_83@0,,"For preprocessing, besides filtering based on metareview length, we also remove submissions with only one or two reviews, since the majority of the submissions have more than 3 reviews.","Delete,Fact/Evidence",Fact/Evidence
379,124-ARR,,124-ARR_v1_85@2,,"For the rest of the hyperparameters, we use the pretrained model's default values.","Delete,Fact/Evidence",Fact/Evidence
380,124-ARR,124-ARR_v2_2@7,,"† Chenhui, Liying, and Ran are under the Joint PhD Program between Alibaba and their corresponding universities.",,"Add,Fact/Evidence",Fact/Evidence
381,124-ARR,124-ARR_v2_3@1,,1 Our code and data are released at https://github.,,"Add,Fact/Evidence",Fact/Evidence
382,124-ARR,124-ARR_v2_6@1,,"The more-to-less text generation tasks output a concise piece of text from some more abundant input, such as text summarization (Tan et al., 2017;Kryściński et al., 2018).",,"Add,Fact/Evidence",Fact/Evidence
383,124-ARR,124-ARR_v2_11@0,,(2) We propose a new task of controllable generation focusing on controlling the passage macro structures.,,"Add,Fact/Evidence",Fact/Evidence
384,124-ARR,124-ARR_v2_11@1,,It offers stronger generation flexibility and applicability for practical use cases.,,"Add,Claim",Claim
385,124-ARR,124-ARR_v2_16@3,,Table 2 shows the statistics of data collected from each year.,,"Add,Fact/Evidence",Fact/Evidence
386,124-ARR,124-ARR_v2_16@4,,"Initially, 7,894 submissions are collected.",,"Add,Fact/Evidence",Fact/Evidence
387,124-ARR,124-ARR_v2_16@5,,"After filtering, 7,089 meta-reviews are retained with their corresponding 23,675 reviews.",,"Add,Fact/Evidence",Fact/Evidence
388,124-ARR,,124-ARR_v1_9@0,,"We will release our full dataset, code, and detailed settings to the community.","Delete,Claim",Claim
389,124-ARR,124-ARR_v2_41@2,,"Due to long inputs (see Table 17), we experiment with different source truncation lengths of 1024, 2048, and 3072 tokens.",,"Add,Fact/Evidence",Fact/Evidence
390,124-ARR,124-ARR_v2_41@3,,We cannot explore truncation length of more than 3072 tokens due to the limitation of GPU space.,,"Add,Fact/Evidence",Fact/Evidence
391,124-ARR,124-ARR_v2_41@4,,"Our learning rate is 5e-5, and we use Adam optimizer with momentum β 1 = 0.9, β 2 = 0.999 without any warm-up steps or weight decay.",,"Add,Fact/Evidence",Fact/Evidence
392,124-ARR,124-ARR_v2_41@5,,"We set the seed to be 0, and train the model for 3 epochs with gradient accumulation step of 1.",,"Add,Fact/Evidence",Fact/Evidence
393,124-ARR,124-ARR_v2_41@6,,"For decoding, we use a beam size of 4 and length penalty of 2.",,"Add,Fact/Evidence",Fact/Evidence
394,124-ARR,124-ARR_v2_45@0,,Review Combination Results,,"Add,Other",Other
395,124-ARR,124-ARR_v2_46@0,,"We also show uncontrolled generation results for different review combination methods in Table 6, with source truncation of 2048.",,"Add,Fact/Evidence",Fact/Evidence
396,124-ARR,124-ARR_v2_46@2,,"Rateconcat has the best overall performance, which is the setting we used for the main results.",,"Add,Fact/Evidence",Fact/Evidence
397,124-ARR,124-ARR_v2_46@3,,"Never- theless, it is not significantly better than merge.",,"Add,Fact/Evidence",Fact/Evidence
398,124-ARR,124-ARR_v2_46@4,,"It is also interesting to see that for merge, providing additional rating information (rate-merge) slightly worsens the performance.",,"Add,Fact/Evidence",Fact/Evidence
399,124-ARR,124-ARR_v2_46@5,,We will leave the investigation of better review combination methods for future work.,,"Add,Claim",Claim
400,124-ARR,124-ARR_v2_61@1,,"For each test instance, we provide the judges with the input reviews and randomly ordered generations from different models, and ask them to individually evaluate the generations based on the following criteria: (1) Fluency: is the generation fluent, grammatical, and without unnecessary repetitions? (2) Content Relevance: does the generation reflect the review content well, or does it produce general but trivial sentences? (3) Structure Similarity: how close does the generation structure resemble the gold structure (i.e., the control sequence)? ( 4) Decision Correctness: does the generation correctly predicts the gold human decision?",,"Add,Fact/Evidence",Fact/Evidence
401,124-ARR,124-ARR_v2_66@2,,Our work is the first fully-annotated dataset in this domain for the structure-controllable generation task.,,"Add,Claim",Claim
402,124-ARR,124-ARR_v2_70@0,,Ethical Concerns,,"Add,Other",Other
403,124-ARR,124-ARR_v2_71@0,,We have obtained approval from ICLR organizers to use the data collected from ICLR 2018-2021 on OpenReview.,,"Add,Fact/Evidence",Fact/Evidence
404,124-ARR,124-ARR_v2_72@1,,"Note that due to limited GPU space, we cannot fit 2048 input tokens for T5.",,"Add,Fact/Evidence",Fact/Evidence
405,124-ARR,124-ARR_v2_72@2,,"Thus, for fair comparison, all results shown are from source truncation of 1024.",,"Add,Fact/Evidence",Fact/Evidence
406,124-ARR,124-ARR_v2_73@1,,"Specifically, we define the task as a sequence labeling problem and apply the long short-term memory (LSTM) (Hochreiter and Schmidhuber, 1997) networks with a conditional random field (CRF) (Lafferty et al., 2001) (i.e., LSTM-CRF (Lample et al., 2016)) model on the annotated MReD dataset.",,"Add,Fact/Evidence",Fact/Evidence
407,124-ARR,124-ARR_v2_74@0,,The same data split as the meta-review generation task is used.,,"Add,Fact/Evidence",Fact/Evidence
408,124-ARR,124-ARR_v2_74@1,,"We adopt the standard IOBES tagging scheme (Ramshaw, 1995;Ratinov and Roth, 2009), and fine-tune BERT (Devlin et al., 2019) and RoBERTa models in Hugging Face.",,"Add,Fact/Evidence",Fact/Evidence
409,124-ARR,124-ARR_v2_74@2,,"All models are trained for 30 epochs with an early stop of 20, and each epoch takes about 30 minutes.",,"Add,Fact/Evidence",Fact/Evidence
410,124-ARR,124-ARR_v2_74@3,,We select the best model parameters based on the best micro F 1 score on the development set and apply it to the test set for evaluation.,,"Add,Fact/Evidence",Fact/Evidence
411,124-ARR,124-ARR_v2_75@0,,All models are run with single V100 GPUs.,,"Add,Fact/Evidence",Fact/Evidence
412,124-ARR,124-ARR_v2_75@1,,"We use Adam (Kingma and Ba, 2014) with an initial learning rate of 2e-5.",,"Add,Fact/Evidence",Fact/Evidence
413,124-ARR,124-ARR_v2_75@2,,We report the F 1 scores for each category as well as the overall micro F 1 and macro F 1 scores in Table 14.,,"Add,Fact/Evidence",Fact/Evidence
414,124-ARR,124-ARR_v2_79@2,,"Nevertheless, the pattern is less evident in the source (reviews) baselines.",,"Add,Claim",Claim
415,124-ARR,124-ARR_v2_19@2,124-ARR_v1_16@2,"Each meta-review sentence is independently labeled by 2 different annotators, and a third expert annotator resolves any disagreement between the first two annotators.","Each meta-review sentence is independently labeled by 2 different annotators, and a third annotator resolves any disagreement between the first two annotators.","Modify,Clarity",Clarity
416,124-ARR,124-ARR_v2_19@3,124-ARR_v1_16@3,"We label 45,929 sentences from 7,089 meta-reviews in total, and the Cohen's kappa is 0.778 between the first two annotators, showing that the annotation is of quite high quality.","We label 45,929 sentences from 7,089 meta-reviews in total, and the Cohen's kappa is 0.778 between the two annotators, showing that the annotation is of quite high quality.","Modify,Clarity",Clarity
417,124-ARR,124-ARR_v2_22@1,124-ARR_v1_19@1,"The number of sentences in different categories are shown in Figure 1, breakdown by the decision (i.e., accept or reject).","The sentence numbers in different categories are shown in Figure 1, breakdown by the decision (i.e., accept or reject).","Modify,Clarity",Clarity
418,124-ARR,124-ARR_v2_27@2,124-ARR_v1_24@2,"To achieve such flexibility, the task of structure-controllable text generation is defined as: given the text input (i.e., reviews) and a control sequence of the output structure, a model should generate a meta-review that is derivable from the reviews and presents the required structure.","To achieve such flexibility, the task of structure-controllable text generation is defined as: given the text input (i.e., reviews) and a control sequence of the output structure, a model should generate a meta-review which is derivable from the reviews and presents the required structure.","Modify,Clarity",Clarity
419,124-ARR,124-ARR_v2_31@1,124-ARR_v1_28@1,"One simple method, concat, is to concatenate all inputs one after another (Fabbri et al., 2019).","One simple method to combine multiple inputs for encoder-decoder models is to concatenate all inputs one after another (Fabbri et al., 2019).","Modify,Clarity",Clarity
420,124-ARR,124-ARR_v2_31@2,124-ARR_v1_28@2,"Besides the text inputs, the review rating, which cannot be found in the review passages but exists in the field of rating score, is also crucial information for writing meta-reviews.","Beside the text inputs, the review rating is also crucial information for writing meta reviews, which cannot be found in the review passages but exists in the field of rating score.","Modify,Clarity",Clarity
421,124-ARR,124-ARR_v2_32@2,124-ARR_v1_30@2,Sent-ctrl uses one control label per target sentence and controls generation on the sentence-level.,Sent-ctrl uses one control label per target sentence and controls generation on a sentence-level.,"Modify,Grammar",Grammar
422,124-ARR,124-ARR_v2_33@4,124-ARR_v1_31@4,"More specifically, we use the Py-Torch implementation in the open-source library Hugging Face Transformers (Wolf et al., 2020) and its hosted pretrained models 3 .","More specifically, we use the pytorch implementation in the open-source library Hugging Face Transformers (Wolf et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
423,124-ARR,124-ARR_v2_36@5,124-ARR_v1_34@5,"After ranking with each of the above models, we select sentences as output with different strategies according to the controlled and uncontrolled settings.","After ranking with the above models, we select sentences as output with different strategies according to the controlled and uncontrolled settings.","Modify,Clarity",Clarity
424,124-ARR,124-ARR_v2_36@8,124-ARR_v1_34@8,"To do so, we employ an LSTM-CRF (Lample et al., 2016) tagger trained on the labeled meta-reviews to predict the labels of each input review sentence.","To do so, we employ an LSTM-CRF (Lample et al., 2016) tagger trained on the labeled meta-reviews to predict the sentence labels of each input review.","Modify,Clarity",Clarity
425,124-ARR,124-ARR_v2_43@5,124-ARR_v1_39@5,"On the other hand, for bart-large-cnn, sent-ctrl is the best, followed by seg-ctrl.","On the other hand, for the Transformers, sent-ctrl is the best, followed by seg-ctrl.","Modify,Fact/Evidence",Fact/Evidence
426,124-ARR,124-ARR_v2_44@1,124-ARR_v1_39@8,"This is also validated by the ""Target Generic"" baseline's consistent improvement over the ""Source Generic"" baseline, which shows that generic sentences from meta-reviews can suit generation better than those in reviews.","This is again validated by the ""Target Generic"" baseline's significant improvement over the ""Source Generic"" baseline, which shows that generic sentences from meta-reviews can suit generation much better than those in reviews.","Modify,Clarity",Clarity
427,124-ARR,124-ARR_v2_63@1,124-ARR_v1_54@1,"Sentctrl also has better fluency and decision correctness, suggesting that having a better output structure can benefit readability and decision generation.","Sentctrl also has better fluency and decision correctness, suggesting that having a better output structure can benefit the readability and decision generation.","Modify,Grammar",Grammar
428,124-ARR,124-ARR_v2_65@2,124-ARR_v1_56@2,"In this paper, we explore text summarization in a new domain (i.e., the peer review domain) and provide a new dataset, i.e., MReD. Moreover, MReD's reference summaries (i.e., meta-reviews) are fully annotated and thus allow us to propose a new task, namely, structurecontrollable text generation.","In this paper, we explore text summarization in a new domain (i.e., the peer review domain) and provide a new dataset, i.e., MReD. Moreover, MReD's reference summaries (i.e., meta-reviews) are fully annotated and thus allow us to propose a new task, namely structurecontrollable text generation.","Modify,Grammar",Grammar
429,124-ARR,124-ARR_v2_66@3,124-ARR_v1_57@2,"There are also some datasets and annotation schemes on research articles (Teufel et al., 1999;Liakata et al., 2010;Lauscher et al., 2018), which differ in nature from the peer review domain and cannot be easily transferred to our task.","There are also some explorations on research articles (Teufel et al., 1999;Liakata et al., 2010;Lauscher et al., 2018), which differ in nature from the peer review domain.","Modify,Claim",Claim
430,124-ARR,124-ARR_v2_7@0,124-ARR_v1_5@0,"To some extent, the existing task settings are not so adequate because they do not have a deep understanding of the domains they are working on, i.e., domain knowledge.","To some extent, the existing task settings are not so adequate because they do not have deep understanding of the domains they are working on, i.e., domain knowledge.","Modify,Grammar",Grammar
431,124-ARR,124-ARR_v2_7@1,124-ARR_v1_5@1,"Taking text summarization as an example, the most well-experimented dataset CNN/Daily Mail (Nallapati et al., 2016) is composed of the training pairs of news content and human-written summary bullets.","Taking text summarization as an example, the most well-experimented dataset CNN/Daily Mail (Nallapati et al., 2016) is composed of the training pairs of news content and news titles.","Modify,Fact/Evidence",Fact/Evidence
432,124-ARR,124-ARR_v2_31@7,124-ARR_v1_76@4,"Then, for each paragraph embedding in the nonbackbone reviews, we calculate a cosine similarity score with each backbone paragraph embedding.","Then, for each paragraph embedding in the non-backbone reviews, we calculate a cosine similarity score with each backbone paragraph embedding, and insert it after the backbone paragraph with which it has the highest similarity score.","Split+Modify,Grammar",Grammar
433,124-ARR,124-ARR_v2_31@8,124-ARR_v1_76@4,We then insert each non-backbone paragraph after the backbone paragraph with which it has the highest similarity score.,"Then, for each paragraph embedding in the non-backbone reviews, we calculate a cosine similarity score with each backbone paragraph embedding, and insert it after the backbone paragraph with which it has the highest similarity score.","Split+Modify,Clarity",Clarity
434,124-ARR,124-ARR_v2_7@2,124-ARR_v1_5@2,"However, it does not tell why a particular piece of news content should have that corresponding summary, for example for the same earnings report, why one media emphasizes its new business success in the summary, but another emphasizes its net income.","However, it does not tell why a particular piece of news content should have that corresponding title, for example for the same earnings report, why one media emphasizes its new business success in the title, but another emphasizes its net income.","Modify,Clarity",Clarity
435,124-ARR,124-ARR_v2_31@11,124-ARR_v1_76@6,"Additionally, we provide a longest-review baseline, which does not combine reviews but only uses the longest review as the input.","Additionally, we provide a baseline setting longestreview, which does not combine reviews but only uses the longest review as the input.","Modify,Clarity",Clarity
436,124-ARR,124-ARR_v2_31@10,124-ARR_v1_76@7,We further add rating sentences in front of the results of merge to obtain rate-merge.,"Moreover, we add rating sentences in front of the results of concat and merge to obtain rate-concat and rate-merge, respectively.","Modify,Fact/Evidence",Fact/Evidence
437,124-ARR,124-ARR_v2_46@1,124-ARR_v1_77@0,"The longest-review setting has the worst performance, thus validating that the review combination methods are necessary in order not to omit important information.","As shown in Table 12, the longest-review setting has the worst performance, thus validating that the review combination methods are necessary in order not to omit important information.","Modify,Fact/Evidence",Fact/Evidence
438,124-ARR,124-ARR_v2_75@7,124-ARR_v1_79@6,"RoBERTabase is the best performing model, therefore we use this model to predict review sentence labels.","RoBERTabase is the best performing model, therefore we use this model for review sentence label prediction.","Modify,Clarity",Clarity
439,124-ARR,124-ARR_v2_76@0,124-ARR_v1_80@0,"Besides the baselines of ""Source Generic"" and ""Target Generic"", we explore subsets of papers with high scores (average reviewers' rating ⩾ 7) or low scores (average reviewers' rating ⩽ 3) to obtain 4 generic baselines: ""Source High Score"", ""Source Low Score"", ""Target High Score"", ""Target Low Score"".","Besides the baselines of ""Source Generic"" and ""Target Generic"", we explore subsets of papers with high scores (average reviewers' rating 7) or low scores (average reviewers' rating 3) to obtain 4 additional generic baselines: ""Source High Score"", ""Source Low Score"", ""Target High Score"", ""Target Low Score"".","Modify,Fact/Evidence",Fact/Evidence
440,124-ARR,124-ARR_v2_77@0,124-ARR_v1_80@1,"We use ""Target High Score"" as an example to explain how we obtain the generic sentences: From the training subset of high score papers, We first separate all meta-review sentences into the corresponding label categories, obtaining a total of 9 groups of sentences.","We use ""Target Generic"" as an example to explain how we obtain the generic sentences: We first group all meta-review sentences from the training set according to their label categories, and then re-arrange the sentences in each category using TextRank (our best performing extractive model).","Split+Modify,Fact/Evidence",Fact/Evidence
441,124-ARR,124-ARR_v2_77@1,124-ARR_v1_80@1,"Then, we re-arrange the sentences in each group using TextRank (our best extractive model).","We use ""Target Generic"" as an example to explain how we obtain the generic sentences: We first group all meta-review sentences from the training set according to their label categories, and then re-arrange the sentences in each category using TextRank (our best performing extractive model).","Split+Modify,Clarity",Clarity
442,124-ARR,124-ARR_v2_79@0,124-ARR_v1_80@3,"All generic sentence baselines can be obtained in a similarly procedure as outlined above, and we show results in Table 15.","Similarly, different sets of generic sentences can be obtained for the other 5 baselines.","Merge+Modify,Fact/Evidence",Fact/Evidence
443,124-ARR,124-ARR_v2_78@0,124-ARR_v1_81@0,"After obtaining the generic sentence sets, we can create baseline generations using the sent-ctrl sequence on the corresponding high score paper test data.","After obtaining the generic sentence sets, we can create baseline generations using the sent-ctrl sequence.","Modify,Fact/Evidence",Fact/Evidence
444,124-ARR,124-ARR_v2_79@0,124-ARR_v1_82@0,"All generic sentence baselines can be obtained in a similarly procedure as outlined above, and we show results in Table 15.",We show results in Table 15.,"Merge+Modify,Clarity",Clarity
445,124-ARR,124-ARR_v2_79@1,124-ARR_v1_82@1,"Both ""Target High Score"" and ""Target Low Score"" perform much better than the ""Target Genric"" baseline, suggesting that papers with very high or low scores tend to have more typical patterns in their meta-reviews.","The low score baselines perform the best amongst both source and target baselines, suggesting that the sentences from low score submissions are more typical for both reviews and meta-reviews.","Modify,Claim",Claim
446,124-ARR,124-ARR_v2_41@0,124-ARR_v1_85@0,"For bart-large-cnn, we first load the pretrained model and then fine-tune it on MReD. All experiments are conducted on single V100 GPUs, using a batch size of 1 in order to fit the large pretrained model on a single GPU.","For the Transformers, we first load the pretrained model and then fine-tune it on MReD. All experiments are conducted on single V100 GPUs, using a batch size of 1 in order to fit the large pretrained model on a single GPU.","Modify,Fact/Evidence",Fact/Evidence
447,124-ARR,124-ARR_v2_41@1,124-ARR_v1_85@1,"During fine-tuning, we set the hyperparameters of ""minimum_target_length"" to 20, and ""maximum_target_length"" to 400, according to our filter range on the meta-review lengths.","During finetuning, we set the Transformers' hyperparameters of ""minimum_target_length"" to 20, and ""maxi-mum_target_length"" to 400, according to our filter range on the meta-review lengths.","Modify,Clarity",Clarity
448,124-ARR,124-ARR_v2_80@1,124-ARR_v1_86@1,We further investigate the performance of different source truncation lengths under the setting of rate-concat.,We further investigate the performance of different source truncation lengths using rate-concat.,"Modify,Clarity",Clarity
449,124-ARR,124-ARR_v2_82@1,124-ARR_v1_88@1,"We use max-pooling to aggregate attention for same-sentence input tokens, because summation unfairly gives high attention scores to excessively long sentences due to attention weight accumulation, whereas average-pooling disfavors long sentences containing a few relevant phrases by averaging the weights out.","We use max-pooling to aggregate attention for same-sentence input tokens, because summation gives high attention scores to excessively long sentences due to attention weight accumulation, whereas average-pooling disfavors long sentences containing a few relevant phrases by averaging the weights out.","Modify,Other",Other
450,124-ARR,124-ARR_v2_84@1,124-ARR_v1_91@1,"We then calculate the normalized token-level edit distance between the judge-annotated label sequence and the given control sequence, where each label is considered as a single token, and finally deduct this value from 1.","We then calculate the normalized token-level edit distance between the judge-annotated label sequence and the given control sequence, then deduct this value from 1.","Modify,Fact/Evidence",Fact/Evidence
451,124-ARR,124-ARR_v2_85@1,124-ARR_v1_92@1,"More specifically, we give 0 if the generation produces either contradictory decisions or a wrong decision, or if the generation does not show enough hints for rejection or acceptance.","More specifically, we give 0 if the generation produces contradictory decisions and a wrong decision, or the generation does not show enough hints for rejection or acceptance.","Modify,Grammar",Grammar
452,124-ARR,124-ARR_v2_8@2,124-ARR_v1_6@2,"Thus from the same input text, the trained generator can generate varied outputs according to the given control signals.","Thus from the same input text, the trained generator can generate varied outputs according to the given control signal.","Modify,Grammar",Grammar
453,124-ARR,124-ARR_v2_2@2,124-ARR_v1_2@2,"A more useful text generator should leverage both the input text and the control signal to guide the generation, which can only be built with a deep understanding of the domain knowledge.","A more useful text generator should leverage both the input text and the control signal to guide the generation, which can only be built with deep understanding of the domain knowledge.","Modify,Grammar",Grammar
454,124-ARR,124-ARR_v2_8@9,124-ARR_v1_6@9,"Our MReD is obviously different from the previous text generation/summarization datasets because, given the rich annotations of individual meta-review sentences, a model is allowed to learn more sophisticated generation behaviors to control the structure of the generated passage.","Our MReD is obviously different from previous text generation/summarization datasets because, given the rich annotations of individual meta-review sentences, a model is allowed to learn more sophisticated generation behaviors to control the structure of the generated passage.","Modify,Grammar",Grammar
455,124-ARR,124-ARR_v2_8@10,124-ARR_v1_6@10,"Our proposed task is also noticeably different from the existing controllable text generation tasks (e.g., text style transfer on sentiment polarity (Shen et al., 2017;Liao et al., 2018) and formality (Shang et al., 2019)) because we focus on controlling the macro structure of the whole passage, rather than the wordings.","Our proposed task is also noticeably different from existing controllable text generation tasks (e.g., text style transfer on sentiment polarity (Shen et al., 2017;Liao et al., 2018) and formality (Shang et al., 2019)) because we focus on controlling the macro structure of the whole passage, rather than the wordings.","Modify,Grammar",Grammar
456,124-ARR,124-ARR_v2_14@1,124-ARR_v1_11@1,"Unlike the previous datasets that mainly focus on domains like news, the domain for meta-reviews is worth-studying because it contains essential and high-density opinions.","Unlike previous datasets that mainly focus on domains like news, meta-review is a worthstudying domain containing essential and highdensity opinions.","Modify,Clarity",Clarity
457,124-ARR,124-ARR_v2_16@0,124-ARR_v1_13@0,"We collect the meta-review related data of ICLR from an online peer-reviewing platform, i.e., Open-Review 2 from 2018 to 2021.",We collect the meta-review related data from an online peer reviewing platform for ICLR 2 from 2018 to 2021.,"Modify,Fact/Evidence",Fact/Evidence
458,124-ARR,124-ARR_v2_16@2,124-ARR_v1_13@2,"To prepare our dataset for controllable text generation, for each submission, we collect all of its corresponding official reviews with reviewer ratings and confidence scores, the final meta-review decision, and the meta-review passage.","To prepare our dataset for controllable text generation, for each submission, we collect multiple reviews with reviewer ratings and confidence scores, the final meta-review decision, and the meta-review passage.","Modify,Fact/Evidence",Fact/Evidence
459,125-ARR,,125-ARR_v1_25@0,,"We want to point out one advantage of using generation-based models under the low-resource scenario compared to previous classification-based event extraction models -generation-based models do not require named entity annotations (Sha et al., 2018;Lin et al., 2020).","Delete,Fact/Evidence",Fact/Evidence
460,125-ARR,,125-ARR_v1_25@1,,"The pre-trained decoder inherently identifies reasonable entity spans, which makes generation-based models become a good choice when annotations are expensive.","Delete,Claim",Claim
461,125-ARR,,125-ARR_v1_48@1,,"In addition to the previously mentioned EE models: OneIE (Lin et al., 2020), BERT_QA (Du and Cardie, 2020), TANL (Paolini et al., 2021), and Text2Event (Lu et al., 2021), we also consider the following baselines focusing on the high-resource setting.","Delete,Fact/Evidence",Fact/Evidence
462,125-ARR,,125-ARR_v1_48@7,,"Therefore, the advantage of DEGREE over DEGREE(PIPE) becomes less obvious.","Delete,Claim",Claim
463,125-ARR,,125-ARR_v1_48@8,,This result justifies our hypothesis that DEGREE has better performance for the lowresource setting because of its ability to better capture dependencies.,"Delete,Claim",Claim
464,125-ARR,,125-ARR_v1_49@0,,Results for event argument extraction.,"Delete,Other",Other
465,125-ARR,,125-ARR_v1_49@1,,"In Table 3, we additionally study the performance for event argument extraction task, where the model makes argument predictions with the gold trigger provided.","Delete,Fact/Evidence",Fact/Evidence
466,125-ARR,,125-ARR_v1_49@2,,"Interestingly, DEGREE(EAE) achieves pretty strong performance and outperforms other baselines with a large margin.","Delete,Fact/Evidence",Fact/Evidence
467,125-ARR,,125-ARR_v1_49@3,,"Combining the results in Table 2, we hypothesize that event argument extraction is a more challenging task than event trigger detection and it requires more training examples to learn well.","Delete,Claim",Claim
468,125-ARR,,125-ARR_v1_49@4,,"Hence, our proposed model, which takes the advantage of using label semantics to better capture dependencies, achieves a new state-of-the-art for event argument extraction.","Delete,Claim",Claim
469,125-ARR,,125-ARR_v1_87@0,,Limitations.,"Delete,Other",Other
470,125-ARR,,125-ARR_v1_87@2,,We believe this assumption holds for most of common NLP tasks.,"Delete,Claim",Claim
471,125-ARR,,125-ARR_v1_87@3,,"However, for some specific domains, such as the biomedical domain, acquiring this information can be a bit difficult (e.g., needs to hire experts to write down templates), which increases the cost of training DEGREE.","Delete,Claim",Claim
472,125-ARR,,125-ARR_v1_87@4,,"In addition, our proposed model is based on pre-trained language models.","Delete,Fact/Evidence",Fact/Evidence
473,125-ARR,,125-ARR_v1_87@5,,DEGREE performs well because it is able to leverage the prompts and the pre-trained knowledge.,"Delete,Claim",Claim
474,125-ARR,,125-ARR_v1_87@6,,"However, if the downstream domain is far from the pre-trained corpus, the advantage of leveraging knowledge becomes restricted.","Delete,Claim",Claim
475,125-ARR,,125-ARR_v1_87@8,,"DE-GREE achieves a good performance on two datasets (ACE 2005 and ERE-EN), which are more related to news-styled passages.","Delete,Claim",Claim
476,125-ARR,,125-ARR_v1_87@9,,"When considering other downstream domains, it is possible that the improvement is not as significant as it is for the two datasets we use in the paper.","Delete,Claim",Claim
477,125-ARR,,125-ARR_v1_87@10,,"The reason is the gap between the downstream domain knowledge and the pre-trained knowledge, as mentioned in the previous paragraph.","Delete,Claim",Claim
478,125-ARR,,125-ARR_v1_88@0,,Potential risks.,"Delete,Other",Other
479,125-ARR,125-ARR_v2_4@3,,"Fincke et al., 2021) usually divides EE into two subtasks: (1) event detection, which identifies event triggers and their types, and (2) event argument extraction, which extracts the arguments and their roles for given event triggers.",,"Add,Fact/Evidence",Fact/Evidence
480,125-ARR,125-ARR_v2_4@4,,"EE has been shown to benefit a wide range of applications, e.g., building knowledge graphs , question answering (Berant et al., 2014;, and other downstream studies (Han et al., 2019a;Hogenboom et al., 2016;.",,"Add,Fact/Evidence",Fact/Evidence
481,125-ARR,125-ARR_v2_12@9,,"For example, in our experiments, we take the information from the annotation guideline, which is provided along with the dataset.",,"Add,Fact/Evidence",Fact/Evidence
482,125-ARR,125-ARR_v2_16@0,,Our code and models can be found at https: //github.com/PlusLabNLP/DEGREE.,,"Add,Fact/Evidence",Fact/Evidence
483,125-ARR,125-ARR_v2_23@0,,We list three EAE templates in Table 1.,,"Add,Fact/Evidence",Fact/Evidence
484,125-ARR,125-ARR_v2_32@0,,Efficiency Considerations.,,"Add,Other",Other
485,125-ARR,125-ARR_v2_32@1,,"DEGREE requires to enumerate all event types during inference, which could cause efficiency considerations when extending to applications that contain many event types.",,"Add,Claim",Claim
486,125-ARR,125-ARR_v2_32@2,,"This issue is minor for our experiments on the two datasets (ACE 2005 and ERE-EN), which are relatively small scales in terms of the number of event types.",,"Add,Claim",Claim
487,125-ARR,125-ARR_v2_32@4,,We leave the work on benchmarking and improving the efficiency of DEGREE in the scenario considering more diverse and comprehensive types of events as future work.,,"Add,Claim",Claim
488,125-ARR,125-ARR_v2_46@1,,"We consider the following classification-based models: (1) OneIE , the current state-of-the-art (SOTA) EE model trained with designed global features.",,"Add,Fact/Evidence",Fact/Evidence
489,125-ARR,125-ARR_v2_46@2,,"( 2) BERT_QA (Du and Cardie, 2020), which views EE tasks as a sequence of extractive question answering problems.",,"Add,Fact/Evidence",Fact/Evidence
490,125-ARR,125-ARR_v2_46@3,,"Since it learns a classifier to indicate the position of the predicted span, we view it as a classification model.",,"Add,Fact/Evidence",Fact/Evidence
491,125-ARR,125-ARR_v2_46@4,,"We also consider the following generation-based models: (3) TANL (Paolini et al., 2021), which treats EE tasks as translation tasks between augmented natural languages.",,"Add,Fact/Evidence",Fact/Evidence
492,125-ARR,125-ARR_v2_52@0,,"Finally, we perform additional experiments on few-shot and zero-shot experiments.",,"Add,Fact/Evidence",Fact/Evidence
493,125-ARR,125-ARR_v2_52@1,,The results can be found in Appendix E.,,"Add,Fact/Evidence",Fact/Evidence
494,125-ARR,125-ARR_v2_65@4,,"The output sequence designs of TANL and Temp-Gen hinder the models from fully leveraging label semantics, unlike DEGREE that generates natural sentences.",,"Add,Claim",Claim
495,125-ARR,125-ARR_v2_70@1,,This assumption may holds for most situations.,,"Add,Claim",Claim
496,125-ARR,125-ARR_v2_70@2,,"We leave the automation of template construction for future work, which can further ease the needed efforts when deploying DEGREE in a large-scale corpus.",,"Add,Claim",Claim
497,125-ARR,125-ARR_v2_94@0,,"In order to further test our models' generaliability, we additionally conduct zero-shot and fewshot experiments on the ACE05-E dataset with DEGREE(ED) and DEGREE(EAE).",,"Add,Fact/Evidence",Fact/Evidence
498,125-ARR,125-ARR_v2_95@0,,Settings.,,"Add,Other",Other
499,125-ARR,125-ARR_v2_95@1,,"We first select the top n common event types as ""seen"" types and use the rest as ""unseen/rare"" types, where the top common types are listed in Table 12.",,"Add,Fact/Evidence",Fact/Evidence
500,125-ARR,125-ARR_v2_95@2,,"To simulate a zero-shot scenario, we remove all events with ""unseen/rare"" types from the training data.",,"Add,Fact/Evidence",Fact/Evidence
501,125-ARR,125-ARR_v2_95@3,,"To simulate a few-shot scenario, we keep only k event examples for each ""unseen/rare"" type (denoted as k-shot).",,"Add,Fact/Evidence",Fact/Evidence
502,125-ARR,125-ARR_v2_95@4,,"During the evaluation, we calculate micro F1-scores only for these ""unseen/rare"" types.",,"Add,Fact/Evidence",Fact/Evidence
503,125-ARR,125-ARR_v2_23@1,125-ARR_v1_20@0,The full list of EAE templates and the construction details can be found in Appendix A.,The full list of EAE templates and the constructing details can be found in Appendix A.,"Modify,Clarity",Clarity
504,125-ARR,125-ARR_v2_2@7,125-ARR_v1_2@7,"Moreover, DEGREE is capable of using additional weaklysupervised information, such as the description of events encoded in the prompts.","In addition, the proposed model is capable of using additional weakly-supervised information, such as the description of events.","Modify,Fact/Evidence",Fact/Evidence
505,125-ARR,125-ARR_v2_26@1,125-ARR_v1_22@1,"For the case that there are multiple triggers for the given event type in the input passage, DEGREE is trained to generate the output text that contains multiple E2E template such that each E2E template corresponds to one trigger and its argument roles.","For the case that there are multiple triggers for the given event type, DEGREE will generate the E2E template multiple times such that each E2E template corresponds to each trigger and its argument roles.","Modify,Fact/Evidence",Fact/Evidence
506,125-ARR,125-ARR_v2_28@1,125-ARR_v1_23@2,"After we obtain the generated sentences, we compare the outputs with E2E template to determine the predicted triggers and arguments in string format.","Then, we compare the generated output with the placeholders in E2E template to determine the predicted trigger spans and predicted argument spans.","Modify,Fact/Evidence",Fact/Evidence
507,125-ARR,125-ARR_v2_28@2,125-ARR_v1_23@3,"Finally, we apply string matching to convert the predicted string to span offsets in the passage.","Finally, we apply string matching to convert the word spans to the offsets in the passage.","Modify,Fact/Evidence",Fact/Evidence
508,125-ARR,125-ARR_v2_28@3,125-ARR_v1_23@4,"If the predicted string appears in the passage multiple times, we choose all span offsets that match for trigger predictions and choose the one closest to the given trigger span for argument predictions.","If the predicted span appears in the passage multiple times, we choose all that match for trigger predictions and choose the one being closest to the given trigger span for argument predictions.","Modify,Clarity",Clarity
509,125-ARR,125-ARR_v2_2@8,125-ARR_v1_2@8,"Finally, DE-GREE learns triggers and arguments jointly in an end-to-end manner, which encourages the model to better utilize the shared knowledge and dependencies among them.","Finally, learning triggers and argument roles in an end-toend manner encourages the model to better utilize the shared knowledge and dependencies between them.","Modify,Clarity",Clarity
510,125-ARR,125-ARR_v2_30@6,125-ARR_v1_24@7,"For example, DEGREE knows the relationship between the role Attacker and the role Target (who is attacking and who is attacked) due to E2E template.","For example, DEGREE knows the relation between the role Attacker and the role Target (who is attacking and who is attacked) because of the word ""attacked"" in E2E template.","Modify,Fact/Evidence",Fact/Evidence
511,125-ARR,125-ARR_v2_30@7,125-ARR_v1_24@8,This guidance helps DEGREE learn the dependencies between entities.,This guidance makes DEGREE learn the dependencies between entities well with less training data.,"Modify,Claim",Claim
512,125-ARR,125-ARR_v2_30@9,125-ARR_v1_24@10,This not only uses label semantics better but also makes the model easier to leverage the knowledge from the pre-trained decoder.,This not only utilizes label semantics better but also makes the model easier to leverage the knowledge from the pre-trained decoder.,"Modify,Clarity",Clarity
513,125-ARR,125-ARR_v2_2@9,125-ARR_v1_2@9,Our experimental results demonstrate the strong performance of DEGREE for low-resource event extraction.,Our experimental results and ablation studies demonstrate the strong performance of DEGREE for low-resource event extraction.,"Modify,Fact/Evidence",Fact/Evidence
514,125-ARR,125-ARR_v2_31@4,125-ARR_v1_26@4,"In fact, several prior works Du and Cardie, 2020;) also use constructed templates as weakly-supervised signals to improve models.","In fact, several prior works Du and Cardie, 2020;Li et al., 2020) also use constructed templates as weakly-supervised signals to improve models.","Modify,Fact/Evidence",Fact/Evidence
515,125-ARR,125-ARR_v2_2@0,125-ARR_v1_2@0,"Event extraction requires high-quality expert human annotations, which are usually expensive.","Due to the high cost of human annotations, learning a data-efficient event extraction model that can be trained with only a few labeled examples has become a crucial challenge.","Split+Modify,Claim",Claim
516,125-ARR,125-ARR_v2_2@1,125-ARR_v1_2@0,"Therefore, learning a data-efficient event extraction model that can be trained with only a few labeled examples has become a crucial challenge.","Due to the high cost of human annotations, learning a data-efficient event extraction model that can be trained with only a few labeled examples has become a crucial challenge.","Split+Modify,Clarity",Clarity
517,125-ARR,125-ARR_v2_4@0,125-ARR_v1_4@0,"Event extraction (EE) aims to extract events, each of which consists of a trigger and several participants (arguments) with their specific roles, from a given passage.","Event extraction (EE) aims to extract different types of events, each of which includes a trigger and several participants (arguments) with specific roles, from the given passage.","Modify,Clarity",Clarity
518,125-ARR,125-ARR_v2_44@1,125-ARR_v1_39@1,"We generate different proportions (1%, 2%, 3%, 5%, 10%, 20%, 30%, and 50%) of training data to study the influence of the size of the training set and use the original development set and test set for evaluation.","We generate different proportions (1%, 2%, 3%, 5%, 10%, 20%, 30%, and 50%) of training data to study the influence of the size of training set and use the original dev set and test set for evaluation.","Modify,Clarity",Clarity
519,125-ARR,125-ARR_v2_44@2,125-ARR_v1_39@2,Appendix C lists more details about the split generation process and the data statistics.,Appendix C lists more details about the split generating process and the data statistics.,"Modify,Clarity",Clarity
520,125-ARR,125-ARR_v2_46@6,125-ARR_v1_40@4,Note that the outputs of both generation-based baselines are not natural sentences.,Notice that the outputs of both generation-based baselines are not natural sentences.,"Modify,Clarity",Clarity
521,125-ARR,125-ARR_v2_4@1,125-ARR_v1_4@1,"For example, in Figure 1, a Justice:Execute event is triggered by the word ""execution"" and this event contains three argument roles, including an Agent (Indonesia) who carries out the execution, a Person who is executed (convicts), and a Place where the event occurs (not mentioned in the passage).","For example, in Figure 1, a Justice:Execute event is triggered by the word ""execution"" and this event contains three argument roles, including an Agent (Indonesia) who carries out the execution, a Person been executed (convicts), and a Place where the event occurs (not mentioned in the passage).","Modify,Grammar",Grammar
522,125-ARR,125-ARR_v2_48@0,125-ARR_v1_42@0,Table 2 shows the trigger classification F1-scores and the argument classification F1-scores in three data sets with different proportions of training data.,Table 1 shows the trigger classification F1-scores and the argument classification F1-scores across three datasets with different proportions of training data.,"Modify,Grammar",Grammar
523,125-ARR,125-ARR_v2_49@2,125-ARR_v1_43@2,"For example, when only 1% of the training data is available, DEGREE and DEGREE(PIPE) achieve more than 15 points of improvement in trigger classification F1 scores and more than 5 points in argument classification F1 scores.","For example, when only 1% of training data is available, DEGREE and DEGREE(PIPE) achieve more than 15 points of trigger classification F1scores improvement and more than 5 points of argument classification F1-scores.","Modify,Clarity",Clarity
524,125-ARR,125-ARR_v2_49@4,125-ARR_v1_43@4,"The generation-based model with carefully designed prompts is able to utilize the label semantics and the additional weakly supervised signals, thus helping learning under the low-resource regime.","The generationbased model with carefully designed prompts is able to utilize the label semantics and the additional weakly-supervised signals, thus, helps the learning under the low-resource regime.","Modify,Grammar",Grammar
525,125-ARR,125-ARR_v2_50@0,125-ARR_v1_44@0,Another interesting finding is that DEGREE and DEGREE(PIPE) seem to be more beneficial for predicting arguments than for predicting triggers.,Another interesting finding is that DEGREE and DEGREE(PIPE) seem to be more beneficial to argument prediction than trigger prediction.,"Modify,Clarity",Clarity
526,125-ARR,125-ARR_v2_50@1,125-ARR_v1_44@1,"For example, OneIE, the strongest baseline, requires 20% of training data to achieve competitive performance on trigger prediction to DEGREE and DEGREE(PIPE); however, it requires about 50% of training data to achieve competitive performance in predicting arguments.","For instance, OneIE, the strongest baseline, requires 20% of training data to achieve competitive performance on trigger prediction to DEGREE and DEGREE(PIPE); however, it requires about 50% of training data to achieve competitive performance on argument prediction.","Modify,Clarity",Clarity
527,125-ARR,125-ARR_v2_51@0,125-ARR_v1_45@0,"Furthermore, we observe that DEGREE is slightly better than DEGREE(PIPE) under the lowresource setting.","Finally, we observe that DEGREE is slightly better than DEGREE(PIPE) under the low-resource setting.","Modify,Clarity",Clarity
528,125-ARR,125-ARR_v2_51@1,125-ARR_v1_45@1,This provides empirical evidence on the benefit of jointly predicting triggers and arguments in a low-resource setting.,We hypothesize that DEGREE jointly predicts triggers and arguments and therefore can better take advantage of the output dependencies.,"Modify,Claim",Claim
529,125-ARR,125-ARR_v2_54@0,125-ARR_v1_47@0,"Although we focus on data-efficient learning for low-resource event extraction, to better understand the advantages and disadvantages of our model, we additionally study DEGREE in the high-resource setting for controlled comparisons.","While we focus on data-efficient learning for lowresource event extraction, to better understand the advantages and disadvantages of our model and make sure that it is indeed more data-efficient, rather than simply a stronger model, we additionally study DEGREE in the high-resource setting for controlled comparisons.","Modify,Fact/Evidence",Fact/Evidence
530,125-ARR,125-ARR_v2_56@0,125-ARR_v1_50@0,Ablation Studies,Ablation Study,"Modify,Grammar",Grammar
531,125-ARR,125-ARR_v2_5@0,125-ARR_v1_5@0,"Most prior works on EE rely on a large amount of annotated data for training (Nguyen and Grishman, 2015;Nguyen et al., 2016;Han et al., 2019b;Du and Cardie, 2020;Paolini et al., 2021).","Several previous EE approaches rely on a large amount of annotated data for training (Nguyen and Grishman, 2015;Nguyen et al., 2016;Du and Cardie, 2020;Paolini et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
532,125-ARR,125-ARR_v2_5@1,125-ARR_v1_5@1,"However, high-quality event annotations are expensive to obtain.","However, these high-quality event annotations are expensive to be obtained.","Modify,Clarity",Clarity
533,125-ARR,125-ARR_v2_5@2,125-ARR_v1_5@2,"For example, the ACE 2005 corpus (Doddington et al., 2004), one of the most widely used EE datasets, requires two rounds of annotations by linguistics experts.","For example, the ACE 2005 corpus (Doddington et al., 2004), one of the most common EE datasets, requires two rounds of annotations by linguistics experts.","Modify,Clarity",Clarity
534,125-ARR,125-ARR_v2_65@2,125-ARR_v1_59@6,Their predicted target-augmented language embed labels into the input passage via using brackets and vertical bar symbols.,"Their predicted targetaugmented language embed labels into the input passage via using brackets and vertical bar symbols, hindering the model from fully leveraging label semantics.","Modify,Claim",Claim
535,125-ARR,125-ARR_v2_65@6,125-ARR_v1_59@8,"They solve event extraction with a pipeline, which prevents knowledge sharing across subtasks.","Yet, similar to TANL, they solve event extraction with a pipeline, which prevents knowledge sharing across subtasks.","Modify,Fact/Evidence",Fact/Evidence
536,125-ARR,125-ARR_v2_66@1,125-ARR_v1_60@1,It has been a growing interest in event extraction in a scenario with less data.,It has been a rising interest in event extraction under less data scenario.,"Modify,Clarity",Clarity
537,125-ARR,125-ARR_v2_68@0,125-ARR_v1_62@0,Conclusion & Future Work,Conclusion,"Modify,Other",Other
538,125-ARR,125-ARR_v2_5@4,125-ARR_v1_5@4,"Therefore, how to learn a data-efficient EE model trained with only a few annotated examples is a crucial challenge.","Therefore, how to learn a data-efficient EE model trained with only a few annotated examples is a crucial research question.","Modify,Clarity",Clarity
539,125-ARR,125-ARR_v2_6@0,125-ARR_v1_6@0,"In this paper, we focus on low-resource event extraction, where only a small amount of training examples are available for training.","In this paper, we focus on low-resource event extraction, where only a small amount of training examples are available during training.","Modify,Clarity",Clarity
540,125-ARR,125-ARR_v2_2@2,125-ARR_v1_2@1,"In this paper, we focus on low-resource end-to-end event extraction and propose DE-GREE, a data-efficient model that formulates event extraction as a conditional generation problem.","In this paper, we focus on low-resource end-toend event extraction.","Merge+Modify,Grammar",Grammar
541,125-ARR,125-ARR_v2_12@2,125-ARR_v1_6@3,DEGREE enjoys the following advantages to learn well with less training data.,DEGREE enjoys the following three advantages to learn well with less training data.,"Modify,Fact/Evidence",Fact/Evidence
542,125-ARR,125-ARR_v2_95@6,125-ARR_v1_83@4,"We consider the following baselines: (1) BERT_QA (Du and Cardie, 2020) (2) OneIE (3) Matching baseline, a proposed baseline that makes trigger predictions by performing string matching between the input passage and the event keywords.","We consider the following baselines: (1) BERT_QA (Du and Cardie, 2020) (2) OneIE (Lin et al., 2020) (3) Matching baseline, a proposed baseline that makes trigger predictions by performing string matching between the input passage and the event keywords.","Modify,Fact/Evidence",Fact/Evidence
543,125-ARR,125-ARR_v2_70@0,125-ARR_v1_87@1,"DEGREE assumes that some weakly-supervised information (the description of events, similar keywords, and human-written templates) is accessible or not expensive for the users to craft.","DEGREE assumes that some weakly-supervised information (the description of events, similar keywords, and human-written templates) is accessible and not expensive.","Modify,Claim",Claim
544,125-ARR,125-ARR_v2_71@0,125-ARR_v1_88@1,"DEGREE fine-tunes the pre-trained generative language model (Lewis et al., 2020).","DEGREE fine-tunes the pretrained generative language (Lewis et al., 2020).","Modify,Clarity",Clarity
545,125-ARR,125-ARR_v2_10@2,125-ARR_v1_10@2,"The input of DEGREE consists of the given passage and our design prompt that contains an event type description, event keywords, and a E2E template.","The input of DEGREE consists of the given passage and our design prompt that contains a event type description, some event keywords, and a E2E template.","Modify,Grammar",Grammar
546,125-ARR,125-ARR_v2_2@2,125-ARR_v1_2@2,"In this paper, we focus on low-resource end-to-end event extraction and propose DE-GREE, a data-efficient model that formulates event extraction as a conditional generation problem.","We propose DEGREE, a model that formulates event extraction as a conditional generation problem.","Merge+Modify,Claim",Claim
547,125-ARR,125-ARR_v2_12@5,125-ARR_v1_12@2,"In addition, the sentence structure of the template and the word ""attacked"" depict the semantic relation between the role Attacker and the role Target.","Also, the word ""attacked"" in the prompt depicts the relationship between the role Attacker and the role Target.","Modify,Claim",Claim
548,125-ARR,125-ARR_v2_12@6,125-ARR_v1_12@3,"With these kinds of guidance, DEGREE can make more accurate predictions with less training examples.","With these kinds of guidance, DEGREE can make accurate predictions without many training examples.","Modify,Clarity",Clarity
549,125-ARR,125-ARR_v2_12@7,125-ARR_v1_12@4,"Second, the prompts can incorporate additional weaksupervision signal about the task, such as the description of the event and similar keywords.","Second, the prompts can be further extended to include additional weakly-supervised information about the task, such as the description of the event and similar keywords.","Modify,Clarity",Clarity
550,125-ARR,125-ARR_v2_2@3,125-ARR_v1_2@3,"Given a passage and a manually designed prompt, DEGREE learns to summarize the events mentioned in the passage into a natural sentence that follows a predefined pattern.","Given a passage and a manually designed prompt, DEGREE learns to summarize the event happening in the passage into a natural sentence that follows a predefined pattern.","Modify,Clarity",Clarity
551,125-ARR,125-ARR_v2_12@10,125-ARR_v1_12@5,This information facilitates DEGREE to learn under a low-resource situation.,1 This information facilitates DEGREE to learn under the low-resource situation.,"Modify,Grammar",Grammar
552,125-ARR,125-ARR_v2_12@12,125-ARR_v1_12@7,Leveraging the shared knowledge and dependencies between the two tasks makes our model more data-efficient.,Utilizing the shared knowledge and dependencies between the two tasks makes DEGREE more dataefficient.,"Modify,Clarity",Clarity
553,125-ARR,125-ARR_v2_13@0,125-ARR_v1_13@0,Existing works on EE usually have only one or two of above-mentioned advantages.,Prior approaches on EE usually have only one or two above-mentioned advantages.,"Modify,Clarity",Clarity
554,125-ARR,125-ARR_v2_13@3,125-ARR_v1_13@3,"As a result, our model DEGREE can achieve significantly better performance than prior approaches on low-resource event extraction, as we will demonstrate in Section 3.","As a result, DEGREE can achieve significantly better performance than prior approaches on low-resource event extraction, as we will demonstrate in Section 3.","Modify,Clarity",Clarity
555,125-ARR,125-ARR_v2_2@4,125-ARR_v1_2@4,The final event predictions are then extracted from the generated sentence with a deterministic algorithm.,The final event structure predictions are then extracted from the generated sentence with a deterministic algorithm.,"Modify,Clarity",Clarity
556,125-ARR,125-ARR_v2_18@1,125-ARR_v1_16@1,"Unlike previous works , which separate event extraction into two pipelined tasks (event detection and event argument extraction), DEGREE is designed for the end-to-end event extraction and predict event triggers and arguments at the same time.","Unlike previous works (Wadden et al., 2019;Lin et al., 2020), which separate event extraction into two pipelined tasks (event detection and event argument extraction), DEGREE is designed for the end-to-end event extraction and makes trigger predictions and argument predictions at the same time.","Modify,Fact/Evidence",Fact/Evidence
557,125-ARR,125-ARR_v2_19@0,125-ARR_v1_17@0,The DEGREE Model,DEGREE,"Modify,Other",Other
558,125-ARR,125-ARR_v2_20@4,125-ARR_v1_18@4,"By designing appropriate prompts, we encourage DEGREE to better capture the dependencies between entities and, therefore, to reduce the number of training examples needed.","By designing appropriate prompts, we encourage DEGREE to better capture the dependencies between entities and therefore reduce the number of needed training examples.","Modify,Grammar",Grammar
559,125-ARR,125-ARR_v2_2@5,125-ARR_v1_2@5,DEGREE has three advantages to learn well with less training data.,DEGREE has the following advantages to learn well with less training data.,"Modify,Fact/Evidence",Fact/Evidence
560,125-ARR,125-ARR_v2_2@6,125-ARR_v1_2@6,"First, our designed prompts provide semantic guidance for DEGREE to leverage label semantics and thus better capture the event arguments.","First, with our design of prompts, DEGREE obtains semantic guidance by leveraging label semantics and thus better captures the argument roles.","Modify,Clarity",Clarity
642,13-ARR,,13-ARR_v1_19@6,,We denote the O mask as the mask for an object 1.,"Delete,Fact/Evidence",Fact/Evidence
643,13-ARR,,13-ARR_v1_20@0,,"We first sample the trajectories in the Matterport (Chang et al., 2017) Environment.","Delete,Fact/Evidence",Fact/Evidence
644,13-ARR,,13-ARR_v1_20@1,,"We randomly sample the starting and ending positions, and collect tracks with lengths of less than 8 hops.","Delete,Fact/Evidence",Fact/Evidence
645,13-ARR,,13-ARR_v1_20@2,,Then we obtain the corresponding actions of each trajectory by firstperson movement.,"Delete,Fact/Evidence",Fact/Evidence
646,13-ARR,,13-ARR_v1_20@3,,"If the agent chooses the front navigable position to move, we generate a 'forward' action.","Delete,Fact/Evidence",Fact/Evidence
647,13-ARR,,13-ARR_v1_20@4,,"If the agent chooses the back navigable position to move, we generate an 'around' action.","Delete,Fact/Evidence",Fact/Evidence
648,13-ARR,,13-ARR_v1_20@5,,"Otherwise, if the agent selects the right front navigable position to move for the next step, we generate an action sequence like {'right', 'forward'}, which is used to fill actionable verbs during instruction generation.","Delete,Fact/Evidence",Fact/Evidence
649,13-ARR,,13-ARR_v1_21@1,,"ProbES introduces CLIP, a powerful vision-language alignment model learned from a large-scale image-caption dataset.","Delete,Fact/Evidence",Fact/Evidence
650,13-ARR,,13-ARR_v1_22@0,,"To generate structured augmentation data, we fullfill the templates with phrases that describe the sampled trajectory and actions.","Delete,Fact/Evidence",Fact/Evidence
651,13-ARR,,13-ARR_v1_22@1,,"A trajectory is denoted as {v 1 , v 2 , ..., v n }, where v i represents an observation viewpoint.","Delete,Fact/Evidence",Fact/Evidence
652,13-ARR,13-ARR_v2_25@5,,"For the vision stream, since the trajectory is represented as a sequence of panoramic image regions, which is different from VLMs pretrained on image-caption pairs, we also update the visual embedding during prompt tuning.",,"Add,Fact/Evidence",Fact/Evidence
653,13-ARR,13-ARR_v2_25@6,,The visual embedding contains image embedding and location embedding.,,"Add,Fact/Evidence",Fact/Evidence
654,13-ARR,13-ARR_v2_33@1,,"Rec indicates using Recurrent VLN-Bert (Hong et al., 2021) with different backbones or parameter initialization.",,"Add,Fact/Evidence",Fact/Evidence
655,13-ARR,13-ARR_v2_38@2,,"Our model outperforms the model fine-tuned on R2R dataset by 1.1% in unseen split, indicating that ProbES improves the generalization ability of the navigation model.",,"Add,Claim",Claim
656,13-ARR,13-ARR_v2_38@4,,"Table 6 introduces comprehensive ablation experiments showing the impact of key steps in the strategy of generating instructions, and the experiments are performed in the baseline model: IL+RL from En-vDrop .",,"Add,Fact/Evidence",Fact/Evidence
657,13-ARR,13-ARR_v2_38@5,,Class indicates classes we use to feed into CLIP.,,"Add,Fact/Evidence",Fact/Evidence
658,13-ARR,13-ARR_v2_38@6,,M and P/O represent classes from Matterport and Place365/Objects365 datasets respectively.,,"Add,Fact/Evidence",Fact/Evidence
659,13-ARR,13-ARR_v2_38@7,,G T emplate denotes the strategy used to generate templates. 'ours' denote the strategy shown in Sec 3.2.,,"Add,Fact/Evidence",Fact/Evidence
660,13-ARR,13-ARR_v2_38@8,,"For S T emplate , 'random' and 'match' indicate sampling a template randomly and choosing a template with the same number of masks as the number of viewpoints.",,"Add,Fact/Evidence",Fact/Evidence
661,13-ARR,13-ARR_v2_2@5,13-ARR_v1_2@5,"Unlike the conventional approach of fine-tuning, we introduce prompt-based learning to achieve fast adaptation for language embeddings, which substantially improves the learning efficiency by leveraging prior knowledge.","Unlike the conventional approach of fine-tuning, we introduce prompt tuning to achieve fast adaptation for language embeddings, which substantially improves the learning efficiency by leveraging prior knowledge.","Modify,Clarity",Clarity
662,13-ARR,13-ARR_v2_2@6,13-ARR_v1_2@6,"By automatically synthesizing trajectoryinstruction pairs in any environment without human supervision and efficient prompt-based learning, our model can adapt to diverse visionlanguage navigation tasks, including VLN and REVERIE.","By automatically synthesizing trajectoryinstruction pairs in any environment without human supervision and instruction prompt tuning, our model can adapt to diverse visionlanguage navigation tasks, including VLN and REVERIE.","Modify,Claim",Claim
663,13-ARR,13-ARR_v2_2@7,13-ARR_v1_2@7,Both qualitative and quantitative results show that our ProbES significantly improves the generalization ability of the navigation model * .,Both qualitative and quantitative results show that our ProbES significantly improves the generalization ability of the navigation model.,"Modify,Grammar",Grammar
664,13-ARR,13-ARR_v2_25@4,13-ARR_v1_26@4,"Then in the prompt tuning process, we only train E p and fix the parameters of E x for the language stream.","Then in the prompt tuning process, we only train E p and fix the parameters of E x .","Modify,Fact/Evidence",Fact/Evidence
665,13-ARR,13-ARR_v2_26@0,13-ARR_v1_26@5,"We sample hard negative paths based on distance in the environment for an instruction-trajectory pair, and the model is trained to choose the best path among them.","Similar to VLN-Bert (Devlin et al., 2018), we sample 3 hard negative paths using beam search for an instruction-trajectory pair, and the model is trained to choose the best path among them.","Modify,Fact/Evidence",Fact/Evidence
666,13-ARR,13-ARR_v2_30@0,13-ARR_v1_31@0,"We experiment with our proposed ProbES on two downstream tasks: goal-oriented navigation task (R2R (Anderson et al., 2018)), and objectoriented navigation task (REVERIE ).","We experiment with our proposed ProbES on two downstream tasks: goal-oriented navigation task (R2R ), and objectoriented navigation task (REVERIE ).","Modify,Fact/Evidence",Fact/Evidence
667,13-ARR,13-ARR_v2_4@2,13-ARR_v1_4@2,"The vision-language navigation (VLN) task (Anderson et al., 2018) is proposed where an agent is required to navigate in a photo-realistic environment stepby-step following a natural language instruction.",The vision-language navigation (VLN) task is proposed where an agent is required to navigate in a photo-realistic environment stepby-step following a natural language instruction.,"Modify,Fact/Evidence",Fact/Evidence
668,13-ARR,13-ARR_v2_33@0,13-ARR_v1_34@0,"We compare ProbES with previous state-of-the-art methods on the R2R dataset in the generative setting, which predicts actions sequentially, as shown in Table 2.","We compare ProbES with previous state-of-the-art methods on the R2R dataset in the generative setting, as shown in Table 2.","Modify,Fact/Evidence",Fact/Evidence
669,13-ARR,13-ARR_v2_34@0,13-ARR_v1_35@0,"We compare ProbES with VLN-BERT in the discriminative setting, which outputs scores for instruction-trajectory pairs, as in Table 4.",We compare ProbES with VLN-BERT in the discriminative setting as in Table 4.,"Modify,Fact/Evidence",Fact/Evidence
670,13-ARR,13-ARR_v2_4@3,13-ARR_v1_5@0,Recent tasks focus on target objects localization that asks an agent to identify an object in an unseen room.,"To solve a more practical problem, the REVERIE task focuses on target objects localization that asks an agent to identify an object in an unseen room.","Modify,Claim",Claim
671,13-ARR,13-ARR_v2_7@5,13-ARR_v1_7@12,"We evaluate ProbES on R2R (Anderson et al., 2018) and REVERIE datasets by discriminative and generative settings.",We evaluate ProbES on R2R and REVERIE datasets by discriminative and generative settings.,"Modify,Fact/Evidence",Fact/Evidence
672,13-ARR,13-ARR_v2_15@2,13-ARR_v1_12@2,"Inspired by BERT (Devlin et al., 2019), much work has extended it to process visual tokens and pretrain on large-scale image-text pairs for learning generic visio-linguistic representations.","Inspired by BERT (Devlin et al., 2018), much work has extended it to process visual tokens and pretrain on large-scale image-text pairs for learning generic visio-linguistic representations.","Modify,Fact/Evidence",Fact/Evidence
673,133-ARR,,133-ARR_v1_66@2,,We make the source code available upon acceptance of the paper.,"Delete,Fact/Evidence",Fact/Evidence
674,133-ARR,133-ARR_v2_22@0,,Models for Text Categorization,,"Add,Other",Other
675,133-ARR,133-ARR_v2_23@0,,"We formally introduce the three families of models for text categorization, namely the BoW-based, graph-based, and sequence-based models.",,"Add,Fact/Evidence",Fact/Evidence
676,133-ARR,133-ARR_v2_23@1,,"Table 1 summarizes the key properties of the approaches: whether they require a synthetic graph, whether word position is reflected in the model, whether the model can deal with arbitrary length text, and whether the model is capable of inductive learning.",,"Add,Fact/Evidence",Fact/Evidence
677,133-ARR,133-ARR_v2_24@0,,BoW-Based Text Categorization,,"Add,Other",Other
678,133-ARR,133-ARR_v2_25@0,,"Under pure BoW-based text categorization, we denote approaches that are not order-aware and operate only on the multiset of words from the input document.",,"Add,Fact/Evidence",Fact/Evidence
679,133-ARR,133-ARR_v2_72@0,,The focus of this work is text classification.,,"Add,Fact/Evidence",Fact/Evidence
680,133-ARR,133-ARR_v2_72@1,,Potential risks that apply to text classification in general also apply to this work.,,"Add,Claim",Claim
681,133-ARR,133-ARR_v2_72@2,,"Nonetheless, we present alternatives to commonly used pretrained language models, which suffer from various sources of bias due to the large and poorly manageable data used for pretraining (Bender et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
682,133-ARR,133-ARR_v2_72@3,,"In contrast, the presented alternatives render full control over the training data and, thus, contribute to circumvent the biases otherwise introduced during pretraining.",,"Add,Claim",Claim
683,133-ARR,133-ARR_v2_76@3,,"We further motivate the choice of using wide layers with results from multi-label text classification (Galke et al., 2017), which has shown that a (wide) MLP outperforms all tested classical baselines such as SVMs, k-Nearest Neighbors, and logistic regression.",,"Add,Fact/Evidence",Fact/Evidence
684,133-ARR,133-ARR_v2_76@4,,"Follow-up work (Mai et al., 2018) then found that also CNN and LSTM do not substantially improve over the wide MLP.",,"Add,Fact/Evidence",Fact/Evidence
685,133-ARR,133-ARR_v2_16@9,133-ARR_v1_16@9,"Semantic hyperedges for word-word connections are derived from topic models (Blei et al., 2001).","Semantic hyperedges for word-word connections are derived from topic models (Blei et al., 2003).","Modify,Fact/Evidence",Fact/Evidence
686,133-ARR,133-ARR_v2_2@5,133-ARR_v1_2@5,"Finally, since Transformers need to compute O(L 2 ) attention weights with sequence length L, the MLP models show higher training and inference speeds on datasets with long sequences.","Finally, since Transformers need to compute O(L 2 ) attention weights with L sequence length, the MLP models show higher training and inference speeds on datasets with long sequences.","Modify,Clarity",Clarity
687,133-ARR,133-ARR_v2_18@4,133-ARR_v1_18@3,"Also Text-RCNN (Lai et al., 2015), a model combining recurrence and convolution uses only the 4 major categories in the 20ng dataset.","Also Tex-tRCNN (Lai et al., 2015), a model combining recurrence and convolution uses only the 4 major categories in the 20ng dataset.","Modify,Grammar",Grammar
688,133-ARR,133-ARR_v2_18@5,133-ARR_v1_18@4,The results of Text-RCNN are identical with BLSTM-2DCNN.,The results of Text-RCNN is identical with BLSTM-2DCNN.,"Modify,Grammar",Grammar
689,133-ARR,133-ARR_v2_18@6,133-ARR_v1_18@5,"For the MR dataset, BLSTM-2DCNN provides no information on the specific split of the dataset.","For the MR dataset, BLSTM-2DCNN provides no information on the specific splitting of the dataset.","Modify,Grammar",Grammar
690,133-ARR,133-ARR_v2_19@0,133-ARR_v1_19@0,"Sequence models: Transformers Surprisingly, only few works consider Transformer models for text categorization.","Sequence models: Transformers Surprisingly, only few works consider Transformer models for topical text classification.","Modify,Clarity",Clarity
691,133-ARR,133-ARR_v2_20@3,133-ARR_v1_20@3,"TinyBERT (Jiao et al., 2020) and Mo-bileBERT (Sun et al., 2020) would be similarly suitable alternatives, among others.","TinyBERT (Jiao et al., 2020) and Mo-bileBERT would be similarly suitable alternatives, among others.","Modify,Fact/Evidence",Fact/Evidence
692,133-ARR,133-ARR_v2_4@1,133-ARR_v1_4@1,"Research on text categorization is a very active field as just the sheer amount of new methods in recent surveys shows (Bayer et al., 2021;Li et al., 2020;Zhou et al., 2020;Kowsari et al., 2019;Kadhim, 2019).","Research on text categorization is a very active field as just the sheer amount of new methods in recent surveys shows (Bayer et al., 2021;Zhou et al., 2020;Kowsari et al., 2019;Kadhim, 2019).","Modify,Fact/Evidence",Fact/Evidence
693,133-ARR,133-ARR_v2_26@0,133-ARR_v1_22@0,"As BoW-based model, we consider a one hidden layer WideMLP (i. e., two layers in total).","As BoW-based models, we consider a one hidden layer WideMLP (i. e., two layers in total).","Modify,Grammar",Grammar
694,133-ARR,133-ARR_v2_26@1,133-ARR_v1_22@1,"We experiment with pure BoW, TF-IDF weighted, and averaged GloVe input representations.","We further experiment with pure BoW, TF-IDF weighted, or averaged GloVe input representations and two hidden layers WideMLP-2.","Split+Modify,Clarity",Clarity
695,133-ARR,133-ARR_v2_26@2,133-ARR_v1_22@1,We also use a two hidden layers WideMLP-2.,"We further experiment with pure BoW, TF-IDF weighted, or averaged GloVe input representations and two hidden layers WideMLP-2.","Split+Modify,Clarity",Clarity
696,133-ARR,133-ARR_v2_26@3,133-ARR_v1_22@2,"We list the numbers for fastText, SWEM, and logistic regression from Ding et al. (2020) in our comparison.","We also list the numbers for fastText, SWEM, and logistic regression from Ding et al. (2020) in our comparison.","Modify,Clarity",Clarity
697,133-ARR,133-ARR_v2_28@1,133-ARR_v1_24@1,"For instance, in TextGCN the graph is set up in two parts: word-word connections are modeled by pointwise mutual information and word-document edges resemble that the word occurs in the document.","For instance, TextGCN the graph is set up in two parts: word-word connections modeled by pointwise mutual information and word-document edges resemble that the word occurs in the document.","Modify,Grammar",Grammar
698,133-ARR,133-ARR_v2_28@6,133-ARR_v1_24@6,A detailed discussion of the connection between TextGCN and MLP is provided in Appendix B.,A detailed discussion of the connection between TextGCN and MLP is provided in the Appendix B.,"Modify,Grammar",Grammar
699,133-ARR,133-ARR_v2_37@2,133-ARR_v1_33@2,"The mean sequence length is 551 words with a standard deviation (SD) of 2,047.","The mean sequence length is 551 words with a standard deviation of 2,047.","Modify,Clarity",Clarity
700,133-ARR,133-ARR_v2_5@1,133-ARR_v1_5@1,"Among them are Deep Averaging Networks (DAN) (Iyyer et al., 2015), a deep Multi-Layer Perceptron (MLP) model with n layers that relies on averaging the BoW, Simple Word Embedding Models (SWEM) (Shen et al., 2018) that explores different pooling strategies for pretrained word embeddings, and fastText (Bojanowski et al., 2017), which uses a linear layer on top of pretrained word embed-dings.","Among them are Deep Averaging Networks (DAN) (Iyyer et al., 2015), a deep Multi-Layer Perceptron (MLP) model with n layers that relies on averaging the BoW, Simple Word Embedding Models (SWEM) (Shen et al., 2018) that explores different pooling strategies for pretrained word embeddings, and fastText , which uses a linear layer on top of pretrained word embed-dings.","Modify,Fact/Evidence",Fact/Evidence
701,133-ARR,133-ARR_v2_43@7,133-ARR_v1_39@7,We use this augmentation strategy to increase the number of training examples by a factor of two (BERT w/ shuf. augm.).,We use this augmentation strategy to increase the number of training examples by a factor of two (BERT w/ shuffle augment).,"Modify,Clarity",Clarity
702,133-ARR,133-ARR_v2_6@1,133-ARR_v1_6@1,"Besides TextGCN, there are follow-up works like HeteGCN (Ragesh et al., 2021), TensorGCN (Liu et al., 2020), and HyperGAT (Ding et al., 2020), which we collectively call graph-based models.","Besides TextGCN, there are follow-up works like HeteGCN (Ragesh et al., 2021), TensorGCN , and HyperGAT (Ding et al., 2020), which we collectively call graph-based models.","Modify,Fact/Evidence",Fact/Evidence
703,133-ARR,133-ARR_v2_61@1,133-ARR_v1_57@1,"In such cases, the performance of graph neural networks is the state of the art (Kipf and Welling, 2017;Velickovic et al., 2018) and are superior to MLPs that use only the node features and not the graph structure (Shchur et al., 2018).","In such cases, the performance of graph neural networks is the state of the art (Kipf and Welling, 2017;Veličković et al., 2018) and are superior to MLPs that use only the node features and not the graph structure (Shchur et al., 2018).","Modify,Grammar",Grammar
704,133-ARR,133-ARR_v2_66@3,133-ARR_v1_62@3,"In computer vision, Tolstikhin et al. ( 2021) and Melas-Kyriazi (2021) proposed attention-free MLP models that are on par with the Vision Transformer .","In computer vision, Tolstikhin et al. (2021 and Melas-Kyriazi (2021) attentionfree MLP models are on par with the Vision Transformer (Dosovitskiy et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
705,133-ARR,133-ARR_v2_76@0,133-ARR_v1_70@0,"Depth vs. Width In text classification, width seems more important than depth.","Depth vs width In text classification, width seems more important than depth.","Modify,Grammar",Grammar
706,133-ARR,133-ARR_v2_78@0,133-ARR_v1_72@0,"In our experiments, we did not observe any improvement with more hidden layers (WideMLP-2), as suggested by Iyyer et al. (2015), but it might be beneficial for other, more challenging datasets.","In our experiments, we did not observe any improvement with more hidden layers (WideMLP-2), as suggested by Iyyer et al. (2015), but it might help for other, more challenging, datasets.","Modify,Clarity",Clarity
707,133-ARR,133-ARR_v2_81@1,133-ARR_v1_74@1,"A single layer Text-GCN is a BoW-MLP, except for the document embedding.","A single layer Text-GCN is a bow MLP, except for the document embedding.","Modify,Grammar",Grammar
708,133-ARR,133-ARR_v2_82@0,133-ARR_v1_75@0,The basic GCN equation H = σ( ÂXW ) reveals that the order of transformation and neighborhood aggregation is irrelevant.,The basic GCN equation reveals that the order of transformation and neighborhood aggregation is equivalent.,"Modify,Claim",Claim
709,133-ARR,133-ARR_v2_82@2,133-ARR_v1_75@2,"Truly new documents, as in inductive learning scenarios, would need a special treatment such as using an all zero embedding vector.",Truly new documents would need a special treatment such as using an all zero embedding vector.,"Modify,Clarity",Clarity
710,133-ARR,133-ARR_v2_83@1,133-ARR_v1_76@1,"On bag-of-words inputs, the first layer W (1) x + b (1) can be replaced by an equivalent embedding layer with weighting (e. g., TF-IDF or length normalization) being applied during aggregation of the embedding vectors.","The first layer can be replaced by an embedding layer such that H = XE, where X is the weighted term-document matrix.","Modify,Fact/Evidence",Fact/Evidence
711,133-ARR,133-ARR_v2_2@1,133-ARR_v1_2@1,We show that a wide multi-layer perceptron (MLP) using a Bag-of-Words (BoW) outperforms the recent graph-based models TextGCN and Hete-GCN in an inductive text classification setting and is comparable with HyperGAT.,"We show that a simple multi-layer perceptron (MLP) using a ""Bag of Words"" (BoW) outperforms the recent graph-based models TextGCN and Het-eGCN in an inductive text classification setting and is comparable with HyperGAT.","Modify,Clarity",Clarity
712,133-ARR,133-ARR_v2_88@2,133-ARR_v1_81@2,"Only with a second layer, TextGCN considers the embedding of other documents whose words are connected to the present documents' words.","Only with a second layer, TextGCN considers the embedding of other documents whose words are related to the present documents' words.","Modify,Clarity",Clarity
713,133-ARR,133-ARR_v2_12@6,133-ARR_v1_12@6,"We check whether modified versions of the datasets have been used (e. g., fewer classes), to avoid bias and wrongfully giving advantages.","We check whether modified versions of the datasets have been used (e. g., less classes), to avoid bias and wrongfully giving advantages.","Modify,Grammar",Grammar
714,133-ARR,133-ARR_v2_13@4,133-ARR_v1_13@4,"In fastText (Bojanowski et al., 2017;Joulin et al., 2017) a linear layer on top of pretrained embeddings is used for classification.",In fastText a linear layer on top of pretrained embeddings is used for classification.,"Modify,Fact/Evidence",Fact/Evidence
715,133-ARR,133-ARR_v2_16@1,133-ARR_v1_16@1,"Examples of GNN-based methods operating on a word-document co-occurence graph are TextGCN (Yao et al., 2019) and its successor TensorGCN (Liu et al., 2020) as well as Hete-GCN (Ragesh et al., 2021), HyperGAT (Ding et al., 2020), andDADGNN (Liu et al., 2020).","Examples of GNN-based methods operating on a word-document co-occurence graph are TextGCN (Yao et al., 2019) and its successor TensorGCN as well as Hete-GCN (Ragesh et al., 2021), HyperGAT (Ding et al., 2020), and DADGNN .","Modify,Fact/Evidence",Fact/Evidence
893,14-ARR,14-ARR_v2_25@0,,"• Grammatical error (Gram): Erroneous usage of past/current tense and mistakes in misplaced modifiers. • Event mismatch (Event): Stories that are offtopic, which present events that are not relevant to the image stream. • Object mismatch (Obj): Irrelevant nouns that do not appear in the images and are not semantically related.",,"Add,Fact/Evidence",Fact/Evidence
894,14-ARR,14-ARR_v2_69@5,,"• Stretch-VST (Hsu et al., 2021b): a modification of KGStory that produces more sentences in the story while maintaining quality.",,"Add,Fact/Evidence",Fact/Evidence
895,14-ARR,14-ARR_v2_69@6,,Appropriate knowledge added to the story results in a more detailed story.,,"Add,Claim",Claim
896,14-ARR,14-ARR_v2_16@0,14-ARR_v1_18@0,The construction of VHED is shown in Figure 2.,The construction of VHED is shown in Fig. 2.,"Modify,Clarity",Clarity
897,14-ARR,14-ARR_v2_28@2,14-ARR_v1_28@2,"SIMCSE uses contrastive learning with dropout as augmentation, then trained on natural langauge inference datasets to obtain better sentence embeddings from BERT (Devlin et al., 2019).","SIMCSE uses contrastive learning with dropout as augmentation, then trained on natural langauge inference datasets to obtain better sentence embeddings from BERT (Devlin et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
898,14-ARR,14-ARR_v2_29@2,14-ARR_v1_29@2,"We hypothesize that utilizing this feature makes it possible to extract more information, making it easier for the model to learn human judgment.","We hypothesize that thus doing makes it possible to extract more information, making it easier for the model to learn human judgment for story pairs.","Modify,Clarity",Clarity
899,14-ARR,14-ARR_v2_29@3,14-ARR_v1_29@3,"However, due to the small amount of data available, high variance is likely (Mosbach et al., 2020) to occur during inference.","However, due to the small amount of data available, high variance is likely (Mosbach et al., 2021) to occur during inference.","Modify,Fact/Evidence",Fact/Evidence
900,14-ARR,14-ARR_v2_29@4,14-ARR_v1_29@4,"Hence, we used all data from VHED, including human agreement=3 to increase the stability of our model following Mosbach et al. (2020).","Hence, we used all data from VHED, including human agreement=3 to increase the stability of our model following Mosbach et al. (2021).","Modify,Fact/Evidence",Fact/Evidence
901,14-ARR,14-ARR_v2_33@3,14-ARR_v1_33@3,"Given the story pair (x 1 , x 2 ), the automatic metric being assessed predicts the corresponding story quality scores (s 1 , s 2 ) which we compare to the averaged ranks y 1 and y 2 of x 1 and x 1 from human evaluation.","Given the story pair (x 1 , x 2 ), the autometric being assessed predicts the corresponding story quality scores (s 1 , s 2 ) which we compare to the averaged ranks y 1 and y 2 of x 1 and x 1 from human evaluation.","Modify,Clarity",Clarity
902,14-ARR,14-ARR_v2_40@1,14-ARR_v1_39@1,"We also implement the more recent BERT-Score, BLEURT, and UNION as baseline metrics.","We also considered the more recent BERT-Score, BLEURT, and UNION as baseline metrics.","Modify,Clarity",Clarity
903,14-ARR,14-ARR_v2_40@2,14-ARR_v1_39@2,"In addition to the above automatic metrics, we also include a random baseline, denoted as Random in Table 4, to provide a random score for each story as the lower bound.","In addition to the above automatic metrics, we also included a random baseline to provide a random score for each story, shown as Random in Table 4, as the lower bound.","Modify,Clarity",Clarity
904,14-ARR,14-ARR_v2_0@0,14-ARR_v1_0@0,Learning to Rank Visual Stories from Human Ranking Data,Learning to Rank Visual Stories From Human Ranking Data,"Modify,Grammar",Grammar
905,14-ARR,14-ARR_v2_43@1,14-ARR_v1_42@1,"This algorithm only applies when evaluating story pairs containing references, i.e., reference-machine pairs in this paper.","The Reference Absent Algorithm only applies when evaluating story pairs containing references, i.e., reference-machine pairs in this paper.","Modify,Clarity",Clarity
906,14-ARR,14-ARR_v2_47@10,14-ARR_v1_47@10,"We also find that Vrank ranks correctly when machine is better than reference, showing that Vrank yields 26.5% recall when the other metrics have 0 recall without Eq. 3 and ∼18% with Eq. 3.",Another analysis to study ability of Vrank to rank correctly when machine is better than reference shows that Vrank yields 26.5% recall when the other metrics have 0 recall without Eq. 3 and ∼18% with Eq. 3.,"Modify,Clarity",Clarity
907,14-ARR,14-ARR_v2_50@2,14-ARR_v1_49@2,It is crucial for automatic metrics to also recognize errors to judge generated text.,It is crucial for automatic metrics to also recognize such errors to judge generated text.,"Modify,Clarity",Clarity
908,14-ARR,14-ARR_v2_54@1,14-ARR_v1_53@1,"To determine whether Vrank generalizes to textual stories, we selected MANS dataset (Guan et al., 2021), an imagefree storytelling dataset in which the stories are derived from the ROCStories corpus .","To determine whether Vrank generalizes to textual stories, we selected as the benchmark the MANS dataset (Guan et al., 2021), an image-free storytelling dataset in which the stories are derived from the ROCStories corpus.","Modify,Clarity",Clarity
909,14-ARR,14-ARR_v2_54@2,14-ARR_v1_53@2,"MANS includes 200 story prompts, where each prompt includes five model-generated stories and a reference.","This dataset includes 200 story prompts, where each prompt includes five model-generated stories and a reference.","Modify,Clarity",Clarity
910,14-ARR,14-ARR_v2_61@0,14-ARR_v1_60@0,"After applying Vrank to assess five recent VIST models, we present the results in Figure 4: the models are gradually approaching human-level writing, outlining an exciting development of NLG in VIST.","After applying Vrank to assess five recent VIST models, we present the results in Fig. 4: the models are gradually approaching human-level writing, outlining an exciting development of NLG in VIST.","Modify,Clarity",Clarity
911,14-ARR,14-ARR_v2_61@2,14-ARR_v1_60@2,We also show the correlation between different error types in Figure 5.,We also show the correlation between different error types in Fig. 5.,"Modify,Clarity",Clarity
912,14-ARR,14-ARR_v2_61@4,14-ARR_v1_60@4,"Ranking Gap Distribution The ranking gap distribution is shown in Figure 6, in which both the ranking gaps and the number of stories are normalized.","Ranking Gap Distribution The ranking gap distribution is shown in Fig. 6, in which both the ranking gaps and the number of stories are normalized.","Modify,Clarity",Clarity
913,14-ARR,14-ARR_v2_65@2,14-ARR_v1_64@2,"The batch size is set as 32 and the random seed for training can be set as 7,777 for reproduction.",The batch size is set as 32 and the random seed for training can be set as 7777 for reproduction.,"Modify,Grammar",Grammar
914,14-ARR,14-ARR_v2_8@1,14-ARR_v1_9@1,We then re-purposed VHED to create a better metric Vrank for VIST to rank visual stories.,We then re-purposed VHED to create a better metric for VIST named Vrank (VIST Ranker).,"Modify,Fact/Evidence",Fact/Evidence
915,14-ARR,14-ARR_v2_9@7,14-ARR_v1_10@7,"Indeed, 38% of machine-generated stories are better than the references, which suggests that the afore-mentioned assumption may need to be revisited .","Indeed, 38% of machine-generated stories are better than the references, which suggests that the afore-mentioned assumption may need to be revisited (Clark et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
917,14-ARR,14-ARR_v2_9@13,14-ARR_v1_10@12,"Moreover, Vrank can rank machine and human stories decently and is better at detecting story errors.","In conclusion, Vrank excels in the above assessments and able to follow human behaviors in ranking, rank machine and human stories decently and is better at detecting story errors.","Split+Modify,Clarity",Clarity
918,14-ARR,14-ARR_v2_9@14,14-ARR_v1_11@0,"Specifically, we make three major contributions:",The contributions of this paper are threefold:,"Modify,Claim",Claim
919,141-ARR,,141-ARR_v1_7@0,,The correct answer should be Saint Vincent and the Grenadines instead of United States although both entities have co-occurring contexts with Moonhole.,"Delete,Fact/Evidence",Fact/Evidence
920,141-ARR,,141-ARR_v1_73@2,,The proof can be found in the Appendix.,"Delete,Fact/Evidence",Fact/Evidence
921,141-ARR,,141-ARR_v1_73@8,,"Then µ(r m (s, a)) takes the m-th entry of F( hs , ha ).","Delete,Fact/Evidence",Fact/Evidence
922,141-ARR,,141-ARR_v1_79@6,,The number of final clauses to define the query relation is H = 5 and the number of candidate bridging contexts for each hop is set to K = 5.,"Delete,Fact/Evidence",Fact/Evidence
923,141-ARR,,141-ARR_v1_79@7,,"The dimension of predicate embeddings and biGRU layer is 100 and 200, respectively.","Delete,Fact/Evidence",Fact/Evidence
924,141-ARR,,141-ARR_v1_79@8,,"For training, we adopt Adam optimization with learning rate initialized at 0.001.","Delete,Fact/Evidence",Fact/Evidence
925,141-ARR,,141-ARR_v1_79@9,,The batch size is set to 10.,"Delete,Fact/Evidence",Fact/Evidence
926,141-ARR,,141-ARR_v1_79@10,,"For all the experiments, we use the development dataset to evaluate the results because the test data is not publicly available.","Delete,Fact/Evidence",Fact/Evidence
927,141-ARR,,141-ARR_v1_80@0,,Experimental Result,"Delete,Other",Other
928,141-ARR,,141-ARR_v1_81@0,,"Weber et al. ( 2019) only selects four different query relations from WikiHop, namely Publisher, Developer, Country and Record_label, to evaluate their model.","Delete,Fact/Evidence",Fact/Evidence
929,141-ARR,,141-ARR_v1_81@1,,"For fair comparison, we first follow their setting to compare on these specific domains.","Delete,Fact/Evidence",Fact/Evidence
930,141-ARR,,141-ARR_v1_81@2,,"Besides BIDAF (Seo et al., 2017) and FastQA (Weissenborn et al., 2017), we also consider another three representative deep learning baselines : EPAr (Yichen Jiang and Bansal, 2019), HDEG (Tu et al., 2019), DynSAN (Zhuang and Wang, 2019) 2 , and a differentiable reasoning model DrMD adapted from (Dhingra et al., 2020).","Delete,Fact/Evidence",Fact/Evidence
931,141-ARR,,141-ARR_v1_81@3,,HDEG is a graph-based DNN.,"Delete,Fact/Evidence",Fact/Evidence
932,141-ARR,,141-ARR_v1_81@4,,EPAr and DynSAN are memory-based DNNs.,"Delete,Fact/Evidence",Fact/Evidence
933,141-ARR,,141-ARR_v1_81@5,,"DrMD is implemented following (Dhingra et al., 2020), except that we remove pre-defined entities and only consider mention interactions given our settings.","Delete,Fact/Evidence",Fact/Evidence
934,141-ARR,,141-ARR_v1_81@6,,BERT is a baseline model that concatenates query subject (or a candidate entity) with each context in the form of we feed the hidden representations corresponding to the query subject (or candidates) into an attention model to generate a single vector to be fed into a classifier.,"Delete,Fact/Evidence",Fact/Evidence
935,141-ARR,,141-ARR_v1_81@7,,"For all the baselines, we train the models on each query relation separately to test the reasoning capability, same as our setting.","Delete,Fact/Evidence",Fact/Evidence
936,141-ARR,,141-ARR_v1_81@8,,"Table 1 lists the results for MedHop and four query relations from WikiHop according to (Weber et al., 2019).","Delete,Fact/Evidence",Fact/Evidence
937,141-ARR,,141-ARR_v1_81@9,,"Clearly, DILR substantially outperforms all the baselines on MedHop, demonstrating the importance of the reasoning capabilities for interaction-intensive medical dataset.","Delete,Claim",Claim
938,141-ARR,,141-ARR_v1_81@10,,"On the four query relations from WikiHop, we still obtain the best performances.","Delete,Fact/Evidence",Fact/Evidence
939,141-ARR,,141-ARR_v1_81@13,,The results in terms of accuracy are shown in Table 2.,"Delete,Fact/Evidence",Fact/Evidence
940,141-ARR,,141-ARR_v1_81@15,,"As shown in Table 2, there are 38 relations (D1) containing less than 1,000 training examples, 7 relations (D2) with training examples ranging from 1,000 to 4,000 and 2 relations (D3) having more than 4,000 training examples.","Delete,Fact/Evidence",Fact/Evidence
941,141-ARR,,141-ARR_v1_81@21,,The Detailed comparison on each query relation can be found in Appendix.,"Delete,Fact/Evidence",Fact/Evidence
942,141-ARR,141-ARR_v2_7@0,,"In this example, the underlined entities are used to infer the correct answer, i.e., ""country(Moonhole, Saint Vincent and the Grenadines)"", but are not explicitly annotated for relational reasoning.",,"Add,Fact/Evidence",Fact/Evidence
943,141-ARR,141-ARR_v2_26@3,,"Here r denotes a predicate, i.e., a relation between X 0 and X l+1 .",,"Add,Fact/Evidence",Fact/Evidence
944,141-ARR,141-ARR_v2_84@0,,This completes the proof.,,"Add,Claim",Claim
945,141-ARR,141-ARR_v2_21@0,141-ARR_v1_20@0,"The hypothesis H is a logic program consisting of definite clauses b 1 ∧ ... ∧ b N ⇒ h where b 1 , ..., b N and h are logic atoms.","The hypothesis H is a logic program consisting of definite clauses b 1 ∧ ... ∧ b k ⇒ h where b 1 , ..., b k and h are logic atoms.","Modify,Fact/Evidence",Fact/Evidence
946,141-ARR,141-ARR_v2_29@0,141-ARR_v1_29@0,"Overall, DILR simulates a multi-hop reasoning process considering different number of inference steps.","Overall, DILR simulates multi-hop reasoning processes considering different number of inference steps.","Modify,Grammar",Grammar
947,141-ARR,141-ARR_v2_31@0,141-ARR_v1_31@0,"To avoid inevitable errors brought by off-the-shelf NER tools for named entity extraction, we propose to extract relevant information using an attentive reader.","To avoid inevitable errors brought by the NER tools for named entity extraction, we propose to learn to extract relevant information using an attentive reader.","Modify,Clarity",Clarity
948,141-ARR,141-ARR_v2_33@0,141-ARR_v1_33@0,"Given a query subject s with n s tokens, a candidate a with n a tokens, and a context c of length n c , we denote by S ∈ R ns×D , A ∈ R na×D and C ∈ R nc×D their word features after a biGRU layer, respectively.","Given a query subject s with n s tokens, a candidate a with n a tokens, and a context c of length n c , we denote by S ∈ R ns×D , A ∈ R na×D and C ∈ R nc×D as their word features after a biGRU layer, respectively.","Modify,Grammar",Grammar
949,141-ARR,141-ARR_v2_4@1,141-ARR_v1_4@1,"However, when the background knowledge is expressed in natural languages, as shown in the multi-hop reading comprehension problem with triplet-form questions (Welbl et al., 2018), it becomes difficult to conduct complex reasoning because the entities and relations are not explicitly labeled in the documents.","However, when the background knowledge is expressed in natural languages, as shown in the multi-hop reading comprehension problem with triplet-form questions (Welbl et al., 2018), it becomes difficult to conduct complex reasoning.","Modify,Claim",Claim
950,141-ARR,141-ARR_v2_35@1,141-ARR_v1_35@1,We obtain the normalized similarity score α s ij between the i-th token in the subject and the j-th token in the context via a softmax operation on each row of B s .,We obtain the normalized similarity score α s ij between i-th token in the subject and j-th token in the context via a softmax operation on each row of B s .,"Modify,Grammar",Grammar
951,141-ARR,141-ARR_v2_37@2,141-ARR_v1_37@2,"We denote by s = β s S, and a = β a A the feature representation of the query subject and the candidate entity, respectively.","We denote by s = β s S, and a = β a A the query subject and candidate representations, respectively.","Modify,Clarity",Clarity
952,141-ARR,141-ARR_v2_38@0,141-ARR_v1_38@0,"For (l + 1)-hop reasoning (l ≥ 0), it is desired to relocate to intermediate (bridging) entities that are related to the l-hop entities.","For (l + 1)-hop reasoning (l ≥ 0), it is desired to relocate to intermediate (bridging) entities related to the l-hop entities.","Modify,Clarity",Clarity
953,141-ARR,141-ARR_v2_2@0,141-ARR_v1_2@0,Multi-hop reading comprehension requires an ability to reason across multiple documents.,Multi-hop reading comprehension requires the ability to reason across multiple documents.,"Modify,Grammar",Grammar
954,141-ARR,141-ARR_v2_40@1,141-ARR_v1_40@1,We use α l+1 ij to denote a normalized attention score between the i-th and the j-th context tokens after applying a softmax operator over each row of B l+1 .,We use α l+1 ij to denote a normalized attention score between i-th and j-th context tokens after applying a softmax operator over each row of B l+1 .,"Modify,Grammar",Grammar
955,141-ARR,141-ARR_v2_54@0,141-ARR_v1_55@0,The multi-hop reasoner aims to conduct complex reasoning by first generating probable logic clauses and then evaluating each clause by instantiating the variables with relevant contexts obtained from the attentive reader.,The multi-hop reasoner aims to conduct complex reasoning by first generating probable logic clauses and then evaluating each clause by instantiating the variables.,"Modify,Fact/Evidence",Fact/Evidence
956,141-ARR,141-ARR_v2_54@2,141-ARR_v1_55@2,An illustration of the procedure is shown in Figure 1 and is elaborated in the following sub-section.,An illustration of the procedure is shown in Figure 1 and will be elaborated in the next section.,"Modify,Clarity",Clarity
957,141-ARR,141-ARR_v2_54@3,141-ARR_v1_55@3,"The clause evaluation process is then to instantiate variables in each atom with constants such as query subjects, candidate entities or bridging entities.","Then the clause evaluation process will ground each atom with query subjects, candidate entities or bridging entities.","Modify,Fact/Evidence",Fact/Evidence
958,141-ARR,141-ARR_v2_54@4,141-ARR_v1_55@4,"The outputs from the attentive reader, i.e., hs , ha and {h l k }'s (l > 0), can be used as feature representations for these constants to compute the atom scores for clause evaluation and updates.","The outputs from the attentive reader, i.e., hs , ha and {h l k }'s (l > 0), can be regarded as these constant representations to compute the atom scores for clause evaluation and updates.","Modify,Clarity",Clarity
959,141-ARR,141-ARR_v2_59@0,141-ARR_v1_58@0,"The clause generation process is divided into two stages: 1) to generate clauses defining invented predicates using only the existential predicates, and 2) to generate final clauses defining query relation q using only the invented predicates.",The clause generation process is divided into two stages: 1) generate clauses defining invented predicates using only the existential predicates; 2) generate final clauses defining query relation using only the invented predicates.,"Modify,Clarity",Clarity
960,141-ARR,141-ARR_v2_61@1,141-ARR_v1_60@2,"We use sparsemax, a sparse version of softmax (Martins and Astudillo, 2016), to select only a small number of predicates.","We use sparsemax which is a sparse version of softmax (Martins and Astudillo, 2016) to select only a small number of predicates.","Modify,Clarity",Clarity
961,141-ARR,141-ARR_v2_61@2,141-ARR_v1_60@3,"Intuitively, to learn to define a l-hop invented predicate r l m , ( 5) and ( 6) sequentially produce F t (X t , X t+1 ) at each step t ∈ {0, ..., l} to form the clause body by attending over all the existential predicates with attention weight S l t .","Intuitively, to learn to define a l-hop invented predicate r l m , ( 5) and (6) will sequentially produce F t (X t , X t+1 ) at each step t ∈ {0, ..., l} to form the clause body by attending over all the existential predicates with attention weight S l t .","Modify,Grammar",Grammar
962,141-ARR,141-ARR_v2_62@2,141-ARR_v1_62@2,"Given an embedding u q ∈ R D for the target relation q, we use a multi-head attention mechanism to compute a probability distribution s h over all the invented predicates for each head h ∈ {1, ..., H} to produce the h-th final clause:","Given an embedding u q ∈ R D for the target relation q, we use a multi-head attention mechanism to compute a probability distribution s i over all the invented predicates for each head i ∈ {1, ..., H} to produce the i-th final clause:","Modify,Fact/Evidence",Fact/Evidence
963,141-ARR,141-ARR_v2_64@1,141-ARR_v1_64@1,"For example, if s h selects r 0 1 and r 1 2 , the final clause becomes r 0 1 (X, Y ) ∧ r 1 2 (X, Y ) ⇒ q(X, Y ), which involves at most 1 inference step because r 1 2 is a 1-hop invented predicate.","For example, if s i selects r 0 1 and r 1 2 , the final clause becomes r 0 1 (X, Y ) ∧ r 1 2 (X, Y ) ⇒ q(X, Y ), which involves at most 1 inference step (r 12 ).","Modify,Fact/Evidence",Fact/Evidence
964,141-ARR,141-ARR_v2_66@0,141-ARR_v1_66@0,"Instantiation The clauses generated using the attentive memories need to be tested and refined against the given positive and negative examples, known as learning from entailment that tries to maximize the truth probabilities of positive examples and minimize those of negative examples.","Instantiation The clauses generated using the attentive memories will be tested and refined against the given positive and negative examples, known as learning from entailment that tries to maximize the truth probabilities of positive examples and minimize those of negative examples.","Modify,Clarity",Clarity
965,141-ARR,141-ARR_v2_66@1,141-ARR_v1_66@1,"The positive examples correspond to q(s, a) and the negative examples correspond to {q(s, a − )}'s, where s, a and a − refers to the query subject, correct answer and incorrect candidate, respectively.","The positive examples correspond to q(s, a) and the negative examples correspond to {q(s, a j )}'s, where s, a and a j refers to the query subject, correct answer and incorrect candidate, respectively.","Modify,Fact/Evidence",Fact/Evidence
966,141-ARR,141-ARR_v2_66@2,141-ARR_v1_66@2,"To obtain the truth probabilities of these atoms, we first instantiate the variables for each generated clause with constant contexts, e.g., X = s and Y = a (or Y = a − ) in q(X, Y ).","To obtain the truth probabilities of these atoms, we first instantiate the variables for each generated clause, e.g., X = s and Y = a (or Y = a j ) in q(X, Y ).","Modify,Fact/Evidence",Fact/Evidence
967,141-ARR,141-ARR_v2_66@4,141-ARR_v1_66@4,"Specifically, to instantiate each X l , we pick top-K contexts (documents) {c l 1 , ..., c l K } ⊆ C, namely X l = c l k , 1 ≤ k ≤ K with highest probabilities according to p l k computed via (4).","To avoid inaccurate selection, for each X l , we pick K contexts {c l 1 , ..., c l K } with highest probabilities according to p l k in (4).","Modify,Fact/Evidence",Fact/Evidence
968,141-ARR,141-ARR_v2_66@5,141-ARR_v1_66@5,"Neural Logic Operator Given a definite clause b 1 ∧ ... ∧ b N ⇒ h consisting of grounded atoms (e.g., b 1 = r 1 (s, a)), we could obtain the value for its head atom as µ(h) = µ(b 1 ∧ ... ∧ b N ).","Neural Logic Operator Given a definite clause b 1 ∧ ... ∧ b K ⇒ h consisting of grounded atoms (e.g., b 1 = r 1 (s, a)), we could obtain the value for its head atom as µ(h) = µ(b 1 ∧ ... ∧ b k ).","Modify,Fact/Evidence",Fact/Evidence
969,141-ARR,141-ARR_v2_85@1,141-ARR_v1_73@1,"When N = 2, the RHS of the inequality equals to 1/4 • µ n̸ =min , which makes G ∧ closer to µ min when µ n̸ =min is smaller.","When K = 2, the RHS of the inequality equals to 1/4 • µ k̸ =min , which makes G ∧ closer to µ min when µ k̸ =min is smaller.","Modify,Fact/Evidence",Fact/Evidence
970,141-ARR,141-ARR_v2_85@3,141-ARR_v1_73@4,"Moreover, It avoids exponential decay in the output when N > 1.","Moreover, It avoids exponential decay in the output when K > 1.","Modify,Fact/Evidence",Fact/Evidence
971,141-ARR,141-ARR_v2_8@4,141-ARR_v1_8@3,"However, DNNs only implicitly encode relevant contexts and fail to explicitly uncover the underlying relational compositions for complex inference.","However, DNNs only implicitly encode relevant contexts but fail to explicitly uncover the underlying relational compositions for complex inference.","Modify,Clarity",Clarity
972,141-ARR,141-ARR_v2_90@4,141-ARR_v1_75@4,We use a max operator to generate the maximum score over all possible instantiations in Z l to represent the final truth probability of each invented predicate.,We use a max operator to generate the maximum score over all possible bridging entities to represent the final truth probability of each invented predicate.,"Modify,Fact/Evidence",Fact/Evidence
973,141-ARR,141-ARR_v2_92@2,141-ARR_v1_77@1,"Here we organize the dataset according to subject-candidate pairs: (s, a).","Here we organize the dataset according to subject-candidate pairs: (s n , a n ).","Modify,Fact/Evidence",Fact/Evidence
974,141-ARR,141-ARR_v2_8@5,141-ARR_v1_8@4,"For instance, in the above example, DNNs may encode Bequia and Gladys Johnson into 1-hop features, given the fact that both entities co-occur with the query Moonhole.","With the above example, DNNs may encode Bequia and Gladys Johnson into 1-hop features, given both entities co-occur with the query Moonhole.","Modify,Clarity",Clarity
975,141-ARR,141-ARR_v2_92@3,141-ARR_v1_77@2,"We associate the ground-truth label y = 1 with (s, a) if a is the correct answer, otherwise, y = 0.","We associate the ground-truth label y n = 1 with (s n , a n ) if a n is the correct answer, otherwise, y n = 0.","Modify,Fact/Evidence",Fact/Evidence
976,141-ARR,141-ARR_v2_94@5,141-ARR_v1_79@5,"We define M = 10 relations as existential predicates and M l = 5 invented predicates for each hop with (Weber et al., 2019).","We define M = 10 relations as existential predicates and M l = 5 invented predicates for each hop with l = 0, 1, 2.","Modify,Fact/Evidence",Fact/Evidence
977,141-ARR,141-ARR_v2_8@7,141-ARR_v1_8@6,"In contrast, human beings would easily produce the correct answer given the knowledge ""if A is in B and B is part of country C, then A is in country C"" and by examining the relations between each entity pair co-occurred in the context.","However, a human would easily produce the correct answer given the knowledge ""if A is in B and B is part of country C, then A is in country C"" and by examining the relations between each entity pair co-occurred in the context.","Modify,Clarity",Clarity
978,141-ARR,141-ARR_v2_95@0,141-ARR_v1_81@14,"For a more thorough analysis, we take the entire WikiHop dataset and group the query relations in terms of the number of training instances.","For a more thorough analysis, we group the query relations in terms of the number of training instances.","Modify,Fact/Evidence",Fact/Evidence
979,141-ARR,141-ARR_v2_94@6,141-ARR_v1_81@17,"Clearly, DILR gives the best performances across all the baselines, demonstrating the advantage of combining deep attentive learning with logic reasoning.","Our model achieves the best performances over all data groups, demonstrating the advantage of combining deep attentive learning with logic reasoning.","Split+Modify,Clarity",Clarity
980,141-ARR,141-ARR_v2_95@3,141-ARR_v1_81@17,"Clearly, our model achieves the best performances over all data groups.","Our model achieves the best performances over all data groups, demonstrating the advantage of combining deep attentive learning with logic reasoning.","Split+Modify,Clarity",Clarity
981,141-ARR,141-ARR_v2_94@8,141-ARR_v1_81@20,"Even with well-trained contextualized word embeddings (DILR-BERT), our model still brings consistent performance gains.","Even with well-trained contextualized word embeddings, DILR still brings consistent performance gains.","Modify,Fact/Evidence",Fact/Evidence
982,141-ARR,141-ARR_v2_97@3,141-ARR_v1_83@3,"Clearly, ≤ 0 Hop and ≤ 3 Hop produce lower accuracies because ≤ 0 Hop fails to model the bridging entities and ≤ 3 Hop could overfit the model given most of the questions only involve at most 2 reasoning hops.","Clearly, ≤ 0 Hop and ≤ 3 Hop produce lower accuracies due to either missing bridging entities or overfitting with excessive inference steps.","Modify,Fact/Evidence",Fact/Evidence
983,141-ARR,141-ARR_v2_9@1,141-ARR_v1_9@1,"To answer the previous query, ILP could generate a rule as located_in(X, Z) ∧ country(Z, Y ) ⇒ country(X, Y ).","To answer the previous query, ILP could generate this rule: located_in(X, Z)∧ country(Z, Y ) ⇒ country(X, Y ).","Modify,Clarity",Clarity
984,141-ARR,141-ARR_v2_9@6,141-ARR_v1_9@6,"However, their work relies on the degree of precision for pre-extracted NERs and is limited by the number of rule templates.","However, their work relies on the accuracies of pre-extracted NERs and is limited by the number of rule templates.","Modify,Clarity",Clarity
985,141-ARR,141-ARR_v2_10@0,141-ARR_v1_10@0,"To address the aforementioned limitations, we propose a novel end-to-end integration of deep learning and logic reasoning termed Deep Inductive Logic Reasoning (DILR).","To address these limitations, we propose a novel end-to-end combination of deep learning and logic reasoning termed Deep Inductive Logic Reasoning (DILR).","Modify,Clarity",Clarity
986,141-ARR,141-ARR_v2_10@1,141-ARR_v1_10@1,"It consists of two components: 1) a hierarchical attentive reader that filters query-related and candidate-related information from given documents, and 2) a multihop reasoner that conducts inductive logic reasoning by attentively selecting proper predicates to form candidate rules and refines them upon given examples.",It consists of two components: 1) a hierarchical attentive reader that filters query-related and candidate-related information from given documents; 2) a multi-hop reasoner that conducts inductive logic reasoning by attentively selecting proper predicates to form candidate rules and refines them upon given examples.,"Modify,Grammar",Grammar
987,141-ARR,141-ARR_v2_14@1,141-ARR_v1_14@1,"To explicitly incorporate entity connections, De Cao et al. (2019), Ding et al. (2019), Qiu et al. (2019), Tang et al. (2020), Song et al. (2018) and Tu et al. (2019) proposed to build entity graphs and apply Graph Neural Networks for information propagation.","To explicitly incorporate entity connections, De Cao et al. ( 2019), Ding et al. (2019), Qiu et al. (2019), Tang et al. (2020), Song et al. (2018) and Tu et al. (2019) build entity graphs and apply Graph Neural Networks for information propagation.","Modify,Clarity",Clarity
988,141-ARR,141-ARR_v2_14@2,141-ARR_v1_14@2,Kundu et al. (2019) formalized reasoning as a path-finding problem with neural encoding to rank candidate paths.,Kundu et al. (2019) formalizes reasoning as a path-finding problem with neural encoding to rank candidate paths.,"Modify,Grammar",Grammar
989,141-ARR,141-ARR_v2_14@3,141-ARR_v1_14@3,Path modeling was also adopted in using pointer networks.,Path modeling is also adopted in using pointer networks.,"Modify,Grammar",Grammar
990,141-ARR,141-ARR_v2_14@4,141-ARR_v1_14@4,"However, these approaches only focus on local information without the ability to generalize, and some of them rely on off-the-shelf NER tools.","However, these approaches only focus on local information without the ability to generalize, and some of them rely on NER tools.","Modify,Clarity",Clarity
991,141-ARR,141-ARR_v2_14@5,141-ARR_v1_14@5,Dhingra et al. (2020) proposed to convert texts into a virtual knowledge base for retrieval using a pre-constructed entity database.,"Dhingra et al. (2020) converts texts into a virtual knowledge based for retrieval, but requires an entity database.","Modify,Clarity",Clarity
992,141-ARR,141-ARR_v2_18@1,141-ARR_v1_17@1,"Formally, for each RC problem, we are given a set of documents C = {c 1 , ..., c K }, a structured query in the form of a relational triplet (s, q, ?), where s denotes the subject of the relation q, and a list of candidate answers A = {a 1 , ..., a n }.","Formally, for each RC problem, we are given a set of documents D = {D 1 , ..., D n }, a structured query in the form of a relational triplet (s, q, ?) where s denotes the subject of the relation q, and a list of candidate answers A = {a 1 , ..., a m }.","Modify,Fact/Evidence",Fact/Evidence
993,15-ARR,,15-ARR_v1_31@2,,The USA part contains the majority of the arguments as we could reuse an existing dataset.,"Delete,Fact/Evidence",Fact/Evidence
994,15-ARR,15-ARR_v2_4@5,,Categories that tend to conflict are placed on opposite sites.,,"Add,Fact/Evidence",Fact/Evidence
995,15-ARR,15-ARR_v2_4@6,,"Illustration adapted from (Schwartz et al., 2012).",,"Add,Fact/Evidence",Fact/Evidence
996,15-ARR,15-ARR_v2_13@1,,Our consolidated value taxonomy (Section 3) is thus based on these schemes.,,"Add,Fact/Evidence",Fact/Evidence
997,15-ARR,15-ARR_v2_15@1,,We give an overview for completeness.,,"Add,Fact/Evidence",Fact/Evidence
998,15-ARR,15-ARR_v2_21@5,,"Formally, values are connected specifically with the argument's premise.",,"Add,Claim",Claim
999,15-ARR,15-ARR_v2_21@6,,"However, automatic models might still improve when incorporating the textual conclusion as context for the textual premise.",,"Add,Claim",Claim
1000,15-ARR,15-ARR_v2_23@0,,The taxonomy levels are chosen based on usefulness in social science research.,,"Add,Fact/Evidence",Fact/Evidence
1001,15-ARR,15-ARR_v2_23@1,,"The values at Level 1 are intended to be the items in surveys (Schwartz, 1994), which is why we also suggest to use them for dataset annotation.",,"Add,Fact/Evidence",Fact/Evidence
1002,15-ARR,15-ARR_v2_23@2,,"Moreover, Level 1 values can still be classified into being either instrumental or terminal.",,"Add,Claim",Claim
1003,15-ARR,15-ARR_v2_23@3,,"One could, however, create arbitrarily coarse-and fine-grained levels.",,"Add,Claim",Claim
1004,15-ARR,15-ARR_v2_23@5,,"The grouping of values at higher levels allows for classifications at coarser levels of granularity, enabling investigations such as, whether a specific set of arguments focus on persons or society mainly, or whether they imply a rather anxietyfree or a rather anxiety-avoiding background (cf. Figure 1).",,"Add,Claim",Claim
1005,15-ARR,15-ARR_v2_23@6,,"Also, the circular organization of the taxonomy enables the analysis of major ""directions"" in a collection of arguments, which can, for example, be used to study value differences in argumentation datasets of different cultures.",,"Add,Claim",Claim
1006,15-ARR,15-ARR_v2_23@8,,These links allow comparing value distributions identified in regional datasets with survey data.,,"Add,Fact/Evidence",Fact/Evidence
1007,15-ARR,15-ARR_v2_27@4,,"Note that this data is not intended to represent the respective culture, but to train and benchmark classifiers across sources.",,"Add,Fact/Evidence",Fact/Evidence
1008,15-ARR,15-ARR_v2_50@11,,"We found most disagreement arose from the complexity of annotating 54 values at once, with annotators sometimes confusing values despite the descriptions.",,"Add,Fact/Evidence",Fact/Evidence
1009,15-ARR,15-ARR_v2_50@12,,"For follow-up datasets, one could likely reduce such problems by training annotators on the arguments of our dataset with highest disagreement.",,"Add,Claim",Claim
1010,15-ARR,15-ARR_v2_54@4,,By definition this baseline achieves at least as high-and in most cases higher-F 1 -scores than label-wise random guessing according to the label frequency.,,"Add,Fact/Evidence",Fact/Evidence
1011,15-ARR,15-ARR_v2_56@2,,The conclusions were selected so that the different sets contain roughly the specified percentage of arguments.,,"Add,Fact/Evidence",Fact/Evidence
1012,15-ARR,15-ARR_v2_56@3,,"Unfortunately, this process led to different value distributions in the different sets.",,"Add,Fact/Evidence",Fact/Evidence
1013,15-ARR,15-ARR_v2_56@4,,"However, we deemed the conclusion-wise split more important for our experiments, as we want to test whether classifiers generalize to unseen conclusions.",,"Add,Fact/Evidence",Fact/Evidence
1014,15-ARR,15-ARR_v2_57@4,,"The comparably bad performance at higher levels is somewhat surprising, as it indicates that the categories at these higher levels are harder to separate by state-of-the-art language-based approaches.",,"Add,Claim",Claim
1015,15-ARR,15-ARR_v2_57@5,,"Maybe hierarchical classification approaches (e.g., Babbar et al., 2013) can address this comparably weak performance by utilizing signals at each level of the hierarchy simultaneously.",,"Add,Claim",Claim
1016,15-ARR,15-ARR_v2_58@4,,"Moreover, Figure 3 indicates some correlation of value frequency (grey bars) with classifier performance (colored lines).",,"Add,Fact/Evidence",Fact/Evidence
1017,15-ARR,15-ARR_v2_58@5,,One reason for this correlation could be that the dataset is too small for training reliable classifiers on the infrequent values.,,"Add,Claim",Claim
1018,15-ARR,15-ARR_v2_58@6,,"Another reason might be that there is a more developed vocabulary concerning frequent values, making it easier for classifiers to identify these values.",,"Add,Claim",Claim
1019,15-ARR,15-ARR_v2_68@2,,"Clearly expressing values behind arguments could avoid misunderstandings between humans and automated argumentation systems (Kiesel et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
1020,15-ARR,15-ARR_v2_69@1,,"Combined with Internet archive data, one could even analyse references to values over time.",,"Add,Claim",Claim
1021,15-ARR,15-ARR_v2_69@2,,We thus hope that this work can serve as a first step towards a better understanding of how the public sees and saw human values in everyday (digital) life.,,"Add,Claim",Claim
1022,15-ARR,15-ARR_v2_21@2,15-ARR_v1_20@3,"The term ""behind"" reflects the fact that many arguments do not explicate values; for example, in the argument ""no matter they felt forced to commit it: anyone who commits a crime should be prosecuted"" no value is mentioned literally.","The term ""behind"" reflects the fact that many arguments do not explicate values; e.g., in the argument ""no matter they felt forced to commit it: anyone who commits a crime should be prosecuted"" no value is mentioned literally.","Modify,Clarity",Clarity
1023,15-ARR,15-ARR_v2_21@7,15-ARR_v1_20@6,The task studied in this paper is to draw this connection between arguments and values automatically.,The task at hand is to draw this connection automatically.,"Modify,Clarity",Clarity
1024,15-ARR,15-ARR_v2_22@2,15-ARR_v1_21@2,We also asked the annotators to comment on supposedly missing values (see Section 4).,We also asked the annotators to comment on supposedly missing values (cf. Section 4).,"Modify,Clarity",Clarity
1025,15-ARR,15-ARR_v2_22@3,15-ARR_v1_21@3,"For most of the additional 48 value descriptions that we received (be humane, be fair, be modern, etc.), we identified existing values or value combinations in the taxonomy that subsume them, suggesting to extend the value descriptions rather than adding new values.","For most of the additional 48 value descriptions that we received (be humane, be fair, be modern, etc.) we were able to identify in the proposed taxonomy existing values or value combinations that subsume them, suggesting to extend the value descriptions rather than adding new values.","Modify,Clarity",Clarity
1026,15-ARR,15-ARR_v2_22@4,15-ARR_v1_21@4,Only two of the added values are not directly related to the universal needs that Schwartz (1994) based the value categories on.,Only two of the added values are not directly related to the universal needs where Schwartz (1994) based the value categories on.,"Modify,Grammar",Grammar
1027,15-ARR,15-ARR_v2_22@6,15-ARR_v1_21@6,"We adopt a uniform naming scheme where the value names reflect the distinction of Rokeach (1973) into instrumental (be . . . ) and terminal (have . . . ) values, and are easy to embed in sentences, for example, ""it is good to be creative.""","We adopt a uniform naming scheme where the value names reflect the distinction of Rokeach (1973) into instrumental (be . . . ) and terminal (have . . . ) values, that can be easily embedded in sentences, for example, ""it is good to be creative.""","Modify,Clarity",Clarity
1028,15-ARR,15-ARR_v2_23@7,15-ARR_v1_22@1,"In addition, for the 41 values with a link to the World Values Survey (the WVS column in Table 1, Haerpfer et al., 2020), the corresponding dataset contains information on people's value priorities (i.e., value systems) collected rigorously for 51 territories, with the earliest survey from 1981 and the latest from 2020.","For example, for the 41 values with a link to the World Values Survey (the WVS column in Table 1, Haerpfer et al., 2020), the corresponding dataset contains information on people's value priorities (i.e., value systems) collected rigorously for 51 territories, with the earliest survey from 1981 and the latest from 2020.","Modify,Clarity",Clarity
1029,15-ARR,15-ARR_v2_25@2,15-ARR_v1_29@2,"The dataset, taxonomy description, and annotation interface are available online as Webis-ArgValues-22.","The dataset, a taxonomy description, and the annotation interface are available online.","Modify,Fact/Evidence",Fact/Evidence
1030,15-ARR,15-ARR_v2_27@1,15-ARR_v1_31@1,"Each argument consists of one premise, one conclusion, and a stance attribute indicating whether the premise is in favor of (pro) or against (con) the conclusion.","Each argument consists of one premise, one conclusions, and a stance attribute indicating whether the premise is in favor of (pro) or against (con) the conclusion.","Modify,Grammar",Grammar
1031,15-ARR,15-ARR_v2_27@2,15-ARR_v1_31@3,"As existing argument datasets are almost exclusively from a Western background, we had to collect new suitable arguments for the non-US parts, drastically limiting their size.","However, as existing argument datasets are almost exclusively from a Western background, we had to collect new suitable arguments for the other parts.","Modify,Claim",Claim
1032,15-ARR,15-ARR_v2_4@3,15-ARR_v1_4@3,"Some values tend to conflict and others to align (see Figure 1), which can cause disagreement on the best course forward, but also the support, if not formation, of political parties that promote the respective highly revered values.","Some values tend to conflict and others to align (cf. Figure 1), which can cause disagreement on the best course forward, but also the support, if not formation, of political parties that promote the respective highly revered values.","Modify,Clarity",Clarity
1033,15-ARR,15-ARR_v2_5@0,15-ARR_v1_5@0,"Due to their outlined importance, human values are studied both in the social sciences (Schwartz, 1994) and in formal argumentation (Bench-Capon, 2003) for decades.","Due to their outlined importance, human values are studied both in the social sciences (Schwartz, 1994) and formal argumentation (Bench-Capon, 2003) since decades.","Modify,Grammar",Grammar
1034,15-ARR,15-ARR_v2_50@10,15-ARR_v1_45@1,"Despite the difficulty of the annotation task, the crowdworker annotators reached an average value-wise agreement α of 0.49 (Krippendorff, 2004).","Despite the difficulty of the annotation task, the annotators reached an average value-wise agreement α of 0.49 (Krippendorff, 2004).","Modify,Clarity",Clarity
1035,15-ARR,15-ARR_v2_50@13,15-ARR_v1_45@2,"One step we implemented for quality assurance is that we manually checked the 48 arguments (<1%) to which MACE assigned more than 10 values, reducing their values to the most prevalent 5-7 ones.","Moreover, we manually checked the 48 arguments (<1%) to which MACE assigned more than 10 values, reducing their values to the most prevalent 5-7 ones.","Modify,Fact/Evidence",Fact/Evidence
1036,15-ARR,15-ARR_v2_50@14,15-ARR_v1_45@3,"The right side of Table 1 shows the frequency of each value in each dataset part, revealing that each value occurs at least once.",The right side of Table 1 shows the frequency of each value in each dataset part.,"Modify,Fact/Evidence",Fact/Evidence
1037,15-ARR,15-ARR_v2_56@1,15-ARR_v1_52@1,"The approaches are trained on the arguments from 60 unique conclusions (4240 arguments, ~85%), validated on 4 (277, ~5%), and tested on 7 (503, ~10%).","The approaches are trained on the arguments from 60 unique conclusions (4240 arguments), validated on 4 (277), and tested on 7 (503).","Modify,Fact/Evidence",Fact/Evidence
1038,15-ARR,15-ARR_v2_56@5,15-ARR_v1_52@2,"Only one very rare value, be neat and tidy (0.2% of arguments in USA part), does not occur in the test set.","Only one very rare value, be neat and tidy (0.2% of arguments in USA part), does not occur in this test set and is thus excluded from evaluation.","Split+Modify,Clarity",Clarity
1039,15-ARR,15-ARR_v2_56@6,15-ARR_v1_52@2,We thus exclude this value from evaluation.,"Only one very rare value, be neat and tidy (0.2% of arguments in USA part), does not occur in this test set and is thus excluded from evaluation.","Split+Modify,Clarity",Clarity
1040,15-ARR,15-ARR_v2_57@6,15-ARR_v1_53@2,"Moreover, while a F 1 -score of 0.25 at Level 1 is encouraging for largely out-of-the-box approaches, clearly more work is needed.","While a F 1 -score of 0.25 is encouraging for largely out-of-the-box approaches, clearly more work is needed.","Modify,Clarity",Clarity
1041,15-ARR,15-ARR_v2_57@7,15-ARR_v1_53@3,"Though a recall of 0.19 may be acceptable for applications that not rely on completeness, a precision of 0.40 is clearly too low for practical uses.","Though a recall of 0.19 may be acceptable for applications that not rely on completeness, a precision of 0.40 seems low for practical uses.","Modify,Other",Other
1042,15-ARR,15-ARR_v2_58@7,15-ARR_v1_54@4,The results are distributed alongside the dataset for follow-up analyses.,The complete results are distributed alongside the dataset.,"Modify,Fact/Evidence",Fact/Evidence
1043,15-ARR,15-ARR_v2_60@2,15-ARR_v1_56@2,"However, the 1-Baseline is equally affected by this lack, thus providing for a comparison with the previous setting.","However, the 1-Baseline is equally effected by this lack, thus providing for a comparison with the previous setting.","Modify,Grammar",Grammar
1044,15-ARR,15-ARR_v2_6@0,15-ARR_v1_7@0,"To understand the pragmatics of this argument, a reader has to acknowledge the belief (Point 1 in the definition above) that the ""end state"" (2) of having a comfortable life is desirable in general (3).","To understand the pragmatics of this statement, a reader has to acknowledge the belief (Point 1 in the definition above) that the ""end state"" (2) of having a comfortable life is desirable in general (3).","Modify,Clarity",Clarity
1045,15-ARR,15-ARR_v2_62@0,15-ARR_v1_57@4,"These findings constitute first evidence that using a cross-cultural value taxonomy could result in robust methods for identifying the values behind arguments, even though more data and research seem necessary to get there.",These findings constitute first evidence that using a cross-cultural value taxonomy could result in robust methods for identifying the values behind arguments.,"Modify,Claim",Claim
1046,15-ARR,15-ARR_v2_6@2,15-ARR_v1_7@2,"Within computational linguistics, human values thus provide the context to categorize, compare, and evaluate argumentative statements, creating several possibilities: to inform social science research on values through large-scale datasets; to assess argumentation with respect to scope and strength; to generate or select arguments based on the value system of a target audience; and to identify opposing and shared values on both sides of a controversial topic.","Within computational linguistics, human values thus provide the context to categorize, compare, and evaluate argumentative statements, creating several possibilities: to inform social science research on values through large-scale datasets; to assess argumentations with respect to scope and strength; and to generate or select arguments based on the value system of a target audience.","Modify,Claim",Claim
1047,15-ARR,15-ARR_v2_8@0,15-ARR_v1_9@0,"As a first endeavor on the automatic identification of values in written arguments, this paper makes three contributions: (1) a consolidated multilevel taxonomy of 54 human values taken from four authoritative cross-cultural social science studies (Section 3); (2) a dataset of 5270 arguments from the US (most arguments), Africa, China, and India, each of which manually annotated for all values by three annotators, corresponding to about 850k human judgments (Section 4); and (3) first classification results per taxonomy level, establishing a baseline and revealing promising results both within and across cultures (Section 5).","As a first endeavour on the automatic identification of values in written arguments, this paper makes three contributions: (1) a consolidated multilevel taxonomy of 54 human values taken from four authoritative cross-cultural social science studies (Section 3); (2) a dataset of 5270 arguments from the US (most arguments), Africa, China, and India, each of which manually annotated for all values by three annotators, corresponding to about 850k human judgments (Section 4); and (3) first classification results per taxonomy level, establishing a baseline and revealing promising results both within and across cultures (Section 5).","Modify,Grammar",Grammar
1048,15-ARR,15-ARR_v2_12@2,15-ARR_v1_13@2,"The paper at hand follows these definitions and targets the personal values behind arguments, that is, the values that the arguments, mostly implicitly, resort to.","The paper at hand targets the personal values behind arguments, meaning the values in the former sense that the arguments, mostly implicitly, resort to.","Modify,Fact/Evidence",Fact/Evidence
1049,15-ARR,15-ARR_v2_15@0,15-ARR_v1_14@0,"Other schemes, however, pertain to specific purposes, making them less suited for our study.",Several of the value schemes proposed in the literature pertain to specific purposes.,"Modify,Claim",Claim
1050,15-ARR,15-ARR_v2_13@0,15-ARR_v1_15@0,Several proposed value schemes are domainindependent and hence suited to analyze generic argumentation.,Other proposed value schemes are more generic.,"Modify,Claim",Claim
1051,15-ARR,15-ARR_v2_14@0,15-ARR_v1_15@2,"Specifically for cross-cultural analysis, Schwartz et al. ( 2012) derived 48 value questions from the universal needs of individuals and societies, including obeying all the laws and to be humble.","Specifically for cross-cultural analyses, Schwartz et al. ( 2012) derived 48 value questions from the universal needs of individuals and societies, including obeying all the laws and to be humble.","Modify,Grammar",Grammar
1052,15-ARR,15-ARR_v2_14@4,15-ARR_v1_15@6,"However, as the meta-inventory is strictly more coarse-grained than Schwartz et al.'s theory we do not investigate it further in this paper.","However, as the meta-inventory is strictly more coarse-grained than Schwartz et al.'s theory we do not investigate it further for this paper.","Modify,Grammar",Grammar
1053,15-ARR,15-ARR_v2_17@3,15-ARR_v1_17@3,This paper presents a first step towards the large-scale automatic application of these works as it takes values to argument mining.,This paper present a first step towards the large-scale automatic application of these works as it takes values to argument mining.,"Modify,Grammar",Grammar
1054,15-ARR,15-ARR_v2_18@0,15-ARR_v1_18@0,"Values overlap with idea of framing in communication, that is, the selection and emphasis of specific aspects of (perceived) reality to promote a particular problem, causal interpretation, ethical evaluation, and/or recommendation (Entman, 1993).","Partly, values overlap with ideas of framing in communication, that is, the selection and emphasis of specific aspects of (perceived) reality to promote a particular problem definition, causal interpretation, ethical evaluation, and/or recommendation (Entman, 1993).","Modify,Fact/Evidence",Fact/Evidence
1055,15-ARR,15-ARR_v2_18@1,15-ARR_v1_18@1,"In frames, values can define the costs and benefits of options (Entman, 1993), while common value systems are used for evaluation.","In frames, values can define the costs and benefits of options (Entman, 1993) whereas common value systems are used for evaluation.","Modify,Clarity",Clarity
1056,15-ARR,15-ARR_v2_18@2,15-ARR_v1_18@2,"Framing has often been studied computationally for news (Naderi and Hirst, 2015;Chen et al., 2021), but also for political speech (De Vreese, 2005), and argumentation (Ajjour et al., 2019).","Frames have been studied computationally for news (Naderi and Hirst, 2015), political speech (De Vreese, 2005), and argumentation (Ajjour et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
1057,15-ARR,15-ARR_v2_18@3,15-ARR_v1_18@3,"In the latter, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification.","In argumentation, some values are so prevalent that they constitute frames of their own, indicating a potential use of values in frame identification.","Modify,Clarity",Clarity
1058,151-ARR,,151-ARR_v1_20@1,,The input can be formalized as:,"Delete,Fact/Evidence",Fact/Evidence
1059,151-ARR,,151-ARR_v1_35@3,,"Therefore, we propose monotonic regional attention (MRA).","Delete,Claim",Claim
1060,151-ARR,,151-ARR_v1_59@0,,Experimental Settings,"Delete,Other",Other
1061,151-ARR,,151-ARR_v1_60@0,,"Benchmarks Following previous work (Rei et al., 2020;Yuan et al., 2021), we examine the effectiveness of the propose method on WMT 2019 Metrics tasks (Ma et al., 2019).","Delete,Fact/Evidence",Fact/Evidence
1062,151-ARR,,151-ARR_v1_68@5,,"Moreover, we also testify the performance of UniTE-MUP on WMT 2020 QE tasks via finetuning.","Delete,Fact/Evidence",Fact/Evidence
1063,151-ARR,,151-ARR_v1_79@0,,"Considering the English-targeted model, we select Czech (Cz), German (De), Japanese (Ja), Russian (Ru), and Chinese (Zh) as source languages, and English (En) as target.","Delete,Fact/Evidence",Fact/Evidence
1064,151-ARR,,151-ARR_v1_79@1,,"For each translation direction, we collect 1 million samples, finally yielding 5 million examples in total for unified pretraining.","Delete,Fact/Evidence",Fact/Evidence
1065,151-ARR,,151-ARR_v1_79@2,,"As to the multilingual-targeted model, we further collect 1 million synthetic data for each language direction of En-Cz, En-De, En-Ja, En-Ru, and En-Zh.","Delete,Fact/Evidence",Fact/Evidence
1066,151-ARR,,151-ARR_v1_79@3,,"Finally, we construct 10 million examples for the pretraining of the multilingual version by adding the data of the English-targeted model.","Delete,Fact/Evidence",Fact/Evidence
1067,151-ARR,,151-ARR_v1_79@4,,"Note that, for a fair comparison, we filter out all pretraining examples that are involved in benchmarks.","Delete,Fact/Evidence",Fact/Evidence
1068,151-ARR,,151-ARR_v1_80@0,,"After trying several pooling methods which derive sequence-level representations, we use the representations located at the start of sequence as the input of feedforward network (Ranasinghe et al., 2020b).","Delete,Fact/Evidence",Fact/Evidence
1069,151-ARR,,151-ARR_v1_80@1,,"The feedforward network consists of 3 linear transitions, where the dimensionalities of corresponding outputs are 3,072, 1,024, and 1, respectively.","Delete,Fact/Evidence",Fact/Evidence
1070,151-ARR,,151-ARR_v1_80@2,,"Between any two adjacent linear modules in feedforward, hyperbolic tangent function is arranged as activation.","Delete,Fact/Evidence",Fact/Evidence
1071,151-ARR,,151-ARR_v1_82@1,,"As seen, our approach can give better performance than strong QE baselines.","Delete,Claim",Claim
1072,151-ARR,,151-ARR_v1_83@0,,All the models reported in this paper were finetuned on a single Nvidia V100 (32GB) GPU.,"Delete,Fact/Evidence",Fact/Evidence
1073,151-ARR,,151-ARR_v1_83@1,,"Specifically for UniTE-UP and UniTE-MUP, the pretraining is arranged on 4 Nvidia V100 (32GB) GPUs.","Delete,Fact/Evidence",Fact/Evidence
1074,151-ARR,,151-ARR_v1_83@2,,"Our framework is built upon COMET repository (Rei et al., 2020).","Delete,Fact/Evidence",Fact/Evidence
1075,151-ARR,,151-ARR_v1_83@3,,"For the contribution to the research community, we will release both the source code of UniTE framework and the well-trained evaluation models including UniTE-UP and UniTE-MUP checkpoints as described in this paper upon the acceptance.","Delete,Fact/Evidence",Fact/Evidence
1076,151-ARR,151-ARR_v2_42@3,,We prevent specified interactions in SRC+REF training via modifying the attention mask with regional properties.,,"Add,Fact/Evidence",Fact/Evidence
1077,151-ARR,151-ARR_v2_42@4,,"We show the hard (left) and soft design (right, no h → s) in this figure.",,"Add,Fact/Evidence",Fact/Evidence
1078,151-ARR,151-ARR_v2_56@1,,"Following the official report, the Pearson's correlation is used for evaluation.",,"Add,Fact/Evidence",Fact/Evidence
1079,151-ARR,151-ARR_v2_63@0,,High-resource Zero-shot Avg.,,"Add,Other",Other
1080,151-ARR,151-ARR_v2_72@0,,Ranking-based Data Labeling,,"Add,Other",Other
1081,151-ARR,151-ARR_v2_73@0,,"To verify the effectiveness of ranking-based labeling, we collect the results of models applying different pseudo labeling strategies.",,"Add,Fact/Evidence",Fact/Evidence
1082,151-ARR,151-ARR_v2_73@1,,"After deriving the original scores from the well-trained UniTE-MRA checkpoint, we use Z-score and proposed ranking-based normalization methods to label synthetic data.",,"Add,Fact/Evidence",Fact/Evidence
1083,151-ARR,151-ARR_v2_73@2,,"For both methods, we also apply an ensembling strategy to assign training examples with averaged scores deriving from 3 UniTE-MRA checkpoints.",,"Add,Fact/Evidence",Fact/Evidence
1084,151-ARR,151-ARR_v2_73@3,,"Results show that, Z-score normalization reveals a performance drop when applying score ensembling with multiple models.",,"Add,Fact/Evidence",Fact/Evidence
1085,151-ARR,151-ARR_v2_73@4,,"Our proposed ranking-based normalization can boost the UniTE-UP model training, and its ensembling approach can further improve the performance.",,"Add,Claim",Claim
1086,151-ARR,151-ARR_v2_20@0,151-ARR_v1_20@0,"By receiving a data example composing of hypothesis, source, and reference segment, UniTE first modifies it into concatenated sequence following the given setting as REF , SRC , or SRC+REF :","By receiving a data example composing of hypothesis, source, and reference segment, UniTE first modifies it into concatenated sequence following the given setting as REF , SRC , or SRC+REF .","Modify,Grammar",Grammar
1087,151-ARR,151-ARR_v2_26@1,151-ARR_v1_26@1,"According to Ranasinghe et al. (2020b), we use the first output representation as the input of feedforward layer.","According to common practice (Ranasinghe et al., 2020b), we use the first output representation as the input of feedforward layer (see Appendix B).","Modify,Fact/Evidence",Fact/Evidence
1088,151-ARR,151-ARR_v2_27@0,151-ARR_v1_27@0,"Compared to existing methods (Zhang et al., 2020;Rei et al., 2020) which take sentence-level representations for evaluation, the advantages of our architecture design are as follows.","Compared to existing methods (Rei et al., 2020;Zhang et al., 2020) which only take the outputted representations of the topmost layer for evaluation, the advantages of our architecture design are as follows.","Modify,Fact/Evidence",Fact/Evidence
1089,151-ARR,151-ARR_v2_27@1,151-ARR_v1_27@1,"First, our UniTE model can benefit from layer-coordinated semantical interactions inside every one of PLM layers, which is proven effective on capturing diverse linguistic features (He et al., 2018;Lin et al., 2019;Jawahar et al., 2019;Tenney et al., 2019;Rogers et al., 2020).","First, our UniTE model can benefit from layer-coordinated semantical interactions inside every one layer of PLM, which is proven effective on capturing diverse linguistic features (He et al., 2018;Lin et al., 2019;Jawahar et al., 2019;Tenney et al., 2019;Rogers et al., 2020).","Modify,Clarity",Clarity
1090,151-ARR,151-ARR_v2_2@8,151-ARR_v1_2@7,Both source code and associated models are available at https://github.com/NLP2CT/UniTE.,Both source code and associated models will be released upon the acceptance of this paper.,"Modify,Fact/Evidence",Fact/Evidence
1091,151-ARR,151-ARR_v2_32@0,151-ARR_v1_31@0,"For training, we encourage the model to reduce the mean squared error with respect to given score q:","During training, we encourage the model to reduce the mean squared error between model prediction and given score q:","Modify,Clarity",Clarity
1092,151-ARR,151-ARR_v2_35@0,151-ARR_v1_33@0,"However, for the pretraining of most PLMs (e,g., XLM-R, Conneau et al., 2020), the input patterns are designed to receive two segments at most.","However, the input patterns for most multilingual PLMs (e,g., XLM-R, Conneau et al., 2020) are designed to receive two segments at most during pretraining.","Modify,Clarity",Clarity
1093,151-ARR,151-ARR_v2_35@2,151-ARR_v1_33@2,"Moreover, previous study (Takahashi et al., 2020) shows that directly training over SRC+REF by following such design leads to worse performance than REF scenario.","Moreover, previous studies (Takahashi et al., 2020) show that directly training over SRC+REF by following such design leads to slightly worse performance than REF scenarios.","Modify,Grammar",Grammar
1094,151-ARR,151-ARR_v2_4@0,151-ARR_v1_4@0,"Automatically evaluating the translation quality with the given reference segment(s), is of vital importance to identify the performance of Machine Translation (MT) models (Freitag et al., 2020;Mathur et al., 2020a;Zhao et al., 2020;Kocmi et al., 2021).","Automatically evaluating the translation quality with the given reference segment(s), is of vital importance to identify the performance of Machine Translation (MT) models (Freitag et al., 2020;Mathur et al., 2020;Zhao et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1096,151-ARR,151-ARR_v2_2@1,151-ARR_v1_2@0,"According to the input format, it is mainly separated into three tasks, i.e., reference-only, source-only and source-reference-combined.","Translation quality evaluation plays a crucial role in machine translation, and is mainly separated into three tasks according to different input formats, i.e., reference-only, sourceonly and source-reference-combined.","Split+Modify,Clarity",Clarity
1097,151-ARR,151-ARR_v2_37@0,151-ARR_v1_35@0,"To fill the modeling gap between the pretraining of PLM and the joint training of three downstream tasks, a natural idea is to unify the number of involved segments when modeling semantics for SRC , REF and SRC+REF tasks.","In order to fill the modeling gap between the pretraining of PLM and the joint training of three downstream tasks, a natural idea is to unify the number of involved segments when modeling semantics for SRC , REF and SRC+REF tasks.","Modify,Clarity",Clarity
1098,151-ARR,151-ARR_v2_37@3,151-ARR_v1_36@0,Considering the conventional attention module:,The conventional attention module can be expressed as:,"Modify,Clarity",Clarity
1099,151-ARR,151-ARR_v2_39@1,151-ARR_v1_39@1,"2 As to monotonic regional attention (MRA), we simply add a mask M to the softmax logits to control attention flows:","2 As to MRA, we simply add a mask M to the softmax logits to control attention flows:","Modify,Clarity",Clarity
1100,151-ARR,151-ARR_v2_43@0,151-ARR_v1_44@0,"To give more fine-grained designs, we propose two approaches for UniTE-MRA, which apply the MRA mechanism into UniTE model (Figure 2):","To give more fine-grained designs, we propose two approaches for UniTE-MRA, which apply the MRA mechanism into UniTE model:","Modify,Fact/Evidence",Fact/Evidence
1101,151-ARR,151-ARR_v2_4@1,151-ARR_v1_4@1,"Based on the input contexts, translation evaluation can be mainly categorized into three classes: 1) reference-only evaluation ( REF ) approaches like BLEU (Papineni et al., 2002) and BLEURT (Sellam et al., 2020a), which evaluate the hypothesis by referring the golden reference at target side; 2) source-only evaluation ( SRC ) methods like YiSi-2 (Lo, 2019) and TransQuest (Ranasinghe et al., 2020b), which are also referred as quality estimation (QE).","According to the input contexts, translation evaluation can be mainly categorized into three classes: 1) reference-only evaluation ( REF ) approaches like BLEU (Papineni et al., 2002) and BLEURT (Sellam et al., 2020a), which evaluate the hypothesis by referring the golden reference at target side; 2) source-only evaluation ( SRC ) methods like YiSi-2 (Lo, 2019) and TransQuest (Ranasinghe et al., 2020b), which are also referred as quality estimation (QE).","Modify,Clarity",Clarity
1102,151-ARR,151-ARR_v2_45@0,151-ARR_v1_46@0,"Note that, although the processing in source and reference may be affected because their positions are not indexed from the start, related studies on positional embeddings reveal that, PLM can well capture relative positional information (Wang and Chen, 2020), which dispels this concern.","Note here that, although the processing in source and reference segments may be affected because their position embeddings are not indexed from the start, related studies on positional embeddings reveal that PLM models can well capture relative positional information (Wang and Chen, 2020), which dispels this concern.","Modify,Clarity",Clarity
1103,151-ARR,151-ARR_v2_47@0,151-ARR_v1_48@0,"To further bridge the modeling gap between PLM and the joint training of UniTE mentioned in §3.1, we propose a unified pretraining strategy including the following main stages: 1) collecting and downgrading synthetic data; 2) labeling examples with a novel ranking-based strategy; 3) multi-task learning for unified pretraining and finetuning.","To further bridge the modeling gap between PLM and the joint training of UniTE as we mentioned in §3.1, we propose a unified pretraining strategy including the following main stages: 1) collecting and downgrading synthetic data; 2) labeling examples with a novel ranking-based strategy; 3) multi-task learning for unified pretraining and finetuning.","Modify,Clarity",Clarity
1104,151-ARR,151-ARR_v2_48@1,151-ARR_v1_49@1,"To further improve the diversity of synthetic data quality, we follow existing experiences (Sellam et al., 2020a;Wan et al., 2021) to apply the word and span dropping strategy to downgrade a portion of hypotheses.","In order to further improve the diversity of synthetic data quality, we follow Sellam et al. (2020a) to apply the word and span dropping strategy to downgrade a portion of hypotheses.","Modify,Fact/Evidence",Fact/Evidence
1105,151-ARR,151-ARR_v2_49@0,151-ARR_v1_50@0,"Specifically, we first use available approaches to derive the predicted score qi for each item, yielding labeled synthetic quadruple examples formed as D = { h i , s i , r i , qi } N i=1 .","To be concrete, for each data item, we first use existing evaluation approach to give prediction qi for each item, yielding labeled synthetic quadruple examples formed as D = { h i , s i , r i , qi } N i=1 .","Modify,Clarity",Clarity
1106,151-ARR,151-ARR_v2_49@1,151-ARR_v1_50@1,"Then, we tag each example with its rank index qi referring to qi :","After that, we descendingly tag each example with their rank index qi referring to qi :","Modify,Fact/Evidence",Fact/Evidence
1107,151-ARR,151-ARR_v2_53@4,151-ARR_v1_55@4,"For example, different methods may give scores with different distributions.","For example, different existing methods may output scores with different distributions.","Modify,Clarity",Clarity
1108,151-ARR,151-ARR_v2_4@2,151-ARR_v1_4@2,"These methods estimate the quality of the hypothesis based on the source sentence without using references; 3) source-reference-combined evaluation ( SRC+REF ) works like COMET (Rei et al., 2020), where the evaluation exploits information from both source and reference.","These methods estimate the quality of the hypothesis based on the source sentence without using references; 3) source-reference-combined evaluation ( SRC+REF ) works like COMET (Rei et al., 2020), where the model exploits information from both source and reference for the evaluation.","Modify,Clarity",Clarity
1109,151-ARR,151-ARR_v2_54@3,151-ARR_v1_60@1,"For the former, we follow the common practice in COMET 3 (Rei et al., 2020) to collect and preprocess the dataset.","We follow the common practice in COMET 3 (Rei et al., 2020) to collect and preprocess the dataset.","Modify,Clarity",Clarity
1110,151-ARR,151-ARR_v2_56@0,151-ARR_v1_60@4,"For SRC scenario, we further conduct results on WMT 2020 QE task (Specia et al., 2020) referring to Ranasinghe et al. (2020a) for data collection and preprocessing.","For SRC scenario, we further evaluate our method on WMT 2020 QE tasks (Specia et al., 2020), where we follow Ranasinghe et al. (2020a) for data collection and preprocessing.","Modify,Clarity",Clarity
1111,151-ARR,151-ARR_v2_58@0,151-ARR_v1_61@1,"The data is constructed from WMT 2021 News Translation task, where we collect the training sets from five translation tasks.","The data is constructed from WMT 2021 Cz-En, De-En, Ja-En, Ru-En, and Zh-En machine translation training sets.","Split+Modify,Clarity",Clarity
1112,151-ARR,151-ARR_v2_58@1,151-ARR_v1_61@1,"Among those tasks, the target sentences are all in English (En), and the source languages are Czech (Cs), German (De), Japanese (Ja), Russian (Ru), and Chinese (Zh).","The data is constructed from WMT 2021 Cz-En, De-En, Ja-En, Ru-En, and Zh-En machine translation training sets.","Split+Modify,Clarity",Clarity
1113,151-ARR,151-ARR_v2_58@2,151-ARR_v1_61@2,"Specifically, we follow Sellam et al. (2020a) to use TRANSFORMER-base (Vaswani et al., 2017) MT models to generate translation candidates, and use the checkpoints trained via UniTE-MRA approach for synthetic data labeling.","Specifically, we follow Sellam et al. (2020a) to use Transformer-base (Vaswani et al., 2017) model to generate translation candidates, and use the checkpoints trained via UniTE-MRA approach for synthetic data labeling.","Modify,Clarity",Clarity
1114,151-ARR,151-ARR_v2_58@3,151-ARR_v1_61@3,"We pretrain two kinds of models, one is pretrained on English-targeted language directions, and the other is a multilingual version trained using bidirectional data.","We pretrain two kinds of models, one is the English version which is pretrained on English-targeted language directions, the other is a multilingual version trained using bidirectional data.","Modify,Clarity",Clarity
1115,151-ARR,151-ARR_v2_59@1,151-ARR_v1_62@1,"For SRC methods, we post results of both metric and QE methods, including YiSi-2 (Lo, 2019), XLM-R+Concat (Takahashi et al., 2020), PRISM-src (Thompson and Post, 2020) and multilingual-to-multilingual MTran-sQuest (Ranasinghe et al., 2020b).","As to SRC methods, we post results of both metric and QE methods, including YiSi-2 (Lo, 2019), XLM-R+Concat (Takahashi et al., 2020), PRISMsrc (Thompson and Post, 2020) and multilingual-tomultilingual version of MTransQuest (Ranasinghe et al., 2020b).","Modify,Clarity",Clarity
1116,151-ARR,151-ARR_v2_59@2,151-ARR_v1_62@2,"For SRC+REF , we use XLM-R+Concat (Takahashi et al., 2020) and COMET (Rei et al., 2020) as strong baselines.","For SRC+REF scenario, we use XLM-R+Concat (Takahashi et al., 2020) and COMET (Rei et al., 2020) as strong baselines.","Modify,Clarity",Clarity
1117,151-ARR,151-ARR_v2_62@1,151-ARR_v1_64@1,"Among all involved baselines, for REF methods, BARTScore (Yuan et al., 2021) performs better than other statistical and model-based metrics.","For REF methods, BARTScore (Yuan et al., 2021) performs better than other statistical and model-based metrics.","Modify,Clarity",Clarity
1118,151-ARR,151-ARR_v2_63@2,151-ARR_v1_64@2,"Further, COMET (Rei et al., 2020) performs better than XLM-R+Concat (Takahashi et al., 2020) on SRC+REF scenario.","MTransQuest (Ranasinghe et al., 2020b) gives dominant performance on SRC scenario, and COMET (Rei et al., 2020) performs better than XLM-R+Concat on SRC+REF scenario.","Modify,Fact/Evidence",Fact/Evidence
1119,151-ARR,151-ARR_v2_63@3,151-ARR_v1_65@0,"As for our methods, we can see that, UniTE-MRA achieves better results on all tasks, demonstrating the effectiveness of monotonic attention flows for cross-lingual interactions.","As for our methods, UniTE-MRA approach achieves better results on all tasks, demonstrating the effectiveness of monotonic attention flow for cross-lingual interactions.","Modify,Clarity",Clarity
1120,151-ARR,151-ARR_v2_63@4,151-ARR_v1_65@1,"Moreover, the proposed model UniTE-UP, which unifies REF , SRC , and SRC+REF learning on both pretraining and finetuning, yields better results on all evaluation settings.","Moreover, our proposed model UniTE-UP, which unifies both pretraining and finetuning, can yield better results following all evaluation settings.","Modify,Fact/Evidence",Fact/Evidence
1121,151-ARR,151-ARR_v2_63@5,151-ARR_v1_65@2,"Most importantly, UniTE-UP is a single model which surpasses all the different state-of-the-art models on three tasks, showing its dominance on both convenience and effectiveness.","Most importantly, UniTE-UP is a single model which surpasses all the different state-of-the-art models on three tasks.","Modify,Claim",Claim
1122,151-ARR,151-ARR_v2_64@1,151-ARR_v1_68@2,"Besides, the UniTE-UP also gives dominant results, revealing an improvement of 0.6, 0.3 and 0.9 averaged Kendall's τ correlation scores, respectively.","Besides, it is encouraging to see that the UniTE-UP can also give dominant results, revealing an improvement of 0.6, 0.3 and 0.9 averaged Kendall's τ correlation scores, respectively.","Modify,Claim",Claim
1123,151-ARR,151-ARR_v2_64@2,151-ARR_v1_68@3,"However, we find that UniTE-MUP outperforms strong baselines but slightly worse than UniTE-UP on English-targeted translation directions (see Table 3).",Our further comparison indicates that UniTE-MUP also outperforms previous strong baselines but slightly worse than UniTE-UP on English-targeted translation directions.,"Modify,Clarity",Clarity
1124,151-ARR,151-ARR_v2_67@1,151-ARR_v1_70@1,All experiments are conducted by following English-targeted setting.,All experiments follow English-targeted setting on SRC+REF task.,"Modify,Fact/Evidence",Fact/Evidence
1125,151-ARR,151-ARR_v2_69@0,151-ARR_v1_72@0,"To investigate the effectiveness of MRA, we further collect experiments in Table 5.","To investigate the effectiveness of MRA, we further collect experiments for comparison.","Modify,Fact/Evidence",Fact/Evidence
1126,151-ARR,151-ARR_v2_69@1,151-ARR_v1_72@1,"As seen, MRA can give performance improvements than full attention, and preventing the interactions between hypothesis and source segment can improve the performance most.","As seen in Table 3, MRA can give performance improvements than full attention, and preventing the interactions between hypothesis and source segment can improve the performance most.","Modify,Fact/Evidence",Fact/Evidence
1127,151-ARR,151-ARR_v2_69@6,151-ARR_v1_73@1,Wang and Chen (2020) found that the positional embeddings in PLM are engaged with strong adjacent information.,As Wang and Chen (2020) found that the positional embeddings in PLM are engaged with strong adjacent information.,"Modify,Clarity",Clarity
1128,151-ARR,151-ARR_v2_71@1,151-ARR_v1_76@1,"As seen, when using the unified pretraining checkpoint to finetune over the specific task, performance over three models reveals performance drop con- sistently, indicating that the unified finetuning is helpful for model learning.","As seen, when using the unified pretraining checkpoint to finetune over the specific task, performance over three models reveals performance drop consistently, indicating the unified finetuning is helpful for model learning, and SRC , REF and SRC+REF tasks are complementary to each other during learning.","Split+Modify,Grammar",Grammar
1129,151-ARR,151-ARR_v2_71@2,151-ARR_v1_76@1,"This also verifies our hypothesis, that the cores of REF , SRC , and SRC+REF tasks are identical to each other.","As seen, when using the unified pretraining checkpoint to finetune over the specific task, performance over three models reveals performance drop consistently, indicating the unified finetuning is helpful for model learning, and SRC , REF and SRC+REF tasks are complementary to each other during learning.","Split+Modify,Claim",Claim
1130,151-ARR,151-ARR_v2_71@3,151-ARR_v1_76@1,"Moreover, unified pretraining and finetuning are complementary to each other.","As seen, when using the unified pretraining checkpoint to finetune over the specific task, performance over three models reveals performance drop consistently, indicating the unified finetuning is helpful for model learning, and SRC , REF and SRC+REF tasks are complementary to each other during learning.","Split+Modify,Clarity",Clarity
1131,151-ARR,151-ARR_v2_5@2,151-ARR_v1_5@2,"We believe that it is valuable, as well as feasible, to unify the capabilities of all MT evaluation tasks ( REF , SRC and SRC+REF ) into one model.","Therefore, we believe that it is valuable to unify the capabilities of all MT evaluation tasks ( REF , SRC and SRC+REF ) into one model.","Modify,Clarity",Clarity
1132,151-ARR,151-ARR_v2_5@4,151-ARR_v1_5@4,"To achieve this, two important challenges need to be addressed: 1) How to design a model framework that can unify all translation evaluation tasks? 2) How to make the powerful PLMs better adapt to the unified evaluation model?","To achieve this idea, the following two important challenges need to be addressed: 1) how to design a model framework that can unify all translation evaluation tasks? 2) Considering the powerful capabilities of the PLM, how to make the PLM better adapt to the unified evaluation model?","Modify,Clarity",Clarity
1133,151-ARR,151-ARR_v2_2@2,151-ARR_v1_2@1,"Recent methods, despite their promising results, are specifically designed and optimized on one of them.","Recent methods, despite their promising results, are specifically designed and optimized on one of these three tasks.","Modify,Clarity",Clarity
1134,151-ARR,151-ARR_v2_6@1,151-ARR_v1_6@1,"To solve the first challenge as mentioned above, based on the multilingual PLM, we utilize layerwise coordination which concatenates all input segments into one sequence as the unified input form.","To solve the first challenge as mentioned above, based on the multilingual PLM (Conneau et al., 2020), we utilize layerwise coordination which concatenates all input segments into one sequence as the unified input form.","Modify,Fact/Evidence",Fact/Evidence
1135,151-ARR,151-ARR_v2_6@3,151-ARR_v1_6@3,"For the second challenge, a multi-task learning-based unified pretraining is proposed.","For the second challenge, a multi-task learning-xbased unified pretraining is proposed.","Modify,Grammar",Grammar
1136,151-ARR,151-ARR_v2_6@6,151-ARR_v1_6@6,"Finally, the multilingual PLM is continuously pretrained on synthetic dataset with multi-task learning manner.","Finally, The multilingual PLM is continuously pretrained on synthetic dataset with multi-task learning.","Modify,Clarity",Clarity
1137,151-ARR,151-ARR_v2_6@7,151-ARR_v1_6@7,"Besides, our proposed models, named UniTE-MRA and UniTE-UP respectively, can benefit from finetuning with human-annotated data over three tasks at once, not requiring extra task-specific training.","Besides, our proposed models, named as UniTE-MRA and UniTE-UP respectively, can benefit from finetuning with human-annotated data over three tasks at once, not requiring extra taskspecific training.","Modify,Grammar",Grammar
1138,151-ARR,151-ARR_v2_2@3,151-ARR_v1_2@2,"This limits the convenience of these methods, and overlooks the commonalities among tasks.",This limits the convenience of these methods and overlooks commonalities among tasks.,"Modify,Grammar",Grammar
1139,151-ARR,151-ARR_v2_7@1,151-ARR_v1_7@1,"Compared to various strong baseline systems on each task, UniTE, which unifies REF , SRC and SRC+REF tasks into one single model, achieves consistently absolute improvements of Kendall's τ correlations at 1.1, 2.3 and 1.1 scores on English-targeted translation directions of WMT 2019 Metric Shared task (Fonseca et al., 2019), respectively.","Compared to different strong baseline systems on each task, UniTE, which unifies REF , SRC and SRC+REF tasks into one single model, achieves consistently absolute improvements of Kendall's τ correlations at 1.1, 2.3 and 1.1 scores on English-targeted translation directions of WMT 2019 Metric Shared task (Fonseca et al., 2019), respectively.","Modify,Clarity",Clarity
1140,151-ARR,151-ARR_v2_11@4,151-ARR_v1_11@4,"However, recent studies pointed out that these metrics have low consistency with human judgments and insufficiently evaluate high-qualified MT systems (Freitag et al., 2020;Rei et al., 2020;Mathur et al., 2020a).","However, recent studies pointed out that these metrics have low consistency with human judgments and insufficiently evaluate high-qualified MT systems (Freitag et al., 2020;Rei et al., 2020;Mathur et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1141,151-ARR,151-ARR_v2_12@0,151-ARR_v1_12@0,"Consequently, with the rapid development of PLMs, researchers have been paying their attention to model-based approaches.","Consequently, with the rapid development of PLMs, researchers have been paying their attention in model-based approaches.","Modify,Grammar",Grammar
1142,151-ARR,151-ARR_v2_12@1,151-ARR_v1_12@1,"The basic idea of these studies is to collect sentence representations for similarity calculation (BERTScore, Zhang et al., 2020) or evaluating probabilistic confidence (PRISM-ref, Thompson and Post, 2020;BARTScore, Yuan et al., 2021).","The basic idea of these studies is to collect sentences representations for similarity calculation (BERTScore, Zhang et al., 2020) or evaluating probabilistic confidence (PRISM-ref, Thompson and Post, 2020;BARTScore, Yuan et al., 2021).","Modify,Grammar",Grammar
1143,151-ARR,151-ARR_v2_2@5,151-ARR_v1_2@4,"Concretely, we propose monotonic regional attention to control the interaction among input segments, and unified pretraining to better adapt multi-task learning.","Concretely, we propose monotonic regional attention to control the interaction among input segments, and unified pretraining to better adapt multi-task training.","Modify,Clarity",Clarity
1144,151-ARR,151-ARR_v2_2@6,151-ARR_v1_2@5,We testify our framework on WMT 2019 Metrics and WMT 2020 Quality Estimation benchmarks.,We empirically testify our framework on WMT 2019 Metrics and WMT 20 Quality Estimation benchmarks.,"Modify,Fact/Evidence",Fact/Evidence
1145,152-ARR,152-ARR_v2_78@2,,Our proposed methods increases corpus size by a slightly larger factor because sentences that contain rare entity types are resampled multiple times.,,"Add,Fact/Evidence",Fact/Evidence
1146,152-ARR,152-ARR_v2_78@3,,"Although increased training corpus size leads to increased training time, note that our methods are especially suitable for scenarios where the annotated corpus is small and hence the training time is still relatively short.",,"Add,Claim",Claim
1147,152-ARR,152-ARR_v2_78@4,,"Each NER model (Shallow, Bi-LSTM, BERT) is associated with a cluster of vectors sharing the same starting point in the space, which represents the performance on the original corpus.",,"Add,Fact/Evidence",Fact/Evidence
1148,152-ARR,152-ARR_v2_82@0,,Note that data augmentation and sentence-level resampling (and resampling methods in general) are complementary methods for improving NER model training.,,"Add,Claim",Claim
1149,152-ARR,152-ARR_v2_82@1,,"Data augmentation improves the semantic richness of training instances by expanding the coverage of training data in the input feature space, while sentence-level resampling refines the importance weighting of training instances by bridging the gap between the training objective and evaluation metrics.",,"Add,Claim",Claim
1150,152-ARR,152-ARR_v2_82@2,,"Therefore, they work in orthogonal directions.",,"Add,Claim",Claim
1151,152-ARR,152-ARR_v2_82@3,,This points to a promising direction for future work: to explore the two line of methods in combination rather than in competition.,,"Add,Claim",Claim
1152,152-ARR,152-ARR_v2_21@4,152-ARR_v1_20@4,"By direct analogy, sentence importance score measures the utility of a sentence with respect to the entities it contains.","By direct analogy, a sentence importance score measures the utility of a sentence respect to the entity tokens it contains.","Modify,Grammar",Grammar
1153,152-ARR,152-ARR_v2_4@0,152-ARR_v1_4@0,"In natural language processing, named entity recognition (NER) is an important task both on its own and for numerous downstream tasks such as entity linking and question answering.","In natural language processing, named entity recognition (NER) is an important task both on its own and supports numerous downstream tasks such as entity linking and question answering.","Modify,Clarity",Clarity
1154,152-ARR,152-ARR_v2_33@1,152-ARR_v1_32@1,By introducing the rareness of an entity type we propose another function called the smoothed resampling incorporating count and rareness (sCR):,By introducing rareness of an entity type we propose another function called smoothed resampling incorporating count and rareness (sCR):,"Modify,Grammar",Grammar
1155,152-ARR,152-ARR_v2_38@0,152-ARR_v1_38@0,We use √ l s instead of l s to slow down the decrease of f sCRD s when a sentence is too long.,We use √ l s instead of l s because to slow down the decrease of f sCRD s when a sentence is too long.,"Modify,Grammar",Grammar
1156,152-ARR,152-ARR_v2_40@0,152-ARR_v1_40@0,"Here, c(t, s) applies a sublinear increasing function on c(t, s) to implement the diminishing marginal utility when a sentence contains many tokens with the same type.","Here, c(t, s) applies a sublinearly increasing function on c(t, s) to implement the diminishing marginal utility when a sentence contains many tokens with the same type.","Modify,Grammar",Grammar
1157,152-ARR,152-ARR_v2_71@3,152-ARR_v1_69@3,"Similar observation was made by previous work (Devlin et al., 2018).","Similar observations was made by previous work (Devlin et al., 2018).","Modify,Grammar",Grammar
1158,152-ARR,152-ARR_v2_72@1,152-ARR_v1_70@1,These benefits become less salient on large corpus (CoNLL).,These benefit becomes less salient on large corpus (CoNLL).,"Modify,Grammar",Grammar
1159,152-ARR,152-ARR_v2_79@0,152-ARR_v1_77@0,Conclusion and Future Work,Conclusion,"Modify,Other",Other
1160,152-ARR,152-ARR_v2_83@0,152-ARR_v1_80@0,Various other avenues exist for future work.,There are multiple avenues for future work.,"Modify,Clarity",Clarity
1161,152-ARR,152-ARR_v2_83@1,152-ARR_v1_80@1,"First, further theoretical and empirical research can explore more effective resampling functions that deliver consistently better performance across corpora and base NER models.","First, further theoretical and empirical research can explore more effective resampling functions that deliver consistently better performance across corpora and base models.","Modify,Clarity",Clarity
1162,152-ARR,152-ARR_v2_83@2,152-ARR_v1_80@2,"Second, more corpora and models can be examined under these resampling strategies to evaluate their generalizability.","Second, more corpora and models can be examined under these resampling strategies.","Modify,Claim",Claim
1163,152-ARR,152-ARR_v2_83@4,152-ARR_v1_80@4,Future research may seek for corpora-level statistics that can assist practitioners in selecting the appropriate resampling methods.,Future research may seek for corpora-level statistics that can assist practitioners in the process of selecting the appropriate resampling method(s).,"Modify,Clarity",Clarity
1164,152-ARR,152-ARR_v2_6@4,152-ARR_v1_5@4,"Data augmentation was shown to be effective by enriching entity-bearing sentences through methods like segment shuffling and mention replacement (Dai and Adel, 2020;Issifu and Ganiz, 2021;Wang and Henao, 2021).","Data augmentation was shown to be effective by enriching entity-bearing sentences through methods like segment shuffling and mention replacement (Dai and Adel, 2020).","Modify,Fact/Evidence",Fact/Evidence
1165,152-ARR,152-ARR_v2_13@0,152-ARR_v1_11@0,"Researchers have proposed various techniques for imbalanced learning, including resampling and cost-sensitive learning (He and Garcia, 2009).","Researchers have proposed various techniques for imbalanced learning, including resampling and cost-sensitive learning (He and Ma, 2013).","Modify,Fact/Evidence",Fact/Evidence
1166,155-ARR,,155-ARR_v1_85@4,,Table 5: The defense results of different AT methods against two combinatorial optimization attacks.,"Delete,Fact/Evidence",Fact/Evidence
1167,155-ARR,,155-ARR_v1_85@5,,We remove ASR % due to the space limit.,"Delete,Fact/Evidence",Fact/Evidence
1168,155-ARR,,155-ARR_v1_98@3,,We can also conclude that DeBERTa is significantly more robust than RoBERTa.,"Delete,Claim",Claim
1169,155-ARR,155-ARR_v2_48@1,155-ARR_v1_50@1,Take PGD-K as an instance.,Take PGD-K for instance.,"Modify,Grammar",Grammar
1170,155-ARR,155-ARR_v2_4@0,155-ARR_v1_4@0,"Deep neural networks (DNNs) have achieved great success on many natural language processing (NLP) tasks (Kim, 2014;Vaswani et al., 2017;Devlin et al., 2019).","Deep neural networks (DNNs) outperform humans on many natural language processing (NLP) tasks (Kim, 2014;Vaswani et al., 2017;Devlin et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
1171,155-ARR,155-ARR_v2_4@1,155-ARR_v1_4@1,"However, recent studies (Szegedy et al., 2013;Goodfellow et al., 2015) have shown that DNNs are vulnerable to crafted adversarial examples .","However, recent studies have shown that DNNs are vulnerable to crafted adversarial examples (Szegedy et al., 2013;Goodfellow et al., 2014).","Modify,Fact/Evidence",Fact/Evidence
1172,155-ARR,155-ARR_v2_72@0,155-ARR_v1_74@0,"Regarding the training settings and hyperparameters, the optimizer is AdamW (Loshchilov and Hutter, 2019); the learning rate is 2e −5 ; the number of epochs is 10; the batch size is 64 for SST-2 and 24 for IMDb; the maximum sentence length kept for all the models is 40 for SST-2 and 200 for IMDb.","Regarding the training settings and hyperparameters, the optimizer is AdamW (Loshchilov and Hutter, 2019); the learning rate is 2e −5 ; the number of epochs is 10; the batch size is 64 for SST-2 and 24 for IMDb.","Modify,Fact/Evidence",Fact/Evidence
1173,155-ARR,155-ARR_v2_2@4,155-ARR_v1_2@4,"Inspired by this, we propose friendly adversarial data augmentation (FADA) to generate friendly adversarial data.","Inspired by this, we propose friendly adversarial data augmentation (FADA) to generate ""friendly"" adversarial data.","Modify,Grammar",Grammar
1174,155-ARR,155-ARR_v2_21@3,155-ARR_v1_22@3,Goodfellow et al. (2015) proposed fast gradient sign method (FGSM) to obtain δ by one step:,Goodfellow et al. (2014) proposed fast gradient sign method (FGSM) to obtain δ by one step:,"Modify,Fact/Evidence",Fact/Evidence
1175,155-ARR,155-ARR_v2_2@5,155-ARR_v1_2@5,"On top of FADA, we propose geometry-aware adversarial training (GAT) to perform adversarial training on friendly adversarial data so that we can save a large number of search steps.","On top of FADA, we propose geometry-aware adversarial training (GAT) to perform adversarial training (e.g., FGM) on friendly adversarial data so that we can save a large number of search steps.","Modify,Clarity",Clarity
1176,155-ARR,155-ARR_v2_28@1,155-ARR_v1_30@1,Miyato et al. (2017) find that adversarial and virtual adversarial training have good regularization performance.,Miyato et al. (2016) find that adversarial and virtual adversarial training have good regularization performance.,"Modify,Fact/Evidence",Fact/Evidence
1177,155-ARR,155-ARR_v2_30@0,155-ARR_v1_32@0,"Besides, adversarial data augmentation is another effective approach to improve robustness (Ebrahimi et al., 2018;Li et al., 2019;Ren et al., 2019;Jin et al., 2019;Zang et al., 2020;Li et al., 2020;Garg and Ramakrishnan, 2020;Si et al., 2021).","Besides, adversarial data augmentation is another effective approach to improve robustness (Ebrahimi et al., 2017;Li et al., 2018;Ren et al., 2019;Jin et al., 2019;Zang et al., 2020;Li et al., 2020;Garg and Ramakrishnan, 2020;Si et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
1178,155-ARR,155-ARR_v2_2@6,155-ARR_v1_2@6,Comprehensive experiments across two widely used datasets and three pretrained language models demonstrate that GAT can obtain stronger robustness via fewer steps.,Comprehensive experiments across two widely used datasets and three pre-trained language models demonstrate that GAT can obtain stronger robustness via less steps.,"Modify,Grammar",Grammar
1179,156-ARR,,156-ARR_v1_96@0,,"As the results shown in Table 4, the combination of TurnAPE and RoleAPE achieve the best performance.","Delete,Fact/Evidence",Fact/Evidence
1180,156-ARR,,156-ARR_v1_96@1,,"Both absolute and relative position embeddings improve model performance, nevertheless, including them at the same time can be harmful.","Delete,Claim",Claim
1181,156-ARR,,156-ARR_v1_108@0,,"In this paper, different ethical restrictions deserve discussion.","Delete,Claim",Claim
1182,156-ARR,,156-ARR_v1_109@0,,All data used in our pre-training are available online and other dialog corpus in this paper are publicly available sources.,"Delete,Fact/Evidence",Fact/Evidence
1183,156-ARR,,156-ARR_v1_109@1,,We strictly followed the platform's policies and rules when crawling data from web platforms.,"Delete,Fact/Evidence",Fact/Evidence
1184,156-ARR,,156-ARR_v1_109@2,,We did not employ any author-specific information in our research.,"Delete,Fact/Evidence",Fact/Evidence
1185,156-ARR,,156-ARR_v1_110@0,,"Our corpus may includes some bias, such as political bias and social bias, and our model might have inherited some forms of these bias.","Delete,Claim",Claim
1186,156-ARR,,156-ARR_v1_110@1,,"In order to limit these bias as much as possible, we filter controversial articles and removed data with offensive information when possible.","Delete,Fact/Evidence",Fact/Evidence
1187,156-ARR,,156-ARR_v1_112@0,,"We demonstrate the responses generated from our model as well as other baseline models in Table 7, 8 and 9, respectively.","Delete,Fact/Evidence",Fact/Evidence
1188,156-ARR,,156-ARR_v1_112@1,,The results in Table 8 and 9 show that our model accurately outputs the knowledge information contained in context although we do not model knowledge explicitly.,"Delete,Fact/Evidence",Fact/Evidence
1189,156-ARR,156-ARR_v2_20@1,,The n-stream self-attention mechanism incorporates n extra self-attention predicting streams besides main stream to predict next n continuous future tokens respectively at each time step.,,"Add,Fact/Evidence",Fact/Evidence
1190,156-ARR,,156-ARR_v1_10@0,,"Our pre-trained models and source code will be released, hoping to facilitate further research progress in dialogue generation.","Delete,Claim",Claim
1191,156-ARR,156-ARR_v2_68@2,,We obtain 215 million 1 training samples (42GB in total) for pre-training.,,"Add,Fact/Evidence",Fact/Evidence
1192,156-ARR,156-ARR_v2_69@0,,"To accelerate the training process and accommodate GPU memory limitations, we adopt two methods.",,"Add,Fact/Evidence",Fact/Evidence
1193,156-ARR,156-ARR_v2_69@1,,"First, we sort the samples according to the length of the context.",,"Add,Fact/Evidence",Fact/Evidence
1194,156-ARR,156-ARR_v2_69@2,,Samples with similar length (i.e. number of tokens in context) are assembled into a batch to minimize the amount of padding.,,"Add,Fact/Evidence",Fact/Evidence
1195,156-ARR,156-ARR_v2_69@3,,"Secondly, due to the uneven distribution of sample lengths, we divide the Reddit corpus into two sub-datasets: Reddit-Short and Reddit-Long according to the length of context and response.",,"Add,Fact/Evidence",Fact/Evidence
1196,156-ARR,156-ARR_v2_109@0,,This paper proposes a new pre-training framework for dialogue response generation called Di-alogVED.,,"Add,Fact/Evidence",Fact/Evidence
1197,156-ARR,156-ARR_v2_109@1,,"The latent variable is incorporated into the sequence-to-sequence framework based on Transformer, and obtains a robust and diverse response generation model through 4 training targets.",,"Add,Fact/Evidence",Fact/Evidence
1198,156-ARR,156-ARR_v2_109@3,,Extensive experiments prove the effectiveness of our model.,,"Add,Claim",Claim
1199,156-ARR,156-ARR_v2_109@4,,Additional human evaluation demonstrates the advantages of our proposed model.,,"Add,Claim",Claim
1200,156-ARR,156-ARR_v2_86@0,156-ARR_v1_83@0,"As shown in Table 2 and Table 3, our model Di-alogVED is very competitive compared to PLATO and other models.","As shown in Table 2 and Table 6 (in Appendix A), our model DialogVED is very competitive compared to PLATO and other models.","Modify,Fact/Evidence",Fact/Evidence
1201,156-ARR,156-ARR_v2_105@1,156-ARR_v1_103@1,"These models introduce discourse-level diversity and are able to generate diverse dialog responses (Serban et al., 2017;Zhao et al., 2017a.","These models introduce discourse-level diversity and are able to generate diverse dialog responses (Serban et al., 2017;Zhao et al., 2017aZhao et al., , 2018.","Modify,Fact/Evidence",Fact/Evidence
1202,156-ARR,156-ARR_v2_87@2,156-ARR_v1_111@2,"However, DialogVED equipped with beam search or greedy search, can still easily beat PLATO even though it has a post-generation ranking component.","However, DialogVED equipped with beam or search, can still easily beat PLATO even though it has a post-generation ranking component.","Modify,Clarity",Clarity
1203,156-ARR,156-ARR_v2_10@0,156-ARR_v1_10@1,"The main contributions of this paper can be summarized as follows: 1) We propose a pretrained dialog model, which incorporates continuous latent variables into the enhanced encoder-decoder pre-training framework; 2) We explore the impact of latent variable sizes, different decoding strategies, and position embeddings for turns and roles in our model; 3) Extensive experiments show that the proposed model achieves the new state-of-theart (SOTA) in multiple downstream tasks, and our model has better performance both on relevance and diversity than previous SOTA in response generation.","The main contributions of this paper can be summarized as follows: 1) We propose a pretrained dialog model, which incorporates continuous latent variables into the enhanced encoder-decoder pre-training framework; We explore the impact of latent variable sizes, different decoding strategies, and position embeddings for turns and roles in our model; Extensive experiments show that the proposed model achieves the new state-of-the-art (SOTA) in multiple downstream tasks, and our model has better performance both on relevance and diversity than previous SOTA in response generation.","Modify,Grammar",Grammar
1204,157-ARR,,157-ARR_v1_30@0,,Figure 2 shows the relevance of different content (columns) for the various stakeholders (the rows) for a 10K filing document.,"Delete,Fact/Evidence",Fact/Evidence
1205,157-ARR,,157-ARR_v1_30@1,,Groups of stakeholders are made that form the personas interested in the different parts of the document.,"Delete,Fact/Evidence",Fact/Evidence
1206,157-ARR,,157-ARR_v1_30@2,,The different columns are also grouped together as to indicate what kind of information those sections will contain.,"Delete,Fact/Evidence",Fact/Evidence
1207,157-ARR,,157-ARR_v1_53@0,,Table 5: Results from the human experiment on using the Default Reading experience with DYNAMICTOC.,"Delete,Other",Other
1208,157-ARR,157-ARR_v2_30@0,,We can map these columns to the aspects we get from the Aspect Detection Module and determine if a particular persona is interested in that paragraph or not.,,"Add,Fact/Evidence",Fact/Evidence
1209,157-ARR,157-ARR_v2_29@0,157-ARR_v1_28@0,"We consulted a domain expert (financial domain; specifically for SEC 10-K filings) to create a matrix of personas, who read such documents, and what kind of information they are interested in.",We consulted a domain expert (financial domain; specifically for SEC 10-K filings) to get an understanding of the parties or personas who read such documents and what kind of information are they generally interested in.,"Modify,Clarity",Clarity
1210,157-ARR,157-ARR_v2_29@1,157-ARR_v1_28@1,Figure 2 lists out the various stakeholders of a general 10-K filing against the different sections of the document each stakeholder is interested in.,We constructed a matrix listing out the various stakeholders of a general 10-K filing against the different sections of the document each stakeholder is interested in.,"Modify,Fact/Evidence",Fact/Evidence
1211,157-ARR,157-ARR_v2_29@2,157-ARR_v1_28@2,"The stakeholders are grouped together to form the personas used in DYNAMICTOC, viz. employees, business partners, investors and lendors, financial bodies and advisory and regulatory firms.","The stakeholders were grouped together to form the personas used in DYNAMICTOC, viz. employees, business partners, investors and lendors, financial bodies and advisory regulatory firms.","Modify,Grammar",Grammar
1212,157-ARR,157-ARR_v2_29@3,157-ARR_v1_28@3,"Similarly, the columns (headings) are grouped together according to similarity to create a mapping of topics of interest for each persona.","Similarly, the columns (headings) were grouped together according to similarity to create a mapping of topics of interest for each persona.","Modify,Grammar",Grammar
1213,157-ARR,157-ARR_v2_30@1,157-ARR_v1_29@0,"For this, the aspects obtained from the unsupervised technique are compared against the simplified column values from the constructed matrix.",The aspects we got from our unsupervised technique were compared against the simplified column values from the constructed matrix.,"Modify,Clarity",Clarity
1214,157-ARR,157-ARR_v2_30@2,157-ARR_v1_29@1,The columns with the greatest similarity (above a threshold) are associated with each persona.,The columns with the greatest similarity (above a threshold) were associated with each persona.,"Modify,Grammar",Grammar
1215,157-ARR,157-ARR_v2_30@3,157-ARR_v1_29@2,"For getting the personas interested in each paragraph, the paragraphs are first tagged for aspect.","For getting the personas interested in each paragraph, the paragraphs were first tagged for aspect.","Modify,Grammar",Grammar
1216,157-ARR,157-ARR_v2_30@4,157-ARR_v1_29@3,"From the resultant vector (which represents the confidence score of the text for each aspect), the combined score for each persona is calculated using the scores of its constituent aspects.","From the resultant vector (which represents the confidence score of the text for each aspect), the combined score for each persona was calculated using the scores of its constituent aspects.","Modify,Grammar",Grammar
1217,157-ARR,157-ARR_v2_31@1,157-ARR_v1_31@1,"Note that for financial documents, we were able to gather domain knowledge and leverage it to obtain the persona space.","The thing to note here is, for financial documents, we were able to get some domain knowledge and leveraged it to obtain the persona space.","Modify,Clarity",Clarity
1218,157-ARR,157-ARR_v2_31@2,157-ARR_v1_31@2,But the proposed technique is generalizable to other domains as well.,But the technique we are proposing is generalizable to other domains as well.,"Modify,Clarity",Clarity
1219,157-ARR,157-ARR_v2_34@5,157-ARR_v1_34@5,We use ELI5 dataset for training the model.,"We use ELI5 (Fan et al., 2019) dataset for training the model.","Modify,Fact/Evidence",Fact/Evidence
1220,157-ARR,157-ARR_v2_55@1,157-ARR_v1_60@1,"Financial documents are high value documents for businesses, and are often long and complex.","Financial documents and contracts are high value documents for business entities, and are often long and complex.","Modify,Claim",Claim
1221,157-ARR,157-ARR_v2_55@2,157-ARR_v1_60@2,The default ToC-based reading experience is quite limited and document consumption can be enhanced using intelligent technologies.,The default ToC-based reading experience is quite limited and there are immense opportunities to enhance the document consumption using intelligent technologies.,"Modify,Clarity",Clarity
1222,157-ARR,157-ARR_v2_55@3,157-ARR_v1_60@3,DY-NAMICTOC is one of the first works to pursue this exciting research direction.,"We believe that DYNAMICTOC is one of the first works to pursue this exciting research direction, and would enable further exploration in the area.","Modify,Claim",Claim
1223,157-ARR,157-ARR_v2_55@4,157-ARR_v1_61@0,DYNAMICTOC would benefit from in-domain learning of aspect keywords and questions.,"For the future direction, DYNAMICTOC would benefit from a better supervised in-domain learning of aspect keywords and questions.","Modify,Clarity",Clarity
1224,157-ARR,157-ARR_v2_55@5,157-ARR_v1_61@1,Evaluation of paragraph segmentation and mapping of personas to the aspects are future directions.,We would also like to work on evaluation of the paragraph segmentation and mapping of personas to the aspects in future.,"Modify,Clarity",Clarity
1225,157-ARR,157-ARR_v2_55@6,157-ARR_v1_61@2,A better understanding of personas would generalize the work to different domains.,A better understanding of personas or entities interested in consuming the document would help to generalize the work to different domains.,"Modify,Claim",Claim
1226,157-ARR,157-ARR_v2_7@2,157-ARR_v1_7@2,"Keyword detection (Liu et al., 2009;Tixier et al., 2016) & topic modeling (Blei et al., 2001) works aim is to describe the document by a few important words or topics for concise representation.","Keyword detection (Liu et al., 2009;Tixier et al., 2016) & topic modeling (Blei et al., 2003) works aim is to describe the document by a few important words or topics for concise representation.","Modify,Fact/Evidence",Fact/Evidence
1227,157-ARR,157-ARR_v2_7@4,157-ARR_v1_7@4,"Another task is compact and informative headline generation from a document (Dorr et al., 2003;Lopyrev, 2015).","Another task is compact and informative headline generation from a document (David and Zajic, 2003;Lopyrev, 2015).","Modify,Fact/Evidence",Fact/Evidence
1228,157-ARR,157-ARR_v2_8@4,157-ARR_v1_8@4,"Early unsupervised systems are dominated by Latent Dirichlet Allocation (LDA)-based topic models (García-Pablos et al., 2018;Shi et al., 2018;Álvarez-López et al., 2016).","Early unsupervised systems are dominated by Latent Dirichlet Allocation (LDA)-based topic models (García-Pablos et al., 2018;Shi et al., 2018;Alvarez-López et al., 2016).","Modify,Grammar",Grammar
1229,160-ARR,160-ARR_v2_19@7,,"For MBTI, users were able to provide multiple texts, we report unique users in parentheses.",,"Add,Fact/Evidence",Fact/Evidence
1230,160-ARR,160-ARR_v2_29@1,,"The model consists of 3 concatenated CNN layers with kernel size of 1, 2 and 3 respectively.",,"Add,Fact/Evidence",Fact/Evidence
1231,160-ARR,160-ARR_v2_29@2,,"Each layer has a filter size of 256, rectified linear unit (ReLU) activation, L2 regularization (0.001), and global max pooling.",,"Add,Fact/Evidence",Fact/Evidence
1232,160-ARR,160-ARR_v2_29@3,,The models were trained for 35 epochs with a batch size of 32 and learning rate of 1e −4 .,,"Add,Fact/Evidence",Fact/Evidence
1233,160-ARR,160-ARR_v2_30@1,,We kept all parameters the same as in the original paper based on their publically available implementation.,,"Add,Fact/Evidence",Fact/Evidence
1234,160-ARR,160-ARR_v2_31@1,,We used BERT-base-uncased and RoBERTa-base model loaded from the transformers library.,,"Add,Fact/Evidence",Fact/Evidence
1235,160-ARR,160-ARR_v2_32@0,,"We fine-tuned BERT and RoBERTa model for five epochs using the following hyperparameters: a batch size to 32, learning rate of 1e −5 , weight decay of 0.01.",,"Add,Fact/Evidence",Fact/Evidence
1236,160-ARR,160-ARR_v2_32@1,,We saved the final model that achieves the lowest loss on validation set.,,"Add,Fact/Evidence",Fact/Evidence
1237,160-ARR,160-ARR_v2_33@1,,We obtained the gender word lists and stereotype word lists 4 .,,"Add,Fact/Evidence",Fact/Evidence
1238,160-ARR,160-ARR_v2_33@2,,We used Newscommentary-v15 corpus 4 as the external corpus to locate sentences where the gender and stereotype words occur and then debias.,,"Add,Fact/Evidence",Fact/Evidence
1239,160-ARR,160-ARR_v2_33@3,,"All BERT or RoBERTa layers are debiased at the token level, and the debiasing loss weight is set to 0.8.",,"Add,Fact/Evidence",Fact/Evidence
1240,160-ARR,160-ARR_v2_34@2,,"All prediction models, debiasing models are trained on a NVIDIA GeForce RTX 3090 GPU card, with 11.2 CUDA version.",,"Add,Fact/Evidence",Fact/Evidence
1241,160-ARR,160-ARR_v2_18@0,160-ARR_v1_20@0,"Pretrained word embeddings, including static word embeddings such as GloVe and contextualized word embeddings such as BERT, contain humanlike biases and stereotypical associations (Caliskan et al., 2017;Garg et al., 2018;May et al., 2019).","Pretrained word embeddings, including static word embeddings such as GloVe and contexualized word embeddings such as BERT, contain human-like biases and stereotypical associations (Caliskan et al., 2017;Garg et al., 2018;May et al., 2019).","Modify,Grammar",Grammar
1242,160-ARR,160-ARR_v2_19@0,160-ARR_v1_21@0,"Given the wide adoption of transformer-based contextualized embedding models, recent research has investigated bias mitigation in models such as BERT and RoBERTa (Zmigrod et al., 2019;Webster et al., 2020;Garimella et al., 2021;Kaneko and Bollegala, 2021;Guo et al., 2022).","Given the wide adoption of transformer-based contextualized embedding models, recent research has investigated bias mitigation in models such as BERT and RoBERTa (Zmigrod et al., 2019;Webster et al., 2020;Garimella et al., 2021;Kaneko and Bollegala, 2021).","Modify,Fact/Evidence",Fact/Evidence
1243,160-ARR,160-ARR_v2_19@1,160-ARR_v1_21@1,Existing methods for debiasing static and contextualized embeddings have alleviated representational harm along demographic dimensions such as gender.,Existing methods for debiasing static and contextualized embeddings have undoubtedly moved the needle on alleviating representational harm along demographic dimensions such as gender.,"Modify,Clarity",Clarity
1244,160-ARR,160-ARR_v2_55@5,160-ARR_v1_50@9,"Though not depicted in the main paper, plots for RoBERTa show similar trends to those observed for BERT while debiasing with ContextED (see Appendix A).","Though not depicted in the main paper, plots for RoBERTa show similar trends to those observed for BERT while debiasing with ContextED (see Appendix B).","Modify,Fact/Evidence",Fact/Evidence
1245,160-ARR,160-ARR_v2_11@5,160-ARR_v1_12@5,"Towards this goal, the code and data used in this work is publicly available via GitHub.","Towards this goal, we have included code/data and will make them publicly available via GitHub upon publication.","Modify,Clarity",Clarity
1246,161-ARR,,161-ARR_v1_35@6,,The rightmost columns of Table 1 show that having a single model does not adversely impact performance.,"Delete,Fact/Evidence",Fact/Evidence
1247,161-ARR,,161-ARR_v1_35@7,,A more detailed discussion is present in Appendix E.,"Delete,Fact/Evidence",Fact/Evidence
1248,161-ARR,,161-ARR_v1_48@0,,We mention the acquisition functions used below:,"Delete,Fact/Evidence",Fact/Evidence
1249,161-ARR,,161-ARR_v1_52@2,,"We also tried normalizing by N 2 , as well as a globally normalized probability of d ˚(probability of the tree over all possible valid trees, with the partition function computed using the Matrix Tree Theorem (Koo et al., 2007;Smith and Smith, 2007)), but found both to perform worse.","Delete,Fact/Evidence",Fact/Evidence
1250,161-ARR,,161-ARR_v1_63@0,,"Tables 3, 4, 5 and 6 show the performance of the different AL settings on English, Spanish, Dutch and German respectively.","Delete,Fact/Evidence",Fact/Evidence
1251,161-ARR,,161-ARR_v1_63@1,,"Each table shows the F-score across 4 acquisition rounds, both with and without MNLP ( §3.2).","Delete,Fact/Evidence",Fact/Evidence
1252,161-ARR,,161-ARR_v1_63@2,,"This section shows the plots for the performance of an mBERT model trained on de (the source language) in a MonoAL setting relative to the performance of an mBERT model trained on all de data available (100% data, without AL).","Delete,Fact/Evidence",Fact/Evidence
1253,161-ARR,,161-ARR_v1_63@3,,The performance plots are shown for the dependency parsing (Figure 24) and NER (Figure 25) tasks.,"Delete,Fact/Evidence",Fact/Evidence
1254,161-ARR,161-ARR_v2_30@0,,"Dependency Parsing We use a subset of treebanks with 5 languages (English (en), Spanish (es), German (de), Dutch (nl), Japanese (ja)) from the full Universal Dependencies v2.3 corpus (Nivre et al., 2018); a total of 11 treebanks.",,"Add,Fact/Evidence",Fact/Evidence
1255,161-ARR,161-ARR_v2_37@3,,Here MNLP is the AL method adopted for NER.,,"Add,Fact/Evidence",Fact/Evidence
1256,161-ARR,161-ARR_v2_37@7,,"Here, LC is the AL method adopted for classification.",,"Add,Fact/Evidence",Fact/Evidence
1257,161-ARR,161-ARR_v2_42@2,,The bars (left y-axis) represent the relative fraction of cumulative tokens acquired per language compared to random sampling.,,"Add,Fact/Evidence",Fact/Evidence
1258,161-ARR,161-ARR_v2_42@3,,The lines (right y-axis) show the difference of performance of the language when compared to its 100% data performance (MM).,,"Add,Fact/Evidence",Fact/Evidence
1259,161-ARR,161-ARR_v2_42@4,,"Notice that the model tends to favor acquiring data from languages that underperform compared to their 100% counterpart (here, es and de).",,"Add,Fact/Evidence",Fact/Evidence
1260,161-ARR,161-ARR_v2_42@5,,This in turn helps the model to arbitrate its acquisitions so as to achieve similar performance (relative to 100% performance) across all languages (indicated by the convergence of the line plots).,,"Add,Claim",Claim
1261,161-ARR,161-ARR_v2_46@0,,"In this section, we elaborate on the task specific adaptations:",,"Add,Fact/Evidence",Fact/Evidence
1262,161-ARR,161-ARR_v2_63@0,,Table 13 compares the performance (LAS and UAS) of the single model trained on all data to the performance of one model trained per language.,,"Add,Fact/Evidence",Fact/Evidence
1263,161-ARR,161-ARR_v2_63@1,,"Table 14 gives the detailed breakdown of each AL setup for each of the dependency parsing datasets, aggregated across all the acquisition rounds. ) is poor on all other languages (Fig. 17,18,20,21,22,23,25,26), while the performance of all other languages is poor on Japanese (Fig. 19, 24).",,"Add,Fact/Evidence",Fact/Evidence
1264,161-ARR,161-ARR_v2_63@2,,"Consequently, the graphs below have a kink in order to capture this difference in the range of performance of the languages.",,"Add,Fact/Evidence",Fact/Evidence
1265,161-ARR,161-ARR_v2_59@1,161-ARR_v1_59@1,"We observe this to be the case consistently for both the NER and the classification tasks (refer Figure 4), regardless of the source language.","We observe this to be the case consistently for both the NER and the classification tasks (refer Figure 4 for classification and Appendix I for the other tasks), regardless of the source language.","Modify,Fact/Evidence",Fact/Evidence
1266,161-ARR,161-ARR_v2_6@2,161-ARR_v1_9@2,"Recently, another direction that has gained popularity has been leveraging multilingual pre-trained language models (MPLMs) which inherently map multiple languages to a common embedding space (Devlin et al., 2019;Conneau et al., 2020).","Recently, another direction that has gained popularity has been leveraging multilingaul pre-trained language models (MPLMs) which inherently map multiple languages to a common embedding space (Devlin et al., 2019;Conneau et al., 2020).","Modify,Grammar",Grammar
1267,161-ARR,161-ARR_v2_60@9,161-ARR_v1_61@0,Figures 5 and 6 show the acquisition curriculum.,Figures 5 and 6 show the acquisition (as described in Appendix G for both the classification and NER tasks.,"Modify,Fact/Evidence",Fact/Evidence
1268,161-ARR,161-ARR_v2_9@0,161-ARR_v1_11@7,We release our code at https://github.,We release our code at URL.,"Modify,Fact/Evidence",Fact/Evidence
1269,161-ARR,161-ARR_v2_14@0,161-ARR_v1_16@0,Task Specific Models,Task Specific Models:,"Modify,Grammar",Grammar
1270,161-ARR,161-ARR_v2_15@1,161-ARR_v1_17@1,"We use the standard training methodology for the tasks: For classification, we use a single layer over the [CLS] embedding.","We use the standard training methodology for the tasks: for classification, we use a single layer over the [CLS] embedding, for sequence tagging, we use a single layer for each word to predict its tag, and for dependency parsing, we follow Kondratyuk and Straka (2019) and use mBERT embeddings with the graph-based bi-affine attention parser (Dozat and Manning, 2017); refer Appendix A for details.","Split+Modify,Grammar",Grammar
1273,161-ARR,161-ARR_v2_21@0,161-ARR_v1_23@0,Active Learning Acquisition Strategies,Active Learning Acquisition Strategies:,"Modify,Grammar",Grammar
1274,163-ARR,163-ARR_v2_50@5,,Examples of paraphrases generated by QCP G ⋆ compared to the ground truth paraphrases appear in Table 10.,,"Add,Fact/Evidence",Fact/Evidence
1275,163-ARR,163-ARR_v2_51@1,,"Tables 5 and 6 show the BLEU scores (Papineni et al., 2002) obtained by QCPG and the uncontrolled baseline respectively.",,"Add,Fact/Evidence",Fact/Evidence
1276,163-ARR,163-ARR_v2_51@2,,The results verify that the input quality vectors induced by the target sentences are effectively utilized by QCPG to achieve better prediction performance.,,"Add,Fact/Evidence",Fact/Evidence
1277,163-ARR,163-ARR_v2_52@6,,"This advantage is statistically significant (p − value < 0.05) as obtained by applying the Wilcoxon signed-rank test to the difference between the number of annotators that voted for QCP G ⋆ and those voted for the baseline, across all datasets.",,"Add,Fact/Evidence",Fact/Evidence
1278,163-ARR,163-ARR_v2_63@5,,"In order to find the candidate similarity measure with the highest agreement with human judgments, we first computed, for each triplet, the difference between the number of annotators voted for t 2 and those voted for t 3 .",,"Add,Fact/Evidence",Fact/Evidence
1279,163-ARR,163-ARR_v2_63@6,,"We then computed for each candidate measure, the difference between the similarity of t 2 to t 1 and and of t 3 to t 1 .",,"Add,Fact/Evidence",Fact/Evidence
1280,163-ARR,163-ARR_v2_63@8,,Table 3 shows the resultant correlations.,,"Add,Fact/Evidence",Fact/Evidence
1281,163-ARR,163-ARR_v2_63@9,,"The highest correlations are obtained for SBERT (Reimers and Gurevych, 2019), but since it was trained on WikiAns and MSCOCO, we could not use it in our study.",,"Add,Fact/Evidence",Fact/Evidence
1282,163-ARR,163-ARR_v2_64@0,,We study the coupling between the different semantic similarity measures and the linguistic diversity.,,"Add,Fact/Evidence",Fact/Evidence
1283,163-ARR,163-ARR_v2_65@0,,"We assume that the level of coupling of a good similarity measure will resemble that of humans, and will be less sensitive to lexical and syntactic properties of the paraphrase.",,"Add,Claim",Claim
1284,163-ARR,163-ARR_v2_65@1,,Table 4 presents the Kendall tau correlation between the different similarity measures and the linguistic diversity.,,"Add,Fact/Evidence",Fact/Evidence
1285,163-ARR,163-ARR_v2_65@2,,Results for human judgments are also shown for a reference.,,"Add,Fact/Evidence",Fact/Evidence
1286,163-ARR,163-ARR_v2_66@0,,"The results show that Bleurt demonstrates the lowest coupling with linguistic diversity among the automatic measures (aside from SBERT which, as mentioned before, was trained with MSCOCO and WikiAns).",,"Add,Fact/Evidence",Fact/Evidence
1287,163-ARR,163-ARR_v2_66@1,,"The comparison to human judgments shows that Bleurt is more influenced by linguistic features, indicating that automatic measures need to be further improved to reach the decoupling level achieved by humans.",,"Add,Fact/Evidence",Fact/Evidence
1288,163-ARR,163-ARR_v2_2@7,163-ARR_v1_2@7,We show that our method is able to generate paraphrases which maintain the original meaning while achieving higher diversity than the uncontrolled baseline.,We show that our method is able to generate paraphrases which maintain the original meaning while achieving higher diversity than baseline.,"Modify,Clarity",Clarity
1289,163-ARR,163-ARR_v2_2@8,163-ARR_v1_2@8,"The models, the code, and the data can be found in https://github.com/IBM/quality-c ontrolled-paraphrase-generation.","We will publish the models, the code, and the data.","Modify,Fact/Evidence",Fact/Evidence
1290,163-ARR,163-ARR_v2_43@6,163-ARR_v1_39@6,The nonmonotonic behavior of the responsiveness implies that the input offsets should be selected carefully in order to optimize the quality of the resultant paraphrases.,The nonmonotonic behavior of the responsiveness implies that the input offsets should be selected carefully in order to optimize the quality of resultant paraphrases.,"Modify,Grammar",Grammar
1291,163-ARR,163-ARR_v2_50@3,163-ARR_v1_46@3,"A clear advantage is obtained even for Self-BLEU, which was not part of the metrics used as input controls.","A clear advantage is obtained even for i-BLEU, which was not part of the metrics used as input controls.","Modify,Fact/Evidence",Fact/Evidence
1292,163-ARR,163-ARR_v2_50@4,163-ARR_v1_46@4,"Importantly, the quality of the paraphrases generated by our model is comparable to, or at times better than the quality of the paraphrases in the ground truth of the datasets.","Importantly, the quality of the paraphrases generated by our model is comparable to or at times better than the quality of the paraphrases in the ground truth of the datasets.","Modify,Grammar",Grammar
1293,163-ARR,163-ARR_v2_50@6,163-ARR_v1_46@5,This is an important step towards the goal of obtaining paraphrases in the sparse area of high quality (recall the top right corner of Figure 1).,This is an important step towards the goal of obtaining paraphrases in the very sparse area of high quality (recall the top right corner of Figure 1).,"Modify,Clarity",Clarity
1294,163-ARR,163-ARR_v2_52@3,163-ARR_v1_47@3,"The annotators were shown the source sentence, along with the two generated paraphrases (randomly ordered), and were asked which of the two better preserves the semantic meaning of the source sentence (ties are also allowed).","The workers were shown the source sentence, along with the two generated paraphrases (randomly ordered), and were asked which of the two better preserves the semantic meaning of the source sentence (ties are also allowed).","Modify,Clarity",Clarity
1295,163-ARR,163-ARR_v2_52@7,163-ARR_v1_47@6,"Thus, the human evaluation is in line with the results of the automatic semantic similarity measure.","Thus, the human evaluation validates the results of the automatic semantic similarity measure.","Modify,Clarity",Clarity
1296,163-ARR,163-ARR_v2_52@8,163-ARR_v1_47@7,"We also verified, that the results of this sample, in terms of linguistic diversity, are very similar to those shown in Table 1.","We also verified, that the results of this sample in terms of linguistic diversity are very similar to those shown in Table 1.","Modify,Grammar",Grammar
1297,163-ARR,163-ARR_v2_57@1,163-ARR_v1_52@1,"One approach is to use an exemplar sentence for guiding the syntax of the generated paraphrase Bao et al., 2019;Hosking and Lapata, 2021).","One approach is to use an exemplar sentence for guiding the syntax of the generated paraphrase Bao et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
1298,163-ARR,163-ARR_v2_58@1,163-ARR_v1_53@1,"Liu et al. (2020b) optimize a quality oriented objective by casting paraphrase generation as an optimization problem, and searching the sentence space to find the optimal point.","Liu et al. (2020) optimize a quality oriented objective by casting paraphrase generation as an optimization problem, and searching the sentence space to find the optimal point.","Modify,Fact/Evidence",Fact/Evidence
1299,163-ARR,163-ARR_v2_60@0,163-ARR_v1_55@0,"In this paper, we propose a novel controlled paraphrase generation model, that leverages measures of paraphrase quality for encouraging the generation of paraphrases with desired quality.","In this paper, we propose a novel controlled paraphrase generation model, that leverages measures of paraphrase quality for encouraging the generation of high quality paraphrases.","Modify,Clarity",Clarity
1300,163-ARR,163-ARR_v2_63@0,163-ARR_v1_58@0,"Recently, several strong metrics have been proposed for measuring semantic similarity between sentences (Reimers and Gurevych, 2019;?;Sellam et al., 2020).","Recently, several strong metrics have been proposed for measuring semantic similarity between sentences.","Modify,Fact/Evidence",Fact/Evidence
1301,163-ARR,163-ARR_v2_63@3,163-ARR_v1_58@3,"Given a dataset, we randomly selected 100 clusters, and picked three sentences at random from each cluster.","Given a datset, we randomly selected 100 clusters, and picked three sentences at random from each cluster.","Modify,Grammar",Grammar
1302,163-ARR,163-ARR_v2_63@4,163-ARR_v1_58@4,"For each triplet of sentences t = (t 1 , t 2 , t 3 ) we asked 5 human annotators to choose which of the two sentences, t 2 or t 3 , better preserves the semantic meaning of t 1 .","For each triplet of sentences t = (t 1 , t 2 , t 3 ) we asked 5 human annotators to choose which of the two sentences, t 2 , t 3 better preserves the semantic meaning of t 1 .","Modify,Clarity",Clarity
1303,163-ARR,163-ARR_v2_63@7,163-ARR_v1_58@5,"We then measured Kendall's Tau correlation (Daniel, 1990) between the difference vector of the human judgments and that of the judgments of each of the candidate measures.",We then measured Spearman correlation between the human judgments and the judgments of each of the candidate metrics.,"Modify,Fact/Evidence",Fact/Evidence
1304,163-ARR,163-ARR_v2_63@10,163-ARR_v1_58@6,We selected Bleurt due to its highest correlation with human judgments over the three datasets (among the methods that were not exposed to the considered datasets).,"Based on the results, we selected Bleurt due to its highest correlation with human judgments over the three datasets.","Modify,Fact/Evidence",Fact/Evidence
1305,163-ARR,163-ARR_v2_67@2,163-ARR_v1_59@2,"For the baseline we selected the one which yielded the best BLEU score (Papineni et al., 2002) on the corresponding dev set The best learning rate for every dataset was chosen based on the Dev set BLEU score.",For the baseline we selected the one which yielded the best BLEU score on the corresponding dev set The best learning rate for every dataset was chosen based on the Dev set BLEU score.,"Modify,Fact/Evidence",Fact/Evidence
1306,163-ARR,163-ARR_v2_7@0,163-ARR_v1_7@0,"In this paper we propose QCPG, a Quality Controlled Paraphrase Generation model, that given an input sentence and quality constraints, represented by a three dimensional vector of semantic similarity, and syntactic and lexical distances, produces a target sentence that conforms to the quality constraints.","In this paper we propose a Quality-Guided Controlled Paraphrase Generation (QCPG) neural model, that given an input sentence and quality constraints, represented by a three dimensional vector of semantic similarity, and syntactic and lexical distances, produces a target sentence that conforms to the quality constraints.","Modify,Clarity",Clarity
1307,163-ARR,163-ARR_v2_15@0,163-ARR_v1_12@0,"The most common dimensions for measuring paraphrase quality are the semantic, syntactic and lexical dimensions.","The most common dimensions for measuring paraphrase quality are the semantic, syntactic and lexical dimensions 1 (McCarthy et al., 2009).","Modify,Fact/Evidence",Fact/Evidence
1308,163-ARR,163-ARR_v2_15@2,163-ARR_v1_12@11,"However, since our focus is on the supervised setting, we rely on the gold paraphrases as fluency guidance for the model (Mc-Carthy et al., 2009).","However, since our focus is on the supervised setting, we rely on the gold paraphrases as fluency guidance for the model.","Modify,Fact/Evidence",Fact/Evidence
1309,164-ARR,,164-ARR_v1_29@0,,Inferring Start and End.,"Delete,Other",Other
1310,164-ARR,,164-ARR_v1_29@1,,"To infer the start and end times S i and E i from D i , we define an optimization problem and formulate it as an integer linear programming (ILP) problem detailed below.","Delete,Fact/Evidence",Fact/Evidence
1311,164-ARR,,164-ARR_v1_64@2,,"Recently, Acharya et al. (2021) made a first step in addressing this gap.","Delete,Fact/Evidence",Fact/Evidence
1312,164-ARR,164-ARR_v2_6@2,,"Such a grounding model can provide cultural context to machine translation systems (de Medeiros Caseli et al., 2010), language learning apps (Teske, 2017), and user-centered dialogue systems (Miehle et al., 2016).",,"Add,Fact/Evidence",Fact/Evidence
1313,164-ARR,164-ARR_v2_22@0,,Figure 3 displays the HIT.,,"Add,Fact/Evidence",Fact/Evidence
1314,164-ARR,164-ARR_v2_24@2,,We paid 0.3 USD per HIT.,,"Add,Fact/Evidence",Fact/Evidence
1315,164-ARR,164-ARR_v2_47@3,,"Since the gold standard grounding allows overlap between time expressions, we reward models for predicting any of the gold standard time expressions for a given minute.",,"Add,Fact/Evidence",Fact/Evidence
1316,164-ARR,164-ARR_v2_66@1,,Several recent papers start addressing this gap.,,"Add,Fact/Evidence",Fact/Evidence
1317,164-ARR,164-ARR_v2_66@2,,Yin et al. (2021) and Liu et al. (2021) extended existing visual question answering datasets with images from non-Western cultures.,,"Add,Fact/Evidence",Fact/Evidence
1318,164-ARR,164-ARR_v2_66@3,,Models trained to answer questions regarding images in the original datasets learned Western commonsense knowledge such as the association between weddings and white dresses.,,"Add,Claim",Claim
1319,164-ARR,164-ARR_v2_66@4,,"As a result, their performance drops on non-Western images, such as an Indian wedding ceremony where the bride is wearing a red sari.",,"Add,Claim",Claim
1320,164-ARR,164-ARR_v2_68@1,,The focus of both Vilares and Gómez-Rodríguez (2018) and Acharya et al. (2021) is on analyzing such cultural differences.,,"Add,Fact/Evidence",Fact/Evidence
1321,164-ARR,164-ARR_v2_68@2,,"Conversely, we formulated cultural-differences in the grounding of time expressions into a task, for which we collected gold standard annotations and proposed several methods.",,"Add,Fact/Evidence",Fact/Evidence
1322,164-ARR,164-ARR_v2_73@0,,Languages and Countries.,,"Add,Other",Other
1323,164-ARR,164-ARR_v2_73@4,,This assumption is challenged for countries with multiple languages and for languages spoken across multiple countries.,,"Add,Claim",Claim
1324,164-ARR,164-ARR_v2_73@5,,"For example, we can expect a Portuguese speaker from Brazil and a Portuguese speaker from Portugal to perceive time expressions differently due to the different time zones in which they live.",,"Add,Claim",Claim
1325,164-ARR,164-ARR_v2_74@0,,The alternative approach of using country as a proxy for culture is not applicable since corpora and language models are available for languages rather than countries.,,"Add,Claim",Claim
1326,164-ARR,164-ARR_v2_74@1,,"We can therefore assume that the models' predictions for each language are dominated by the country with the larger number of speakers (or more precisely, with the larger number of Wikipedia contributors).",,"Add,Claim",Claim
1327,164-ARR,164-ARR_v2_74@2,,"For example, the grounding of time expressions of the Portuguese model is likely dominated by speakers in Brazil and doesn't represent speakers in Portugal faithfully.",,"Add,Claim",Claim
1328,164-ARR,164-ARR_v2_77@2,,"First, the automatic translation of time expressions and templates from English to other languages may introduce some errors.",,"Add,Claim",Claim
1329,164-ARR,164-ARR_v2_6@0,164-ARR_v1_5@0,"We propose to re-frame the research question posed by Vilares and Gómez-Rodríguez (2018) as a task of time expression grounding: given a time expression, the goal is to map it to a range of hours during the day.","We propose to re-frame the research question posed by Vilares and Gómez-Rodríguez (2018) as a task of time expression grounding: given a time expression, the goal is to map it to a specific range of hours during the day.","Modify,Clarity",Clarity
1330,164-ARR,164-ARR_v2_67@0,164-ARR_v1_64@3,"With respect to temporal commonsense, Acharya et al. (2021) surveyed crowdsourcing workers in the US and India regarding rituals that are commonly found across cultures such as birth, marriage, and funerals.","They surveyed crowdsourcing workers in the US and India regarding rituals that are commonly found across cultures such as birth, marriage, and funerals.","Modify,Fact/Evidence",Fact/Evidence
1331,164-ARR,164-ARR_v2_68@0,164-ARR_v1_64@5,The paper presented anecdotal differences such that a wedding lasts a few hours in the US but a few days in India.,The paper mentions anecdotal differences such that a wedding lasts a few hours in the US but a few days in India.,"Modify,Clarity",Clarity
1332,164-ARR,164-ARR_v2_73@2,164-ARR_v1_65@1,"For example, in ConceptNet (Speer et al., 2017), a multilingual commonsense knowledge base, the English entry for breakfast specifies pancakes as breakfast food, while the Chinese entry mentions noodles.","For example, in ConceptNet, a multilingual commonsense knowledge base, the English entry for breakfast specifies pancakes as breakfast food, while the Chinese entry mentions noodles (Speer et al., 2017).","Modify,Clarity",Clarity
1333,164-ARR,164-ARR_v2_69@3,164-ARR_v1_66@3,"In particular, Elazar et al. (2019) mention cultural differences that arose when crowdsourcing workers were asked to estimate whether an item's price was expensive or not: annotators from India judged prices differently from annotators in the US.",Elazar et al. (2019) mention cultural differences that arose when crowdsourcing workers were asked to estimate whether an item's price was expensive or not: annotators from India judged prices differently from annotators in the US.,"Modify,Clarity",Clarity
1334,164-ARR,164-ARR_v2_77@1,164-ARR_v1_71@4,"While the methods in this paper are languageagnostic, they are designed based on English, and they don't produce equally good predictions for all languages.","While the methods in this paper are languageagnostic, they don't produce equally good predictions for all languages.","Modify,Fact/Evidence",Fact/Evidence
1335,164-ARR,164-ARR_v2_77@3,164-ARR_v1_71@5,"Second, beyond the differences in the set of commonly used time expressions in each language (e.g., ""evening"" being missing from Spanish, or ""dawn"" being commonly used in other languages), time might also be discussed differently in different languages.","Beyond the differences in the set of commonly used time expressions in each language (e.g., ""evening"" being missing from Spanish, or ""dawn"" being commonly used in other languages), time might also be discussed differently in different languages.","Modify,Clarity",Clarity
1336,164-ARR,164-ARR_v2_7@3,164-ARR_v1_6@1,"Encouraged by the performance on the labelled languages, we applied the method to additional 23 unlabelled languages, and analyzed the differences predicted by the models.","Encouraged by the performance on the labelled languages, we applied the method to additional 24 unlabelled languages, and analyzed the differences predicted by the models.","Modify,Fact/Evidence",Fact/Evidence
1337,164-ARR,164-ARR_v2_8@2,164-ARR_v1_7@2,"We hope this work would be another small step in the long-term goal of developing culturally-aware NLP models (Hovy and Yang, 2021).","We hope this work would be another small step in the long-term goal of developing culturally-aware commonsense reasoning models (Acharya et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
1338,164-ARR,164-ARR_v2_15@0,164-ARR_v1_9@2,"We describe the rationale behind the choice of languages ( §2.1), the HIT (Human Intelligence Task) and annotation guidelines ( §2.2), and the observations from the collected data ( §2.3).","We describe the rationale behind the choice of languages ( §2.1), the annotation guidelines ( §2.2), and the observations from the collected data ( §2.3).","Modify,Fact/Evidence",Fact/Evidence
1339,164-ARR,164-ARR_v2_2@2,164-ARR_v1_1@2,We then apply this method to 27 languages and analyze the similarities across languages in the grounding of time expressions.,We then apply this method to 28 languages and analyze the similarities across languages in the grounding of time expressions.,"Modify,Fact/Evidence",Fact/Evidence
1340,164-ARR,164-ARR_v2_17@0,164-ARR_v1_13@0,The languages in our dataset are not meant to be a representative sample of all languages.,The languages in this paper are not meant to be a representative sample of all languages.,"Modify,Clarity",Clarity
1341,164-ARR,164-ARR_v2_20@7,164-ARR_v1_16@1,"As we discuss in Section 4.3, we applied the model to additional 23 languages, selected based on the availability of a Wikipedia corpus and an LM for that language.","As we discuss in Section 4.3, we applied the model to additional 24 languages, selected based on the availability of a Wikipedia corpus and an LM for that language.","Modify,Fact/Evidence",Fact/Evidence
1342,164-ARR,164-ARR_v2_24@0,164-ARR_v1_20@0,"We then allowed workers to add any time expression in their native language that wasn't mentioned in the HIT, as well as free text comments.",We followed with an option to add a time expression in their language that wasn't mentioned in the HIT as well as free text comments.,"Modify,Clarity",Clarity
1382,169-ARR,,169-ARR_v1_34@3,,"Regret is calculated with respect to the optimal model π * ∈ arg max π∈Π E (q,c,y,r)∼D [r], where Π is the set of all models and D is the data distribution.","Delete,Fact/Evidence",Fact/Evidence
1383,169-ARR,,169-ARR_v1_51@2,,"Starting with weaker initial models and learning with a higher noise ratio may cause learning to fail (e.g., simulation on SQUAD with 64 initial examples and 20% noise).","Delete,Claim",Claim
1384,169-ARR,,169-ARR_v1_51@3,,"When online perturbation-free simulation fails, online learning with noisy feedback fails too.","Delete,Claim",Claim
1385,169-ARR,,169-ARR_v1_51@4,,"Learning progression across datasets shows that initial models trained with 1,024 examples can achieve peak performance with one third or even one quarter of feedback provided.","Delete,Fact/Evidence",Fact/Evidence
1386,169-ARR,,169-ARR_v1_52@0,,"Training Transformerbased models has been shown to have stability issues, especially when training with limited amount of data .","Delete,Claim",Claim
1387,169-ARR,,169-ARR_v1_52@1,,"Our non-standard training procedure (i.e., one epoch with a fixed learning rate) may further increase instability.","Delete,Claim",Claim
1388,169-ARR,,169-ARR_v1_57@3,,We report experiments with online learning.,"Delete,Fact/Evidence",Fact/Evidence
1389,169-ARR,,169-ARR_v1_57@4,,Offline adaptation experiments are discussed in Appendix B.3.,"Delete,Fact/Evidence",Fact/Evidence
1390,169-ARR,,169-ARR_v1_58@9,,"While NewsQA is crowdsourced, Trischler et al. (2017) report relatively low human performance.","Delete,Fact/Evidence",Fact/Evidence
1391,169-ARR,169-ARR_v2_13@1,,The learner aims to minimize the cumulative regret.,,"Add,Fact/Evidence",Fact/Evidence
1392,169-ARR,169-ARR_v2_43@1,,The MRQA benchmark simplifies all datasets so that each example has a single span answer with a limited evidence document length (truncated at 800 tokens).,,"Add,Fact/Evidence",Fact/Evidence
1393,169-ARR,169-ARR_v2_54@1,,Regret numbers are averaged over the number of feedback observations.,,"Add,Fact/Evidence",Fact/Evidence
1394,169-ARR,169-ARR_v2_54@3,,This is expected because later interactions in the simulation can benefit from early feedback in online learning.,,"Add,Claim",Claim
1395,169-ARR,169-ARR_v2_58@4,,"This is potentially because the model is exposed to different signals from two datasets and overall sees more data, either as supervised examples or through feedback.",,"Add,Claim",Claim
1396,169-ARR,169-ARR_v2_58@5,,"However, on SearchQA, learning with SQUAD-initialized model performs much worse than learning with the initial model trained on 1,024 in-domain examples, potentially because of the gap in initial model performance (23.5 vs. 65 F1).",,"Add,Fact/Evidence",Fact/Evidence
1397,169-ARR,169-ARR_v2_60@5,,"Implicit human feedback, where feedback is derived from human behavior rather than explicitly requested, has also been studied, including for dialogue (Jaques et al., 2020) and instruction generation (Kojima et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
1398,169-ARR,169-ARR_v2_60@6,,"We focus on explicit feedback, but implicit signals also hold promise to improve QA systems.",,"Add,Claim",Claim
1399,169-ARR,169-ARR_v2_61@2,,Campos et al. (2020) proposes feedback-weighted learning to improves conversational QA using simulated binary feedback.,,"Add,Fact/Evidence",Fact/Evidence
1400,169-ARR,169-ARR_v2_61@3,,"Their approach relies on multiple samples (i.e., feedback signals) per example, training for multiple epochs online by re-visiting the same questions repeatedly, and tuning two additional hyperparameters.",,"Add,Fact/Evidence",Fact/Evidence
1401,169-ARR,169-ARR_v2_61@4,,"In contrast, we study improving QA systems via feedback as a bandit learning problem.",,"Add,Fact/Evidence",Fact/Evidence
1402,169-ARR,169-ARR_v2_61@5,,"In both online and offline setups, we assume only one feedback sample per example.",,"Add,Fact/Evidence",Fact/Evidence
1403,169-ARR,169-ARR_v2_61@6,,"We also provide extensive sensitivity studies to the amount of annotations available, different model initialization, and noisy feedback across various datasets.",,"Add,Fact/Evidence",Fact/Evidence
1404,169-ARR,169-ARR_v2_66@0,,Our work's limitations are discussed in Section 1 and Section 9.,,"Add,Fact/Evidence",Fact/Evidence
1405,169-ARR,169-ARR_v2_66@1,,"All six datasets we use are from prior work, are publicly available, and are commonly used for the study of extractive QA.",,"Add,Fact/Evidence",Fact/Evidence
1406,169-ARR,169-ARR_v2_66@2,,Section 4 reports our computational budget and experimental setup in detail.,,"Add,Fact/Evidence",Fact/Evidence
1407,169-ARR,169-ARR_v2_66@3,,Our codebase is available at https://github.com/ lil-lab/bandit-qa.,,"Add,Fact/Evidence",Fact/Evidence
1408,169-ARR,169-ARR_v2_38@1,169-ARR_v1_34@1,We also estimate the learner regret (Equation 1).,"We also estimate the learner regret, a common measure for evaluating bandit learning.","Modify,Fact/Evidence",Fact/Evidence
1409,169-ARR,169-ARR_v2_13@2,169-ARR_v1_34@2,"Intuitively, regret is the deficit suffered by the learner relative to the optimal policy up to a specific time step.","Intuitively, regret is the deficit suffered by the learner relative to the optimal model (i.e., policy) up to a specific time step.","Modify,Clarity",Clarity
1410,169-ARR,169-ARR_v2_13@3,169-ARR_v1_34@4,"Formally, the cumulative regret at time T is computed with respect to the optimal policy π * ∈ arg max π∈Π E (x,y,r)∼(D,π) [r]:",The cumulative regret at time T is:,"Modify,Fact/Evidence",Fact/Evidence
1411,169-ARR,169-ARR_v2_40@1,169-ARR_v1_39@1,"Initialization is critical so the model does not return random answers, which are likely to be all bad because of the large output space.","Initialization is critical so the model does not return random answers, which are likely to all be bad because of the large output space.","Modify,Grammar",Grammar
1412,169-ARR,169-ARR_v2_40@2,169-ARR_v1_39@2,We use relatively little supervised data from the same domain for in-domain experiments (Section 5 and 6) to focus on the data annotation reduction potential of user feedback.,We use relatively little supervised data from the same domain for in-domain experiments (Sections 5 and 6) to focus on the data annotation reduction potential of user feedback.,"Modify,Grammar",Grammar
1413,169-ARR,169-ARR_v2_41@1,169-ARR_v1_40@1,"If the predicted answer span is an exact match index-wise to the annotated span, the learner observes a positive reward of 1.0, and a negative reward of -0.1 otherwise.","If the predicted answer span is an exact match index-wise to the annotated span, the learner observes a positive reward of 1.0, and negative reward -0.1 otherwise.","Modify,Grammar",Grammar
1414,169-ARR,169-ARR_v2_41@2,169-ARR_v1_40@2,7 This reward signal is stricter than QA evaluation metrics (tokenlevel F1 or exact match after normalization).,6 This reward signal is more strict than QA evaluation metrics (tokenlevel F1 or exact match after normalization).,"Modify,Grammar",Grammar
1415,169-ARR,169-ARR_v2_45@2,169-ARR_v1_45@2,"We obtain the sets of 64, 256, or 1,024 examples from prior work (Ram et al., 2021).","We obtain the sets of 64, 256, or 1024 examples from prior work (Ram et al., 2021).","Modify,Grammar",Grammar
1416,169-ARR,169-ARR_v2_45@3,169-ARR_v1_45@3,"10 For models initially trained on complete datasets (Section 7), we use a learning rate 2e-5 with a linear schedule, batch size 40, and 4 epochs.","9 For models initially trained on complete datasets (Section 7), we use a learning rate 2e-5 with a linear schedule, batch size 40, and four epochs.","Modify,Grammar",Grammar
1417,169-ARR,169-ARR_v2_46@1,169-ARR_v1_46@1,We turn off dropout to simulate interaction with users in deployment.,"We turn off dropout, because all experiments simulate interaction with users.","Modify,Fact/Evidence",Fact/Evidence
1418,169-ARR,169-ARR_v2_46@3,169-ARR_v1_46@3,"For offline learning experiments (Section 6), we train the model for 3 epochs on the collected feedback with a linear schedule learning rate of 3e-5.","For offline learning experiments (Section 6), we train the model for three epochs on the collected feedback with a linear schedule learning rate of 3e-5.","Modify,Grammar",Grammar
1419,169-ARR,169-ARR_v2_49@2,169-ARR_v1_49@2,"This section focuses on online learning, where the learner updates the model parameters after each feedback is observed (Algorithm 1).","This section focuses on online learning, where the learner updates the model parameters after each feedback collection (Algorithm 1).","Modify,Clarity",Clarity
1420,169-ARR,169-ARR_v2_50@5,169-ARR_v1_50@5,"This may be attributed to the quality of training set annotations, which determines the accuracy of reward in our setup.","The may be attributed to the quality of training set annotations, which determines the accuracy of reward in our setup.","Modify,Clarity",Clarity
1421,169-ARR,169-ARR_v2_53@3,169-ARR_v1_55@3,"This illustrates the benefit of the more standard training loop, especially with our Transformerbased model that is better optimized with a linear learning rate schedule and multiple epochs, both incompatible with the online setup.","This illustrates the benefit of the more standard training loop, especially with our Transformerbased model that is best optimized with a linear learning rate schedule and multiple epochs, both incompatible with the online setup.","Modify,Clarity",Clarity
1422,169-ARR,169-ARR_v2_56@0,169-ARR_v1_57@0,Learning from user feedback creates a compelling avenue to deploy systems that target new domains not addressed by existing datasets.,Learning from user feedback creates a compelling avenue to deploy systems that target domains not addressed by existing datasets.,"Modify,Clarity",Clarity
1423,169-ARR,169-ARR_v2_60@0,169-ARR_v1_61@0,"Bandit learning has been applied to a variety of NLP problems including neural machine translation (NMT; Kreutzer et al., 2018a,b;Mendoncca et al., 2021), structured prediction (Sokolov et al., 2016), semantic parsing (Lawrence and Riezler, 2018), intent recognition (Falke and Lehnen, 2021), and summarization (Gunasekara et al., 2021).","Bandit learning has been applied to a variety of NLP problems including neural machine translation (NMT; Sokolov et al., 2017;Kreutzer et al., 2018a,b;Mendoncca et al., 2021), structured prediction (Sokolov et al., 2016), semantic parsing (Lawrence and Riezler, 2018), intent recognition (Falke and Lehnen, 2021), and summarization (Gunasekara et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
1424,169-ARR,169-ARR_v2_60@1,169-ARR_v1_61@1,"Explicit human feedback has been studied as a direct learning signal for NMT (Kreutzer et al., 2018b;Mendoncca et al., 2021), semantic parsing (Artzi and Zettlemoyer, 2011;Lawrence and Riezler, 2018), and summarization (Stiennon et al., 2020).","Human feedback has been studied as a direct learning signal for NMT (Kreutzer et al., 2018b;Mendoncca et al., 2021), semantic parsing (Lawrence and Riezler, 2018), summarization (Stiennon et al., 2020), and dialogue (Jaques et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1425,169-ARR,169-ARR_v2_61@1,169-ARR_v1_61@6,"Kratzwald et al. (2020) resembles our setting in seeking binary feedback to replace span annotation, but their goal is to create supervised data more economically.","Kratzwald et al. (2020) resembles our setting in that it seeks binary feed-back to replace span annotation, but their goal is to create supervised data more economically.","Modify,Clarity",Clarity
1426,169-ARR,169-ARR_v2_61@7,169-ARR_v1_61@7,"Domain adaptation for QA has been widely studied (Fisch et al., 2019;Khashabi et al., 2020b), including using data augmentation (Yue et al., 2021), adversarial training , contrastive method (Yue et al., 2021), back-training (Kulshreshtha et al., 2021, and exploiting small lottery subnetworks (Zhu et al., 2021).","Domain adaptation for QA has been studied in prior work (Fisch et al., 2019;Khashabi et al., 2020b), including using data augmentation (Yue et al., 2021), adversarial training , contrastive method (Yue et al., 2021), back-training (Kulshreshtha et al., 2021, and exploiting small lottery subnetworks (Zhu et al., 2021).","Modify,Clarity",Clarity
1427,169-ARR,169-ARR_v2_67@2,169-ARR_v1_66@2,"13 In practice, this does not introduce a stronger learning signal, potentially because the distribution over F1 scores is bimodal and focused on extreme values: around 85 % F1 scores are either 0 or 1 for predicted spans from a SQUAD-trained model on 8% NQ training data.","13 In practice, using F1 as feedback does not introduce stronger learning signals, potentially because the distribution over F1 scores is bimodal on extreme values: around 85 % F1 scores are either 0 or 1 for predicted spans from a SQUAD-trained model on 8% NQ training data.","Modify,Clarity",Clarity
1428,169-ARR,169-ARR_v2_8@3,169-ARR_v1_8@3,"For example, sharing question-and answer-annotator roles (Rajpurkar et al., 2016), which is detrimental to emulate information seeking behavior (Choi et al., 2018).","For example, sharing question-annotator and answer-annotator roles (Rajpurkar et al., 2016), which is detrimental to emulate information seeking behavior (Choi et al., 2018).","Modify,Clarity",Clarity
1429,169-ARR,169-ARR_v2_2@2,169-ARR_v1_2@2,"We show that systems initially trained on a small number of examples can dramatically improve given feedback from users on modelpredicted answers, and that one can use existing datasets to deploy systems in new domains without any annotation, but instead improving the system on-the-fly via user feedback.","We show that systems initially trained on few examples can dramatically improve given feedback from users on model-predicted answers, and that one can use existing datasets to deploy systems in new domains without any annotation effort, but instead improving the system on-the-fly via user feedback.","Modify,Clarity",Clarity
1430,169-ARR,169-ARR_v2_9@4,169-ARR_v1_9@4,Our code is publicly available at https://github.com/ lil-lab/bandit-qa.,Our code will be made available upon publication.,"Modify,Fact/Evidence",Fact/Evidence
1431,169-ARR,169-ARR_v2_18@2,169-ARR_v1_15@2,"This formulation reflects a setup where, given a question-context pair, the QA system interacts with a user, who validates the model-predicted answer in context, and provides feedback which is mapped to numerical reward.","This formulation reflects a setup where, given a question-context pair, the QA system interacts with users, who validate the model-predicted answer in context, and provide feedback which is mapped to a numerical reward.","Modify,Grammar",Grammar
1432,17-ARR,,17-ARR_v1_22@8,,"Our SUBS could outperform Herzig and Berant (2020), although our induced tree are based on their model.","Delete,Fact/Evidence",Fact/Evidence
1433,17-ARR,,17-ARR_v1_22@9,,"That said, incorporating inductive biases to data and then to the model (seq2seq model finetuning) could achieve superior performance than directly incorporating inductive biases to model via latent variables (Herzig and Berant, 2020).","Delete,Claim",Claim
1434,17-ARR,,17-ARR_v1_28@1,,"Besides, we employ a weight-decay rate 0.01.","Delete,Fact/Evidence",Fact/Evidence
1435,17-ARR,,17-ARR_v1_28@2,,All the parameters are manually tuned based on the dev performance.,"Delete,Fact/Evidence",Fact/Evidence
1436,17-ARR,,17-ARR_v1_29@0,,We train all models on NVIDIA A100 SXM4 40 GB GPU.,"Delete,Fact/Evidence",Fact/Evidence
1437,17-ARR,,17-ARR_v1_29@1,,We set the max training epoch to be 100 and select the best performed epoch according to dev performance.,"Delete,Fact/Evidence",Fact/Evidence
1438,17-ARR,,17-ARR_v1_29@2,,Training process on each clause or whole sequence could be finished within 3 hours.,"Delete,Fact/Evidence",Fact/Evidence
1439,17-ARR,,17-ARR_v1_30@0,,"For baselines with other data augmentation methods, we reran GECA and SCFG on this FunQL formalism of GEOQUERY and these splits with annotated span trees.","Delete,Fact/Evidence",Fact/Evidence
1440,17-ARR,,17-ARR_v1_30@1,,That's why our results are a little different from the reported results in the original paper.,"Delete,Claim",Claim
1441,17-ARR,,17-ARR_v1_30@2,,"We got similar results with their source code and our code on our data, in order to make sure that there is no problem with our results and code.","Delete,Fact/Evidence",Fact/Evidence
1442,17-ARR,,17-ARR_v1_31@0,,"We got the same denotation accuracy as reported by Herzig and Berant (2020), but we reported exactmatch accuracy on Table 2 for fair comparison.","Delete,Fact/Evidence",Fact/Evidence
1443,17-ARR,17-ARR_v2_2@5,,We have publicly released our code at https: //github.com/GT-SALT/SUBS .,,"Add,Fact/Evidence",Fact/Evidence
1444,17-ARR,17-ARR_v2_4@6,,"Jingfeng Yang proposed subtree substitution data augmentation for compositional semantic parsing, implemented augmentation and LSTM/BART parsers, and ran SCFG/GECA baselines.",,"Add,Fact/Evidence",Fact/Evidence
1445,17-ARR,17-ARR_v2_4@7,,Le Zhang induced span trees and ran span-based semantic parsing baseline.,,"Add,Fact/Evidence",Fact/Evidence
1446,17-ARR,17-ARR_v2_20@5,,"To test compositional semantic parsing, we use the Primitive right (RIGHT) and Primitive around right (AROUNDRIGHT) compositional splits from Loula et al. (2018), where templates of the form Primitive right and Primitive around right (respectively) appear only in the test set.",,"Add,Fact/Evidence",Fact/Evidence
1447,17-ARR,17-ARR_v2_20@6,,"In these templates, Primitive stands for jump, walk, run, or look.",,"Add,Fact/Evidence",Fact/Evidence
1448,17-ARR,17-ARR_v2_20@7,,"For simplicity, func(•) is defined only on i_right and i_left, where func(i_right) = func(i_left) = direction.",,"Add,Fact/Evidence",Fact/Evidence
1449,17-ARR,17-ARR_v2_26@8,,"Some rule-based data augmentation methods were also explored in table semantic parsing (Eisenschlos et al., 2020;Yang et al., 2022).",,"Add,Fact/Evidence",Fact/Evidence
1450,17-ARR,,17-ARR_v1_17@0,,Experiments and Results,"Delete,Other",Other
1451,17-ARR,17-ARR_v2_24@0,17-ARR_v1_22@0,"Table 2 shows the results of experiments on GEO-QUERY dataset, where we examined both seq2seq LSTM and BART Large parsers.","Table 2 shows the results of experiments on GEO-QUERY dataset, where we examined both seq2seq LSTM and BART parsers.","Modify,Fact/Evidence",Fact/Evidence
1452,17-ARR,17-ARR_v2_24@6,17-ARR_v1_22@6,"Therefore, subtree substitution is a simple yet effective compositional data augmentation method for compositional semantic parsing.","Therefore, subtree substitution is a simple yet effective compositional data augmentation method for semantic parsing.","Modify,Claim",Claim
1453,17-ARR,17-ARR_v2_26@6,17-ARR_v1_25@6,"Dependency tree swapping was explored in low-resource language dependency parsing (Dehouck and Gómez-Rodríguez, 2020), and Universal Dependency features was used for zero-shot cross-lingual semantic parsing (Yang et al., 2021).","Dependency tree swapping was explored in low-resource language dependency parsing (Dehouck and Gómez-Rodríguez, 2020).","Modify,Fact/Evidence",Fact/Evidence
1454,17-ARR,17-ARR_v2_19@0,17-ARR_v1_16@0,"After getting augmented data by subtree substitution, we then combine augmented data and the original training data to train a seq2seq semantic parser, where we choose LSTM models with attention (Luong et al., 2015) and copying mechanism (Gu et al., 2016), or pretrained BART Large (Lewis et al., 2020) as the seq2seq model architecture.","After getting augmented data by subtree substitution, we then combine augmented data and the original training data to train a seq2seq semantic parser, where we choose LSTM models with attention (Luong et al., 2015) and copying mechanism (Gu et al., 2016), or pretrained BART (Lewis et al., 2020) as the seq2seq model architecture.","Modify,Fact/Evidence",Fact/Evidence
1455,170-ARR,,170-ARR_v1_49@0,,Multimodal Fusion.,"Delete,Other",Other
1456,170-ARR,,170-ARR_v1_55@2,,We optimize models by joint training to minimize the cross-entropy losses to generate responses and functional programs.,"Delete,Fact/Evidence",Fact/Evidence
1457,170-ARR,,170-ARR_v1_55@4,,"For more details of data and training, please refer to Appendix B and C.","Delete,Fact/Evidence",Fact/Evidence
1458,170-ARR,,170-ARR_v1_61@6,,Future work may focus on learning better question parsers or directly deploying a better off-the-shelf parser tool.,"Delete,Claim",Claim
1459,170-ARR,,170-ARR_v1_67@0,,"To learn compositional programs, we follow (Johnson et al., 2017a;Hu et al., 2017) and consider program generation as a sequence-tosequence task.","Delete,Fact/Evidence",Fact/Evidence
1460,170-ARR,,170-ARR_v1_67@1,,"We adopt a simple template "" param 1 module 1 param 2 module 2 ..."" as the target sequence.","Delete,Fact/Evidence",Fact/Evidence
1461,170-ARR,,170-ARR_v1_67@2,,The resulting target sequences for dialogue and video understanding programs are sequences P dial and P vid respectively.,"Delete,Fact/Evidence",Fact/Evidence
1462,170-ARR,,170-ARR_v1_68@0,,The parsers decompose questions into subsequences to construct compositional reasoning programs for dialogue and video understanding.,"Delete,Fact/Evidence",Fact/Evidence
1463,170-ARR,,170-ARR_v1_68@1,,Each parser is an attention-based Transformer decoder.,"Delete,Fact/Evidence",Fact/Evidence
1464,170-ARR,,170-ARR_v1_68@2,,"The Transformer attention is a multi-head attention on query q, key k, and value v tensors, denoted as Attention(q, k, v).","Delete,Fact/Evidence",Fact/Evidence
1465,170-ARR,,170-ARR_v1_68@3,,"For each token in the q sequence , the distribution over tokens in the k sequence is used to obtain the weighted sum of the corresponding representations in the v sequence.","Delete,Fact/Evidence",Fact/Evidence
1466,170-ARR,170-ARR_v2_56@0,,Training Details.,,"Add,Other",Other
1467,170-ARR,170-ARR_v2_63@5,,These observations imply that GPT-based models can better capture video context from video caption/summary through rich pretrained representations.,,"Add,Claim",Claim
1468,170-ARR,170-ARR_v2_63@6,,"However, without access to video caption/summary, these models may fail to understand video from visual-only representations.",,"Add,Claim",Claim
1469,170-ARR,170-ARR_v2_63@7,,"In this setting, GPT-based models may be inferior to VGNMN, which explicitly exploits the compositional structures from textual inputs to integrate visual features.",,"Add,Claim",Claim
1470,170-ARR,170-ARR_v2_63@8,,We also found that VGNMN applied to object-level features is competitive to the model applied to CNN-based features.,,"Add,Claim",Claim
1471,170-ARR,170-ARR_v2_63@9,,The Robustness.,,"Add,Other",Other
1472,170-ARR,170-ARR_v2_63@10,,"To evaluate model robustness, we report BLEU4 and CIDEr of model variants in various experimental settings.",,"Add,Fact/Evidence",Fact/Evidence
1473,170-ARR,170-ARR_v2_63@11,,"Specifically, we compare against performance of output responses in the first dialogue turn position (i.e. 2 nd -10 th turn vs. the 1 st turn), or responses grounded on the shortest video length range (video ranges are intervals of 0-10 th , 10-20 th percentile and so on).",,"Add,Fact/Evidence",Fact/Evidence
1474,170-ARR,170-ARR_v2_63@13,,"Video features are retrieved through a token-level representation of questions (Le et al., 2019b).",,"Add,Fact/Evidence",Fact/Evidence
1475,170-ARR,170-ARR_v2_63@15,,Dialogue history is encoded by a hierarchical LSTM encoder .,,"Add,Fact/Evidence",Fact/Evidence
1476,170-ARR,170-ARR_v2_76@0,,How to locate entities?,,"Add,Other",Other
1477,170-ARR,170-ARR_v2_67@4,170-ARR_v1_60@13,"Since TGIF-QA questions follow a very specific type distribution (count, action, transition, and frameQA), the question structures are simpler and easier to learn than AVSD.","Since TGIF-QA questions follow a very specific question type distribution (count, action, transition, and frameQA), the question structures are simpler and easier to learn than AVSD.","Modify,Clarity",Clarity
1478,170-ARR,170-ARR_v2_71@2,170-ARR_v1_66@2,"For any potential application or extension of work, we would like to highlight some specific concerns.","For any potential application or extension of this work, we would like to highlight some specific concerns.","Modify,Clarity",Clarity
1479,170-ARR,170-ARR_v2_72@0,170-ARR_v1_70@0,Each attention is followed by a network applied to each position identically.,Each attention is followed by a feed-forward network applied to each position identically.,"Modify,Clarity",Clarity
1517,173-ARR,,173-ARR_v1_18@2,,"For categorical learning, we include miniImageNet (Vinyals et al., 2016), a meta learning dataset.","Delete,Fact/Evidence",Fact/Evidence
1518,173-ARR,,173-ARR_v1_18@3,,"Following (Tsimpoukelli et al., 2021), we use only meta test data to evaluate FEWVLM in a few-shot manner and test on 5-way k-shot setup, where 5 classes and k examples per class are given.","Delete,Fact/Evidence",Fact/Evidence
1519,173-ARR,,173-ARR_v1_18@5,,We study hand-crafted prompts on zero-shot and few-shot tasks.,"Delete,Fact/Evidence",Fact/Evidence
1520,173-ARR,,173-ARR_v1_18@6,,"[Q] and [A] refer to question text and answer text, respectively.","Delete,Fact/Evidence",Fact/Evidence
1521,173-ARR,,173-ARR_v1_18@7,,<text_1> is a sentinel token.,"Delete,Fact/Evidence",Fact/Evidence
1522,173-ARR,,173-ARR_v1_18@8,,We append image features to input text.,"Delete,Fact/Evidence",Fact/Evidence
1523,173-ARR,,173-ARR_v1_18@9,,"Target prompts are ""[A]"" and ""<text_1> [A]"" in VQA.","Delete,Fact/Evidence",Fact/Evidence
1524,173-ARR,,173-ARR_v1_18@10,,We use caption text as a target prompt in captioning.,"Delete,Fact/Evidence",Fact/Evidence
1525,173-ARR,173-ARR_v2_2@7,,Our code is publicly available at https://github.,,"Add,Fact/Evidence",Fact/Evidence
1526,173-ARR,173-ARR_v2_15@0,,"For zero-shot tasks, a pre-trained VL model L have no access to training set D train and development set D dev , and directly makes inference on the test instances D test .",,"Add,Fact/Evidence",Fact/Evidence
1527,173-ARR,173-ARR_v2_36@2,,The pre-training datasets contains 9.18M image-text pairs and 180K distinct images.,,"Add,Fact/Evidence",Fact/Evidence
1528,173-ARR,173-ARR_v2_55@0,,Performance on Few-shot Learning,,"Add,Other",Other
1529,173-ARR,173-ARR_v2_56@0,,Tables 3 and 5 show the few-shot performance on VQA and captioning datasets.,,"Add,Fact/Evidence",Fact/Evidence
1530,173-ARR,173-ARR_v2_57@0,,"On VQAv2 and OK-VQA, PICa shows the best performance while our FEWVLM large achieves the comparable result on VQAv2.",,"Add,Fact/Evidence",Fact/Evidence
1531,173-ARR,173-ARR_v2_57@1,,"OK-VQA requires external knowledge to answer unlike other VQA datasets, so larger models and large pre-training data (prior knowledge) are necessary to improve.",,"Add,Claim",Claim
1532,173-ARR,173-ARR_v2_57@2,,"Interestingly, FEWVLM * base , which is trained with 4 training examples, outperforms Frozen.",,"Add,Claim",Claim
1533,173-ARR,173-ARR_v2_57@3,,"On captioning data, FEWVLM base notably outperforms VL-T5 no-vqa by 31.1% point on NoCaps CIDEr.",,"Add,Fact/Evidence",Fact/Evidence
1534,173-ARR,173-ARR_v2_67@0,,Pre-training Objectives,,"Add,Other",Other
1535,173-ARR,173-ARR_v2_25@1,173-ARR_v1_24@1,We include Unified VLP for few-shot VQAv2 and Flickr30k.,"We include Unified VLP (Zhou et al., 2020) for few-shot VQAv2 and Flickr30k.","Modify,Fact/Evidence",Fact/Evidence
1536,173-ARR,173-ARR_v2_25@3,173-ARR_v1_24@3,"For fully fine-tuned models L f ull , we borrow numbers from Uniter large for VQAv2, Oscar (Li et al., 2020b) for GQA, SimVLM and VinVL (Zhang et al., 2021) for NoCaps CIDER and SPICE respectively, and Unified VLP for Flickr30k captioning.","For fully fine-tuned models L f ull , we borrow numbers from Uniter large for VQAv2, Oscar (Li et al., 2020b) for GQA, SimVLM and VinVL (Zhang et al., 2021) for NoCaps CIDER and SPICE respectively, and Unified VLP (Zhou et al., 2020) for Flickr30k captioning.","Modify,Fact/Evidence",Fact/Evidence
1537,173-ARR,173-ARR_v2_28@0,173-ARR_v1_27@0,Encoder-decoder Vision-language Model,Encoder-Decoder Vision-language Model,"Modify,Grammar",Grammar
1538,173-ARR,173-ARR_v2_34@3,173-ARR_v1_34@1,We include prefix language modeling (PrefixLM) following Raffel et al. (2020).,We include prefix language modeling (PrefixLM) following Raffel et al. (2019).,"Modify,Fact/Evidence",Fact/Evidence
1539,173-ARR,173-ARR_v2_41@0,173-ARR_v1_42@0,Visual Question Answering,Visual Question Answering.,"Modify,Grammar",Grammar
1540,173-ARR,173-ARR_v2_43@0,173-ARR_v1_46@0,Captioning,Captioning.,"Modify,Grammar",Grammar
1541,173-ARR,173-ARR_v2_66@8,173-ARR_v1_66@0,"In addition, we explore two different target prompts, ""<text_1> [A]"" and "" [A].""","In addition, we explore two different target prompts, ""<text_1 [A]"" and "" [A].""","Modify,Grammar",Grammar
1542,173-ARR,173-ARR_v2_66@9,173-ARR_v1_66@1,"We try to mimic the MaskedLM's target text format, so we add ""<text_1>"" to target prompt on VQA.","We try to mimic the MaskedLM's target text format, so we add ""<text_1"" to target prompt on VQA.","Modify,Grammar",Grammar
1543,173-ARR,173-ARR_v2_66@11,173-ARR_v1_66@3,"In Fig. 6, we notice an interesting phenomenon; the target prompt ""[A]"" shows a larger variance than the other suggesting that introducing ""<text_1>"" helps the model quickly adapt to a new task.","In Fig. 6, we notice an interesting phenomenon; the target prompt ""[A]"" shows a larger variance than the other suggesting that introducing ""<text_1"" helps the model quickly adapt to a new task.","Modify,Grammar",Grammar
1544,173-ARR,173-ARR_v2_72@1,173-ARR_v1_70@1,"FEWVLM base and FEWVLM large is based on VL-T5 and T5 (Raffel et al., 2020), respectively.","FEWVLM base and FEWVLM large is based on VL-T5 and T5 (Raffel et al., 2019), respectively.","Modify,Fact/Evidence",Fact/Evidence
1545,173-ARR,173-ARR_v2_73@1,173-ARR_v1_71@1,"We use Karpathy split (Karpathy and Li, 2015) for MS COCO captioning, which re-splits train and val images into 113,287 / 5000 / 5000 for train / validation / test.","We use Karpathy split (Karpathy and Fei-Fei, 2015) for MS COCO captioning, which re-splits train and val images into 113,287 / 5000 / 5000 for train / validation / test.","Modify,Fact/Evidence",Fact/Evidence
1546,173-ARR,173-ARR_v2_5@3,173-ARR_v1_6@1,"For FEWVLM, we pre-train a sequence-to-sequence transformer model Raffel et al., 2020) with prefix language modeling (PrefixLM) and masked language modeling (MaskedLM).","For FEWVLM, we pre-train a sequence-to-sequence transformer model Raffel et al., 2019) with prefix language modeling (PrefixLM) and masked language modeling (MaskedLM).","Modify,Fact/Evidence",Fact/Evidence
1547,173-ARR,173-ARR_v2_5@5,173-ARR_v1_6@3,"In such a few-shot setting, task-specific prompts or task descriptions are important and have shown effectiveness in few-shot NLP tasks Radford et al., 2021;Schick and Schütze, 2021a,b;Brown et al., 2020).","In such a few-shot setting, task-specific prompts or task descriptions are important and have shown effectiveness in few-shot NLP tasks Radford et al., 2021;Schick and Schütze, 2020a,b;Brown et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1548,173-ARR,173-ARR_v2_6@3,173-ARR_v1_6@7,"In addition, we study pre-training objectives on few-shot tasks inspired by Raffel et al. (2020): prefix language modeling (PrefixLM) inspired by Raffel et al. (2020) and masked language modeling (MaskedLM).","In addition, we study pre-training objectives on few-shot tasks inspired by Raffel et al. (2019): prefix language modeling (PrefixLM) inspired by Raffel et al. (2019) and masked language modeling (MaskedLM).","Modify,Fact/Evidence",Fact/Evidence
1549,173-ARR,173-ARR_v2_10@1,173-ARR_v1_10@1,"Providing prompts or task descriptions play an vital role in improving pre-trained language models in many tasks Radford et al., 2021;Schick and Schütze, 2021a,b;Brown et al., 2020).","Providing prompts or task descriptions play an vital role in improving pre-trained language models in many tasks Radford et al., 2021;Schick and Schütze, 2020a,b;Brown et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1550,173-ARR,173-ARR_v2_11@1,173-ARR_v1_10@3,"In light of this direction, prompt-based approaches improve small pre-trained models in few-shot text classification tasks Schick and Schütze, 2021a,b).","In light of this direction, prompt-based approaches improve small pre-trained models in few-shot text classification tasks Schick and Schütze, 2020a,b).","Modify,Fact/Evidence",Fact/Evidence
1551,173-ARR,173-ARR_v2_17@2,173-ARR_v1_15@2,"Providing a pretrained language model with task-specific prompts or significantly improves zero-shot and few-shot performance on NLP domains Schick and Schütze, 2021a,b;Brown et al., 2020).","Providing a pretrained language model with task-specific prompts or significantly improves zero-shot and few-shot performance on NLP domains Schick and Schütze, 2020a,b;Brown et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1552,173-ARR,173-ARR_v2_18@0,173-ARR_v1_15@7,Q3) How do different pre-training objectives affect zero/few-shot performance?,Q3) How do different pre-training objectives affect zero/few-shot learning?,"Modify,Clarity",Clarity
1553,177-ARR,,177-ARR_v1_14@3,,"We extract the birth year of the applicant from the case facts, if possible, and classify its case in an age group (≤35, ≤64, or older) ; and (c) the applicant's gender, extracted from the facts, if possible based on pronouns, classified in two categories (male, female).","Delete,Fact/Evidence",Fact/Evidence
1554,177-ARR,,177-ARR_v1_15@0,,The US Supreme Court (SCOTUS) is the highest federal court in the United States of America and generally hears only the most controversial or otherwise complex cases which have not been sufficiently well solved by lower courts.,"Delete,Claim",Claim
1555,177-ARR,,177-ARR_v1_15@1,,"We combine information from SCOTUS opinions with the Supreme Court DataBase (SCDB) 10 (Spaeth et al., 2020).","Delete,Fact/Evidence",Fact/Evidence
1556,177-ARR,,177-ARR_v1_4@0,,"The sector of law produces massive volumes of textual data (Katz et al., 2020), and as a result, legal research for settling personal injury claims, for example, can take several years, potentially discouraging clients.","Delete,Claim",Claim
1557,177-ARR,,177-ARR_v1_50@1,,"Our hierarchical model, first, encodes the text through a pre-trained Transformer-based architecture, thus representing each paragraph independently with the [CLS] token.","Delete,Fact/Evidence",Fact/Evidence
1558,177-ARR,,177-ARR_v1_50@2,,"Then, the paragraph representations are fed into a two-layers transformer encoder with the exact same specifications of the first one (e.g., hidden units, number of attention heads), so as to contextualize them, i.e., it makes paragraphs representations aware of the surrounding paragraphs.","Delete,Fact/Evidence",Fact/Evidence
1559,177-ARR,,177-ARR_v1_50@3,,"Finally, the model max-pools the context-aware paragraph representations computing the document-level representation and feed it to a classification layer.","Delete,Fact/Evidence",Fact/Evidence
1560,177-ARR,,177-ARR_v1_56@0,,13 Both links will be revealed upon acceptance.,"Delete,Fact/Evidence",Fact/Evidence
1561,177-ARR,,177-ARR_v1_56@1,,"14 The group of unidentified instances includes the instances, where the value of the examined attribute is unidentifiable (unknown).","Delete,Fact/Evidence",Fact/Evidence
1562,177-ARR,,177-ARR_v1_56@2,,See details in Appendix C.2.,"Delete,Fact/Evidence",Fact/Evidence
1563,177-ARR,,177-ARR_v1_65@7,,We highlight the worst and best performing group per attribute.,"Delete,Fact/Evidence",Fact/Evidence
1564,177-ARR,,177-ARR_v1_65@8,,"In boldface, we highlight the best (less harmful) value per factor across groups.","Delete,Fact/Evidence",Fact/Evidence
1565,177-ARR,,177-ARR_v1_66@5,,"In other words, there are other reasons that lead to performance disparity in this case; for example, inconsistencies in rules and gathering of evidence in criminal cases potentially affects the predictability of rulings (Macula, 2019).","Delete,Claim",Claim
1566,177-ARR,,177-ARR_v1_66@6,,"In sum, we do not see any of these factors fully explain the performance disparities across groups.","Delete,Claim",Claim
1567,177-ARR,,177-ARR_v1_77@1,,"For example, criminal justice is already often strongly influenced by racial bias, with people of colour being more likely to be arrested and receive higher punishments than others, both in both in the USA 16 and in the UK.","Delete,Claim",Claim
1568,177-ARR,,177-ARR_v1_78@0,,"We fine-tune all models using the AdamW (Loshchilov and Hutter, 2019) optimizer with a learning rate of 3e-5.","Delete,Fact/Evidence",Fact/Evidence
1569,177-ARR,,177-ARR_v1_78@1,,We use a batch size of 16 and train models for up to 20 epochs using early stopping on validation performance.,"Delete,Fact/Evidence",Fact/Evidence
1570,177-ARR,,177-ARR_v1_79@0,,"In Figure 2 we report the distribution of sequence (document) length across FairLex datasets (ECtHR, SCOTUS, FSCS).","Delete,Fact/Evidence",Fact/Evidence
1571,177-ARR,,177-ARR_v1_79@1,,"We observe that the documents are extremely long (3,000-6,000+ words) across datasets.","Delete,Fact/Evidence",Fact/Evidence
1572,177-ARR,,177-ARR_v1_80@0,,In Tables 5 and 6 we report the group distribution per examined attribute under consideration.,"Delete,Fact/Evidence",Fact/Evidence
1573,177-ARR,,177-ARR_v1_80@1,,"In some cases, the extraction of the specific attribute, e.g., gender or age in ECtHR, was not possible, i.e., the applied rules would no suffice, possibly because the information is intentionally missing.","Delete,Claim",Claim
1574,177-ARR,,177-ARR_v1_80@2,,"During training, the groups of unidentified samples is included, but we report test scores excluding those, i.e., mF1 and GD do not take into account the F1 of these groups.","Delete,Fact/Evidence",Fact/Evidence
1575,177-ARR,,177-ARR_v1_81@0,,"In Tables 7, 8, 9, and 10, we report the Jensen-Shannon divergences between train-test, train-dev and test-test distribution of labels separately for each protrected attribute values and for each dataset in our framework.","Delete,Fact/Evidence",Fact/Evidence
1576,177-ARR,177-ARR_v2_2@3,,"Furthermore, we provide a quantitative and qualitative analysis of our results, highlighting open challenges in the development of robustness methods in legal NLP.",,"Add,Fact/Evidence",Fact/Evidence
1577,177-ARR,177-ARR_v2_6@0,,Societal transformations perpetually shape our legal systems.,,"Add,Claim",Claim
1578,177-ARR,,177-ARR_v1_6@2,,"In a supervised learning setting, models are trained on historical data that not always represent all groups in our societies equally.","Delete,Claim",Claim
1579,177-ARR,177-ARR_v2_12@0,,Fairness in law Studying fair machine learning in the context of legal (computational) applications has a limited history.,,"Add,Claim",Claim
1580,177-ARR,177-ARR_v2_13@3,,"Another line of work (Rice et al., 2019;Baker Gillis, 2021;Gumusel et al., 2022) explores representational bias with respect to race and gender analyzing word latent representations trained in legal text corpora.",,"Add,Fact/Evidence",Fact/Evidence
1581,177-ARR,177-ARR_v2_13@4,,"While we agree that representational bias can potentially reinforce unfortunate biases, these may not impact the treatment of individuals (or groups).",,"Add,Claim",Claim
1582,177-ARR,177-ARR_v2_13@5,,We therefore focus on directly measuring equal risk on downstream applications instead.,,"Add,Fact/Evidence",Fact/Evidence
1583,177-ARR,177-ARR_v2_15@1,,"Despite their value, recent work has raised criticism on several limitations of the so called NLU benchmarks (Paullada et al., 2020;Bowman and Dahl, 2021;Raji et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
1584,177-ARR,177-ARR_v2_16@0,,"We believe that the release of FairLex, a domainspecific (legal-oriented) benchmark suite for evaluating fairness, overcomes (or at least mitigates) some of the aforementioned limitations.",,"Add,Claim",Claim
1585,177-ARR,177-ARR_v2_16@1,,"We introduce the core motivation in Section 1, while specific (case-by-case) details are described in Section 3.",,"Add,Fact/Evidence",Fact/Evidence
1586,177-ARR,177-ARR_v2_16@2,,Our benchmark is open-ended and inevitably has several limitations; we report known limitations and ethical considerations in Sections 7 and 8.,,"Add,Fact/Evidence",Fact/Evidence
1587,177-ARR,177-ARR_v2_16@3,,Nonetheless we believe that it will help critical research in the area of fairness.,,"Add,Claim",Claim
1588,177-ARR,177-ARR_v2_54@0,,"In Table 2, we report the group performance (mF1), where models trained with the ERM algorithm, across all datasets and attributes.",,"Add,Fact/Evidence",Fact/Evidence
1589,177-ARR,177-ARR_v2_54@1,,"We observe that the intensity of group disparities vary a lot between different attributes, but in many cases the group disparities are very vibrant.",,"Add,Fact/Evidence",Fact/Evidence
1590,177-ARR,177-ARR_v2_55@0,,"For example, in ECtHR, we observe substantial group disparity between the two defendant state groups (21.5% absolute difference), similarly for applicant's gender groups (16.2% absolute difference).",,"Add,Fact/Evidence",Fact/Evidence
1591,177-ARR,177-ARR_v2_55@1,,"In FSCS, we observe language disparity, where performance is on average 3-5% lower for cases written in Italian compared to those written in French and German.",,"Add,Fact/Evidence",Fact/Evidence
1592,177-ARR,177-ARR_v2_55@2,,"Performance disparity is even higher with respect to legal areas, where the model has the best performance for criminal (penal law) cases (83.4%) compared to others (approx. 10-20% lower).",,"Add,Fact/Evidence",Fact/Evidence
1593,177-ARR,177-ARR_v2_55@3,,"We also observe substantial group disparities with respect to the court region, e.g., cases ruled in E. Switzerland courts (66.8%) compared to Federation courts (56.4%).",,"Add,Fact/Evidence",Fact/Evidence
1594,177-ARR,177-ARR_v2_55@4,,"The same applies for CAIL, e.g., cases ruled in Beijing courts (66.8%) compared to Sichuan courts (56.4%).",,"Add,Fact/Evidence",Fact/Evidence
1595,177-ARR,177-ARR_v2_71@0,,Limitations,,"Add,Other",Other
1596,177-ARR,177-ARR_v2_72@0,,"The current version of FairLex covers a very small fraction of legal applications, jurisdictions, and protected attributes.",,"Add,Claim",Claim
1597,177-ARR,177-ARR_v2_73@0,,"Our benchmark is open-ended and inevitably cannot cover ""everything in the whole wide (legal) world"" (Raji et al., 2021), but nonetheless we believe that the published resources will help critical research in the area of fairness.",,"Add,Claim",Claim
1598,177-ARR,177-ARR_v2_73@1,,"Some protected attributes within our datasets are extracted automatically, i.e., the gender and the age in the ECtHR dataset, if possible, by means of regular expressions, or manually clustered by the authors, such as the defendant state in the ECtHR dataset and the respondent attribute in the SCO-TUS dataset.",,"Add,Fact/Evidence",Fact/Evidence
1599,177-ARR,177-ARR_v2_73@2,,"Various simplifications made, e.g, the binarization of gender, would be inappropriate in real-world applications.",,"Add,Claim",Claim
1600,177-ARR,177-ARR_v2_74@0,,"Another important limitation is that what is considered the ground truth in these datasets (with the exception of SCOTUS) is only ground truth relative to judges' interpretation of a specific (EC, US, Swiss, Chinese) jurisdiction and legal framework.",,"Add,Claim",Claim
1601,177-ARR,177-ARR_v2_75@0,,"The labeling is therefore somewhat subjective for non-trivial cases, and its validity is only relative to a given legal framework.",,"Add,Claim",Claim
1602,177-ARR,177-ARR_v2_75@1,,We of course do not in any way endorse the legal standards or framework of the examined datasets.,,"Add,Claim",Claim
1603,177-ARR,177-ARR_v2_78@0,,"In future work, we aim to further expand the benchmark with more datasets that could possibly cover more sensitive attributes.",,"Add,Claim",Claim
1604,177-ARR,177-ARR_v2_78@1,,"Further analysis on the reasons behind group disparities, e.g., representational bias, systemic bias, is also critical.",,"Add,Claim",Claim
1605,177-ARR,177-ARR_v2_79@0,,The scope of this work is to provide an evaluation framework along with extensive experiments to further study fairness within the legal domain.,,"Add,Fact/Evidence",Fact/Evidence
1606,177-ARR,177-ARR_v2_79@1,,"Following the work of Angwin et al. (2016), Dressel and Farid (2018), and Wang et al. (2021b), we provide a diverse benchmark covering multiple tasks, jurisdictions, and protected (examined) attributes.",,"Add,Fact/Evidence",Fact/Evidence
1607,177-ARR,177-ARR_v2_79@2,,"We conduct experiments based on pretrained transformer-based language models and compare model performance across four representative group-robust algorithm, i.e., Adversarial Removal (Elazar and Goldberg, 2018), Group DRO (Sagawa et al., 2020), IRM (Arjovsky et al., 2020) and REx (Krueger et al., 2020).",,"Add,Fact/Evidence",Fact/Evidence
1608,177-ARR,177-ARR_v2_80@1,,"We believe that this is an important application field, where more research should be conducted (Tsarapatsanis and Aletras, 2021) in order to improve legal services and democratize law, but more importantly highlight (inform the audience on) the various multi-aspect shortcomings seeking a responsible and ethical (fair) deployment of technology.",,"Add,Claim",Claim
1609,177-ARR,177-ARR_v2_81@1,,"We release the compiled version of the dataset under a CC-BY-NC-SA-4.0 license to favor academic research, and forbid to the best of our ability potential commercial dual use.",,"Add,Claim",Claim
1610,177-ARR,177-ARR_v2_81@3,,"If datasets or the papers where they were introduced in were not compiled or written by ourselves, we have referenced the original work and encourage FairLex users to do so as well.",,"Add,Fact/Evidence",Fact/Evidence
1611,177-ARR,177-ARR_v2_81@4,,"In fact, we believe that this work should only be referenced, in addition to citing the original work, when jointly experimenting with multiple FairLex datasets and using the FairLex evaluation framework and infrastructure, or use any newly introduced annotations (EC-tHR, SCOTUS).",,"Add,Claim",Claim
1612,177-ARR,177-ARR_v2_81@5,,Otherwise only the original work should be cited.,,"Add,Claim",Claim
1613,177-ARR,177-ARR_v2_82@0,,The data is in general partially anonymized in accordance with the applicable national law.,,"Add,Fact/Evidence",Fact/Evidence
1614,177-ARR,177-ARR_v2_82@1,,The data is considered to be in the public sphere from a privacy perspective.,,"Add,Claim",Claim
1615,177-ARR,177-ARR_v2_82@2,,"This is a very sensitive matter, as the courts try to keep a balance between transparency (the public's right to know) and privacy (respect for private and family life).",,"Add,Claim",Claim
1616,177-ARR,177-ARR_v2_82@3,,ECtHR cases are partially annonymized by the court.,,"Add,Fact/Evidence",Fact/Evidence
1617,177-ARR,,177-ARR_v1_2@3,,"Furthermore, we analyze what causes performance differences across groups, and how group-robust fine-tuning techniques fail to mitigate group disparities under both representation inequality and temporal distribution swift.","Delete,Fact/Evidence",Fact/Evidence
1618,177-ARR,177-ARR_v2_82@4,,Its data is processed and made public in accordance with the European data protection laws.,,"Add,Fact/Evidence",Fact/Evidence
1619,177-ARR,177-ARR_v2_82@5,,"SCOTUS cases may also contain personal information and the data is processed and made available by the US Supreme Court, whose proceedings are public.",,"Add,Claim",Claim
1620,177-ARR,177-ARR_v2_82@6,,"While this ensures compliance with US law, it is very likely that similarly to the ECtHR any processing could be justified by either implied consent or legitimate interest under European law.",,"Add,Claim",Claim
1621,177-ARR,177-ARR_v2_82@7,,"In FSCS, the names of the parties have been redacted by the courts according to the official guidelines.",,"Add,Fact/Evidence",Fact/Evidence
1622,177-ARR,177-ARR_v2_82@8,,CAIL cases are also partially anonymized by the courts according to the courts' policy.,,"Add,Fact/Evidence",Fact/Evidence
1623,177-ARR,177-ARR_v2_82@9,,Its data is processed and made public in accordance with Chinese Law.,,"Add,Fact/Evidence",Fact/Evidence
1624,177-ARR,177-ARR_v2_84@0,,"In the context of law, the principle of equality and non-discrimination is of paramount importance at international, regional and domestic level.",,"Add,Claim",Claim
1625,177-ARR,177-ARR_v2_84@1,,"Article 2 of the Universal Declaration of Human Rights (UDHR) prohibits discrimination on grounds of race, colour, sex, language, religion, political or other opinion, national or social origin, property, birth or other status, with the latter term having an open-ended meaning.",,"Add,Claim",Claim
1626,177-ARR,177-ARR_v2_84@2,,"The principle is also reflected in several other United Nations (UN) human rights instruments and in regional legal instruments, including Article 24 American Convention of Human Rights (ACHR), Articles 2 and 3 African Charter on Human and People's Rights (ACHPR) and Article 14 and Protocol N. 12 of the European Convention on Human Rights (ECHR).",,"Add,Claim",Claim
1627,177-ARR,177-ARR_v2_85@0,,"The principle of non-discrimination is included in all international human rights instruments, although only a few explicitly provide a definition of non-discrimination (e.g. Article 1(1) CERD, Article 1 CEDAW, Article 2 CRPD, Article 1(1) ILO).",,"Add,Claim",Claim
1628,177-ARR,177-ARR_v2_85@2,,"In addition, many international instruments explicitly allow for 'positive action', without mandating an obligation on States in that sense.",,"Add,Claim",Claim
1629,177-ARR,177-ARR_v2_85@3,,The term 'positive action' refers to active measures taken by private institutions or governments that favour members of previously disadvantaged groups with the aim to remedy the effects of past and present discrimination.,,"Add,Claim",Claim
1630,177-ARR,177-ARR_v2_85@4,,"At both regional and domestic level, a great number of countries have implemented non-discrimination law directly in their legislation.",,"Add,Claim",Claim
1631,177-ARR,177-ARR_v2_85@5,,"The following brief analysis provides an overview of the legal framework applicable in the EU and in the USA, in light of the wide deployment of algorithms and increasing risk of algorithmic discrimination documented in these contexts.",,"Add,Claim",Claim
1632,177-ARR,177-ARR_v2_90@0,,"Beyond the boundaries of EU and US law, a great number of countries explicitly prohibit discrimination in their laws on the basis of nationality, race, ethnicity and religion.",,"Add,Claim",Claim
1633,177-ARR,177-ARR_v2_90@1,,Other countries extend the prohibition only in relation to race and religion instead.,,"Add,Claim",Claim
1634,177-ARR,177-ARR_v2_90@2,,"In many countries, there is not yet any specific or dedicated law against non-discrimination, such as in China, India, Indonesia, Japan, Korea and Saudi Arabia.",,"Add,Claim",Claim
1635,177-ARR,177-ARR_v2_90@3,,This does not imply by any means that there are not potentially separate pieces of legislation that enforce non-discrimination for some class attributes.,,"Add,Claim",Claim
1636,177-ARR,177-ARR_v2_91@0,,"In this section, we provide finer details on attribute extraction and grouping.",,"Add,Fact/Evidence",Fact/Evidence
1637,177-ARR,177-ARR_v2_92@1,,We group the defendant states mainly relying on their classification by the EuroVoc thesaurus 24 .,,"Add,Fact/Evidence",Fact/Evidence
1638,177-ARR,177-ARR_v2_92@2,,"The grouping mainly reflects the high disproportion of violations between mainly Eastern European countries, and in a second degree Central European, and the rest (Western European, Nordic, Mediterranean states).",,"Add,Fact/Evidence",Fact/Evidence
1639,177-ARR,177-ARR_v2_92@3,,"Applicant's birth year is extracted from the case facts, if available, e.g., ""The first applicant, Mr X, was born in 1967."", using Regular Expressions (RegEx).",,"Add,Fact/Evidence",Fact/Evidence
1640,177-ARR,177-ARR_v2_92@4,,"Then, we compute the age by subtract birth year from the judgment date, extracted from the HUDOC case metadata, as well.",,"Add,Fact/Evidence",Fact/Evidence
1641,177-ARR,177-ARR_v2_92@5,,The age grouping does not follow any pattern and aims to cluster applicants in discrete groups that have statistical support.,,"Add,Fact/Evidence",Fact/Evidence
1642,177-ARR,177-ARR_v2_19@3,177-ARR_v1_15@3,"We consider the available 14 thematic issue areas (e.g, Criminal Procedure, Civil Rights, Economic Activity, etc.) as labels.","We consider the available 14 thematic issue areas (e.g, Criminal Procedure, Civil Rights, Economic Activity, etc.).","Modify,Clarity",Clarity
1643,177-ARR,177-ARR_v2_20@0,177-ARR_v1_16@0,"From SCDB, we also use the following attributes to study fairness: (a) the type of respondent, which is a manual categorization of respondents (defendants) in five categories (person, public entity, organization, facility and other); and (c) the direction of the decision, i.e., whether the decision is considered liberal, or conservative, provided by SCDB.","From SCDB, we also use the following attributes to study fairness: (a) the type of respondent, which is a manual categorization of respondents (defendants) in five categories (person, public entity, organization, facility and other); and (c) the direction of the decision, i.e., whether the decision is liberal, or conservative, provided by SCDB.","Modify,Clarity",Clarity
1644,177-ARR,177-ARR_v2_23@1,177-ARR_v1_19@1,"The Chinese AI and Law challenge (CAIL) dataset (Xiao et al., 2018) is a Chinese legal NLP dataset for judgment prediction and contains over 1m criminal cases.","The Chinese AI and Law challenge (CAIL) dataset (Xiao et al., 2018) is a Chinese legal NLP dataset for judgment prediction and contains more 1m criminal cases.","Modify,Grammar",Grammar
1645,177-ARR,177-ARR_v2_23@7,177-ARR_v1_20@4,"In our study, we re-frame the imprisonment term prediction and examine a soft version, dubbed crime severity prediction task, a multi-class classification task, where given the facts of a case, the goal is to predict how severe was the committed crime with respect to the imprisonment term.","In our study, we examine a crime severity prediction task, a single-label multi-class classification task, where given the facts of a case, the goal is to predict how severe was the committed crime with respect to the imprisonment term.","Modify,Fact/Evidence",Fact/Evidence
1646,177-ARR,177-ARR_v2_4@0,177-ARR_v1_4@2,"Natural Language Processing (NLP) for law (Chalkidis and Kampas, 2019;Aletras et al., 2019;Zhong et al., 2020;Chalkidis et al., 2022) receives increasing attention.","Natural Language Processing (NLP) for law (Chalkidis and Kampas, 2019;Aletras et al., 2019;Zhong et al., 2020) receives increasing attention.","Modify,Fact/Evidence",Fact/Evidence
1647,177-ARR,177-ARR_v2_2@0,177-ARR_v1_2@0,We present a benchmark suite of four datasets for evaluating the fairness of pre-trained language models and the techniques used to fine-tune them for downstream tasks.,We present a benchmark suite of four datasets for evaluating the fairness of pre-trained legal language models and the techniques used to fine-tune them for downstream tasks.,"Modify,Clarity",Clarity
1648,177-ARR,177-ARR_v2_4@2,177-ARR_v1_4@4,"They can also help legal scholars to study case law (Katz, 2012;Coupette et al., 2021), improve access of law to laypersons, help sociologists and research ethicists to expose biases in the justice system (Angwin et al., 2016;Dressel and Farid, 2018), and even scrutinize decision-making itself (Bell et al., 2021).","They can also help legal scholars to study case law (Katz, 2012), improve access of law to laypersons, help sociologists and research ethicists to expose biases in the justice system (Angwin et al., 2016;Dressel and Farid, 2018), and even scrutinize decision-making itself (Bell et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
1649,177-ARR,177-ARR_v2_51@3,177-ARR_v1_54@1,"Given the limited size of these models, we can effectively use up to 4096 tokens in ECtHR and SCOTUS and up to 2048 tokens in FSCS and CAIL for up to 16 samples per batch in a 24GB GPU card.","Given the limited size of these models, we can effectively use up to 4096 tokens in ECtHR and SCOTUS and up to 2048 tokens in FSCS and SPC for up to 16 samples per batch in a 24gb nvidia gpu card.","Modify,Fact/Evidence",Fact/Evidence
1650,177-ARR,177-ARR_v2_51@4,177-ARR_v1_54@2,"10 For completeness, we also consider linear Bag-of Words (BoW) classifiers using TF-IDF scores of the most frequent n-grams (where n = 1, 2, 3) in the training corpus of each dataset.","12 For completeness, we also consider linear Bagof Words (BoW) classifiers using TF-IDF scores of the most frequent n-grams (where n = 1, 2, 3) in the training corpus of each dataset.","Modify,Grammar",Grammar
1651,177-ARR,177-ARR_v2_5@2,177-ARR_v1_4@6,"Direct discrimination occurs when one person is treated less favourably than others would be treated in comparable situations on grounds of sex, racial or ethnic origin, disability, sexual orientation, religion or belief and age.","Discrimination occurs when one person is treated less favourably than others would be treated in comparable situations on grounds of sex, racial or ethnic origin, disability, sexual orientation, religion or belief and age.","Modify,Clarity",Clarity
1652,177-ARR,177-ARR_v2_62@1,177-ARR_v1_56@4,"To estimate their performance, we report the average macro-F1 across groups (mF1) and the group disparity (GD) among groups measured as the group-wise std dev.:",We report the average macro-F1 across groups (mF1) and the group disparity (GD) among groups measured as the group-wise std dev.:,"Modify,Clarity",Clarity
1653,177-ARR,177-ARR_v2_53@0,177-ARR_v1_59@0,Results,Baseline Results,"Modify,Other",Other
1654,177-ARR,177-ARR_v2_67@0,177-ARR_v1_61@0,"As one can see, transformer-based models trained with the ERM algorithm, i.e., without taking into account information about groups and their distribution, perform either better on in the same ballpark than models trained with methods specialized to mitigate biases (Section 4), with an average loss of 0.17% only in terms of mF1 and of 0.78% in terms of mF1 W .","As one can see, transformer-based models trained with the ERM algorithm, i.e., without taking into account information about groups and their distribution, perform either better on in the same ballpark than models trained with methods specialized to mitigate biases (Section 4), with an average loss of 0.17 only in terms of mF1 and of 0.78 in terms of mF1 W .","Modify,Fact/Evidence",Fact/Evidence
1655,177-ARR,177-ARR_v2_77@2,177-ARR_v1_61@1,"While, these algorithms improve worst case performance in the literature, when applied in a controlled experimental environment, they fail in a more realistic setting, where both groups across attributes, and labels are imbalanced, while also both group and label distributions change over time.","While, these algorithms improve worst case performance in the literature, when applied in a controlled experimental environment, they fail in a real-world setting, where both groups across attributes and labels are imbalanced, while also both group and label distribution change over time.","Modify,Clarity",Clarity
1656,177-ARR,177-ARR_v2_59@10,177-ARR_v1_68@3,27% originated in E. Switzerland (bestperforming group) and 42% in Federation (worst performing group) are relevant to public law.,27% originated in E. Switzerland (best-performing group) and 42% in Federation (worst performing group) are relevant to penal law.,"Modify,Fact/Evidence",Fact/Evidence
1657,177-ARR,177-ARR_v2_59@11,177-ARR_v1_68@4,"In both attributes, there is a 15% increase of cases relevant to public law for the worst performing groups.","In both attributes, there is a 15% increase of cases relevant to penal law for the worst performing groups.","Modify,Fact/Evidence",Fact/Evidence
1658,177-ARR,177-ARR_v2_59@12,177-ARR_v1_68@5,"In other words, the group disparity in one attribute A 2 (language, region) could be also explained by the influence of another attribute A 1 (legal area).","In other words, the group disparity in one attribute A2 (language, region) could be also explained by the influence of another attribute A1 (legal area).","Modify,Grammar",Grammar
1659,177-ARR,177-ARR_v2_60@0,177-ARR_v1_69@0,"In Table 3, we report the performance in the aforementioned cross-attribute (A 1 , A 2 ) pairings.","In Table 4, we report the performance in the aforementioned cross-attribute (A1, A2) pairings.","Modify,Grammar",Grammar
1660,177-ARR,177-ARR_v2_77@0,177-ARR_v1_72@0,"We introduced FairLex, a multi-lingual benchmark suite for the development and testing of models and bias-mitigation algorithms within the legal domain, based on four datasets covering four jurisdictions, five languages and various sensitive attributes.","We introduced FairLex, a multi-lingual benchmark for the development and testing of bias-mitigation models or algorithms within the legal domain, based on four datasets covering four jurisdictions, five languages and various sensitive attributes.","Modify,Clarity",Clarity
1661,177-ARR,177-ARR_v2_77@1,177-ARR_v1_72@1,"Furthermore, we provided competitive baselines including transformer-based language models adapted to the examined datasets, and examination of performance of four group robust algorithms (Adversarial Removal, IRM, Group DRO, and V-REx).","Furthermore, we provided competitive baselines including state-of-the-art transformer-based models adapted to the examined datasets, and an in-dept examination of performance of four group robust algorithms (Adversarial Removal, IRM, Group DRO, and REx).","Modify,Fact/Evidence",Fact/Evidence
1662,177-ARR,177-ARR_v2_83@0,177-ARR_v1_73@0,"The legal notion of discrimination has a different scope and semantics in comparison to the notions of fairness and bias used in the context of machine learning (Gerards and Xenedis, 2020), where the aim usually is not to achieve equal odds, e.g. that a court shall rule the same decision for both men and woman based on similar facts, or to have 50/50 favourable decisions for both man and woman, but equal opportunities (Rawls, 1971).","The legal notion of discrimination has a different scope and semantics in comparison to the notions of fairness and bias used in the context of machine learning (Gerards and Xenedis, 2020), where the aim usually is to achieve equal odds, e.g. that a court shall rule the same decision for both men and woman based on similar facts, or to have 50/50 favourable decisions for both man and woman, but equal opportunities (Rawls, 1971).","Modify,Fact/Evidence",Fact/Evidence
1663,177-ARR,177-ARR_v2_86@5,177-ARR_v1_74@5,"The Directives define indirect discrimination as situations where an apparently neutral provision, criterion or practice would put persons with a protected characteristic at disadvantage in comparison to other persons, unless 'that provision, criterion or practice is ""justified by a legitimate aim and the means of achieving that aim are appropriate and necessary"".","Indirect discrimination refers to situations in which an apparently neutral provision, criterion or practice would put persons with a protected characteristic at disadvantage in comparison to other persons, unless 'that provision, criterion or practice is ""justified by a legitimate aim and the means of achieving that aim are appropriate and necessary"".","Modify,Clarity",Clarity
1664,177-ARR,177-ARR_v2_7@6,177-ARR_v1_5@3,"Contrary, there is also a capability-centered approach to fairness (Anderson, 1999;Robeyns, 2009), in which the goal is to reserve enough resources per group to achieve similar performance levels, which is ultimately what is important for how individuals are treated in legal processes.","Contrary, there is also a capability-centered approach to fairness (Anderson, 1999;Robeyns, 2009), in which the goal is reserve enough resources per group to achieve similar performance levels, which is ultimately what is important for how individuals are treated in legal processes.","Modify,Grammar",Grammar
1665,177-ARR,177-ARR_v2_88@0,177-ARR_v1_76@0,In April 2021 the European Commission presented a proposal for a Regulation laying down harmonized rules on artificial intelligence (AI Act / AIA).,"In April 2021 the European Commission presented a proposal for a Regulation laying down harmonized rules on artificial intelligence (AI Act / AIA) (Council of European Union, 2021).","Modify,Fact/Evidence",Fact/Evidence
1666,177-ARR,177-ARR_v2_2@1,177-ARR_v1_2@1,"Our benchmarks cover four jurisdictions (European Council, USA, Switzerland, and China), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, region, language, and legal area).","Our benchmarks cover four jurisdictions (European Council, USA, Swiss, and Chinese), five languages (English, German, French, Italian and Chinese) and fairness across five attributes (gender, age, nationality/region, language, and legal area).","Modify,Grammar",Grammar
1667,177-ARR,177-ARR_v2_6@1,177-ARR_v1_77@0,"The topic deserves great attention because AI systems learning from historical data pose the risk of lack of generalisability beyond the training data, and more importantly transporting biases previously encumbered in the data in future decision-making, thereby exponentially increasing their effect (Delacroix, 2022).","The topic deserves great attention because AI systems learning from historical data pose the risk of transporting biases previously encumbered in the data in future decision-making, thereby exponentially increasing their effect.","Modify,Fact/Evidence",Fact/Evidence
1668,177-ARR,177-ARR_v2_8@1,177-ARR_v1_6@1,"For everyone to be treated equally under the law, regardless of race, gender, nationality, or other characteristics, NLP assistive technologies need to be (approximately) insensitive to these attributes.","For everyone to be treated equally under the law, regardless of race, gender, nationality, or other characteristics, NLP technologies need to be (approximately) insensitive to these attributes.","Modify,Clarity",Clarity
1669,177-ARR,177-ARR_v2_7@0,177-ARR_v1_6@3,Historical legal data do not represent all groups in our societies equally and tend to reflect social biases in our societies and legal institutions.,"Moreover, historical legal data tends to reflect social biases in our societies and legal institutions.","Modify,Claim",Claim
1670,177-ARR,177-ARR_v2_2@2,177-ARR_v1_2@2,"In our experiments, we evaluate pretrained language models using several grouprobust fine-tuning techniques and show that performance group disparities are vibrant in many cases, while none of these techniques guarantee fairness, nor consistently mitigate group disparities.","In our experiments, we evaluate pre-trained language models using several group-robust fine-tuning techniques and show that none of these combinations guarantee fairness, nor consistently mitigate group disparities.","Modify,Fact/Evidence",Fact/Evidence
1671,177-ARR,177-ARR_v2_11@1,177-ARR_v1_9@1,See Mehrabi et al. (2021); Makhlouf et al. (2021); Ding et al. (2021) for recent surveys.,See Mehrabi et al. (2021) for a recent survey.,"Modify,Fact/Evidence",Fact/Evidence
1672,177-ARR,177-ARR_v2_11@4,177-ARR_v1_9@4,The fairness-promoting learning algorithms we evaluate are discussed in detail in Section 4.,The fairness-promoting learning algorithms we evaluate are discussed in detail in §4.,"Modify,Clarity",Clarity
1673,177-ARR,177-ARR_v2_12@3,177-ARR_v1_9@9,"Angwin et al. found that blacks were almost twice as likely as whites to be mislabeled as high risk (of reoffending), revealing a severe racial bias in the system.","Angwin et al. (2016) found that blacks were almost twice as likely as whites to be mislabeled as high risk (of re-offending), revealing a severe racial bias in the system.","Modify,Fact/Evidence",Fact/Evidence
1674,177-ARR,177-ARR_v2_12@5,177-ARR_v1_10@0,"These studies relied on tabular data and did not involve text processing (e.g., encoding case facts or decisions).",These studies relied on tabular data and did not involve text processing.,"Modify,Fact/Evidence",Fact/Evidence
1675,177-ARR,177-ARR_v2_14@2,177-ARR_v1_11@2,"Furthermore, we provide competitive baselines including pre-trained transformer-based language models, adapted to the examined datasets, and an in-dept examination of performance of four group robust algorithms described in detail in Section 4.","Furthermore, we provide competitive baselines including stateof-the-art transformer-based models, adapted to the examined datasets, and an in-dept examination of performance of four group robust algorithms described in detail in Section 4.","Modify,Fact/Evidence",Fact/Evidence
1691,181-ARR,,181-ARR_v1_35@3,,The second row shows the occurrence time of the type of GQ in GQNLI.,"Delete,Fact/Evidence",Fact/Evidence
1692,181-ARR,,181-ARR_v1_35@4,,The following rows show models' performance on the dataset.,"Delete,Fact/Evidence",Fact/Evidence
1693,181-ARR,,181-ARR_v1_35@5,,We tested most competitive models fine-tuned for NLI available on Hugging Face.,"Delete,Fact/Evidence",Fact/Evidence
1694,181-ARR,,181-ARR_v1_35@6,,All but ALBERT (xxlarge) and DeBERTa-v3 (base) are size large.,"Delete,Fact/Evidence",Fact/Evidence
1695,181-ARR,,181-ARR_v1_35@7,,"S, M, F, Ling, A, DocNLI refer to SNLI, MNLI, Fever-NLI, LingNLI (Parrish et al., 2021), ANLI and DocNLI (Yin et al., 2021), respectively.","Delete,Fact/Evidence",Fact/Evidence
1696,181-ARR,,181-ARR_v1_35@8,,Numbers in bold represent the highest accuracy in one category.,"Delete,Fact/Evidence",Fact/Evidence
1697,181-ARR,,181-ARR_v1_35@9,,Due to space limitation we provide the link to each modelin the Appendix H.,"Delete,Fact/Evidence",Fact/Evidence
1698,181-ARR,,181-ARR_v1_66@0,,We reused the fine-tuned BERT and RobERTa in Section 4.,"Delete,Fact/Evidence",Fact/Evidence
1699,181-ARR,,181-ARR_v1_66@1,,The other fine-tuned LMs are from Hugging Face.,"Delete,Fact/Evidence",Fact/Evidence
1700,181-ARR,181-ARR_v2_36@2,,It is worth noting that the level of semantic or pragmatic interpretation difference of GQs is reflected in the measurement.,,"Add,Claim",Claim
1701,181-ARR,181-ARR_v2_20@3,181-ARR_v1_24@3,"In our error analysis, we initially focus on three English NLI datasets, MultiNLI (MNLI; , SNLI (Bowman et al., 2015a) and ANLI (Nie et al., 2020) as testbeds.","In our error analysis, we initially focus on three English NLI datasets, MultiNLI (MNLI; Williams et al., 2018), SNLI (Bowman et al., 2015a) and ANLI (Nie et al., 2020) as testbeds.","Modify,Fact/Evidence",Fact/Evidence
1702,181-ARR,181-ARR_v2_27@7,181-ARR_v1_31@7,"We fine-tune mBERT 5 (Devlin et al., 2019) and XLM 6 (Lample and Conneau, 2019) on the MNLI training set and evaluate them on XNLI.",We fine-tune mBERT training set and evaluate them on XNLI.,"Modify,Fact/Evidence",Fact/Evidence
1703,181-ARR,181-ARR_v2_34@2,181-ARR_v1_38@2,"To choose the premises, we randomly sampled 100 premises with GQs from SNLI and ANLI test sets, respectively, and selected 10 premises in total, that we consider are semantically adequate for adding GQs and making simple hypotheses.","To choose the premises, we randomly sampled 100 premises with GQs from SNLI and ANLI test sets, respectively, and selected 30 premises in total, that we consider are semantically adequate for adding GQs and making simple hypotheses.","Modify,Fact/Evidence",Fact/Evidence
1704,181-ARR,181-ARR_v2_39@1,181-ARR_v1_42@1,"With more training data, models improve, but the best performance is 48%, less than 15 points above chance level.","With more training data, models improve, but the best performance is 42.7%, less than 10 points above chance level.","Modify,Fact/Evidence",Fact/Evidence
1705,181-ARR,181-ARR_v2_43@2,181-ARR_v1_46@2,"BART is no longer the second best model, replaced by RoBERTa.","DeBERTa-v3 is no longer the best model, replaced by BERT and BART.","Modify,Fact/Evidence",Fact/Evidence
1706,181-ARR,181-ARR_v2_43@3,181-ARR_v1_46@3,The improvement by training with more data is overall consistent for reasoning over GQs with negation.,The improvement by training with more data becomes unstable for reasoning over GQs with negation.,"Modify,Fact/Evidence",Fact/Evidence
1707,181-ARR,181-ARR_v2_47@3,181-ARR_v1_50@3,"The training bias give an advantage to the model on the subsumption subset, half cases of which are labelled neutral. But such bias has a negative effect on non-subsumption cases; the accuracy drops by 20.2% comparing to the model without training with DocNLI.","The training bias give an advantage to the model on the subsumption subset, half cases of which are labelled neutral. But such bias has a negative effect on non-subsumption cases; the accuracy drops by 16.2% comparing to the model without training with DocNLI.","Modify,Fact/Evidence",Fact/Evidence
1708,181-ARR,181-ARR_v2_51@4,181-ARR_v1_54@4,"All of the above focused on English, but in an extension to TaxiNLI, K et al. ( 2021) incorporated quantifiers into the Logic class and found a large cross-lingual transfer gap on LMs.","All of the above focused on English, but in an extension to TaxiNLI, K et al. ( 2021) incorporated quantifiers into the Logic class and found a large cross-lingual tranfer gap on LMs.","Modify,Grammar",Grammar
1709,181-ARR,181-ARR_v2_53@2,181-ARR_v1_56@2,We examined generalized quantifiers in multilingual NLU tasks with regards to their expressiveness and logical reasoning requirement.,We examined generalized quantifiers in NLU tasks with regards to their expressiveness and logical reasoning requirement.,"Modify,Fact/Evidence",Fact/Evidence
1710,181-ARR,181-ARR_v2_15@1,181-ARR_v1_19@1,"At the same time, generalized quantifiers can be instantiated very differently across languages due to pragmatic considerations (Grice, 1989) or cognitive economy and costbenefit optimisation in the exchange of information (Levinson et al., 2000;Steinert-Threlkeld, 2021;Uegaki, 2022).","At the same time, generalized quantifiers can be instantiated very differently across languages due to pragmatic considerations (Grice, 1989) or cognitive economy and cost-benefit optimisation in the exchange of information (Sperber and Wilson, 1986;Levinson et al., 2000).","Modify,Fact/Evidence",Fact/Evidence
1711,182-ARR,,182-ARR_v1_41@1,,"For example, MCD may be sensitive to errors in acoustic feature prediction outside the perceptual range of listening test participants.","Delete,Claim",Claim
1712,182-ARR,,182-ARR_v1_60@1,,Results are shown in Figure 4.,"Delete,Fact/Evidence",Fact/Evidence
1713,182-ARR,,182-ARR_v1_60@5,,There were six participants for the Kanien'kéha survey and 12 participants for the Gitksan survey.,"Delete,Fact/Evidence",Fact/Evidence
1714,182-ARR,,182-ARR_v1_70@0,,"In Table 1, we compare the training and inference time of the off-the-shelf FastSpeech2 system, as well as the adapted version described above.","Delete,Fact/Evidence",Fact/Evidence
1715,182-ARR,182-ARR_v2_23@3,,"In keeping with this, the datasets described in this paper are not being released publicly at this time.",,"Add,Fact/Evidence",Fact/Evidence
1716,182-ARR,182-ARR_v2_28@2,,Handling utterances with non-Kanien'kéha characters would have required grapheme-to-phoneme prediction capable of dealing with multilingual text and code-switching which we did not have available.,,"Add,Claim",Claim
1717,182-ARR,,182-ARR_v1_16@1,,"Assuming a rate of 200 forms/hr for 4 hours per day, 5 days per week, this would take a teacher out of the classroom for approximately a year.","Delete,Claim",Claim
1718,182-ARR,182-ARR_v2_52@2,,MUSHRA-style questions were used as a practical way to evaluate this large number of models.,,"Add,Fact/Evidence",Fact/Evidence
1719,182-ARR,182-ARR_v2_59@1,,"We used A/B tests for more targeted comparisons between different systems, namely cold-start vs. fine-tuned and neural vs. concatenative.",,"Add,Fact/Evidence",Fact/Evidence
1720,182-ARR,182-ARR_v2_60@2,,The model received a 3.56 ± 0.26 MOS compared with a MOS for the reference recordings of 4.63 ± 0.19 as shown in Figure 5.,,"Add,Fact/Evidence",Fact/Evidence
1721,182-ARR,182-ARR_v2_61@3,,"As seen in Figure 6, participant responses were generally positive; full responses are reported in Appendix B.",,"Add,Fact/Evidence",Fact/Evidence
1722,182-ARR,182-ARR_v2_69@0,,"For reasons of environmental impact and accessibility, reducing the amount of computation required for both training and inference is important for any neural speech synthesis system, particularly so for Indigenous languages.",,"Add,Claim",Claim
1723,182-ARR,182-ARR_v2_70@7,,"Reducing the number of parameters in a neural TTS model should translate to increased efficiency, and might make the model less prone to overfitting when training on limited amounts of data.",,"Add,Claim",Claim
1724,182-ARR,182-ARR_v2_70@8,,"As discussed in §4.2.2, we modified the base implementation of FastSpeech2 from Chien (2021) closely following the lightweight alternative discovered through neural architecture search in Luo et al. (2021).",,"Add,Fact/Evidence",Fact/Evidence
1725,182-ARR,182-ARR_v2_70@10,,"We saw a 33% improvement in average batch processing times on the GPU during training, and 64% on the CPU, which may be even more relevant for Indigenous language communities with limited computational resources.",,"Add,Fact/Evidence",Fact/Evidence
1726,182-ARR,182-ARR_v2_70@11,,"During inference, we saw a 15% speed-up on GPU and 57% on CPU.",,"Add,Fact/Evidence",Fact/Evidence
1727,182-ARR,182-ARR_v2_70@14,,CPU tests were performed on an Intel(R) Xeon(R) CPU E5-2650 v2 @ 2.60GHz with 4 cores and 16GB memory reserved.,,"Add,Fact/Evidence",Fact/Evidence
1728,182-ARR,182-ARR_v2_70@15,,All timings used a batch size of 16.,,"Add,Fact/Evidence",Fact/Evidence
1729,182-ARR,182-ARR_v2_71@0,,"Strubell et al. ( 2019) also argue that NLP researchers should have a responsibility to disclose the environmental footprint of their research, in order for the community to effectively evaluate any gains and to allow for a more equitable and reproducible field.",,"Add,Fact/Evidence",Fact/Evidence
1730,182-ARR,182-ARR_v2_22@0,182-ARR_v1_24@0,"Although the term 'low resource' is used to describe a wide swath of languages, most Indigenous languages in Canada would be considered 'lowresource' in multiple senses of the word, having both a low amount of available data (annotated or unannotated), and a relatively low number of speakers.","Although the term 'low resource' is used to describe a wide swath of languages, most Indigenous languages in Canada would be considered 'lowresource' in multiple senses of the word, having both a low amount of available data (annotated or unannotated), and a low number of speakers proportional to the population.","Modify,Clarity",Clarity
1731,182-ARR,182-ARR_v2_22@1,182-ARR_v1_24@1,"Most Indigenous languages lack transcribed audio corpora, and fewer still have such data recorded in a studio context.",Most Indigenous languages lack transcribed audio corpora; fewer still have such data recorded in a studio context.,"Modify,Grammar",Grammar
1732,182-ARR,182-ARR_v2_27@2,182-ARR_v1_29@2,"Later, a team of four speakers and learners, including this paper's third author, aligned the text and audio at the utterance level using Praat (Boersma and van Heuven, 2001) and ELAN (Brugman and Russel, 2004).","Later, a team of four speakers and learners, including one of the authors, aligned the text and audio at the utterance level using Praat (Boersma and van Heuven, 2001) and ELAN (Brugman and Russel, 2004).","Modify,Clarity",Clarity
1733,182-ARR,182-ARR_v2_28@0,182-ARR_v1_30@0,"While a total of 24 hours of audio were recorded, members of the Kanien'kéha-speaking community told us it would be inappropriate to use the voices of speakers who had passed away, leaving only recordings of Satewas's voice.","While a total of 24 hours of audio were recorded, it was deemed inappropriate to use the voices of speakers who had passed away, leaving only recordings of Satewas's voice.","Modify,Fact/Evidence",Fact/Evidence
1734,182-ARR,182-ARR_v2_28@1,182-ARR_v1_30@1,"Using a GMMbased speaker ID system (Kumar, 2017), we removed utterances by these speakers, then removed utterances that were outliers in duration (less than 0.4s or greater than 11s) and speaking rate (less than 4 phones per second or greater than 15), recordings with an unknown phase effect present, and utterances containing non-Kanien'kéha characters (e.g. proper names like 'Euphrades').","Using a GMMbased speaker ID system Kumar (2017), we removed utterances by these speakers, then removed utterances that were outliers in duration (less than 0.4s or greater than 11s) and speaking rate (less than 4 phones per second or greater than 15), recordings with an unknown phase effect present, and utterances containing non-Kanien'kéha characters (e.g. proper names like 'Euphrades').","Modify,Clarity",Clarity
1735,182-ARR,182-ARR_v2_31@0,182-ARR_v1_33@0,"As there were no studio-quality recordings of the Gitksan language publicly available, and as an intermediate speaker of the language, the first author recorded a sample set himself.","As there were no studio-quality recordings of the Gitksan language publicly available, and as an intermediate speaker of the language, the first author decided to record a sample set himself.","Modify,Clarity",Clarity
1736,182-ARR,182-ARR_v2_34@0,182-ARR_v1_36@0,"As there were no studio-quality recordings of the SENĆOŦEN language publicly available, we recorded 25.92 minutes of the language with PENÁĆ David Underwood reading two stories originally spoken by elder Chris Paul.","As there were no studio-quality recordings of the SENĆOŦEN language publicly available, we recorded 25.92 minutes of the language from PENÁĆ David Underwood reading two stories originally spoken by elder Chris Paul.","Modify,Grammar",Grammar
1737,182-ARR,182-ARR_v2_37@0,182-ARR_v1_39@0,Low-Resource Evaluation,Low-resource Evaluation,"Modify,Grammar",Grammar
1738,182-ARR,182-ARR_v2_38@1,182-ARR_v1_40@1,"For some Indigenous languages in Canada, the total number of speakers of the language is less than the number typically required for statistical significance in a listening test (Wester et al., 2015).","For some Indigenous languages in Canada, the total number of speakers of the language is less than the number typically required for statistical significance in a listening test.","Modify,Fact/Evidence",Fact/Evidence
1739,182-ARR,182-ARR_v2_38@2,182-ARR_v1_40@2,"While the number of speakers in these conditions is sub-optimal for statistical analysis, we have been told by the communities we work with that the positive assessment of a few widely respected and community-engaged language speakers would be practically sufficient to assess the pedagogical value of speech models in language revitalization contexts.","While the number of speakers in these conditions is sub-optimal for statistical analysis, the positive assessment of a few widely respected and community-engaged language speakers is practically sufficient to assess the pedagogical value of speech models in language revitalization contexts.","Modify,Fact/Evidence",Fact/Evidence
1740,182-ARR,182-ARR_v2_39@0,182-ARR_v1_41@0,"While some objective metrics do exist, such as Mel cepstral distortion (MCD, Kubichek, 1993), we do not believe they should be considered reliable proxies for listening tests.","While some objective metrics do exist, such as Mel cepstral distortion (MCD, Kubichek, 1993), we don't believe they should be considered reliable proxies for listening tests.","Modify,Clarity",Clarity
1741,182-ARR,182-ARR_v2_41@1,182-ARR_v1_44@1,"Due to the prominence of Tacotron2 (Shen et al., 2018), it seems that many people have assumed that the data requirements for training any neural speech synthesizer of similar quality must be the same as the requirements for this particular model.","Due to the prominence of Tacotron2 (Shen et al., 2018), many people have assumed the data requirements for training a Tacotron2 model are synonymous with the data requirements for training any neural speech synthesizer of similar quality.","Modify,Clarity",Clarity
1742,182-ARR,182-ARR_v2_42@0,182-ARR_v1_45@0,Replacing attention-based weak duration models,Architecture choice,"Modify,Other",Other
1743,182-ARR,182-ARR_v2_43@0,182-ARR_v1_46@0,"Tacotron2 is an autoregressive model, meaning it predicts the speech parameters ŷt from both the input sequence of text x and the previous speech parameters y 1 , ..., y t−1 .","Tacotron2 is an autoregressive model, meaning it predicts the speech parameters y t from both the input sequence of text x and the previous speech parameters y 1 , ..., y t−1 .","Modify,Fact/Evidence",Fact/Evidence
1744,182-ARR,182-ARR_v2_43@1,182-ARR_v1_46@1,"Typically, the model is trained with 'teacher-forcing', where the autoregressive frame y t−1 passed as input for predicting ŷt is taken from the ground truth acoustic features and not the prediction network's output from the previous frame ŷt−1 .","Typically, the model is trained with 'teacher-forcing', where the autoregressive frame y t−1 passed as input for predicting y is taken from the ground truth label and not the prediction network's output from the previous frame ŷt−1 .","Modify,Fact/Evidence",Fact/Evidence
1745,182-ARR,182-ARR_v2_43@2,182-ARR_v1_46@2,"As discussed by , such a system might learn to copy the teacher forcing input or disregard the text en-tirely, which could still optimize Tacotron2's root mean square error function over predicted acoustic features, but result in an untrained or degenerate attention network which is unable to properly generalize to new inputs at inference time when the teacher forcing input is unavailable.","As discussed by , such a system might learn to copy the teacher forcing input or disregard the text entirely, which could still optimize Tacotron2's root mean square error function, but result in an untrained or degenerate attention network which is unable to properly generalize to new inputs at inference time when the teacher forcing input is unavailable.","Modify,Claim",Claim
1746,182-ARR,182-ARR_v2_45@0,182-ARR_v1_48@0,"FastSpeech2 (Ren et al., 2021), and similar systems like FastPitch (Łańcucki, 2021), present an alternative to Tacotron2-type attentive, autoregressive systems with similar listening test results and without the characteristic errors related to attention.","FastSpeech2 (Ren et al., 2021), and similar systems like FastPitch (Łańcucki, 2021), present an alternative to Tacotron2-type autoregressive systems with similar listening test results and without the characteristic errors related to attention.","Modify,Fact/Evidence",Fact/Evidence
1747,182-ARR,182-ARR_v2_45@1,182-ARR_v1_48@1,"Instead of modelling duration using attention, they include an explicit duration prediction module trained on phone duration targets extracted from the training data.","Instead of modelling duration using attention, they include an explicit duration prediction module trained on phone duration targets extracted from forced alignments over the training data.","Modify,Fact/Evidence",Fact/Evidence
1748,182-ARR,182-ARR_v2_45@2,182-ARR_v1_48@2,"For the original FastSpeech, target phone durations derived from the attention weights of a pre-trained Tacotron2 system were used to provide phone durations (Ren et al., 2019).","In the predecessor 'FastSpeech', attention weights from a Tacotron2 system were used to provide phone durations (Ren et al., 2019).","Modify,Clarity",Clarity
1749,182-ARR,182-ARR_v2_46@4,182-ARR_v1_49@4,"For example, Perez-Gonzalez-de-Martos et al. ( 2021) submitted a non-attentive model trained from forced alignments to the Blizzard Challenge 2021, where their system was found to be among the most natural and intelligible in subjective listening tests despite only using 5 hours of speech; all other submitted systems included often significant amounts of additional training data (up to 100 hours total).","For example, Perez-Gonzalez-de-Martos et al. ( 2021) submitted a non-autoregressive model trained from forced alignments to the Blizzard Challenge 2021, where their system was found to be among the most natural and intelligible in subjective listening tests despite only using 5 hours of speech; all other submitted systems included often significant amounts of additional training data (up to 100 hours total).","Modify,Fact/Evidence",Fact/Evidence
1750,182-ARR,182-ARR_v2_47@0,182-ARR_v1_50@0,Experimental Comparison of Data Requirements for Neural TTS,Experimental comparison of data requirements for neural TTS,"Modify,Grammar",Grammar
1751,182-ARR,182-ARR_v2_6@1,182-ARR_v1_6@1,Most notable is the usual assumption that neural speech synthesis models require at least tens of hours of audio recordings with corresponding text transcripts to be trained adequately.,Most notable is the usual assumption that neural speech synthesis models require tens of hours of audio recordings with corresponding text transcripts to be trained adequately.,"Modify,Clarity",Clarity
1752,182-ARR,182-ARR_v2_0@0,182-ARR_v1_0@0,Requirements and Motivations of Low-Resource Speech Synthesis for Language Revitalization,Requirements and motivations of low-resource speech synthesis for language revitalization,"Modify,Grammar",Grammar
1753,182-ARR,182-ARR_v2_50@0,182-ARR_v1_51@4,"For comparison, we trained seven FastSpeech2 models with batch size 16 for 200k steps on 15 and 30 minute, 1, 3, 5, 10 and 24 hour incremental partitions of LJ Speech.","For comparison, we trained seven FastSpeech2 models on 15 and 30 minute, 1, 3, 5, 10 and 24 hour incremental partitions of LJ Speech.","Modify,Fact/Evidence",Fact/Evidence
1754,182-ARR,182-ARR_v2_50@3,182-ARR_v1_51@6,"Motivated by concerns of efficiency in model training and inference, and the possibility of overfitting a large model to limited amounts of data, we further modified the base architecture to match the Light-Speech model presented in Luo et al. (2021).","We further modified the base architecture to match the LightSpeech model presented in Luo et al. (2021), removing the energy adaptor and substituting depthwise separable convolutions throughout the model.","Split+Modify,Fact/Evidence",Fact/Evidence
1755,182-ARR,182-ARR_v2_50@4,182-ARR_v1_51@6,"We removed the energy adaptor, replaced the convolutional layers in the encoder, decoder and remaining variance predictors with depthwise separable convolutions (Kaiser et al., 2018) and matched encoder and decoder convolutional kernel sizes with Luo et al. (2021).","We further modified the base architecture to match the LightSpeech model presented in Luo et al. (2021), removing the energy adaptor and substituting depthwise separable convolutions throughout the model.","Split+Modify,Fact/Evidence",Fact/Evidence
1756,182-ARR,182-ARR_v2_52@5,182-ARR_v1_54@2,"Even still, there was a lot of variation in responses from the remaining participants, as seen in Figure 3.","Even still, there was a lot of variation in responses from the remaining participants (Figure 2).","Modify,Clarity",Clarity
1757,182-ARR,182-ARR_v2_53@5,182-ARR_v1_54@10,"Additionally, while all the FastSpeech2 voices were intelligible, all Tacotron2 models trained with less than 10 hours of data produced unintelligible speech.","Additionally, while all the FastSpeech2 voices were intelligible, all Tacotron2 models trained with 5 hours or less data produced unintelligible speech.","Modify,Fact/Evidence",Fact/Evidence
1758,182-ARR,182-ARR_v2_55@0,182-ARR_v1_55@0,Indigenous Language Experiments,Indigenous language experiments,"Modify,Grammar",Grammar
1759,182-ARR,182-ARR_v2_56@2,182-ARR_v1_56@2,"Additionally, we trained cold-start FastSpeech2 models for each language, as well as models fine-tuned for 25k steps from a multilin-gual, multispeaker FastSpeech2 model pre-trained on a combination of VCTK (Yamagishi et al., 2019), Kanien'kéha and Gitksan recordings.","Additionally, we trained cold-start Fast-Speech2 models for each language, as well as models trained in a pre-training, fine-tuning pipeline where the multilingual, multispeaker FastSpeech2 donor model was trained on a combination of VCTK (Yamagishi et al., 2019), Kanien'kéha and Gitksan recordings.","Modify,Fact/Evidence",Fact/Evidence
1760,182-ARR,182-ARR_v2_59@0,182-ARR_v1_59@0,"For the Kanien'kéha listening test, 6 participants were asked to answer 20 A/B questions comparing synthesized utterances from the various models.","For the Kanien'kéha listening test, 6 participants were asked to answer 20 A/B questions comparing different synthesized utterances.","Modify,Clarity",Clarity
1761,182-ARR,182-ARR_v2_59@2,182-ARR_v1_59@1,Results showed that 72.2% of A/B responses from participants preferred our FastSpeech2 model over our baseline concatenative model.,Results showed that 72.22% of A/B responses from participants preferred our FastSpeech2 model over our baseline concatenative model.,"Modify,Fact/Evidence",Fact/Evidence
1762,182-ARR,182-ARR_v2_59@3,182-ARR_v1_59@2,"In addition, 81.7% of A/B responses from participants preferred the cold-start to the model fine-tuned on the multispeaker, multi-lingual model, suggesting that the transfer learning approach discussed in §2.3 might not be necessary for models with explicit durations such as FastSpeech2 since they are relieved of the burden to learn an implicit model of duration through attention from limited data.","In addition, 81.67% of A/B responses from participants preferred the cold-start to the model fine-tuned on the multi-speaker, multilingual model, suggesting that the transfer learning approach discussed in §2.3 might not be necessary for models with explicit durations such as FastSpeech2.","Modify,Fact/Evidence",Fact/Evidence
1763,182-ARR,182-ARR_v2_60@0,182-ARR_v1_60@0,"For the Gitksan listening test, we did not build a concatenative model as with Kanien'kéha and so we were not comparing different models, but rather just gathering opinions on the quality of the cold-start FastSpeech2 model.","For the Gitksan listening test, 10 MOS-style questions were presented to 12 participants for both natural utterances and samples from our Fast-Speech2 model.","Split+Modify,Fact/Evidence",Fact/Evidence
1764,182-ARR,182-ARR_v2_60@1,182-ARR_v1_60@0,"Accordingly, 10 MOS-style questions were presented to 12 participants for both natural utterances and samples from our FastSpeech2 model.","For the Gitksan listening test, 10 MOS-style questions were presented to 12 participants for both natural utterances and samples from our Fast-Speech2 model.","Split+Modify,Clarity",Clarity
1765,182-ARR,182-ARR_v2_63@0,182-ARR_v1_62@0,Satisfying the goal of adding supplementary audio to a reference tool like Kawennón:nis can be straightforwardly implemented by linking entries in the verb conjugator to pre-generated audio for the domain from a static server.,"Satisfying the goal of adding supplementary audio to a reference tool like Kawennón:nis, can be straightforwardly implemented by linking entries in the verb conjugator to pre-generated audio for the domain from a static server.","Modify,Grammar",Grammar
1766,182-ARR,182-ARR_v2_70@9,182-ARR_v1_67@4,"These changes reduced the size of the model from Chien (2021) from 35M to 11.6M parameters, reduced the size of the stored model from 417 MB to 135 MB and significantly improved inference and train times as summarized in Table 1.","These changes reduced the number of parameters in the model from 35,076,161 to 11,591,233 without noticeable change in voice quality, in addition to reducing the size of the stored model from 417.06MB to 135.24MB and significantly improving inference and train times as summarized in Table 1.","Modify,Fact/Evidence",Fact/Evidence
1767,182-ARR,182-ARR_v2_70@6,182-ARR_v1_68@0,"Strubell et al. (2019) present an argument for equitable access to computational resources for NLP research; put another way, we might say that systems which require less compute are more accessible.","In addition to describing the environmental cost of popular NLP models, Strubell et al. (2019) also make a compelling argument for equitable access to compute.","Merge+Modify,Clarity",Clarity
1768,182-ARR,182-ARR_v2_70@6,182-ARR_v1_68@1,"Strubell et al. (2019) present an argument for equitable access to computational resources for NLP research; put another way, we might say that systems which require less compute are more accessible.","Put another way, systems which require less compute, are more accessible.","Modify,Clarity",Clarity
1769,182-ARR,182-ARR_v2_70@1,182-ARR_v1_69@0,"Beyond assessing the benefits and risks of introducing a new technology into language revitalization efforts, communities are concerned with the way the technology is researched and developed, as this process has the ability to empower or disempower language communities in equal measure (Alia, 2009; Brinklow et al., 2019.","Beyond assessing the benefits and risks of introducing a new technology into language revitalization efforts, communities are concerned with the way the technology is researched and devel-oped; as this process has the ability to empower or disempower language communities in equal measure (Alia, 2009; Brinklow et al., 2019.","Modify,Grammar",Grammar
1770,182-ARR,182-ARR_v2_70@3,182-ARR_v1_69@2,"For Indigenous communities to create speech synthesis tools for their languages, they should not be required to hand over their language data to a large government or corporate organization.","For Indigenous communities to create speech synthesis tools for their languages, they should not need be required to hand over their language data to a large government or corporate organization.","Modify,Grammar",Grammar
1771,182-ARR,182-ARR_v2_70@4,182-ARR_v1_69@3,"A pre-training, fine-tuning pipeline could be attractive for this reason; communities could fine-tune their own models on a laptop if a multilingual/multi-speaker model were pre-trained on GPUs at a larger institution.","A pre-training, fine-tuning pipeline is attractive for this reason; communities could fine tune their own models on a laptop if a multilingual/multi-speaker model were pre-trained on GPUs at a larger institution.","Modify,Clarity",Clarity
1772,182-ARR,182-ARR_v2_78@2,182-ARR_v1_74@5,"This is a comparatively low CO2 consumption for over 1500 GPU hours, largely due to the low CO2/kWh output of Quebec electricity when compared with the 2019 USA average of 400g CO2eq/kWh (EPA, 2019).","This is a comparatively low C02 consumption for over 1500 GPU hours, largely due to the low CO2/kWh output of Quebec electricity when compared with the 2019 USA average of 400g CO2eq/kWh (EPA, 2019).","Modify,Grammar",Grammar
1773,182-ARR,182-ARR_v2_78@5,182-ARR_v1_74@8,"Innu Nation Grand Chief Mary Ann Nui spoke to this when she commented that ""over the past 50 years, vast areas of our ancestral lands were destroyed by the Churchill Falls hydroelectric project, people lost their land, their livelihoods, their travel routes, and their personal belongings when the area where the project is located was flooded. Our ancestral burial sites are under water, our way of life was disrupted forever. Innu of Labrador weren't informed or consulted about that project"" (Innu-Atikamekw-Anishnabeg Coalition, 2020).","Innu Nation Grand Chief Mary Ann Nui spoke to this when she commented that ""over the past 50 years, vast areas of our ancestral lands were destroyed by the Churchill Falls hydroelectric project, people lost their land, their livelihoods, their travel routes, and their personal belongings when the area where the project is located was flooded. Our ancestral burial sites are under water, our way of life was disrupted forever. Innu of Labrador weren't informed or consulted about that projec"" (Innu-Atikamekw-Anishnabeg Coalition, 2020).","Modify,Grammar",Grammar
1774,182-ARR,182-ARR_v2_14@0,182-ARR_v1_14@0,"The pronominal system is largely responsible for much of this productivity, since in transitive paradigms, agent/patient pairs are fused, as illustrated in Figure 1.","The pronominal system is largely responsible for much of this productivity, since in transitive paradigms, agent/patient pairs are fused:","Modify,Clarity",Clarity
1775,182-ARR,182-ARR_v2_18@1,182-ARR_v1_20@1,One of the problems with this approach is that the input space often differs between languages.,One of the problems with this approach is that the input space differs between languages.,"Modify,Claim",Claim
1776,183-ARR,,183-ARR_v1_50@0,,"Here, σ(.) is the component-wise logistic function.","Delete,Fact/Evidence",Fact/Evidence
1777,183-ARR,,183-ARR_v1_50@1,,Model is fit using one-vs-all binarization of the classification task.,"Delete,Fact/Evidence",Fact/Evidence
1778,183-ARR,,183-ARR_v1_58@0,,"Similarly, in-training methods like PosCal tend to achieve higher accuracy but fail to be consistent in reducing calibration error.","Delete,Claim",Claim
1779,183-ARR,,183-ARR_v1_58@1,,Our proposed method (PB or PBtop) hits the sweet-spot between the two extremes and is shown to achieve better results than baselines: highest accuracy except for 1).,"Delete,Fact/Evidence",Fact/Evidence
1780,183-ARR,183-ARR_v2_16@1,,We are considering the first class of problems and leave the structured calibration to future work.,,"Add,Fact/Evidence",Fact/Evidence
1781,183-ARR,183-ARR_v2_25@2,,This refers to CalEmpProb() function in algorithm 1.,,"Add,Fact/Evidence",Fact/Evidence
1782,183-ARR,183-ARR_v2_29@4,,We use the notation σ to denote the softmax function.,,"Add,Fact/Evidence",Fact/Evidence
1783,183-ARR,183-ARR_v2_36@2,,"Contrary to equal-width binning, uniform-mass binning is a well-balanced binning scheme with guarantees on error bounds of estimated Expected Calibration Error, ECE .",,"Add,Claim",Claim
1784,183-ARR,183-ARR_v2_39@0,,Experiments,,"Add,Other",Other
1785,183-ARR,183-ARR_v2_43@0,,Select g using equation 2.,,"Add,Fact/Evidence",Fact/Evidence
1786,183-ARR,183-ARR_v2_44@0,,Uniform-mass binning over g(p i ).,,"Add,Fact/Evidence",Fact/Evidence
1787,183-ARR,183-ARR_v2_29@2,183-ARR_v1_33@2,"Histogram binning calibrator, on the other hand, constructs a set of bins that partitions [0, 1] via a binning scheme.","On the other hand, Histogram binning constructs a set of bins that partitions [0, 1] via a binning scheme.","Modify,Clarity",Clarity
1788,183-ARR,183-ARR_v2_38@5,183-ARR_v1_43@5,"In the following section we prove the efficacy of our method by carrying out extensive evaluation of the performance of pretrained transformer models such as BERT (Devlin et al., 2019) on simple multi-class text classification tasks.","In the following section we prove the efficacy of our method by carrying out extensive evaluation of the performance of pretrained transformer models such as BERT (Devlin et al., 2018) on simple multi-class text classification tasks.","Modify,Fact/Evidence",Fact/Evidence
1789,183-ARR,183-ARR_v2_40@0,183-ARR_v1_47@0,In the experiments we fine-tune the parameters on pre-trained BERT classifier using the regularized loss in equation (1).,In the experiments we finetune the parameters on pre-trained BERT classifier using the regularized loss in equation ( 1).,"Modify,Grammar",Grammar
1790,183-ARR,183-ARR_v2_50@1,183-ARR_v1_53@1,"In the experiments we used λ = 1.0, 10 bin for discretisation of q and we update Q after every training epoch.","In the experiments we used λ = 1.0, 10 bin for descretization of q and we update Q after every training epoch.","Modify,Grammar",Grammar
1791,183-ARR,183-ARR_v2_54@1,183-ARR_v1_57@1,Note that this reduction has not compromised the model performance.,Note that this reduction has not compromised with the model performance.,"Modify,Grammar",Grammar
1792,183-ARR,183-ARR_v2_11@2,183-ARR_v1_11@2,One common way to calibrate multi-class posteriors after training the classifier f : X → R is to treat the problem as K one-vs-all binary problems.,One common way to calibrate multiclass posteriors after training the classifier f : X → R is to treat the problem as K one-vsall binary problems.,"Modify,Grammar",Grammar
1793,183-ARR,183-ARR_v2_13@2,183-ARR_v1_13@2,"However, the marginalization of the weights in BNN is intractable in general.","However, the marginalization of the weights in BNN is intractable.","Modify,Clarity",Clarity
1794,183-ARR,183-ARR_v2_14@2,183-ARR_v1_13@5,"For instance, in (Joo et al., 2020) the authors model the distribution on posterior probability using a Dirichlet prior distribution and variational inference.","In (Joo et al., 2020) the authors model the distribution on posterior probability using a Dirichlet prior distribution and variational inference.","Modify,Clarity",Clarity
1795,184-ARR,,184-ARR_v1_26@0,,Methods,"Delete,Other",Other
1796,184-ARR,,184-ARR_v1_37@7,,The outer loop iterates over the multiparallel sentences in the training set.,"Delete,Fact/Evidence",Fact/Evidence
1797,184-ARR,,184-ARR_v1_75@0,,Table 4 presents accuracies for POS tagging in Yoruba.,"Delete,Fact/Evidence",Fact/Evidence
1798,184-ARR,,184-ARR_v1_75@1,,Unsupervised baseline performance is 50.86%.,"Delete,Fact/Evidence",Fact/Evidence
1799,184-ARR,,184-ARR_v1_75@2,,Supervised training using pseudo-labels mostly outperforms the unsupervised baseline.,"Delete,Claim",Claim
1800,184-ARR,,184-ARR_v1_75@3,,Projecting the majority POS labels to Yoruba improves over projecting English labels.,"Delete,Claim",Claim
1801,184-ARR,,184-ARR_v1_6@3,,"Recent work (Bird, 2020) suggests a number of approaches to develop technologies for indigenous languages.","Delete,Fact/Evidence",Fact/Evidence
1802,184-ARR,,184-ARR_v1_6@4,,Multiparallel corpora are a valuable (and arguably complementary) resource for this aim.,"Delete,Claim",Claim
1803,184-ARR,,184-ARR_v1_6@5,,We use the PBC corpus since it covers more than 1300 languages.,"Delete,Fact/Evidence",Fact/Evidence
1804,184-ARR,184-ARR_v2_8@0,,We consider the task of word alignment for multiparallel sentences.,,"Add,Fact/Evidence",Fact/Evidence
1805,184-ARR,184-ARR_v2_8@1,,The basic motivation is that the alignment between words in languages U and V can benefit from word-level alignments of U and V with a translation in a third language W .,,"Add,Fact/Evidence",Fact/Evidence
1806,184-ARR,184-ARR_v2_8@2,,"Following up on the work of Imani Googhari et al. (2021), we model multilingual word alignments with tools borrowed from graph theory (community detection algorithms) combined with neural network based models, specifically, the graph neural network (GNN) model of Scarselli et al. (2009).",,"Add,Fact/Evidence",Fact/Evidence
1807,184-ARR,184-ARR_v2_9@2,,"We use this property to take into account properties of the whole alignment graph, notably its tendency to cluster into communities, see Figure 1.",,"Add,Fact/Evidence",Fact/Evidence
1808,184-ARR,184-ARR_v2_12@0,,MultiParallel Word Alignment Graphs,,"Add,Other",Other
1809,184-ARR,184-ARR_v2_13@0,,Building MultiParallel Word Alignment Graphs,,"Add,Other",Other
1810,184-ARR,184-ARR_v2_14@2,,An MPWA graph is constructed using the following two steps:,,"Add,Fact/Evidence",Fact/Evidence
1811,184-ARR,184-ARR_v2_20@0,,One important advantage of GNNs over traditional graph algorithms is that they can directly incorporate signals from different sources in the form of node and edge features.,,"Add,Claim",Claim
1812,184-ARR,,184-ARR_v1_11@0,,"Since the nodes in the graph are words that are translations of each other, we expect them to create densely connected regions or communities.","Delete,Fact/Evidence",Fact/Evidence
1813,184-ARR,184-ARR_v2_28@0,,Predicting and using MultiParallel,,"Add,Other",Other
1814,184-ARR,184-ARR_v2_29@0,,Word Alignments (MPWAs),,"Add,Other",Other
1815,184-ARR,,184-ARR_v1_11@1,,Our analysis of the structure of the multiparallel alignment graph confirms this intuition; see Figure 1.,"Delete,Fact/Evidence",Fact/Evidence
1816,184-ARR,184-ARR_v2_32@0,,Below is the step-by-step overview of our GNNbased approach for an MPWA graph:,,"Add,Fact/Evidence",Fact/Evidence
1817,184-ARR,184-ARR_v2_33@0,,1. run community detection algorithms on the initial graph ( §2.2);,,"Add,Fact/Evidence",Fact/Evidence
1818,184-ARR,184-ARR_v2_34@0,,2. obtain features for the nodes of the graph ( §3.1.3);,,"Add,Fact/Evidence",Fact/Evidence
1819,184-ARR,184-ARR_v2_35@0,,3. compute node embeddings from node features and initial alignment links in the GNN encoding step ( §3.1.2);,,"Add,Fact/Evidence",Fact/Evidence
1820,184-ARR,184-ARR_v2_36@0,,4. learn to distinguish between nodes that are aligned together and that are not aligned together in the GNN decoding step ( §3.1.2);,,"Add,Fact/Evidence",Fact/Evidence
1821,184-ARR,184-ARR_v2_37@0,,"After the GNN model is trained on multiple MPWA graphs, it is used to infer an alignment probability matrix between tokens in a source language and tokens in a target language for a multiparallel sentence, see §3.1.4.",,"Add,Fact/Evidence",Fact/Evidence
1822,184-ARR,,184-ARR_v1_11@2,,We use community detection algorithms to find communities.,"Delete,Fact/Evidence",Fact/Evidence
1823,184-ARR,184-ARR_v2_39@2,,The encoder creates a hidden representation for each node of the graph and the decoder predicts the links of the graph given the nodes' representations.,,"Add,Fact/Evidence",Fact/Evidence
1824,184-ARR,184-ARR_v2_39@3,,"Using the graph of word alignments, the model will learn the word alignment task.",,"Add,Fact/Evidence",Fact/Evidence
1825,184-ARR,,184-ARR_v1_11@3,,We show that pruning inter-community edges and adding intracommunity edges is helpful.,"Delete,Fact/Evidence",Fact/Evidence
1826,184-ARR,184-ARR_v2_39@4,,Therefore it will be able to predict word alignments that are missed by the original bilingual word aligner and also detect incorrect alignment edges.,,"Add,Fact/Evidence",Fact/Evidence
1827,184-ARR,,184-ARR_v1_11@4,,We use community information as node features for our GNN.,"Delete,Fact/Evidence",Fact/Evidence
1828,184-ARR,,184-ARR_v1_12@0,,We enable the removal of alignment edges from initial alignments by inferring alignments from the alignment probability matrix.,"Delete,Fact/Evidence",Fact/Evidence
1829,184-ARR,,184-ARR_v1_13@0,,"For our experiments, we follow the setup of Imani et al. (2021).","Delete,Fact/Evidence",Fact/Evidence
1830,184-ARR,,184-ARR_v1_13@1,,We train a GNN model with a link prediction objective.,"Delete,Fact/Evidence",Fact/Evidence
1831,184-ARR,,184-ARR_v1_13@2,,"We show improved results for three language pairs on word alignment (English-French, Finnish-Hebrew and Finnish-Greek).","Delete,Fact/Evidence",Fact/Evidence
1832,184-ARR,,184-ARR_v1_13@5,,We show that our model is especially helpful for distant languages.,"Delete,Fact/Evidence",Fact/Evidence
1833,184-ARR,184-ARR_v2_76@5,,Using the verses from HELFI train split as our training set is for convenience.,,"Add,Fact/Evidence",Fact/Evidence
1834,184-ARR,184-ARR_v2_85@10,,"ImaniGooghari et al. (2021) provide a tool to browse a word-aligned multiparallel corpus, which can be used for the comparative study of languages and for error analysis in machine translation.",,"Add,Fact/Evidence",Fact/Evidence
1835,184-ARR,184-ARR_v2_24@1,184-ARR_v1_21@1,"As exact modularity maximization is intractable, we experiment with two CD algorithms implementing different heuristic approaches:",We experiment with two CD algorithms:,"Modify,Fact/Evidence",Fact/Evidence
1836,184-ARR,184-ARR_v2_26@2,184-ARR_v1_23@2,"Table 1 reports the average number of graph components per sentence before and after running GMC and LPC, as well as the corresponding F 1 for word alignment (see §4.1 for details on the evaluation datasets).","Table 1 reports the average number of graph components per sentence before and after runing GMC and LPC, as well as the corresponding F 1 for word alignment.","Modify,Fact/Evidence",Fact/Evidence
1837,184-ARR,184-ARR_v2_27@0,184-ARR_v1_25@0,This analysis shows that CD algorithms compute valuable information for word alignments.,These results indicate that CD algorithms can provide valuable information.,"Modify,Fact/Evidence",Fact/Evidence
1838,184-ARR,184-ARR_v2_27@1,184-ARR_v1_25@1,"To exploit this in our GNN model, we add node community information as a node feature; see §3.1.3.","To exploit this in our GNN model, we add a node's community information as a GNN node feature; see §3.1.2.","Modify,Clarity",Clarity
1839,184-ARR,184-ARR_v2_30@0,184-ARR_v1_27@0,GNNs for MPWA,GNN in MPWA,"Modify,Grammar",Grammar
1840,184-ARR,184-ARR_v2_39@0,184-ARR_v1_30@0,Our model is inspired by the Graph Auto Encoder (GAE) model of Kipf and Welling (2016) for link prediction.,Our model is inspired by the Graph Auto Encoder (GAE) model of Kipf and Welling (2016b) for link prediction.,"Modify,Fact/Evidence",Fact/Evidence
1841,184-ARR,184-ARR_v2_39@1,184-ARR_v1_30@1,A GAE model consists of an encoder and a decoder.,The architecture consists of an encoder and a decoder.,"Modify,Fact/Evidence",Fact/Evidence
1842,184-ARR,184-ARR_v2_40@0,184-ARR_v1_30@2,We make changes to this model to improve the model's quality and reduce its computational cost.,We make changes to this model to improve the model's quality and reduce its computation cost.,"Modify,Grammar",Grammar
1843,184-ARR,184-ARR_v2_40@1,184-ARR_v1_30@3,"We use GATConv layers (Veličković et al., 2018) for the encoder instead of GCNConv (Kipf and Welling, 2017) and a more sophisticated decoder instead of simple dot product for a stronger model.","We use GATConv layers (Veličković et al., 2018) for encoder instead of GCNConv (Kipf and Welling, 2016a)and a more sophisticated decoder instead of simple dot product for a stronger model.","Modify,Fact/Evidence",Fact/Evidence
1844,184-ARR,184-ARR_v2_45@0,184-ARR_v1_35@0,"(3) where is concatenation, g is LeakyReLU, and a is a weight vector.","(3) where is concatanation, g is LeakyReLU, and a is a weight vector.","Modify,Grammar",Grammar
1845,184-ARR,184-ARR_v2_47@0,184-ARR_v1_37@0,Training,Training.,"Modify,Grammar",Grammar
1846,184-ARR,184-ARR_v2_48@1,184-ARR_v1_37@2,This approach requires at least tens of epochs over the training dataset to converge and a lot of GPU memory for graphs as large as ours.,This approach requires at least tens of epochs over training dataset to converge and a lot of GPU memory for graphs as big as ours.,"Modify,Grammar",Grammar
1847,184-ARR,184-ARR_v2_48@2,184-ARR_v1_37@3,We train our model using mini-batches to decrease memory requirements and improve the performance.,We train our model using mini-batches and an adversarial loss to decrease memory requirements and improve the performance.,"Modify,Fact/Evidence",Fact/Evidence
1848,184-ARR,184-ARR_v2_48@4,184-ARR_v1_37@5,We take care to select informative negative samples (as opposed to random selection) as described below.,"The negative samples are selected more elegantly, as described below.","Modify,Clarity",Clarity
1849,184-ARR,184-ARR_v2_4@0,184-ARR_v1_4@0,"Word alignments are crucial for statistical machine translation (Koehn et al., 2003) and useful for many other multilingual tasks such as neural machine translation (Alkhouli and Ney, 2017;Alkhouli et al., 2016), typological analysis (Lewis and Xia, 2008;Östling, 2015;Asgari and Schütze, 2017) and annotation projection (Yarowsky and Ngai, 2001;Fossum and Abney, 2005;Wisniewski et al., 2014;Huck et al., 2019).","Word alignments are crucial for statistical machine translation (Koehn et al., 2003) and useful for many other multilingual tasks such as neural machine translation (Alkhouli and Ney, 2017;Alkhouli et al., 2016), typological analysis (Lewis and Xia, 2008;Östling, 2015;Asgari and Schütze, 2017), annotation projection (Yarowsky and Ngai, 2001;Fossum and Abney, 2005;Wisniewski et al., 2014;Huck et al., 2019).","Modify,Grammar",Grammar
1850,184-ARR,184-ARR_v2_49@1,184-ARR_v1_37@8,The training set contains one graph for each sentence.,The training set contains one graph for each sentence; the graph is constructed using the bilingual alignment edges between all language pairs.,"Modify,Fact/Evidence",Fact/Evidence
1851,184-ARR,184-ARR_v2_50@1,184-ARR_v1_38@1,"On the decoder side, for each link between two nodes in the batch, the hidden representations of the two nodes are concatenated to create the decoder's input.","On the decoder side, for each link of the batch, the hidden representations of the attached nodes are concatenated to create the decoder's input.","Modify,Clarity",Clarity
1852,184-ARR,184-ARR_v2_56@5,184-ARR_v1_43@10,Then we represent the community membership information of the nodes as one-hot vectors and learn an embedding of size 32 for each of the two algorithms.,Then we take the community membership information of the nodes as one-hot vectors and learn an embedding of size 32 for each of the two algorithms.,"Modify,Clarity",Clarity
1853,184-ARR,184-ARR_v2_57@2,184-ARR_v1_44@2,We learn 100-dimensional multilingual word embeddings using Levy et al. (2017)'s sentence-ID method on the 84 PBC languages selected by Imani Googhari et al. (2021).,We learn 100-dimensional multilingual word embeddings using Levy et al. (2017)'s sentence-ID method on the 84 PBC languages selected by Imani et al. (2021).,"Modify,Fact/Evidence",Fact/Evidence
1854,184-ARR,184-ARR_v2_59@0,184-ARR_v1_46@0,Inducing Bilingual Alignment Edges,Inducing Alignment Edges,"Modify,Other",Other
1855,184-ARR,184-ARR_v2_60@0,184-ARR_v1_47@0,"Given a source sentence x = x 1 , x 2 , . . . , x m in language X and a target sentence ŷ = y 1 , y 2 , . . . , y l in language Y , we feed all possible alignment links between source and target to the decoder.","When our trained GNN model is used to predict alignment edges between a source sentence x = x 1 , x 2 , . . . , x m in language X and a target sentence ŷ = y 1 , y 2 , . . . , y l in language Y , it produces a symmetric alignment probability matrix S 4 of size m × l where S ij is the predicted alignment probability between words x i and y j .","Split+Modify,Fact/Evidence",Fact/Evidence
1856,184-ARR,184-ARR_v2_60@1,184-ARR_v1_47@0,This produces a symmetric alignment probability matrix S of size m × l where S ij is the predicted alignment probability between words x i and y j .,"When our trained GNN model is used to predict alignment edges between a source sentence x = x 1 , x 2 , . . . , x m in language X and a target sentence ŷ = y 1 , y 2 , . . . , y l in language Y , it produces a symmetric alignment probability matrix S 4 of size m × l where S ij is the predicted alignment probability between words x i and y j .","Split+Modify,Fact/Evidence",Fact/Evidence
1857,184-ARR,184-ARR_v2_68@0,184-ARR_v1_54@0,"We evaluate the resulting alignments using F 1 score and alignment error rate (AER), the standard metrics in the word alignment literature.","We evaluate the resulting alignments using F 1 score and alignment error rate (AER), the standard evaluation measures in the word alignment literature.","Modify,Clarity",Clarity
1858,184-ARR,184-ARR_v2_70@1,184-ARR_v1_56@1,"A model trained on data with ""annotationprojected"" labels can perform better than a completely unsupervised method.","A model trained on data with ""annotationprojected"" labels can perform better than full unsupervision.","Modify,Clarity",Clarity
1859,184-ARR,184-ARR_v2_6@2,184-ARR_v1_5@2,Red dashed lines cut links that incorrectly connect distinct concepts.,Red dashed lines sever links that incorrectly connect distinct concepts.,"Modify,Clarity",Clarity
1860,184-ARR,184-ARR_v2_72@4,184-ARR_v1_59@1,The graph algorithms used by Imani Googhari et al. ( 2021) operate on each multiparallel sentence separately.,The graph algorithms used by Imani et al. (2021) operate on each multiparallel sentence separately.,"Modify,Fact/Evidence",Fact/Evidence
1861,184-ARR,184-ARR_v2_72@5,184-ARR_v1_59@2,"In contrast, our approach allows for an inductive setting where a model is trained on a training set, accumulating knowledge from multiple multiparallel sentences.","In contrast, our approach allows for an inductive setting where a model is trained on a training set and then evaluated on a separate test set.","Modify,Fact/Evidence",Fact/Evidence
1862,184-ARR,184-ARR_v2_72@6,184-ARR_v1_59@3,"We combine the verses in the training sets of Finnish-Hebrew and Finnish-Greek for a combined training set size of 24,159.","We combine the verses in the training sets of Finnish-Hebrew and Finnish-Greek for a combined train set size of 24,159.","Modify,Grammar",Grammar
1863,184-ARR,184-ARR_v2_74@4,184-ARR_v1_61@4,We use the same subset of 84 languages as Imani Googhari et al. (2021).,We use the same subset of 84 languages as Imani et al. (2021).,"Modify,Fact/Evidence",Fact/Evidence
1864,184-ARR,184-ARR_v2_7@1,184-ARR_v1_6@0,"Examples of multiparallel corpora are JW300 (Agić and Vulić, 2019), PBC (Mayer and Cysouw, 2014) which covers the highest number of languages (1334), and Tatoeba.","Multiparallel corpora contain sentence level parallel text in more than two languages, e.g., JW300 (Agić and Vulić, 2019), PBC (Mayer and Cysouw, 2014) and Tatoeba.","Modify,Fact/Evidence",Fact/Evidence
1865,184-ARR,184-ARR_v2_76@2,184-ARR_v1_63@2,We train for one epoch on the training set -a small portion of the training set is enough to learn good embeddings (see §5.1.1).,We train for one epoch on the train set -a small portion of the train set is enough to learn good embeddings (see §5.1.1).,"Modify,Grammar",Grammar
1866,184-ARR,184-ARR_v2_79@1,184-ARR_v1_66@1,"Our GNNs yield a better trade-off between precision and recall, most likely thanks to their ability to remove edges, and achieve the best F 1 and AER on all three datasets, outperforming WAdAd and NMF.","Our GNNs provide a better trade-off between precision and recall, most likely thanks to their ability to remove edges, and achieve the best F 1 and AER on all three datasets, outperforming WAdAd and NMF.","Modify,Clarity",Clarity
1867,184-ARR,184-ARR_v2_79@3,184-ARR_v1_67@1,"As argued in Imani Googhari et al. (2021), this is mostly due to the different ways these two datasets were annotated.","As argued in Imani et al. (2021), this is mostly due to the different ways these two datasets were annotated.","Modify,Fact/Evidence",Fact/Evidence
1868,184-ARR,184-ARR_v2_79@5,184-ARR_v1_67@3,This suggests that one can choose between GNN (TGDFA) and GNN (TGDFA+orig) based on the desired characteristics of the alignment.,This suggests that one can choose between GNN (TGDFA) and GNN (TGDFA+orig) based on the characteristics of the desired alignments.,"Modify,Clarity",Clarity
1869,184-ARR,184-ARR_v2_7@2,184-ARR_v1_6@1,"1 While the perlanguage amount of data provided in such corpora is less than bilingual corpora, they support highly low-resource languages, many of which are not covered by existing language technologies (Joshi et al., 2020).","1 While the amount of data provided by multiparallel corpora is less than bilingual corpora, this type of corpus is essential to study very low-resource languages.","Link+Modify,Clarity",Clarity
1870,184-ARR,184-ARR_v2_7@3,184-ARR_v1_6@1,"Therefore, these corpora are essential for studying many of the world's low-resource languages.","1 While the amount of data provided by multiparallel corpora is less than bilingual corpora, this type of corpus is essential to study very low-resource languages.","Link+Modify,Clarity",Clarity
1871,184-ARR,184-ARR_v2_81@3,184-ARR_v1_69@3,"Using more than 6,400 samples does not change the performance at all.","Indeed, using more than 6,400 samples does not change the performance at all.","Modify,Other",Other
1872,184-ARR,184-ARR_v2_7@2,184-ARR_v1_6@2,"1 While the perlanguage amount of data provided in such corpora is less than bilingual corpora, they support highly low-resource languages, many of which are not covered by existing language technologies (Joshi et al., 2020).","There are thousands of languages in the world a very small portion of which is covered by language technologies (Joshi et al., 2020).","Link+Modify,Clarity",Clarity
1873,184-ARR,184-ARR_v2_85@5,184-ARR_v1_75@6,"Although neural models achieve superior performance compared to statistical aligners, they can only be used for fewer than two hundred high-resource languages that are supported by multilingual language models like BERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020).","Although neural models achieve superior performance compared to statistical aligners, they are only applicable for less than two hundred high-resource languages that are supported by multilingual language models like BERT (Devlin et al., 2019) and XLM-R (Conneau et al., 2020).","Modify,Clarity",Clarity
1874,184-ARR,184-ARR_v2_87@0,184-ARR_v1_76@0,To the best of our knowledge Lardilleux and Lepage (2008) and Östling (2014) 7 are the only word alignment methods designed for multiparallel corpora.,To the best of our knowledge Östling (2014) 7 is the only word alignment method designed for multiparallel corpora.,"Modify,Fact/Evidence",Fact/Evidence
1875,184-ARR,184-ARR_v2_87@1,184-ARR_v1_76@1,"However, the latter method is outperformed by Eflomal (Östling and Tiedemann, 2016), a bilingual method from the same author.","However, this method is outperformed by Eflomal (Östling and Tiedemann, 2016), a ""biparallel"" method from the same author.","Modify,Fact/Evidence",Fact/Evidence
1876,184-ARR,184-ARR_v2_87@2,184-ARR_v1_76@2,"Recently, Imani Googhari et al. (2021) proposed MPWA, which we use as our baseline.","Recently, Imani et al. (2021) proposed MPWA, which we use as our baseline.","Modify,Fact/Evidence",Fact/Evidence
1877,184-ARR,184-ARR_v2_88@1,184-ARR_v1_77@1,"GNNs achieve impressive performance in many domains, including social networks (Wu et al., 2020) and natural science (Sanchez-Gonzalez et al., 2018) as well as NLP tasks like sentence classification (Huang et al., 2020), question generation (Pan et al., 2020), summarization (Fernandes et al., 2019) and derivational morphology (Hofmann et al., 2020).","GNNs achieve impressive performance in many domains, including social networks (Wu et al., 2020) and natural science (Sanchez-Gonzalez et al., 2018) as well as NLP tasks like sentence classification (Huang et al., 2020), question generation (Pan et al., 2020), and summarization (Fernandes et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
1878,184-ARR,184-ARR_v2_14@0,184-ARR_v1_8@0,"Our starting point is the work of Imani Googhari et al. ( 2021), who introduce MPWA (MultiParallel Word Alignment), a framework that utilizes the synergy between multiple language pairs to improve bilingual word alignments for a target language pair.","They introduce MPWA (MultiParallel Word Alignment), a framework that utilizes the synergy between multiple language pairs to improve bilingual word alignments.","Modify,Fact/Evidence",Fact/Evidence
1879,184-ARR,184-ARR_v2_15@0,184-ARR_v1_9@0,1. create initial bilingual alignments for all language pairs in a multiparallel corpus using a bilingual word aligner;,The first step in MPWA is to create bilingual alignments for all language pairs in a multiparallel corpus using a bilingual word aligner.,"Modify,Clarity",Clarity
1880,184-ARR,184-ARR_v2_16@0,184-ARR_v1_9@1,2. represent the bilingual alignments for each multiparallel sentence in a graph containing one vertex for each token occurring in any language and one edge for each initial bilingual word alignment link.,Then the bilingual alignments for a multiparallel sentence are represented as a graph where words are nodes and initial word alignments are edges.,"Modify,Fact/Evidence",Fact/Evidence
1881,184-ARR,184-ARR_v2_17@0,184-ARR_v1_9@3,"Potentially missing alignment links are then added based on the graph structure in an inference step, casting the word alignment task as an edge prediction problem.","MPWA infers missing alignment links based on the graph structure in a postprocessing step, casting the word alignment task as an edge prediction problem.","Modify,Fact/Evidence",Fact/Evidence
1882,184-ARR,184-ARR_v2_17@2,184-ARR_v1_9@4,"Imani Googhari et al. ( 2021) use two traditional graph algorithms, Adamic-Adar and non-negative matrix factorization, for predicting new alignment edges from the MPWA graph.","They use two traditional graph algorithms, Adamic-Adar and non-negative matrix factorization, for edge prediction.","Modify,Fact/Evidence",Fact/Evidence
1883,184-ARR,184-ARR_v2_17@3,184-ARR_v1_9@5,"However, these graph algorithms are applied to individual multiparallel sentences independently and therefore cannot accumulate knowledge from multiple sentences.","However, these standard graph algorithms are applied to individual multiparallel sentences independently and therefore cannot accumulate knowledge from multiple sentences.","Modify,Clarity",Clarity
1884,184-ARR,184-ARR_v2_17@4,184-ARR_v1_9@6,"Moreover, their edge predictions are solely based on the structure of the graph and do not take advantage of other beneficial signals such as a word's language, relative position and meaning.","Moreover, their edge predictions are solely based on the structure of the graph and do not take advantage of other beneficial signals such as a word's language, relative position and word meaning.","Modify,Clarity",Clarity
1885,184-ARR,184-ARR_v2_17@5,184-ARR_v1_9@7,"Another limitation of this work is that it only adds links and does not remove any, which is important to improve precision.","Another limitation is that it only adds links and does not remove any, which is important to improve precision.","Modify,Clarity",Clarity
1886,184-ARR,184-ARR_v2_18@0,184-ARR_v1_10@0,This work addresses these shortcomings by using GNNs to predict alignment edges from MPWA graphs.,"In this paper, we propose to use graph neural networks (GNNs) to exploit the graph structure of multiparallel word alignments and address the limitations of prior work.","Modify,Fact/Evidence",Fact/Evidence
1887,184-ARR,184-ARR_v2_9@0,184-ARR_v1_10@1,"GNNs were proposed to extend the powerful current generation of neural network models to the processing of graph-structured data and they have gained increasing popularity in many domains (Wu et al., 2020;Sanchez-Gonzalez et al., 2018;He et al., 2020).","GNNs were proposed to extend the powerful current generation of neural network models to processing graph-structured data (Scarselli et al., 2009) and they have gained increasing popularity in many domains (Wu et al., 2020;Sanchez-Gonzalez et al., 2018;He et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1888,184-ARR,184-ARR_v2_9@1,184-ARR_v1_10@2,GNNs can incorporate heterogeneous sources of signal in the form of node and edge features.,"In contrast to other graph algorithms, GNNs can incorporate heterogeneous sources of signal in the form of node and edge features.","Modify,Clarity",Clarity
1889,184-ARR,184-ARR_v2_37@1,184-ARR_v1_12@1,"Our method predicts new alignment links from this matrix, independently of initial edges.",Our method predicts new alignment links independently of initial edges.,"Modify,Clarity",Clarity
1890,184-ARR,184-ARR_v2_37@2,184-ARR_v1_12@2,"Therefore, given an initial bilingual alignment, it is not limited to adding edges, but it can also remove them.","Therefore it is not limited to adding edges wrt initial bilingual alignments, it can also remove them.","Modify,Clarity",Clarity
1891,184-ARR,184-ARR_v2_2@4,184-ARR_v1_2@4,"Next, we use graph neural networks (GNNs) to exploit the graph structure.","Next, we use graph neural networks (GNNs) and community detection algorithms to exploit the graph structure.","Modify,Fact/Evidence",Fact/Evidence
1892,184-ARR,184-ARR_v2_19@0,184-ARR_v1_15@0,Community Detection in Alignment Graphs,Graph Analysis with Community Detection (CD),"Modify,Other",Other
1893,184-ARR,184-ARR_v2_20@2,184-ARR_v1_16@1,"If the initial bilingual alignments are of good quality, we expect words that are mutual translations to form densely connected regions or communities; see Figure 1.","If the initial bilingual alignments are of good quality, we expect these translated words to form densely connected regions or communities; see Figure 1.","Modify,Clarity",Clarity
1894,184-ARR,184-ARR_v2_20@3,184-ARR_v1_16@2,"These communities should not be linked to each other, each corresponding to a distinct connected component.","We expect these communities to be genarally disconnected, each corresponding to a distinct connected component.","Modify,Clarity",Clarity
1895,184-ARR,184-ARR_v2_20@5,184-ARR_v1_17@1,"While, this intuition will not be true for all concepts between all possible language pairs, we nonetheless hypothesize that identifying distinct concepts in a multiparallel word alignment graph can provide useful information.","Clearly, this intuition will not be true for all concepts between all possible language pairs.","Merge+Modify,Clarity",Clarity
1896,184-ARR,184-ARR_v2_20@5,184-ARR_v1_17@2,"While, this intuition will not be true for all concepts between all possible language pairs, we nonetheless hypothesize that identifying distinct concepts in a multiparallel word alignment graph can provide useful information.","Nonetheless, we hypothesize that identifying distinct concepts in a multiparallel word alignment graph can provide useful information.","Merge+Modify,Clarity",Clarity
1897,184-ARR,184-ARR_v2_2@5,184-ARR_v1_2@5,"Our GNN approach (i) utilizes information about the meaning, position and language of the input words, (ii) incorporates information from multiple parallel sentences, (iii) adds and removes edges from the initial alignments, and (iv) yields a prediction model that can generalize beyond the training sentences.","Our GNN approach (i) utilizes information about the meaning, position and language of the input words, (ii) incorporates information from multiple parallel sentences, (iii) adds and removes edges from the initial alignments, and (iv) provides a prediction model that can generalize beyond the sentences it is trained on.","Modify,Clarity",Clarity
1898,184-ARR,184-ARR_v2_21@0,184-ARR_v1_18@0,"To examine to what extent these expectations are met, we count the components in the original Eflomal-generated (Östling and Tiedemann, 2016) graph (see §4.2 for details on the initial alignments).","To examine to what extent this expectation is met, we count the components in the original Eflomal-generated (Östling and Tiedemann, 2016) graph.","Modify,Fact/Evidence",Fact/Evidence
1899,184-ARR,184-ARR_v2_21@2,184-ARR_v1_18@2,"But intuitively, the number of components should roughly correspond to sentence length (or, more precisely, the number of content words).","But intuitively, the number of components should roughly correspond to sentence length (i.e., the number of content words).","Modify,Clarity",Clarity
1900,184-ARR,184-ARR_v2_22@1,184-ARR_v1_19@1,"One well-known approach to CD attempts to maximize the modularity measure (Newman and Girvan, 2004).","CD algorithms maximize the modularity measure (Newman and Girvan, 2004).","Modify,Fact/Evidence",Fact/Evidence
1901,184-ARR,184-ARR_v2_22@2,184-ARR_v1_19@2,"Modularity assesses how beneficial a division of a community into two communities is, in the sense that there are many links within communities and only a few between them.","Modularity measures how beneficial a division of a community into two communities is, in the sense that there are many links within communities and only a few between them.","Modify,Clarity",Clarity
1902,185-ARR,,185-ARR_v1_75@4,,Figure 4 shows the system performance positively correlates with the amount of training data available in the target domain.,"Delete,Fact/Evidence",Fact/Evidence
1903,185-ARR,,185-ARR_v1_75@5,,"To visualize how well DAML-ATM performs on the new unseen domain, we use t-SNE (Van der Maaten and Hinton, 2008) plots to analyze the degree of separation between the source domain sentences and the generated target domain sentences.","Delete,Fact/Evidence",Fact/Evidence
1904,185-ARR,,185-ARR_v1_75@6,,"Figure 5 shows that as the training epoch increases, the sentences generated by DAML-ATM in the target domain are completely separated from the source domain in the latent space.","Delete,Fact/Evidence",Fact/Evidence
1905,185-ARR,,185-ARR_v1_81@0,,"Our model is initialized from T5 and Bart Raffel et al., 2019).","Delete,Fact/Evidence",Fact/Evidence
1906,185-ARR,,185-ARR_v1_84@0,,"To demonstrate the robustness of our algorithm, we trained our algorithm on the Shakespeare dataset (Xu et al., 2012).","Delete,Fact/Evidence",Fact/Evidence
1907,185-ARR,,185-ARR_v1_84@1,,"We choose three of these plays, Hamlet, Macbeth, and Othello, as different domains.","Delete,Fact/Evidence",Fact/Evidence
1908,185-ARR,,185-ARR_v1_85@0,,The restaurant domain is used as the target domain and the other three domains as the source domain.,"Delete,Fact/Evidence",Fact/Evidence
1909,185-ARR,,185-ARR_v1_86@0,,"As shown in Table 8, our approach achieves good results on the more difficult Shakespearean style transfer, which indicates that our algorithm generalizes nicely to other complex style transfer tasks.","Delete,Fact/Evidence",Fact/Evidence
1910,185-ARR,,185-ARR_v1_87@1,,"We choose one as the target domain and the others as the source domain, every target domain uses 1% data for fine-tuning, and the base model is ATM.","Delete,Fact/Evidence",Fact/Evidence
1911,185-ARR,,185-ARR_v1_8@0,,"With the DAML strategy, we design a TST model for each domain.","Delete,Fact/Evidence",Fact/Evidence
1912,185-ARR,185-ARR_v2_31@3,,The structure of the model is shown in Figure 2.,,"Add,Fact/Evidence",Fact/Evidence
1913,185-ARR,185-ARR_v2_39@3,,Our model training involves a pre-training learning strategy and a domain adaptive meta-learning strategy.,,"Add,Fact/Evidence",Fact/Evidence
1914,185-ARR,185-ARR_v2_71@1,,"Then, the evaluation is conducted on the test set of a target domain using the direct domain shift strategy;",,"Add,Fact/Evidence",Fact/Evidence
1915,185-ARR,185-ARR_v2_66@1,185-ARR_v1_64@1,"(ii) Yelp restaurant review dataset (Li et al., 2018).",(ii) Yelp restaurant review dataset .,"Modify,Fact/Evidence",Fact/Evidence
1916,185-ARR,185-ARR_v2_66@2,185-ARR_v1_64@2,"(iii) Amazon product review dataset (Li et al., 2018).",(iii) Amazon product review dataset .,"Modify,Fact/Evidence",Fact/Evidence
1917,185-ARR,185-ARR_v2_5@2,185-ARR_v1_5@2,"The recent surge of deep generative methods (Hu et al., 2017a;Li et al., 2018) has spurred progress in text style transfer without parallel data.","The recent surge of deep generative methods (Hu et al., 2017a; has spurred progress in text style transfer without parallel data.","Modify,Fact/Evidence",Fact/Evidence
1918,185-ARR,185-ARR_v2_5@3,185-ARR_v1_5@3,"However, these methods typically require large amounts of non-parallel data and do not perform well in low-resource domain scenarios.","However, these methods typically require large amounts of nonparallel data and not perform well in low-resource domain scenarios.","Modify,Grammar",Grammar
1919,185-ARR,185-ARR_v2_6@0,185-ARR_v1_6@0,"One typical method is to resort to massive data from different domains, which has been studied as an effective solution to address the above data insufficiency issue (Glorot et al., 2011;Wang et al., 2017;Li et al., 2021b).","One typical method is to resort to massive data from different domains, which has been studied as an effective solution to address the above data insufficiency issue (Glorot et al., 2011;Wang et al., 2017).","Modify,Fact/Evidence",Fact/Evidence
1920,185-ARR,185-ARR_v2_8@0,185-ARR_v1_8@1,"To well preserve content and transfer style, one typical strategy of a TST model is to decouple style information from the semantics of a text, and it tends to produce content loss during style transfer (Hu et al., 2017b;Dai et al., 2019;Carlson et al., 2018).","Usually, if a TST model tries to decouple style information from the semantics of a text, it tends to produce content loss during style transfer (Hu et al., 2017b;Dai et al., 2019;Carlson et al., 2018).","Modify,Claim",Claim
1921,185-ARR,185-ARR_v2_8@1,185-ARR_v1_8@2,"Here, we do not try to decouple content and style, and propose a new Adversarial style Transfer model ATM, which is composed of a sequenceto-sequence pre-trained language model combined with adversarial style training for style transfer.","Thus, we propose a new style transfer model ATM, which is composed of a sequence-to-sequence pre-trained language model combined with adversarial style training for style transfer.","Modify,Fact/Evidence",Fact/Evidence
1922,185-ARR,185-ARR_v2_8@2,185-ARR_v1_8@3,"In this way, our model can better preserve the content information without disentangling content and style in the latent space.","In this way, ATM can better preserve the content information without disentangling content and style in the latent space.","Modify,Clarity",Clarity
1923,185-ARR,185-ARR_v2_2@4,185-ARR_v1_2@4,"DAML is a domain adaptive meta-learning approach to learn general knowledge in multiple heterogeneous source domains, capable of adapting to new unseen domains with a small amount of data.","DAML is a domain adaptive metalearning approach to refine general knowledge in multi-heterogeneous source domains, capable of adapting to new unseen domains with a small amount of data.","Modify,Clarity",Clarity
1924,185-ARR,185-ARR_v2_17@0,185-ARR_v1_17@0,"Domain adaptation has been studied in various natural language processing tasks (Glorot et al., 2011;Qian and Yu, 2019;Wang et al., 2017;Li et al., 2021a).","Domain adaptation has been studied in various natural language processing tasks (Glorot et al., 2011;Qian and Yu, 2019;Wang et al., 2017).","Modify,Fact/Evidence",Fact/Evidence
1925,19-ARR,,19-ARR_v1_56@10,,The ensemble metric outperformed the top individual metric of COMET when the zero-shot model was removed.,"Delete,Fact/Evidence",Fact/Evidence
1926,19-ARR,,19-ARR_v1_65@7,,"The current BILLBOARD setup is based on rubric-based, expert evaluation data from previous work, but future work can explore ways to improve crowdsourced evaluations and use them to update BILLBOARDs.","Delete,Claim",Claim
1927,19-ARR,,19-ARR_v1_66@1,,"In particular, generation models have more aspects than generation quality, such as training and inference efficiency, sample efficiency, and robustness.","Delete,Claim",Claim
1928,19-ARR,,19-ARR_v1_66@2,,"These aspects are often ignored in the current leaderboard paradigm but are important to better serving practitioners' needs (Schwartz et al., 2019;Ethayarajh and Jurafsky, 2020).","Delete,Fact/Evidence",Fact/Evidence
1929,19-ARR,,19-ARR_v1_75@0,,Seen in Table 11 are ablation studies for the ensemble metrics where one of the three selected metrics is removed at a time.,"Delete,Fact/Evidence",Fact/Evidence
1930,19-ARR,,19-ARR_v1_75@1,,"Dropping one metric often has no impact on the correlation score, suggesting that these metrics are highly redundant and capture similar aspects of the output quality.","Delete,Claim",Claim
1931,19-ARR,,19-ARR_v1_75@2,,BILLBOARDs encourage researchers to explore ways to diversify automatic evaluations by updating the ensemble metric every time a new metric is submitted.,"Delete,Claim",Claim
1932,19-ARR,19-ARR_v2_52@0,,"9 Prior work used a concatenation of author-written highlights as a reference, but here we do not add it to the reference set.",,"Add,Fact/Evidence",Fact/Evidence
1933,19-ARR,19-ARR_v2_52@1,,"This is because these highlights are sometimes noisy (e.g., containing URLs) or lack coherence (Fabbri et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
1934,19-ARR,19-ARR_v2_63@5,,"We examined all papers whose title contains ""machine translation"" and ""summarization"" and disregarded papers primarily on evaluation metrics.",,"Add,Fact/Evidence",Fact/Evidence
1935,19-ARR,19-ARR_v2_63@6,,"""QA"" metrics use a QA system to evaluate summaries (e.g., Eyal et al., 2019).",,"Add,Fact/Evidence",Fact/Evidence
1936,19-ARR,19-ARR_v2_63@7,,"""Specialized"" indicates specialized evaluation in a particular dimension, rather than the overall generation quality, such as document-level evaluations on contrastive sets (Voita et al., 2019).",,"Add,Fact/Evidence",Fact/Evidence
1937,19-ARR,19-ARR_v2_63@9,,The score column indicates the score from the metric that currently correlates best with the human judgments (ensemble).,,"Add,Fact/Evidence",Fact/Evidence
1938,19-ARR,19-ARR_v2_66@1,,"16 They share similar pipeline structure but vary in model architecture, (pre)training data, model size, and (pre)training objective.",,"Add,Fact/Evidence",Fact/Evidence
1939,19-ARR,19-ARR_v2_67@0,,Table 12 presents fixed-effect coefficients that measure how much each automatic metric overrates machines over humans ( §2.3).,,"Add,Fact/Evidence",Fact/Evidence
1940,19-ARR,19-ARR_v2_67@1,,"With some exceptions in CNNDM summarization, almost all automatic metrics underrate human generations (significantly positive coefficients).",,"Add,Fact/Evidence",Fact/Evidence
1941,19-ARR,19-ARR_v2_67@2,,"Table 13 swaps the roles of human-generated text, but we still see similar patterns: almost all metrics overrate machines over humans, but the problem is mitigated in COMET-QE, a referenceless, quality estimation metric.",,"Add,Fact/Evidence",Fact/Evidence
1942,19-ARR,19-ARR_v2_67@3,,This confirms that our findings hold independently of the design choice.,,"Add,Claim",Claim
1943,19-ARR,19-ARR_v2_27@1,19-ARR_v1_31@3,"To make fair comparisons, we simulate situations where the ensemble is applied to a newly submitted generator that has no human evaluations.","To make fair comparisons, we simulate situations that the ensemble is applied to a newly submitted generator that has no human evaluations.","Modify,Grammar",Grammar
1944,19-ARR,19-ARR_v2_30@0,19-ARR_v1_33@0,"Recent work (Kasai et al., 2022) observed that automatic metrics tend to overrate machine-generated text over human one on the MSCOCO image captioning task (Chen et al., 2015).","Recent work (Kasai et al., 2021b) observed that automatic metrics tend to overrate machine-generated text over human one on the MSCOCO image captioning task (Chen et al., 2015).","Modify,Fact/Evidence",Fact/Evidence
1945,19-ARR,19-ARR_v2_30@1,19-ARR_v1_33@1,This problem is particularly severe in conventional metrics that are based on n-gram overlap such as BLEU and CIDEr .,"This problem is particularly severe in conventional metrics that are based on n-gram overlap such as BLEU and CIDEr (Vedantam et al., 2015).","Modify,Fact/Evidence",Fact/Evidence
1946,19-ARR,19-ARR_v2_37@6,19-ARR_v1_38@6,"Prior work also points out other problems in ranking metrics like outlier effects where outlier systems have a disproportionately large effect on the overall correlation (Mathur et al., 2020a,b).","Prior work also points out other problems in ranking metrics like outlier effects where outlier systems have a disproportionately large effect on the overall correlation (Mathur et al., 2020b,a).","Modify,Grammar",Grammar
1947,19-ARR,19-ARR_v2_40@3,19-ARR_v1_41@3,"These crowdworker evaluations depend highly on individual annotators' discretion and understanding of the annotation scheme (Freitag et al., 2021;Clark et al., 2021), making it difficult to decompose, interpret, and validate (Kasai et al., 2022).","These crowdworker evaluations depend highly on individual annotators' discretion and understanding of the annotation scheme (Freitag et al., 2021;Clark et al., 2021), making it difficult to decompose, interpret, and validate (Kasai et al., 2021b).","Modify,Fact/Evidence",Fact/Evidence
1948,19-ARR,19-ARR_v2_48@5,19-ARR_v1_51@5,"Note that this aggregation method can be modified, depending on the downstream task of interest (Kasai et al., 2022).","Note that this aggregation method can be modified, depending on the downstream of interest (Kasai et al., 2021b).","Modify,Fact/Evidence",Fact/Evidence
1949,19-ARR,19-ARR_v2_49@3,19-ARR_v1_52@3,"For each of 500 test images, rubric-based evaluations (THUMB 1.0) are available for five systems, including one caption from a crowdworker (Kasai et al., 2022).","For each of 500 test images, rubric-based evaluations (THUMB 1.0) are available for five systems, including one caption from a crowdworker (Kasai et al., 2021b).","Modify,Fact/Evidence",Fact/Evidence
1950,19-ARR,19-ARR_v2_51@4,19-ARR_v1_54@4,We follow Kasai et al. (2022) for MSCOCO and score their randomly-selected Human caption using the other four as the reference.,We follow Kasai et al. (2021b) for MSCOCO and score their randomly-selected Human caption using the other four as the reference.,"Modify,Fact/Evidence",Fact/Evidence
1951,19-ARR,19-ARR_v2_55@12,19-ARR_v1_57@9,"These results suggest that the evaluation practice should be regularly updated as our generation models become stronger (and perhaps, more similar to human generation) in the future.","These results suggest that the evaluation practice should be regularly updated as our generation model becomes stronger (and perhaps, more similar to human generation) in the future.","Modify,Grammar",Grammar
1952,19-ARR,19-ARR_v2_6@0,19-ARR_v1_6@0,"Meanwhile, many evaluation metrics that improve correlation with human judgments have been proposed (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but this progress has yet to be broadly adopted by the community of researchers focused on advancing models.","Meanwhile, many evaluation metrics that improve correlation with human judgments have been proposed (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but this progress is largely ignored by the community of researchers focused on advancing models.","Modify,Other",Other
1953,19-ARR,19-ARR_v2_55@15,19-ARR_v1_63@0,"Table 3: β 0 fixed-effect coefficients from the linear mixed-effects models, quantifying how much automatic metrics overrate machines over humans, relative to human raters.","Table 3: β 0 (fixed-effect coefficients) from the linear mixed-effects models that analyze how much automatic metrics overrate machines over humans, relative to human raters.","Modify,Clarity",Clarity
1954,19-ARR,19-ARR_v2_6@1,19-ARR_v1_6@1,"Indeed, consistent with prior metaevaluations (Marie et al., 2021), we found that 68% of the machine translation papers from NAACL and ACL 2021 evaluated their models solely by BLEU, and only 5% measured the performance using recent metrics with contextual representations such as COMET (Rei et al., 2020).","Indeed, we found that 68% of the machine translation papers from NAACL and ACL 2020 evaluated their models solely by BLEU, and only 5% measured the performance using recent metrics with contextual representations such as COMET (Rei et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
1955,19-ARR,19-ARR_v2_57@7,19-ARR_v1_66@3,"There are ongoing modeling and benchmarking efforts especially for efficient machine translation (Heafield et al., 2020;Peng et al., 2021;Kasai et al., 2021b, inter alia).","There are ongoing modeling and benchmarking efforts especially for efficient machine translation (Heafield et al., 2020;Peng et al., 2021, inter alia).","Modify,Fact/Evidence",Fact/Evidence
1956,19-ARR,19-ARR_v2_59@1,19-ARR_v1_68@1,"We established and released four BILL-BOARDs on machine translation, summarization, and image captioning tasks.","We established four BILLBOARDs on machine translation, summarization, and image captioning tasks.","Modify,Fact/Evidence",Fact/Evidence
1957,19-ARR,19-ARR_v2_2@1,19-ARR_v1_2@1,"Meanwhile, efforts to improve generation models tend to depend on simple n-gram overlap metrics (e.g., BLEU, ROUGE).","Meanwhile, efforts to improve generation models tend to focus on simple n-gram overlap metrics (e.g., BLEU, ROUGE).","Modify,Claim",Claim
1958,19-ARR,19-ARR_v2_8@0,19-ARR_v1_8@0,"We release four BILLBOARD interfaces (https://nlp.cs.washington.edu/ billboard/) spanning three generation tasks: the WMT20 EN-DE and WMT20 ZH-EN machine translation tasks (Barrault et al., 2020), the CNNDM summarization task (Hermann et al., 2015), and the MSCOCO image captioning task (Lin et al., 2014).","We release four BILLBOARDs spanning three generation tasks: the WMT20 EN-DE and WMT20 ZH-EN machine translation tasks (Barrault et al., 2020), the CNNDM summarization task (Hermann et al., 2015), and the MSCOCO image captioning task (Lin et al., 2014).","Modify,Fact/Evidence",Fact/Evidence
1959,19-ARR,19-ARR_v2_2@3,19-ARR_v1_2@3,"We therefore propose a generalization of leaderboards, bidimensional leaderboards (BILLBOARDs), that simultaneously tracks progress in language generation models and metrics for their evaluation.","We therefore propose a generalization of leaderboards, bidimensional leaderboards (BILLBOARDs), that simultaneously tracks progress in language generation tasks and metrics for their evaluation.","Modify,Clarity",Clarity
1960,19-ARR,19-ARR_v2_16@0,19-ARR_v1_15@0,"In particular, scores from automatic metrics often diverge from human judgments in language generation tasks, especially when models become increasingly powerful (Ma et al., 2019).","In particular, scores from automatic metrics often diverge from human judgments in language generation tasks especially when models become increasingly powerful (Ma et al., 2019).","Modify,Grammar",Grammar
1961,19-ARR,19-ARR_v2_16@1,19-ARR_v1_15@1,"Much recent work proposed new evaluation metrics that improve correlations with human judgments in certain generation tasks (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but most developers of generation models are not benefiting from them (See Appendix A for our analysis of papers from NAACL/ACL 2021).","Much recent work proposed new evaluation metrics that improve correlations with human judgments in certain generation tasks (Clark et al., 2019;Zhang et al., 2020b;Sellam et al., 2020;Hessel et al., 2021, inter alia), but most developers of generation models are not benefiting from them (See Appendix A for our analysis of papers from NAACL/ACL 2020).","Modify,Fact/Evidence",Fact/Evidence
1962,19-ARR,19-ARR_v2_16@3,19-ARR_v1_15@3,"Developers of evaluation metrics, on the other hand, are missing the opportunity to apply their metrics to new generation models and compare them with the existing ones.","Developers of evaluation metrics, on the other hand, are missing the opportunity to apply their metrics to new generation models and compare with the existing ones.","Modify,Clarity",Clarity
2112,196-ARR,,196-ARR_v1_32@0,,We provide additional examples of syntactic and morphological negations in Table 6.,"Delete,Fact/Evidence",Fact/Evidence
2113,196-ARR,196-ARR_v2_20@1,,"The third column presents the expected answer for the example (a choice, judgment, or score depending on the task).",,"Add,Fact/Evidence",Fact/Evidence
2114,196-ARR,196-ARR_v2_24@2,,"Despite the fact that negations are not important in WSC and WiC, they do affect the experimental results (details in Q3).",,"Add,Claim",Claim
2115,196-ARR,196-ARR_v2_25@3,,"Perhaps unsurprisingly, syntactic negations are much more common than morphological negations (Common-senseQA: 88.6% vs 11.4%, SST-2: 71.9% vs 28.1%).",,"Add,Claim",Claim
2116,196-ARR,196-ARR_v2_25@4,,"More importantly, syntactic negations are more often important in SST-2 (42.3% vs 23%), but both syntactic and morphological negation are roughly equaly important in CommonsenseQA (55.2% vs 52.4%).",,"Add,Claim",Claim
2117,196-ARR,196-ARR_v2_26@3,,"Further, even though all negations are unimportant in WiC and WSC, we observe a drop in performance for the instances with negation compared to the instances without negation (WiC: 0.64 vs 0.67 and WSC: 0.59 vs 0.63).",,"Add,Fact/Evidence",Fact/Evidence
2118,196-ARR,196-ARR_v2_31@2,,"While fine-training, the negation cues are marked with BIO (B: Beginning of cue, I: Inside of cue, O: Outside of cue) tagging scheme.",,"Add,Fact/Evidence",Fact/Evidence
2119,196-ARR,196-ARR_v2_31@3,,The contextualized representations from the last layer of RoBERTa are passed to a fully connected (FC) layer.,,"Add,Fact/Evidence",Fact/Evidence
2120,196-ARR,196-ARR_v2_31@4,,"Finally, a conditional random field (CRF) layer produces the output sequence for the labels.",,"Add,Fact/Evidence",Fact/Evidence
2121,196-ARR,196-ARR_v2_32@1,,The neural model takes about two hours on average to train on a single GPU of NVIDIA Tesla K80.,,"Add,Fact/Evidence",Fact/Evidence
2122,196-ARR,196-ARR_v2_32@3,,"Hp-1, Hp-2, and Hp-3 refer to the number of epochs, batch size, and learning rate used in the training procedure.",,"Add,Fact/Evidence",Fact/Evidence
2123,196-ARR,196-ARR_v2_32@4,,We use default settings for the other hyperparameters when we use the implementation by Phang et al. (2020).,,"Add,Fact/Evidence",Fact/Evidence
2124,196-ARR,196-ARR_v2_24@1,196-ARR_v1_24@1,These percentages indicate that one can safely ignore (almost) all negations and still solve the benchmarks.,This indicates that one can safely ignore (almost) all negations and still solve the benchmarks.,"Modify,Clarity",Clarity
2125,196-ARR,196-ARR_v2_25@8,196-ARR_v1_25@5,We refer the readers to the Appendix B for the details about these models and hyperparameters.,We refer the reader to the supplementary materials for details about these models and hyperparameters.,"Modify,Clarity",Clarity
2126,196-ARR,196-ARR_v2_34@1,196-ARR_v1_31@2,"We use the default settings of the hyperparameters, except for a few, when fine-tuning the model on each benchmark.","We accept the default settings of the hyperparameters, except for a few, when fine-tuning the model on each benchmark.","Modify,Clarity",Clarity
2127,196-ARR,196-ARR_v2_5@0,196-ARR_v1_5@0,Many corpora for natural language understanding tasks contain language generated by annotators rather than retrieved from texts written independently of the corpus creation process.,Many corpora for natural language understanding tasks contain language generated by annotators rather than retrieved from texts created independently of the corpus creation process.,"Modify,Clarity",Clarity
2128,197-ARR,,197-ARR_v1_73@4,,"The ResNet-56 model (He et al., 2016) serves as the backbone, and we compare PCEE-BERT with PABEE.","Delete,Fact/Evidence",Fact/Evidence
2129,197-ARR,197-ARR_v2_2@7,,The code for PCEE-BERT can be found at https://github. com/michael-wzhu/PCEE-BERT.,,"Add,Fact/Evidence",Fact/Evidence
2130,197-ARR,197-ARR_v2_4@0,197-ARR_v1_4@0,"Since BERT (Devlin et al., 2018), the pre-trained language models (PLMs) have become the default state-of-the-art (SOTA) models for natural language processing (NLP).","Since BERT (Devlin et al., 2018), the pre-trained language models (PLMs) become the default stateof-the-art (SOTA) models for natural language processing (NLP).","Modify,Grammar",Grammar
2131,197-ARR,197-ARR_v2_4@1,197-ARR_v1_4@1,"The recent years have witnessed the rise of many PLMs, such as GPT (Radford et al., 2019), XLNet (Yang et al., 2019), ALBERT (Lan et al., 2020), and so forth.","The recent years have witnessed the rise of many PLMs, such as GPT (Radford et al., 2019), XLNet (Yang et al., 2019), and AL-BERT (Lan et al., 2020), and so forth.","Modify,Clarity",Clarity
2132,197-ARR,197-ARR_v2_2@0,197-ARR_v1_2@0,BERT and other pre-trained language models (PLMs) are ubiquitous in modern NLP.,BERT and other pre-trained language models (PLMs) are ubiquitous in the modern NLP.,"Modify,Grammar",Grammar
2133,197-ARR,197-ARR_v2_45@2,197-ARR_v1_48@2,"Budgeted exiting is a direct way to speed up BERT's inference, but it is not instance adaptive.","Budgeted exiting is a direct way to speed up BERT's inference, but it is instance adaptive.","Modify,Claim",Claim
2134,197-ARR,197-ARR_v2_2@1,197-ARR_v1_2@1,"Even though PLMs are the state-of-the-art (SOTA) models for almost every NLP task (Qiu et al., 2020), the significant latency during inference prohibits wider industrial usage.","Even though PLMs are the state-of-the-art (SOTA) models for almost every NLP task (Qiu et al., 2020), the significant latency during inference forbids more widely industrial usage.","Modify,Clarity",Clarity
2136,197-ARR,197-ARR_v2_71@3,197-ARR_v1_73@5,"We conduct experiments on two image classification datasets, CIFAR-10 and CIFAR-100 (Krizhevsky, 2009) at every two convolutional layers.",We place an exiting classifier at every two convolutional layers.,"Merge+Modify,Fact/Evidence",Fact/Evidence
2137,197-ARR,197-ARR_v2_5@9,197-ARR_v1_5@9,"For example, during the flu season, online medical consultation will be used much more often than usual.","For example, during the flu season, online medical consultation will be used much often than usual.","Modify,Grammar",Grammar
2138,197-ARR,197-ARR_v2_6@2,197-ARR_v1_8@2,The speed-up ratio can be easily controlled with certain hyper-parameters to handle significant changes in query traffic without re-deploying the model services or maintaining a group of models.,The speed-up ratio can be easily controlled with certain hyper-parameters to process significant changes in query traffic without re-deploying the model services or maintaining a group of models.,"Modify,Clarity",Clarity
2139,197-ARR,197-ARR_v2_11@1,197-ARR_v1_12@1,"A multi-exit BERT is adopted as the backbone model, and an intermediate classifier (i.e., an exit) is installed right after each transformer block.","A multi-exit BERT is adopted as the backbone model, and an intermediate classifier (i.e., an exit) is installed right after each transformer black.","Modify,Grammar",Grammar
2140,197-ARR,197-ARR_v2_13@3,197-ARR_v1_14@3,"Third, we conduct experiments on the GLUE benchmark and conduct a series of ablation studies.","Third, we conduct experiments on the GLUE benchmark and conduct a series of ablations studies.","Modify,Grammar",Grammar
2141,200-ARR,,200-ARR_v1_76@0,,"We hereby report a more detailed description of the datasets introduced by (Emelin et al., 2020).","Delete,Fact/Evidence",Fact/Evidence
2142,200-ARR,,200-ARR_v1_76@1,,"From § 4.2, recall that these challenge sets are based on sense clusters built on BabelNet, where each sense cluster contains an English polysemous word and a set of German monosemous terms, which uniquely identify a certain meaning.","Delete,Fact/Evidence",Fact/Evidence
2143,200-ARR,,200-ARR_v1_76@2,,"We highlight that there is no direct link between the sense clusters and the data produced by our Annotation Refinement process, as the sense clusters are i) heavily manually refined 12 and ii) based off of the entire BabelNet4 inventory (16M concepts), while EWISER only covers the subgraph of Ba-belNet linked to WordNet (117k concepts), as is common in the multilingual WSD setting.","Delete,Fact/Evidence",Fact/Evidence
2144,200-ARR,,200-ARR_v1_76@3,,"As such, we do not consider the evaluation to be favorable in any way towards our system.","Delete,Claim",Claim
2145,200-ARR,,200-ARR_v1_77@0,,WSD Bias contains sentences whose targeted English term is likely to be translated to a specific different sense due to co-occurrences of words in the sentence itself.,"Delete,Claim",Claim
2146,200-ARR,,200-ARR_v1_77@1,,"For example, in the sentence ""a lot of money was spent to renovate the capital"" the word capital is likely to be translated to its sense of amount of money due to the presence of the words money and spent.","Delete,Claim",Claim
2147,200-ARR,,200-ARR_v1_77@2,,A mistake is detected if the term is translated to any of the German words contained in the most likely sense cluster.,"Delete,Fact/Evidence",Fact/Evidence
2148,200-ARR,,200-ARR_v1_77@3,,The goal of this task is to measure the intrinsic bias the model learned during training.,"Delete,Fact/Evidence",Fact/Evidence
2149,200-ARR,,200-ARR_v1_78@0,,"Adversarial contains two sets of sentences, the original sentence and its adversarial counterpart, built by injecting an adjective that is likely to flip the disambiguation performed by the NMT model towards a specific sense.","Delete,Fact/Evidence",Fact/Evidence
2150,200-ARR,,200-ARR_v1_78@1,,"For example, given the sentence ""they met in the spring of 2020"", the adversarial example would be ""they met in the hot spring of 2020"".","Delete,Claim",Claim
2151,200-ARR,,200-ARR_v1_78@2,,The injection of hot leads the model to translate spring to its sense of water source as opposed to its correct sense of season.,"Delete,Fact/Evidence",Fact/Evidence
2152,200-ARR,,200-ARR_v1_81@0,,"For instance, EN→DE has 74.4M parameters, EN→ES has 77.9M, EN→FR has 75.1M.","Delete,Fact/Evidence",Fact/Evidence
2153,200-ARR,200-ARR_v2_17@0,,"Finally, Campolungo et al. (2022) proposed DIBIMT, the first fully manually annotated test set for measuring the disambiguation bias of neural machine translation models, covering five language combinations, namely, from English to German, Spanish, Italian, Russian and Chinese.",,"Add,Fact/Evidence",Fact/Evidence
2154,200-ARR,200-ARR_v2_17@1,,"In their work, the authors showed that open neural models still exhibit strong semantic biases towards frequent senses, confirming once again the suspicions about this under-explored issue.",,"Add,Fact/Evidence",Fact/Evidence
2155,200-ARR,200-ARR_v2_72@0,,System Examples,,"Add,Other",Other
2156,200-ARR,200-ARR_v2_79@0,,Evaluation on DIBIMT,,"Add,Other",Other
2157,200-ARR,200-ARR_v2_80@0,,"In Table 4 we report the results obtained on DIBIMT (Campolungo et al., 2022).",,"Add,Fact/Evidence",Fact/Evidence
2158,200-ARR,200-ARR_v2_81@0,,"While on English→German we observe an improvement of 1%, the performance on English→Spanish decreases by around 0.6%.",,"Add,Fact/Evidence",Fact/Evidence
2159,200-ARR,200-ARR_v2_81@1,,"We hypothesize that our English→Spanish model might be undertrained, as its accuracy differs by around 10% from OPUS, its direct comparison, while on English→German the difference is only of around 3%.",,"Add,Claim",Claim
2160,200-ARR,200-ARR_v2_81@2,,"We leave further investigation of this issue, including training larger, more capable models, as future work.",,"Add,Fact/Evidence",Fact/Evidence
2161,200-ARR,200-ARR_v2_86@1,,"While this is rather intuitive, and has been shown to be the case in previous works (Nguyen et al., 2018;Pu et al., 2018b), we test this hypothesis in our setting by training an NMT model, from scratch, with sense-enhanced sentences only (see § 3.3 for details).",,"Add,Fact/Evidence",Fact/Evidence
2162,200-ARR,200-ARR_v2_86@2,,"We train a model comparable with the Baseline (i.e., same architecture and hyperparameters) on the English→German training set ( § 4.2), and observe that it achieves higher BLEU scores than the Baseline (which is trained on the same data but with plain sentences).",,"Add,Fact/Evidence",Fact/Evidence
2163,200-ARR,200-ARR_v2_86@3,,"For instance, the senseenhanced model achieves a BLEU score of 27.22 on WMT14 and 36.79 on WMT19, with the first being a statistically significant improvement.",,"Add,Fact/Evidence",Fact/Evidence
2164,200-ARR,200-ARR_v2_86@4,,"This confirms, once again, that sense-enhanced NMT models are on par or better than plain NMT models, although they introduce the heavy requirement of WSD at inference time, which our work aims at dropping.",,"Add,Claim",Claim
2165,200-ARR,200-ARR_v2_98@0,,3. Our pipeline is strictly tied to both the accuracy of the multilingual WSD system employed and by the coverage of the underlying sense inventory.,,"Add,Fact/Evidence",Fact/Evidence
2166,200-ARR,200-ARR_v2_98@1,,"While EWISER and Babel-Net work reasonably well for high-resource languages, the quality of the annotated corpus might decrease for low-resource ones.",,"Add,Claim",Claim
2167,200-ARR,200-ARR_v2_19@1,200-ARR_v1_17@1,"We propose a novel approach, similar to that introduced in Luan et al. (2020), for creating high-quality sense-annotated parallel corpora, and we use this semantic information to regularize an NMT model, making it less biased and capable of producing higher-quality translations.","We propose a novel approach to create high-quality sense-annotated parallel corpora, which leverages the most recent advances in WSD, and use this semantic information to regularize a NMT model, making it less biased and capable of producing higher-quality translations.","Modify,Fact/Evidence",Fact/Evidence
2168,200-ARR,200-ARR_v2_21@4,200-ARR_v1_19@3,"However, data that would allow these two worlds to be brought together, i.e., parallel corpora where words are associated with semantic labels, are currently still produced automatically by leveraging outdated approaches to WSD (Delli Bovi et al., 2017).","However, data that would allow to bring these two worlds together, i.e., parallel corpora where words are associated with semantic labels, are produced automatically by leveraging outdated approaches to WSD (Delli Bovi et al., 2017).","Modify,Clarity",Clarity
2169,200-ARR,200-ARR_v2_22@0,200-ARR_v1_20@0,"In what follows, we first provide some preliminary information about resources and tools that we employ in our method ( § 3.1); then, we introduce a new approach for automatically annotating tokens within parallel sentences with sense annotations, i.e., labels explicitly defining their meanings ( § 3.2); finally, we propose a fine-tuning objective for leveraging such annotations in order to mitigate the sense bias while also improving the translation quality overall ( § 3.3).","In what follows, we first provide some preliminary information about resources and tools that we employ in our method ( § 3.1); then, we introduce a new approach to automatically annotate tokens within parallel sentences with sense annotations, i.e., labels explicitly defining their meanings ( § 3.2); finally, we leverage such annotations within a new approach that we propose in order to mitigate the sense bias while also improving the translation quality overall ( § 3.3).","Modify,Clarity",Clarity
2170,200-ARR,200-ARR_v2_24@2,200-ARR_v1_22@2,"For instance, the synset of plant organism contains the following lexicalizations: plant EN , pianta IT , Pflanze DE , among others.","For instance, the concept of plant organism contains the following lexicalizations: plant EN , pianta IT , Pflanze DE , among others.","Modify,Clarity",Clarity
2171,200-ARR,200-ARR_v2_24@5,200-ARR_v1_22@5,"2 Since BabelNet contains millions of synsets, which may make the computation too expensive, we restrict the vocabulary to just those containing at least one English sense from WordNet, as is also done in several other works (Barba et al., 2020;Scarlini et al., 2020b;Bevilacqua and Navigli, 2020).","3 Since BabelNet contains millions of synsets, which may make the computation too expensive, we restrict the vocabulary only to those containing at least one English sense from WordNet, as also done in several other works (Barba et al., 2020;Scarlini et al., 2020b;Bevilacqua and Navigli, 2020).","Modify,Clarity",Clarity
2172,200-ARR,200-ARR_v2_29@1,200-ARR_v1_27@1,"To this end, given as input a sentence s 3 from a parallel corpus C, we first apply Part-of-Speech tagging and lemmatization to it, then pass it through our WSD system, which returns a distribution over its possible meanings.","To this end, given as input a sentence s 4 from a parallel corpus C, we first lemmatize and POS-tag it, then pass it through our WSD system which returns a distribution over its possible meanings.","Modify,Clarity",Clarity
2173,200-ARR,200-ARR_v2_29@3,200-ARR_v1_27@3,"The WSD system assigns a score c(S|w i , s) to each synset S ∈ σ(w i ); we denote the synset of w i with the highest confidence as S * w i .","The WSD system assigns a score c(S|w i , s) to each synset S ∈ σ(w i ) and we denote the synset of w i with the highest confidence as S * w i .","Modify,Grammar",Grammar
2174,200-ARR,200-ARR_v2_34@0,200-ARR_v1_30@0,"Finally, we assign the same synset S * to both words (w s i , w t j ) in P as follows:","Finally, we assign a synset S * to both words (w s i , w t j ) in P as follows:","Modify,Clarity",Clarity
2175,200-ARR,200-ARR_v2_38@1,200-ARR_v1_34@1,"Ideally, we want the model to benefit from such annotations during training, while not being dependent on them at inference time.","Ideally, we want the model to benefit from such annotations during training while not being dependent on them at inference time.","Modify,Grammar",Grammar
2176,200-ARR,200-ARR_v2_2@0,200-ARR_v1_2@0,"Recent studies have shed some light on a common pitfall of Neural Machine Translation (NMT) models, stemming from their struggle to disambiguate polysemous words without lapsing into their most frequently occurring senses in the training corpus.","Recent works have shed some light on a common pitfall of Neural Machine Translation (NMT) models, lying in their struggle to disambiguate polysemous words without lapsing into their most frequently occurring sense in the training corpus.","Modify,Clarity",Clarity
2177,200-ARR,200-ARR_v2_4@3,200-ARR_v1_4@3,"Therefore, several efforts have been recently devoted to shed some light and create test beds (Rios Gonzales et al., 2017;Raganato et al., 2019;Emelin et al., 2020;Campolungo et al., 2022) to challenge NMT models.","Therefore, several efforts have been recently invested to shed some light and create adversarial test beds (Gonzales et al., 2017;Raganato et al., 2019;Emelin et al., 2020) to challenge NMT models.","Modify,Fact/Evidence",Fact/Evidence
2178,200-ARR,200-ARR_v2_41@3,200-ARR_v1_35@2,"Additionally, to enforce the connection between the tagged word and its sense annotation, we set the position ids for the word and the sense embedding to the same value, as if they were a single token.","Additionally, to enforce the connection between the tagged word and its sense annotation, we set the position ids for the word and the sense embedding to the same value, as if they were a single token, and represent the sense with its sense embedding 6 passed through a linear projection layer (as shown in Figure 2).","Modify,Fact/Evidence",Fact/Evidence
2179,200-ARR,200-ARR_v2_42@0,200-ARR_v1_36@0,"We hereby propose the Semantic Consistency Regularization (SCR) objective, inspired by MVR (Wang et al., 2021).",We hereby propose the Semantic Consistency Regularization (SCR) objective.,"Modify,Fact/Evidence",Fact/Evidence
2180,200-ARR,200-ARR_v2_4@4,200-ARR_v1_4@4,"Results show that these models still struggle to deal with highly polysemous words, especially when used to express least frequent senses.","Results showed that these models still struggle to deal with highly polysemous words, especially when used to express least frequent senses.","Modify,Grammar",Grammar
2181,200-ARR,200-ARR_v2_50@1,200-ARR_v1_43@1,"As pre-trained sense embeddings we use ARES (Scarlini et al., 2020b), since they provide multilingual representations for each synset in our vocabulary.","As pre-trained sense embeddings we use ARES, since they provide multilingual representations for each synset in our vocabulary (Scarlini et al., 2020b).","Modify,Clarity",Clarity
2182,200-ARR,200-ARR_v2_5@0,200-ARR_v1_5@0,"For example, given the sentence ""The energy comes from a distant plant."", both Google Translate and DeepL disambiguate 1 plant to its sense of organism when translating into Italian, and produce the following incorrect sentence ""L'energia proviene da una pianta lontana."", rather than ""L'energia proviene da un impianto lontano."", where impianto is the translation for the factory meaning of plant.","For example, given the sentence ""The energy comes from a distant plant."", both Google Translate and DeepL disambiguate 1 plant to its sense of organism when translating to Italian, and produce the following incorrect sentence ""L'energia proviene da una pianta lontana."", rather than ""L'energia proviene da un impianto lontano."", where impianto is the translation for the factory meaning of plant.","Modify,Grammar",Grammar
2183,200-ARR,200-ARR_v2_53@2,200-ARR_v1_46@2,"As disambiguation system, we use EWISER (Bevilacqua and Navigli, 2020), a neural WSD model based on BERT (Devlin et al., 2019), which has attained state-of-the-art performances on English as well as other languages.","As disambiguation system, we use EWISER (Bevilacqua and Navigli, 2020), a neural WSD model based on BERT (Devlin et al., 2019), which attained state-of-the-art performances on English as well as other languages.","Modify,Grammar",Grammar
2184,200-ARR,200-ARR_v2_53@4,200-ARR_v1_46@4,Detailed statistics of the base and parallel corpora produced are provided in § A.5.,Detailed statistics of the base and produced parallel corpora are provided in § A.5.,"Modify,Clarity",Clarity
2185,200-ARR,200-ARR_v2_55@1,200-ARR_v1_48@1,"These challenge sets are based on sense clusters built by automatically merging together BabelNet synsets, which then are manually refined to ensure their correctness.","These challenge sets are based on sense clusters built by automatically merging together BabelNet synsets, and then are manually refined to ensure their correctness.","Modify,Grammar",Grammar
2186,200-ARR,200-ARR_v2_60@0,200-ARR_v1_52@0,"We note that, due to the way in which the WSD Bias Challenge Sets were constructed (i.e., by using sentences reserved from WMT14, see § 4.2), any fair evaluation against OPUS and MBart-50 is to be considered impossible, as such models have seen the sentences in the challenge sets during training.","We note that, due to how the WSD Bias challenge sets were constructed (i.e., by using sentences reserved from WMT14, see § 4.2), any fair evaluation against OPUS and MBart-50 is to be considered impossible, as such models have seen the sentences in the challenge sets during training.","Modify,Clarity",Clarity
2187,200-ARR,200-ARR_v2_60@1,200-ARR_v1_52@1,"We therefore evaluate these two models only on standard BLEU, and point out that the resulting scores should only be regarded as references for our models' competence in the translation task.","We therefore evaluate these two models only on standard BLEU metrics, and point out that the resulting scores should only be regarded as references for our models' competence in the translation task.","Modify,Clarity",Clarity
2188,200-ARR,200-ARR_v2_64@0,200-ARR_v1_56@0,"In Table 1 we observe that the trained baselines are more than competent in the translation task: indeed, when considering average BLEU scores, they place between OPUS, which is trained on much more data but has the same parameter count, and MBart-50 (Tang et al., 2021), which is ~8 times larger but is capable of translating English to 50 languages.","In Table 1 we observe that the trained baselines are more than competent in the translation task: indeed, when considering average BLEU scores, they place between OPUS, which is trained on much more data but has the same parameter count, and MBart-50 (Tang et al., 2020), which is 8 times larger but is capable of translating English to 50 languages.","Modify,Fact/Evidence",Fact/Evidence
2189,200-ARR,200-ARR_v2_65@0,200-ARR_v1_57@0,"In contrast to common debiasing techniques, which often observe a degradation in performance on standard benchmarks (Clark et al., 2019;He et al., 2019), we report consistent BLEU improvements on all language pairs, all of which are statistically significant at different p-values (Table 1), providing empirical proof that the proposed method does not hurt the model's general translation capability, while at the same time it helps models generate less biased translations (as will be discussed in the upcoming sections).","Contrarily to common debiasing techniques, which often observe a degradation in performance on standard benchmarks (Clark et al., 2019;He et al., 2019), we report consistent BLEU improvements on all language pairs, all of which are statistically significant at different p-values (Table 1), providing empirical proof that the proposed method does not hurt the model's general translation capability, while it helps models generate less biased translations (as discussed in the upcoming sections).","Modify,Clarity",Clarity
2190,200-ARR,200-ARR_v2_67@0,200-ARR_v1_59@0,"Results on the Disambiguation Bias Challenge Sets ( § 4.2) are reported in Table 2, for both of which we show improvements: on the WSD Bias Challenge Set, the bias is reduced, significantly, by more than 1%; similarly, on the Adversarial Challenge Set, we see a reduction of homographs mistakenly disambiguated due to the injection of adversarial adjectives of 0.27%.","Results on the Disambiguation Bias Challenge Sets ( § 4.2) are reported in Table 2 (numbers represent error rates), for both of which we show improvements: on the WSD Bias challenge set, the bias is reduced, significantly, by more than 1%; similarly, on the Adversarial challenge set, we see a reduction of homographs mistakenly disambiguated due to the injection of adversarial adjectives of 0.27%.","Modify,Grammar",Grammar
2191,200-ARR,200-ARR_v2_69@0,200-ARR_v1_61@0,"We conduct an analysis of the performance of EWISER on the English sentences of the WSD Bias Challenge Set, to see how it fares in comparison with our NMT models.","We conducted an analysis of the performance of EWISER on the English sentences of the WSD Bias Challenge Set, to see how it would fare in comparison with our NMT models.","Modify,Grammar",Grammar
2192,200-ARR,200-ARR_v2_69@1,200-ARR_v1_62@0,"Unfortunately, as the sense clusters are not directly associated with BabelNet synsets, we reconstruct this association automatically and manage to retrieve only 1847 of the 3000 sentences in the challenge set.","Unfortunately, as the sense clusters were not directly associated with BabelNet synsets, we reconstructed this association automatically and managed to retrieve only 1847 of the 3000 sentences in the challenge set.","Modify,Grammar",Grammar
2193,200-ARR,200-ARR_v2_6@0,200-ARR_v1_6@0,"Some recent studies have explored how to leverage explicit sense information within NMT models (Rios Gonzales et al., 2017;Pu et al., 2018a;Nguyen et al., 2018).","Some recent works have explored how to leverage explicit sense information within NMT models (Gonzales et al., 2017;Pu et al., 2018;Nguyen et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
2194,200-ARR,200-ARR_v2_70@1,200-ARR_v1_64@1,"With this in mind, we evaluate EWISER, Baseline and Baseline+SCR on the aforementioned subset of sentences; we report the results of this evaluation in Table 2 (bottom).","With that in mind, we evaluated EWISER, Baseline and Baseline+SCR on the aforementioned subset of sentences; we report the results of this evaluation in Table 2 (bottom).","Modify,Grammar",Grammar
2195,200-ARR,200-ARR_v2_71@0,200-ARR_v1_65@0,"The results indicate that, for this setting, both NMT models actually perform quite a lot better than a pre-trained disambiguation system.","The results indicate that, for this setting, both NMT models actually perform quite better than a pre-trained disambiguation system.","Modify,Other",Other
2196,200-ARR,200-ARR_v2_71@1,200-ARR_v1_65@1,"One reason for this might be the different distributions the models are trained on: by design, the challenge sentences follow a distribution similar to the corpus used to train the NMT model, whereas EWISER is trained on sentences coming from news corpora from the 1960s and dictionary-like definitions.","One reason might be the different distributions the models are trained on: by design, the challenge sentences follow a distribution similar to the corpus used to train the NMT model, whereas EWISER was trained on sentences coming from news corpora from the 1960s and dictionary-like definitions.","Modify,Grammar",Grammar
2197,200-ARR,200-ARR_v2_71@4,200-ARR_v1_66@0,"Finally, we choose not to perform a similar comparison on the Adversarial Challenge Set, as its examples are designed to specifically target NMT models via adversarial injections; we leave studying their impact in WSD systems as future work.","Finally, we chose not to perform a similar comparison on the Adversarial challenge set, as its examples were designed to specifically target NMT models via adversarial injections; we leave studying their impact in WSD systems as future work.","Modify,Grammar",Grammar
2198,200-ARR,200-ARR_v2_75@0,200-ARR_v1_68@0,"Ablation on SCR To measure the importance of the KL term in the loss, we fine-tune the model without including it in the SCR objective ( § 3.3) and report the results in Tables 1 and 2 (row Baseline+SCR −KL ).","Ablation on SCR To measure the importance of the KL term in the loss, we fine-tune the model without including it in the SCR objective ( § 3.3) and report the results in Table 1 and 2 (row Baseline+SCR −KL ).","Modify,Grammar",Grammar
2199,200-ARR,200-ARR_v2_77@0,200-ARR_v1_69@0,"We evaluate our sense Annotation Refinement process ( § 3.2) by fine-tuning the model on the unconstrained sense annotations provided by EWISER (Baseline+SCR −AR ), i.e., by considering the synset with the highest confidence on the source word as the correct one, instead of S * .",We evaluate our sense Annotation Refinement process ( § 3.2) by fine-tuning the model on the unconstrained sense annotations provided by EWISER (Baseline+SCR −AR ).,"Modify,Fact/Evidence",Fact/Evidence
2200,200-ARR,200-ARR_v2_77@2,200-ARR_v1_69@2,"Furthermore, the BLEU scores drop too, although not as significantly (Table 1), but still always under-performing with respect to Baseline+SCR.","Furthermore, the BLEU scores drop too, although not as significantly (Table 1), but still always underperforming with respect to Base-line+SCR.","Modify,Grammar",Grammar
2201,200-ARR,200-ARR_v2_83@0,200-ARR_v1_72@0,"In this paper, we presented a fine-tuning strategy that, by leveraging the explicit sense annotations produced by a novel high-precision technique, effectively reduces the disambiguation bias of a baseline Neural Machine Translation model while at the same time also strengthening translation performances, without introducing any requirement at inference time.","In this paper, we presented a fine-tuning strategy that, by leveraging the explicit sense annotations produced by a novel high-precision technique, effectively reduces the disambiguation bias of a baseline Neural Machine Translation model while also strengthening translation performances, without introducing any requirement at inference time.","Modify,Clarity",Clarity
2202,200-ARR,200-ARR_v2_84@0,200-ARR_v1_73@0,"Our analysis on a strong disambiguation system showed that its ability to disambiguate polysemous nouns is worse than that of a baseline NMT model, at least in the studied out-of-domain setting.","Our analysis on a strong disambiguation system has shown that its ability to disambiguate polysemous nouns is worse than that of a baseline NMT model, at least in the studied out-of-domain setting.","Modify,Grammar",Grammar
2203,200-ARR,200-ARR_v2_85@1,200-ARR_v1_74@1,"As future work, we plan to further study the ability of NMT models to perform Word Sense Disambiguation and to strengthen research at the intersection of these two fields, with a view to building stronger and more reliable models.","As future work, we plan to further study the ability of NMT models to perform Word Sense Disambiguation and to strengthen research at the intersection of these two fields to build stronger and more reliable models.","Modify,Clarity",Clarity
2204,200-ARR,200-ARR_v2_86@0,200-ARR_v1_79@0,Our work is based on the assumption that providing a neural model with sense annotations for ambiguous words helps in disambiguating them.,Our work is based on the assumption that providing a neural model with sense annotations for ambiguous words helps disambiguating them.,"Modify,Grammar",Grammar
2205,200-ARR,200-ARR_v2_92@0,200-ARR_v1_83@0,"Model training hyperparameters Similarly to (Emelin et al., 2020), we trained it on the entire dataset for a max of 100,000 steps with approximately 24k tokens per batch, label smoothing at 0.1 and an inverse square root learning rate scheduler with 4000 warmup steps.","Model training hyperparameters Similarly to (Emelin et al., 2020), we train it on the entire dataset for a max of 100,000 steps with approximately 24k tokens per batch, label smoothing at 0.1 and an inverse square root learning rate scheduler with 4000 warmup steps.","Modify,Grammar",Grammar
2206,200-ARR,200-ARR_v2_92@1,200-ARR_v1_83@1,"As optimizer, we used Adam (Kingma and Ba, 2015) with betas (0.99, 0.98) and learning rate 7 • 10 −4 , additionally employing an early stopping strategy with patience 5, monitoring the BLEU score on a validation set.","As optimizer, we use Adam (Kingma and Ba, 2015) with betas (0.99, 0.98) and learning rate 7 • 10 −4 , additionally employing an early stopping strategy with patience 5, monitoring the BLEU score on a validation set.","Modify,Grammar",Grammar
2207,200-ARR,200-ARR_v2_92@2,200-ARR_v1_83@2,We produced translations at inference time using a beam size of 5.,We produce translations at inference time using a beam size of 5.,"Modify,Grammar",Grammar
2208,200-ARR,200-ARR_v2_93@0,200-ARR_v1_84@0,"Fine-tuning hyperparameters For the finetuning, we resumed training using the weights of the baseline models, changed the learning to 1 • 10 −5 and reduced the warmup to 1000 steps; additionally, we evaluated the model every 10% of the fine-tuning steps rather than after each epoch, as we observed fast convergence during fine-tuning and multiple epochs were superfluous.","Fine-tuning hyperparameters For the finetuning, we resume training using the weights of the baseline models, change the learning to 1 • 10 −5 and reduce the warmup to 1000 steps; additionally, we evaluate the model every 10% of the fine-tuning steps rather than after each epoch, as we observed fast convergence during fine-tuning and multiple epochs were superfluous.","Modify,Grammar",Grammar
2209,200-ARR,200-ARR_v2_94@0,200-ARR_v1_85@0,"Table 5 reports the same results displayed in the paper, but includes the percentage of Correct translations for both challenge sets as well as the percentage of errors made from sentences that, after the injection of the adversarial adjectives, were translated into a sense that was neither the correct one, nor the one targeted by the adversarial injection (i.e., other).","Table 3 reports the same results displayed in the paper, but includes the percentage of Correct translations for both challenge sets as well as the percentage of errors made from sentences that, after the injection of the adversarial adjectives, were translated to a sense that wasn't either the correct one nor the one targeted by the adversarial injection (i.e., other).","Modify,Grammar",Grammar
2210,200-ARR,200-ARR_v2_96@0,200-ARR_v1_87@0,"1. Due to limited computational budget and the large number of resources required to train and fine-tune NMT models from scratch, we had to limit ourselves to one run per experiment, though, despite this, the consistency across languages seems to point to the empirical correctness of the claims.","1. Due to limited computational budget and the high number of resources required to train and fine-tune NMT models from scratch, we had to limit ourselves to one run per experiment, though the consistency across languages seems to point to the empirical correctness of the claims.","Modify,Clarity",Clarity
2211,200-ARR,200-ARR_v2_97@0,200-ARR_v1_88@0,2. We evaluated the bias reduction explicitly only on the English→German language pair.,2. We evaluate the bias reduction explicitly only on the English→German language pair.,"Modify,Grammar",Grammar
2212,200-ARR,200-ARR_v2_73@0,200-ARR_v1_89@0,"In Table 3, we report some examples of disambiguation corrected by our model according to the WSD Bias Challenge Set.",Table 5 shows some examples of disambiguations corrected by our model according to the WSD Bias challenge set.,"Modify,Clarity",Clarity
2213,200-ARR,200-ARR_v2_2@1,200-ARR_v1_2@1,"In this paper, we first provide a novel approach for automatically creating high-precision sense-annotated parallel corpora, and then put forward a specifically tailored fine-tuning strategy for exploiting these sense annotations during training without introducing any additional requirement at inference time.","In this paper, we first provide a novel approach for automatically creating highprecision sense-annotated parallel corpora, and then we put forward a specifically tailored finetuning strategy to exploit such sense annotations during training without introducing any additional requirement at inference time.","Modify,Grammar",Grammar
2214,200-ARR,200-ARR_v2_11@0,200-ARR_v1_11@0,4. We present a case study on how a state-of-theart WSD system compares to an NMT model on disambiguating words within a challenging set for detecting sense bias in MT.,4. We present a case study on how a state-of-theart WSD system compares to a NMT model on disambiguating words within a challenging set for detecting sense bias in MT.,"Modify,Grammar",Grammar
2215,200-ARR,200-ARR_v2_12@0,200-ARR_v1_12@0,"We make all the generated datasets, the code of the model and for the experiments available at https://github.com/sapienzanlp/ reducing-wsd-bias-in-nmt.","We make all the generated datasets, the code of the model and for the experiments available at ANONYMOUS_URL.","Modify,Fact/Evidence",Fact/Evidence
2216,200-ARR,200-ARR_v2_14@0,200-ARR_v1_14@0,Word Sense Disambiguation was first formulated as a computational task by Weaver (1949) in the context of Machine Translation.,Word Sense Disambiguation has been first formulated as a computational task by Weaver (1949) in the context of Machine Translation.,"Modify,Grammar",Grammar
2217,200-ARR,200-ARR_v2_14@1,200-ARR_v1_14@1,"The two fields then followed parallel paths, with more or less successful attempts over the years to join them back together (Carpuat and Wu, 2005;Vickrey et al., 2005;Carpuat and Wu, 2007).","The two fields then followed parallel paths, with more or less successful attempts over the years to try joining them back together (Carpuat and Wu, 2005;Vickrey et al., 2005;Carpuat and Wu, 2007).","Modify,Clarity",Clarity
2218,200-ARR,200-ARR_v2_14@3,200-ARR_v1_14@3,"More recently, Pu et al. (2018a) and Nguyen et al. (2018) proposed systems that successfully leverage sense information in NMT models, although they introduced a heavy requirement, i.e., that of disambiguating the ambiguous words in the sentence prior to generating a translation, which makes them unfeasible in many real-world settings.","More recently, Pu et al. (2018) and Nguyen et al. (2018) proposed systems that successfully leverage sense information in NMT models, although they introduce a heavy requirement, i.e., that of disambiguating the ambiguous words in the sentence prior to generating a translation, which makes them unfeasible in many realworld settings.","Modify,Fact/Evidence",Fact/Evidence
2219,200-ARR,200-ARR_v2_14@4,200-ARR_v1_14@4,"Lately, contextualized word embeddings have been employed to produce additional back-translated parallel training data via mining sense-specific target sentences, in order to improve handling of infrequent senses (Hangya et al., 2021).","Furthermore, contextualized word embeddings have been employed to produce additional back-translated parallel training data via mining sense-specific target sentences, to improve handling of infrequent senses (Hangya et al., 2021).","Modify,Clarity",Clarity
2220,200-ARR,200-ARR_v2_15@0,200-ARR_v1_15@0,"Nevertheless, the proper treatment of lexical ambiguity is still an open problem, with neural models struggling to translate least frequent senses and often relying on spurious correlations among words (Emelin et al., 2020;Raganato et al., 2019;Rios Gonzales et al., 2017).","Nevertheless, the proper treatment of lexical ambiguity is still an open problem, with neural models struggling to translate least frequent senses and often relying on spurious correlations among words (Emelin et al., 2020;Raganato et al., 2019;Gonzales et al., 2017).","Modify,Fact/Evidence",Fact/Evidence
2221,200-ARR,200-ARR_v2_15@1,200-ARR_v1_15@1,"Thus, the disambiguation bias topic has received renewed interest, and several benchmarks have been introduced in the most recent years with the goal of directly measuring the extent to which neural architectures are able to capture word semantics.","Thus, the disambiguation bias topic received a renewed interest, and several benchmarks have been introduced in the most recent years with the goal of directly measuring the extent to which neural architectures are able to capture word semantics.","Modify,Grammar",Grammar
2222,200-ARR,200-ARR_v2_15@2,200-ARR_v1_15@2,"One of the first of this kind was ContraWSD (Rios Gonzales et al., 2017).","One of the first of this kind has been ContraWSD (Gonzales et al., 2017).","Modify,Fact/Evidence",Fact/Evidence
2223,200-ARR,200-ARR_v2_15@3,200-ARR_v1_15@3,"In this first attempt to evaluate WSD capabilities of NMT models, the authors built an adversarial test set where source sentences containing an ambiguous word were associated with a correct translation and several incorrect alternatives.","In this first attempt to evaluate WSD capabilities of NMT models, the authors built an adversarial test set where source sentences containing an ambiguous word are associated with a correct translation and several incorrect alternatives.","Modify,Grammar",Grammar
2224,200-ARR,200-ARR_v2_15@4,200-ARR_v1_15@4,These latter were built by replacing the reference translation for the ambiguous word with the translation of one of its other possible meanings.,These latter are built by replacing the reference translation for the ambiguous word with the translation of one of its other possible meanings.,"Modify,Grammar",Grammar
2225,200-ARR,200-ARR_v2_15@5,200-ARR_v1_15@5,"The task measured whether a model ranked the correct translation higher, i.e., it assigned it a higher probability than the adversarial ones.","The task measures whether a model ranks the correct translation higher, i.e., it assigns a higher probability, than the adversarial ones.","Modify,Grammar",Grammar
2226,200-ARR,200-ARR_v2_15@6,200-ARR_v1_15@6,"This study provided evaluation data for two language pairs only, i.e., German→English and German→French, and within a few years it became outdated as modern NMT models could easily attain high performances (Emelin et al., 2019).","This work provides evaluation data for two language pairs only, i.e., German→English and German→French, and it is now outdated as modern NMT models can easily attain high performances (Emelin et al., 2019).","Modify,Grammar",Grammar
2227,200-ARR,200-ARR_v2_15@7,200-ARR_v1_15@7,"Thus, MuCoW (Raganato et al., 2019) took things a step further and leveraged BabelNet (Navigli and Ponzetto, 2012;) -a large multilingual knowledge base -and sense embeddings (Camacho-Collados et al., 2016;Mancini et al., 2017) in order to automatically create adversarial translations for five language pairs while also increasing the difficulty of the task itself; however, the fully automatic nature of these challenge sets made them noisy and prone to containing irrelevant challenge samples.","Thus, MuCoW (Raganato et al., 2019) took a step further and leveraged BabelNet (Navigli and Ponzetto, 2012) -a large multilingual knowledge base -and sense embeddings (Camacho-Collados et al., 2016;Mancini et al., 2017) to automatically create adversarial translations for five language pairs while also increasing the difficulty of the task itself; unfortunately, the fully automatic nature of these challenge sets makes them noisy and prone to contain irrelevant challenge samples.","Modify,Clarity",Clarity
2228,200-ARR,200-ARR_v2_16@0,200-ARR_v1_15@8,"More recently, Emelin et al. (2020) proposed two challenge sets for the English→German pair, one measuring the model sensitivity to most frequent senses and the other estimating, through adversarial injections, its susceptibility to changing a correct sense to a wrong one.","Recently, Emelin et al. (2020) proposed two challenge sets for the English→German pair, one measuring the model sensitivity to most frequent senses while the other estimating, through adversarial injections, the susceptibility to changing a correct sense to a wrong one.","Modify,Clarity",Clarity
2229,200-ARR,200-ARR_v2_16@1,200-ARR_v1_15@9,"In contrast to previous studies, these challenge sets were based on correlations among words in the training set and relied on manually-refined sense clusters, providing an excellent test bed for measuring semantic bias.","Contrarily to previous works, these challenge sets are based on correlations among words in the training set and rely on manually-refined sense clusters, making them a great test bed for measuring disambiguation bias.","Modify,Fact/Evidence",Fact/Evidence
2230,200-ARR,200-ARR_v2_18@0,200-ARR_v1_16@0,"Despite all the effort made in putting forward challenging sets of data to test WSD capabilities of NMT models, to the best of our knowledge, only a few approaches (Rios Gonzales et al., 2017;Liu et al., 2018) have been proposed to mitigate this issue, and none of these is effective with modern Transformer-based architectures.","Despite the effort in putting forward challenging sets of data to test WSD capabilities of NMT models, to the best of our knowledge, only a few approaches (Gonzales et al., 2017;Liu et al., 2018) have been proposed to mitigate this issue, and none of them are effective with modern Transformerbased architectures.","Modify,Fact/Evidence",Fact/Evidence
2231,200-ARR,200-ARR_v2_18@1,200-ARR_v1_16@1,"Furthermore, while parallel corpora have been exploited to produce sense annotations in the past (Bonansinga and Bond, 2016;Delli Bovi et al., 2017), they were built by utilizing outdated disambiguation approaches that have recently been surpassed by more advanced neural architectures.","Furthermore, while parallel corpora have been exploited to produce sense annotations in the past (Bonansinga and Bond, 2016;Delli Bovi et al., 2017), they have been built by utilizing outdated disambiguation approaches that have been recently surpassed by more advanced neural architectures.","Modify,Grammar",Grammar
2232,200-ARR,200-ARR_v2_19@0,200-ARR_v1_17@0,"Thus, differently from previous studies in the literature, we focus on closing the gap between these two fields, i.e., Neural Machine Translation and Word Sense Disambiguation, by putting the recent advances in WSD at the service of NMT models.","Thus, differently from previous works in the literature, we focus on closing the gap between these two fields, i.e., Neural Machine Translation and Word Sense Disambiguation, by putting the recent advances in WSD at the service of NMT models.","Modify,Clarity",Clarity
2233,202-ARR,,202-ARR_v1_6@0,,"Letters to Santa (Polish: Listy do M.), alternatively known as Letters to St. Nicholas, is a 2011 Polish-language romantic comedy film, directed by the director Mitja Okorn.","Delete,Fact/Evidence",Fact/Evidence
2234,202-ARR,,202-ARR_v1_6@1,,"The action takes place during one single Christmas Eve, when a few adults find the loves of their lives.","Delete,Fact/Evidence",Fact/Evidence
2235,202-ARR,,202-ARR_v1_88@1,,"As we can see in the tables, a few lexical variants of entities and fact-level paraphrasing are presented across questions and passages, which can be interpreted as factual evidence for OpenQA passage matching.","Delete,Fact/Evidence",Fact/Evidence
2236,202-ARR,202-ARR_v2_19@7,,"Different to these studies, our method focuses on a more general setting where the retriever is only trained with the naturally occurring web documents, and has no access to any downstream datasets.",,"Add,Fact/Evidence",Fact/Evidence
2237,202-ARR,202-ARR_v2_67@4,,"The results of our study are shown in Table 5 which reveals that HLP consistently outperforms others methods, with up to a 11-point improvement on top-5 retrieval accuracy of bridge questions.",,"Add,Fact/Evidence",Fact/Evidence
2238,202-ARR,202-ARR_v2_67@5,,"Furthermore, WLP yields a 4-point advantages in average over ICT and BFS on bridge questions, showing that document-wise relevance contributes to better associative abilities.",,"Add,Fact/Evidence",Fact/Evidence
2239,202-ARR,202-ARR_v2_76@0,,Conclusion,,"Add,Other",Other
2240,202-ARR,202-ARR_v2_77@0,,"This paper proposes Hyperlink-induced Pretraining (HLP), a pre-training method for OpenQA passage retrieval by leveraging the online textual relevance induced by hyperlink-based topology.",,"Add,Claim",Claim
2241,202-ARR,202-ARR_v2_77@1,,"Our experiments show that HLP gains significant improvements across multiple QA datasets under different scenarios, consistently outperforming other pre-training methods.",,"Add,Fact/Evidence",Fact/Evidence
2242,202-ARR,202-ARR_v2_77@2,,Our method provides insights into OpenQA passage retrieval by analyzing the underlying bi-text relevance.,,"Add,Claim",Claim
2243,202-ARR,202-ARR_v2_77@3,,Future work involves addressing tasks like MS MARCO where the granularity of the information-seeking target is at the passage level.,,"Add,Claim",Claim
2244,202-ARR,202-ARR_v2_28@0,202-ARR_v1_29@0,"The rationale behind this is that both the natural question and the Wikipedia document are intended to describe related facts and events regarding a targeted object, whereas the object is an answer for a question but a topical entity for a Wikipedia document.","The rationale behind this is that both the natural question and the Wikipedia document are intended to describe related facts and events regarding a targeted object, whereas the object is an answer for a question but a topic for a Wikipedia document.","Modify,Clarity",Clarity
2245,202-ARR,202-ARR_v2_2@5,202-ARR_v1_2@5,The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by more than 10 points in terms of top-20 retrieval accuracy under the zero-shot scenario.,The experiments show our HLP outperforms the BM25 by up to 7 points as well as other pre-training methods by up to 30 points in terms of top-20 retrieval accuracy under the zero-shot scenario.,"Modify,Fact/Evidence",Fact/Evidence
2246,202-ARR,202-ARR_v2_65@1,202-ARR_v1_66@1,"Specifically, we fine-tune the pre-trained models on large datasets (NQ, Triv-iaQA) with m (m ∈ {16, 256, 1024}) samples and present the few-shot retrieval results in Table 2.","Specifically, we fine-tune the pre-trained models on large datasets (NQ, Triv-iaQA) with m (m = {16, 256, 1024}) samples and present the few-shot retrieval results in Table 2.","Modify,Grammar",Grammar
2247,202-ARR,202-ARR_v2_65@2,202-ARR_v1_66@2,"With only a few hundred labeled data for fine-tuning, all the models with intermediate pretraining perform better than those without, and HLP outperforms the others by a larger margin when m is smaller.","With only a few hundred labeled data for fine-tuning, all the models with intermediate pre-training perform better than that without, and HLP outperforms the other methods by a larger margin when m is smaller.","Modify,Grammar",Grammar
2248,202-ARR,202-ARR_v2_65@3,202-ARR_v1_66@3,"Moreover, among three reimplemented baselines, WLP gains the largest improvement with increasing number of samples, outperforming ICT and BFS when a thousand labelled samples are provided for fine-tuning.","Among three reimplemented baselines, WLP gains the largest improvement with increasing number of samples, outperforming ICT and BFS when a thousand labelled samples are provided for fine-tuning.","Modify,Clarity",Clarity
2249,202-ARR,202-ARR_v2_0@0,202-ARR_v1_0@0,Hyperlink-induced Pre-training for Passage Retrieval in Open-domain Question Answering,Hyperlink-induced Pre-training for Passage Retrieval of Open-domain Question Answering,"Modify,Grammar",Grammar
2250,202-ARR,202-ARR_v2_78@0,202-ARR_v1_77@0,"For the pre-training, all models we reproduced are trained with 20 million Q-P pairs.","For the pre-training, all models including our reproduced baselines are trained with 20 million Q-P pairs with in-batch negative sampling.","Modify,Clarity",Clarity
2251,202-ARR,202-ARR_v2_79@0,202-ARR_v1_78@0,We discuss how we conduct data analysis to determine the hyperlink-based topology.,"In this part, we detailedly discuss how we conduct exploratory data analysis on NQ training set to determine the hyperlink-based topology.","Modify,Clarity",Clarity
2252,202-ARR,202-ARR_v2_79@1,202-ARR_v1_78@1,"Driven by a strong interest in what roles the Q-P overlapping spans play, we conduct exploratory data analysis on the widely-used NQ dataset.","Driven by a strong interest in what kind of roles the overlapping spans play between the queries q and passages p, we conduct exploratory data analysis on the widelyused NQ dataset.","Modify,Clarity",Clarity
2253,202-ARR,202-ARR_v2_79@2,202-ARR_v1_78@2,"Specifically, we extract all entities and mentions from the Q-P pairs using TagMe (Ferragina and Scaiella, 2010) for further investigation.","Specifically, we recognize all entities and mentions from the queries and the passages using TagMe (Ferragina and Scaiella, 2010) for further investigation.","Modify,Clarity",Clarity
2254,202-ARR,202-ARR_v2_79@3,202-ARR_v1_78@3,We observe about 55% queries q either explicitly mentions the titles of p or successfully links to the document via TagMe.,"As a result, we observe about 55% queries q either explicitly mentions the titles of p or the successfully links to the document where p originated via TagMe, which motivates us to construct the dual-link topology where the pseudo queries q mention p via a hypertext.","Modify,Clarity",Clarity
2255,202-ARR,202-ARR_v2_79@4,202-ARR_v1_78@3,This observation motivates us to construct the dual-link topology where the pseudo queries q mention p via a hypertext.,"As a result, we observe about 55% queries q either explicitly mentions the titles of p or the successfully links to the document where p originated via TagMe, which motivates us to construct the dual-link topology where the pseudo queries q mention p via a hypertext.","Split+Modify,Clarity",Clarity
2256,202-ARR,202-ARR_v2_79@5,202-ARR_v1_78@4,"Moreover, we observe about 45% queries q do not mention the titles of q but instead they share the same mentions.","Moreover, we observe about 45% queries do not mention title of q but share the same mentions with p which encourages us to adopt the co-mention topology where the pseudo q and p both mention a third-party document through hypertext.","Split+Modify,Clarity",Clarity
2257,202-ARR,202-ARR_v2_79@6,202-ARR_v1_78@4,This encourages us to adopt the co-mention topology where the pseudo q and p both mention a third-party document through hypertext.,"Moreover, we observe about 45% queries do not mention title of q but share the same mentions with p which encourages us to adopt the co-mention topology where the pseudo q and p both mention a third-party document through hypertext.","Split+Modify,Clarity",Clarity
2258,202-ARR,202-ARR_v2_82@0,202-ARR_v1_79@0,"Intuitively, we assume any mentioned entity, let's say e Y mentioned in a Wikipedia document X, is used to describe the topical entity e X of this document.","Intuitively, we assume the mentioned entity, let's say e Y mentioned in a Wikipedia document X, is used to describe the topical entity e X of this document.","Modify,Clarity",Clarity
2259,202-ARR,202-ARR_v2_82@1,202-ARR_v1_79@1,"In other words, e Y is likely to attend in a topically relevant fact or event related to e X , which can be represented as a triple <e X , r XY , e Y > where r XY is a latent relation between e X and e Y .","In other words, e Y is likely to attend in a topically relevant fact or event, which can be represented as a triple <e X , r XY , e Y > where r XY is a latent relation between e X and e Y .","Modify,Fact/Evidence",Fact/Evidence
2260,202-ARR,202-ARR_v2_82@2,202-ARR_v1_80@0,"Given any passage pair (q, p) from Wikipedia, we consider q and p have fact-level evidence if they both entail a fact that can be represented as a triple, let's say <e X , r XY , e Y >.","Given any passage pair (q, p) from Wikipedia, we call q and p have fact-level evidence if they both entail a fact that can be represented as a triple <e X , r XY , e Y > where e X , e Y are entities and r XY is their corresponding relations.","Modify,Clarity",Clarity
2261,202-ARR,202-ARR_v2_82@3,202-ARR_v1_80@1,"Further, if both passages q and p contain representative hypertext or topic of e X and e Y , we consider such fact-level evidence can be induced by hyperlink-based topology, namely hyperlink-induced fact.","Further, if both passages q and p contain representative hypertext or topic of e X and e Y , we say this fact-level evidence can be induced by hyperlink-based topology, namely hyperlink-induced fact.","Modify,Clarity",Clarity
2262,202-ARR,202-ARR_v2_82@4,202-ARR_v1_80@2,Below we show that any Q-P pair with hyperlink-induced fact while satisfying answer containing is within either DL or CM hyperlink-based topology.,"In this session, we prove that any Q-P pair with hyperlink-induced fact while satisfying answer containing is within either DL or CM hyperlink-based topology.","Modify,Clarity",Clarity
2263,202-ARR,202-ARR_v2_83@0,202-ARR_v1_81@0,"Following the example above, given q and p containing a factual triple <e X , r XY , e Y >, we have facts <e Q , r QX , e X >, <e Q , r QY , e Y > at q-side while <e P , r P X , e X >, <e P , r P Y , e Y > at p-side.","Following the example above, both q and p contain a factual triple <e X , r XY , e Y >.","Merge+Modify,Clarity",Clarity
2264,202-ARR,202-ARR_v2_83@0,202-ARR_v1_81@1,"Following the example above, given q and p containing a factual triple <e X , r XY , e Y >, we have facts <e Q , r QX , e X >, <e Q , r QY , e Y > at q-side while <e P , r P X , e X >, <e P , r P Y , e Y > at p-side.","Since mentioned entities are used to describe the topical entity, we have facts <e Q , r QX , e X >, <e Q , r QY , e Y > at q-side while <e P , r P X , e X >, <e P , r P Y , e Y > at p-side.","Merge+Modify,Clarity",Clarity
2265,202-ARR,202-ARR_v2_83@1,202-ARR_v1_81@2,"Further, p entails <e P , r P Q , e Q > because of the answer containing property.","Further, p contains <e P , r P Q , e Q > because of the answer containing condition.","Modify,Clarity",Clarity
2266,202-ARR,202-ARR_v2_86@0,202-ARR_v1_86@0,We evaluate HLP on multi-hop scenario where knowledge from different documents need to be associated.,We evaluate HLP on multi-hop scenario where knowledge from different documents need to be associated for retrieval.,"Modify,Clarity",Clarity
2267,202-ARR,202-ARR_v2_86@2,202-ARR_v1_86@2,"In Table 8, a complex question is proposed, requiring the retriever firstly to retrieve the document ""Apple Remote"" and then ""Front Row (software)"".","In Table 8, a complex question is proposed, requiring the retriever firstly to retrieve the document ""Apple Remote"" and then ""Front Row (software)"" to fetch the final answer.","Modify,Clarity",Clarity
2268,202-ARR,202-ARR_v2_86@3,202-ARR_v1_87@0,HLP successfully retrieves both golds in the top-10 retrieved passages while the vanilla DPR fails.,Our HLP successfully retrieves both golds in the top-10 retrieved passages while the vanilla DPR fails.,"Modify,Clarity",Clarity
2269,202-ARR,202-ARR_v2_86@4,202-ARR_v1_87@1,"We find 6 items retrieved by HLP are related to the brand ""Apple"" while 4 by DPR, which indicates stronger comprehension and associative ability of HLP.","We find 6 items retrieved by HIS are related to the brand ""Apple"" while 4 are by DPR, showing stronger comprehension and associative ability from HLP.","Modify,Grammar",Grammar
2270,202-ARR,202-ARR_v2_87@0,202-ARR_v1_88@0,We present case studies on the constructed HLP Q-P pairs in Table 9 and Table 10.,"Besides human evaluation, we present case studies on HLP Q-P pairs, which is shown in Table 9 and Table 10.","Modify,Clarity",Clarity
2271,202-ARR,202-ARR_v2_12@1,202-ARR_v1_14@1,"However, these pre-training tasks construct relevance signals largely depending on easily attainable sentence-level or document-level contextual relationships.","However, these pre-training tasks construct relevance signals largely depending on easily achieving sentence-level or document-level contextual relationships.","Modify,Clarity",Clarity
2272,202-ARR,202-ARR_v2_2@4,202-ARR_v1_2@4,"We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zero-shot, few-shot, multihop, and out-of-domain scenarios.","We investigate the effectiveness of our approach across a wide range of open-domain QA datasets under zeroshot, few-shot, multi-hop, and out-of-domain scenarios.","Modify,Grammar",Grammar
2273,203-ARR,203-ARR_v2_6@2,,"It has to be noted however, that this only works across languages with similar types of phonemes.",,"Add,Claim",Claim
2274,203-ARR,203-ARR_v2_17@3,203-ARR_v1_17@3,Other variants are described in Antoniou et al. (2019); Rajeswaran et al. (2019).,Other variants are described in Antoniou et al. (2018); Rajeswaran et al. (2019).,"Modify,Fact/Evidence",Fact/Evidence
2275,203-ARR,203-ARR_v2_20@4,203-ARR_v1_20@4,"In comparison to the fine-tuning of a simple single speaker model, we found training and fine-tuning a model conditioned on language embeddings and speaker embeddings much more sensitive to the choice of hyperparameters.","In comparison to the fine-tuning of a simple single speaker model, we found training and fine-tuning a model conditioned on language embeddings and speaker embeddings much more difficult to train and much more sensitive to the choice of hyperparameters.","Modify,Claim",Claim
2276,203-ARR,203-ARR_v2_25@1,203-ARR_v1_23@1,It comes with an open-source tool 2 which we use to convert phonemes into numeric vectors.,It comes with an open-source tool 2 which we use to get numeric vectors for a given phoneme.,"Modify,Clarity",Clarity
2277,203-ARR,203-ARR_v2_25@2,203-ARR_v1_23@2,"Each vector encodes one feature per dimension and takes the value of either -1, 0 or 1, putting the features on a scale wherever meaningful.","The vector encodes one feature per dimension and takes the value of either -1, 0 or 1, putting the features on a scale wherever meaningful.","Modify,Clarity",Clarity
2278,203-ARR,203-ARR_v2_25@3,203-ARR_v1_23@3,"This featureset also includes phonological features which go beyond simple phonetics, such as whether a phoneme is syllabic.","This featureset also includes some phonological features which go beyond simple phonetics, such as whether a phoneme is syllabic.","Modify,Clarity",Clarity
2279,203-ARR,203-ARR_v2_28@1,203-ARR_v1_26@1,The inner loop needs hundreds of updates in order to make a significant change to the performance of the task specific model.,The inner loop needs many updates in order to make a significant change to the performance of the task specific model.,"Modify,Clarity",Clarity
2280,203-ARR,203-ARR_v2_29@1,203-ARR_v1_27@1,"We then sum up the losses, backpropagate and update the Meta Model directly using Adam (Kingma and Ba, 2015).","We then sum up the losses, backpropagate and update the Meta Model directly using Adam (Kingma and Ba, 2017).","Modify,Fact/Evidence",Fact/Evidence
2281,203-ARR,203-ARR_v2_43@1,203-ARR_v1_41@1,"The embedding functions are each trained for 3000 epochs using Adam (Kingma and Ba, 2015) with a batchsize of 32.","The embedding functions are each trained for 3000 epochs using Adam (Kingma and Ba, 2017) with a batchsize of 32.","Modify,Fact/Evidence",Fact/Evidence
2282,203-ARR,203-ARR_v2_5@2,203-ARR_v1_5@2,Attempts at reducing the required resources in a target language by making use of transfer learning from multilingual data have been made by Azizah et al. (2020); ; Chen et al. (2019).,Attempts at reducing the required resources in a target language by making use of transfer learning from multilingual data have been made by Azizah et al. (2020); ; Tu et al. (2019).,"Modify,Fact/Evidence",Fact/Evidence
2283,203-ARR,203-ARR_v2_48@0,203-ARR_v1_46@0,"In order to investigate the effectiveness of our proposed LAML procedure, we train a Tacotron 2 model and a FastSpeech 2 model on the full Karlsson dataset as a strong baseline.","In order to investigate the effectiveness of our proposed language agnostic meta learning procedure, we train a Tacotron 2 model and a FastSpeech 2 model on the full Karlsson dataset as a strong baseline.","Modify,Clarity",Clarity
2284,203-ARR,203-ARR_v2_50@3,203-ARR_v1_48@3,"By the time the model learned to speak in the new speaker's voice, it had overfitted the 30 minutes of training data and collapsed, producing no more intelligible speech.","By the time the model learned to speak in the new speakers voice, it had overfitted the 30 minutes of training data and collapsed, producing no more intelligible speech.","Modify,Grammar",Grammar
2285,203-ARR,203-ARR_v2_50@5,203-ARR_v1_48@5,"Both the articulatory features, as well as the LAML pretraining seem necessary to achieve cross-lingual fine-tuning on low-resource data.","Both the articulatory features, as well as the meta learning procedure seem necessary to achieve cross-lingual fine-tuning on low-resource data.","Modify,Claim",Claim
2286,203-ARR,203-ARR_v2_58@1,203-ARR_v1_55@1,Each participant is shown 12 phonetically balanced samples produced by the Tacotron 2 and FastSpeech 2 models.,Each participant is shown multiple phonetically balanced samples produced by the Tacotron 2 and FastSpeech 2 models.,"Modify,Fact/Evidence",Fact/Evidence
2287,203-ARR,203-ARR_v2_59@5,203-ARR_v1_56@5,"In 56% of the cases, the model finetuned on 30 minutes of data was perceived to be as good or better than the model trained on 29 hours.","In 56% of the cases, the model finetuned on 30 minutes of data was perceived to be as good or better than the model trained on 29 hours from scratch.","Modify,Clarity",Clarity
2288,203-ARR,203-ARR_v2_60@1,203-ARR_v1_57@1,Training the Tacotron Baseline took 2 days.,Training time of the Tacotron Baseline was 2 days.,"Modify,Clarity",Clarity
2289,203-ARR,203-ARR_v2_60@4,203-ARR_v1_57@4,The HiFi-GAN vocoder used to generate all samples took 4 days to train and was not fine-tuned on the unseen data.,The HiFi-GAN vocoder used for the samples in the study and in our own preliminary subjective evaluation took 4 days to train and was not fine-tuned on the unseen data.,"Modify,Fact/Evidence",Fact/Evidence
2290,203-ARR,203-ARR_v2_60@5,203-ARR_v1_57@5,"We did not perform hyperparameter searches and used the suggested default settings for all methods, which worked sufficiently well, but could surely be improved.","We did not perform hyperparameter searches and stuck with the suggested default settings for all methods unless specified otherwise, which worked sufficiently well, but could surely be improve.","Modify,Clarity",Clarity
2291,203-ARR,203-ARR_v2_62@1,203-ARR_v1_59@1,"The speaker embedding is built according to the ECAPA-TDNN architecture (Desplanques et al., 2020) and provided open source by SpeechBrain (Ravanelli et al., 2021).","The speaker embedding is built according to the ECAPA-TDNN architecture (Desplanques et al., 2020) and provided open source by Speechbrain (Ravanelli et al., 2021).","Modify,Grammar",Grammar
2292,203-ARR,203-ARR_v2_62@2,203-ARR_v1_59@2,"It is trained on VoxCeleb 1 and 2 (Nagrani et al., 2017(Nagrani et al., , 2019Chung et al., 2018) which to the best of our knowledge does not overlap with any of the other training and evaluation data we used.","It is trained on Voxceleb 1 and 2 (Nagrani et al., 2017(Nagrani et al., , 2019Chung et al., 2018) which to the best of our knowledge does not overlap with any of the other training and evaluation data we used.","Modify,Grammar",Grammar
2293,203-ARR,203-ARR_v2_66@1,203-ARR_v1_62@1,One limitation to our findings is that we investigated only the transfer of languages that share similar phoneme inventories.,One limitation to our findings is that we investigated only the transfer of languages that are related.,"Modify,Fact/Evidence",Fact/Evidence
2294,203-ARR,203-ARR_v2_6@0,203-ARR_v1_6@0,"Using articulatory features as inputs for neural TTS has been attempted recently by Staib et al. (2020) and Wells et al. (2021), following the classical approach of Jakobson et al. (1961).","Using articulatory features as inputs for neural TTS has been attempted recently by Staib et al. (2020) and Wells et al. (2021), following the classical approach of Jakobson et al. (1951).","Modify,Fact/Evidence",Fact/Evidence
2295,203-ARR,203-ARR_v2_6@3,203-ARR_v1_6@2,Also Gutkin (2017) have applied phonological features to low-resource TTS with fair success.,"Also (Gutkin, 2017) have applied phonological features to low-resource TTS with fair success.","Modify,Grammar",Grammar
2309,209-ARR,209-ARR_v2_7@3,,"Similarly reported in the many-to-many training with zero-shot setup (Gu et al., 2019;Yang et al., 2021b), the complete MNMT model also suffers from capturing correlations in the data for all the X-Y directions as one model training, due to highly imbalanced data.",,"Add,Fact/Evidence",Fact/Evidence
2310,209-ARR,209-ARR_v2_14@1,,"The parallel sentences are provided among English (en), five Central and East European languages of {Croatian (hr), Hungarian (hu), Estonian (et), Serbian (sr), Macedonian (mk)} for the task 1, and five Southeast Asian languages of {Javanese (jv), Indonesian (id), Malay (ms), Tagalog (tl), Tamil (ta)} for the task 2.",,"Add,Fact/Evidence",Fact/Evidence
2311,209-ARR,209-ARR_v2_14@2,,"We removed sentence pairs either of whose sides is an empty line, and eventually collected the data with (Englishcentric, Non-English-centric)=(321M, 651M) sentence pairs in total.",,"Add,Fact/Evidence",Fact/Evidence
2312,209-ARR,,209-ARR_v1_5@3,,"The model suffers from handling many diverse languages, in contrast to successful manyto-one translation (Johnson et al., 2017).","Delete,Fact/Evidence",Fact/Evidence
2313,209-ARR,209-ARR_v2_14@9,,All the multilingual systems including many-to-one baselines and the proposed model are 12E6D.,,"Add,Fact/Evidence",Fact/Evidence
2314,209-ARR,209-ARR_v2_14@10,,"Note that the ""Pivot-based"" system for manyto-English directions is identical to ""Bilingual"".",,"Add,Claim",Claim
2315,209-ARR,209-ARR_v2_17@2,,"In Table 1, we present the average sacreBLEU scores for many-to-L directions, showing that our proposed approach successfully achieved the best performance in most targeted languages.",,"Add,Fact/Evidence",Fact/Evidence
2316,209-ARR,209-ARR_v2_17@3,,"Compared to the many-to-one multilingual baselines, the proposed approach of utilizing the complete MNMT model transfers multilingual representations more effectively to the targeted translation directions, as the L-centric data size are smaller.",,"Add,Claim",Claim
2317,209-ARR,209-ARR_v2_17@4,,"We also note that the winning system of the shared task achieved (task1, task2)=(37.6, 33.9) BLEU with a 36-layer encoder and 12-layer decoder model (Yang et al., 2021a) that is pretrained on extra language data including parallel and monolingual data, while our best system with a 24-layer encoder and 12-layer decoder obtained (task1, task2)=(25.7, 22.8) sacreBLEU, without using those extra data.",,"Add,Fact/Evidence",Fact/Evidence
2318,209-ARR,209-ARR_v2_21@1,209-ARR_v1_19@1,"To investigate the usefulness of the multi-centric data training, we pretrain our Transformer models with deeper 24-12 layers described in Section 3, on the English-centric data and the L-centric data (L={en,de,fr}), individually.","To investigate the usefulness of the multi-centric data training, we pretrain Transformer Big models with deeper 24-12 layers on the English-centric data and the L-centric data (L={en,de,fr}), individually.","Modify,Fact/Evidence",Fact/Evidence
2319,209-ARR,209-ARR_v2_23@2,209-ARR_v1_20@2,"Recent studies (Kasai et al., 2021;Hsu et al., 2020;Li et al., 2021) have experimentally shown that models with a deep encoder and a shallow decoder can address the issue, without losing much performance.","Recent studies (Kasai et al., 2020;Hsu et al., 2020;Li et al., 2021) have experimentally shown that models with a deep encoder and a shallow decoder can address the the issue, without losing much performance.","Modify,Fact/Evidence",Fact/Evidence
2320,209-ARR,209-ARR_v2_23@4,209-ARR_v1_20@4,"To examine the light NMT model architecture, we train the Transformer base architecture modified with 9-3 layers (E9D3) in a bilingual setting and compare it with a standard Transformer base model, with 6-6 layers (E6D6), as a baseline.","To examine the light MNMT model architecture, we train the Transformer Base architecture modified with 9-3 layers (E9D3) in a bilingual setting and compare it with a standard Transformer Base model, with 6-6 layers (E6D6), as a baseline.","Modify,Grammar",Grammar
2321,209-ARR,209-ARR_v2_23@5,209-ARR_v1_20@5,"Additionally, we also report direct X-Y translation performance, when distilling the best large-scale MNMT models alongside the light NMT models as a student model.","Additionally, we also report direct XY translation performance, when distilling the best large-scale models alongside the light MNMT models as a student model.","Modify,Fact/Evidence",Fact/Evidence
2322,209-ARR,209-ARR_v2_23@6,209-ARR_v1_20@6,"More specifically, following Kim and Rush (2016), we train light NMT student models (E9D3) that serve many-to-L translations (L={de, fr, es, it, pl}).","More specifically, following Kim and Rush (2016), we train five light MNMT student models (E9D3) that serve many-to-L translations (L={de, fr, es,it,pl}).","Modify,Fact/Evidence",Fact/Evidence
2323,209-ARR,209-ARR_v2_24@1,209-ARR_v1_21@1,"For the xx-{de,fr} directions, the proposed finetuning helps both English-centric and multi-centric pretrained models to improve the accuracy.","For the xx-{de,fr} directions, the proposed finetuning helps both English-centric and multi-centtric pretrained models to improve the accuracy.","Modify,Grammar",Grammar
2324,209-ARR,209-ARR_v2_24@2,209-ARR_v1_21@2,"Overall, the finetuned multi-centric models achieved the best, largely outperforming the English pivot-based baselines by +2.6 and +2.8 points.","Over- all, the finetuned multi-centric models achieved the best, largely outperforming the English pivotbased baselines by +2.6 and +2.8 points.","Modify,Grammar",Grammar
2325,209-ARR,209-ARR_v2_24@3,209-ARR_v1_21@3,"For the comparison among the multilingual systems, the multi-centric model without finetuning already surpasses the finetuned English-centric systems with a large margin of +0.9 and +0.8 points for both xx-{de,fr} directions.",The multicentric models surpass the corresponding finetuned English-centric systems with a large margin of +0.9 and +0.8 points.,"Modify,Fact/Evidence",Fact/Evidence
2326,209-ARR,209-ARR_v2_24@5,209-ARR_v1_21@5,"For the xx-{es,it,pl} directions 1 , the fineutned multi-centric systems gain similar accuracy improvement, averagely outperforming the conventional pivot-based baselines.","For the xx-{es,it,pl} directions 4 , each finetuned system gains similar accuracy improvement, significantly outperforming the conventional baselines.","Modify,Fact/Evidence",Fact/Evidence
2327,209-ARR,209-ARR_v2_25@0,209-ARR_v1_22@0,"Figure 2 shows the effectiveness of our light NMT model architecture for five bilingual En-X directions, reporting the translation performance in sacreBLEU scores and the latency measured on CPUs.","Figure 2 shows the effectiveness of our light NMT model architecture for 5 EX directions, reporting the translation performance in sacreBLEU scores and the latency measured on CPUs.","Modify,Fact/Evidence",Fact/Evidence
2328,209-ARR,209-ARR_v2_25@2,209-ARR_v1_22@2,"Employing this light model architecture as a student model, we report the distilled many-to-one model performance in Table 3, measured by sacreBLEU and COMET scores (Rei et al., 2020).","Employing this light model architecture as a student model, we report the distilled many-to-one model performance in Table 1, measured by sacreBLEU and COMET (Rei et al., 2020) that are distilled from the bilingual Teachers then obtained the English pivot-based translation performance.","Split+Modify,Clarity",Clarity
2329,209-ARR,209-ARR_v2_25@3,209-ARR_v1_22@2,"For consistent comparison, we also built English bilingual baselines (E6D6) that are distilled from the bilingual Teachers, then we obtained the English pivot-based translation performance.","Employing this light model architecture as a student model, we report the distilled many-to-one model performance in Table 1, measured by sacreBLEU and COMET (Rei et al., 2020) that are distilled from the bilingual Teachers then obtained the English pivot-based translation performance.","Split+Modify,Fact/Evidence",Fact/Evidence
2330,209-ARR,209-ARR_v2_25@4,209-ARR_v1_22@3,"For all the many-to-L directions (L={de,fr,es,it,pl}), the light NMT models that are distilled from the best MNMT models show the best performance in both metrics.","For all xx-{de,fr,es,it,pl} directions, our proposed models show the best performance in both metrics.","Modify,Fact/Evidence",Fact/Evidence
2331,209-ARR,209-ARR_v2_5@0,209-ARR_v1_4@0,"Multilingual Neural Machine Translation (MNMT), which enables one system to serve translation for multiple directions, has attracted much attention in the machine translation area (Zoph and Knight, 2016;Firat et al., 2016).","Multilingual Neural Machine Translation (MNMT) has attracted much attention in the machine translation area, enabling one system to serve translation for multiple directions (Zoph and Knight, 2016;Firat et al., 2016).","Modify,Clarity",Clarity
2332,209-ARR,209-ARR_v2_25@5,209-ARR_v1_22@4,"Besides that, we also note that our direct X-Y light NMT systems successfully save the decoding cost with 75% against the pivot translation 2 .","We also note that, at inference time, our direct XY systems save the decoding cost with 75% against the pivot translation.","Modify,Fact/Evidence",Fact/Evidence
2333,209-ARR,209-ARR_v2_27@2,209-ARR_v1_24@2,"In the WMT'21 translation task, we experimentally showed that the proposed approach substantially improve translation accuracy for most X-Y directions against the strong conventional baselines of bilingual systems, pivot translation systems, and many-to-one multilingual systems.","In the WMT'21 translation task, we experimentally showed that the proposed approach substantially improve translation accuracy for most XY directions against the strong conventional baselines of bilingual systems and pivot translation systems.","Modify,Fact/Evidence",Fact/Evidence
2334,209-ARR,209-ARR_v2_27@3,209-ARR_v1_24@3,"We also examined the proposed approach in the extremely large-scale setting, while addressing the practical questions such as multiway parallel data collection, the usefulness of multilinguality during the pretraining and finetuning, and how to save the decoding cost, achieving the better X-Y quality.","We also examined the proposed approach in the extremely large-scale setting, while addressing the practical questions such as multi-way parallel data collection, the usefulness of multilinguality during the pretraining and finetuning, and how to save the decoding cost, achieving the better XY quality.","Modify,Grammar",Grammar
2335,209-ARR,209-ARR_v2_5@1,209-ARR_v1_4@1,"Because the multilingual capability hugely reduces the deployment cost at training and inference, MNMT has actively been employed as a machine translation system backbone in recent years (Johnson et al., 2017;Hassan et al., 2018).","Because the multilingual capability hugely reduces the deployment cost at training and inference, the MNMT has actively been employed as a machine translation system backbone in recent years (Johnson et al., 2017;Hassan et al., 2018).","Modify,Grammar",Grammar
2336,209-ARR,209-ARR_v2_7@2,209-ARR_v1_5@2,"In our preliminary experiments, we observed that the complete manyto-many training is still as challenging as one-tomany training (Johnson et al., 2017;Wang et al., 2020), since we have introduced more one-to-many translation tasks into the training.","In our preliminary experiment, we observed that the complete manyto-many training is still as challenging as one-tomany training (Johnson et al., 2017;Wang et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
2337,209-ARR,209-ARR_v2_8@0,209-ARR_v1_6@0,"In this paper, we propose a two-stage training for complete MNMT systems that serve arbitrary X-Y translations by 1) pretraining a complete multilingual many-to-many model and 2) finetuning the model to effectively transfer knowledge from pretraining to task-specific multilingual systems.","In this paper, we propose a two-stage training for complete MNMT systems that serve arbitrary XY translations by 1) pretraining a complete multilingual many-to-many model and 2) finetuning the model to effectively transferring knowledge from the complete multilingual training.","Modify,Fact/Evidence",Fact/Evidence
2338,209-ARR,209-ARR_v2_8@1,209-ARR_v1_6@1,"Considering that MNMT is a multi-task learner of translation tasks with ""multiple languages"", the complete multilingual model learns more diverse and general multilingual representations.","Considering that MNMT is a multi-task learner of translation task with ""multiple languages"", the complete multilingual model learns more diverse and general multilingual representations.","Modify,Grammar",Grammar
2339,209-ARR,209-ARR_v2_8@2,209-ARR_v1_6@2,"We transfer the representations to a specifically targeted task via many-to-one multilingual finetuning, and eventually build multiple many-to-one MNMT models that cover all X-Y directions.","We transfer the representations to a specifically targeted task via manyto-one multilingual finetuning, and eventually build multiple many-to-one MNMT models that cover all XY directions.","Modify,Grammar",Grammar
2340,209-ARR,209-ARR_v2_8@3,209-ARR_v1_6@3,The experimental results on the WMT'21 multilingual translation task show that our systems have substantial improvement against conventional bilingual approaches and many-to-one multilingual approaches for most directions.,"Experimenting on multilingual translation tasks at WMT'21, we have confirmed that our systems show substantial improvement against the conventional bilingual approaches for most directions.","Modify,Fact/Evidence",Fact/Evidence
2341,209-ARR,209-ARR_v2_8@5,209-ARR_v1_8@2,"""12E6D/24E12D"" denote our two settings, with ""+FT"" suffix for finetuned systems.","""Base / Big"" denote our two settings, with the suffix ""FT"" for finetuned systems.","Modify,Fact/Evidence",Fact/Evidence
2342,209-ARR,209-ARR_v2_11@3,209-ARR_v1_9@2,"Then, we transfer the multilingual representations to one target language L by finetuning the system on a subset of training data for many-to-L directions (i.e., multilingual many-to-one finetuning).","Then, we transfer the multilingual representations by finetuning the system on the training data subset for XL directions (i.e., multilingual many-to-one finetuning).","Modify,Fact/Evidence",Fact/Evidence
2343,209-ARR,209-ARR_v2_2@2,209-ARR_v1_2@2,The model suffers from poor performance in one-to-many and many-to-many with zero-shot setup.,The model suffers from poor performance in one-to-many and zero-shot directions.,"Modify,Fact/Evidence",Fact/Evidence
2344,209-ARR,209-ARR_v2_13@0,209-ARR_v1_11@0,We experiment with two small tasks of the WMT'21 large-scale multilingual translation task.,We experiment with two small tasks provided at WMT'21 large-scale multilingual translation task 1 .,"Modify,Clarity",Clarity
2345,209-ARR,209-ARR_v2_14@0,209-ARR_v1_11@1,"The tasks provide multilingual multi-way parallel corpora from the Flores 101 data (Wenzek et al., 2021).","The tasks provide multilingual multi-way parallel data 2 from the Flores 101 data, with (Englishcentric, Non-English-centric)=(321M, 166M) in total.","Modify,Fact/Evidence",Fact/Evidence
2346,209-ARR,209-ARR_v2_14@4,209-ARR_v1_11@3,"To balance the data distribution across languages (Kudugunta et al., 2019), we up-sample the low-resource languages with temperature=5.","To balance the data distribution across languages (Kudugunta et al., 2019), we upsample the low-resource languages with tempera-ture=5.","Modify,Grammar",Grammar
2347,209-ARR,209-ARR_v2_3@0,209-ARR_v1_2@3,"To address this issue, this paper discusses how to practically build MNMT systems that serve arbitrary X-Y translation directions while leveraging multilinguality with a two-stage training strategy of pretraining and finetuning.","To address the issue, this paper discusses how to practically build MNMT systems that serve arbitrary XY translation directions while leveraging multilinguality with the two-stage training strategy of pretraining and finetuning.","Modify,Clarity",Clarity
2348,209-ARR,209-ARR_v2_14@7,209-ARR_v1_12@0,"We train Transformer models (Vaswani et al., 2017) consisting of a m-layer encoder and n-layer decoder with (hidden dim., ffn dim.) =(768, 3072) in a complete multilingual many-to-many fashion.","We train Transformer models Base and Big (Vaswani et al., 2017) in a complete multilingual many-to-many fashion, respectively.","Modify,Fact/Evidence",Fact/Evidence
2349,209-ARR,209-ARR_v2_15@1,209-ARR_v1_12@1,"The model parameters are optimized by using RAdam (Liu et al., 2020) with an initial learning rate of 0.025, and warm-up steps of 10k and 30k for the 12E6D and 24E12D model training, respectively.","The model parameters are optimized by using RAdam (Liu et al., 2020) with an initial learning rate of 0.025, and warm-up steps of 10k and 30k for the Base and Big model training, respectively.","Modify,Fact/Evidence",Fact/Evidence
2350,209-ARR,209-ARR_v2_15@2,209-ARR_v1_12@2,The systems are pretrained on 64 V100 GPUs with a mini-batch size of 3072 tokens and gradient accumulation of 16.,The systems are pretrained on 64 V100 GPUs with a mini-batch size of 3072 tokens and graduation accumulation of 16.,"Modify,Grammar",Grammar
2351,209-ARR,209-ARR_v2_15@3,209-ARR_v1_12@3,"After the pretraining, the models are finetuned on a subset of X-L training data.","After pretraining, the models are finetuned on a subset of XL training data.","Modify,Grammar",Grammar
2352,209-ARR,209-ARR_v2_15@4,209-ARR_v1_12@4,"We finetune the model parameters gently on 8 V100 GPUs with the same mini-batch size, gradient accumulations, and optimizer with different learning rate scheduling of (init_lr, warm-up steps)=({1e-4, 1e-5, 1e-6}, 8k).","We tune the model parameters gently on 8 V100 GPUs with the same mini-batch size, graduation accumulations, and the same optimizer with different learning rate scheduling of (init_lr, warm-up steps)=({1e-4, 1e-5, 1e-6}, 8k).","Modify,Clarity",Clarity
2353,209-ARR,209-ARR_v2_16@1,209-ARR_v1_13@1,The bilingual and pivot-based baselines employ the Transformer base architecture.,Both are based on the Transformer Base architecture.,"Modify,Clarity",Clarity
2354,209-ARR,209-ARR_v2_16@3,209-ARR_v1_13@3,"For the X-Y pivot translation, a source sentence in language X is translated to English with a beam size of 5 by the X-En model, then the best output is translated to the final target language Y by the En-Y model.","For the XY pivot translation, a source sentence in language X is translated to English with a beam size of 5 by the XE model, then the best output is translated to the final target language Y by the EY model.","Modify,Grammar",Grammar
2355,209-ARR,209-ARR_v2_17@0,209-ARR_v1_14@0,"All results on the test sets are displayed in Figure 1 and Table 1, where we report the case-sensitive sacreBLEU score (Post, 2018) for translation accuracy.","All results on the test sets are displayed in Figure 1, where we report the case-sensitive sacreBLEU score (Post, 2018) for translation accuracy.","Modify,Fact/Evidence",Fact/Evidence
2356,209-ARR,209-ARR_v2_17@1,209-ARR_v1_14@1,"Overall, our best systems (""24E12D+FT"") are significantly better by ≥ +0.5 sacreBLEU for 83% and 88% directions against the bilingual baselines and the pivot translation baselines, respectively.","Our best systems (""BigFT"") are significantly better by ≥ +0.5 sacreBLEU for 83% and 88% directions against the bilingual baselines and the pivot translation baselines, respectively.","Modify,Fact/Evidence",Fact/Evidence
2357,209-ARR,209-ARR_v2_19@0,209-ARR_v1_14@2,Deploying a larger and larger model is not always feasible.,"However, building a larger and larger model is not always feasible.","Modify,Clarity",Clarity
2358,209-ARR,209-ARR_v2_3@1,209-ARR_v1_2@4,"Experimenting with the WMT'21 multilingual translation task, we demonstrate that our systems outperform the conventional baselines of direct bilingual models and pivot translation models for most directions, averagely giving +6.0 and +4.1 BLEU, without the need for architecture change or extra data collection.","Experimenting in the WMT'21 multilingual translation task, we demonstrate that our systems outperform the conventional baselines of direct bilingual models and pivot translation models for most directions, averagely giving +6.0 and +4.1 BLEU, without the need for architecture change or extra data collection.","Modify,Grammar",Grammar
2359,209-ARR,209-ARR_v2_19@2,209-ARR_v1_15@0,"In this section, we validate our proposed approach in an extremely large-scale data setting and also discuss how we can build lighter NMT models without the performance loss, while distilling the proposed MNMT systems (Kim and Rush, 2016).","In the following section, we validate our proposed approach in an extremely large-scale data setting and also discuss how we can build lighter MNMT models without the performance loss.","Modify,Fact/Evidence",Fact/Evidence
2360,209-ARR,209-ARR_v2_19@3,209-ARR_v1_17@0,"We briefly touch the following three topics of 1) multi-way multilingual data collection, 2) English-centric vs. multi-centric pretraining for X-Y translations, and 3) a lighter NMT model that addresses the tradeoff issue between performance and latency.","We validate our proposed approach in an extremely large-scale setting, while briefly touching the following three topics of 1) multi-way multilingual data collection, 2) English-centric vs. multi-centric pretraining for better XY, and 3) a lighter MNMT model that addresses the trade-off issue between performance and latency.","Modify,Fact/Evidence",Fact/Evidence
2361,209-ARR,209-ARR_v2_20@0,209-ARR_v1_18@0,"We build an extremely large-scale data set using our in-house English-centric data set, consisting of 10 European languages, ranging 24M-192M sentences per language.","We build an extremely large-scale data set using our in-house English-centric data set, consisting of 10 European languages, ranging 19M-187M sentences per language 3 .","Modify,Fact/Evidence",Fact/Evidence
2362,209-ARR,209-ARR_v2_20@2,209-ARR_v1_18@2,"Specifically, we extracted {de, fr, es, it, pl}-centric data and concatenate them to the existent direct X-Y data, providing 78M-279M sentence pairs per direction.","Specifically, we extracted {de, fr, es, it, pl}-centric data and concatenate them to the existing direct XY data, providing 24M-192M per direction.","Modify,Fact/Evidence",Fact/Evidence
2363,209-ARR,209-ARR_v2_20@3,209-ARR_v1_18@3,"Similarly as in Section 3, we build a shared SentencePiece vocabulary with 128k tokens to address the large-scale setting.","Similarly as in Section 2.1, we build a shared SentencePiece vocabulary with 128k tokens to address the largescale setting.","Modify,Grammar",Grammar
2406,218-ARR,218-ARR_v2_7@2,,We believe previous approaches using BERT for AES suffer from at least three limitations.,,"Add,Claim",Claim
2407,218-ARR,218-ARR_v2_7@3,,"First, the pre-trained models are usually trained on sentence-level, but fail to learn enough knowledge of essays.",,"Add,Claim",Claim
2408,218-ARR,218-ARR_v2_7@4,,"Second, the AES training data is usually quite limited for direct fine-tuning of the pre-trained models in order to learn better representation of essays.",,"Add,Claim",Claim
2409,218-ARR,218-ARR_v2_8@1,,We propose to explicitly model more effective representations by extracting multiscale features as well as leveraging the knowledge learned from numerous sentence data.,,"Add,Claim",Claim
2410,218-ARR,218-ARR_v2_8@5,,The source code of prediction module with a trained model for ASAP's prompt 8 is publicly available 3 .,,"Add,Fact/Evidence",Fact/Evidence
2411,218-ARR,218-ARR_v2_11@0,,Related Work,,"Add,Other",Other
2412,218-ARR,,218-ARR_v1_8@3,,"However, the researchers who used pretrained models in previous work simply made use of the single scale features.","Delete,Claim",Claim
2413,218-ARR,218-ARR_v2_65@4,,"Following previous work, we adopt 5-fold cross validation with 60/20/20 split for train, develop and test sets.",,"Add,Fact/Evidence",Fact/Evidence
2414,218-ARR,,218-ARR_v1_9@2,,We consider it caused by that multi-scale features are not effectively constructed in the representation layer of pre-trained model due to the lack of data for fine-tuning in the AES task.,"Delete,Claim",Claim
2415,218-ARR,,218-ARR_v1_9@3,,We need to explicitly model the multi-scale information of the essay data and combine it with the powerful linguistic knowledge of pre-trained model.,"Delete,Claim",Claim
2416,218-ARR,,218-ARR_v1_11@3,,"Through the above attempts, our model outperforms the state-of-the-art deep learning models based on LSTM (Dong et al., 2017;Tay et al., 2018).","Delete,Fact/Evidence",Fact/Evidence
2417,218-ARR,218-ARR_v2_4@0,218-ARR_v1_4@0,"AES is a valuable task, which can promote the development of automated assessment and help teachers reduce the heavy burden of assessment.","AES is a very valuable task, which can promote the development of automated assessment and help teachers reduce the heavy burden of assessment.","Modify,Clarity",Clarity
2418,218-ARR,218-ARR_v2_36@0,218-ARR_v1_37@0,"4. Use an LSTM model to process the sequence of m segment representations, followed by attention pooling operation on the hidden states of the LSTM output to obtain the segmentscale essay representation corresponding to scale k i .","4. Use an LSTM model to process the sequence of m segments representations, followed by attention pooling operation on the hidden states of the LSTM output to obtain the segmentscale essay representation corresponding to scale k i .","Modify,Grammar",Grammar
2419,218-ARR,218-ARR_v2_43@3,218-ARR_v1_46@3,"We input the segment-scale representation into another dense regression layer to get the score corresponding to segment-scale k. The final score is obtained by adding the scores of all S segmentscales and the score of the document-scale and token-scale, which is illustrated as below:","We input the segment-scale representation into another dense regression layer to get the scores corresponding to segment-scale k. The final score is obtained by adding the scores of all S segmentscales and the score of the document-scale and token-scale, which is illustrated as below:","Modify,Grammar",Grammar
2420,218-ARR,218-ARR_v2_45@5,218-ARR_v1_48@5,W is the token-scale essay representation.,W is the word-scale essay representation.,"Modify,Fact/Evidence",Fact/Evidence
2421,218-ARR,218-ARR_v2_45@6,218-ARR_v1_48@6,"H doc,tok is the concatenation of document-scale and token-scale essay representations.","H doc,tok is the concatenation of documentscale and word-scale essay representations.","Modify,Fact/Evidence",Fact/Evidence
2422,218-ARR,218-ARR_v2_5@0,218-ARR_v1_5@0,"AES systems typically consist of two modules, which are essay representation and essay scoring modules.","AES systems mainly consist of two modules, which are essay representation and essay scoring modules.","Modify,Clarity",Clarity
2423,218-ARR,218-ARR_v2_52@0,218-ARR_v1_54@1,A teacher takes into account the overall level distribution of all the students when rating an essay.,A teacher will take into account the overall level distribution of all the students when rating an essay.,"Modify,Grammar",Grammar
2424,218-ARR,218-ARR_v2_58@1,218-ARR_v1_60@1,N is the number of the essay pairs.,N is the number of the essays.,"Modify,Clarity",Clarity
2425,218-ARR,218-ARR_v2_66@2,218-ARR_v1_65@2,"We also use 5-fold cross validation with 60/20/20 split for train, develop and test sets on CRP data set.","We also use 5-fold cross validation to evaluate our system with a 60/20/20 split for train, develop and test sets on CRP data set.","Modify,Fact/Evidence",Fact/Evidence
2426,218-ARR,218-ARR_v2_66@3,218-ARR_v1_65@3,"As the RMSE metric is used in the CRP competition, we also use it to evaluate our system in ease score prediction task.","As the RMSE mertic is used in CRP competition, we also use it to evaluate our system in ease score prediction task.","Modify,Grammar",Grammar
2427,218-ARR,218-ARR_v2_2@0,218-ARR_v1_2@0,"In recent years, pre-trained models have become dominant in most natural language processing (NLP) tasks.","In recent years, the pre-trained model has become dominant in most natural language processing (NLP) tasks.","Modify,Grammar",Grammar
2428,218-ARR,218-ARR_v2_74@0,218-ARR_v1_73@0,"HA-LSTM+SST+DAT and BERT+SST+DAT propose to use two selfsupervised tasks and a domain adversarial training technique to optimize their training, which is the first work to use pre-trained language model to outperform LSTM based methods.","BERT+SST+DAT and HA-LSTM+SST+DAT proposes to use two selfsupervised tasks and a domain adversarial training technique to optimize their training, which is the first work to use pre-trained language model to outperform LSTM based methods.","Modify,Grammar",Grammar
2429,218-ARR,218-ARR_v2_75@0,218-ARR_v1_74@0,"BERT 2 (Yang et al., 2020) combines regression and ranking to fine-tune BERT model which also outperforms LSTM based methods and even obtains the new state-of-the-art.","BERT 2 (Yang et al., 2020) combine regression and ranking to fine-tune BERT model which also outperform LSTM based methods and even obtain the new state-of-the-art.","Modify,Grammar",Grammar
2430,218-ARR,218-ARR_v2_78@0,218-ARR_v1_77@0,Multi-scale Models.,Multi-Scale Models.,"Modify,Grammar",Grammar
2431,218-ARR,218-ARR_v2_79@1,218-ARR_v1_78@1,"To transfer learn from the out-of-domain essays 6 , we additionally employ a pre-training stage, which is similar to the work of (Song et al., 2020).","To transfer learn from the out-domain essays 5 , we additionally employ a pre-training stage, which is similar to the work of (Song et al., 2020).","Modify,Grammar",Grammar
2432,218-ARR,218-ARR_v2_79@2,218-ARR_v1_78@2,"In this stage, we scale all the labels of essays from out-of-domain data into range 0-1 and pre-train the model on them with MSE loss.","In this stage, we scale all the labels of essays from out-domain data into range 0-1 and pre-train them with MSE loss.","Modify,Grammar",Grammar
2433,218-ARR,218-ARR_v2_85@1,218-ARR_v1_83@1,"Table 3 shows the results of our model and the state-of-the-art models on essays in prompt 1, 2 and 8, whose WordPiece length are longer than 510.","Table 3 shows the results of our model and the state-of-the-art models on essays in prompt 1, 2 and 8, whose averaged WordPiece lengths are longer than 510.","Modify,Fact/Evidence",Fact/Evidence
2434,218-ARR,218-ARR_v2_88@4,218-ARR_v1_87@4,Results on both table indicate the similar findings.,Results on both table indicates the similar findings.,"Modify,Grammar",Grammar
2435,218-ARR,218-ARR_v2_90@3,218-ARR_v1_89@3,The results of the significance test show that the improvement of Longformer-DOC-TOK-SEG over Longformer-DOC are significant (p<0.0001) in most cases.,The results of the significance test show that the improvement of Longformer-DOC-TOK-SEG over Longformer-DOC are significantly (p<0.0001) in most cases.,"Modify,Grammar",Grammar
2436,218-ARR,218-ARR_v2_90@4,218-ARR_v1_89@4,"Performance of the two models are shown in Table 6, and we get the following findings.","Performance of the two models are shown in Table 6, we get the following findings.","Modify,Grammar",Grammar
2437,218-ARR,218-ARR_v2_92@4,218-ARR_v1_91@4,"As is shown in table 7, by incorporating the pre-training stage which learns the knowledge from out-of-domain data, Tran-BERT-MS model improves the result from 0.782 to 0.788 compared to BERT-DOC-TOK-SEG model.","As is shown in table 7, by incorporating the pre-training stage which learns the knowledge from out-domain data, Tran-BERT-MS model improves the result from 0.782 to to 0.788 compared to BERT-DOC-TOK-SEG model.","Modify,Grammar",Grammar
2438,218-ARR,218-ARR_v2_2@1,218-ARR_v1_2@1,"However, in the area of Automated Essay Scoring (AES), pre-trained models such as BERT have not been properly used to outperform other deep learning models such as LSTM.","However, most researchers in the area of Automated Essay Scoring (AES) have not been able to properly use the pre-trained model such as BERT to outperform other deep learning models such as LSTM.","Modify,Grammar",Grammar
2439,218-ARR,218-ARR_v2_94@0,218-ARR_v1_93@0,"In this paper, we propose a novel multi-scale essay representation approach based on pre-trained language model, and employ multiple losses and transfer learning for AES task.","In this paper, we propose a novel multi-scale representation approach based on pre-trained language model, and employ multiple losses and transfer learning.","Modify,Clarity",Clarity
2440,218-ARR,218-ARR_v2_94@1,218-ARR_v1_93@1,We almost obtain the state-of-the-art result among deep learning models.,We obtain the state-of-the-art results among deep learning models.,"Modify,Fact/Evidence",Fact/Evidence
2441,218-ARR,218-ARR_v2_94@2,218-ARR_v1_93@2,"In addition, we show multi-scale representation has a significant advantage when dealing with long texts.","In particular, multiscale representation has a very significant advantage in dealing with long text.","Modify,Clarity",Clarity
2442,218-ARR,218-ARR_v2_95@0,218-ARR_v1_94@0,One of the future directions could be exploring soft multi-scale representation.,One of the future directions can be exploring more efficient and soft multi-scale representation.,"Modify,Other",Other
2443,218-ARR,218-ARR_v2_95@1,218-ARR_v1_94@1,Introducing linguistic knowledge to segment at a more reasonable scale may bring further improvement.,Introducing linguistic knowledge to segment a more reasonable scale may bring further improvement.,"Modify,Grammar",Grammar
2444,218-ARR,218-ARR_v2_6@0,218-ARR_v1_8@0,"When a teacher rates an essay, the scores are often affected by multiple signals from different granularity levels, such as token level, sentence level, paragraph level and etc.","When a teacher rates an essay, the scores are often affected by multi-scale features of the essay, such as token level, sentence level and paragraph level, etc.","Modify,Clarity",Clarity
2445,218-ARR,218-ARR_v2_2@2,218-ARR_v1_2@2,"In this paper, we introduce a novel multi-scale essay representation for BERT that can be jointly learned.","In this paper, we introduce a novel multi-scale essay representation for BERT to jointly learn.","Modify,Clarity",Clarity
2446,218-ARR,218-ARR_v2_7@0,218-ARR_v1_9@0,Most of the deep neural networks AES systems use LSTM or CNN.,Most of the deep neural networks approaches use LSTM or CNN in their work.,"Modify,Claim",Claim
2447,218-ARR,218-ARR_v2_7@1,218-ARR_v1_9@1,"Some researchers (Uto et al., 2020;Rodriguez et al., 2019;Mayfield and Black, 2020) attempt to use BERT (Devlin et al., 2019) in their AES systems but fail to outperform other deep neural networks methods (Dong et al., 2017;Tay et al., 2018).","Some researchers (Uto et al., 2020;Rodriguez et al., 2019;Mayfield and Black, 2020) attempt to use BERT (Devlin et al., 2019) in their AES systems but fail to achieve competitive results as previous state-of-the-art results of deep neural networks methods.","Modify,Fact/Evidence",Fact/Evidence
2448,218-ARR,218-ARR_v2_7@5,218-ARR_v1_10@0,"Last but not least, mean squared error (MSE) is commonly used in the AES task as the loss function.","In addition, the loss function commonly used in the AES task is Mean Squared Error (MSE).","Modify,Clarity",Clarity
2449,218-ARR,218-ARR_v2_7@6,218-ARR_v1_10@1,"However, the distribution of the sample population and the sorting properties between samples are also important issues to be considered when designing the loss functions as they imitate the psychological process of teachers rating essays.","For the AES task, the distribution of the sample population and the sorting properties between samples are also important issues for selecting the loss functions.","Merge+Modify,Clarity",Clarity
2450,218-ARR,218-ARR_v2_2@3,218-ARR_v1_2@3,We also employ multiple losses and transfer learning from out-of-domain essays to further improve the performance.,"To further improve the performance of our model, we also employ multiple losses and transfer learning from out-domain essays.","Modify,Clarity",Clarity
2451,218-ARR,218-ARR_v2_7@6,218-ARR_v1_10@2,"However, the distribution of the sample population and the sorting properties between samples are also important issues to be considered when designing the loss functions as they imitate the psychological process of teachers rating essays.",They imitate the psychological process of teachers rating essays from overall student level considerations.,"Merge+Modify,Clarity",Clarity
2452,218-ARR,218-ARR_v2_7@7,218-ARR_v1_10@3,Different optimizations can also bring diversity to the final overall score distribution and contribute to the effectiveness of ensemble learning.,Different optimization directions also can bring diversity to the final overall score distribution and contribute to the effect of ensemble learning.,"Modify,Grammar",Grammar
2453,218-ARR,218-ARR_v2_8@0,218-ARR_v1_11@0,"To address the aforementioned issues and limitations, we introduce joint learning of multi-scale essay representation into the AES task with BERT, which outperforms the state-of-the-art deep learning models based on LSTM (Dong et al., 2017;Tay et al., 2018).","In this paper, we introduce the joint learning of multi-scale essay representation into the AES task with BERT.","Modify,Fact/Evidence",Fact/Evidence
2454,218-ARR,218-ARR_v2_8@2,218-ARR_v1_11@2,"As the training data is limited, we also employ transfer learning from out-of-domain essays which is inspired by (Song et al., 2020).","As the training data is limited, we also employ transfer learning from outdomain essays which is inspired by (Song et al., 2020).","Modify,Grammar",Grammar
2455,218-ARR,218-ARR_v2_2@4,218-ARR_v1_2@4,Experiment results show that our approach derives much benefit from joint learning of multi-scale essay representation and obtains almost the state-of-the-art result among all deep learning models in the ASAP 1 task.,Experiment results show that our approach derives much benefit from joint learning of multi-scale essay representation and obtains the state-ofthe-art results in the ASAP 1 task.,"Modify,Clarity",Clarity
2456,218-ARR,218-ARR_v2_17@0,218-ARR_v1_18@0,"Quadratic weighted Kappa (QWK) (Cohen, 1968) metric is commonly used to evaluate AES systems by researchers, which measures the agreement between the scoring results of two raters.","Quadratic Weighted Kappa (QWK) (Cohen, 1968) metric is commonly used to evaluate AES systems by researchers, which measures the agreement between the scoring results of two raters.","Modify,Grammar",Grammar
2457,218-ARR,218-ARR_v2_2@5,218-ARR_v1_2@5,"Our multi-scale essay representation also generalizes well to CommonLit Readability Prize (CRP 2 ) data set, which suggests that the novel text representation proposed in this paper may be a new and effective choice for long-text tasks.","Multi-scale essay representation also generalizes well to CommonLit Readability Prize (CRP 2 ) data set, which indicates that our novel text representation is a new choice for long text tasks when equipped with BERT.","Modify,Clarity",Clarity
2458,219-ARR,,219-ARR_v1_18@1,,"Our method can also be easily extended to multi-gram, text span or other type of features by summing the attention scores over spans.","Delete,Claim",Claim
2459,219-ARR,,219-ARR_v1_18@2,,"For a vocabulary of wordpieces as used in BERT, we concatenate wordpieces with a prefix of ""##"" to form unigrams and sum the attention scores.","Delete,Fact/Evidence",Fact/Evidence
2460,219-ARR,,219-ARR_v1_44@3,,We use the same training set for identifying shortcuts at a larger scale.,"Delete,Fact/Evidence",Fact/Evidence
2461,219-ARR,,219-ARR_v1_44@4,,"For cross-dataset analysis, we use Yelp (Asghar, 2016) sentiment classification dataset, which consists of 5, 101 Yelp reviews after filtering out reviews with more than 128 tokens.","Delete,Fact/Evidence",Fact/Evidence
2462,219-ARR,,219-ARR_v1_51@6,,"Table 8 demonstrates that mitigating shortcuts helps to reduce the performance gap (∆) between male and female groups, resulting in a fairer model.","Delete,Fact/Evidence",Fact/Evidence
2463,219-ARR,219-ARR_v2_8@4,,Our code and data have been made publicly.,,"Add,Fact/Evidence",Fact/Evidence
2464,219-ARR,219-ARR_v2_12@1,,"In the first step, we extract important tokens from input text.",,"Add,Fact/Evidence",Fact/Evidence
2465,219-ARR,219-ARR_v2_12@2,,"In the second step, we analyze extracted tokens from various datasets to identify likely ""spurious"" tokens.",,"Add,Fact/Evidence",Fact/Evidence
2466,219-ARR,219-ARR_v2_12@3,,"Finally, we further validate the output from the second step through knowledge-aware perturbation.",,"Add,Fact/Evidence",Fact/Evidence
2467,219-ARR,219-ARR_v2_47@3,,"We then evaluate the model on SST-2 training set 5 and Yelp (As-ghar, 2016) test set and obtain attention scores.",,"Add,Fact/Evidence",Fact/Evidence
2468,219-ARR,219-ARR_v2_47@4,,"For cross-dataset analysis, we compare the important tokens extracted from SST-2 and Yelp.",,"Add,Fact/Evidence",Fact/Evidence
2469,219-ARR,219-ARR_v2_56@0,,A Case Study: Occupation Classification,,"Add,Other",Other
2470,219-ARR,,219-ARR_v1_12@1,,"Different from most existing work that defines types of spurious correlations or shortcut patterns beforehand (Ribeiro et al., 2020;McCoy et al., 2019;Jia and Liang, 2017), which is often limited and requires expert knowledge, in this work we focus on automatically identifying models' unrobust regions at scale.","Delete,Claim",Claim
2471,219-ARR,,219-ARR_v1_12@2,,"Another line of work aims at identifying shortcuts in models (Wang and Culotta, 2020a) by training classifiers to better distinguish ""spurious"" correlations from ""genuine"" ones from human annotated examples.","Delete,Fact/Evidence",Fact/Evidence
2472,219-ARR,,219-ARR_v1_12@3,,"In contrast, we propose a cross-dataset approach and a knowledge-aware perturbation approach to automate this identification process with less human intervention in-between.","Delete,Fact/Evidence",Fact/Evidence
2473,219-ARR,219-ARR_v2_24@5,219-ARR_v1_24@5,"Thus, we propose to penalize the tokens with low frequencies:","Thus, we propose to penalize the tokens with an extreme low frequency:","Modify,Other",Other
2474,219-ARR,219-ARR_v2_47@1,219-ARR_v1_44@1,"For the task of sentiment classification, we use several datasets in our experiments.","For the task of sentiment classification, we use three datasets in our experiments.","Modify,Fact/Evidence",Fact/Evidence
2475,219-ARR,219-ARR_v2_47@2,219-ARR_v1_44@2,"To find shortcuts in Stanford Sentiment Treebank (SST-2) (Socher et al., 2013) dataset, we first train a model on SST-2 training set which consists of 67, 349 sentences.","We train a model on the Stanford Sentiment Treebank (SST-2) (Socher et al., 2013) training set, which consists of 67, 349 sentences.","Modify,Fact/Evidence",Fact/Evidence
2476,219-ARR,219-ARR_v2_47@5,219-ARR_v1_45@0,"Similarly, we train another model on 80, 000 amazon kitchen reviews (He and McAuley, 2016), and apply it on the kitchen review dev set and the amazon electronics dev set, both having 10, 000 reviews.","We also train another model on 80, 000 amazon kitchen reviews (He and McAuley, 2016), and apply it on the kitchen review dev set and the amazon electronics dev set, both having 10, 000 reviews.","Modify,Clarity",Clarity
2477,219-ARR,219-ARR_v2_49@2,219-ARR_v1_45@6,Note that our proposed framework can also be easily extended to models with different architectures.,"However, it is important to note that our proposed framework can also be easily extended to models with different architectures.","Modify,Clarity",Clarity
2478,219-ARR,219-ARR_v2_59@3,219-ARR_v1_51@3,"As shown in Table 5, masking out shortcuts, especially in training data, can improve model's generalization to out-of-distribution data.",As shown in out-of-distribution data.,"Modify,Fact/Evidence",Fact/Evidence
2479,219-ARR,219-ARR_v2_60@1,219-ARR_v1_52@1,"As shown in Table 9, our method is not very sensitive to the choice of λ.","As shown in Table 9, our method is not very sensitive to the changing of λ.","Modify,Clarity",Clarity
2480,219-ARR,219-ARR_v2_13@1,219-ARR_v1_13@1,Du et al. (2021) proposes to mitigate shortcuts by suppressing model's prediction on examples with a large shortcut degree.,Du et al. (2021) proposes to mitigate shortcuts by suppressing model's prediction on examples with large shortcut degree.,"Modify,Grammar",Grammar
2481,23-ARR,,23-ARR_v1_2@5,,"Our goal is to direct attention on a challenging aspect of out-of-domain generalization by providing a new evaluation benchmark, as well as an initial direction for solving this problem, and reference point for future work.","Delete,Claim",Claim
2482,23-ARR,23-ARR_v2_14@3,,Our evaluation benchmarks along with code for reproducing our experiments are available at https://aka.ms/ text-to-sql-schema-expansion-generalization.,,"Add,Fact/Evidence",Fact/Evidence
2483,23-ARR,23-ARR_v2_27@4,,"This step will result in disproportionally more column operations being used in our test set than in our train set, which means that the model will need to learn to generalize well in this setting to do well in this dataset.",,"Add,Claim",Claim
2484,23-ARR,23-ARR_v2_49@1,,"Note that for SQUALL, researchers often also report execution accuracy, which measures the fraction of examples for which executing the predicted SQL queries results in the correct answer to the input question.",,"Add,Claim",Claim
2485,23-ARR,23-ARR_v2_49@2,,"However, we found that for 7% of the examples that are representative of out-of-domain generalization, executing the gold SQL queries does not yield the correct answer (e.g., in cases where the correct answer is a sub-string of a cell value).",,"Add,Fact/Evidence",Fact/Evidence
2486,23-ARR,23-ARR_v2_49@3,,Therefore we chose to only report exact match accuracy in our experiments.,,"Add,Fact/Evidence",Fact/Evidence
2487,23-ARR,23-ARR_v2_63@4,,"Through column expansion, we created a new table schema that is more friendly to downstream parsers.",,"Add,Claim",Claim
2488,23-ARR,23-ARR_v2_63@5,,"Our work uses heuristics based schema expansion and works well when limited to columns that have specified types (e.g., scores or timespans), but our synthetic experiments suggest much larger potential on this problem.",,"Add,Claim",Claim
2489,23-ARR,23-ARR_v2_17@7,23-ARR_v1_16@7,"To be applicable in real scenarios, semantic parsers must be able to generalize to new domains since collecting domain-specific labeled data is often prohibitively expensive.","However, to be applicable in real scenarios, semantic parsers should be able to generalize to new domains, since collecting domain-specific labeled data is often prohibitively expensive.","Modify,Other",Other
2490,23-ARR,23-ARR_v2_3@3,23-ARR_v1_2@4,"This method can be easily applied to multiple existing base parsers, and we show that it significantly outperforms baseline parsers on this domain generalization problem, boosting the underlying parsers' overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new SQUALL data split.","We show that on this domain generalization over column operations problem, our proposed method significantly outperforms baseline parsers, and as a result boosting the underlying parsers' overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new SQUALL data split.","Link+Modify,Clarity",Clarity
2491,23-ARR,23-ARR_v2_18@6,23-ARR_v1_17@6,"However, as Suhr et al. (2020) point out, SPIDER also uses a simplified setting which excludes examples that involve multiple columns (e.g., adding two columns together), as well as ones that require background knowledge.","However, as Suhr et al. (2020) point out, SPIDER uses a simplified setting which excludes examples that involve multiple columns (e.g., adding two columns together), as well as ones that require background knowledge.","Modify,Clarity",Clarity
2492,23-ARR,23-ARR_v2_18@8,23-ARR_v1_17@8,"Furthermore, while both WIKISQL and SPIDER assume ""simple"" tables with only String-or Number-valued columns, in practice we may encounter tables where the columns themselves may have structured types (e.g., TimeSpan).","Also, while both WIKISQL and SPIDER assume ""simple"" tables with only String-or Number-valued columns, in practice we may encounter tables where the columns themselves may have structured types (e.g., TimeSpan).","Modify,Clarity",Clarity
2493,23-ARR,23-ARR_v2_18@14,23-ARR_v1_17@14,"Therefore as we will show in the following section, we aim to address this limitation by repartitioning SQUALL into new train and test splits.","Therefore as we will show in the following section, we aim to addresses this limitation by repartitioning SQUALL into new train and test splits.","Modify,Grammar",Grammar
2494,23-ARR,23-ARR_v2_18@21,23-ARR_v1_17@21,"SMBOP, on the other hand, uses bottom-up decoding, which represents programs as abstract syntax trees and constructs these trees in a bottom-up fashion (i.e., it starts by predicting the leaf nodes and then recursively composes generated sub-trees into new trees and ranks them, in a way that resembles beam search), until it reaches the tree root.","SMBOP, on the other hand, uses bottom-up decoding, which represents programs as abstract syntax trees and constructs these trees in a bottom-up fashion (i.e., it starts by predicting the leave nodes and then recursively composes generated sub-trees into new trees and ranks them, in a way that resembles beam search), until it reaches the tree root.","Modify,Grammar",Grammar
2495,23-ARR,23-ARR_v2_20@0,23-ARR_v1_19@0,"Our goal is to design an evaluation benchmark that has the following out-of-domain generalization properties: (i) the training data involves a different set of domains from the test data, (ii) the questions and tables that appear in the train and test data are non-overlapping, not only in terms of the domains they belong to, but also in terms of the program fragments that they contain, and (iii) to simulate the more challenging setting that is often encountered in real applications, the test data is biased to contain more examples that involve both nested column access operations, like getting the start of a ""Term"" in Figure 2, as well as composite column expressions, like getting the duration of a ""Term"".","Our goal is to design an evaluation benchmark that has the following out-of-domain generalization properties: (i) the training data involves a different set of domains than the test data, (ii) the questions and tables that appear in the train and test data are non-overlapping, not only in terms of the domains they belong to, but also in terms of the program fragments that they contain, and (iii) To simulate the more challenging setting that often encountered in real applications, the test data is biased to contain more examples that involve both nested column access operations, like getting the start of a ""term"" in Figure 2, as well as composite column expressions, like getting the duration of a ""term"".","Modify,Grammar",Grammar
2496,23-ARR,23-ARR_v2_23@2,23-ARR_v1_22@2,"2. For each column we declare a set of noun phrases that can be used to refer to it (e.g., ""wages"" for ""Income"" and ""base salary"" for ""salary"").","2. For each column we declare a set of noun phrases that can be used to refer to it (e.g., ""wages"" for ""Income"", and ""base salary"" for ""salary"").","Modify,Grammar",Grammar
2497,23-ARR,23-ARR_v2_23@3,23-ARR_v1_22@3,"We also define a SQL query template that shall be used for all programs: SELECT <column> FROM t WHERE ""Year"" = <year>, and a question template What was <column> in <year>?","And we define the SQL query template that shall be used for all programs: SELECT <column> FROM t WHERE ""Year"" = <year>, and a question template What was <column> in <year>?","Modify,Clarity",Clarity
2498,23-ARR,23-ARR_v2_23@5,23-ARR_v1_22@5,"3. We sample a formula and a variable from that formula (e.g., ""Income"" from formula ""Income"" = ""Salary"" + ""Stock"" ).","3. We first sample a formula, and a variable from that formula (e.g., sample ""Income"" from formula ""Income"" = ""Salary"" + ""Stock"" ).","Modify,Clarity",Clarity
2499,23-ARR,23-ARR_v2_33@1,23-ARR_v1_32@5,The goal of schema expansion is to reduce column operation challenges to column matching by adding synthetic columns to the table schema.,"The goal of schema expansion is to reduce column operations to column matching, by adding synthetic columns to the table schema, which correspond to expressions or accessors over existing columns (e.g., it may add a column that represents the sum of two columns).","Split+Modify,Claim",Claim
2500,23-ARR,23-ARR_v2_33@2,23-ARR_v1_32@5,"These synthetic columns correspond to expressions or accessors over existing columns (e.g., a column that represents the sum of two columns).","The goal of schema expansion is to reduce column operations to column matching, by adding synthetic columns to the table schema, which correspond to expressions or accessors over existing columns (e.g., it may add a column that represents the sum of two columns).","Split+Modify,Clarity",Clarity
2501,23-ARR,23-ARR_v2_33@3,23-ARR_v1_32@6,"Rather than learning (or memorizing) the ways in which different types of columns can be composed together, we propose to inject prior knowledge as to what kind of symbolic operations are possible based solely on the column types in a schema.",This is based on the intuition that learning (or rather memorizing) the ways in which different types of columns can be composed together requires a large amount of in-domain training data.,"Merge+Modify,Claim",Claim
2502,23-ARR,23-ARR_v2_33@3,23-ARR_v1_32@7,"Rather than learning (or memorizing) the ways in which different types of columns can be composed together, we propose to inject prior knowledge as to what kind of symbolic operations are possible based solely on the column types in a schema.","Instead, we propose to inject prior knowledge as to what kind of symbolic operations are possible based solely on the column types in a schema.","Merge+Modify,Clarity",Clarity
2504,23-ARR,23-ARR_v2_33@5,23-ARR_v1_32@8,"For example, ""Income"" can now map to a synthetic column that corresponds to the sum of ""Salary"" and ""Stock"" instead of having the parser produce the sum expression directly.","This reduces column operations to column matching by effectively bringing the target programs closer to their surface form in the natural language question (e.g., ""Income"" can now map to a synthetic column that corresponds to the sum of ""Salary"" and ""Stock"", instead of having the parser produce the sum expression directly).","Split+Modify,Clarity",Clarity
2505,23-ARR,23-ARR_v2_33@6,23-ARR_v1_32@9,"Since our expansion is based on column types, we argue that it is reasonable to assume that all schemas are typed and our expansion could be applied to any new domain.","Since our expansion is based on column types, we argue that it's reasonable to assume that all schemas are typed and our expansion could be applied to any new domain.","Modify,Clarity",Clarity
2506,23-ARR,23-ARR_v2_34@2,23-ARR_v1_33@2,"To this end, we introduce a schema pruning component that looks at both the expanded table schema and the question and decides which columns to prune before invoking the parser.","To this end, we introduce a schema pruning component which looks at both the expanded table schema and the question and decides which columns to prune before invoking the parser.","Modify,Clarity",Clarity
2507,23-ARR,23-ARR_v2_36@3,23-ARR_v1_35@3,"Although these templates are somewhat tailored to this dataset, our main goal is to show that there is considerable room for improvement in this challenging generalization scenario, and that even a simple approach with minimal manual effort can result in significant gains.","Although these templates are somewhat tailored to this dataset, our main goal is to show that there is considerable room for improvement in this challenging generalization scenario, and that even a very simple approach requiring minimal manual effort can result in significant boosts.","Modify,Clarity",Clarity
2508,23-ARR,23-ARR_v2_43@3,23-ARR_v1_39@9,This will result in the underlying parser being unable to handle situations where irrelevant columns are mistakenly left unpruned by the pruning model.,This will result in the underlying parser being unable to handle situations where irrelevant columns are left in by the pruning model.,"Modify,Fact/Evidence",Fact/Evidence
2509,23-ARR,23-ARR_v2_43@4,23-ARR_v1_39@10,"To this end, during training we introduce some irrelevant columns to improve the robustness of the underlying parser.","To this end, during training we introduce some irrelevant columns (i.e., negative column sampling) to improve the robustness of the underlying parser.","Modify,Fact/Evidence",Fact/Evidence
2510,23-ARR,23-ARR_v2_43@5,23-ARR_v1_39@11,"We found that making sure to always include at least 3 columns in the resulting schemas was sufficient and equivalent to randomly sampling 1 or 2 additional columns for each training example, and so that is what we did in our experiments.","We found that making sure to always include at least 3 columns in the schemas was sufficient and equivalent to randomly sampling 1 or 2 additional columns for each training example, and so that is what we did in our experiments.","Modify,Clarity",Clarity
2511,23-ARR,23-ARR_v2_49@0,23-ARR_v1_44@1,"We repeat each experiment three times using different random seeds and report mean exact match accuracy (i.e., fraction of examples where the predicted SQL queries exactly match the gold queries), and standard error for this mean.","We repeat each experiment 3 times using different random seeds and report mean exact match accuracy (i.e., fraction of examples where the predicted SQL queries exactly match the gold queries), and standard error for this mean.","Modify,Grammar",Grammar
2512,23-ARR,23-ARR_v2_7@0,23-ARR_v1_5@1,"In such scenarios, it is common to encounter tables specific to new domains that were not encountered while training a parser.","In such scenarios, it is common to encounter tables specific to new domains that were never encountered before while training a parser.","Modify,Clarity",Clarity
2513,23-ARR,23-ARR_v2_51@5,23-ARR_v1_47@2,"In this case, our approach provides a very significant accuracy gain, rendering them useful (up to 55.0% absolute / 327.4% relative).","In this case, our approach provides a very significant accuracy boost, rendering them useful (up to 55.0% absolute / 327.4% relative).","Modify,Clarity",Clarity
2514,23-ARR,23-ARR_v2_7@2,23-ARR_v1_5@3,"We argue that two kinds of abstract operations, shown in Figure 1, are particularly challenging for new domains:","This is mainly because of two kinds of abstract operations, shown in Figure 1, that are challenging for new domains:","Modify,Claim",Claim
2515,23-ARR,23-ARR_v2_63@0,23-ARR_v1_59@0,"In this paper, we introduced and focused on column operations, an important challenge related to out-ofdomain generalization for text-to-SQL parsing.","In this paper we introduced and focused on column operations, an important challenge related to out-of-domain generalization for Text-to-SQL parsing.","Modify,Grammar",Grammar
2516,23-ARR,23-ARR_v2_63@3,23-ARR_v1_59@3,"We also introduced a schema pruning component allowing us to scale schema expansion, and showed that when paired together, these two components can boost the performance of existing text-to-SQL parsers by a significant amount (up to 13.8% relative accuracy gain / 5.1% absolute in our experiments).","We also introduced a schema pruning component allowing us to scale schema expansion, and showed that when paired together, these two components can boost the performance of arbitrary underlying Text-to-SQL parsers by a significant amount (up to 13.8% relative accuracy gain / 5.1% absolute in our experiments).","Modify,Clarity",Clarity
2517,23-ARR,23-ARR_v2_2@1,23-ARR_v1_2@1,We argue that existing benchmarks fail to capture a certain out-of-domain generalization problem that is of significant practical importance: matching domain specific phrases to composite operations over columns.,We argue that existing benchmarks fail to capture a certain out-ofdomain generalization problem that is of significant practical importance: matching domain specific phrases to composite operation over columns.,"Modify,Grammar",Grammar
2518,23-ARR,23-ARR_v2_63@6,23-ARR_v1_59@4,We hope this work could motivate future research on creating a parserfriendly table ontology.,We hope that this work puts attention on this important challenge and provides a reference point for future work to build upon.,"Modify,Claim",Claim
2519,23-ARR,23-ARR_v2_63@7,23-ARR_v1_59@5,"Future work could explore learning approaches that use models to automatically expand any table schema, for example, by showing appropriate prompts to ask pre-trained language models to tackle it (Brown et al., 2020;Petroni et al., 2019).","Possible directions include making the schema expansion component learnable or prompting models like GPT-3 (Brown et al., 2020) to address it.","Modify,Claim",Claim
2520,23-ARR,23-ARR_v2_12@1,23-ARR_v1_10@1,"We then show that existing neural parsers underperform on both benchmarks because they require an impractically large amount of in-domain training datawhich is not available in our setting-to effectively ""memorize"" mappings from natural language phrases to program fragments.","We then show that existing neural parsers underperform on both benchmarks, because they require an impractically large amount of in-domain training datawhich is not available in our setting-to effectively ""memorize"" mappings from natural language phrases to program fragments.","Modify,Grammar",Grammar
2521,23-ARR,23-ARR_v2_3@0,23-ARR_v1_2@2,"To study this problem, we propose a synthetic dataset and a re-purposed train/test split of the SQUALL dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations.","To study this problem, we first propose a synthetic dataset along with a repurposed train/test split of the SQUALL dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations, and find existing state-of-the-art parsers struggle in these benchmarks.","Split+Modify,Clarity",Clarity
2522,23-ARR,23-ARR_v2_3@1,23-ARR_v1_2@2,Our results indicate that existing state-of-the-art parsers struggle in these benchmarks.,"To study this problem, we first propose a synthetic dataset along with a repurposed train/test split of the SQUALL dataset (Shi et al., 2020) as new benchmarks to quantify domain generalization over column operations, and find existing state-of-the-art parsers struggle in these benchmarks.","Split+Modify,Clarity",Clarity
2523,23-ARR,23-ARR_v2_13@1,23-ARR_v1_11@1,"Relying on generic types makes this method applicable to new domains, as long as they make use of similar underlying types.","Relying on generic types enables this method to apply to new domains, as long as they make use of similar underlying types.","Modify,Clarity",Clarity
2524,23-ARR,23-ARR_v2_13@3,23-ARR_v1_12@0,"While schema expansion may result in a large number of unnecessary expanded columns, schema pruning then examines both the input question and the available columns (original and expanded) and prunes the set of columns that the final parser is exposed to.","While schema expansion may result in a large number of unnecessary expanded columns, schema pruning then prunes the set of relevant columns that final parser is allowed to look at, based on both the questions and the expanded schemas.","Modify,Fact/Evidence",Fact/Evidence
2525,23-ARR,23-ARR_v2_3@2,23-ARR_v1_2@3,"We propose to address this problem by incorporating prior domain knowledge by preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning.","We then propose to address this problem by incorporating prior domain knowledge through preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning, which can be easily applied to different base parsers.","Link+Modify,Grammar",Grammar
2526,23-ARR,23-ARR_v2_3@3,23-ARR_v1_2@3,"This method can be easily applied to multiple existing base parsers, and we show that it significantly outperforms baseline parsers on this domain generalization problem, boosting the underlying parsers' overall performance by up to 13.8% relative accuracy gain (5.1% absolute) on the new SQUALL data split.","We then propose to address this problem by incorporating prior domain knowledge through preprocessing table schemas, and design a method that consists of two components: schema expansion and schema pruning, which can be easily applied to different base parsers.","Link+Modify,Clarity",Clarity
2527,238-ARR,238-ARR_v2_11@3,,"Bisani and Ney (2008) assumed that graphones underlie both graphemes and phonemes, and achieved great performance by learning graphones to minimize joint errors.",,"Add,Fact/Evidence",Fact/Evidence
2528,238-ARR,,238-ARR_v1_18@0,,"Syllables เส end to the other, and obtain a set of pronunciation candidates = { | = 0, . . .} by joining syllables assigned to nodes.","Delete,Fact/Evidence",Fact/Evidence
2529,238-ARR,238-ARR_v2_32@3,238-ARR_v1_30@9,We also used accuracy and the difference between correct and predicted pronunciations counted by phoneme symbols as evaluation metrics.,We also used accuracy and the difference between correct and predicted pronunciations counted by symbols as evaluation metrics.,"Modify,Clarity",Clarity
2530,238-ARR,238-ARR_v2_37@0,238-ARR_v1_40@0,"To confirm that the main process of our method can be applied to other languages, we performed additional experiments on the Japanese Hiragana dataset available from SIGMORPHON (2021).","To confirm that the main process of our method is language independent, we performed additional experiments on the Japanese Hiragana dataset available from SIGMORPHON (2021).","Modify,Clarity",Clarity
2531,238-ARR,238-ARR_v2_38@1,238-ARR_v1_41@1,"The prepared entries consisted of 85 characters, 405 syllables, and 45 phoneme symbols, and each syllable was composed of up to 6 phoneme symbols.","The prepared entries consisted of 85 characters, 405 syllables, and 45 phoneme symbols, and each syllable was composed of up to 6 symbols.","Modify,Clarity",Clarity
2532,238-ARR,238-ARR_v2_6@1,238-ARR_v1_6@1,This means that G2P for languages with syllabic orthography rules can be formulated as the task of selecting the best path in a lattice generated for a given input word or phrase if we prepare enough orthography rules to make sure that any lattice generated almost certainly includes the path for the correct pronunciation.,This means that G2P can be formulated as the task of selecting the best path in a lattice generated for a given input word or phrase if we prepare enough orthography rules to make sure that any lattice generated almost certainly includes the path for the correct pronunciation.,"Modify,Clarity",Clarity
2533,238-ARR,238-ARR_v2_12@2,238-ARR_v1_12@2,"Yolchuyeva et al. (2020) and Vesik et al. (2020) applied a transformer architecture (Vaswani et al., 2017) to train models that can deal with English or many other languages.","Yolchuyeva et al. (2020) applied a transformer architecture (Vaswani et al., 2017) to train a single model that can deal with a large number of languages.","Modify,Fact/Evidence",Fact/Evidence
2534,238-ARR,238-ARR_v2_15@1,238-ARR_v1_15@1,"Although the main process of the proposed method is language independent, we take Thai as an example in this section.","Although the main process of the proposed method is language independent, we use Thai as an example language in this section.","Modify,Clarity",Clarity
2535,238-ARR,238-ARR_v2_17@0,238-ARR_v1_16@1,"The prepared entries consisted of 77 characters, 5,772 syllables, and 31 phoneme symbols, and each syllable was composed of up to 7 phoneme symbols.","The prepared entries consisted of 77 characters, 5,772 syllables, and 31 phoneme symbols, and each syllable was composed of up to 7 symbols.","Modify,Clarity",Clarity
2536,238-ARR,238-ARR_v2_18@1,238-ARR_v1_17@1,We begin by tracing characters in each vocabulary v i one at a time to generate a lattice of nodes corresponding to entries.,We begin by tracing characters in each vocabulary one at a time to generate a lattice of nodes corresponding to entries.,"Modify,Fact/Evidence",Fact/Evidence
2537,238-ARR,238-ARR_v2_23@1,238-ARR_v1_23@1,This s i j takes a maximum of 1 when c i j = p i and approaches a minimum of 0 as c i j diverges from p i .,This takes a maximum of 1 when = and approaches a minimum of 0 as diverges from .,"Modify,Fact/Evidence",Fact/Evidence
2538,238-ARR,238-ARR_v2_23@2,238-ARR_v1_23@2,"For the previous example, we obtained p i = /klaaN Ă £ khWWn Ă £/; thus s(/klaaN Ă £ khWWn Ă £/, /klaaN Ă £ khWWn Ă £/) = 1, s(/klaaN Ă £ khWWn Ă £/, /klaa Ă £ Na Ă £ khWWn Ă £/) = 13/16, for example, were obtained.","For the previous example, we obtained = /klaaN Ă £ khWWn Ă £/; thus (/klaaN Ă £ khWWn Ă £/, /klaaN Ă £ khWWn Ă £/) = 1, (/klaaN Ă £ khWWn Ă £/, /klaa Ă £ Na Ă £ khWWn Ă £/) = 13/16, for example, were obtained.","Modify,Fact/Evidence",Fact/Evidence
2539,238-ARR,238-ARR_v2_24@1,238-ARR_v1_24@1,"More specifically, we train the model to return the similarity s i j from the encoded vectors of v i and c i j using RNNs with mean absolute error as the loss function to keep each sample error as small as possible.","More specifically, we train the model to return the similarity from the encoded vectors of and using RNNs.","Modify,Fact/Evidence",Fact/Evidence
2540,238-ARR,238-ARR_v2_25@1,238-ARR_v1_25@1,Vocabulary v is converted into a d v -dimensional vector by a character embedding layer and a bi-directional GRU (Bi-GRU).,Vocabulary is converted into a -dimensional vector by a character embedding layer and a bi-directional GRU (Bi-GRU).,"Modify,Fact/Evidence",Fact/Evidence
2541,238-ARR,238-ARR_v2_25@2,238-ARR_v1_25@2,"Candidate c is converted into a d c -dimensional vector by a syllable embedding layer, a phoneme embedding layer, and Bi-GRUs, like the network of Lample et al. (2016).","Candidate is converted into adimensional vector by a syllable embedding layer, a phoneme embedding layer, and Bi-GRUs, like the network of Lample et al. (2016).","Modify,Fact/Evidence",Fact/Evidence
2542,238-ARR,238-ARR_v2_25@3,238-ARR_v1_25@3,"Finally, both vectors are concatenated and converted into similarity s by two dense layers.","Finally, both vectors are concatenated and converted into similarity by two dense layers.","Modify,Fact/Evidence",Fact/Evidence
2543,238-ARR,238-ARR_v2_25@6,238-ARR_v1_26@1,"Therefore, we can predict the pronunciation p for a given vocabulary v as follows.","Therefore, we can predict the pronunciation for a given vocabulary as follows.","Modify,Fact/Evidence",Fact/Evidence
2544,238-ARR,238-ARR_v2_25@9,238-ARR_v1_26@4,"Finally, we output the predicted pronunciation p = c j max .","Finally, we output the predicted pronunciation = max .","Modify,Fact/Evidence",Fact/Evidence
2545,24-ARR,,24-ARR_v1_34@0,,Model Structure,"Delete,Other",Other
2546,24-ARR,,24-ARR_v1_38@0,,Maximizing the log-likelihood of Eqn. ( 5) is unpractical due to its exponential searching spaces and complex decoding process.,"Delete,Fact/Evidence",Fact/Evidence
2547,24-ARR,,24-ARR_v1_38@1,,"Therefore, we follow Kaiser et al. (2018) and adopt a discretization technique to train the model.","Delete,Fact/Evidence",Fact/Evidence
2548,24-ARR,,24-ARR_v1_56@0,,Training by Glancing Latent Variables,"Delete,Other",Other
2549,24-ARR,,24-ARR_v1_57@0,,"As our design, the discretized latent variables will have fewer modes than raw sentences, which can be trained directly without the help of distillation.","Delete,Fact/Evidence",Fact/Evidence
2550,24-ARR,,24-ARR_v1_61@1,,"As shown in Figure 1c, we eventually employ glancing training with target token for optimizing L GSZ , namely we optimize the Mix.","Delete,Fact/Evidence",Fact/Evidence
2551,24-ARR,,24-ARR_v1_86@0,,We can see from Table 1 that our mix-GLT almost outperforms all the NAT baselines (NAT and GLAT) in generation quality on all tasks while keeping a competitive decoding speedup to the autoregressive counterpart.,"Delete,Fact/Evidence",Fact/Evidence
2552,24-ARR,,24-ARR_v1_87@0,,Machine Translation.,"Delete,Other",Other
2553,24-ARR,,24-ARR_v1_87@1,,"As seen, without using an AT model as a teacher for training NAT models, the vanilla NAT and advanced GLAT model only obtain inferior generation quality.","Delete,Fact/Evidence",Fact/Evidence
2554,24-ARR,,24-ARR_v1_87@2,,"In contrast, mix-GLT achieves competitive generation quality in machine translation tasks, indicating that the introduced latent variables effectively reduce the multi-modality issue and support glancing training well.","Delete,Fact/Evidence",Fact/Evidence
2555,24-ARR,,24-ARR_v1_87@3,,It narrows the performance gap between nonautoregressive decoding and autoregressive decoding from 11.46 (GLAT vs. AT) to 2.34 (mix-GLT vs. AT) BLEU points on WMT14 EN→DE task while keeping a high-speed decoding efficiency.,"Delete,Fact/Evidence",Fact/Evidence
2556,24-ARR,,24-ARR_v1_87@4,,Paraphrasing.,"Delete,Other",Other
2557,24-ARR,,24-ARR_v1_87@5,,"Unlike the translation task, the performance gap between non-autoregressive and autoregressive decoding on the paraphrase generation task is minor (NAT vs. AT, −3.32 BLEU points, GLAT vs. AT, −0.96 BLEU points ).","Delete,Fact/Evidence",Fact/Evidence
2558,24-ARR,,24-ARR_v1_87@6,,"Nevertheless, our introduced discrete latent variables still are helpful to obtain a better performance.","Delete,Claim",Claim
2559,24-ARR,,24-ARR_v1_88@0,,Dialog Generation.,"Delete,Other",Other
2560,24-ARR,,24-ARR_v1_88@1,,We can see a different trend on the DailyDialog dataset -an AT model performs poorly than NAT models.,"Delete,Fact/Evidence",Fact/Evidence
2561,24-ARR,,24-ARR_v1_88@2,,"Both GLAT and mix-GLT outperform the AT model in BLEU-1, BLEU-2, and BLEU scores, indicating that these models recall more reference tokens and organize the tokens well.","Delete,Fact/Evidence",Fact/Evidence
2562,24-ARR,,24-ARR_v1_110@0,,Glancing Training for Latent Predictor.,"Delete,Other",Other
2563,24-ARR,,24-ARR_v1_110@1,,"With the decoder input H = h 1:m and the discretized latent variable sequence z = z 1:m , we adopt the glancing sampling technique for training the latent predictor in the following steps:","Delete,Fact/Evidence",Fact/Evidence
2564,24-ARR,,24-ARR_v1_115@4,,"With the decoder input H = h 1:m , the reference sentence Y, and the glancing latent variable sequence z obs , we train it in the following steps:","Delete,Fact/Evidence",Fact/Evidence
2565,24-ARR,,24-ARR_v1_9@0,,"Each latent variable sequence discretized from sentence are information to determine the mode of the sentence, which effectively reduces the multimodality problem at the sentence level.","Delete,Fact/Evidence",Fact/Evidence
2566,24-ARR,24-ARR_v2_8@3,,"Second, the word categorical information is informativeness to the sentence reconstruction.",,"Add,Fact/Evidence",Fact/Evidence
2567,24-ARR,24-ARR_v2_9@1,,"More impressively, latent-GLAT even outperforms autoregressive models in Quora and DailyDialog datasets, further validating our motivation for removing knowledge distillation.",,"Add,Fact/Evidence",Fact/Evidence
2568,24-ARR,24-ARR_v2_10@0,,Background,,"Add,Other",Other
2569,24-ARR,,24-ARR_v1_10@0,,"We conduct experiments on various text generation tasks, including machine translation, paraphrase generation, and dialog generation.","Delete,Fact/Evidence",Fact/Evidence
2570,24-ARR,24-ARR_v2_19@3,,"Besides, recent studies Sun and Yang, 2020) point out that the multimodality phenomenon in the dataset aggravates the challenge of NAT models.",,"Add,Fact/Evidence",Fact/Evidence
2571,24-ARR,24-ARR_v2_29@1,,"In such a case, we can directly learn the discrete latent variables by the Glancing Transformer (Qian et al., 2021a), keeping competitive inference efficiency.",,"Add,Fact/Evidence",Fact/Evidence
2572,24-ARR,24-ARR_v2_30@0,,Introducing Discrete Latent Variables for Modeling Target Categorical Information,,"Add,Other",Other
2573,24-ARR,,24-ARR_v1_11@0,,Parallel Decoding in Sequence Models,"Delete,Other",Other
2574,24-ARR,24-ARR_v2_49@0,,"The small number (K < 128) of discrete latent variables can capture high-level categorical information of the target words, supporting better learning design for parallel sequence decoding.",,"Add,Claim",Claim
2575,24-ARR,24-ARR_v2_50@0,,Our first insight is that we can learn to nonautoregressively predict the discretized latent variables directly without the help of distillation.,,"Add,Claim",Claim
2576,24-ARR,24-ARR_v2_75@1,,"The training set contains 87,170 sentence pairs (11,118 dialogues).",,"Add,Fact/Evidence",Fact/Evidence
2577,24-ARR,24-ARR_v2_75@2,,"The validation and testing set in the dataset contain 8069 pairs (1000 dialogues) and 7740 pairs (1000 dialogues), respectively.",,"Add,Fact/Evidence",Fact/Evidence
2578,24-ARR,24-ARR_v2_75@3,,Note that these tasks emphasize different aspects.,,"Add,Fact/Evidence",Fact/Evidence
2579,24-ARR,24-ARR_v2_81@0,,We can see from results in this unusual phenomenon.,,"Add,Fact/Evidence",Fact/Evidence
2580,24-ARR,24-ARR_v2_88@0,,We now turn to verify our intuition that latent-GLAT can alleviate the multi-modality problem.,,"Add,Fact/Evidence",Fact/Evidence
2581,24-ARR,24-ARR_v2_92@1,,"We can see in Table 5 that introducing latent variables both obtain performance gains to their counterpart (L#2 vs. L#1, +0.83 points, and L#4 vs. L#3, +1.69 points).",,"Add,Fact/Evidence",Fact/Evidence
2582,24-ARR,24-ARR_v2_92@2,,"As expected, the gains are largely improved while adopting the glancing training with discrete latent variables (L#5 vs. L#1, +9.75 points), which already outperforms glancing training with the reference token (L#5 vs. L#4, +3.55 points).",,"Add,Fact/Evidence",Fact/Evidence
2583,24-ARR,24-ARR_v2_92@3,,"Finally, we jointly perform glancing training with the reference tokens and discrete latent variables, achieving the best result (L#6 vs. L#1, +11.04 points).",,"Add,Fact/Evidence",Fact/Evidence
2584,24-ARR,24-ARR_v2_92@5,,We search the length penalty ratio γ for latent-GLAT while fixing the K = 64.,,"Add,Fact/Evidence",Fact/Evidence
2585,24-ARR,24-ARR_v2_100@3,,"Following the most common in NAT models (Wei et al., 2019;, we use Softcopy mechanism for initializing the decoder inputs H = (h 1 , h 2 , • • • , h m ):",,"Add,Fact/Evidence",Fact/Evidence
2586,24-ARR,,24-ARR_v1_24@0,,"During training, GLT samples Y obs according to the model's prediction: sample fewer target words for well-predicted cases and sample more words for worse-predicted cases.","Delete,Fact/Evidence",Fact/Evidence
2587,24-ARR,,24-ARR_v1_28@0,,"As observed, LT models first predict the latent variables with p(z|X ), then simultaneously decode the sentence by arg max yt p(y t |z, X ).","Delete,Fact/Evidence",Fact/Evidence
2588,24-ARR,,24-ARR_v1_33@0,,"As aforementioned in Section §2, we can decompose the original multi-modal targets with a small set of latent variables.","Delete,Fact/Evidence",Fact/Evidence
2589,24-ARR,24-ARR_v2_29@2,24-ARR_v1_33@2,"More importantly, we can employ the latent variables to invoke glancing training for modeling the target sentences, which is informative enough to reduce the multi-modality problem of original sentences.","In such a case, we can incorporate glancing training to directly model the reduced-modality target sentences based on the latent variables.","Modify,Claim",Claim
2590,24-ARR,24-ARR_v2_31@0,24-ARR_v1_35@0,"In this part, we state the structure of latent-GLAT, which introduces a small set of discrete latent variables for a NAT model, basically following Kaiser et al. (2018); ; Bao et al. (2021).","In this part, we state the structure of mix-GLT, which introduces a small set of discrete latent variables for a NAT model, basically following Kaiser et al. (2018); ; Bao et al. (2021).","Modify,Fact/Evidence",Fact/Evidence
2591,24-ARR,24-ARR_v2_34@2,24-ARR_v1_39@1,We assign each token y i with a group j ∈ [K] that has the nearest distance to its representation:,"Specifically, we assign each token y i with a group j ∈ [K] that has the nearest distance to its representation:","Modify,Clarity",Clarity
2592,24-ARR,24-ARR_v2_43@1,24-ARR_v1_52@1,"As shown in Figure 1, latent-GLAT mainly consists of an encoder F ENC (NAT Encoder), a latent predictor F LP (NAT Predictor), and a decoder F DEC (Mix. Decoder).","As shown in Figure 1a, mix-GLT mainly consists of an encoder F enc (NAT Encoder), a latent predictor F LP (NAT Predictor), and a decoder F dec (Mix. Decoder).","Modify,Clarity",Clarity
2593,24-ARR,24-ARR_v2_43@3,24-ARR_v1_52@3,Their functions can be formalized as:,We formalize their functions as:,"Modify,Clarity",Clarity
2594,24-ARR,24-ARR_v2_50@1,24-ARR_v1_57@1,"Specifically, we parameterize the F LP in a nonautoregressive fashion and use a glancing training technique (GLT, Qian et al., 2021a) for optimizing it, as shown in Figure 2a:","Notably, we model the latent variable sequence in a non-autoregressive fashion, in which we use a glancing training technique (Qian et al., 2021a) for optimizing it, as shown in Figure 1b:","Modify,Fact/Evidence",Fact/Evidence
2595,24-ARR,24-ARR_v2_4@2,24-ARR_v1_4@2,"It attracts many researchers to explore NAT in machine translation (Gu et al., 2018;Lee et al., 2018;Kaiser et al., 2018) and text-to-speech tasks Peng et al., 2020).","It attracts many researchers to explore NAT in machine translation (Gu et al., 2018;Lee et al., 2018;Kaiser et al., 2018) and text-to-speech tasks (Chen et al., 2019;Peng et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
2596,24-ARR,24-ARR_v2_54@0,24-ARR_v1_61@0,We find Eqn. (10) works robustly in experiments and analyze it in Section ( § 4.3).,We experimentally find Eqn. ( 11) works robustly and analyze it in Section ( § 4.3).,"Modify,Clarity",Clarity
2597,24-ARR,24-ARR_v2_2@0,24-ARR_v1_2@0,"Recently, parallel text generation has received widespread attention due to its success in generation efficiency.","Recently, parallel decoding of sentences has received widespread attention due to its success in decoding efficiency.","Modify,Claim",Claim
2598,24-ARR,24-ARR_v2_62@0,24-ARR_v1_68@0,"In inference phase, latent-GLAT predicts the target length, latent variables, and sentence in turn.","The inference process of mix-GLT includes length prediction, latent variables and sentence prediction.","Modify,Fact/Evidence",Fact/Evidence
2599,24-ARR,24-ARR_v2_63@0,24-ARR_v1_69@0,"For the target length, latent-GLAT first predicts the target length m with the length predictor F LEN .","For determining the target length, mix-GLT first predicts the target target length m with the length predictor.","Modify,Fact/Evidence",Fact/Evidence
2600,24-ARR,24-ARR_v2_65@0,24-ARR_v1_71@0,"Then, latent-GLAT predicts the latent variables ẑ with arg max z p θ (z|X) and sentence Ŷ with arg max Y p θ (Y | ẑ, X) for each candidate.","Then, mix-GLT predicts the latent variables ẑ with arg max z p θ (z|X ) and sentence Ŷ with arg max Y p θ (Y| ẑ, X ) for each candidate length.","Modify,Clarity",Clarity
2601,24-ARR,24-ARR_v2_66@0,24-ARR_v1_72@0,"Similar to Ma et al. (2019), latent-GLAT also ranks the candidates by itself (self-reranking) and chooses the highest score output with:","Like Ma et al. (2019), mix-GLT ranks them by itself and chooses the highest score output with:","Modify,Clarity",Clarity
2602,24-ARR,24-ARR_v2_71@0,24-ARR_v1_77@0,"We conduct experiments on several generation tasks, including machine translation, paraphrase generation, and dialog generation.","We conduct experiments on several generation tasks, including machine translation, paraphrase, and dialog generation.","Modify,Clarity",Clarity
2603,24-ARR,24-ARR_v2_5@1,24-ARR_v1_5@1,"Such as modeling word inter-dependencies by curriculum learning (Guo et al., 2020a;Liu et al., 2020) or iterative refinements mechanism (Ghazvininejad et al., 2019;Guo et al., 2020b), introducing latent variables to decompose target sentences and serve as the springboard for decoding (Shu et al., 2019;Ma et al., 2019;Bao et al., 2021), and introduce inductive bias for models' training (Wei et al., 2019;.","Such as modeling word inter-dependencies by curriculum learning (Guo et al., 2020a;Liu et al., 2020) or iterative refinements mechanism (Ghazvininejad et al., 2019;Guo et al., 2020b), introducing latent variables serve as the springboard for parallel decoding (Shu et al., 2019;Ma et al., 2019;Bao et al., 2021), or introduce inductive bias for NAT models' training (Wei et al., 2019;.","Modify,Fact/Evidence",Fact/Evidence
2604,24-ARR,24-ARR_v2_76@1,24-ARR_v1_81@1,"We compare latent-GLAT with Transformer (Vaswani et al., 2017), NAT (Gu et al., 2018), and GLAT (Qian et al., 2021a) models.","We mainly compare mix-GLT with Transformer (Vaswani et al., 2017), vanilla NAT (Gu et al., 2018), and GLAT (Qian et al., 2021a) models.","Modify,Fact/Evidence",Fact/Evidence
2605,24-ARR,24-ARR_v2_77@1,24-ARR_v1_82@1,The number of layers in latent-GLAT decoder and latent predictor are both set to 4 in experiments.,The number of layers in mix-GLT decoder and latent predictor are both set to 4 in experiments.,"Modify,Clarity",Clarity
2606,24-ARR,24-ARR_v2_77@2,24-ARR_v1_82@2,We use inverse square root learning rate scheduling for WMT14 and a linear annealing learning rate from 3.0 × 10 −4 to 1.0×10 −5 in 250K steps for IWSLT14.,We use inverse square root learning rate scheduling for WMT14 and a linear annealing learning rate from 3.0 × 10 −4 to 1.0 × 10 −5 in 250K steps for IWSLT14.,"Modify,Grammar",Grammar
2607,24-ARR,24-ARR_v2_77@5,24-ARR_v1_82@5,The mini-batch in each step consists of 2K tokens for IWSLT14 and 64K tokens for WMT14.,The mini-batch in each step consists of 2K MultiTurnDialogZoo tokens for IWSLT14 and 64K tokens for WMT14.,"Modify,Fact/Evidence",Fact/Evidence
2608,24-ARR,24-ARR_v2_5@2,24-ARR_v1_5@2,"The most successful method is the glancing transformer (GLAT, Qian et al., 2021a), which trains the NAT model by sampling partial target words as inputs to predict the remaining target words, explicitly building dependencies between the observed and unobserved words.","The most successful method is the glancing transformer (GLAT, Qian et al., 2021a), which trains the NAT model by sampling partial target words as inputs to predict the remaining words, explicitly building dependencies between the observed and unobserved words.","Modify,Clarity",Clarity
2609,24-ARR,24-ARR_v2_81@1,24-ARR_v1_88@3,"Specifically, the weak connection may encourage the AT model to predict the tokens by paying more attention to their history outputs, which degenerate to a targetside language model.",We conjecture that the weak and indirect association between the inputs and outputs of the dialogue encourages the AT model to predict the tokens by paying more attention to their history outputs.,"Merge+Modify,Clarity",Clarity
2610,24-ARR,24-ARR_v2_81@1,24-ARR_v1_88@4,"Specifically, the weak connection may encourage the AT model to predict the tokens by paying more attention to their history outputs, which degenerate to a targetside language model.","Finally, it may collapse into a target-side language model.","Merge+Modify,Clarity",Clarity
2611,24-ARR,24-ARR_v2_5@3,24-ARR_v1_5@3,"Qian et al. (2021b) employ GLAT to achieve impressive results on the translation task of WMT21 1 , even outperforming many strong autoregressive translation systems in BLEU score (Papineni et al., 2002).","Qian et al. (2021b) employ GLAT to achieve a fantastic result, even outperforming many strong autoregressive translation systems in BLEU score (Papineni et al., 2002) on the German-English translation task of WMT21 1 .","Modify,Clarity",Clarity
2612,24-ARR,24-ARR_v2_84@2,24-ARR_v1_92@2,"In contrast, the proposed latent-GLAT outperforms all NAT models with a relatively low cost, keeping a competitive speedup over autoregressive Transformer (AT).","In contrast, the proposed mix-GLT outperforms all NAT models with a relatively low cost, keeping a competitive speedup over autoregressive Transformer (AT).","Modify,Clarity",Clarity
2613,24-ARR,24-ARR_v2_84@3,24-ARR_v1_92@3,"Specifically, latent-GLAT with one-pass decoding narrows the performance gap to the AT from 5.87 BLEU points to 2.34 BLEU points on the WMT14 EN→DE test set.","Specifically, mix-GLT with onepass decoding narrows the performance gap to the AT from 5.87 BLEU points to 2.34 BLEU points on the WMT14 EN→DE test set.","Modify,Clarity",Clarity
2614,24-ARR,24-ARR_v2_86@0,24-ARR_v1_94@0,"As seen, latent-GLAT is located on the top-right of the baselines.","As seen, mix-GLT is located on the top-right of the baselines.","Modify,Clarity",Clarity
2615,24-ARR,24-ARR_v2_88@2,24-ARR_v1_96@1,"Previous researches (Gu et al., 2018;Ma et al., 2019;Qian et al., 2021a;Bao et al., 2021) always utilize a Transformer model as a teacher for training NAT models, namely sequence-level knowledge distillation (Kim and Rush, 2016) directly reduces the sentence-level multi-modal phenomenon in datasets.","Previous researches (Gu et al., 2018;Ma et al., 2019;Qian et al., 2021a;Bao et al., 2021) always utilize a Transformer model as a teacher for training NAT models, namely sequence-level knowledge distillation (Kim and Rush, 2016), which can directly reduces the sentence-level multi-modal phenomenon in datasets.","Modify,Clarity",Clarity
2616,24-ARR,24-ARR_v2_89@2,24-ARR_v1_97@2,Our proposed latent-GLAT well combines the above two techniques.,Our proposed mix-GLT well combines the above two techniques.,"Modify,Clarity",Clarity
2617,24-ARR,24-ARR_v2_93@1,24-ARR_v1_100@2,"As shown in Figure 4 and Table 6, we search the hyper-parameter of latent-GLAT that the number of discrete latent variables and the length penalty ratio γ according to the validation performance.","As shown in Figure 3 and Table 6, we search the hyper-parameter of mix-GLT that the number of discrete latent variables and the length penalty ratio γ according to the validation performance.","Modify,Fact/Evidence",Fact/Evidence
2618,24-ARR,24-ARR_v2_93@3,24-ARR_v1_100@4,The latent-GLAT implemented with 64 latent variables and γ = 1.1 obtains the best result on WMT14 EN→DE valid set.,The mix-GLT implemented with 64 latent variables and γ = 1.1 obtains the best result.,"Modify,Fact/Evidence",Fact/Evidence
2619,24-ARR,24-ARR_v2_2@1,24-ARR_v1_2@1,"Although many advanced techniques are proposed to improve its generation quality, they still need the help of an autoregressive model for training to overcome the one-to-many multi-modal phenomenon in the dataset, limiting their applications.","Many advanced techniques are proposed to improve its inferior quality, such as curriculum learning or introducing latent variables.","Merge+Modify,Claim",Claim
2620,24-ARR,24-ARR_v2_95@0,24-ARR_v1_102@0,"To alleviate this performance degradation, many researchers work to enhance word dependency modeling, including imitation learning (Wei et al., 2019;, curriculum learning (Guo et al., 2020a;Liu et al., 2020), iterative refinements (Lee et al., 2018;Ghazvininejad et al., 2019;Gu et al., 2019;Guo et al., 2020b;Huang et al., 2022), and a simplified autoregressive process .","To alleviate this performance degradation, many researchers work to enhance word dependency modeling, including imitation learning (Wei et al., 2019;, curriculum learning (Guo et al., 2020a;Liu et al., 2020), iterative refinements (Lee et al., 2018;Ghazvininejad et al., 2019;Gu et al., 2019;Guo et al., 2020b), and a simplified autoregressive process .","Modify,Fact/Evidence",Fact/Evidence
2621,24-ARR,24-ARR_v2_96@1,24-ARR_v1_103@0,"Among them, our method is close to Kaiser et al. (2018); Shu et al. (2019); Ma et al. (2019); Akoury et al. (2019); Bao et al. (2021).","Our method introduces latent variables to NAT models, which are close to Kaiser et al. (2018) Bao et al. (2021).","Modify,Fact/Evidence",Fact/Evidence
2622,24-ARR,24-ARR_v2_97@1,24-ARR_v1_104@1,"As a result, latent-GLAT accomplishes a competitive performance both in decoding efficiency and quality.","As a result, mix-GLT accomplishes a competitive performance both in decoding efficiency and quality.","Modify,Clarity",Clarity
2623,24-ARR,24-ARR_v2_99@0,24-ARR_v1_106@0,"We propose latent-GLAT, which can be directly trained without the help of knowledge distillation.","We propose mix-GLT, which can be directly trained without the help of knowledge distillation.","Modify,Clarity",Clarity
2624,24-ARR,24-ARR_v2_99@1,24-ARR_v1_106@1,"Specifically, we employ discrete latent variables to capture the word categorical information and divide the original goal into the latent variables modeling and word prediction tasks.","Specifically, we employ discrete latent variables to divide the NAT prediction to the latent variables modeling and sentence reconstruction tasks.","Modify,Fact/Evidence",Fact/Evidence
2625,24-ARR,24-ARR_v2_99@2,24-ARR_v1_106@2,"Then, we learn each task with the glancing training and encourage the model to build dependencies on the latent variables, which have fewer modes than the words and are also informative for modeling the target sentences.","Then, we learn each task with the glancing training and encourages the model to build dependencies on the latent variables, which have few modes and are informative to modeling the target sentences.","Modify,Fact/Evidence",Fact/Evidence
2626,24-ARR,24-ARR_v2_99@3,24-ARR_v1_106@3,"Experiments results on machine translation, paraphrase generation, and dialogue generation tasks validate the effectiveness of our latent-GLAT.",Experiments results on several representative text generation tasks validate the effectiveness of that our mix-GLT.,"Modify,Fact/Evidence",Fact/Evidence
2627,24-ARR,24-ARR_v2_100@0,24-ARR_v1_107@0,"According to the performance shown in Figure 5a, we can see a GLAT model will degenerate to a NAT model while using a small sampling ratio.",We can see in Figure 1a that the performance of a GLAT model will degenerate to that of a NAT model while the sampling ratio annealing too small.,"Modify,Clarity",Clarity
2628,24-ARR,24-ARR_v2_100@1,24-ARR_v1_107@1,"In such a case, introducing an autoregressive Transformer as a teacher for training the GLAT model alleviates this issue (Figure 5b), indicating that the GLAT model still needs the help of knowledge distillation for alleviating multi-modality problems.","In addition, introducing the knowledge distillation for training the GLAT model alleviates this issue (Figure 1b).","Modify,Claim",Claim
2629,24-ARR,24-ARR_v2_6@2,24-ARR_v1_6@1,"Training with the outputs of an AT can directly bypass the multi-modal phenomenon in the dataset, effectively improving the models' performances.",Training with the outputs of an AT can alleviate the multi-modality problem by filtering the training set.,"Modify,Claim",Claim
2630,24-ARR,24-ARR_v2_7@0,24-ARR_v1_7@0,"However, training NAT models by knowledge distillation are limited.","However, training NAT models with an AT model is quite limited.","Modify,Other",Other
2631,24-ARR,24-ARR_v2_7@1,24-ARR_v1_7@1,"First, it needs to train an extra AT model, which inevitably enlarges the training cost.",Including knowledge distillation via an AT model significantly enlarges the training cost due to its extra training time.,"Modify,Clarity",Clarity
2632,24-ARR,24-ARR_v2_7@2,24-ARR_v1_7@2,"Second, it is hard to promise that the teacher (or AT) model can be accurate enough in all text generation settings, which will become the bottleneck for its student NAT model.","Besides, the AT models may not be accurate enough in other text generation settings except machine translation, which will become the bottleneck for its student NAT model.","Modify,Claim",Claim
2633,24-ARR,24-ARR_v2_7@3,24-ARR_v1_7@3,"Therefore, training a model from scratch without the help of an AT model is still an open and interesting problem.","Therefore, training a model from scratch without an AT model is an open and exciting challenge.","Modify,Clarity",Clarity
2634,24-ARR,24-ARR_v2_8@0,24-ARR_v1_8@0,"In this paper, we propose latent-GLAT, which can directly learn from the raw dataset.","In this paper, we propose mix-GLT, which can directly learn from the raw dataset.","Modify,Fact/Evidence",Fact/Evidence
2635,24-ARR,24-ARR_v2_8@1,24-ARR_v1_8@1,"It alleviates the multi-modality problem following a divide-andconquer spirit, introducing a small set of discrete latent variables to capture the target word categorical information and divide the origin goal into latent variables modeling and sentence reconstruction.","To overcome the multi-modality problem, we follow a divideand-conquer spirit, introducing a small set of discrete latent variables to divide the origin goal into latent variable modeling and sentence modeling.","Modify,Fact/Evidence",Fact/Evidence
2636,24-ARR,24-ARR_v2_2@1,24-ARR_v1_2@2,"Although many advanced techniques are proposed to improve its generation quality, they still need the help of an autoregressive model for training to overcome the one-to-many multi-modal phenomenon in the dataset, limiting their applications.","However, we observe that these techniques still need an autoregressive teacher to help the model overcome the one-to-many multi-modal phenomenon in the dataset, which enlarges the training costs.","Merge+Modify,Claim",Claim
2637,24-ARR,24-ARR_v2_8@2,24-ARR_v1_9@1,"First, the categorical information may have fewer multi-modality phenomena than the original words, thus can be learned directly without the help of knowledge distillation.","Also, these latent variables will have fewer modes than origin sentences, namely, fewer multi-modality phenomena, which can be modeled with a glancing transformer (Qian et al., 2021a) directly.","Modify,Fact/Evidence",Fact/Evidence
2638,24-ARR,24-ARR_v2_8@4,24-ARR_v1_9@2,"We can extend glancing training with these discrete latent variables for modeling the sentence, encouraging the model to build dependencies on word categorical information rather than words, which works more robustly.","Finally, we extend glancing training with the latent variables to model the sentence, encouraging the model to build dependencies on latent variables rather than specific words, which works more robust.","Modify,Clarity",Clarity
2639,24-ARR,24-ARR_v2_9@0,24-ARR_v1_10@1,"Experiment results on WMT14, Quora, and Dai-lyDialog datasets show that latent-GLAT achieves remarkable improvements over several strong baselines, verifying the effectiveness of latent-GLAT.","Experiments results show that mix-GLT achieves remarkable improvements over several strong baselines, verify the effectiveness of mix-GLT.","Modify,Fact/Evidence",Fact/Evidence
2640,24-ARR,24-ARR_v2_9@2,24-ARR_v1_10@2,In-depth analyses indicate that the introduced discrete latent variables are helpful to alleviate the multi-modality problem and are necessary for performance improvement.,In-depth analyses and ablation studies indicate that the introduced latent variables and glancing training are necessary for performance improvement.,"Modify,Fact/Evidence",Fact/Evidence
2641,24-ARR,24-ARR_v2_11@0,24-ARR_v1_14@1,"For a sequence-to-sequence task of predicting sequence Y = (y 1 , y 2 , • • • , y m ) given its input sequence X = (x 1 , x 2 , • • • , x n ), the classical autoregressively factorization decomposes the p(Y |X) with a series of conditional probability:","Dozens of researches (Bahdanau et al., 2015;Gehring et al., 2017;Vaswani et al., 2017) factorize p(Y|X ) with a series of conditional probability:","Modify,Fact/Evidence",Fact/Evidence
2642,24-ARR,24-ARR_v2_15@0,24-ARR_v1_16@1,"Although such factorization achieved great success in previous studies (Bahdanau et al., 2015;Gehring et al., 2017;Vaswani et al., 2017), they predict each word 2 based on the prefix words, which may suffer from the issues of error accumulation and slow decoding during inference.","Such autoregressive factorization predicts words 2 based on its history predictions, which exists the risk of exposure bias and slow decoding during inference.","Modify,Fact/Evidence",Fact/Evidence
2643,24-ARR,24-ARR_v2_16@1,24-ARR_v1_17@1,"To tackle the above problems, Gu et al. (2018) firstly propose non-autoregressive Transformer (NAT), introducing a non-autoregressive factorization as:","To tackle the above problems, Gu et al. (2018) firstly propose non-autoregressive Transformer (NAT), removing y <t and factorizing p(Y|X ) as:","Modify,Fact/Evidence",Fact/Evidence
2644,24-ARR,24-ARR_v2_2@2,24-ARR_v1_2@3,"In this paper, we propose latent-GLAT, which employs the discrete latent variables to capture word categorical information and invoke an advanced curriculum learning technique, alleviating the multi-modality problem.","In this paper, we propose mix-GLT, which well combines the power of latent variable models and an advanced glancing training technique to alleviate the multi-modality problem.","Modify,Claim",Claim
2645,24-ARR,24-ARR_v2_19@0,24-ARR_v1_20@0,"During inference, the NAT model can decode the word simultaneously by arg max yt p(y t |X) for each y t , remarkably improving the efficiency (15× speedups to an autoregressive Transformer).","During inference, NAT model decodes a sentence by arg max yt p(y t |X ) for each position t, remarkably improving the efficiency (15× speedups).","Modify,Fact/Evidence",Fact/Evidence
2646,24-ARR,24-ARR_v2_19@2,24-ARR_v1_20@1,"Due to this,the efficiency improvements of NAT are at the cost of its quality, e.g., the performance degradation by more than 10.0 BLEU (Papineni et al., 2002) points in machine translation tasks (Gu et al., 2018).","However, the efficiency improvements of NAT are at the cost of its quality, e.g., the performance degradation by more than 10.0 BLEU (Papineni et al., 2002) points in machine translation tasks (Gu et al., 2018).","Modify,Clarity",Clarity
2647,24-ARR,24-ARR_v2_19@1,24-ARR_v1_20@2,"However, the independence assumption may prevent the NAT model from leveraging the inherent word dependencies to organize consistent outputs.",The independence assumption prevents the NAT model from leveraging the inherent word dependencies to organize consistent outputs.,"Modify,Clarity",Clarity
2648,24-ARR,24-ARR_v2_20@1,24-ARR_v1_21@1,"To mitigate the issue of missing word dependency in NAT models, Qian et al. (2021a) propose Glancing Transformer (GLAT), introducing glancing training (GLT) and sampling partial target tokens for training NAT:","Qian et al. (2021a) propose Glancing Transformer (GLAT), which introduces glancing training (GLT) and trains NAT predictions with:","Modify,Fact/Evidence",Fact/Evidence
2649,24-ARR,24-ARR_v2_22@1,24-ARR_v1_24@1,It progressively decreases the sampling ratio and obtains better performances in machine translation tasks.,"Moreover, it progressively decreases the sampling ratio and obtains better performances in machine translation tasks.","Modify,Clarity",Clarity
2650,24-ARR,24-ARR_v2_22@3,24-ARR_v1_25@1,"Second, it still heavily relies on a teacher model for further improvements (Qian et al., 2021a).","Second, it still needs a teacher model for further improvements (Qian et al., 2021a).","Modify,Clarity",Clarity
2651,24-ARR,24-ARR_v2_23@1,24-ARR_v1_26@1,"To alleviate the multimodality problem, Kaiser et al. (2018); Shu et al. (2019); Ma et al. (2019); Bao et al. (2021) propose Latent Transformer (LT), introducing latent variables z for NAT predictions as:","Kaiser et al. (2018); Shu et al. (2019); Ma et al. (2019); Bao et al. (2021) propose Latent Transformer (LT), introducing latent variables z for NAT predictions as:","Modify,Fact/Evidence",Fact/Evidence
2652,24-ARR,24-ARR_v2_2@3,24-ARR_v1_2@4,"Experiment results show that our method outperforms strong baselines without the help of an autoregressive model, which further broadens the application scenarios of the parallel decoding paradigm.",Experiments results on several representative text generation tasks show that our method is much better than the strong baselines and further improving the generality of the parallel decoding paradigm.,"Modify,Fact/Evidence",Fact/Evidence
2653,24-ARR,24-ARR_v2_26@0,24-ARR_v1_30@0,"Although Latent Transformer models improve performance in terms of BLEU score, their used autoregressive predictor (Kaiser et al., 2018;Bao et al., 2021) or deep iterative transformation (Shu et al., 2019;Ma et al., 2019) for predicting latent variables unavoidable sacrifice the overall decoding efficiency.","Although LT models improve performance in terms of BLEU score, the used autoregressive predictor (Kaiser et al., 2018;Bao et al., 2021) or deep iterative transformation (Shu et al., 2019;Ma et al., 2019) for predicting latent variables unavoidable sacrifice the overall decoding efficiency.","Modify,Clarity",Clarity
2654,24-ARR,24-ARR_v2_26@1,24-ARR_v1_30@1,"Besides, they do not explicitly build the interdependencies among the outputs.","In addition, they do not explicitly build the interdependencies among the outputs.","Modify,Clarity",Clarity
2655,24-ARR,24-ARR_v2_28@0,24-ARR_v1_32@0,"In this section, we present latent-GLAT.","In this section, we present mix-GLT in detail.","Modify,Clarity",Clarity
2656,24-ARR,24-ARR_v2_29@0,24-ARR_v1_33@1,"First, compared to the words, the introduced discrete latent variables may have fewer modes than words and be informative to determine the modes of the sentences.",The decomposed latent variables are informative to determine the mode of the sentence and alleviate its multi-modality issues.,"Modify,Fact/Evidence",Fact/Evidence
2657,245-ARR,,245-ARR_v1_83@1,,"The implementation is based on PyTorch (Paszke et al., 2019).","Delete,Fact/Evidence",Fact/Evidence
2658,245-ARR,,245-ARR_v1_83@2,,The code is attached in the supplementary materials.,"Delete,Fact/Evidence",Fact/Evidence
2659,245-ARR,,245-ARR_v1_98@1,,"For TextCNN, we adopt Pretrained GloVe (Pennington et al., 2014) word embeddings.","Delete,Fact/Evidence",Fact/Evidence
2660,245-ARR,,245-ARR_v1_98@5,,"We set α to be 0.1 and 0.5 for sentiment analysis and topic classification respectively, and the query-split radio (radio of query samples to entire training samples) to be 0.1 for both sentiment analysis and topic classification.","Delete,Fact/Evidence",Fact/Evidence
2661,245-ARR,245-ARR_v2_12@2,,"There are some works adopt meta learning-based weighting methods in multilingual learning, e.g., (Wang et al., 2020) and (Tarunesh et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
2662,245-ARR,245-ARR_v2_12@3,,"However, these works cannot solve multi-objective optimization problems.",,"Add,Claim",Claim
2663,245-ARR,245-ARR_v2_12@4,,"By contrast, this paper proposes a novel method which can solve multi-objective optimization problems.",,"Add,Fact/Evidence",Fact/Evidence
2664,245-ARR,245-ARR_v2_32@0,,"In this section, we demonstrate the gap between existing task weighting strategies and the generalization performance of MTL in Section 4.1.",,"Add,Fact/Evidence",Fact/Evidence
2665,245-ARR,245-ARR_v2_32@2,,"Moreover, we propose an algorithm to solve the MetaWeighting problem in Section 4.3.",,"Add,Fact/Evidence",Fact/Evidence
2666,245-ARR,245-ARR_v2_105@1,,The results on TextCNN are shown in Fig. 2 and 3.,,"Add,Fact/Evidence",Fact/Evidence
2667,245-ARR,245-ARR_v2_148@0,,Fig. 12 illustrates the changes in task weights in the training process of MetaWeighting for all the tasks of sentiment analysis.,,"Add,Fact/Evidence",Fact/Evidence
2668,245-ARR,245-ARR_v2_149@1,,Each colored cluster illustrates the classification accuracy performance of a method over 10 runs.,,"Add,Fact/Evidence",Fact/Evidence
2669,245-ARR,245-ARR_v2_149@2,,"Our proposed MetaWeighting outperforms all baselines on eleven of the fourteen tasks; besides, its average performance is superior to that of all baselines.",,"Add,Fact/Evidence",Fact/Evidence
2670,245-ARR,245-ARR_v2_150@1,,Each colored cluster illustrates the classification accuracy performance of a method over 10 runs.,,"Add,Fact/Evidence",Fact/Evidence
2671,245-ARR,245-ARR_v2_150@2,,"Our proposed MetaWeighting outperforms all baselines on three of the four tasks; besides, its average performance is superior to that of all baselines.",,"Add,Fact/Evidence",Fact/Evidence
2672,245-ARR,245-ARR_v2_108@4,245-ARR_v1_104@4,"For both sentiment analysis and topic classification, ρ = 0.1 provides satisfactory results.","For both sentiment analysis and topic classification, setting ρ = 0.1 provides satisfactory results.","Modify,Clarity",Clarity
2673,245-ARR,245-ARR_v2_112@1,245-ARR_v1_108@1,"From these figures, we can see that there is a large gap between the training and generalization loss, while the gap between the query and generalization loss is smaller than that between the training and generalization loss.","From these figures, we can see that there is a large gap between the training and generalization loss, and the gap between the query and generalization loss is smaller than that between the training and generalization loss.","Modify,Clarity",Clarity
2674,245-ARR,245-ARR_v2_0@0,245-ARR_v1_0@0,MetaWeighting: Learning to Weight Tasks in Multi-Task Learning,MetaWeighting: Learning to Weight Tasks in Multi-Task Text Classification,"Modify,Clarity",Clarity
2675,245-ARR,245-ARR_v2_6@4,245-ARR_v1_7@2,"Figure 1 demonstrates that the training losses and generalization losses (estimated by the test losses) have different magnitudes; moreover, they have different patterns, such as a task might have the largest training loss but the lowest generalization loss among the tasks.","Figure 1 demonstrates that training losses and generalization losses (estimated by the test losses) have different magnitudes; moreover, they have different patterns, such as a task might have largest training loss but have the lowest generalization loss among the tasks.","Modify,Grammar",Grammar
2676,245-ARR,245-ARR_v2_117@1,245-ARR_v1_113@1,"In MetaWeighting, multi-task text classification is formulated as a multi-objective bilevel programming problem, and then solved in a learning-to-learn manner.","MetaWeighting works in a learningto-learn manner, which automatically learns the task weights without any pre-defined heuristic and achieves state-of-the-art performance.","Split+Modify,Claim",Claim
2677,245-ARR,245-ARR_v2_117@2,245-ARR_v1_113@1,MetaWeighting automatically learns the task weights without any predefined heuristic and achieves state-of-the-art performance.,"MetaWeighting works in a learningto-learn manner, which automatically learns the task weights without any pre-defined heuristic and achieves state-of-the-art performance.","Split+Modify,Clarity",Clarity
2678,245-ARR,245-ARR_v2_11@0,245-ARR_v1_11@0,"Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018;Lin et al., 2019;Mahapatra and Rajan, 2020;Lin et al., 2020;Mao et al., 2020).","Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018;Mahapatra and Rajan, 2020;Lin et al., 2020;Mao et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
2679,245-ARR,245-ARR_v2_12@1,245-ARR_v1_12@1,This paper proposes a novel meta learning-based task weighting method to solve this issue.,This paper proposes a novel task weighting method to solve this issue.,"Modify,Fact/Evidence",Fact/Evidence
2680,245-ARR,245-ARR_v2_37@0,245-ARR_v1_32@0,"By contrast, existing task weighting strategies train an MTL model via the following objective.","By contrast, existing task weighting strategies train a MTL model via the following objective.","Modify,Grammar",Grammar
2681,245-ARR,245-ARR_v2_46@1,245-ARR_v1_41@1,"To properly estimate the generalization loss, we randomly divide the training set D t into two subsets: support set D s t and query set D q t , where D s t is used to train an MTL model, and D q t is used to estimate generalization loss of the MTL model.","To properly estimate the generalization loss, we randomly divide the training set D t into two subsets: support set D s t and query set D q t , where D s t is used to train a MTL model, and D q t is used to estimate generalization loss of the MTL model.","Modify,Grammar",Grammar
2726,25-ARR,,25-ARR_v1_19@2,,"This is despite evidence of adjectival scale labels being problematic in terms of bias resulting from positively and negatively worded items not being true opposites of one another, and items intended to have neutral intensity in fact proving to have specific conceptual meanings.","Delete,Claim",Claim
2727,25-ARR,,25-ARR_v1_46@0,,Comparison with Automatic Evaluation Metrics,"Delete,Other",Other
2728,25-ARR,,25-ARR_v1_48@0,,As can be seen from Tables Tables 6 unfortu-9 Raw average scores for models in the Ice-breaker run are additionally provided in Table 10 in Appendix A.4.,"Delete,Fact/Evidence",Fact/Evidence
2729,25-ARR,25-ARR_v2_42@2,,Models are consistent with Table 3.,,"Add,Fact/Evidence",Fact/Evidence
2730,25-ARR,25-ARR_v2_48@0,,Evaluating with Prescribed Topics,,"Add,Other",Other
2731,25-ARR,25-ARR_v2_49@6,,Raw average scores for models in the Ice-breaker run are additionally provided in Table 11 in Appendix A.4.,,"Add,Fact/Evidence",Fact/Evidence
2732,25-ARR,25-ARR_v2_50@1,,It also uses the brevity penalty to penalize short outputs.,,"Add,Fact/Evidence",Fact/Evidence
2733,25-ARR,25-ARR_v2_51@1,,"It computes the precision and recall using longest common subsequence (LSC) instead of n-gram, and the F1 score of precision and recall is reported as the final score.",,"Add,Fact/Evidence",Fact/Evidence
2734,25-ARR,25-ARR_v2_52@1,,"It computes the unigram precision and recall, and have a different mechanism of choosing the brevity penalty.",,"Add,Fact/Evidence",Fact/Evidence
2735,25-ARR,25-ARR_v2_53@1,,The minimum of precision and recall is reported as the final GLEU score.,,"Add,Fact/Evidence",Fact/Evidence
2736,25-ARR,25-ARR_v2_56@0,,Reference-free Metrics,,"Add,Other",Other
2737,25-ARR,25-ARR_v2_57@0,,The following introduces two reference-free automatic metrics we employed: FED and USR.,,"Add,Fact/Evidence",Fact/Evidence
2738,25-ARR,25-ARR_v2_57@1,,Their scores are computed using the conversations collected in our experiment.,,"Add,Fact/Evidence",Fact/Evidence
2739,25-ARR,25-ARR_v2_59@1,,"It consists of three sub-metrics: USR-MLM is to evaluate the understandability and naturalness, USR-DR(c) and USR-DR(f) are to evaluate the interestingness and consistency.",,"Add,Fact/Evidence",Fact/Evidence
2740,25-ARR,25-ARR_v2_59@2,,The sub-metric scores then produce an overall score through a regression model.,,"Add,Fact/Evidence",Fact/Evidence
2741,25-ARR,25-ARR_v2_60@0,,Correlation between Automatic Metrics and Human Evaluation,,"Add,Other",Other
2742,25-ARR,25-ARR_v2_35@2,25-ARR_v1_35@2,"Table 2 shows subsequent proportions (%) of workers, and the detailed instructions are introduced in Figure 5 in Appendix A.4.",Table 2 shows subsequent proportions (%) of workers.,"Modify,Fact/Evidence",Fact/Evidence
2743,25-ARR,25-ARR_v2_61@0,25-ARR_v1_47@0,"We compute the correlation between commonly applied automatic metrics and our human evaluation methods, including word-overlap-based metrics and reference-free metrics, as shown in Tables 5 and 6 respectively.","In this section, we compute the correlation between commonly applied automatic metrics and our human evaluation methods, including word-overlapbased metrics and reference-free metrics, as shown in Tables 6 and 5 respectively.","Modify,Clarity",Clarity
2744,25-ARR,25-ARR_v2_8@0,25-ARR_v1_8@0,"In terms of the live evaluation, competitions such as ConvAI2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.","In terms of the live evaluation, competitions such as Convai2 report such evaluations as highly challenging, with many of the resulting dialogues reported to be senseless, offensive, or simply not in line with instructions and ultimately live evaluation results have been discarded.","Modify,Grammar",Grammar
2745,25-ARR,25-ARR_v2_17@0,25-ARR_v1_17@0,"A continuous (0-100) rating scale is employed with three main motivation points (Graham et al., 2013;Novikova et al., 2018;Li et al., 2019;Santhanam and Shaikh, 2019;Barrault et al., 2020;Howcroft et al., 2020).","A continuous (0-100) rating scale is employed with three main motivation points (Graham et al., 2013;Mille et al., 2020;Barrault et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
2772,252-ARR,252-ARR_v2_140@1,,"Su et al. (2021)'s approach has a soft length penalty to encourage short output, but cannot generate longer summaries than trained.",,"Add,Fact/Evidence",Fact/Evidence
2773,252-ARR,,252-ARR_v1_43@4,,"The CTC training is by maximum marginal likelihood estimation, treating the predictors as unobserved latent variables.","Delete,Fact/Evidence",Fact/Evidence
2774,252-ARR,,252-ARR_v1_99@2,,"Their code and pretrained models are not available, making replication difficult.","Delete,Fact/Evidence",Fact/Evidence
2775,252-ARR,,252-ARR_v1_99@3,,"4 The standard minimal encoder-decoder NAR model has 6 layers for the encoder and another 6 layers for the decoder (Vaswani et al., 2017).","Delete,Fact/Evidence",Fact/Evidence
2776,252-ARR,,252-ARR_v1_99@4,,Our NAUS only has a 6-layer encoder.,"Delete,Fact/Evidence",Fact/Evidence
2777,252-ARR,,252-ARR_v1_99@5,,Our pilot study shows that more layers do not further improve performance in our encoder-only architecture.,"Delete,Fact/Evidence",Fact/Evidence
2778,252-ARR,,252-ARR_v1_100@0,,Human Evaluation.,"Delete,Other",Other
2779,252-ARR,,252-ARR_v1_107@7,,We further propose a dynamic programming algorithm to control the summary length.,"Delete,Fact/Evidence",Fact/Evidence
2780,252-ARR,252-ARR_v2_4@2,,"In this paper, we focus on the setting of sentence summarization (Rush et al., 2015;Filippova et al., 2015).",,"Add,Fact/Evidence",Fact/Evidence
2781,252-ARR,252-ARR_v2_87@2,,"Both of our variants outperform Schumann et al. ( 2020) by 1.21-2.73 in terms of the total ROUGE score (Rows 5-6 & 13-14, Table 1).",,"Add,Fact/Evidence",Fact/Evidence
2782,252-ARR,252-ARR_v2_87@3,,"As mentioned, Schumann et al. (2020) only extract original words with order preserved, yielding noisy sentences.",,"Add,Fact/Evidence",Fact/Evidence
2783,252-ARR,252-ARR_v2_87@4,,"Our NAUS, as a student, learns from the search-based teacher model and is able to smooth out its noise.",,"Add,Fact/Evidence",Fact/Evidence
2784,252-ARR,252-ARR_v2_87@5,,"This is a compelling result, as our student model outperforms its teacher.",,"Add,Claim",Claim
2785,252-ARR,252-ARR_v2_97@1,,"Nevertheless, our non-autoregressive NAUS with length control is ~200 times faster than search and ~3 times faster than the AR Transformer.",,"Add,Fact/Evidence",Fact/Evidence
2786,252-ARR,252-ARR_v2_98@1,,We present additional results in our appendices:,,"Add,Fact/Evidence",Fact/Evidence
2787,252-ARR,252-ARR_v2_103@0,,The importance of controlling the output length is recently realized in the summarization community.,,"Add,Claim",Claim
2788,252-ARR,252-ARR_v2_103@3,,"Song et al. (2021) is able to precisely control the length by progressively filling a predetermined number of decoding slots, analogous to the vanilla NAR model in our non-autoregressive setting.",,"Add,Fact/Evidence",Fact/Evidence
2789,252-ARR,252-ARR_v2_104@1,,"Wiseman et al. (2018) address the table-to-text generation task, and model output segments by a hidden semi-Markov model (Ostendorf et al., 1996), simultaneously generating tokens for all segments.",,"Add,Fact/Evidence",Fact/Evidence
2790,252-ARR,252-ARR_v2_108@0,,Acknowledgments,,"Add,Other",Other
2791,252-ARR,252-ARR_v2_126@0,,"Each reported number in Tables 1-3 were averaged over 10 independent runs, whereas the results in Table 7 (Appendix F) were based on a single run due to the limited time.",,"Add,Fact/Evidence",Fact/Evidence
2792,252-ARR,252-ARR_v2_39@2,252-ARR_v1_40@2,"Instead, we allow blank tokens scattering over the entire sentence; the residual connections in Eqns ( 2) and (3) can better utilize such input-output correspondence for summarization.","Instead, we allow blank tokens scattering over the entire sentence; thus, the residual connections in Eqns ( 2) and (3) can better utilize such input-output correspondence for summarization.","Modify,Clarity",Clarity
2793,252-ARR,252-ARR_v2_42@1,252-ARR_v1_43@1,"The Connectionist Temporal Classification (CTC, Graves et al., 2006) algorithm allows a special blank token in the vocabulary, and uses dynamic programming to marginalize out such blank tokens, known as latent alignment .","The Connectionist Temporal Classification (CTC, Graves et al., 2006) algorithm allows a special blank token in the vocabulary, and uses dynamic programming to marginalize out such blank tokens.","Modify,Clarity",Clarity
2794,252-ARR,252-ARR_v2_43@0,252-ARR_v1_44@0,"Concretely, the predicted likelihood is marginalized over all possible fillings of , i.e., all possible token sequences that are reduced to the groundtruth text:","Concretely, the likelihood is marginalized over all possible fillings of , i.e., all possible token sequences that are reduced to the groundtruth text:","Modify,Clarity",Clarity
2795,252-ARR,252-ARR_v2_77@0,252-ARR_v1_79@0,"The headline generation dataset (Rush et al., 2015) is constructed from the Gigaword news corpus (Graff et al., 2003), where the first sentence of a news article is considered as input text and the news title is considered as the summary.","The head generation dataset (Rush et al., 2015) is constructed from the Gigaword news corpus (Graff et al., 2003), where the first sentence of a news article is considered as input text and the news title is considered as the summary.","Modify,Clarity",Clarity
2796,252-ARR,252-ARR_v2_77@2,252-ARR_v1_79@2,"Based on the analysis of the training size in Appendix B, we used 3M samples for training NAUS.","Based on the curve in Appendix B, we used 3M samples for training NAUS.","Modify,Clarity",Clarity
2797,252-ARR,252-ARR_v2_83@0,252-ARR_v1_85@0,"In addition to summary quality, we also evaluated the inference efficiency of different methods, as it is important for the deployment of deep learning models in real-time applications.","In addition to summary quality, we also evaluated inference efficiency of different methods, as it is important for the deployment of deep learning models in real-time applications.","Modify,Grammar",Grammar
2798,252-ARR,252-ARR_v2_83@3,252-ARR_v1_85@3,Appendix B presents additional implementation details.,Other implementation details are presented in Appendix B.,"Modify,Clarity",Clarity
2799,252-ARR,252-ARR_v2_7@1,252-ARR_v1_7@1,"Their model maximizes a heuristically defined scoring function that evaluates the quality (fluency and semantics) of the generated summary, achieving higher performance than cycle-consistency methods.","Their model maximizes a scoring function that evaluates the quality (fluency and semantics) of the generated summary, achieving higher performance than cycle-consistency methods.","Modify,Clarity",Clarity
2800,252-ARR,252-ARR_v2_94@0,252-ARR_v1_96@0,"We first tried vanilla encoder-decoder NAR Transformer (Rows 4 & 13, Gu et al., 2018), where we set the number of decoding slots as the desired summary length; thus, the blank token and the length-control algorithm are not needed.","We first tried vanilla encoder-decoder NAR Transformer (Rows 4 & 13, Gu et al., 2018), where we set the number of decoding slots as the desired summary length and thus length-control is not needed.","Modify,Fact/Evidence",Fact/Evidence
2801,252-ARR,252-ARR_v2_95@2,252-ARR_v1_97@2,"We also experimented with previous nonautoregressive work for supervised summarization (Su et al., 2021) 4 in our learning-from-search setting.","We also experimented with previous non-autoregressive work for supervised summarization (Su et al., 2021) 3 in our learning-fromsearch setting.","Modify,Grammar",Grammar
2802,252-ARR,252-ARR_v2_95@4,252-ARR_v1_97@4,"Their performance is higher than vanilla NAR models, but lower than ours.","Their performance is higher than vanilla NAR models, but than ours.","Modify,Grammar",Grammar
2803,252-ARR,252-ARR_v2_132@0,252-ARR_v1_100@1,We conducted human evaluation with a focus on truncating and length-control decodings.,We also conducted human evaluation with a focus on truncating and lengthcontrol decodings.,"Modify,Grammar",Grammar
2804,252-ARR,252-ARR_v2_134@2,252-ARR_v1_101@2,"This verifies that length-control decoding is important for summarization, as truncating yields incomplete sentences, which are inadequately reflected by ROUGE scores.","This verifies that length-control decoding is important for summarization, as truncating yields incomplete sentences, which are reflected by ROUGE scores.","Modify,Clarity",Clarity
2805,252-ARR,252-ARR_v2_98@0,252-ARR_v1_102@0,Additional Results.,Additional results.,"Modify,Grammar",Grammar
2806,252-ARR,252-ARR_v2_100@2,252-ARR_v1_104@2,"Abstraction systems generate new utterances as the summary, e.g., by sequence-to-sequence models trained in a supervised way (Zhang et al., 2020;Liu et al., 2021b).","Abstraction systems generate new utterances as the summary, e.g., by sequence-to-sequence models trained in a supervised way Zhang et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
2807,252-ARR,252-ARR_v2_101@1,252-ARR_v1_105@1,Yang et al. (2020) propose to use the Lead baseline (first several sentences) as the pseudo-groundtruth.,"For example, Yang et al. (2020) propose to use the Lead baseline (first several sentences) as the pseudo-groundtruth.","Modify,Clarity",Clarity
2808,252-ARR,252-ARR_v2_101@4,252-ARR_v1_105@4,Zhou and Rush (2019) propose a step-by-step decomposable scoring function and perform beam search for summary generation.,Zhou and Rush (2019) propose a step-by-step decomposable scoring function and perform beam search for generate summarization.,"Modify,Grammar",Grammar
2809,252-ARR,252-ARR_v2_102@1,252-ARR_v1_106@1,"Previously, Li et al. (2020) fine-tune a GPT-2 model based on search results for unsupervised paraphrasing; Jolly et al. (2022) adopt the search-and-learning framework to improve the semantic coverage for few-shot data-to-text generation.","Previously, fine-tune a GPT-2 model based on search results for unsupervised paraphrasing.","Modify,Fact/Evidence",Fact/Evidence
2810,252-ARR,252-ARR_v2_104@2,252-ARR_v1_107@1,Jia et al. (2021) apply non-autoregressive models to extractive document-level summarization.,"Recently, Jia et al. (2021) apply non-autoregressive models to extractive document-level summarization.","Modify,Clarity",Clarity
2811,252-ARR,252-ARR_v2_104@4,252-ARR_v1_107@3,Yang et al. (2021) apply auxiliary part-ofspeech (POS) loss and explore pretraining strategies for encoder-decoder nonautoregressive summarization.,Yang et al. (2021) apply auxiliary part-of-speech (POS) loss and explore pretraining strategies for encoder-decoder non-autoregressive summarization; their length is given by POS tag/EOS predictions.,"Modify,Fact/Evidence",Fact/Evidence
2812,252-ARR,252-ARR_v2_103@2,252-ARR_v1_107@4,None of these studies can control the length explicitly.,"All these studies concern supervised summarization, and none can explicitly control the output length.","Link+Modify,Clarity",Clarity
2814,252-ARR,252-ARR_v2_104@5,252-ARR_v1_107@5,"All these studies concern supervised summarization, while our paper focuses on unsupervised summarization.","By contrast, our paper focuses on unsupervised summarization.","Link+Modify,Clarity",Clarity
2815,252-ARR,252-ARR_v2_107@3,252-ARR_v1_110@3,"This is because previous supervised summarization studies lack explicit categorization of summary lengths (Yang et al., 2020;, making comparisons unfair and problematic (Schumann et al., 2020).","This is because previous supervised summarization papers lack explicitly categorization of summary lengths (Yang et al., 2020;, making comparisons unfair and problematic (Schumann et al., 2020).","Modify,Clarity",Clarity
2816,252-ARR,252-ARR_v2_107@4,252-ARR_v1_110@4,"Such an observation is also evidenced by Su et al. (2021), where the same model may differ by a few ROUGE points when generating summaries of different lengths.","This is also evidenced by Su et al. (2021), where the same model may differ by a few ROUGE points when generating summaries of different lengths.","Modify,Clarity",Clarity
2817,252-ARR,252-ARR_v2_8@2,252-ARR_v1_8@2,"Different from Li et al. (2020), we propose to utilize non-autoregressive decoders, which generate all output tokens in parallel due to our following observations:","Different from Li et al. (2020), we propose to utilize non-autoregressive text generators, which generate all tokens in the output in parallel, based on our following observations:","Modify,Clarity",Clarity
2818,252-ARR,252-ARR_v2_110@1,252-ARR_v1_112@1,"We denote this by Γ , for example, Γ (a aabb ) = aaabb, as opposed to Γ(a aabb ) = aab in our algorithm.","We denote this by Γ , for example, Γ (a aabb ) = aaabb, as opposed to Γ(a aabb ) = aabb in our algorithm.","Modify,Grammar",Grammar
2819,252-ARR,252-ARR_v2_114@0,252-ARR_v1_116@0,"In ( 13), β 1,0 refers to the probability of one token that is reduced to zero words, in which case the first predicted token can only be the blank token , corresponding to Eqn. ( 9) with s = 1 and t = 0.","In ( 13), β 1,0 refers to the probability of one token that is reduced to zero words, in which case, the first predicted token can only be the blank token , corresponding to Eqn. ( 9) with s = 1 and t = 0.","Modify,Grammar",Grammar
2820,252-ARR,252-ARR_v2_119@2,252-ARR_v1_122@2,"We show in this part that our algorithm, with beam size B = 1, may not yield the exact optimum with an example in Table 4.","We show in this part that our algorithm, with beam size B = 1, does not yield the exact optimum with an example in Table 5.","Modify,Other",Other
2821,252-ARR,252-ARR_v2_135@0,252-ARR_v1_135@0,"In the main paper, we present results where our NAUS is trained on search outputs (Schumann et al., 2020) that have the same length as the inference target.","In the main paper, we present results where our NAUS is trained on search outputs (Schumann et al., 2020), which have the same length as the inference target.","Modify,Clarity",Clarity
2822,252-ARR,252-ARR_v2_15@0,252-ARR_v1_15@0,"Our work on unsupervised summarization follows the recent progress of search-based text generation (Liu et al., , 2021aKumar et al., 2020).",Our work on unsupervised summarization follows the recent progress of search-based text generation.,"Modify,Fact/Evidence",Fact/Evidence
2823,252-ARR,252-ARR_v2_21@0,252-ARR_v1_21@0,A pilot analysis in Schumann et al. (2020) shows that words largely overlap between a source text and its reference summary.,A pilot analysis in Schumann et al. (2020) shows that words largely overlap between a source text and its summary.,"Modify,Clarity",Clarity
2824,252-ARR,252-ARR_v2_27@0,252-ARR_v1_27@0,"Let X (n) ∈ R T ×d be the representation at the nth layer, where T is the number of words and d is the dimension.","Let X (n) ∈ R T ×d be representation at the nth layer, where T is the number of words and d is the dimension.","Modify,Grammar",Grammar
2825,255-ARR,255-ARR_v2_66@5,,We train all our models on a single GeForce RTX 3090.,,"Add,Fact/Evidence",Fact/Evidence
2826,255-ARR,255-ARR_v2_85@6,,We hope our work is helpful for those who aim to further exploit the power of mixture-of-experts on table-based reasoning in the future.,,"Add,Claim",Claim
2827,255-ARR,255-ARR_v2_2@7,255-ARR_v1_2@7,Our code is available at https: //github.com/THUMLP/SaMoE.,Our code will be available at (URL to be released here).,"Modify,Fact/Evidence",Fact/Evidence
2828,255-ARR,255-ARR_v2_36@0,255-ARR_v1_36@0,Multi-expert Training,Supervised Learning,"Modify,Clarity",Clarity
2829,255-ARR,255-ARR_v2_37@0,255-ARR_v1_37@0,Multi-expert training guides each expert on dealing with different reasoning types while maintaining balanced training across experts.,Supervised learning guides each expert on dealing with different reasoning types while maintaining balanced training across experts.,"Modify,Clarity",Clarity
2830,255-ARR,255-ARR_v2_4@2,255-ARR_v1_4@2,"Table-based verification faces different challenges than unstructured-text-based due to the complexity of the requirements, including sophisticated textual, numerical, and logical reasoning across evidence tables; even for some statements, multiple types of reasoning are indispensable to complete the verification.","Table-based verification is more challenging than unstructured-text-based due to the complexity of the requirements, including sophisticated textual, numerical, and logical reasoning across evidence tables; even for some statements, multiple types of reasoning are indispensable to complete the verification.","Modify,Claim",Claim
2831,255-ARR,255-ARR_v2_66@1,255-ARR_v1_67@0,"SaMoE is first trained in the Multi-expert training stage for 57,680 steps (20 epochs).","SaMoE is first trained in the supervised learning stage for 57,680 steps (20 epochs).","Modify,Clarity",Clarity
2832,255-ARR,255-ARR_v2_74@1,255-ARR_v1_75@1,We conduct two experiments: one reduces the number of experts to 1 to disable the contribution from the MoE structure (SaMoE w/o Sa (n e = 1)); the other trains the proposed framework with only the Multi-expert training stage (SaMoE w/o Sa).,We conduct two experiments: one reduces the number of experts to 1 to disable the contribution from the MoE structure (SaMoE w/o Sa (n e = 1)); the other trains the proposed framework with only the supervised learning stage (SaMoE w/o Sa).,"Modify,Clarity",Clarity
2833,255-ARR,255-ARR_v2_83@3,255-ARR_v1_84@2,"In this paper, we develop a self-adapted mixture-of-experts framework that achieves a more effective combination of experts by learning from the experts' performance on the train set.",We develop a self-adapted mixture-ofexperts framework that achieves a more effective combination of experts by learning from the experts' performance on the train set.,"Modify,Clarity",Clarity
2834,255-ARR,255-ARR_v2_85@0,255-ARR_v1_86@0,This paper proposes a new method that exploits the mixture of experts to recognize and execute different types of reasoning required for table-based fact verification.,This paper proposes a framework that leverages the mixture of experts to recognize and execute different types of reasoning required for table-based fact verification.,"Modify,Clarity",Clarity
2835,255-ARR,255-ARR_v2_85@2,255-ARR_v1_86@2,"Moreover, we design a supervisor network to adjust the imprecise attention score and achieve a more efficient combination across experts.","Moreover, we design a novel supervisor network to adjust the imprecise attention score and achieve a more efficient combination across experts.","Modify,Claim",Claim
2836,255-ARR,255-ARR_v2_86@1,255-ARR_v1_87@1,"We initial parameters of the feature extractor with the embedding and the bottom 12 encoding layers of RoBERTa-Large and each expert with the upper 12 encoding layers of RoBERTa-Large, respectively.","We initial parameters of the feature extractor with the embedding layer and the bottom 12 encoding layers of RoBERTa-Large and each expert with the upper 12 encoding layers of RoBERTa-Large, respectively.","Modify,Clarity",Clarity
2837,255-ARR,255-ARR_v2_8@0,255-ARR_v1_8@0,Research Question,Task Formulation,"Modify,Other",Other
2884,28-ARR,,28-ARR_v1_23@1,,Figure 2 illustrates the generation of the training samples from a taxonomy.,"Delete,Fact/Evidence",Fact/Evidence
2885,28-ARR,,28-ARR_v1_27@2,,"The definition is defined by the average of the pre-trained embeddings of the terms the definition, and the synset is represented by the pre-trained embedding of the synonym word itself.","Delete,Fact/Evidence",Fact/Evidence
2886,28-ARR,28-ARR_v2_33@3,,The details of GAT and its difference from GNN are given in Section B of Appendix.,,"Add,Fact/Evidence",Fact/Evidence
2887,28-ARR,28-ARR_v2_33@4,,Thus we used position enhanced GAT to obtain the node embeddings of an anchor's ego tree.,,"Add,Fact/Evidence",Fact/Evidence
2888,28-ARR,28-ARR_v2_63@3,,"Like Taxo-Expan (Shen et al., 2020) evaluation strategy, we scale the MRR score by a factor of 10 to highlight the discrepancy of the performances among different methods.",,"Add,Fact/Evidence",Fact/Evidence
2889,28-ARR,28-ARR_v2_64@2,,"As Taxo-Expan and TMN outperform SemEval-2016 (Shen et al., 2020;Zhang et al., 2021), we have not included SemEval-2016 as baseline in this study.",,"Add,Fact/Evidence",Fact/Evidence
2890,28-ARR,28-ARR_v2_69@4,,"In TEAM-RG(M), we obtain near-perfect MRR scores.",,"Add,Fact/Evidence",Fact/Evidence
2891,28-ARR,28-ARR_v2_69@5,,This is because the definitions are already present in training set for the query concepts with known definitions (test sample drawn from the base taxonomy).,,"Add,Fact/Evidence",Fact/Evidence
2892,28-ARR,28-ARR_v2_69@6,,The score of 1 indicates the ability of the proposed method TEAM-RG(M) to correctly identify the appropriate anchor nodes for the merge operation.,,"Add,Fact/Evidence",Fact/Evidence
2893,28-ARR,28-ARR_v2_80@1,,Another future research possibility can be to explore the response of this model using advanced contextual encoders.,,"Add,Claim",Claim
2894,28-ARR,28-ARR_v2_31@1,28-ARR_v1_28@1,"An ego tree T a : (V a , E a ) of a node a in the taxonomy T is a sub-tree that comprises the node a and its k-hop neighborhood nodes.","An ego tree T a : (V a , E a ) of a node a in the taxonomy T is a sub-tree comprising of the node a and its k-hop neighborhood nodes.","Modify,Clarity",Clarity
2895,28-ARR,28-ARR_v2_54@2,28-ARR_v1_50@2,It fails to give us a reliable ranked list of prospective anchors-(A/ M) given a query -since it does not learn the relative ranks of positive and negative anchors for a query.,It fails to give us a reliable ranked list of prospective anchors-(A/ M) given a query -since it does not learn the relative ranks of positive and corrupted anchors for a query.,"Modify,Clarity",Clarity
2896,28-ARR,28-ARR_v2_60@4,28-ARR_v1_56@4,"Since both of our proposed frameworks optimize for ranking loss, i.e., discriminates true candidate pairs from the negative ones -we get a ranked list of candidate anchors a while matching each of them with q via respective matching modules.","Since both of our proposed frameworks optimize for ranking loss, i.e., discriminates true candidate pairs from the corrupted ones -we get a ranked list of candidate anchors a while matching each of them with q via respective matching modules.","Modify,Clarity",Clarity
2897,28-ARR,28-ARR_v2_63@2,28-ARR_v1_59@2,"We use Mean Rank (MR), Hit@k, and Mean Reciprocal Rank (MRR) to evaluate the ranks of the retrieved results obtained from different models, for the test queries.","We use Mean Rank (MR), Hit@k, and Mean Reciprocal Rank (MRR) to evaluate a model's performance to produce a ranked list of anchors given a test query.","Modify,Clarity",Clarity
2898,28-ARR,28-ARR_v2_63@4,28-ARR_v1_59@3,"Further, we use Accuracy, Micro/ Macro F1, Precision, Recall, and F-Scores to evaluate a method's prediction capability to decide which operation among merge (M), attach (A), and no-operation (N) needs to be performed.","Further, we use Accuracy, Micro/ Macro F1, Precision, Recall, and F-Scores to evaluate a method's prediction capability to decide which operation among merge (M), attach (A), and no-operation (N) is to perform.","Modify,Clarity",Clarity
2899,28-ARR,28-ARR_v2_77@0,28-ARR_v1_75@0,"Existing methods for taxonomy expansion can be divided into two categories: relying on alignment between multiple taxonomies [Ruiz-Casado et al. (2005), Toral et al. (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011] or relying on machine learning-based rating sub-graphs.","Existing methods for taxonomy expansion can be divided into two categories: relying on alignment between multiple taxonomies [Ruiz-Casado et al. (2005), Toral and Monachini (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011)] or relying on machine learning-based rating sub-graphs.","Modify,Fact/Evidence",Fact/Evidence
2900,28-ARR,28-ARR_v2_79@4,28-ARR_v1_78@4,"In various experimental setups, the proposed TEAM-RG and TEAM-CL outperformed its state of the art for attach operation and provided a highly encouraging performance on merge operation.","In various experimental setups, the proposed TEAM-RG and TEAM-CL outperformed its state-of-the-art for attach operation and provided a highly encouraging performance on merge operation.","Modify,Grammar",Grammar
2901,28-ARR,28-ARR_v2_81@1,28-ARR_v1_80@1,"Ruiz-Casado et al. (2005), Toral et al. (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011 exploit structured information in Wikipedia to expand Word-Net with new synsets.","Ruiz-Casado et al. (2005), Toral and Monachini (2008), Ponzetto and Navigli (2009), and Yamada et al. (2011 exploit structured information in Wikipedia to expand WordNet with new synsets.","Modify,Fact/Evidence",Fact/Evidence
2902,28-ARR,28-ARR_v2_6@4,28-ARR_v1_6@4,"Though most of the existing studies consider the expansion a regression problem (Shen et al., 2020;Yu et al., 2020b;Zhang et al., 2021), considering that our method performs both the attach and merge operation in a single model, it can also be considered a classification task.","Though most of the existing studies consider the expansion a regression problem, considering that our method performs both the attach and merge operation in a single model, it can also be considered a classification task.","Modify,Fact/Evidence",Fact/Evidence
2903,28-ARR,28-ARR_v2_6@5,28-ARR_v1_6@5,"As a result, we propose two versions of TEAM, namely, TEAM-RG: Regression, and TEAM-CL: Classification to perform with explicit and implicit rankings.","As a result, we propose two versions of TEAM, namely, TEAM-RG: Regression, and TEAM-CL: Classification to perform with implicit and explicit rankings.","Modify,Clarity",Clarity
2904,28-ARR,28-ARR_v2_11@1,28-ARR_v1_9@1,"A WordNet may be defined by a collection of concepts connected by various semantic relationships such as hypernymy, hyponymy, troponymy, etc., where each concept is further defined by a set of attributes such as definition, synonyms, examples, etc (Bhattacharyya, 2010).","A WordNet may be defined by a collection of concepts connected by various semantic relationships such as hypernymy, hyponymy, troponymy, etc., where each concept is further defined by a set of attributes such as definition, synonyms, examples, etc.","Modify,Fact/Evidence",Fact/Evidence
2905,28-ARR,28-ARR_v2_14@1,28-ARR_v1_12@1,"The taxonomy T is arranged in a hierarchical manner with directed edges in E, as shown in Figure 1.",The taxonomy T is arranged in a hierarchical manner directed edges in E as shown in Figure 1.,"Modify,Grammar",Grammar
2906,28-ARR,28-ARR_v2_15@0,28-ARR_v1_13@0,"Attach (A) -An attach operation is performed when the concept q is not present in T. The objective of the attach operation is to identify the best matching parent node in taxonomy network known as anchor concept a = (d a , s a ), and insert a new concept q with an edge e : (a hyper − −− → q).","Attach (A) -An attach operation is performed when the concept q is not present in T. The objective of the attach operation is to identify the best matching parent node in taxonomy network known as anchor concept a = (d a , s a ), and insert a the new concept q with an edge e : (a hyper − −− → q).","Modify,Grammar",Grammar
2907,282-ARR,,282-ARR_v1_46@2,,Two nodes in G × d are neighbors if and only if the corresponding nodes in G d and G h are both neighbors.,"Delete,Fact/Evidence",Fact/Evidence
2908,282-ARR,,282-ARR_v1_61@2,,The details can refer to the Appendix or relevant references.,"Delete,Fact/Evidence",Fact/Evidence
2909,282-ARR,,282-ARR_v1_70@0,,Our work is closely related to unsupervised neural word alignment.,"Delete,Fact/Evidence",Fact/Evidence
2910,282-ARR,,282-ARR_v1_77@1,,"It can be clearly observed that by introducing Hierarchical Graph Random Walks in the decoding process, the ""hidden graphs"" can capture both the local and global dependencies of target sentences, making the model obtain more discriminative features representation which are further adopted to produce high-quality translation results.","Delete,Fact/Evidence",Fact/Evidence
2911,282-ARR,,282-ARR_v1_77@2,,"Besides, we provide the translation results among different variants of our proposal in Figure 7.","Delete,Fact/Evidence",Fact/Evidence
2912,282-ARR,282-ARR_v2_20@0,,Multi-task Learning,,"Add,Other",Other
2913,282-ARR,282-ARR_v2_26@0,,"In summary, we learn three tasks simultaneously, machine translation and word alignment via supervised signals while inferring syntactic graph of the target side as a byproduct in an unsupervised way.",,"Add,Fact/Evidence",Fact/Evidence
2914,282-ARR,282-ARR_v2_30@2,,"It treats any of the observed tokens as the central node alternately, to reward its significant dependencies from multi-hops neighbor and penalize leftovers.",,"Add,Fact/Evidence",Fact/Evidence
2915,282-ARR,282-ARR_v2_43@0,,Figure 3 illustrates the detailed process of introduced DGCN.,,"Add,Fact/Evidence",Fact/Evidence
2916,282-ARR,282-ARR_v2_46@1,,The learned representation simultaneously contains the content and structure information of the context for accurate word alignment.,,"Add,Fact/Evidence",Fact/Evidence
2917,282-ARR,282-ARR_v2_52@2,,"We refer to the original paper (Nikolentzos and Vazirgiannis, 2020) for more details.",,"Add,Fact/Evidence",Fact/Evidence
2918,282-ARR,282-ARR_v2_63@1,,"In the meantime, the syntactic information from both encoder and decoder are considered to access the robust and high-quality translation system.",,"Add,Fact/Evidence",Fact/Evidence
2919,282-ARR,282-ARR_v2_70@2,,"NAIVE-ATT (Garg et al., 2019) SD-SMOOTHGRAD (Ding et al., 2019) induces alignments from token saliency.",,"Add,Fact/Evidence",Fact/Evidence
2920,282-ARR,282-ARR_v2_70@3,,"ADDSGD (Zenkel et al., 2019) explicitly adds an extra attention layer on top of Transformer to predict the to-be-aligned target token.",,"Add,Fact/Evidence",Fact/Evidence
2921,282-ARR,282-ARR_v2_70@4,,"SHIFT-ATT (Chen et al., 2020) induces alignments when the to-be-aligned target token is the decoder input instead of the output.",,"Add,Fact/Evidence",Fact/Evidence
2922,282-ARR,282-ARR_v2_70@5,,"SHIFT-AET (Chen et al., 2020) extracts alignments from an additional module with supervision from symmetrized SHIFT-ATT alignments.",,"Add,Fact/Evidence",Fact/Evidence
2923,282-ARR,,282-ARR_v1_8@3,,(4) We will release our codebase upon acceptance.,"Delete,Claim",Claim
2924,282-ARR,282-ARR_v2_23@2,282-ARR_v1_20@2,"However, since we mainly focus on the word alignment dataset, we do not leverage the groundtruth of the target syntactic graph to maximize the likelihood.","However, we do not leverage the ground-truth of the target syntactic graph to maximize the likelihood.","Modify,Fact/Evidence",Fact/Evidence
2925,282-ARR,282-ARR_v2_23@3,282-ARR_v1_20@3,"In order to use the supervised signal of word alignment, we propose a proxy to construct the word alignment α with graph convolution networks:",We propose a proxy to construct the word alignment α with graph convolution networks.,"Modify,Claim",Claim
2926,282-ARR,282-ARR_v2_29@2,282-ARR_v1_24@2,"Afterwards, Dynamic Graph Convolution Networks are leveraged to adaptively adjust the graph topology for obtaining refined adjacent structures.","Therefore, Dynamic Graph Convolution Networks is leveraged to adaptively adjust the graph topology for obtaining refined adjacent structures.","Modify,Grammar",Grammar
2927,282-ARR,282-ARR_v2_30@3,282-ARR_v1_25@2,A light-weight two-layer pooling network is used to learn the mask which could be formulated as:,A light-weight two-layer pooling network is used to learn the mask.,"Modify,Clarity",Clarity
2928,282-ARR,282-ARR_v2_46@2,282-ARR_v1_41@1,"Finally, we choose the source token with the maximum attention weight towards the current target token:","Finally, we choose the source token with the maximum attention weight towards the current target token.","Modify,Grammar",Grammar
2929,282-ARR,282-ARR_v2_48@0,282-ARR_v1_43@0,"IMPORTANT Note that even during training, we only use the ground-truth syntactic graph of source side.","IMPORTANT Note that even during training, we only use the ground-truth syntactic graph of the source side.","Modify,Grammar",Grammar
2930,282-ARR,282-ARR_v2_48@1,282-ARR_v1_43@1,The syntactic graph of target side is inferred during training and its derived attention weights subsequently participate the loss calculation of word alignment task.,The syntactic graph of target side is inferred during training and its derived attention weights subsequently participate the word alignment loss calculation.,"Modify,Clarity",Clarity
2931,282-ARR,282-ARR_v2_50@1,282-ARR_v1_45@1,"The random walk kernel can quantify the similarity of two graphs based on the number of common walks, adopted to effectively capture structures of the input graphs when compared against a number of trainable ""hidden graphs"" 1 .","The random walk kernel can quantify the similarity of two graphs based on the number of common walks, adopted to effectively capture structures of the input graphs when compared against a number of trainable ""hidden graphs"" 1 (Nikolentzos and Vazirgiannis, 2020).","Modify,Fact/Evidence",Fact/Evidence
2932,282-ARR,282-ARR_v2_52@1,282-ARR_v1_46@1,"Consider the syntactic graph (denoted as G d ) in the decoder and a ""hidden graph"" G h , their direct product G × d is a graph over pairs of nodes from G d and G h .","Consider the syntactic graph (denoted as G d ) in the decoder and a ""hidden graph"" G h , their direct product G × d is a graph (Nikolentzos and Vazirgiannis, 2020) over pairs of nodes from G d and G h .","Modify,Fact/Evidence",Fact/Evidence
2933,282-ARR,282-ARR_v2_53@3,282-ARR_v1_46@6,We then perform the P -step (P ∈ N) random walk kernel which calculates the number of common walks of length p between two graphs:,We perform the P -step (P ∈ N) random walk kernel which calculates the number of common walks of length p between two graphs:,"Modify,Clarity",Clarity
2934,282-ARR,282-ARR_v2_62@0,282-ARR_v1_54@0,"Finally, the matrix R is flattened as supplementary representation to incorporate structural constraints into the decoder outputs from Transformer for guiding translation outputs.","Finally, the matrix R is flattened as supplementary representation to incorporate structural constraints into the decoder outputs from Transformer for producing translation results.","Modify,Clarity",Clarity
2935,282-ARR,282-ARR_v2_68@1,282-ARR_v1_59@1,Both the encoder and the decoder of Transformer have 4 layers of attentions with 4 attention heads each.,Both the encoder and decoder of the transformer have 4 layers of attentions with 4 attention heads each.,"Modify,Grammar",Grammar
2936,282-ARR,282-ARR_v2_68@5,282-ARR_v1_59@5,"We aggregated the 1and 2-hop neighbor of each target token in proposed dynamic graph convolutions for alignment, and performed P = {0, 1}-steps random walk with beam size to 4 in the decoding process of translation.","We aggregated the 1and 2-hop neighbor of each target token in proposed dynamic graph convolution for alignment, and performed P = {0, 1}-steps random walk with beam size to 4 in the decoding process of translation.","Modify,Grammar",Grammar
2937,282-ARR,282-ARR_v2_73@2,282-ARR_v1_63@2,"Specifically, it improves over GIZA++ by 2.0-7.2 AER points across different language pairs, demonstrating that building a neural aligner is better than statistical aligners.","Specifically, it improves over GIZA++ by 2.0-7.2 AER points across different language pairs, demonstrating that building a neural aligner is better than statistical aligners and having more potential to become a universal alignment tool.","Modify,Claim",Claim
2938,282-ARR,282-ARR_v2_79@3,282-ARR_v1_68@3,"However, continuing to increase the step (e.g., p = 3) length will not always improve the performance, since it not only introduces more parameters, but also is likely to confuse the model by the complicated closed-loop structure which is prevalent in the graph network.","However, continuing to increase the step (e.g., p = 3) length will not always improve the performance, since it not only introduces more parameters, but also is likely to confuse the model by the complicated closed-loop structure.","Modify,Claim",Claim
2939,282-ARR,282-ARR_v2_63@2,282-ARR_v1_68@5,"We also provide case studies of the experiments in Figure 5, demonstrating the learned ""hidden graphs"" can capture both the local and global dependencies of target sentences, leading to more discriminative features which are further adopted to guide the translation outputs.","We also provide case studies in the Appendix, demonstrating the learned ""hidden graphs"" can capture both the local and global dependencies of target sentences, leading to more discriminative features which are further adopted to produce high-quality translations.","Modify,Fact/Evidence",Fact/Evidence
2940,282-ARR,282-ARR_v2_2@2,282-ARR_v1_2@2,"In this work, we propose to incorporate the syntactic structure of both source and target tokens into the encoder-decoder framework, tightly correlating the internal logic of word alignment and machine translation for multitask learning.","In this work, to our best knowledge, we first propose to incorporate the syntactic structure of both source and target tokens into the encoder-decoder framework, tightly correlating the internal logic of word alignment and machine translation for multi-task learning.","Modify,Claim",Claim
2941,282-ARR,282-ARR_v2_9@0,282-ARR_v1_8@0,(1) We introduce Dynamic Graph Convolution Networks to sequentially infer the syntactic graphs of target tokens and further guide the word alignment learning.,(1) We introduce Dynamic Graph Convolution Networks to sequentially infer the syntactic graphs of target tokens to guide the word alignment learning.,"Modify,Clarity",Clarity
2942,282-ARR,282-ARR_v2_10@0,282-ARR_v1_8@2,"(3) Results on four language pairs demonstrate that our method is highly effective in such alignmentor translation-related NLP tasks, consistently out-performing baselines in alignment accuracy and translation quality.","(3) Results on four language pairs demonstrate that our method is highly effective in such alignment-or translation-related NLP tasks, consistently outperforming baselines in alignment accuracy and translation quality.","Modify,Grammar",Grammar
2943,282-ARR,282-ARR_v2_15@1,282-ARR_v1_13@1,"For decoding step t in layer l, α l t,i is the attention weight of the i-th position in the source, produced by an average of all the attention heads in Transformer (Vaswani et al., 2017).","For decoding step t in layer l, α l t,i is the attention weight of the i-th position in the source, produced by an average of all the attention heads in Transformer.","Modify,Fact/Evidence",Fact/Evidence
2944,282-ARR,282-ARR_v2_15@2,282-ARR_v1_13@2,"Although simple to implement, this method fails to obtain satisfactory alignment results Ding et al., 2019;Chen et al., 2020).","Although simple to implement, this method fails to obtain satisfactory alignment results (Li et al., 2019;Ding et al., 2019;Chen et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
2945,282-ARR,282-ARR_v2_17@1,282-ARR_v1_15@1,Existing NMT models are generally equipped with the encoder-decoder structure.,Existing NMT models are generally equipped with encoder-decoder structure.,"Modify,Grammar",Grammar
2946,282-ARR,282-ARR_v2_17@3,282-ARR_v1_15@3,"In this work, we adopt Transformer (Vaswani et al., 2017) as the baseline to build our method, which is also an encoder-decoder framework while each decoder layer attends to the encoder output with multi-head attention.","In this work, we adopt Transformer (Vaswani et al., 2017) as the baseline to build our method.","Merge+Modify,Clarity",Clarity
2948,282-ARR,282-ARR_v2_2@3,282-ARR_v1_2@3,"Particularly, we won't leverage any annotated syntactic graph of the target side during training, so we introduce Dynamic Graph Convolution Networks (DGCN) on observed target tokens to sequentially and simultaneously generate the target tokens and the corresponding syntactic graphs, and further guide the word alignment.","Particularly, we introduce Dynamic Graph Convolution Networks (DGCN) on observed target tokens to sequentially generate the syntactic graphs of target tokens and further guide the word alignment.","Modify,Claim",Claim
2949,284-ARR,,284-ARR_v1_33@1,,"For SPI and UOR objectives whose goal is to model high-level conversational features, we select samples from Chinese conversation dataset (i.e., DuConv) and English conversation datasets (i.e., Persona-Chat and CMU-DoG) with equal probability.","Delete,Fact/Evidence",Fact/Evidence
2950,284-ARR,,284-ARR_v1_42@0,,Table 2 presents the results of ablation studies on pre-training objectives and different modules.,"Delete,Fact/Evidence",Fact/Evidence
2951,284-ARR,,284-ARR_v1_55@4,,The statistics of the datasets are listed in Table 6.,"Delete,Fact/Evidence",Fact/Evidence
2952,284-ARR,,284-ARR_v1_62@0,,We report some more detailed experimental results here.,"Delete,Fact/Evidence",Fact/Evidence
2953,284-ARR,,284-ARR_v1_62@1,,Table 7 summarize the standard deviations of the main evaluation results on three datasets.,"Delete,Fact/Evidence",Fact/Evidence
2954,284-ARR,284-ARR_v2_35@2,,"For language in-domain evaluation, we compare to SimpleBERT (Shi and Lin, 2019), CSRL-BERT (Xu et al., 2021) and CSAGN (Wu et al., 2021b), all of which employ the Chinese pre-trained language model as the backbone.",,"Add,Fact/Evidence",Fact/Evidence
2955,284-ARR,284-ARR_v2_35@3,,"For cross-lingual evaluation, we compare to SimpleXLMR, CSRL-XLMR and CSAGN-XLMR by simply replacing the BERT backbones of those models with XLM-R. Additionally, we also compare to the back-translation baselines, i.e., Translate-test and Translate-train.",,"Add,Fact/Evidence",Fact/Evidence
2956,284-ARR,284-ARR_v2_35@4,,"Specifically, Translate-test means that the English test data is translated and projected to Chinese annotations using Google Translate (Wu et al., 2016) and the state-of-the-art word alignment toolkit Awesome-align(Dou and Neubig, 2021).",,"Add,Fact/Evidence",Fact/Evidence
2957,284-ARR,284-ARR_v2_35@5,,"Similarly, Translate-train means the Chinese training data is translated and projected to English annotations for training.",,"Add,Fact/Evidence",Fact/Evidence
2958,284-ARR,284-ARR_v2_35@6,,We feed the translated samples into CSAGN/CSAGN-XLMR to obtain the backtranslation results.,,"Add,Fact/Evidence",Fact/Evidence
2959,284-ARR,284-ARR_v2_44@1,,Table 6 lists the evaluation results on CANARD.,,"Add,Fact/Evidence",Fact/Evidence
2960,284-ARR,284-ARR_v2_58@2,284-ARR_v1_61@2,"For UniLM, the generation is same with the rewriting task, wherein the extracted semantic pairs, the context and the response are concatenated into a sequence and encoded with the special mask.","For UniLM, the generation process is same with the rewriting task, wherein the extracted semantic pairs, the context and the response are concatenated into a sequence and encoded with the special mask.","Modify,Clarity",Clarity
2961,284-ARR,284-ARR_v2_7@5,284-ARR_v1_6@5,"(4) We release our code, the new annotated English CSRL test sets and checkpoints of our best models to facilitate the further research at https://github. com/hahahawu/Zero-Shot-XCSRL.","(4) We will release our code, the new annotated English CSRL test sets and checkpoints of our best models to facilitate the further research.","Modify,Fact/Evidence",Fact/Evidence
2962,284-ARR,284-ARR_v2_10@7,284-ARR_v1_9@7,"We would like to distinguish our work from the work (Wu et al., 2021b) which purely focuses on improving the monolingual CSRL performance where they try to model predicate-aware representations.","We would like to distinguish our work from the concurrent work (Wu et al., 2021b) which purely focuses on improving the monolingual CSRL performance where they try to model predicate-aware representations.","Modify,Clarity",Clarity
2963,29-ARR,,29-ARR_v1_85@3,,One future direction to this work is to apply E-LANG to multiple Super and Swift models with different sizes.,"Delete,Claim",Claim
2964,29-ARR,29-ARR_v2_73@0,,Figure 3 illustrates the distribution of the energy scores across the input samples in GLUE tasks.,,"Add,Fact/Evidence",Fact/Evidence
2965,29-ARR,29-ARR_v2_73@1,,"For each task, the distributions of the samples processed by the Super and the Swift models are plotted.",,"Add,Fact/Evidence",Fact/Evidence
2966,29-ARR,29-ARR_v2_73@2,,"As shown, the samples routed to the Super model tend to have lower energy scores that are indeed considered as out-of-distribution samples for the Swift.",,"Add,Fact/Evidence",Fact/Evidence
2967,29-ARR,29-ARR_v2_73@3,,"On the other hand, in overall, higher scores are observed for the Swift distribution, that is for the samples handled by the Swift only.",,"Add,Fact/Evidence",Fact/Evidence
2968,29-ARR,29-ARR_v2_73@4,,"For some tasks such as MRPC and QNLI, the Swift is shown to be highly capable of handling the majority of the input samples.",,"Add,Fact/Evidence",Fact/Evidence
2969,29-ARR,29-ARR_v2_73@5,,"This is also supported by the results in Table 1 and Figure 2, where 91% (for MRPC) and 75% (for QNLI) of the samples are accurately processed by the Swift.",,"Add,Fact/Evidence",Fact/Evidence
2970,29-ARR,29-ARR_v2_73@6,,"In contrast, for other datasets including RTE and MNLI with Swift ratio of less than 50%, most of the samples are hard for the Swift, which are transferred to the Super model.",,"Add,Fact/Evidence",Fact/Evidence
2971,29-ARR,29-ARR_v2_73@7,,"Based on our experiments, the most optimal results for our joint inference framework is achieved when the crossing point of the two distributions (highlighted in green in the figures) is chosen as the threshold t in Equation (9).",,"Add,Fact/Evidence",Fact/Evidence
2972,29-ARR,29-ARR_v2_75@5,,"Another potential mechanism is the perplexity (Chen et al., 1998), but since it provides the same information as entropy, we did not add any extra experiment on it.",,"Add,Fact/Evidence",Fact/Evidence
2973,29-ARR,29-ARR_v2_13@1,29-ARR_v1_15@1,"To this end, inspired by the method in (Akbari et al., 2021), a routing mechanism empowered by energy-based models (EBM) is introduced to dynamically distribute the input samples between the Super and Swift models.","To this end, a routing mechanism empowered by energy-based models (EBM) is introduced to dynamically distribute the input samples between the Super and Swift models.","Modify,Fact/Evidence",Fact/Evidence
2974,29-ARR,29-ARR_v2_2@11,29-ARR_v1_2@11,Code and demo are available here.,Code is available in supplementary materials.,"Modify,Fact/Evidence",Fact/Evidence
2975,29-ARR,29-ARR_v2_44@0,29-ARR_v1_49@0,"In addition to energy, softmax and entropy (Xin et al., ACL 2020) scores can also be used for analyzing the Swift model's performance in the routing mechanism.","In addition to energy, softmax and entropy scores can also be used for analyzing the Swift model's performance in the routing mechanism.","Modify,Fact/Evidence",Fact/Evidence
2976,29-ARR,29-ARR_v2_72@1,29-ARR_v1_72@1,The curves related to all tasks are given in the supplementary materials.,The curves related to all tasks are given in the appendix.,"Modify,Clarity",Clarity
2977,29-ARR,29-ARR_v2_75@4,29-ARR_v1_74@4,"However, as also discussed in Sections 3.3.1 and 3.3.2, the energy score is still a better mechanism with about 14% less FLOPs.","However, as also discussed in Sections 3.3.1 and 3.3.2, the energy score is still a better routing mechanism with about 14% less FLOPs.","Modify,Clarity",Clarity
2978,29-ARR,29-ARR_v2_5@0,29-ARR_v1_5@0,"A common solution to speed-up the large language models is to apply model compression (Gupta et al., 2020).",A common solution to speed-up the large language models is to apply model compression .,"Modify,Fact/Evidence",Fact/Evidence
2979,29-ARR,29-ARR_v2_78@3,29-ARR_v1_77@4,The results show the effectiveness of E-LANG along with other compression techniques such as distillation.,The results in this experiment show the effectiveness of E-LANG along with other compression techniques such as distillation.,"Modify,Clarity",Clarity
2980,29-ARR,29-ARR_v2_78@4,29-ARR_v1_77@5,The trade-off curves for this experiment will be provided in the supplementary materials.,The trade-off curves for this experiment will be provided in the appendix.,"Modify,Clarity",Clarity
2981,29-ARR,29-ARR_v2_5@5,29-ARR_v1_5@5,"Instance-wise early-exiting (Xin et al., ACL 2020) is another technique, which allows a sample to adaptively choose from multiple available exit nodes if some conditions are met.","Instance-wise early-exiting is another technique, which allows a sample to adaptively choose from multiple available exit nodes if some conditions are met.","Modify,Fact/Evidence",Fact/Evidence
2982,29-ARR,29-ARR_v2_10@5,29-ARR_v1_11@5,"DeeBERT (Xin et al., ACL 2020) also proposed an instance-wise multi-exit method via the entropy of the output probability distribution to speed-up BERT inference.",DeeBERT also proposed an instance-wise multi-exit method via the entropy of the output probability distribution to speed-up BERT inference.,"Modify,Fact/Evidence",Fact/Evidence
2983,293-ARR,,293-ARR_v1_51@1,,Figure 2 shows the number of updates to convergence on the development dataset for controlled TS with/without CL.,"Delete,Fact/Evidence",Fact/Evidence
2984,293-ARR,293-ARR_v2_20@3,,"Figure 1 shows an example instantiation of the edit actions generated by the Levenshtein Edit Distance to transform the original input sequence (""a b c d e"") to the output sequence (""c a t"").",,"Add,Fact/Evidence",Fact/Evidence
2985,293-ARR,293-ARR_v2_20@4,,"In this example, the oracle action is to delete the tokens [""b"", ""d"", ""e""], reposition ""a"" and ""c"" and insert ""t"" at the appropriate position.",,"Add,Fact/Evidence",Fact/Evidence
2986,293-ARR,293-ARR_v2_20@5,,The reposition and the insertion modules are trained in a supervised fashion to predict these oracle operations during training.,,"Add,Fact/Evidence",Fact/Evidence
2987,293-ARR,293-ARR_v2_22@0,,"To tailor training to editing tasks, we propose to modify the roll-in policy to better match the intermediate sequences encountered at inference, and introduce a curriculum to increase the difficulty of oracle actions learned throughout training.",,"Add,Claim",Claim
2988,293-ARR,293-ARR_v2_23@0,,EDITING Roll-in Sequences generated using the roll-in policy control the search space explored during training.,,"Add,Fact/Evidence",Fact/Evidence
2989,293-ARR,293-ARR_v2_57@0,,Impact of EDITING roll-in,,"Add,Other",Other
2990,293-ARR,293-ARR_v2_62@0,,"We report the performance of the From Input model, when trained with curriculum only without the EDITING policy, i.e. ED I TCL-ED I T I N G in the same Table 6.",,"Add,Fact/Evidence",Fact/Evidence
2991,293-ARR,293-ARR_v2_62@1,,Both ED I T I N G roll-in and curriculum controlled roll-out provides complementary advantages to the model training as removing either results in the drop in performance across all the metrics for controllable TS.,,"Add,Fact/Evidence",Fact/Evidence
2992,293-ARR,293-ARR_v2_62@2,,"However, we observe larger drop in the scores when we do not apply the EDITING policy which shows that our proposed roll-in policy is necessary to reap the benefits of curriculum learning.",,"Add,Fact/Evidence",Fact/Evidence
2993,293-ARR,293-ARR_v2_63@3,,The tagging and editing models are trained independently.,,"Add,Fact/Evidence",Fact/Evidence
2994,293-ARR,293-ARR_v2_63@4,,"By contrast, we propose approaches to adapt NAR models designed for MT for these tasks and train an end-toend model to generate an edited sequence.",,"Add,Fact/Evidence",Fact/Evidence
2995,293-ARR,,293-ARR_v1_19@3,,"Motivated by these observations, we propose a new policy, EDITING, that allows exploration by injecting noise to the input sequence to generate new intermediate sequences for training.","Delete,Fact/Evidence",Fact/Evidence
2996,293-ARR,,293-ARR_v1_19@4,,This lets the model learn to fix errors without deviating from learning the task at hand.,"Delete,Fact/Evidence",Fact/Evidence
2997,293-ARR,293-ARR_v2_2@4,293-ARR_v1_2@4,Our approach significantly improves output quality on both tasks and controls output complexity better on the simplification task.,Our approach significantly improves output quality on both tasks and controls output complexity better on the controllable TS task.,"Modify,Claim",Claim
2998,293-ARR,293-ARR_v2_27@0,293-ARR_v1_21@0,"Resulting Algorithm Given a training dataset D = {y s , y * } M i=1 consisting of M samples, the difficulty score d(s i ) for each sample s i = {y s i , y * i } ∈ D is measured by the Levenshtein Distance between the input and the output sequence.","Resulting Algorithm Given a training dataset D = {y s , y * } M i=1 consisting of M samples, the difficulty score for each sample s i = {y s i , y * i } ∈ D is measured by the Levenshtein Distance between the input and the output sequence.","Modify,Clarity",Clarity
2999,293-ARR,293-ARR_v2_27@1,293-ARR_v1_21@1,"The cumulative density function (CDF) of the difficulty scores results in one difficulty CDF score per sample, d(s i ).","The cumulative density function (CDF) of the difficulty scores is then computed, resulting in one difficulty CDF score per sample, d(s i ).","Modify,Clarity",Clarity
3000,293-ARR,293-ARR_v2_27@2,293-ARR_v1_21@2,"At each training step t, we estimate the progress made by the learner by computing the competence of the model c(t) ∈ (0, 1] as follows:","At each training step t, we compute the current competence value c(t) ∈ (0, 1], given by:","Modify,Fact/Evidence",Fact/Evidence
3001,293-ARR,293-ARR_v2_32@0,293-ARR_v1_26@0,"We evaluate our approach on Controllable Simplification and Abstractive Summarization, two challenging sequence editing tasks that are motivated by real world information access needs.","We evaluate our approach on Controllable TS and Abstractive Summarization, two challenging sequence editing tasks that are motivated by real world information access needs.","Modify,Clarity",Clarity
3002,293-ARR,293-ARR_v2_33@0,293-ARR_v1_27@0,Controllable Simplification,Controllable Text Simplification,"Modify,Other",Other
3003,293-ARR,293-ARR_v2_52@2,293-ARR_v1_45@3,"On lower-cased outputs, our best model falls behind FELIX by 1.7 ROUGE points.","On lower-cased outputs, our best model falls behind FELIX by ∼ 1.7 ROUGE points.","Modify,Fact/Evidence",Fact/Evidence
3004,293-ARR,293-ARR_v2_52@4,293-ARR_v1_45@5,"As a result, this comparison confirms the promise of our approach overall.",So overall this comparison confirms the promise of our approach.,"Modify,Clarity",Clarity
3005,293-ARR,293-ARR_v2_61@1,293-ARR_v1_52@3,Our proposed criterion outperforms both task-specific (Grade Difference) and task-agnostic criteria (Length Ratio) on the Newsela Grade development set across all the metrics.,"Our proposed criterion outperforms both task-specific (""Grade Difference"") and task agnostic criteria (""Length Ratio"") on the Newsela Grade development set across all the metrics.","Modify,Grammar",Grammar
3006,293-ARR,293-ARR_v2_61@2,293-ARR_v1_52@4,"Length Ratio achieves better correlation with Edit distance than Grade Difference which is also reflected by its performance (SARI: +0.3, PCC: 0.032, ARI: 0.7) on the Controllable Simplification task.","""Length Ratio"" achieves better correlation with Edit distance than ""Grade Difference"" which is also reflected by its performance (SARI: +0.3, PCC: 0.032, ARI: 0.7) on the Controlled TS task.","Modify,Clarity",Clarity
3007,293-ARR,293-ARR_v2_64@2,293-ARR_v1_52@9,Chang et al. (2021) use Levenshtein edit distance as a sample difficulty criteria to order the samples for the task of data-to-text generation where the training model uses an AR seq2seq model.,Chang et al. (2021) use Levenshtein edit distance as a sample difficulty criteria to order the samples for the task of data-to-text generation where the training model using an AR seq2seq model.,"Modify,Grammar",Grammar
3008,293-ARR,293-ARR_v2_67@1,293-ARR_v1_55@1,"Together, these strategies improve output quality consistently on controllable simplification and abstractive summarization.","Together, these strategies improve output quality consistently on controlled TS and abstractive summarization.","Modify,Clarity",Clarity
3009,293-ARR,293-ARR_v2_11@2,293-ARR_v1_11@2,"Second, we introduce a training CURRICULUM to expose the model to training samples in order of increasing edit distance, thus gradually increasing the complexity of oracle edit operations that the model learns to imitate.","Second, we introduce a training curriculum to expose the model to training samples in order of increasing edit distance, thus gradually increasing the complexity of oracle edit operations that the model learns to imitate.","Modify,Grammar",Grammar
3011,293-ARR,293-ARR_v2_15@0,293-ARR_v1_15@1,"Models differ based on the nature of edit actions used and support different operations such as insertion, deletion, reposition and substitution.","Models support different operations such as insertion, deletion, reposition and substitution and are trained with different types of roll-in policies (mixed/learned/expert).","Merge+Modify,Claim",Claim
3012,293-ARR,293-ARR_v2_18@2,293-ARR_v1_16@0,Training NAR models are typically trained via imitation learning that uses a roll-in policy and a roll-out policy.,Training NAR models are trained via imitation learning that uses a roll-in policy to generate the sequences that the model learns to refine from and a roll-out policy to estimate the cost-to-go from the generated roll-in sequences to the desired output sequences.,"Split+Modify,Clarity",Clarity
3013,293-ARR,293-ARR_v2_18@3,293-ARR_v1_16@0,The roll-in policy is used to generate the sequences that the model learns to refine from.,Training NAR models are trained via imitation learning that uses a roll-in policy to generate the sequences that the model learns to refine from and a roll-out policy to estimate the cost-to-go from the generated roll-in sequences to the desired output sequences.,"Split+Modify,Clarity",Clarity
3014,293-ARR,293-ARR_v2_18@4,293-ARR_v1_16@0,A roll-out policy is then used to estimate the cost-to-go from the generated roll-in sequences to the desired output sequences.,Training NAR models are trained via imitation learning that uses a roll-in policy to generate the sequences that the model learns to refine from and a roll-out policy to estimate the cost-to-go from the generated roll-in sequences to the desired output sequences.,"Split+Modify,Clarity",Clarity
3015,293-ARR,293-ARR_v2_18@5,293-ARR_v1_16@1,The cost-to-go is calculated by comparing the model actions to oracle demonstrations.,The latter is performed by comparing the model actions to oracle demonstrations.,"Modify,Clarity",Clarity
3016,293-ARR,293-ARR_v2_20@0,293-ARR_v1_16@3,"For EDITOR, the roll-in sequences for the reposition (or insertion) module are stochastic mixtures (parameterized by α or β) of the output of the insertion (or reposition) module or a noised version of the output sequence.","For EDITOR, the roll-in sequences for the reposition (or insertion) module are stochastic mixtures of the output of the insertion(or reposition) module or a noised version of the output sequence.","Modify,Fact/Evidence",Fact/Evidence
3017,293-ARR,293-ARR_v2_24@0,293-ARR_v1_19@0,"While typically, the roll-in policy is a stochastic mixture of the model and the expert demonstrations as described above, the noise incurred early on due to the large difference between the expert demonstration and the learner's policy actions may hurt overall performance (Brantley et al., 2019;He et al., 2012;Leblond et al., 2018).","While typically, the roll-in policy is a stochastic mixture of the model and the oracle demonstrations as described above, the noise incurred early on due to the large difference between the expert demonstration and the learner's policy actions may hurt overall performance (Brantley et al., 2019;He et al., 2012;Leblond et al., 2018).","Modify,Clarity",Clarity
3018,296-ARR,,296-ARR_v1_64@1,,"We conduct experiments on BERTbase (Devlin et al., 2019) and compare robust accuracy of Flooding-X with other adversarial training algorithms to demonstrate its strength.","Delete,Fact/Evidence",Fact/Evidence
3019,296-ARR,,296-ARR_v1_81@11,,"In the cases of AG News and QNLI, our re-implement the results of BERT fine-tuning to 97.0 and 91.6 respectively so Flooding-X does not surpass the reported performance, but still outperforming the baselines of our implementation.","Delete,Fact/Evidence",Fact/Evidence
3020,296-ARR,,296-ARR_v1_93@2,,Jia and Liang (2017) mislead MRC models via a human-involved phrase generation method.,"Delete,Fact/Evidence",Fact/Evidence
3021,296-ARR,,296-ARR_v1_96@5,,This criterion carries is theoretically proved to have a close relation with generalization and overfitting.,"Delete,Claim",Claim
3022,296-ARR,296-ARR_v2_24@0,,"Flooding is designed for overfitting, but why is it valid for adversarial robustness?",,"Add,Claim",Claim
3023,296-ARR,296-ARR_v2_30@3,,"Among all the training methods involved in Figure 1, Flooding-X leads to the most smooth loss landscape, indicating an overall more robust model against attacks.",,"Add,Claim",Claim
3024,296-ARR,296-ARR_v2_73@0,,"Flooding Flooding (Ishida et al., 2020) has been introduced in detail in section 2.1.",,"Add,Fact/Evidence",Fact/Evidence
3025,296-ARR,296-ARR_v2_73@1,,We implemented Flooding and search for the flooding level at the step of 0.01 according to the tradition.,,"Add,Fact/Evidence",Fact/Evidence
3026,296-ARR,296-ARR_v2_73@2,,The best result for each dataset is reported.,,"Add,Fact/Evidence",Fact/Evidence
3027,296-ARR,296-ARR_v2_96@1,,"As is shown in Figure 4, Flooding-X improves BERT's adversarial robustness to a relatively high level at epoch 5, which is competitive with that of standard fine-tuning at the last epoch.",,"Add,Fact/Evidence",Fact/Evidence
3028,296-ARR,296-ARR_v2_96@2,,"Besides, Flooding-X accelerates the increase of robustness at late training stage.",,"Add,Fact/Evidence",Fact/Evidence
3029,296-ARR,296-ARR_v2_96@3,,"Starting from epoch 7 our method enables a steep increment on the accuracy under attack, which is due to the effect of Flooding that forces the model to perform a more fierce ""random walk"" since the training loss of most batches are going below the flooding level.",,"Add,Claim",Claim
3030,296-ARR,296-ARR_v2_96@4,,"It is also demonstrated that the training loss stops approaching zero under the constraint of Flooding-X, while the standard fine-tuning and adversarial training continues to decrease the training loss towards zero which brings about the risk of overfitting.",,"Add,Claim",Claim
3031,296-ARR,296-ARR_v2_2@5,296-ARR_v1_2@5,"We experimentally show that our method improves BERT's resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks.","We experimentally show that our method improves Bert's resistance to textual adversarial attacks by a large margin, and achieves state-of-the-art robust accuracy on various text classification and GLUE tasks.","Modify,Grammar",Grammar
3032,296-ARR,296-ARR_v2_4@0,296-ARR_v1_4@0,"Despite their impressive performances on various NLP tasks, deep neural networks such as BERT (Devlin et al., 2019) suffer a sharp performance degradation against deliberately constructed adversarial attacks (Zeng et al., 2021;Wang et al., 2021b;Nie et al., 2020;Zang et al., 2020;Ren et al., 2019;Zhang et al., 2019).","Despite their impressive performances on various NLP tasks, deep neural networks such as BERT (Devlin et al., 2019) suffer a sharp decline facing deliberately constructed adversarial attacks (Zeng et al., 2021;Nie et al., 2020;Zang et al., 2020;Ren et al., 2019;Zhang et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
3033,296-ARR,296-ARR_v2_4@1,296-ARR_v1_4@1,"A line of work attempts to alleviate this problem by creating adversarially robust models via defense methods, including adversarial data augmentation (Chen et al., 2021;Si et al., 2021), regularization (Wang et al., 2021a), and adversarial training (Wang et al., 2020;Zhu et al., 2020;Madry et al., 2018).","A line of works attempt to alleviate this problem by creating adversarially robust models via defense methods, including adversarial data augmentation (Chen et al., 2021;Si et al., 2021), regularizing (Wang et al., 2020a), and adversarial training (Wang et al., 2020b;Zhu et al., 2019;Madry et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
3034,296-ARR,296-ARR_v2_67@0,296-ARR_v1_66@0,"We compare Flooding-X with three adversarial training algorithms, one regularization method as well as the vanilla Flooding.",We compare our proposed Flooding-X with three adversarial training algorithms and one regularization method.,"Modify,Fact/Evidence",Fact/Evidence
3035,296-ARR,296-ARR_v2_69@0,296-ARR_v1_68@0,FreeLB Zhu et al. (2020) propose FreeLB to improve the generalization of language models.,FreeLB Zhu et al. (2019) propose FreeLB to improve the generalization of language models.,"Modify,Fact/Evidence",Fact/Evidence
3036,296-ARR,296-ARR_v2_72@0,296-ARR_v1_70@0,"InfoBERT InfoBERT (Wang et al., 2021a) leverages two mutual-information-based regularizers for robust model training, suppressing noisy mutual information while increasing mutual information between local stable features and global features.","InfoBERT InfoBERT (Wang et al., 2020a) leverages two mutual-information-based regularizers for robust model training, suppressing noisy mutual information while increasing mutual information between local stable features and global features.","Modify,Fact/Evidence",Fact/Evidence
3037,296-ARR,296-ARR_v2_4@2,296-ARR_v1_4@2,Data augmentation and adversarial training rely on additional adversarial examples generated either by hand-crafting or conducting gradient ascent on the clean data for virtual adversarial samples.,Data augmentation and adversarial training rely on extra adversarial examples generated either by handcrafting or conducting gradient ascent on the clean data for virtual adversarial samples.,"Modify,Clarity",Clarity
3038,296-ARR,296-ARR_v2_80@1,296-ARR_v1_77@1,Robust models are expected to score low on Suc%.,Robust models are expected to score low at Suc%.,"Modify,Grammar",Grammar
3039,296-ARR,296-ARR_v2_5@0,296-ARR_v1_4@3,"However, generating adversarial examples scales up the cost of training computationally, which makes vanilla adversarial training almost impractical on large-scale NLP tasks like QNLI (Questionanswering NLI, Rajpurkar et al., 2016).","However, generating adversarial examples scales up the cost of training computationally, which makes vanilla adversarial training almost impractical on large-scale NLP tasks like QNLI (Questionanswering NLI).","Modify,Fact/Evidence",Fact/Evidence
3040,296-ARR,296-ARR_v2_87@1,296-ARR_v1_81@8,"Under most cases, our method remains the best performing algorithm against BERTAttack (Li et al., 2020) and TextBugger (Li et al., 2018b).","Under most cases, our method remains the best performing algorithm facing BERTAttack (Li et al., 2020) and TextBugger (Li et al., 2018b).","Modify,Clarity",Clarity
3041,296-ARR,296-ARR_v2_87@3,296-ARR_v1_81@10,"As a byproduct, the clean accuracy of our method is also competing among the baseline methods, which is inherent to the vanilla Flooding that aims at better generalization.","As a byproduct, the clean accuracy of our method is also the best among all the baseline methods, which is inherent to the vanilla Flooding that aims at better generalization.","Modify,Claim",Claim
3042,296-ARR,296-ARR_v2_5@1,296-ARR_v1_4@4,"An increasing amount of researchers express their concern about the time-consuming property of standard adversarial training and offer cheaper but competitive alternatives by (i) replacing the perturbation generation with an additional generator network (Baluja and Fischer, 2017;Xiao et al., 2018), or by (ii) combining the gradient computation of clean data and perturbations into one backward pass (Shafahi et al., 2019).","Increasing researches express their concern of the time-consuming property of standard adversarial training and offer cheaper but competitive alternatives by (i) replacing the perturbation generation with an extra generator network (Baluja and Fischer, 2017;Xiao et al., 2018), or by (ii) combining the gradient computation of clean data and perturbations into one backward pass (Shafahi et al., 2019).","Modify,Clarity",Clarity
3043,296-ARR,296-ARR_v2_99@1,296-ARR_v1_96@0,"One way of identifying overfitting is to see whether the generalization gap, i.e., the test minus the training loss, is increasing or not (Salakhutdinov, 2014).","One way of identifying overfitting is to see whether the generalization gap, i.e., the test minus the training loss, is increasing or not (Goodfellow et al., 2016).","Modify,Fact/Evidence",Fact/Evidence
3044,296-ARR,296-ARR_v2_5@2,296-ARR_v1_4@5,These approaches still rely on additional adversarial examples generated either by the model itself or by an extra module.,These approaches still rely on extra adversarial examples generated either by the model itself or by an extra module.,"Modify,Clarity",Clarity
3045,296-ARR,296-ARR_v2_101@3,296-ARR_v1_98@3,"Experimental results prove that gradient accordance is closely related with the phenomenon of overfitting, equipped with which Flooding-X beats the well-received adversarial training methods and achieves state-of-the-art performances on various NLP tasks against different textual attack methods.","Experimental results prove that gradient accordance is closely related with the phenomenon of overfitting, equipped with which Flooding-X beats the well-received adversarial training methods and achieves state-of-the-art performances on various NLP tasks facing different textual attack methods.","Modify,Clarity",Clarity
3046,296-ARR,296-ARR_v2_101@5,296-ARR_v1_98@5,We call for further exploration and deeper understanding in the nature of adversarial robustness and attacks.,We call for further exploring and deeper understanding in the nature of adversarial robustness and attacks.,"Modify,Clarity",Clarity
3047,296-ARR,296-ARR_v2_9@0,296-ARR_v1_8@0,"1) We analyze and demonstrate the effectiveness of Flooding, which is designed for generalization, in improving adversarial robustness especially in NLP domain.","1) We propose a novel method, Flooding-X, that achieves state-of-the-art robust accuracy for BERT on various tasks, which is adversarial-example-free and takes no more training time than fine-tuning.","Modify,Fact/Evidence",Fact/Evidence
3048,296-ARR,296-ARR_v2_30@1,296-ARR_v1_28@1,"Generally, the flooded model is guided into an area with a smooth parameter landscape that leads to better adversarial robustness (Stutz et al., 2021;Prabhu et al., 2019;Yu et al., 2018;Li et al., 2018a).","Generally, the flooded model is guided into an area with a smooth parameter landscape that leads to better adversarial robustness (Prabhu et al., 2019;Yu et al., 2018;Li et al., 2018a).","Modify,Fact/Evidence",Fact/Evidence
3049,296-ARR,296-ARR_v2_30@2,296-ARR_v1_28@2,"As is demonstrated in Figure 1, adversarial training brings about a smoother loss change to the model when the input embedding is perturbed by Gaussian random noise, which is closely related the stronger adversarial robustness.","As is demonstrated in Figure 1, adversarial training brings about a smoother loss change to the model when the input embedding is perturbed by Gaussian random noise.","Modify,Claim",Claim
3050,3-ARR,,3-ARR_v1_87@4,,Our code can be found in Footnote 1.,"Delete,Fact/Evidence",Fact/Evidence
3051,3-ARR,,3-ARR_v1_95@2,,"We evaluate such performance in Table 4 by Precision, Recall, and F1 scores against manually annotated evidence sentences that are provided in the dataset.","Delete,Fact/Evidence",Fact/Evidence
3052,3-ARR,,3-ARR_v1_95@3,,"In this analysis, we do not perform relation prediction, but concern about entity pairs knowingly having certain relations.","Delete,Fact/Evidence",Fact/Evidence
3053,3-ARR,,3-ARR_v1_103@1,,"This shows the robustness of SIEF-trained models, as they are less sensitive to non-evidences sentences for DocRE.","Delete,Claim",Claim
3054,3-ARR,,3-ARR_v1_7@2,,"Moreover, the proposed approach outperforms a variety of models on DocRED dataset.","Delete,Fact/Evidence",Fact/Evidence
3055,3-ARR,3-ARR_v2_60@2,,Moreover it should be calculated repeatedly once the parameter of the model is updated.,,"Add,Claim",Claim
3056,3-ARR,3-ARR_v2_4@2,3-ARR_v1_4@2,"Different from sentence-level relation extraction (Zeng et al., 2014;Xiao and Liu, 2016;Song et al., 2019), the supporting evidence in the DocRE setting may involve multiple sentences scattering in the document.","Different from sentence-level relation extraction (Zeng et al., 2014;Xiao and Liu, 2016;Yu et al., 2017;Song et al., 2019), the supporting evidence in the DocRE setting may involve multiple sentences scattering in the document.","Modify,Fact/Evidence",Fact/Evidence
3057,3-ARR,3-ARR_v2_68@1,3-ARR_v1_65@1,Their approach is much slower than ours.,Their approach is much computationally slower than ours.,"Modify,Fact/Evidence",Fact/Evidence
3058,3-ARR,3-ARR_v2_74@2,3-ARR_v1_72@1,"GAIN constructs two graphs: mention-document graphs and entity graphs, and performs graph and path reasoning over the two graphs separately.","GAIN constructs two graphs: mention-document graphs and entity graphs separately, and performs graph and path reasonings.","Modify,Clarity",Clarity
3059,3-ARR,3-ARR_v2_84@0,3-ARR_v1_81@0,"We also evaluated our approach on DialogRE (V2, Yu et al., 2020), which contains 36 relation types, 17 of which are interpersonal.","We also evaluated our approach on DialogRE (V2, Yu et al., 2020), which contains 36 relation types (17 of which are interpersonal).","Modify,Clarity",Clarity
3060,3-ARR,3-ARR_v2_84@1,3-ARR_v1_81@1,"We followed the standard split with 1073 training dialogues, 358 validation, and 357 test.","We followed the standard split of 1073 training dialogues, 358 validation, and 357 test.","Modify,Grammar",Grammar
3061,3-ARR,3-ARR_v2_86@0,3-ARR_v1_83@0,"For DocRED, we consider additional competing methods: Two Phase , which first predicts whether the entity pair has a relation and then predicts the relation type; LSR (Nan et al., 2020), which constructs the graph by inducing a latent document-level graph; Reconstructor (Xu et al., 2021b), which encourages the model to reconstruct a reasoning path during training; DRN (Xu et al., 2021a), which considers different reasoning skills explicitly and uses graph representation and context representation to model the reasoning skills; ATLOP (Zhou et al., 2021), which aggregates contextual information by the Transformer attentions and adopts an adaptive threshold for different entity pairs; and DocuNet (Zhang et al., 2021), which models DocRE as a semantic segmentation task.","For DocRED, we consider additional competing methods as follows: Two Phase , which first predicts whether the entity pair has a relation and then predicts the relation type.","Merge+Modify,Clarity",Clarity
3066,3-ARR,3-ARR_v2_86@0,3-ARR_v1_84@3,"For DocRED, we consider additional competing methods: Two Phase , which first predicts whether the entity pair has a relation and then predicts the relation type; LSR (Nan et al., 2020), which constructs the graph by inducing a latent document-level graph; Reconstructor (Xu et al., 2021b), which encourages the model to reconstruct a reasoning path during training; DRN (Xu et al., 2021a), which considers different reasoning skills explicitly and uses graph representation and context representation to model the reasoning skills; ATLOP (Zhou et al., 2021), which aggregates contextual information by the Transformer attentions and adopts an adaptive threshold for different entity pairs; and DocuNet (Zhang et al., 2021), which models DocRE as a semantic segmentation task.","DocuNet (Zhang et al., 2021), which models DocRE as a semantic segmentation task.","Merge+Modify,Clarity",Clarity
3067,3-ARR,3-ARR_v2_89@0,3-ARR_v1_87@0,"We use the repositories 2,3,4,5 of base models to implement our approach.","We use the repository 2,3,4,5 of base models to implement our approach.","Modify,Grammar",Grammar
3069,3-ARR,3-ARR_v2_93@1,3-ARR_v1_91@0,"As seen, the results are consistent with the improvement on DocRED, as our SIEF largely improves F1 and F1 c for both base models.","We further conducted experiments on the DialogRE dataset, and compare our approach with the BERT baselines in Yu et al. (2020) the results are consistent with the improvement on DocRED, as our SIEF largely improves F1 and F1 c for both base models.","Split+Modify,Clarity",Clarity
3070,3-ARR,3-ARR_v2_5@5,3-ARR_v1_5@2,"The evidence sentences are {1,2}, and humans can easily identify such a relation when reading sentences {1,2} only.","The evidence sentences are [1,2], and humans can easily identify such a relation when reading sentences [1,2] only.","Modify,Grammar",Grammar
3071,3-ARR,3-ARR_v2_99@1,3-ARR_v1_99@1,"This further verifies that our SIEF framework not only improves relation extraction performance, but also is able to better detect evidence and non-evidence sentences, which is important for the interpretability of machine learning models.","This further verifies that our SIEF framework not only improves relation extraction performance, but also is able to better detect evidence and non-evidence sentences, which is important for the robustness of machine learning models.","Modify,Claim",Claim
3072,3-ARR,3-ARR_v2_103@1,3-ARR_v1_103@3,Our SIEF framework has one hyperaparameter β that controls how strict we treat a sentence as evidence or nonevidence (Section 4.3).,Our SIEF framework has one hyperaparameter β that controls how strict we treat a sentence as evidence or nonevidence (in Section 4.3).,"Modify,Grammar",Grammar
3073,3-ARR,3-ARR_v2_5@6,3-ARR_v1_5@3,"However, the recent DocRE model GAIN (Zeng et al., 2020) identifies the relation ""MemberOf"" correctly from the entire document {1,2,3}, but predicts ""not MemberOf"" from sentences {1,2}.","However, the recent DocRE model GAIN (Zeng et al., 2020) identifies the relation ""MemberOf"" correctly from the entire document [1,2,3], but predicts ""not MemberOf"" from sentences [1,2].","Modify,Grammar",Grammar
3074,3-ARR,3-ARR_v2_5@7,3-ARR_v1_5@4,"Intuitively, removing sentence {3} should not change the result, as this sentence does not provide information regarding whether ""MemberOf"" holds or not for the two entities.","Intuitively, removing sentence [3] should not change the results, as this sentence does not provide information regarding whether ""not MemberOf"" holds or not for the two entities.","Modify,Grammar",Grammar
3075,3-ARR,3-ARR_v2_10@1,3-ARR_v1_9@2,"Pantel and Pennacchiotti (2006) propose a rule-based approach, and Mintz et al. (2009) manually design features for classifying relations.","Pantel and Pennacchiotti (2006) propose a rule-based approach, and Mintz et al. (2009) design features for classifying relations.","Modify,Fact/Evidence",Fact/Evidence
3076,3-ARR,3-ARR_v2_11@0,3-ARR_v1_10@0,"Document-level relation extraction (DocRE) is attracting increasing attention in the community, as it considers the interactions of entity mentions expressed in different sentences Yao et al., 2019).","Document-level relation extraction (DocRE) is attracting increasing attention in the community, as it considers the interactions across entity mentions expressed in different sentences Yao et al., 2019).","Modify,Grammar",Grammar
3077,3-ARR,3-ARR_v2_16@0,3-ARR_v1_15@0,"In this section, we present the formulation of document relation extraction (DocRE).","In this section, we present formulation of document relation extraction (DocRE).","Modify,Grammar",Grammar
3078,3-ARR,3-ARR_v2_16@1,3-ARR_v1_15@1,"Consider an unstructured document comprising N sentences, D = {s 1 , s 2 , • • • , s N }, where each sentence s n is a sequence words.","Consider an unstructured document comprising N sentences, D = {s 1 , s 2 , • • • , s N }, where each sentence s n are a sequence words.","Modify,Grammar",Grammar
3079,3-ARR,3-ARR_v2_16@2,3-ARR_v1_15@2,"In a DocRE dataset, the document D is typically annotated with entity mentions, each mention (e.g., U.S. and USA) labeled by its conceptual entity e and its entity type (e.g., location).","Typically, the document D is annotated with entity mentions, each mention (e.g., U.S. and USA) labeled by its conceptual entity e and its entity type (e.g., location).","Modify,Clarity",Clarity
3080,3-ARR,3-ARR_v2_27@4,3-ARR_v1_27@4,"Then, Sections 4.2 and 4.3 present our approach that encourages the model to produce the same output distribution, when the entire document is fed as input and when non-evidence sentences are removed.","Then, Sections 4.2 and 4.3 present our approach encouraging the model to produce the same output distribution, when the entire document is fed as input and when non-evidence sentences are removed.","Modify,Clarity",Clarity
3133,306-ARR,,306-ARR_v1_46@1,,The corresponding p-value which indicates statistical significance can be obtained:,"Delete,Fact/Evidence",Fact/Evidence
3134,306-ARR,306-ARR_v2_8@5,,"Pagnoni et al. (2021) made a careful categorization of factual errors and benchmarked factuality metrics using human annotations they collected on CNN/DailyMail and XSum dataset (Narayan et al., 2018).",,"Add,Fact/Evidence",Fact/Evidence
3135,306-ARR,306-ARR_v2_9@2,,"Khalifa et al. (2021) designed several tricks to address the special challenges in dialogue summarization and analysized their effects, such as using name substitution to cope with the presence of multiple speakers in dialogues.",,"Add,Fact/Evidence",Fact/Evidence
3136,306-ARR,306-ARR_v2_9@4,,No manual evaluation was involved in these studies.,,"Add,Fact/Evidence",Fact/Evidence
3137,306-ARR,306-ARR_v2_50@1,,"3. In each dimension, metrics which are strongly correlated with human judgments exist, but few metrics show significant strengths in all four dimensions.",,"Add,Fact/Evidence",Fact/Evidence
3138,306-ARR,306-ARR_v2_62@0,,Table 5 shows the result of model evaluation using annotations from Amazon Mechanical Turk.,,"Add,Fact/Evidence",Fact/Evidence
3139,306-ARR,306-ARR_v2_62@1,,"The performance of the models is indistinguishable, which is not consistent with our observation.",,"Add,Fact/Evidence",Fact/Evidence
3140,306-ARR,306-ARR_v2_64@0,,"Table 6 shows the value of ROUGE-1, ROUGE-2 and ROUGE-L on the test set of SAMSum for the models we reproduced.",,"Add,Fact/Evidence",Fact/Evidence
3141,306-ARR,306-ARR_v2_64@1,,The results is close to those in Gliwa et al. (2019) and Wu et al. (2021).,,"Add,Fact/Evidence",Fact/Evidence
3142,306-ARR,306-ARR_v2_19@1,306-ARR_v1_20@0,"10 Embedding average (Landauer and Dumais, 1997) is an embedding based metric computing the cosine similarity between the embeddings of two texts.","Embedding average (Sharma et al., 2017) is an embedding based metric computing the cosine similarity between the embeddings of two texts.","Modify,Fact/Evidence",Fact/Evidence
3143,306-ARR,306-ARR_v2_24@0,306-ARR_v1_25@0,"FactCC (Kryscinski et al., 2020) is a metric based on entailment classification.","FactCC (Kryscinski et al., 2020) is an entailment classification metric.","Modify,Clarity",Clarity
3144,306-ARR,306-ARR_v2_39@3,306-ARR_v1_40@3,"For each dimension, we removed the noise separately and calculated the the Krippendorff's alpha coefficient (Krippendorff, 2011).","For each dimension, we removed the noise separately and calculated the the Krippendorffs alpha coefficient (Krippendorff, 2011).","Modify,Grammar",Grammar
3145,306-ARR,306-ARR_v2_39@4,306-ARR_v1_40@4,"We found the inter-annotator interval metric to be within an acceptable range -from 0.5621 to 0.7564, as detailed in Table 2.","We found the inter-annotator interval kappa to be within an acceptable range -from 0.5621 to 0.7564, as detailed in Table 2.","Modify,Clarity",Clarity
3146,306-ARR,306-ARR_v2_39@6,306-ARR_v1_40@6,"At last, we use the average of the cleaned data to represent the human evaluation score of an summary on a dimension.","At last, we use the average of the remaining data to represent the human evaluation score of an summary on a dimension.","Modify,Clarity",Clarity
3147,306-ARR,306-ARR_v2_59@5,306-ARR_v1_61@5,"We hope that researchers in the field recognize the importance of evaluation in current research, choose some other metrics in addition to ROUGE when evaluating models, propose automatic evaluation metrics that can be better adapted to the field of dialogue summarization based on our work.","We hope that researchers in the field recognize the importance of evaluation in current research, choose some metrics other than ROUGE when evaluating models, propose automatic evaluation metrics that can be better adapted to the field of dialogue summarization based on our work.","Modify,Clarity",Clarity
3148,306-ARR,306-ARR_v2_8@6,306-ARR_v1_9@5,"Notably, Gabriel et al. (2021) is one of the few current studies using the dialogue summarization dataset SAMSum (Gliwa et al., 2019) for meta-evaluation, but it focuses on factual consistency and selects a small number of metrics.","Gabriel et al. (2021) is one of the few current studies using the dialogue summarization dataset SAMSum (Gliwa et al., 2019) for meta-evaluation, but it focuses on factual consistency and selects a small number of metrics.","Modify,Clarity",Clarity
3149,306-ARR,306-ARR_v2_18@2,306-ARR_v1_19@2,"6 BARTScore treats evaluation as a nature language generation task and assumes that when the quality of generated text is better, the conditional language model has a higher probability of generating it from the source text or the reference, or is more likely to generate the reference from it.",5 BARTScore assumes that models trained to convert the generated text to/from a reference output or the source text will achieve higher scores when the generated text is better.,"Modify,Claim",Claim
3150,306-ARR,306-ARR_v2_18@5,306-ARR_v1_19@5,"Specifically, it measures the performance boost of the masked language modeling for BERT utilizing the summary in two different ways.","Specifically, it measures the performance boost of BERT by utilizing the summary in two different ways.","Modify,Fact/Evidence",Fact/Evidence
3151,308-ARR,,308-ARR_v1_71@2,,"For the classification tasks the impact of the adversarial attacks was measured using fooling rate, whilst for the L-Bus dataset task, the average output score from the system is given.","Delete,Fact/Evidence",Fact/Evidence
3152,308-ARR,,308-ARR_v1_71@3,,Figure A.2 gives the encoder embedding space PCA residue plots for all the datasets not included in the main text.,"Delete,Fact/Evidence",Fact/Evidence
3153,308-ARR,,308-ARR_v1_72@1,,"For completeness, Table A.2 presents the success of the adversarial attack detection approaches from the main text on two other popular adversarial attack approaches:","Delete,Fact/Evidence",Fact/Evidence
3154,308-ARR,,308-ARR_v1_74@0,,"Table A.3 compares the impact on error sizes (using l 2 and l ∞ norms) and the residue plot metric, N σ for the original text space discrete attacks and an artificial input embedding space continuous attack.","Delete,Fact/Evidence",Fact/Evidence
3155,308-ARR,,308-ARR_v1_74@1,,The purpose of this table is to present the results for the datasets not included in the main text in Table 6.,"Delete,Fact/Evidence",Fact/Evidence
3156,308-ARR,308-ARR_v2_55@2,,The L-Bus data is from a multi-level prompt-response free speaking test i.e. candidates from a range of proficiency levels provide open responses to prompted questions.,,"Add,Fact/Evidence",Fact/Evidence
3157,308-ARR,308-ARR_v2_55@3,,"Based on this audio input a system must predict a score of 0-6 corresponding to the 6 CEFR (Council of Europe, 2001) grades.",,"Add,Fact/Evidence",Fact/Evidence
3158,308-ARR,308-ARR_v2_55@4,,This audio data was transcribed using an Automatic Speech Recognition system with an average word error rate of 19.5%.,,"Add,Fact/Evidence",Fact/Evidence
3159,308-ARR,308-ARR_v2_70@0,,"Limitations, Risks and Ethics",,"Add,Other",Other
3160,308-ARR,308-ARR_v2_72@0,,Acknowledgements,,"Add,Other",Other
3161,308-ARR,308-ARR_v2_73@0,,"This paper reports on research supported by Cambridge Assessment, University of Cambridge.",,"Add,Fact/Evidence",Fact/Evidence
3162,308-ARR,308-ARR_v2_73@1,,Thanks to Cambridge English Language Assessment for support and access to the Linguaskill-Business data.,,"Add,Fact/Evidence",Fact/Evidence
3163,308-ARR,308-ARR_v2_73@2,,The authors would also like to thank members of the ALTA Speech Team.,,"Add,Fact/Evidence",Fact/Evidence
3164,308-ARR,308-ARR_v2_34@6,308-ARR_v1_35@6,"For this situation, a simple solution is concatenation (Wang and Bansal, 2018;Blohm et al., 2018), where for example, the same N -length sequence of words is appended to each input sequence of words, as described in Raina et al. ( 2020).","For this situation, a simple solution is concatenation (Wang and Bansal, 2018;Blohm et al., 2018), where for example, the same N -length sequence of words is appended to each input sequence of words, as described in (Raina et al., 2020).","Modify,Grammar",Grammar
3165,308-ARR,308-ARR_v2_38@4,308-ARR_v1_39@4,"Many other NLP specific detectors (Zhou et al., 2019;Han et al., 2020;Minervini and Riedel, 2018) have been proposed, but Mozes et al. (2020)'s FGWS detector is considered the state of art and is thus selected for comparison.","Many other NLP specific detectors Han et al., 2020;Minervini and Riedel, 2018) have been proposed, but (Mozes et al., 2020)'s FGWS detector is considered the state of art and is thus selected for comparison.","Modify,Fact/Evidence",Fact/Evidence
3166,308-ARR,308-ARR_v2_39@3,308-ARR_v1_40@3,A single point summary of precision-recall curves is given with the F 1 score.,A single point summary of precision recall-curves is given with the F 1 score.,"Modify,Grammar",Grammar
3167,308-ARR,308-ARR_v2_4@2,308-ARR_v1_4@2,"However, Szegedy et al. (2014) demonstrated that deep models have an inherent weakness: small perturbations in the input can yield significant, undesired, changes in the output from the model.","However, (Szegedy et al., 2014) demonstrated that deep models have an inherent weakness: small perturbations in the input can yield significant, undesired, changes in the output from the model.","Modify,Grammar",Grammar
3168,308-ARR,308-ARR_v2_62@15,308-ARR_v1_63@15,"For the continuous image domain (Img-cont), a VGG-16 architecture image classifier trained on CIFAR-100 (Krizhevsky et al., 2009) image data (achieving a top-5 accuracy of 90.1%) and attacked using a standard l ∞ PGD approach (Equation 3) is used.","For the continuous image domain (Img-cont), a VGG-16 architecture image classifier trained on CIFAR-100 (Krizhevsky et al.) image data (achieving a top-5 accuracy of 90.1%) and attacked using a standard l ∞ PGD approach (Equation 3) is used.","Modify,Fact/Evidence",Fact/Evidence
3169,308-ARR,308-ARR_v2_6@0,308-ARR_v1_6@0,"For adversarial attack generation, a number of specific NLP attacks have been proposed that are designed for NLP task inputs (Lin et al., 2014;Samanta and Mehta, 2017;Rosenberg et al., 2017;Grosse et al., 2016;Sun et al., 2018;Cheng et al., 2018;Blohm et al., 2018;Neekhara et al., 2018;Raina et al., 2020;Jia and Liang, 2017;Minervini and Riedel, 2018;Niu and Bansal, 2018;Ribeiro et al., 2018;Iyyer et al., 2018;Zhao et al., 2017).","For adversarial attack generation, a number of specific NLP attacks have been proposed that are designed for NLP task inputs (Lin et al., 2014;Samanta and Mehta, 2017;Rosenberg et al., 2017;Grosse et al., 2016;Sun et al., 2018;Cheng et al., 2018;Blohm et al., 2018;DBL, 2018;Neekhara et al., 2018;Raina et al., 2020;Jia and Liang, 2017;Minervini and Riedel, 2018;Niu and Bansal, 2018;Ribeiro et al., 2018;Iyyer et al., 2018;Zhao et al., 2017).","Modify,Fact/Evidence",Fact/Evidence
3170,308-ARR,308-ARR_v2_67@2,308-ARR_v1_69@2,"Defence strategies for deep learning systems have been extensively researched, but this research has been predominantly carried out for systems operating in the image domain.","Defence strategies for deep learning systems has been extensively researched, but this work has been predominantly carried out for systems operating in the image domain.","Modify,Clarity",Clarity
3171,308-ARR,308-ARR_v2_7@0,308-ARR_v1_7@0,"The proposed NLP specific detection approach will be referred to as residue detection, as it is shown that adversarial attacks in the discrete, word sequence space result in easily detectable residual components in the sentence embedding space.","The proposed NLP specific detection approach will be referred to as residue detection, as it is shown that adversarial attacks in the discrete, word sequence, space result in easily detectable residual components in the sentence embedding space.","Modify,Grammar",Grammar
3172,308-ARR,308-ARR_v2_9@1,308-ARR_v1_9@1,"First, Feinman et al. (2017) proposed that adversarial subspaces have a lower probability density, motivating the use of the Kernel Density (KD) metric to detect the adversarial examples.","First, (Feinman et al., 2017) proposed that adversarial subspaces have a lower probability density, motivating the use of the Kernel Density (KD) metric to detect the adversarial examples.","Modify,Grammar",Grammar
3173,308-ARR,308-ARR_v2_9@2,308-ARR_v1_9@2,"Nevertheless, Ma et al. (2018) found Local Intrinsic Dimensionality (LID) was a better metric in defining the subspace for more complex data.","Nevertheless, (Ma et al., 2018) found Local Intrinsic Dimensionality (LID) was a better metric in defining the subspace for more complex data.","Modify,Grammar",Grammar
3174,308-ARR,308-ARR_v2_9@3,308-ARR_v1_9@3,"In contrast to the local subspace focused approaches of KD and LID, Carrara et al. (2019b) showed that trajectories of hidden layer features can be used to train a LSTM network to accurately discriminate between authentic and adversarial examples.","In contrast to the local subspace focused approaches of KD and LID, (Carrara et al., 2019b) showed that trajectories of hidden layer features can be used to train a LSTM network to accurately discriminate between authentic and adversarial examples.","Modify,Grammar",Grammar
3175,308-ARR,308-ARR_v2_9@4,308-ARR_v1_9@4,"Out performing all previous methods, introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space).","Out performing all previous methods, ( introduced an effective detection framework using Mahalanobis Distance Analysis (MDA), where the distance is calculated between a test sample and the closest class-conditional Gaussian distribution in the space defined by the output of the final layer of the classifier (logit space).","Modify,Grammar",Grammar
3176,308-ARR,308-ARR_v2_9@5,308-ARR_v1_9@5,Li and Li (2016) also explored using the output of convolutional layers for image classification systems to identify statistics that distinguish adversarial samples from original samples.,"(Li and Li, 2016) also explored using the output of convolutional layers for image classification systems to identify statistics that distinguish adversarial samples from original samples.","Modify,Grammar",Grammar
3177,308-ARR,308-ARR_v2_9@8,308-ARR_v1_9@8,"Hence, Li and Li (2016) extract statistics from the convolutional layer output to train a cascade classifier to separate the original and adversarial samples.","Hence, (Li and Li, 2016) extract statistics from the convolutional layer output to train a cascade classifier to separate the original and adversarial samples.","Modify,Grammar",Grammar
3178,308-ARR,308-ARR_v2_9@9,308-ARR_v1_9@9,"Most recently, Mao et al. (2019) avoid the use of artificially designed metrics and combine the adversarial subspace identification stage and the detecting adversaries stage into a single framework, where a parametric model adaptively learns the deep features for detecting adversaries.","Most recently, (Mao et al., 2019) avoid the use of artificially designed metrics and combine the adversarial subspace identification stage and the detecting adversaries stage into a single framework, where a parametric model adaptively learns the deep features for detecting adversaries.","Modify,Grammar",Grammar
3179,308-ARR,308-ARR_v2_10@0,308-ARR_v1_10@0,"In contrast to the embedding space detection approaches, Cohen et al. (2019) shows that influence functions combined with Nearest Neighbour distances perform comparably or better than the above standard detection approaches.","In contrast to the embedding space detection approaches, (Cohen et al., 2019) shows that influence functions combined with Nearest Neighbour distances perform comparably or better than the above standard detection approaches.","Modify,Grammar",Grammar
3180,308-ARR,308-ARR_v2_11@4,308-ARR_v1_11@4,"To tackle such word-level, semantically similar examples, Zhou et al. (2019) designed a discriminator to classify each token representation as part of an adversarial perturbation or not, which is then used to 'correct' the perturbation.","To tackle such word-level, semantically similar examples, designed a discriminator to classify each token representation as part of an adversarial perturbation or not, which is then used to 'correct' the perturbation.","Modify,Fact/Evidence",Fact/Evidence
3181,308-ARR,308-ARR_v2_11@6,308-ARR_v1_11@6,"Most recently, Mozes et al. (2020) achieved state of the art performance with the Frequency Guided Word Substitution (FGWS) detector, where a change in model prediction after substituting out low frequency words is revealing of adversarial samples.","Most recently, (Mozes et al., 2020) achieved state of the art performance with the Frequency Guided Word Substitution (FGWS) detector, where a change in model prediction after substituting out low frequency words is revealing of adversarial samples.","Modify,Grammar",Grammar
3182,31-ARR,,31-ARR_v1_48@0,,Data Analysis,"Delete,Other",Other
3183,31-ARR,,31-ARR_v1_49@0,,"We collected ParaDetox -a parallel detoxification dataset with 1-3 paraphrases for almost 12,000 toxic sentences.","Delete,Fact/Evidence",Fact/Evidence
3184,31-ARR,,31-ARR_v1_49@1,,"We also manually filtered ParaNMT dataset and get 1,400 toxic-neutral pairs.","Delete,Fact/Evidence",Fact/Evidence
3185,31-ARR,,31-ARR_v1_66@0,,We evaluate the paraphrasers on 671 parallel sentences generated by crowd workers and additionally validated by experts.,"Delete,Fact/Evidence",Fact/Evidence
3186,31-ARR,,31-ARR_v1_74@0,,Table 4 shows examples of different models output.,"Delete,Fact/Evidence",Fact/Evidence
3187,31-ARR,,31-ARR_v1_74@1,,Delete performs deterministic operations which can return disfluent text.,"Delete,Fact/Evidence",Fact/Evidence
3188,31-ARR,,31-ARR_v1_74@2,,"CondBERT has to insert something instead of a toxic word, which is not always a good strategy.","Delete,Fact/Evidence",Fact/Evidence
3189,31-ARR,,31-ARR_v1_74@3,,"ParaGeDi generates sentences from scratch, which sometimes results in a distorted sense.","Delete,Fact/Evidence",Fact/Evidence
3190,31-ARR,,31-ARR_v1_74@4,,BART trained on parallel data is usually free of these drawbacks.,"Delete,Fact/Evidence",Fact/Evidence
3191,31-ARR,,31-ARR_v1_74@5,,More examples of outputs are available in Appendix B.,"Delete,Fact/Evidence",Fact/Evidence
3192,31-ARR,31-ARR_v2_41@5,,"The similarity scores were provided as a part of ParaNMT dataset, the embeddings come from the PARAGRAM-PHRASE model (Wieting et al., 2016).",,"Add,Fact/Evidence",Fact/Evidence
3193,31-ARR,31-ARR_v2_42@0,,"Quality Control To perform paid tasks, users need to pass training and exam sets of tasks.",,"Add,Fact/Evidence",Fact/Evidence
3194,31-ARR,31-ARR_v2_42@1,,Each of them has a corresponding skill -the percentage of correct answers.,,"Add,Fact/Evidence",Fact/Evidence
3195,31-ARR,31-ARR_v2_42@2,,It is assigned to a user upon completing training or exam and serves for filtering out low-performing users.,,"Add,Fact/Evidence",Fact/Evidence
3196,31-ARR,31-ARR_v2_42@3,,"Besides that, users are occasionally given control questions during labeling.",,"Add,Fact/Evidence",Fact/Evidence
3197,31-ARR,31-ARR_v2_42@4,,They serve for computing the labeling skill which can be used for banning low-performing and rewarding well-performing workers.,,"Add,Fact/Evidence",Fact/Evidence
3198,31-ARR,31-ARR_v2_42@5,,The overall training and control pipeline is shown in Figure 6.,,"Add,Fact/Evidence",Fact/Evidence
3199,31-ARR,31-ARR_v2_42@6,,It is used in Tasks 2 and 3.,,"Add,Fact/Evidence",Fact/Evidence
3200,31-ARR,31-ARR_v2_49@0,,The Pipeline Scalability,,"Add,Other",Other
3201,31-ARR,31-ARR_v2_50@0,,The Yandex.Toloka platform has an interface in English and workers from a large number of countries.,,"Add,Fact/Evidence",Fact/Evidence
3202,31-ARR,31-ARR_v2_50@1,,Workers can be filtered by their location and asked to pass built-in language tests (available for many languages) to ensure the knowledge of a particular language.,,"Add,Fact/Evidence",Fact/Evidence
3203,31-ARR,31-ARR_v2_50@2,,This enables the use of Toloka for the creation of NLP resources in many languages.,,"Add,Fact/Evidence",Fact/Evidence
3204,31-ARR,31-ARR_v2_51@0,,"In our work, crowd workers manually rephrase sentences from non-parallel datasets.",,"Add,Fact/Evidence",Fact/Evidence
3205,31-ARR,31-ARR_v2_51@1,,The pipeline does not require any specific data format and can be applied to any text.,,"Add,Fact/Evidence",Fact/Evidence
3206,31-ARR,31-ARR_v2_51@2,,The only prerequisites are to define the source and target styles and to formulate the task of transferring between them.,,"Add,Fact/Evidence",Fact/Evidence
3207,31-ARR,31-ARR_v2_51@3,,"Thus, we believe that the pipeline is suitable for creating parallel datasets for any other style transfer tasks, at least those which have non-parallel datasets and clear definitions of style (positive ↔ negative, complex ↔ simple, impolite ↔ polite, etc.).",,"Add,Claim",Claim
3208,31-ARR,31-ARR_v2_52@0,,"We should admit that our pipeline suggests the availability of (non-parallel) datasets in the chosen styles or at least publicly available sources of such data (e.g. social networks, question answering platforms).",,"Add,Fact/Evidence",Fact/Evidence
3209,31-ARR,31-ARR_v2_52@1,,"However, this is also a prerequisite for any style transfer model trained on non-parallel data.",,"Add,Claim",Claim
3210,31-ARR,31-ARR_v2_52@2,,"Therefore, any work on style transfer suggests that there exists enough data in the chosen style pair and language.",,"Add,Claim",Claim
3211,31-ARR,31-ARR_v2_52@3,,This should not be considered a specific limitation of the pipeline.,,"Add,Claim",Claim
3212,31-ARR,31-ARR_v2_57@5,,We first define the differences between the original and transformed string with the difflib Python library and then compute the percentage of differences that consist in editing swear words and other (non-offensive) words.,,"Add,Fact/Evidence",Fact/Evidence
3213,31-ARR,31-ARR_v2_57@6,,"We use a small manually compiled list of swear words which includes words f*ck, sh*t, a*s, b*tch, d*mn and their variants.",,"Add,Fact/Evidence",Fact/Evidence
3214,31-ARR,31-ARR_v2_63@1,,"We separate the ParaDetox dataset into training and test parts (11,939 and 671 sentence pairs, respectively).",,"Add,Fact/Evidence",Fact/Evidence
3215,31-ARR,31-ARR_v2_63@2,,The test sentences have one reference per sentence.,,"Add,Fact/Evidence",Fact/Evidence
3216,31-ARR,31-ARR_v2_63@3,,We manually validate the test set to exclude the appearance of non-detoxifiable sentences or sentences which stayed toxic after rewriting (we need to verify that since the corpus was generated via crowdsourcing only).,,"Add,Fact/Evidence",Fact/Evidence
3217,31-ARR,31-ARR_v2_63@4,,We do not use the test set neither for training nor for parameter selection of the models.,,"Add,Fact/Evidence",Fact/Evidence
3218,31-ARR,31-ARR_v2_68@0,,"We train BART for 10,000 epochs with the learning rate of 3e-5 and the number of gradient accumulation steps set to 1.",,"Add,Fact/Evidence",Fact/Evidence
3219,31-ARR,31-ARR_v2_68@1,,The other parameters are set to their default values.,,"Add,Fact/Evidence",Fact/Evidence
3220,31-ARR,31-ARR_v2_74@2,,This model is trained on paraphrase pairs extracted from ParaNMT corpus.,,"Add,Fact/Evidence",Fact/Evidence
3221,31-ARR,31-ARR_v2_74@3,,The model's training objective is to yield embeddings such that the similarity of embeddings of paraphrases is higher than the similarity between sentences that are not paraphrases.,,"Add,Fact/Evidence",Fact/Evidence
3222,31-ARR,31-ARR_v2_80@0,,We also check which amount of data is sufficient for a high detoxification quality.,,"Add,Fact/Evidence",Fact/Evidence
3223,31-ARR,31-ARR_v2_80@1,,We train the BART model on subsets of ParaDetox of different sizes.,,"Add,Fact/Evidence",Fact/Evidence
3224,31-ARR,31-ARR_v2_80@2,,"Figure 9 and the performance of ParaDetox-1000 model (Table 4) show that 1,000 training samples is enough to get a good detoxification.",,"Add,Fact/Evidence",Fact/Evidence
3225,31-ARR,31-ARR_v2_80@3,,"While SIM and FL are already high for vanilla BART (see BART-zero-shot model), STA can be improved with only a few parallel examples.",,"Add,Fact/Evidence",Fact/Evidence
3226,31-ARR,31-ARR_v2_80@4,,"This suggests that style transfer does not need large parallel corpora, making our pipeline more useful for other style transfer tasks.",,"Add,Claim",Claim
3227,31-ARR,31-ARR_v2_80@5,,"However, this is the result of the automatic evaluation, which as we show below is not always reliable.",,"Add,Claim",Claim
3228,31-ARR,31-ARR_v2_80@6,,It needs extra investigation.,,"Add,Claim",Claim
3229,31-ARR,31-ARR_v2_84@0,,"We see that it is enough to get 1,000 parallel sentences to perform detoxification with high quality.",,"Add,Fact/Evidence",Fact/Evidence
3230,31-ARR,31-ARR_v2_84@1,,"This suggests that our pipeline can be successfully applied to create useful parallel resources for style transfer even in cases of limited finance or lack of crowd workers because the cost of generating 1,000 examples is very low.",,"Add,Claim",Claim
3231,31-ARR,31-ARR_v2_86@0,,The research on toxicity raises some ethical issues.,,"Add,Claim",Claim
3232,31-ARR,31-ARR_v2_86@1,,"In terms of our work, the parallel corpus we created can indeed be used in the reverse direction, i.e. to ""toxify"" sentences.",,"Add,Fact/Evidence",Fact/Evidence
3233,31-ARR,31-ARR_v2_86@2,,"However, although we did not thoroughly evaluate the quality of such toxification, our intuition is that it would not be high enough to make the corrupted sentences look natural.",,"Add,Claim",Claim
3234,31-ARR,31-ARR_v2_86@3,,"The reason is that the toxic part of our corpus consists of real toxic sentences fetched on the Internet, whereas their non-toxic counterparts are ""translations"" performed by crowd workers.",,"Add,Fact/Evidence",Fact/Evidence
3235,31-ARR,31-ARR_v2_86@4,,"We suggest that they obey the common regularities observed for translationese (texts manually translated from their original language into a different one): they differ from regular texts in terms of vocabulary (Koppel and Ordan, 2011) and syntax (Lembersky et al., 2011).",,"Add,Claim",Claim
3236,31-ARR,31-ARR_v2_86@5,,The manually detoxified texts are different from the original non-toxic texts written by Internet users from scratch.,,"Add,Fact/Evidence",Fact/Evidence
3237,31-ARR,31-ARR_v2_86@6,,"While they are still recognized by human assessors as plausible sentences, we suggest that a sequence-to-sequence model trained to get translationese as input would not be as successful in transforming real texts (as it was shown for machine translation models (Freitag et al., 2019)).",,"Add,Claim",Claim
3238,31-ARR,31-ARR_v2_87@0,,"Thus, although our corpus can be used in the reverse direction, it is not symmetric, which makes it less efficient as training datasets for ""toxifiers"".",,"Add,Claim",Claim
3239,31-ARR,31-ARR_v2_87@1,,"However, we should emphasize that these statements are our hypotheses and should be further investigated.",,"Add,Claim",Claim
3240,31-ARR,31-ARR_v2_87@2,,"Finally, we argue that the risk of using our corpus for toxification is perhaps not game-changing, as simpler approaches based on patterns (e.g. including a set of predefined obscene fragments into neutral texts) can serve the same purpose relatively well.",,"Add,Claim",Claim
3241,31-ARR,31-ARR_v2_3@1,31-ARR_v1_3@1,We conduct both automatic and manual evaluations.,We conduct both automatic and manual evaluation.,"Modify,Grammar",Grammar
3242,31-ARR,31-ARR_v2_29@3,31-ARR_v1_29@3,"Moreover, in some cases toxicity cannot be removed.","On the other hand, in some cases toxicity cannot be removed.","Modify,Clarity",Clarity
3243,31-ARR,31-ARR_v2_32@0,31-ARR_v1_33@0,Task 2: Content Preservation Check We show users the generated paraphrases along with their original variants and ask them to indicate if they have close meanings.,Task 2: Content Preservation Check We show users the generated paraphrases along with their original variants and ask to indicate if they have close meanings.,"Modify,Clarity",Clarity
3244,31-ARR,31-ARR_v2_32@1,31-ARR_v1_33@1,"Besides ensuring content preservation, this task implicitly filters out senseless outputs, because they do not keep the original content.","Besides ensuring content preservation, this task implicitly filters out senseless outputs, because they obviously do not keep the original content.","Modify,Clarity",Clarity
3245,31-ARR,31-ARR_v2_33@1,31-ARR_v1_34@1,We ask users to indicate if the paraphrases contain any offense or swear words (see Figure 3).,We ask users to indicate if the paraphrases contain any offence or swear words (see Figure 3).,"Modify,Grammar",Grammar
3246,31-ARR,31-ARR_v2_3@3,31-ARR_v1_3@3,This suggests that our novel datasets can boost the performance of detoxification systems.,This suggests that our novel datasets can boost the performance of detoxification systems substantially.,"Modify,Clarity",Clarity
3248,31-ARR,31-ARR_v2_36@1,31-ARR_v1_37@2,We fetch them from corpora labeled for toxicity and additionally filter them with a toxicity classifier (described in Section 3.3).,We also additionally filter them with a toxicity classifier (described in Section 3.3).,"Merge+Modify,Clarity",Clarity
3249,31-ARR,31-ARR_v2_36@2,31-ARR_v1_37@3,The overall data collection pipeline (see Figure 4) is as follows:,The overall data collection pipeline (shown in Figure 4) is as follows:,"Modify,Clarity",Clarity
3250,31-ARR,31-ARR_v2_41@6,31-ARR_v1_42@5,"Based on a manual validation, sentences with lower similarity are often not exact paraphrases, and too-similar sentences are either both toxic or both non-toxic.","Sentences with lower similarity are often not exact paraphrases, and too similar sentences are either both toxic or both non-toxic.","Modify,Fact/Evidence",Fact/Evidence
3251,31-ARR,31-ARR_v2_43@1,31-ARR_v1_42@7,"We ban users who submit answers which are: (i) a copy of the input, (ii) too short (< 3 tokens) or too long (more than doubled original length), (iii) contain too many rare words or non-words.","We ban users who submit paraphrases which are: (i) a copy of the input, (ii) too short (< 3 tokens) or too long (more than doubled original length), (iii) contain too many rare words or non-words.","Modify,Clarity",Clarity
3252,31-ARR,31-ARR_v2_43@3,31-ARR_v1_42@9,"We compute the ratio of the number of whitespace-separated tokens and the number of tokens identified by the BPE tokeniser (Sennrich et al., 2016).","We compute the ratio of the number of whitespaceseparated tokens and the number of tokens identified by the BPE tokenizer (Sennrich et al., 2016).","Modify,Grammar",Grammar
3253,31-ARR,31-ARR_v2_43@4,31-ARR_v1_42@10,4 The rationale behind this check is that the BPE tokenizer tends to divide rare words into multiple tokens.,The rationale behind this check is that the BPE tokenizer tends to divide rare words into multiple subtokens.,"Modify,Clarity",Clarity
3254,31-ARR,31-ARR_v2_43@6,31-ARR_v1_42@12,We filter out these answers and ban users who produce them.,We filter out these answers and also ban users who produce them too often.,"Modify,Fact/Evidence",Fact/Evidence
3255,31-ARR,31-ARR_v2_45@2,31-ARR_v1_44@2,"In Tasks 2 and 3, we pay $0.02 and $0.01, respectively, for 12 tasks.","In Tasks 2 and 3, we pay $0.02 and $0.01, respectively for 12 tasks.","Modify,Grammar",Grammar
3256,31-ARR,31-ARR_v2_45@4,31-ARR_v1_44@4,"If a worker has the labeling skill of above 90%, the payment is increased to $0.03 (Task 2) and $0.02 (Task 3).","If a worker has the labelling skill of above 90%, the payment is increased to $0.03 (Task 2) and $0.02 (Task 3).","Modify,Grammar",Grammar
3257,31-ARR,31-ARR_v2_47@0,31-ARR_v1_46@0,"Postprocessing To ensure the correctness of labeling, we ask several workers to label each example.","Postprocessing To ensure the correctness of labelling, we ask several workers to label each example.","Modify,Grammar",Grammar
3258,31-ARR,31-ARR_v2_48@1,31-ARR_v1_47@1,"To improve the quality of the data, we accept only labels with the confidence of over 90% and do not include the rest in the final data.","To improve the quality of data, we accept only labels with the confidence of over 90% and do not include the rest in the final data.","Modify,Grammar",Grammar
3259,31-ARR,31-ARR_v2_54@0,31-ARR_v1_51@0,"We fetched toxic sentences from three sources: Jigsaw dataset of toxic sentences (Jigsaw, 2018), Reddit and Twitter datasets used by Nogueira dos Santos et al. (2018).","We fetched toxic sentences from three sources: Jigsaw dataset of toxic sentences (Jigsaw, 2018), Reddit and Twitter datasets used by (Nogueira dos Santos et al., 2018).","Modify,Grammar",Grammar
3260,31-ARR,31-ARR_v2_54@1,31-ARR_v1_51@1,"We selected 7,000 toxic sentences from each source and gave each of the sentences for paraphrasing to 3 workers.","We selected 6,500 toxic sentences from each source and gave each of the sentences for paraphrasing to 3 workers.","Modify,Fact/Evidence",Fact/Evidence
3261,31-ARR,31-ARR_v2_54@2,31-ARR_v1_51@2,"We get paraphrases for 12,610 toxic sentences (on average 1.66 paraphrases per sentence), 20,437 paraphrases total.","We get paraphrases for 11,939 toxic sentences (on average 1.66 paraphrases per sentence), 19,766 paraphrases total.","Modify,Fact/Evidence",Fact/Evidence
3262,31-ARR,31-ARR_v2_57@4,31-ARR_v1_54@4,We compute the percentage of edits which consisted of removing the most common swear words or replacing them with neutral words.,"We compute the percentage of edits which consisted in removing the most common swear words (f*ck, sh*t, a*s and their variants) or replacing them with more neutral words.","Modify,Clarity",Clarity
3263,31-ARR,31-ARR_v2_58@0,31-ARR_v1_55@0,Another surprisingly common type of editing is the normalization of sentences.,Another surprisingly common type of editing is the normalisation of sentences.,"Modify,Grammar",Grammar
3264,31-ARR,31-ARR_v2_60@0,31-ARR_v1_57@0,"Our automatic filtering of ParaNMT for content yields 500,000 potentially detoxifying sentence pairs, which is 1% of the corpus.","Our automatic filtering of ParaNMT for content and yields 500,000 potentially detoxifying sentence pairs, which is 1% of the corpus.","Modify,Grammar",Grammar
3265,31-ARR,31-ARR_v2_67@0,31-ARR_v1_63@0,"• ParaDetox -our full crowdsourced dataset. • ParaDetox-unique -a subset of ParaDetox where each toxic sentence has only one paraphrase (selected randomly). • ParaDetox-1000 -1,000 samples from the crowdsourced dataset (distributed evenly across data sources, each toxic sample has multiple non-toxic variants). • ParaNMT -filtered ParaNMT corpus, auto stands for automatically filtered 500,000 samples, manual are 1,393 manually selected sentence pairs.","• ParaDetox -our full crowdsourced dataset. • ParaDetox-unique -a subset of ParaDetox where each toxic sentence has only one paraphrase (selected randomly). • ParaNMT -filtered ParaNMT corpus, auto stands for automatically filtered 500,000 samples, manual are 1,393 manually selected sentence pairs.","Modify,Fact/Evidence",Fact/Evidence
3266,31-ARR,31-ARR_v2_72@0,31-ARR_v1_66@1,We compute the BLEU score on the test set.,We compute the BLEU score on this test set.,"Modify,Clarity",Clarity
3267,31-ARR,31-ARR_v2_74@5,31-ARR_v1_68@0,We compute the final joint metric (J) as the multiplication of the three individual metrics.,We compute the final joint metric (J) as the multiplication of the three parameters.,"Modify,Clarity",Clarity
3268,31-ARR,31-ARR_v2_78@4,31-ARR_v1_72@4,This can be explained by the fact that crowd workers often only remove or replaced swear words which is what the Delete model does.,This can be explained by the fact that crowd workers often only removed or replaced swear words which what the Delete model does.,"Modify,Grammar",Grammar
3269,31-ARR,31-ARR_v2_80@10,31-ARR_v1_75@3,"Here, the well-performing Delete model gets the lowest score.","Here, wellperforming Delete model gets the lowest score.","Modify,Grammar",Grammar
3270,31-ARR,31-ARR_v2_80@12,31-ARR_v1_76@1,The manual style accuracy and content preservation are only moderately correlated with their automatic counterparts leaving space for further improvements.,"The manual style accuracy and content preservation are only moderately correlated with their automatic counterparts, and J and J m do not correlate.","Split+Modify,Fact/Evidence",Fact/Evidence
3271,31-ARR,31-ARR_v2_80@13,31-ARR_v1_76@1,J and J m almost do not correlate.,"The manual style accuracy and content preservation are only moderately correlated with their automatic counterparts, and J and J m do not correlate.","Split+Modify,Clarity",Clarity
3272,31-ARR,31-ARR_v2_81@0,31-ARR_v1_77@0,Conclusions,Conclusions and Future Work,"Modify,Other",Other
3273,31-ARR,31-ARR_v2_82@0,31-ARR_v1_78@0,We present ParaDetox -an English parallel corpus for the detoxification task.,We presented ParaDetox -an English parallel corpus for the detoxification task.,"Modify,Grammar",Grammar
3274,31-ARR,31-ARR_v2_82@4,31-ARR_v1_78@4,We also adopt this pipeline to the style-based distillation of paraphrase corpus.,We also adapt this pipeline to the style-based distillation of paraphrase corpus.,"Modify,Grammar",Grammar
3275,31-ARR,31-ARR_v2_85@0,31-ARR_v1_79@0,"Finally, we investigate the relationship between metrics and find that automatic evaluation does not always match the manual judgments and referencebased BLEU cannot replace human evaluation, because it measures content preservation.","Finally, we investigate the relationship between metrics and find that automatic evaluation does not always match the manual judgements and reference-based BLEU cannot replace human evaluation, because it measures content preservation.","Modify,Grammar",Grammar
3276,31-ARR,31-ARR_v2_2@2,31-ARR_v1_2@2,We also show that this pipeline can be used to distill a large existing corpus of paraphrases to get toxicneutral sentence pairs.,We also show that this pipeline can be used to distil a large existing corpus of paraphrases to get toxic-neutral sentence pairs.,"Modify,Grammar",Grammar
3277,31-ARR,31-ARR_v2_13@3,31-ARR_v1_13@3,"In addition to generating the detoxified versions of texts, we consider a way to distill existing datasets of paraphrases for style-specific data.","In addition to generating the detoxified versions of texts, we consider a way to distil existing datasets of paraphrases for style-specific data.","Modify,Grammar",Grammar
3278,31-ARR,31-ARR_v2_13@6,31-ARR_v1_13@6,"Thus, we suggest that by reusing these pipelines the new parallel style transfer datasets can be collected in a fast and affordable way.","Thus, we suggest that by reusing these pipelines the new parallel style transfer datasets can be collected in a fast and cheap way.","Modify,Clarity",Clarity
3279,31-ARR,31-ARR_v2_15@0,31-ARR_v1_15@0,The contributions of our work are three-fold:,The contributions of our work are as three-fold:,"Modify,Clarity",Clarity
3280,31-ARR,31-ARR_v2_18@0,31-ARR_v1_18@0,"Style Transfer Datasets When collecting nonparallel style transfer corpora, style labels often already exist in the data (e.g. positive and negative reviews (Li et al., 2018)) or its source serves as a label (e.g. Twitter, academic texts, legal documents, etc.).","Style Transfer Datasets When collecting nonparallel style transfer corpora, style labels often already exist in the data (e.g. positive and negative reviews (Li et al., 2018a) 1 ) or its source serves as a label (e.g. Twitter, academic texts, legal documents, etc.).","Modify,Fact/Evidence",Fact/Evidence
3281,31-ARR,31-ARR_v2_20@2,31-ARR_v1_20@2,"Since toxic-neutral pairs also do not occur in the wild, we follow this data collection setup with a notable difference -we replace expert validation of crowdsourced sentences with crowd validation and additionally optimize the cost.","Since toxic-neutral pairs also do not occur in the wild, we follow this data collection setup with a notable difference -we replace expert validation of crowdsourced sentences with crowd validation and additionally optimise the cost.","Modify,Grammar",Grammar
3282,31-ARR,31-ARR_v2_21@1,31-ARR_v1_21@1,"They can perform pointwise corrections of stylemarked words (Li et al., 2018;Wu et al., 2019;Malmi et al., 2020).","They can perform pointwise corrections of stylemarked words (Li et al., 2018b;Wu et al., 2019;Malmi et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
3283,31-ARR,31-ARR_v2_22@0,31-ARR_v1_22@0,"Detoxification is usually formulated as style transfer from toxic to neutral (non-toxic) style, so it uses non-parallel datasets labeled for toxicity and considers toxic and neutral sentences as two subcorpora.","Detoxification is usually formulated as style transfer from toxic to neutral (non-toxic) style, so it uses non-parallel datasets labelled for toxicity and considers toxic and neutral sentences as two subcorpora.","Modify,Grammar",Grammar
3304,317-ARR,,317-ARR_v1_45@4,,"1 LM results are obtained using MiniBERTas (Warstadt et al., 2020b) and RoBERTa (Liu et al., 2019b) on templated stimuli.","Delete,Fact/Evidence",Fact/Evidence
3305,317-ARR,,317-ARR_v1_45@5,,"The MiniBERTa models use between 1M to 1B tokens for pretraining, while RoBERTa uses 30B tokens.","Delete,Fact/Evidence",Fact/Evidence
3306,317-ARR,,317-ARR_v1_45@6,,Error bars indicate 95% confidence intervals.,"Delete,Fact/Evidence",Fact/Evidence
3307,317-ARR,,317-ARR_v1_67@2,,"If this were the case, the prototype verb emlike ""from"" (occurring only in the removal construction) or ""on"" (in the caused-motion construction) may provide hints to the sentence meaning.","Delete,Claim",Claim
3308,317-ARR,317-ARR_v2_67@0,,Potential confounds,,"Add,Other",Other
3309,317-ARR,317-ARR_v2_68@0,,"In any experiment, one must be careful to ensure that the observed patterns are due to the phenomenon under investigation rather than confounding factors.",,"Add,Claim",Claim
3310,317-ARR,317-ARR_v2_68@1,,"We discuss potential confounds arising from lexical overlap, anisotropy of contextual embeddings, and neighboring words.",,"Add,Fact/Evidence",Fact/Evidence
3311,317-ARR,317-ARR_v2_69@0,,Lexical overlap.,,"Add,Other",Other
3312,317-ARR,317-ARR_v2_70@0,,Anisotropy.,,"Add,Other",Other
3313,317-ARR,317-ARR_v2_70@1,,"Recent probing work have found that contextual embeddings suffer from anisotropy, where embeddings lie in a narrow cone and have much higher cosine similarity than expected if they were directionally uniform (Ethayarajh, 2019).",,"Add,Fact/Evidence",Fact/Evidence
3314,317-ARR,317-ARR_v2_70@2,,"Furthermore, a small number of dimensions dominate geometric measures such as Euclidean and cosine distance, resulting in a degradation of representation quality (Kovaleva et al., 2021;Timkey and van Schijndel, 2021).",,"Add,Fact/Evidence",Fact/Evidence
3315,317-ARR,317-ARR_v2_70@3,,"Since our experiments rely heavily on Euclidean distance, anisotropy is a significant concern.",,"Add,Claim",Claim
3316,317-ARR,317-ARR_v2_70@4,,"Following Timkey and van Schijndel (2021), we perform standardization by subtracting the mean vector and dividing each dimension by its standard deviation, where the mean and standard deviation for each dimension is computed from a sample of the BNC.",,"Add,Fact/Evidence",Fact/Evidence
3317,317-ARR,317-ARR_v2_70@7,,"Thus, neither of our experiments appear to be affected by anisotropy.",,"Add,Claim",Claim
3318,317-ARR,317-ARR_v2_71@0,,Neighboring words.,,"Add,Other",Other
3319,317-ARR,317-ARR_v2_32@5,317-ARR_v1_32@5,"In Italian and Spanish, some different constructions were substituted as not all of the English constructions had an equivalent in these languages; see the appendix for the complete set of stimuli in each language.","In Italian and Spanish, some different constructions were substituted as not all of the English constructions had an equivalent in these languages; see Appendix for the complete set of stimuli in each language.","Modify,Grammar",Grammar
3320,317-ARR,317-ARR_v2_35@0,317-ARR_v1_35@0,"Johnson and Goldberg (2013) used a ""Jabberwocky"" priming task to show that abstract constructional templates are associated with meaning.","Johnson and Goldberg (2013) used a ""Jabberwocky"" priming setup to show that abstract constructional templates are associated with meaning.","Modify,Clarity",Clarity
3321,317-ARR,317-ARR_v2_39@1,317-ARR_v1_38@1,"Linzen et al. (2016) tested LSTMs on their ability to capture subject-verb agreement, using templates to generate test data.","Linzen et al. (2016) tested LSTMS on their ability to capture subject-verb agreement, using templates to generate test data.","Modify,Grammar",Grammar
3322,317-ARR,317-ARR_v2_40@0,317-ARR_v1_39@0,"So far, relatively few papers approached LM probing from a construction grammar perspective.","So far, most probing work has assumed a theoretical framework based on generative syntax, and relatively few papers approached LM probing from a construction grammar perspective.","Modify,Claim",Claim
3323,317-ARR,317-ARR_v2_40@1,317-ARR_v1_39@1,Madabushi et al. (2020) probed for BERT's knowledge of constructions via a sentence pair classification task of predicting whether two sentences share the same construction.,Madabushi et al. (2020) probed for BERT's knowledge of constructions via a sentence pair classification setup of predicting whether two sentences share the same construction.,"Modify,Clarity",Clarity
3324,317-ARR,317-ARR_v2_40@5,317-ARR_v1_39@5,Lebani and Lenci (2016) is the most similar to our work: they probed distributional vector space models for ASCs based on the Jabberwocky priming experiment by Johnson and Goldberg (2013).,Lebani and Lenci (2016) is most similar to our work: they probed distributional vector space models for ASCs based on the Jabberwocky priming experiment by Johnson and Goldberg (2013).,"Modify,Grammar",Grammar
3325,317-ARR,317-ARR_v2_42@1,317-ARR_v1_41@1,"Using a cloze completion task, Ettinger (2020) found that BERT was less sensitive than humans at commonsense inferences and detecting role reversals, and fails completely at understanding negation.","Using a cloze completion setup, Ettinger (2020) found that BERT was less sensitive than humans at commonsense inferences and detecting role reversals, and fails completely at understanding negation.","Modify,Clarity",Clarity
3326,317-ARR,317-ARR_v2_46@1,317-ARR_v1_45@1,"To simulate varying non-native English proficiency levels, we use MiniBERTa models (Warstadt et al., 2020b) 100M, and 1B tokens.","To simulate varying non-native English proficiency levels, we use MiniBERTa models (Warstadt et al., 2020b), trained with 1M, 10M, 100M, and 1B tokens.","Modify,Fact/Evidence",Fact/Evidence
3327,317-ARR,317-ARR_v2_62@13,317-ARR_v1_62@12,"4 As a control, we measure the Euclidean distance to the prototype verbs of the other three unrelated constructions.","3 As 3 Johnson and Goldberg (2013) also included a third experimental condition using four verbs that are semantically related but not associated with the construction, but one of the verbs a control, we measure the Euclidean distance to the prototype verbs of the other three unrelated constructions.","Modify,Fact/Evidence",Fact/Evidence
3328,317-ARR,317-ARR_v2_69@4,317-ARR_v1_66@1,There is substantial evidence that RoBERTa is able to associate abstract constructional templates with their meaning without lexical cues.,"Thus, there is substantial evidence that RoBERTa is able to associate abstract constructional templates with their meaning, without relying on lexical cues.","Modify,Clarity",Clarity
3329,317-ARR,317-ARR_v2_71@1,317-ARR_v1_67@0,"A final confounding factor is our assumption that RoBERTa's contextual embeddings represent word meaning, when in reality, they contain a mixture of syntactic and semantic information.","One confounding factor in this experiment is our assumption that RoBERTa's contextual embeddings represent word meaning, when in reality, they contain a mixture of syntactic and semantic information.","Modify,Clarity",Clarity
3330,317-ARR,317-ARR_v2_69@3,317-ARR_v1_67@3,"However, the ditransitive and resultative constructions do not contain any such informative words, yet RoBERTa still associates the correct prototype verb for these constructions, so we consider it unlikely to be relying solely on lexical overlap.","However, the ditransitive and resultative constructions do not contain any such informative words, yet RoBERTa still associates the correct prototype verb for these constructions, so we consider it unlikely to be relying solely on lexical cues.","Modify,Clarity",Clarity
3331,317-ARR,317-ARR_v2_7@0,317-ARR_v1_7@0,Here we connect basic research in ASCs with neural probing by adapting several psycholinguistic studies to Transformer-based LMs and show evidence for the neural reality of ASCs.,"Here, we connect basic research in ASCs with neural probing by adapting several psycholinguistic studies to Transformer-based LMs and show evidence for the neural reality of ASCs.","Modify,Grammar",Grammar
3332,317-ARR,317-ARR_v2_8@0,317-ARR_v1_8@0,"Our second case study is based on nonsense ""Jabberwocky"" sentences that nevertheless convey meaning when they are arranged in constructional templates (Johnson and Goldberg, 2013).","Our second case study is based on nonsense ""Jabberwocky"" sentences that nevertheless contain meaning when they are arranged in constructional templates (Johnson and Goldberg, 2013).","Modify,Clarity",Clarity
3333,317-ARR,317-ARR_v2_2@3,317-ARR_v1_2@3,Decades of psycholinguistic research have produced substantial empirical evidence in favor of the construction view.,Two decades of psycholinguistic research have produced substantial empirical evidence in favor of the construction view.,"Modify,Claim",Claim
3334,317-ARR,317-ARR_v2_8@3,317-ARR_v1_8@3,Our source code and data are available at: https://github.com/SPOClab-ca/ neural-reality-constructions.,We include the source code and data for reproducing this work as supplementary material and will release the GitHub repository upon publication.,"Modify,Fact/Evidence",Fact/Evidence
3335,317-ARR,317-ARR_v2_2@4,317-ARR_v1_2@4,Here we adapt several psycholinguistic studies to probe for the existence of argument structure constructions (ASCs) in Transformerbased language models (LMs).,"Here, we adapt several psycholinguistic studies to probe for the existence of argument structure constructions (ASCs) in Transformerbased language models (LMs).","Modify,Grammar",Grammar
3362,320-ARR,,320-ARR_v1_28@2,,"It proves both two strategies proposed in our method are important and effective, and combining these two strategies can achieve a noticeable performance gain.","Delete,Claim",Claim
3363,320-ARR,,320-ARR_v1_28@3,,"More specifically, we can observe that instance ranking or label calibration is effective enough to outperform previous SOTA models with an average performance gain of at least 3.7% in T-REx SPO dataset, showing the effectiveness of these two strategies.","Delete,Fact/Evidence",Fact/Evidence
3364,320-ARR,,320-ARR_v1_30@4,,We also provide a visualization in the Appendix.,"Delete,Fact/Evidence",Fact/Evidence
3365,320-ARR,,320-ARR_v1_37@0,,"To intuitively show how our method helps to refine the relation representation space, we visual the representations of novel relations by using t-SNE (Van der Maaten and Hinton, 2008) to reduce the dimension to 2.","Delete,Fact/Evidence",Fact/Evidence
3366,320-ARR,320-ARR_v2_4@3,,Yajing Xu is the corresponding author.,,"Add,Fact/Evidence",Fact/Evidence
3367,320-ARR,320-ARR_v2_25@0,,Datasets,,"Add,Other",Other
3368,320-ARR,320-ARR_v2_27@0,,Baselines,,"Add,Other",Other
3369,320-ARR,320-ARR_v2_30@0,,Evaluation Metrics,,"Add,Other",Other
3370,320-ARR,320-ARR_v2_32@0,,Implementation Details,,"Add,Other",Other
3371,320-ARR,320-ARR_v2_22@0,320-ARR_v1_21@0,"(2) where D(x, y) is the KL distance between x and y to measure the difference between the cluster assignment probabilities of the instances, m L is the margin for cluster-level ranking loss.","(2) where D(x, y) is the KL distance between x and y to measure the difference between the cluster assignment probabilities of the instances, m L is the margin for cluster-level ranking loss, and θ is the model parameters.","Modify,Fact/Evidence",Fact/Evidence
3372,320-ARR,320-ARR_v2_34@3,320-ARR_v1_33@6,All experiments are conducted by using a GeForce RTX 3090Ti with 24 GB memory.,All experiments are conducted by using a GeForce GTX 3090Ti with 24 GB memory.,"Modify,Fact/Evidence",Fact/Evidence
3373,320-ARR,320-ARR_v2_31@1,320-ARR_v1_36@1,"Considering that any of the three metrics can measure the clustering performance from different angles, we take the average of B 3 F1, Vmeasure F1 and ARI for comprehensive evaluation.","Considering that any of the three metrics can measure the clustering performance from different angles, we take the average for comprehensive evaluation.","Modify,Fact/Evidence",Fact/Evidence
3374,320-ARR,320-ARR_v2_7@4,320-ARR_v1_6@4,"Besides, all instances should follow the same relative relationship in the label semantic space which means the original and positive instances have a more similar cluster probability distribution than the hard and semi-hard negative instances.","Besides, all instances should follow the same relative relationship in the label semantic space which means the original and positive instance have a more similar cluster probability distribution than the hard and semi-hard negative instances.","Modify,Grammar",Grammar
3375,320-ARR,320-ARR_v2_8@4,320-ARR_v1_7@4,"To correct the cluster assignment probabilities of hard and semi-hard negative instances, and keep the probability distributions of the original and positive instances aligned, in the label semantic space, Label Calibration strategy is designed to model two constraint relationships between the original and hard negative instance, and between the hard and semi-hard negative instance.","To correct the cluster assignment probabilities of hard and semi-hard instances, and keep the probability distributions of the original and positive instance aligned, in the label semantic space, Label Calibration strategy is designed to model two constraint relationships between the original and hard negative instance, and between the hard and semi-hard negative instance.","Modify,Clarity",Clarity
3376,320-ARR,320-ARR_v2_14@0,320-ARR_v1_13@0,"Since there are no pre-defined relation types, it is difficult to directly obtain the positive, hard negative, and semi-hard negative instances of the original instance.","Since there is no pre-defined relation types, it is difficult to directly obtain the positive, hard negative, and semi-hard negative instances of the original instance.","Modify,Grammar",Grammar
3377,320-ARR,320-ARR_v2_16@2,320-ARR_v1_15@2,"Specifically, given a group of instances (X i , X p i , X hn i , X sn i ), where X p i , X hn i , X sn i are positive, hard negative, and semi-hard negative instances respectively.","Specifically, given a group of instances (X i , X p i , X hn i , X sn i ), where X p i , X hn i , X sn i are positive, hard, and semi-hard instance respectively.","Modify,Clarity",Clarity
3378,320-ARR,320-ARR_v2_20@0,320-ARR_v1_19@0,"In addition to refining the feature space, we introduce Label Calibration to model the constraint relationship between instances to correct the cluster assignment probabilities of hard and semi-hard negative instances and keep the probability distributions of the original and positive instance aligned in the label semantic space.","In addition to refining the feature space, we introduce Label Calibration to model the constraint relationship between instances to correct the cluster assignment probabilities of hard and semi-hard instances and keep the probability distributions of the original and positive instance aligned in the label semantic space.","Modify,Clarity",Clarity
3415,33-ARR,,33-ARR_v1_71@3,,"Overall, pretrained-based methods generally outperform traditional methods, and this also proves the effectiveness of the pretrained language model on the generation tasks.","Delete,Claim",Claim
3416,33-ARR,,33-ARR_v1_75@3,,"On this basis, adding keyword contrastive learning with removing the keyword graph, the effect of the model has been improved but is still lower than our model by 2.1%.","Delete,Fact/Evidence",Fact/Evidence
3417,33-ARR,,33-ARR_v1_75@4,,"This shows that keywords are indeed conducive to capturing important information, and it also illustrates the significance of a keyword graph.","Delete,Fact/Evidence",Fact/Evidence
3418,33-ARR,,33-ARR_v1_75@5,,"Finally, the experiment of removing the Mahalanobis contrastive loss indicates that only with granularity independent contrast is not sufficient, and the Mahalanobis contrast plays a critical intermediate role.","Delete,Fact/Evidence",Fact/Evidence
3419,33-ARR,33-ARR_v2_8@0,,Our contributions can be summarized as follows:,,"Add,Other",Other
3420,33-ARR,33-ARR_v2_83@0,,Acknowledgments,,"Add,Other",Other
3421,33-ARR,33-ARR_v2_84@0,,We would like to thank the anonymous reviewers for their constructive comments.,,"Add,Claim",Claim
3422,33-ARR,33-ARR_v2_85@0,,Ethics Impact,,"Add,Other",Other
3423,33-ARR,33-ARR_v2_86@0,,"In this paper, we propose an inter-level contrastive learning method, which unifies instance-level and keyword-level contrasts in the CVAE framework.",,"Add,Claim",Claim
3424,33-ARR,33-ARR_v2_86@1,,"The positive impact lies in that it can help improve the capability of generation models on paraphrasing, dialogue generation, and storytelling tasks.",,"Add,Claim",Claim
3425,33-ARR,33-ARR_v2_86@2,,"The negative impact may be that the generation process of the system is not fully controllable, so it is possible to generate inaccurate or unreasonable content in some extreme cases.",,"Add,Claim",Claim
3426,33-ARR,33-ARR_v2_86@3,,"Hence, extra processing steps might be needed if this method were to be used in scenarios where high accuracy is required.",,"Add,Claim",Claim
3427,33-ARR,33-ARR_v2_38@5,33-ARR_v1_36@5,"Based on these keywords as nodes and their relations as edges , the key-word graph G k is constructed.","Based on these keywords as nodes and their relations as edges, the keyword graph G k is constructed.","Modify,Grammar",Grammar
3428,33-ARR,33-ARR_v2_4@0,33-ARR_v1_4@0,"Generation tasks such as storytelling, paraphrasing, and dialogue generation aim at learning a certain correlation between text pairs that maps an arbitrary-length input to another arbitrary-length output.","Generation tasks such as storytelling, paraphrasing, and dialogue generation aim at learning a certain correlation between text pairs that maps an arbitrary-length input text to another arbitrarylength output text.","Modify,Clarity",Clarity
3429,33-ARR,33-ARR_v2_4@1,33-ARR_v1_4@1,"Traditional methods are mostly trained with ""teacher forcing"" and lead to an ""exposure bias"" problem (Schmidt, 2019).","Traditional methods are mostly trained with ""teacher forcing"" and lead to an ""exposure bias"" problem.","Modify,Fact/Evidence",Fact/Evidence
3430,33-ARR,33-ARR_v2_64@7,33-ARR_v1_62@7,"Note that for better performance, our model is built based on BERT, and the decoding process is the same as Transformer (Vaswani et al., 2017).","Note that for better performance, our model is built based on BERT.","Modify,Fact/Evidence",Fact/Evidence
3431,33-ARR,33-ARR_v2_75@1,33-ARR_v1_75@0,"Three annotators are asked to rate paraphrasing questions generated by T5-CLAPS, DialoGPT, Seq2Seq-DU, and our model according to Fluency (Flu), Meaningfulness (Mean), and Differential (Diff).","The annotators are asked to rate paraphrasing questions generated by T5-CLAPS, DialoGPT, Seq2Seq-DU, and our model according to Fluency (Flu), Meaningfulness (Mean), and Differential (Diff).","Modify,Fact/Evidence",Fact/Evidence
3432,33-ARR,33-ARR_v2_14@2,33-ARR_v1_14@2,"Recently, Mahalanobis distance is popularly applied to the NLP tasks (Tran et al., 2019).","Recently, Mahalanobis distance is popularly applied to the NLP tasks (Tran et al., 2019;Denouden et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
3433,331-ARR,331-ARR_v2_10@0,,"Recently, there has been an interest in predicting the performance of NLP models without actually training or testing them, by formulating it as a regression problem.",,"Add,Claim",Claim
3434,331-ARR,331-ARR_v2_10@1,,Xia et al. (2020) showed that using experimental settings for an NLP experiment as inputs it is possible to accurately predict the performance on different languages and model architectures.,,"Add,Fact/Evidence",Fact/Evidence
3435,331-ARR,331-ARR_v2_10@2,,Ye et al. (2021) extended this work by proposing methods to do a fine-grained estimation of the performance as well as predicting well-callibrated confidence intervals.,,"Add,Fact/Evidence",Fact/Evidence
3436,331-ARR,331-ARR_v2_27@0,,"An important thing to note here is that the we do not use identity of a language as a feature while training the models, hence the performance prediction models are capable of generating predictions on new languages unseen during training.",,"Add,Claim",Claim
3437,331-ARR,331-ARR_v2_27@1,,"However, if the features of the new languages deviate significantly from the features seen during training, the predictions are expected to be less accurate as also observed in Xia et al. (2020); Srinivasan et al. (2021) and is one of the main reasons for exploring a multi-task approach.",,"Add,Claim",Claim
3438,331-ARR,331-ARR_v2_46@0,,Ye et al. ( 2021) also uses a Tensor Factorization approach for performance prediction which is similar to our CMF method.,,"Add,Fact/Evidence",Fact/Evidence
3439,331-ARR,331-ARR_v2_46@1,,"However, they train separate models for each task and factorize over metric specific attributes instead for a fine-grained prediction.",,"Add,Fact/Evidence",Fact/Evidence
3440,331-ARR,331-ARR_v2_62@1,,"Overall, we see about 10% drop in LOLO errors on average for MDGPR compared to the best performing single-task model i.e. Lasso Regression.",,"Add,Fact/Evidence",Fact/Evidence
3441,331-ARR,331-ARR_v2_62@2,,"As expected, the benefit of multi-task learning is even more prominent when we consider the tasks for which only a few (≤ 10) data points are available.",,"Add,Fact/Evidence",Fact/Evidence
3442,331-ARR,331-ARR_v2_62@3,,Here we see about 20% reduction in errors.,,"Add,Fact/Evidence",Fact/Evidence
3443,331-ARR,331-ARR_v2_62@4,,"For mBERT as well, we have similar observations, except that CMF performs slightly better than MDGPR.",,"Add,Fact/Evidence",Fact/Evidence
3444,331-ARR,331-ARR_v2_75@1,,"Instead of learning task-specific kernels k t (g(x p,t ), g(x p ′ ,t ′ )), we will have a common kernel over the inputs as k(g(x p,t ), g(x p ′ ,t ′ )) and a positive semi-definite matrix K task for learning inter-task similarities.",,"Add,Fact/Evidence",Fact/Evidence
3445,331-ARR,331-ARR_v2_77@0,,The GP prior will be defined by replacing the task specific kernel K t in the equation 4 with the multi-task kernel K m .,,"Add,Fact/Evidence",Fact/Evidence
3446,331-ARR,331-ARR_v2_77@1,,We use the optimization steps similar to DGP and the inference is done by using the standard GP formulae.,,"Add,Fact/Evidence",Fact/Evidence
3447,331-ARR,331-ARR_v2_78@0,,"Relating MDGPR to equation 1, the global parameters Θ are the parameters of the deep network g, and the task specific parameter Φ is the positive semi-definite matrix K task .",,"Add,Fact/Evidence",Fact/Evidence
3448,331-ARR,331-ARR_v2_78@2,,"In MAML, the set of initialization parameters for the neural network are explicitly learned such that the network can generalize well on a new task with a small number of gradient steps and training samples.",,"Add,Fact/Evidence",Fact/Evidence
3449,331-ARR,331-ARR_v2_79@0,,"Relating to equation 1, the global parameters Θ can be considered as the initial set of parameters for the neural network that are learned and shared across all the tasks.",,"Add,Fact/Evidence",Fact/Evidence
3450,331-ARR,331-ARR_v2_79@1,,Task specific parameters Φ are adapted from Θ by taking K gradient steps using the task's performance data.,,"Add,Fact/Evidence",Fact/Evidence
3451,331-ARR,331-ARR_v2_81@0,,"The FERT and PCW metrics as proposed by Rust et al. (2021), have been compared for mBERT and XLMR in figure 4.",,"Add,Fact/Evidence",Fact/Evidence
3452,331-ARR,331-ARR_v2_4@2,331-ARR_v1_4@2,"What affects the zero-shot transfer across different languages is a subject of considerable interest and importance (K et al., 2020;Pires et al., 2019;Wu and Dredze, 2019;Lauscher et al., 2020), however there is little conclusive evidence and a few papers even show contradictory findings.","What affects the zero-shot transfer across different languages is a subject of considerable interest and importance (K et al., 2019;Pires et al., 2019;Wu and Dredze, 2019;Lauscher et al., 2020), however there is little conclusive evidence and a few papers even show contradictory findings.","Modify,Fact/Evidence",Fact/Evidence
3453,331-ARR,331-ARR_v2_68@8,331-ARR_v1_63@8,"Our observation reinforce the generally held notion that vocabulary overlap between the pivot and target is beneficial for zero-shot transfer (Wu and Dredze, 2019), especially for retrieval tasks, though some studies have argued otherwise (Pires et al., 2019;K et al., 2020).","Our observation reinforce the generally held notion that vocabulary overlap between the pivot and target is beneficial for zero-shot transfer (Wu and Dredze, 2019), especially for retrieval tasks, though some studies have argued otherwise (Pires et al., 2019;K et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
3454,331-ARR,331-ARR_v2_68@13,331-ARR_v1_63@13,We believe that XLMR's surprisingly worse performance than mBERT for Chinese and Japanese UDPOS might be correlated with it's significantly worse tokenizer for these languages based on the fertility (FERT) and Percentage Continued Words (PCW) feature values (see Appendix A.2 for exact values).,We believe that XLMR's surprisingly worse performance than mBERT for Chinese and Japanese on UDPOS might be correlated with it's significantly worse tokenizer for these languages based on the fertility (FERT) and Percentage Continued Words (PCW) feature values (see Appendix A.2 for exact values).,"Modify,Grammar",Grammar
3455,331-ARR,331-ARR_v2_10@5,331-ARR_v1_9@6,"Dolicki and Spanakis (2021) explored individual syntactic features for zero-shot performance prediction instead of working with aggregate similarity values, and showed about 2 to 4 times gain in performance.","Recently, Dolicki and Spanakis (2021) explored individual syntactic features for zero-shot performance prediction instead of working with aggregate similarity values, and showed about 2 to 4 times gain in performance.","Modify,Clarity",Clarity
3456,331-ARR,331-ARR_v2_10@6,331-ARR_v1_9@7,"We extend all of these works by considering a multi-task learning approach, where performance prediction in a task utilizes not only the data available for that task, but also the patterns observed for other tasks.","We extend these work by considering a multi-task learning approach, where performance prediction in a task utilizes not only the data available for that task, but also the patterns observed for other tasks.","Modify,Clarity",Clarity
3457,334-ARR,,334-ARR_v1_51@9,,"This provides interesting future direction, where legal knowledge is incorporated into the prediction model.","Delete,Claim",Claim
3458,334-ARR,334-ARR_v2_54@9,,We also performed quantitative analysis on the model output to better understand the performance.,,"Add,Fact/Evidence",Fact/Evidence
3459,334-ARR,334-ARR_v2_54@10,,"Our model outputs a probabilistic score in the range {0, 1}.",,"Add,Fact/Evidence",Fact/Evidence
3460,334-ARR,334-ARR_v2_55@0,,"A score closer to 0 indicates our model is confident that bail would be denied, while a score closer to 1 means bail granted.",,"Add,Fact/Evidence",Fact/Evidence
3461,334-ARR,334-ARR_v2_55@2,,"We observe the correct bail granted predictions are shifted towards 1, and the correct bail denied predictions are shifted towards 0.",,"Add,Fact/Evidence",Fact/Evidence
3462,334-ARR,334-ARR_v2_55@3,,"Additionally, the incorrect samples are concentrated near the middle (≈ 0.5), which shows that our model was able to identify these as borderline cases.",,"Add,Fact/Evidence",Fact/Evidence
3463,334-ARR,334-ARR_v2_13@0,334-ARR_v1_11@0,Hindi Legal Documents Corpus,Hindi Legal Document Corpus,"Modify,Grammar",Grammar
3464,334-ARR,334-ARR_v2_14@0,334-ARR_v1_12@0,"Hindi Legal Documents Corpus (HLDC) is a corpus of 912,568 Indian legal case documents in the Hindi language.",Hindi Legal Document Corpus (HLDC) is a corpus of about 900K Indian legal case documents in the Hindi language.,"Modify,Fact/Evidence",Fact/Evidence
3465,334-ARR,334-ARR_v2_14@1,334-ARR_v1_13@0,The corpus is created by downloading data from the e-Courts website (a publicly available website: https:// districts.ecourts.gov.in/).,The corpus is created by scraping data from the e-Courts website (a publicly available website: https:// districts.ecourts.gov.in/).,"Modify,Clarity",Clarity
3466,334-ARR,334-ARR_v2_14@3,334-ARR_v1_13@2,We download case documents pertaining to the district courts located in the Indian northern state of Uttar Pradesh (U.P.).,We scrape case documents pertaining to the district courts located in the Indian northern state of Uttar Pradesh (U.P.).,"Modify,Clarity",Clarity
3467,334-ARR,334-ARR_v2_2@9,334-ARR_v1_2@9,Experiments with different models are indicative of the need for further research in this area.,Results on different models are indicative of the need for further research in this area.,"Modify,Clarity",Clarity
3468,334-ARR,334-ARR_v2_14@15,334-ARR_v1_13@14,The first step in HLDC creation is the downloading of documents from the e-Courts website.,The first step in HLDC creation is the scraping of documents from the e-Courts website.,"Modify,Clarity",Clarity
3469,334-ARR,334-ARR_v2_2@0,334-ARR_v1_2@0,Many populous countries including India are burdened with a considerable backlog of legal cases.,"Populous countries (e.g., India) are burdened with a considerable backlog of legal cases.","Modify,Clarity",Clarity
3470,334-ARR,334-ARR_v2_15@3,334-ARR_v1_14@3,"The header contains the meta-information related to the case, for example, case number, court identifier, and applicable sections of the law.","The header contains the meta-information related to the case, for example, case number, court identifier, applicable sections of the law, etc.","Modify,Clarity",Clarity
3471,334-ARR,334-ARR_v2_4@2,334-ARR_v1_4@2,"For example, if a system could readily extract the required information from a legal document for a legal practitioner, then it would help expedite the legal process.","For example, if a system could readily extract the required information from a legal document for a legal practitioner, then it would help them expedite the legal process.","Modify,Clarity",Clarity
3472,334-ARR,334-ARR_v2_18@1,334-ARR_v1_15@18,"Body is further segmented into Facts and Arguments, Judge's summary and Case Result.","The body is further segmented into Facts and Arguments, Judge's summary and Case Result.","Modify,Grammar",Grammar
3473,334-ARR,334-ARR_v2_4@4,334-ARR_v1_4@4,"For example, legal documents are typically quite long (tens of pages), highly unstructured and noisy (spelling and grammar mistakes since these are typed), use domainspecific language and jargon; consequently, pre-trained language models do not perform well on these (Malik et al., 2021b).","For example, legal documents are typically quite long (tens of pages), legal documents are highly unstructured and noisy (spelling and grammar mistakes, since these are typed), language in legal documents are domain-specific, and pre-trained language models do not perform well on these (Malik et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
3474,334-ARR,334-ARR_v2_23@7,334-ARR_v1_19@7,"As observed in previous work (Malik et al., 2021b), anonymization of a judge's name is important as there is a correlation between a case outcome and a judge name.","As observed in previous work (Malik et al., 2021), anonymization of a judge's name is important as there is a correlation between a case outcome and a judge name.","Modify,Fact/Evidence",Fact/Evidence
3475,334-ARR,334-ARR_v2_23@12,334-ARR_v1_19@12,"Moreover, the Bail corpus and corresponding bail prediction systems can promote the development of explainable systems (Malik et al., 2021b), we leave research on such explainable systems for future work.","Moreover, the Bail corpus and corresponding bail prediction systems can promote the development of explainable systems (Malik et al., 2021), we leave research on such explainable systems for future work.","Modify,Fact/Evidence",Fact/Evidence
3476,334-ARR,334-ARR_v2_4@5,334-ARR_v1_5@0,"Thus, to develop legal text processing systems and address the challenges associated with the legal domain, there is a need for creating specialized legal domain corpora.","To develop legal text processing systems and address the challenges associated with the legal domain, there is a need for creating specialized legal domain corpora.","Modify,Clarity",Clarity
3477,334-ARR,334-ARR_v2_2@1,334-ARR_v1_2@1,Development of automated systems that could process legal documents and augment legal practitioners can mitigate this.,This calls for the development of automated systems that could process legal documents and augment legal practitioners.,"Modify,Claim",Claim
3479,334-ARR,334-ARR_v2_5@1,334-ARR_v1_5@1,"For example, Chalkidis et al. (2019) have developed an English corpus of European Court of Justice documents, while Malik et al. (2021b) have developed an English corpus of Indian Supreme Court documents.","In recent times, there have been efforts to develop such corpora for example, Chalkidis et al. (2019) have developed an English corpus of European Court of Justice documents, Malik et al. (2021) have developed an English corpus of Indian Supreme Court documents, Xiao et al. (2018) have developed Chinese Legal Document corpus.","Split+Modify,Fact/Evidence",Fact/Evidence
3481,334-ARR,334-ARR_v2_50@5,334-ARR_v1_45@5,Testing is done on a different set of 17 districts not present in train set.,Testing is done on a different set of 17 districts not present during training.,"Modify,Clarity",Clarity
3482,334-ARR,334-ARR_v2_52@4,334-ARR_v1_48@4,"Another thing to note from the results is that, in general, summarization based models perform better than Doc2Vec and transformer-based models, highlighting the importance of the summarization step in the bail prediction task.","Another thing to note from the results is that, in general, summarization models perform better than Doc2Vec and transformer-based models, highlighting the importance of the summarization step in the bail prediction task.","Modify,Clarity",Clarity
3483,334-ARR,334-ARR_v2_5@4,334-ARR_v1_5@3,"Hindi uses Devanagari script (Wikipedia contributors, 2021) for the writing system.","Hindi uses Devanagri (Wikipedia contributors, 2021) script for the writing system.","Modify,Clarity",Clarity
3484,334-ARR,334-ARR_v2_54@1,334-ARR_v1_51@1,"After examining the miss-classified examples, we observed the following.",We observe a couple of things looking at the misclassified examples.,"Modify,Clarity",Clarity
3485,334-ARR,334-ARR_v2_54@6,334-ARR_v1_51@6,"In some instances, we also observed that even if the facts of the cases are similar the judgements can differ.","In some instances, we also observe that even if the facts of the cases are similar the judgements can differ.","Modify,Grammar",Grammar
3486,334-ARR,334-ARR_v2_5@6,334-ARR_v1_5@6,Most of the lower (district) courts in northern India use Hindi as the official language.,Most of the lower (district) courts in Northern India use Hindi as the official language.,"Modify,Grammar",Grammar
3487,334-ARR,334-ARR_v2_5@7,334-ARR_v1_5@7,"However, most of the legal NLP systems that currently exist in India have been developed on English, and these do not work on Hindi legal documents (Malik et al., 2021b).","However, most of the legal NLP systems that currently exist in India have been developed on English, and these do not work on Hindi legal documents (Malik et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
3488,334-ARR,334-ARR_v2_5@8,334-ARR_v1_5@8,"To address this problem, in this paper, we release a large corpus of Hindi legal documents (HINDI LEGAL DOCUMENTS CORPUS or HLDC) that can be used for developing NLP systems that could augment the legal practitioners by automating some of the legal processes.","To address this problem, in this paper, we release a large corpus of Hindi legal documents (Hindi Legal Document Corpus) that can be used for developing NLP systems that could augment the legal practitioners by automating some of the legal processes.","Modify,Clarity",Clarity
3489,334-ARR,334-ARR_v2_58@8,334-ARR_v1_56@3,"Finally, all sentences labelled as judge's opinion either during reverse iteration or during paragraph level extension are extracted out as judge's summary and rest of the sentences form facts and opinions for further modelling.","Finally, all labelled as judge's opinion either during reverse iteration or during paragraph level extension are extracted out as judge's summary and rest of the sentences form facts and opinions for further modelling.","Modify,Clarity",Clarity
3490,334-ARR,334-ARR_v2_2@2,334-ARR_v1_2@2,"However, there is a dearth of high-quality corpora that is needed to develop such data-driven systems.","To develop such data-driven systems, there is a dearth of high-quality corpora.","Modify,Clarity",Clarity
3491,334-ARR,334-ARR_v2_6@0,334-ARR_v1_6@0,"India follows a Common Law system and has a three-tiered court system with District Courts (along with Subordinate Courts) at the lowest level (districts), followed by High Courts at the state level, and the Supreme Court of India at the highest level.","India follows a Common Law system and has a three-tiered court system with District Courts (along with Subordinate Courts) at the lowest levels of districts, followed by High Courts at the state level and the Supreme Court at the highest level.","Modify,Clarity",Clarity
3492,334-ARR,334-ARR_v2_6@1,334-ARR_v1_6@1,"In terms of number of cases, district courts handle the majority.","In terms of the number of cases, district courts handle the majority of the cases.","Modify,Clarity",Clarity
3493,334-ARR,334-ARR_v2_6@2,334-ARR_v1_6@2,"According to India's National Judicial Data Grid, as of November 2021, there are approximately 40 million cases pending in District Courts (National Judicial Data Grid, 2021) as opposed to 5 million cases pending in High Courts.","According to India's National Judicial Data Grid, as of November 2021, there are approximately 40 million cases pending in District courts (National Judicial Data Grid, 2021) as opposed to 5 million cases pending in High Courts.","Modify,Grammar",Grammar
3494,334-ARR,334-ARR_v2_6@3,334-ARR_v1_6@3,These statistics show an immediate need for developing models that could address the problems at the grass-root levels of the Indian legal system.,These statistics show an immediate need for developing systems that could address the problems at the grass-root levels of the Indian legal system.,"Modify,Clarity",Clarity
3495,334-ARR,334-ARR_v2_2@3,334-ARR_v1_2@3,The problem gets even more pronounced in the case of low resource languages such as Hindi.,"The problem gets even more pronounced in the case of low resource language (e.g., Hindi).","Modify,Clarity",Clarity
3496,334-ARR,334-ARR_v2_6@4,334-ARR_v1_6@4,"Out of the 40 million pending cases, approximately 20 million are from courts where the official language is Hindi (National Judicial Data Grid, 2021).","Out of 40 million pending cases, approximately 20 million cases are from courts where the official language is Hindi (National Judicial Data Grid, 2021).","Modify,Grammar",Grammar
3497,334-ARR,334-ARR_v2_6@5,334-ARR_v1_6@5,"In this resource paper, we create a large corpus of 912,568 Hindi legal documents.","In this resource paper, we create a large corpus of about 900K Hindi legal documents.","Modify,Fact/Evidence",Fact/Evidence
3498,334-ARR,334-ARR_v2_6@6,334-ARR_v1_6@6,"In particular, we collect documents from the state of Uttar Pradesh, the most populous state of India with a population of approximately 237 million (PopulationU, 2021).","In particular, we collect documents from the state of Uttar Pradesh (U.P.), the most populous state of India with a population of approximately 237 million (Popula-tionU, 2021).","Modify,Clarity",Clarity
3499,334-ARR,334-ARR_v2_6@7,334-ARR_v1_6@7,"The Hindi Legal Documents Corpus (HLDC) can be used for a number of legal applications, and as a use case, in this paper, we propose the task of Bail Prediction.","The Hindi Legal Document Corpus (HLDC) can be used for a number of legal applications, and in this paper, we propose the task of Bail Prediction.","Modify,Clarity",Clarity
3500,334-ARR,334-ARR_v2_2@4,334-ARR_v1_2@4,"In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of more than 900K legal documents in Hindi.","In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of 900K legal documents in Hindi.","Modify,Fact/Evidence",Fact/Evidence
3501,334-ARR,334-ARR_v2_2@5,334-ARR_v1_2@5,Documents are cleaned and structured to enable the development of downstream applications.,The documents are cleaned and structured to enable the development of downstream applications.,"Modify,Grammar",Grammar
3502,334-ARR,334-ARR_v2_12@0,334-ARR_v1_10@0,"Majority of the work in the legal domain has focused on the higher court (Malik et al., 2021b;Strickson and De La Iglesia, 2020;Zhong et al., 2020b); however, the lower courts handle the maximum number of cases.","Majority of the work in the legal domain has focused on the higher court (Malik et al., 2021;Strickson and De La Iglesia, 2020;Zhong et al., 2020b); however, the lower courts handle the maximum number of cases.","Modify,Fact/Evidence",Fact/Evidence
3503,334-ARR,334-ARR_v2_2@6,334-ARR_v1_2@6,"Further, as a use-case for the corpus, we introduce the task of bail prediction.","Further, as a usecase for the corpus, we introduce the task of Bail Prediction.","Modify,Grammar",Grammar
3504,334-ARR,334-ARR_v2_12@3,334-ARR_v1_10@3,"The competition has two sub-tasks, a legal information retrieval task and an entailment identification task between law articles and queries.","The competition had two sub-tasks, a legal information retrieval task and an entailment identification task between law articles and queries.","Modify,Grammar",Grammar
3505,336-ARR,,336-ARR_v1_87@3,,It indicates that utilizing consistent representation learning is a more effective way to utilize memory than the existing memory-based CRE method.,"Delete,Claim",Claim
3506,336-ARR,336-ARR_v2_2@8,,The code is publicly available at https://github.com/thuiar/CRL.,,"Add,Fact/Evidence",Fact/Evidence
3507,336-ARR,336-ARR_v2_36@1,,"P (i) = {p ∈ S I : y p = y i } is the indices set that is the same as the z i label in M b , and |P (i)| is its cardinality.",,"Add,Fact/Evidence",Fact/Evidence
3508,336-ARR,336-ARR_v2_88@0,,"(3) Comparing CRL and CRL (w/o KL), not adopting knowledge distillation during training can cause the model to drop 1% and 0.6% on FewRel and TACRED, respectively.",,"Add,Fact/Evidence",Fact/Evidence
3509,336-ARR,336-ARR_v2_88@1,,The experimental results show that knowledge distillation can uniformly alleviate the model's forgetting of previous knowledge to learn a better consistent representation.,,"Add,Fact/Evidence",Fact/Evidence
3510,336-ARR,336-ARR_v2_83@4,336-ARR_v1_79@4,"In order to facilitate the reproduction of our experimental results, the proposed method source code and detailed hyperparameters are provided on Github 2 .","In order to facilitate the reproduction of our experimental results, the proposed method source code and detailed hyperparameters are provided on https: //github.com/submitacl22/CRL.","Modify,Fact/Evidence",Fact/Evidence
3511,336-ARR,336-ARR_v2_86@0,336-ARR_v1_82@0,(1) Our proposed CRL is significantly better than other baselines and achieves state-of-the-art performance in the vast majority of settings.,(1) Our proposed CRL is significantly better than other baselines and achieves state-of-the-art performance.,"Modify,Claim",Claim
3512,336-ARR,336-ARR_v2_98@1,336-ARR_v1_93@1,"Specifically, we use supervised contrastive learning based on a memory bank to train each new task so that the model can effectively learn the feature representation.","Specifically, we use supervised comparative learning based on a memory bank to train each new task so that the model can effectively learn the feature representation.","Modify,Clarity",Clarity
3513,336-ARR,336-ARR_v2_98@2,336-ARR_v1_93@2,"In addition, in order to prevent the catastrophic forgetting of the old task, we contrast and replay the memory samples, and at the same time, make the model retain the knowledge of the relation between the historical tasks through the knowledge distillation.","In addition, in order to prevent the catastrophic forgetting of the old task, we compare and replay the memory samples, and at the same time, make the model retain the knowledge of the relation between the historical tasks through the knowledge distillation.","Modify,Clarity",Clarity
3514,336-ARR,336-ARR_v2_6@1,336-ARR_v1_6@1,"Although these methods have been verified in simple image classification tasks, previous works have proved that memory-based methods are the most effective in natural language processing applications (Wang et al., 2019;de Masson D'Autume et al., 2019).","Although these methods have been verified in simple image classification tasks, previous works have proved that memory-based methods are the most effective in natural language processing applications (Wang et al., 2019;d'Autume et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
3515,336-ARR,336-ARR_v2_11@6,336-ARR_v1_11@6,"Among these methods, memory-based methods are the most effective in NLP tasks (Wang et al., 2019;Sun et al., 2019;de Masson D'Autume et al., 2019).","Among these methods, memory-based methods are the most effective in NLP tasks (Wang et al., 2019;Sun et al., 2019;d'Autume et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
3516,343-ARR,,343-ARR_v1_4@0,,"Robotic tasks in unstructured (e.g., Stuckler et al. (2012)) or semi-structured (e.g., Correll et al. (2018)) environments involve rearranging objects (Batra et al., 2020) to reach the goal.","Delete,Fact/Evidence",Fact/Evidence
3517,343-ARR,,343-ARR_v1_4@1,,"Such tasks can be solved using task and motion planning if the robot has a full and accurate domain model (Garrett et al., 2021).","Delete,Fact/Evidence",Fact/Evidence
3518,343-ARR,343-ARR_v2_5@4,,"In this work we study the natural language of complex referential expressions (REs) like ""a blue square behind both red circles"" which teachers can use when designating an object.",,"Add,Fact/Evidence",Fact/Evidence
3519,343-ARR,343-ARR_v2_7@0,,"In this work, we develop a method to integrate knowledge from interactively gathered evidence in the form of complex RE-designation pairs to aid data acquisition for a (neural) few-shot grounder.",,"Add,Fact/Evidence",Fact/Evidence
3520,343-ARR,343-ARR_v2_7@2,,"A major novel component to our procedure is that we exploit the formal semantics of closed class word categories (e.g., quantifiers and negation) to boost the data efficiency of few-shot neural grounding models.",,"Add,Fact/Evidence",Fact/Evidence
3521,343-ARR,343-ARR_v2_7@3,,Our experiments show these symbolic inductive biases are successful.,,"Add,Fact/Evidence",Fact/Evidence
3522,343-ARR,343-ARR_v2_92@0,,"We suspect that the reason why the three models performed differently in extrinsic evaluation even though they don't with intrinsic evaluation is down to the fact that IGRE uses its complete and accurate knowledge of the meanings of closed class words like quantifiers and negation at test time as well as training time in the extrinsic evaluation, but not in the intrinsic evaluation.",,"Add,Claim",Claim
3523,343-ARR,343-ARR_v2_92@1,,The IGRE model can use these meanings to constrain and correct error-prone estimates of referents for open class words at test time in the reference task (as well as using their meanings to boost the training sets).,,"Add,Fact/Evidence",Fact/Evidence
3524,343-ARR,343-ARR_v2_92@2,,"For example, the RE ""both squares"" implies there exist exactly two squares; if the symbol grounding model has an uncertain belief that there are more (or fewer) squares than this, it will select the two most probably candidates (and infer that all other entities are non-squares).",,"Add,Fact/Evidence",Fact/Evidence
3525,343-ARR,343-ARR_v2_92@3,,"These experiments suggest that this sort of correction to confident but wrong estimates of the denotations of open-class symbols happens sufficiently often at test time in the reference task to make a difference in this low-data regime we are interested in, for addressing ITL tasks.",,"Add,Fact/Evidence",Fact/Evidence
3526,343-ARR,343-ARR_v2_35@0,343-ARR_v1_31@0,"The RE ""a dog that bit both cats"" has logical form _a_q x._both_q y(cat(y), dog(x) ∧ bit(x, y)) .","The RE ""a dog that bit both cats"" has logical form _a_qx._both_qy.(cat(y), dog(x) ∧ bit(x, y)) .","Modify,Grammar",Grammar
3527,343-ARR,343-ARR_v2_4@0,343-ARR_v1_4@2,"The subfield of robotics known as Interactive Task Learning (ITL, see Laird et al. (2017) for a survey) addresses scenarios where a robot must learn to adapt its behaviour to novel and unforeseen objects, relations, and attributes that are introduced into the environment after deployment.",But there are many scenarios in which the robot must adapt its behaviour to novel and unforeseen objects and attributes that are introduced into the environment after deployment.,"Modify,Fact/Evidence",Fact/Evidence
3528,343-ARR,343-ARR_v2_42@0,343-ARR_v1_39@0,"Matching networks (Vinyals et al., 2016) are an extension of the k nearest-neighbour algorithm (Fix and Hodges, 1989) and has been used as a fast fewshot grounder in the ITL setting (Cano Santín et al., 2020).","Matching networks (Vinyals et al., 2016) are an extension of the k nearest-neighbour algorithm (Fix and Hodges, 1989) and they are usable as a fast fewshot grounder in the ITL setting (Cano Santín et al., 2020).","Modify,Clarity",Clarity
3529,343-ARR,343-ARR_v2_53@0,343-ARR_v1_46@0,"Given S n , one can estimate Θ n either via batch learning performed offline, or-when S n is smallin real time, as outlined by Cano Santín et al. (2020).","Given S n , θ n can be estimated either using batch learning, performed offline, or-when S n is smallin real time, as outlined by Cano Santín et al. (2020).","Modify,Clarity",Clarity
3530,343-ARR,343-ARR_v2_56@0,343-ARR_v1_49@0,S n gets augmented whenever the teacher provides an RE-designation pair.,S n gets augmented whenever the teacher provides feedback in the form of an RE-designation pair.,"Modify,Clarity",Clarity
3531,343-ARR,343-ARR_v2_58@1,343-ARR_v1_51@1,"Whenever the teacher's REdesignation pair features a neologism p * , then this expansion to the learner's vocabulary prompts adding (e n , p * , 0.5) to N n for all e n .","As the teacher provides feedback, if a new concept gets introduced with a neologism p * that the teacher utters, N n gets populated with (e n , p * , 0.5) for all denotations observed so far in the interaction.","Modify,Fact/Evidence",Fact/Evidence
3532,343-ARR,343-ARR_v2_58@2,343-ARR_v1_51@2,"During interaction, each RE-designation pair uttered by the teacher adds elements to C n (for designated symbols) and triggers updates to the N n elements for all entities in the current visual scene, as we'll now describe.","During interaction, each teacher's utterance, corresponding to an RE-designation pair, adds elements to C n (for designated symbols) and triggers updates to the N n elements for all entities in the current visual scene, as we'll now describe.","Modify,Clarity",Clarity
3533,343-ARR,343-ARR_v2_59@0,343-ARR_v1_52@0,Integrating the Teacher's Feedback,Integrating Teacher's Feedback,"Modify,Grammar",Grammar
3534,343-ARR,343-ARR_v2_60@1,343-ARR_v1_53@1,"To compute the beliefs about semantic values, given ∆, we model the semantic value of L-sentences of the form p(t n ), in which t n are all constants (ground atom), as a random variable with Bernoulli's distribution B. Thus a distribution over the possible domain models can be estimated using (propositional) model counting MC (Valiant, 1979), which maps each L-sentence to the number of domain models satisfying it.","To compute the beliefs about semantic values, given ∆, we model the semantic value of L-sentences of the form p(t n ), in which t n are all constants, as a random variable with Bernoulli's distribution B. Thus a distribution over the possible domain models can be estimated using (propositional) model counting MC (Valiant, 1979), which maps each L-sentence to the number of domain models satisfying it.","Modify,Clarity",Clarity
3535,343-ARR,343-ARR_v2_62@1,343-ARR_v1_55@1,"In our experiments we use the ADDMC (Dudek et al., 2020) weighted model counter, with weights set to 0.5.","(in our experiments we are using the ADDMC (Dudek et al., 2020) weighted model counter with weights set to 0.5).","Modify,Grammar",Grammar
3536,343-ARR,343-ARR_v2_73@0,343-ARR_v1_65@0,"To generate training and test sets, we construct ShapeWorld domain models (Kuhnle and Copestake, 2017), each consisting of 3-12 entities, synthesized visual scenes X (64x64 pixels), and 5 REs.","To generate training and test sets, we construct ShapeWorld (Kuhnle and Copestake, 2017) domain models, each consisting of 3-12 entities, synthesized visual scenes X (64x64 pixels), and 5 REs.","Modify,Clarity",Clarity
3537,343-ARR,343-ARR_v2_74@3,343-ARR_v1_67@3,"The data statistics for the training set is given in Table 2 for the general categories of symbols, where certain (C n ) means that the designation is denoted by the symbol in the RE, and noisy (N n ) means that the symbol is a part of the RE but is not designated by it.","The data statistics for the training set is given in Table 2 for the general categories of symbols, where certain means that the designation is denoted by the symbol in the RE, and noisy means that the symbol is a part of the RE but is not designated by it.","Modify,Fact/Evidence",Fact/Evidence
3538,343-ARR,343-ARR_v2_79@0,343-ARR_v1_71@0,"To extract visual features for individuals in the scene, we utilize bounding boxes b = [x left , x right , y top , y bottom ] for each entity e ∈ E in the visual scene by localizing them (cropping) and extracting the visual features using a pre-trained visual feature encoder (in our case, DenseNet161 (Huang et al., 2017)).","To extract visual features for denotations e n ∈ E n , we utilize bounding boxes b = [x lef t , x right , y top , y bottom ] for each entity e ∈ E in the visual scene by localizing them (cropping) and extracting the visual features using a pre-trained visual feature encoder (in our case, DenseNet161 (Huang et al., 2017)).","Modify,Clarity",Clarity
3539,343-ARR,343-ARR_v2_79@1,343-ARR_v1_71@1,"Additionally, for the feature vector, we add each entity's bounding box coordinates for spatial information, lost in the localization process:","Additionally, for the feature vector, we add entity's bounding box coordinates for spatial information, lost in the localization process:","Modify,Clarity",Clarity
3540,343-ARR,343-ARR_v2_84@0,343-ARR_v1_76@0,"For |E| entities, there are |E| 2 denotations to consider for each 2-place predicate-a larger search space compared to |E| denotations for 1-place predicates.","For |E| entities, there are |E| 2 denotations to consider for each 2-place predicate-a larger search space compared to |E| denotations for 1-place predicate.","Modify,Grammar",Grammar
3541,343-ARR,343-ARR_v2_84@1,343-ARR_v1_76@1,"Moreover, these predicates can only be acquired from the noisy component N n because the referent of the second argument to the relation is always latent.","Moreover, these predicates can only be acquired from the noisy component N n because the second argument to the relation is always latent.","Modify,Clarity",Clarity
3542,343-ARR,343-ARR_v2_5@3,343-ARR_v1_5@3,Such language creates the possibility that novel symbolsneologisms-are introduced in a context where their denotation is not designated by the teacher.,"But it is highly natural for the teacher's language to be more complex, creating the possibility that novel symbols-neologisms-are introduced in a context where their denotation is not designated by the teacher (e.g., blue and square when a teacher points to the denotation of the noun phrase ""a red circle behind both blue squares"").","Modify,Claim",Claim
3543,343-ARR,343-ARR_v2_94@1,343-ARR_v1_85@1,"Figure 2 shows that this severely impacts their performance, and error analysis showed that in some experiment runs it leads to model-collapse, with all denotations predicted to be in the extensions of all symbols.","Figure 2 shows that this severely impacts their performance, and error analysis showed that in some experiment runs it leads to mode-collapse, with all denotations predicted to be the extensions of all symbols.","Modify,Grammar",Grammar
3544,343-ARR,343-ARR_v2_6@2,343-ARR_v1_6@2,"Thus, a complex RE and its designation can be used to gather multiple (noisy) training exemplars (both positive and negative) for several symbols at once, even if they have not been designated.","Thus, a single RE and its designation can in principle be used to gather several (noisy) training exemplars (both positive and negative) for several symbols at once, even if these symbols have not been designated by the RE.","Modify,Clarity",Clarity
3545,343-ARR,343-ARR_v2_7@1,343-ARR_v1_6@3,We explore the effect of such a method on data efficiency and the overall grounder's performance.,The main aim of this paper is to explore the effects of this facility on data efficiency and accuracy in learning grounders.,"Modify,Clarity",Clarity
3546,343-ARR,343-ARR_v2_10@2,343-ARR_v1_9@2,"This work, on the other hand, explores how to incrementally extract knowledge from few-shot learning, using sequentially observed evidence that includes neologisms.","This work, on the other hand, explores how to incrementally extract knowledge in a few-shot manner, using sequentially observed evidence that consists of weakly-labelled annotations, including neologisms.","Modify,Clarity",Clarity
3547,343-ARR,343-ARR_v2_12@1,343-ARR_v1_10@1,"This task is often realized as grounded grammar induction from image-caption pairs (Shi et al., 2019;Zhao and Titov, 2020), or as learning (neural) semantic parsers from a reward signal (Williams, 1992) in VQA Yi et al., 2018) or in planning (Azaria et al., 2016;Wang et al., 2016Wang et al., , 2017Karamcheti et al., 2020).","This task is commonly realized as grounded grammar induction from image-caption pairs (Shi et al., 2019;Zhao and Titov, 2020), or as (neural) semantic parsers learning from a reward signal (Williams, 1992) in visual question answering Yi et al., 2018) or in planning (Azaria et al., 2016;Wang et al., 2016Wang et al., , 2017Karamcheti et al., 2020).","Modify,Clarity",Clarity
3548,343-ARR,343-ARR_v2_12@2,343-ARR_v1_10@2,"There, the main objective is to learn to map natural language to logical forms, which in turn get associated with visual percepts during the learning process.","In these scenarios, the primary objective is to learn mappings from linguistic expressions to logical forms, which in turn get associated with certain visual percepts during the learning process.","Modify,Clarity",Clarity
3549,343-ARR,343-ARR_v2_12@3,343-ARR_v1_10@3,This paper does not aim to learn a semantic parser.,This paper does not tackle learning logical forms.,"Modify,Clarity",Clarity
3550,343-ARR,343-ARR_v2_12@4,343-ARR_v1_10@4,"Instead, we obtain logical forms from an existing broad-coverage grammar which is hard to engineer, but is robust on lexical variation (Curran et al., 2007).","Instead, we obtain them from an existing broad-coverage grammar and focus on exploiting the logical consequences of those logical forms during symbol grounding-i.e., our focus is to utilise the interpretation of logical forms, and in particular the truth functional meanings of close-class words like quantifiers and negation, to inform the learning of mappings from (open-class) symbols like red to their denotations, given the visual percepts.","Split+Modify,Fact/Evidence",Fact/Evidence
3551,343-ARR,343-ARR_v2_12@5,343-ARR_v1_10@4,"Our focus instead is on exploiting the logical consequences of those logical forms during symbol grounding-i.e., our focus is to utilise the interpretation of logical forms, and in particular the truth functional meanings of close-class words like quantifiers and negation, to inform the learning of mappings from (open-class) symbols like red to their denotations, given the visual percepts.","Instead, we obtain them from an existing broad-coverage grammar and focus on exploiting the logical consequences of those logical forms during symbol grounding-i.e., our focus is to utilise the interpretation of logical forms, and in particular the truth functional meanings of close-class words like quantifiers and negation, to inform the learning of mappings from (open-class) symbols like red to their denotations, given the visual percepts.","Split+Modify,Clarity",Clarity
3553,343-ARR,343-ARR_v2_11@1,343-ARR_v1_11@0,"This is a task of answering free-form questions about an image (Antol et al., 2015).","Visual Questions Answering (VQA) is a task of answering free-form questions about an image (Antol et al., 2015).","Split+Modify,Clarity",Clarity
3554,343-ARR,343-ARR_v2_11@3,343-ARR_v1_11@2,"Grounded VQA models like (Yi et al., 2018) and Bogin et al. (2021) tackle these shortcomings by grounding parts of the question and then learning to compose those parts via the question's syntax to compute the answer.","Grounded VQA models like (Yi et al., 2018) and Bogin et al. (2021) tackle these shortcomings by learning to ground parts of the question and then learning to compose those parts via the question's syntax to compute the answer.","Modify,Clarity",Clarity
3555,343-ARR,343-ARR_v2_11@5,343-ARR_v1_11@4,These 'compositional' models help to achieve out-of-distribution generalization for novel questions.,"By doing so, these models achieve out-of-distribution generalization for novel questions.","Modify,Clarity",Clarity
3556,343-ARR,343-ARR_v2_11@6,343-ARR_v1_11@5,But they lack ITL's requirement for incremental learning: model training relies on batch learning.,"However, these models lack the ITL's requirement for incremental learning: model training relies on batch learning.","Modify,Clarity",Clarity
3557,343-ARR,343-ARR_v2_11@7,343-ARR_v1_11@6,"Furthermore, while their performance is impressive, error analysis shows that it makes mistakes when language includes logical concepts like quantifiers and negation (e.g. Bogin et al. (2021) Figure 9 shows that the determiner most incorrectly denotes an arbitrary subset of entities).","Furthermore, while their performance is impressive, error analysis shows that it tends to make mistakes on sentences containing logical concepts like quantifiers and negation (e.g. Bogin et al. (2021) Figure 9 shows that the determiner most incorrectly denotes an arbitrary subset of entities).","Modify,Clarity",Clarity
3558,343-ARR,343-ARR_v2_11@8,343-ARR_v1_11@7,Our view is that there is little benefit in trying to learn to ground logic concepts as they are domain independent and can be interpreted using formal semantics.,Our view is that there is little benefit in trying to learn to ground these concepts as they are domain independent and can be interpreted using formal semantics.,"Modify,Clarity",Clarity
3559,343-ARR,343-ARR_v2_11@9,343-ARR_v1_11@8,"In our experiments, we are testing the extent to which knowing and reasoning with the logical meanings of these symbols helps incremental grounding, and in particular estimating denotations of symbols within an RE that are not designated.","In our experiments, we are testing the extent to which knowing and reasoning with the logical meanings of these symbols helps incremental grounding, and in particular estimating denotations of symbols within an RE that aren't designated by that RE.","Modify,Clarity",Clarity
3560,343-ARR,343-ARR_v2_13@1,343-ARR_v1_12@1,"In previous experiments, it is often assumed that there is a unique referent in the visual scene for the given RE in the test phase (Kazemzadeh et al., 2014;Whitney et al., 2016).","In previous experimental setups, it is often assumed that there is a unique referent in the visual scene for the given RE in the test phase (e.g., Kazemzadeh et al. (2014); Whitney et al. (2016)).","Modify,Clarity",Clarity
3561,343-ARR,343-ARR_v2_16@0,343-ARR_v1_15@0,"Predicate logic with generalized quantifiers L ( Barwise and Cooper, 1981;van Benthem, 1984) is a canonical meaning representation for natural languages.","The language L of predicate logic with generalized quantifiers (Barwise and Cooper, 1981;van Benthem, 1984) is a canonical formal meaning representation for natural languages.","Modify,Clarity",Clarity
3596,345-ARR,345-ARR_v2_9@5,,We have released our source code 1 to facilitate future work.,,"Add,Fact/Evidence",Fact/Evidence
3597,345-ARR,345-ARR_v2_40@0,,Relationship with prompt learning.,,"Add,Other",Other
3598,345-ARR,345-ARR_v2_40@2,,"In some tasks, fixed-LM tuning (Li and Liang, 2021) in soft prompting becomes competitive only when the language models been scaled to big enough (Lester et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
3599,345-ARR,345-ARR_v2_40@4,,"Both prompt+LM and fixed-LM prompt tuning require storing separate copies of soft prompts for different tasks, while our approach only saves the trained BERT model, which draws on some ideas in prompt learning and makes our considerations in computational and memory efficiency and generality.",,"Add,Claim",Claim
3600,345-ARR,345-ARR_v2_44@0,,Datasets.,,"Add,Other",Other
3601,345-ARR,345-ARR_v2_17@1,345-ARR_v1_17@1,"Discrete methods usually search the natural language template as the prompt (Davison et al., Petroni et al., 2019), while the continuous way always directly works on the embedding space with ""pseudo tokens"" (Liu et al., 2021;Li and Liang, 2021).","Discrete methods usually search the natural language template as the prompt (Davison et al., 2019;Petroni et al., 2019), while the continuous way always directly works on the embedding space with ""pseudo tokens"" (Liu et al., 2021;Li and Liang, 2021).","Modify,Clarity",Clarity
3602,345-ARR,345-ARR_v2_2@5,345-ARR_v1_2@5,"In addition, we utilize both the gradientupdating and momentum-updating encoders to encode instances while dynamically maintaining an additional queue to store the representation of sentence embeddings, enhancing the encoder's learning performance for negative examples.","In addition, we utilize both the gradient-updating and momentumupdating encoders to encode instances while dynamically maintaining an additional queue to store the representation of sentence embeddings, enhancing the encoder's learning performance for negative examples.","Modify,Grammar",Grammar
3603,345-ARR,345-ARR_v2_21@5,345-ARR_v1_22@1,It is obvious that all the positive examples in SimCSE have the same length and structure while negative examples act oppositely.,"Through careful observation, we find that all the positive examples in SimCSE have the same length and structure while negative examples act oppositely.","Modify,Clarity",Clarity
3604,345-ARR,345-ARR_v2_22@2,345-ARR_v1_23@2,"After we scale the max length that SimCSE could accept from 32 to 64 and 128, the performance degrades significantly during the test even though the model is supposed to learn more from the complete version of sentences(See Table 2).","After we scale the max length that SimCSE could accept from 32 to 64 and 128, the performance degrades significantly during the test even though the model is supposed to learn more from the complete version of sentences.","Modify,Fact/Evidence",Fact/Evidence
3605,345-ARR,345-ARR_v2_26@1,345-ARR_v1_27@1,"We take an additional embedding layer outside the BERT encoder to represent a pseudo sentence {0, 1, ..., m} with fixed length m and syntax.","We take an additional embedding layer outside the BERT encoder to represent a pseudo sentence {0, 1, ..., m} with fixed length m and unchangeable syntax.","Modify,Clarity",Clarity
3606,345-ARR,345-ARR_v2_26@3,345-ARR_v1_27@3,"Random initialization is applied to this layer, and each parameter will be updated during training.","Random initialization is applied to this layer, and the parameter will be updated during training.","Modify,Clarity",Clarity
3607,345-ARR,345-ARR_v2_26@4,345-ARR_v1_27@4,The size of this layer depends on the vocabulary of pseudo tokens(length of pseudo sentences).,The size of this layer depends on the length of pseudo sentences.,"Modify,Clarity",Clarity
3608,345-ARR,345-ARR_v2_26@5,345-ARR_v1_27@5,"Besides, adopting the attention mechanism (Vaswani et al., 2017;Bahdanau et al., 2015;Gehring et al., 2017), we take the pseudo sentence embeddings as the query states of cross attention while key and value states are the sentence embeddings obtained from the BERT encoder.","Besides, adopting the attention mechanism (Vaswani et al., 2017;Bahdanau et al., 2015;Gehring et al., 2017), we take the pseudo sentence embeddings as the query while key and value are the sentence embeddings obtained from the BERT encoder.","Modify,Fact/Evidence",Fact/Evidence
3609,345-ARR,345-ARR_v2_26@6,345-ARR_v1_27@6,This allows the pseudo sentence to attend to the core part and the redundant part of original sentence while keeping the fixed length and structure.,This allows the pseudo sentence to attend to the core part and ignore the redundant part while keeping the fixed length and pseudo syntactic structure.,"Modify,Claim",Claim
3610,345-ARR,345-ARR_v2_34@0,345-ARR_v1_35@0,"Similar to the works based on continuous augmentation, at the very beginning of the framework, PT-BERT takes input sentence s and obtains h i and h ′ i with two different encoder functions.","Similar to the works based on continuous augmentation, at the very beginning of the framework, PT-BERT takes input sentence s and obtained h i and h ′ i with two different encoder functions.","Modify,Grammar",Grammar
3611,345-ARR,345-ARR_v2_36@1,345-ARR_v1_37@1,"Our gradient-update and momentumupdate encoder are based on the pre-trained language model with the same structure and dimensions as BERT-base-uncased (Devlin et al., 2019).","Our gradient-update and momentumupdate encoder is based on the pre-trained language model with the same structure and dimensions as BERT-base-uncased (Devlin et al., 2019).","Modify,Grammar",Grammar
3612,345-ARR,345-ARR_v2_42@1,345-ARR_v1_42@1,"For all tasks, we measure the Spearman's correlation to compare our performance with the previous stateof-the-art SimCSE (Gao et al., 2021).","For all tasks, we measure the Spearman's correlation to compare our performance with SimCSE (Gao et al., 2021).","Modify,Claim",Claim
3613,345-ARR,345-ARR_v2_43@0,345-ARR_v1_43@0,Training Data and Settings,Training,"Modify,Other",Other
3614,345-ARR,345-ARR_v2_47@0,345-ARR_v1_46@0,"We implement PT-BERT based on Huggingface transformers (Wolf et al., 2020) and initialize it with the released BERT base (Devlin et al., 2019).","In this subsection, we implement PT-BERT based on Huggingface transformers (Wolf et al., 2020) and initialize it with the released BERT base (Devlin et al., 2019).","Modify,Clarity",Clarity
3615,345-ARR,345-ARR_v2_47@1,345-ARR_v1_46@1,We initialize a new embedding for pseudo tokens with 128×768.,We initialize a new embedding for pseudo tokens with 128 × 768.,"Modify,Grammar",Grammar
3616,345-ARR,345-ARR_v2_4@2,345-ARR_v1_4@2,"The continuous method treats embeddings of the same original sentence as positive examples and augments sentences with the different encoding functions (Carlsson et al., 2021;Gao et al., 2021).","The continuous method treats embeddings o the same original sentence as positive examples and augments sentences with the different encoding functions (Carlsson et al., 2021;Gao et al., 2021).","Modify,Grammar",Grammar
3617,345-ARR,345-ARR_v2_6@0,345-ARR_v1_6@0,"In contrastive learning for sentence embeddings, a key challenge is constructing positive instances.","In contrastive learning for sentence embeddings, a key challenge is how to construct positive instances.","Modify,Clarity",Clarity
3618,345-ARR,345-ARR_v2_6@2,345-ARR_v1_6@2,"Methods in Wu et al. (2018); Meng et al. (2021) perform discrete operations directly on the original sentences, such as word deletion and sentence shuffling, to get positive samples.","Methods in (Wu et al., 2018;Meng et al., 2021) (e.g., CLEAR) perform discrete operations directly on the original sentences, such as word deletion and sentence shuffling, to get positive samples.","Modify,Clarity",Clarity
3619,345-ARR,345-ARR_v2_2@2,345-ARR_v1_2@2,"In this paper, we propose a semantics-aware contrastive learning framework for sentence embeddings, termed Pseudo-Token BERT (PT-BERT), which is able to exploit the pseudotoken space (i.e., latent semantic space) representation of a sentence while eliminating the impact of superficial features such as sentence length and syntax.","In this paper, we propose a semantic-aware contrastive learning framework for sentence embeddings, termed Pseudo-Token BERT (PT-BERT), which is able to explore the pseudo-token space (i.e., latent semantic space) representation of a sentence while eliminating the impact of superficial features such as sentence length and syntax.","Modify,Grammar",Grammar
3620,345-ARR,345-ARR_v2_7@1,345-ARR_v1_7@1,"Inspired by previous works on prompt learning and sentence selection (Li and Liang, 2021;Liu et al., 2021;Humeau et al., 2020), which create a pseudo-sequence and have it serve the downstream tasks, we present PT-BERT to train pseudo token representations and then to map sentences into pseudo token spaces based on an attention mechanism.","Inspired by previous work on prompt learning and sentence selection (Li and Liang, 2021;Liu et al., 2021;Humeau et al., 2020), which create a pseudo-sequence and have it serve the downstream tasks, we present PT-BERT to train pseudo token representations and then to map sentences into pseudo token spaces based on an attention mechanism.","Modify,Grammar",Grammar
3621,345-ARR,345-ARR_v2_8@0,345-ARR_v1_8@0,"In particular, we train additional 128 pseudo token embeddings, together with sentence embeddings extracted from the BERT model (i.e., gradient-encoder), and then use the attention mechanism (Vaswani et al., 2017) to map the sentence embedding to the pseudo token space (i.e., semantic space).","In particular, we train additional 128 pseudo token embeddings, together with sentence embeddings extracted from the BERT model (i.e., gradient-encoder), and then use the attention mechanism (Devlin et al., 2019) to map the sentence embedding to the pseudo token space (i.e., semantic space).","Modify,Fact/Evidence",Fact/Evidence
3622,345-ARR,345-ARR_v2_8@2,345-ARR_v1_8@2,We treat the representations of the original sentence encoded by the gradientencoder and the momentum-encoder as a positive pair.,We treat the representations of original sentence encoded by the gradient-encoder and the momentum-encoder as a positive pair.,"Modify,Grammar",Grammar
3623,345-ARR,345-ARR_v2_13@0,345-ARR_v1_13@0,Contrastive learning.,Contrastive learning and MoCo.,"Modify,Other",Other
3624,345-ARR,345-ARR_v2_13@5,345-ARR_v1_13@5,"While with a large capacity to store more samples, the memory bank is not consistent enough, which could not update the negative examples during comparison.","While with a large capacity to store more samples, the memory bank is not consistent enough, which could not update the ""key"" during comparison.","Modify,Claim",Claim
3625,345-ARR,345-ARR_v2_15@1,345-ARR_v1_15@1,"CT-BERT (Carlsson et al., 2021) encodes the same sentence with two different encoders.","CT-BERT (Carlsson et al., 2021) encodes same sentence with two different encoders.","Modify,Grammar",Grammar
3626,348-ARR,348-ARR_v2_10@4,,"These findings are also consistent with those of Joshi et al. (2020), who scrape and examine a corpus of approximately 44,000 papers, including both *ACL papers and papers from LREC, COLING, and ACL-affiliated workshops.",,"Add,Fact/Evidence",Fact/Evidence
3627,348-ARR,348-ARR_v2_10@5,,"Joshi et al. present a 6-point taxonomy for classifying languages according to the quantity of labelled and unlabelled corpora and models available for each language, and find that *ACL papers are low in terms of language diversity and are dominated by the highestresource languages.",,"Add,Fact/Evidence",Fact/Evidence
3628,348-ARR,348-ARR_v2_10@6,,"Unfortunately, we were unable to apply our language family-level analysis on their dataset, as it was not publicly available for down-load.",,"Add,Fact/Evidence",Fact/Evidence
3629,348-ARR,348-ARR_v2_10@7,,"While Joshi et al. (2020) find that language diversity is somewhat higher at LREC and ACLaffiliated workshops, the larger issue of language homogeneity in top-tier *ACL venues is extremely problematic.",,"Add,Fact/Evidence",Fact/Evidence
3630,348-ARR,348-ARR_v2_10@8,,"In a research community that calls itself the Association for Computational Linguistics, it is completely unacceptable that fewer than 20% of top-tier *ACL abstracts mention the name of any language (see Table 1), and those that do are dominated by one language (English) and its language family (Indo-European).",,"Add,Claim",Claim
3631,348-ARR,348-ARR_v2_12@0,,"The linguistic homogeneity in *ACL papers can be viewed as a symptom of a much larger problem, namely that our research paradigms are deeply rooted in a Western scientific tradition that is inextricably intertwined with colonialism.",,"Add,Claim",Claim
3632,348-ARR,348-ARR_v2_12@2,,"In *ACL research, the act of not explicitly stating any language, of assuming English as the default, is one such practice.",,"Add,Claim",Claim
3633,348-ARR,348-ARR_v2_13@2,,"The first step in enacting decolonial ethical practices is acknowledging that we hold these assumptions and recognizing that there are other Indigenous philosophies of science that are equally valid and are rooted in fundamentally distinct worldviews that center relationality (see Wilson, 2008).",,"Add,Fact/Evidence",Fact/Evidence
3634,348-ARR,348-ARR_v2_25@0,,"In practical terms, this cognizance and the education requisite in this obligation should typically be provided by a senior researcher (one already very familiar with the relevant issues) whenever a new student or junior researcher first expresses an interest to begin research involving Indigenous data.",,"Add,Claim",Claim
3635,348-ARR,348-ARR_v2_25@1,,"At an institutional level, the leadership of multilingual NLP shared tasks such as the SIG-MORPHON shared tasks should take the lead in educating their respective sub-communities in this regard as such shared tasks consider expansion to include Indigenous language data.",,"Add,Claim",Claim
3636,348-ARR,348-ARR_v2_28@2,,"Put another way, ethical research involving Indigenous data must include concrete deliverables requested by the respective Indigenous community or communities.",,"Add,Claim",Claim
3637,348-ARR,348-ARR_v2_31@1,,This relationship-building should take place before the research project begins.,,"Add,Claim",Claim
3638,348-ARR,348-ARR_v2_31@2,,This relationship between researcher and sovereign Indigenous institutions can be thought of as highly analogous to the relationship between the researcher and governmental granting agencies such as the U.S. National Science Foundation.,,"Add,Claim",Claim
3639,348-ARR,348-ARR_v2_31@3,,"In practical terms, once this relationship has been built and research has begun, the researcher should regularly report to and agree to be held accountable by Indigenous community's governing and decision-making institutions with respect to the agreed-upon community goals.",,"Add,Claim",Claim
3640,348-ARR,348-ARR_v2_35@1,,"In practical terms, this means that researchers seeking to engage with Indigenous data critically examine the harmful ramifications of proposed work well before it is conducted.",,"Add,Claim",Claim
3641,348-ARR,,348-ARR_v1_8@4,,"While 66 abstracts mention Arabic, fewer than 20 abstracts mention any other African language.","Delete,Fact/Evidence",Fact/Evidence
3642,348-ARR,,348-ARR_v1_8@5,,Only 11 abstracts mention any Indigenous language of North America.,"Delete,Fact/Evidence",Fact/Evidence
3643,348-ARR,,348-ARR_v1_8@6,,Only 2 abstracts mention an Indigenous language of Australia.,"Delete,Fact/Evidence",Fact/Evidence
3644,348-ARR,,348-ARR_v1_8@7,,Only 1 abstract mentioned an Indigenous language of Zealandia.,"Delete,Fact/Evidence",Fact/Evidence
3645,348-ARR,,348-ARR_v1_9@0,,No abstracts mentioned any Indigenous language of South America.,"Delete,Fact/Evidence",Fact/Evidence
3646,348-ARR,,348-ARR_v1_13@1,,This is because some abstracts mention multiple languages.,"Delete,Claim",Claim
3647,348-ARR,,348-ARR_v1_13@2,,"This additional 1% represents abstracts that mentioned a language from the Sino-Tibetan, Japonic, or Afro-Asiatic language families and did not also mention an Indo-European language such as English.","Delete,Fact/Evidence",Fact/Evidence
3648,348-ARR,348-ARR_v2_14@0,348-ARR_v1_16@0,"Given the distinct value systems and distinct views of reality of outside research scientists and Indigenous communities, it is not surprising that even good-faith efforts of well-meaning outside researchers are often viewed by Indigenous communities as irrelevant at best and exploitative at worst.","Given the distinct value systems and distinct views of reality of research scientists and Indigenous communities, it is not surprising that even good-faith efforts of well-meaning outside researchers are often viewed by Indigenous communities as irrelevant at best and exploitative at worst.","Modify,Claim",Claim
3649,348-ARR,348-ARR_v2_13@3,348-ARR_v1_16@3,"By failing to acknowledge and critically examine the philosophical foundations of our science, we implicitly and unconsciously elevate our ideas of research and language work above those of Indigenous communities (Leonard, 2017).","By failing to acknowledge and critically examine these philosophical foundations, we implicitly and unconsciously elevate our ideas of research and language work above those of Indigenous communities (Leonard, 2017).","Modify,Clarity",Clarity
3650,348-ARR,348-ARR_v2_17@1,348-ARR_v1_16@5,"Even when we consider the ""lived experiences and issues that underlie [the] needs"" of Indigenous communities, these community priorities are far too often treated as subordinate to research questions deemed valuable by members of academe (Leonard, 2018;Wilson, 2008;Simonds and Christopher, 2013).","Even when we consider the ""lived experiences and issues that underlie [the] needs"" of Indigenous communities, these community priorities are typically treated as subordinate to research questions deemed valuable by members of academe (Leonard, 2018;Wilson, 2008;Simonds and Christopher, 2013).","Modify,Clarity",Clarity
3651,348-ARR,348-ARR_v2_17@2,348-ARR_v1_16@6,"Credulous evangelical claims of technology as savior 7,8 only exacerbate these tensions (Irani et al., 2010;Toyama, 2015).","Credulous evangelical claims of technology as savior 6,7 only exacerbate these tensions.","Modify,Fact/Evidence",Fact/Evidence
3652,348-ARR,348-ARR_v2_19@1,348-ARR_v1_18@1,"It is therefore critically urgent that the ACL, perhaps through the recently-formed Special Interest Group on Endangered Languages (SIGEL), should go beyond the ACL's 2020 adoption of the ACM Code of Ethics 9 and begin a process of drafting and adopting a formal ethics policy specifically with respect to research involving Indigenous communities, Indigenous languages, and Indigenous data.","It is therefore critically urgent that the ACL, perhaps through the recently-formed Special Interest Group on Endangered Languages (SIGEL), should begin a process of drafting and adopting a formal ethics policy with respect to Indigenous communities, Indigenous languages, and Indigenous data.","Modify,Claim",Claim
3653,348-ARR,348-ARR_v2_20@0,348-ARR_v1_18@2,"We should draw upon the recent Linguistics Society of America (2019) ethics statement, the foundational principles of medical ethics (autonomy, nonmaleficence, beneficence, and justice; Beauchamp and Childress, 2001), the recommendations of Bird (2020), and the wisdom of Indigenous scholars such as Deloria, Wilson, Smith, and Leonard.","In doing so, we should draw upon the recent Linguistics Society of America (2019) ethics statement, the foundational principles of medical ethics (autonomy, non-maleficence, beneficence, and justice; Beauchamp and Childress, 2001), the recommendations of Bird (2020), and the wisdom of Indigenous scholars such as Deloria, Wilson, Smith, and Leonard.","Modify,Clarity",Clarity
3654,348-ARR,348-ARR_v2_23@2,348-ARR_v1_21@2,"As outside researchers, we stand in a privileged position, and as such have an urgent obligation to educate ourselves about this history and about current practices that perpetuate these systems of oppression in the present day (Kendi, 2019;Smith, 2012).","As outside academic researchers, we stand in a privileged position, and as such have an urgent obligation to educate ourselves about this history and about current practices that perpetuate these systems of oppression in the present day (Kendi, 2019;Smith, 2012).","Modify,Clarity",Clarity
3656,348-ARR,348-ARR_v2_27@1,348-ARR_v1_25@0,"Many of these rights are enumerated in the Declaration on the Rights of Indigenous Peoples (United Nations, 2007).","Indigenous communities are sovereign political entities with inherent political and human rights which are enumerated in the Declaration on the Rights of Indigenous Peoples (United Nations, 2007).","Split+Modify,Clarity",Clarity
3657,348-ARR,348-ARR_v2_27@2,348-ARR_v1_25@1,"This includes the right of each Indigenous community to protect and develop its culture (Article 11), the right to dignity (Article 15), the right to develop and elect its own decisionmaking institutions (Article 18), and the right to ""maintain, control, protect, and develop [the community's] intellectual property over [its] cultural heritage, traditional knowledge, and traditional cultural expressions"" (Article 31).","This includes the right to protect and develop their culture (Article 11), the right to dignity (Article 15), the right to develop and elect their own decision-making institutions (Article 18), and the right to ""maintain, control, protect, and develop their intellectual property over [their] cultural heritage, traditional knowledge, and traditional cultural expressions"" (Article 31).","Modify,Clarity",Clarity
3659,348-ARR,348-ARR_v2_28@1,348-ARR_v1_26@0,"In practical terms, this means that any outside researcher who wants to work with Indigenous data must seek to engage with the relevant Indigenous communities in order to learn about and to meaningfully support priority areas identified by Indigenous governing bodies and decision-making institutions that fall within our respective scopes of expertise.",The obligation of beneficence therefore mandates that we as researchers ensure that our work benefits the Indigenous communities with which we work in ways that those communities recognize as beneficial; we as outside researchers seeking to engage with Indigenous communities have an obligation to learn about and to meaningfully support priority areas identified by Indigenous governing bodies and decision-making institutions that fall within our respective scopes of expertise.,"Split+Modify,Claim",Claim
3660,348-ARR,348-ARR_v2_34@0,348-ARR_v1_31@1,"We must intentionally adopt the ethical prime directive of the medical community, often stated in the Latin aphorism Primum Non Nocere ""Above all, do no harm"" (Smith, 2005).","We must intentionally adopt the prime ethical directive of the medical community, often stated in the Latin aphorism Primum Non Nocere ""Above all, do no harm"" (Smith, 2005).","Modify,Clarity",Clarity
3661,348-ARR,348-ARR_v2_34@1,348-ARR_v1_31@2,"There are many good and laudable reasons why we should choose to engage in research with Indigenous communities, but none of these reasons is powerful enough to justify harm caused by our research.",There are many good and laudable reasons why we should choose to engage in research with Indigenous communities; but none of these reasons is powerful enough to justify harm to these communities caused by our research.,"Modify,Clarity",Clarity
3662,348-ARR,348-ARR_v2_35@0,348-ARR_v1_32@0,"The obligation of non-maleficence therefore mandates that above all else, we do no harm to Indigenous people and Indigenous communities.","The obligation of non-maleficence therefore mandates that above all else, we do no harm to Indigenous people and Indigenous communities; if we can do good through our research without doing harm, that is well, but it is better to not engage than to cause harm.","Split+Modify,Grammar",Grammar
3664,348-ARR,348-ARR_v2_6@2,348-ARR_v1_5@3,"Bender (2009) surveyed papers from ACL 2008 and found that English dominated (63% of papers), with 20 other languages distributed along a Zipfian tail (Chinese and German shared the number 2 slot at just under 4% of papers each); across all ACL 2008 long papers, only three languages (Hindi, Turkish, and Wambaya) were represented outside of the language families listed previously.","Bender (2009) surveyed papers from ACL 2008 and found that English dominated (63% of papers), with 20 other languages distributed along a long Zipfian tail (Chinese and German shared the number 2 slot at just under 4% of papers each); across all ACL 2008 long papers, only three languages (Hindi, Turkish, and Wambaya) were represented outside of the language families listed previously.","Modify,Clarity",Clarity
3665,348-ARR,348-ARR_v2_6@8,348-ARR_v1_5@10,"Ethical research must actively challenge this colonial legacy by actively acknowledging and opposing its continuing presence, and by explicitly acknowledging and centering Indigenous community goals and Indigenous ways of knowing.",Ethical research must actively challenge this colonial legacy by explicitly acknowledging and centering Indigenous community goals and Indigenous ways of knowing.,"Modify,Claim",Claim
3666,348-ARR,348-ARR_v2_7@1,348-ARR_v1_6@1,"We begin in §2 by examining the abstracts of papers published in the proceedings of the toptier conferences (ACL, NAACL, EMNLP, EACL, AACL) and journals (Computational Linguistics, TACL) of the Association for Computational Linguistics from the past several years (hereafter referred to as *ACL papers/abstracts), replicating the results of Bender (2009), confirming that recent *ACL papers still lack significant language diversity.","We begin in §2 by examining the abstracts of *ACL papers from the past several years, replicating the results of Bender (2009), confirming that recent *ACL papers still lack significant language diversity.","Modify,Fact/Evidence",Fact/Evidence
3667,348-ARR,348-ARR_v2_9@1,348-ARR_v1_8@1,We collect a corpus of 9602 recent *ACL abstracts from the ACL Anthology; 4 more than 80% fail to mention any language (see Table 1).,We collect a corpus of 9602 recent *ACL abstracts from the ACL Anthology; 4 more than 80% fail to mention any language.,"Modify,Fact/Evidence",Fact/Evidence
3668,348-ARR,348-ARR_v2_2@3,348-ARR_v1_2@3,The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside researchers.,The toxic legacy of colonialism permeates every aspect of interaction between Indigenous communities and outside academic researchers.,"Modify,Clarity",Clarity
3669,348-ARR,348-ARR_v2_2@4,348-ARR_v1_2@4,"Ethical research must actively challenge this colonial legacy by actively acknowledging and opposing its continuing presence, and by explicitly acknowledging and centering Indigenous community goals and Indigenous ways of knowing.",Ethical research must actively challenge this colonial legacy by explicitly acknowledging and centering Indigenous community goals and Indigenous ways of knowing.,"Modify,Claim",Claim
3670,35-ARR,,35-ARR_v1_74@4,,The output of the Transformer stack is a sequence of the same length.,"Delete,Fact/Evidence",Fact/Evidence
3671,35-ARR,,35-ARR_v1_75@0,,"For each Transformer decoder state h i , the decoder needs to produce s characters.","Delete,Fact/Evidence",Fact/Evidence
3672,35-ARR,,35-ARR_v1_75@1,,This is done by a light-weight autoregressive LSTM decoder.,"Delete,Fact/Evidence",Fact/Evidence
3673,35-ARR,,35-ARR_v1_75@2,,"In each step, it has two inputs: the embedding of the previously decoded character and a projection of the decoder state h i .","Delete,Fact/Evidence",Fact/Evidence
3674,35-ARR,,35-ARR_v1_75@3,,There are s different linear projections for each of the output character generated from a single Transformer state.,"Delete,Fact/Evidence",Fact/Evidence
3675,35-ARR,35-ARR_v2_9@0,,Character-level processing was hardly possible within the statistical MT paradigm that assumed the existence of phrases consisting of semantically rich tokens that roughly correspond to words.,,"Add,Claim",Claim
3676,35-ARR,35-ARR_v2_9@1,,"Neural sequence-to-sequence models (Sutskever et al., 2014;Bahdanau et al., 2015;Vaswani et al., 2017) do not explicitly work with this assumption.",,"Add,Fact/Evidence",Fact/Evidence
3677,35-ARR,35-ARR_v2_9@2,,"In theory, they can learn to transform any sequence into any sequence.",,"Add,Claim",Claim
3678,35-ARR,35-ARR_v2_11@10,,Kreutzer and Sokolov (2018) support this by showing that RNN models which learn segmentation jointly with the rest of the model are close to character-level.,,"Add,Fact/Evidence",Fact/Evidence
3679,35-ARR,35-ARR_v2_14@3,,Nikolov et al. (2018) experimented with character-level models for romanized Chinese.,,"Add,Fact/Evidence",Fact/Evidence
3680,35-ARR,35-ARR_v2_14@4,,"These models performed comparable to models using logographic signs, but significantly worse than models using subwords.",,"Add,Fact/Evidence",Fact/Evidence
3681,35-ARR,35-ARR_v2_14@5,,Zhang and Komachi (2018) argued that signs in logographic languages carry too much information and were able to improve the translation quality by segmenting Chinese and Japanese into sub-character units while keeping subword segmentation on the English side.,,"Add,Fact/Evidence",Fact/Evidence
3682,35-ARR,35-ARR_v2_31@0,,"Originally, CANINE used a local self-attention span as long as 128 characters.",,"Add,Fact/Evidence",Fact/Evidence
3683,35-ARR,35-ARR_v2_31@1,,"In the case of MT, this would usually span the entire sentence, so we use significantly shorter spans.",,"Add,Fact/Evidence",Fact/Evidence
3684,35-ARR,35-ARR_v2_35@0,,Modifying Charformer for the two-step decoding would require a long padding at the beginning of the sequence causing the decoder to diverge.,,"Add,Claim",Claim
3685,35-ARR,35-ARR_v2_35@1,,"Because of that, we use Lee-style encoding on the decoder side when using Charformer in the encoder.",,"Add,Fact/Evidence",Fact/Evidence
3686,35-ARR,35-ARR_v2_56@0,,Intuitive arguments about the inference algorithms are often based on the properties of the subword output distribution.,,"Add,Claim",Claim
3687,35-ARR,35-ARR_v2_56@1,,"On average, character models will produce distributions with lower perplexity and thus likely suffer more from the exposure bias which might harm sampling from the model.",,"Add,Claim",Claim
3688,35-ARR,35-ARR_v2_56@2,,"Therefore, there is a risk that these empirical findings do not apply to character-level models.",,"Add,Claim",Claim
3689,35-ARR,35-ARR_v2_21@0,35-ARR_v1_18@0,We annotated recent system description papers with the input and output segmentation method they used.,We annotated recent system description papers with what input and output segmentation they used.,"Modify,Clarity",Clarity
3690,35-ARR,35-ARR_v2_22@2,35-ARR_v1_19@0,"Almost all systems use a subword-based vocabulary (BPE: 81%, 71%, 66% in the respective years; SentencePiece: None in 2018, 9% and 25% in the following ones).","Almost all systems use subword-based vocabulary (BPE: 81%, 71%, 66% in the respective years; SentencePiece: None in 2018, 9% and 25% in the following ones).","Modify,Grammar",Grammar
3691,35-ARR,35-ARR_v2_23@2,35-ARR_v1_20@2,"This system, however, makes many suboptimal design choices and ended up as the last one in the manual evaluation.",This system however makes many suboptimal design choices and ended up as the last one in the manual evaluation.,"Modify,Grammar",Grammar
3692,35-ARR,35-ARR_v2_30@1,35-ARR_v1_27@1,Lee et al. (2017) process the sequence of character embeddings with convolutions of different kernel sizes and number of output channels.,Lee et al. (2017) process the sequence of character embeddings with convolutions of different kernel sizes and output channels.,"Modify,Clarity",Clarity
3693,35-ARR,35-ARR_v2_30@3,35-ARR_v1_27@3,"In our preliminary experiments, we observed that a too deep stack of highway layers leads to diminishing gradients, and we replaced the second two High-way layers with feedforward sublayers as used in the Transformer architecture (Vaswani et al., 2017).","In our preliminary experiments, we observed that a too deep stack of highway layers leads to diminishing gradients and we replaced the two Highway layers with feedforward sublayers as used in the Transformer architecture (Vaswani et al., 2017).","Modify,Fact/Evidence",Fact/Evidence
3694,35-ARR,35-ARR_v2_32@1,35-ARR_v1_29@1,"Unlike previous approaches, Charformer (Tay et al., 2021) does not apply a nonlinearity on the embeddings and gets latent subword representations by repeated averaging of character embeddings.","Unlike previous approaches, Charformer (Tay et al., 2021) does not apply nonlinearity on the embeddings and gets latent subword representations by repeated averaging of character embeddings.","Modify,Grammar",Grammar
3695,35-ARR,35-ARR_v2_32@2,35-ARR_v1_29@2,"First, it processes the sequence using a 1D convolution, so the states are aware of their mutual local positions in local neighborhoods.","First, it processes the sequence using a 1D convolution, so the states are aware of their mutual local positions.","Modify,Fact/Evidence",Fact/Evidence
3696,35-ARR,35-ARR_v2_32@3,35-ARR_v1_29@3,"Second, non-overlapping character n-grams of length up to N are represented by averages of the respective character embeddings.","Second, nonoverlapping character n-grams of length up to N are represented by averages of the respective embeddings.","Modify,Clarity",Clarity
3697,35-ARR,35-ARR_v2_32@4,35-ARR_v1_29@4,"This means that for each character, there is a vector that represents the character as a member of n-grams of length 1 to N .","For each character, there is a vector that represents the character as a member of n-grams of length 1 to N .","Modify,Clarity",Clarity
3698,35-ARR,35-ARR_v2_32@7,35-ARR_v1_29@7,"Finally, the sequence is downsampled using mean-pooling with window size and stride size N (i.e., the maximum n-gram size).","Finally, the sequence is downsampled using mean-pooling with window size N .","Modify,Fact/Evidence",Fact/Evidence
3699,35-ARR,35-ARR_v2_38@2,35-ARR_v1_34@2,Our source code is available on Github.,Our source code is attached to the submission.,"Modify,Fact/Evidence",Fact/Evidence
3700,35-ARR,35-ARR_v2_45@1,35-ARR_v1_41@1,"Except for translation into Arabic, where character methods outperform BPEs (which is consistent with the findings of Levy, 2021a andLi et al., 2021), subword methods are always better than characters.","Except for translation into Arabic (which is consistent with the findings of Levy, 2021a andLi et al., 2021), where character methods outperform BPEs, subword methods are always better than characters.","Modify,Clarity",Clarity
3701,35-ARR,35-ARR_v2_51@0,35-ARR_v1_42@1,CANINE is significantly worse.,"Charformer performs similarly to using character embeddings directly, CANINE is significantly worse.","Modify,Fact/Evidence",Fact/Evidence
3702,35-ARR,35-ARR_v2_51@2,35-ARR_v1_42@3,Increasing the downsampling rate from 3 to 5 degrades the translation quality for all architectures.,Increasing the downsampling from 3 to 5 degrades the translation quality for all architectures.,"Modify,Clarity",Clarity
3703,35-ARR,35-ARR_v2_54@0,35-ARR_v1_45@0,"Inference algorithms for neural MT have been discussed extensively (Meister et al., 2020;Massarelli et al., 2020;Shi et al., 2020;Shaham and Levy, 2021b) for the subword models.","Inference algorithm for neural MT have been discussed extensively (Meister et al., 2020;Massarelli et al., 2020;Shi et al., 2020;Shaham and Levy, 2021b) for the subword models.","Modify,Grammar",Grammar
3704,35-ARR,35-ARR_v2_59@2,35-ARR_v1_49@2,Sampling from character-level models leads to very poor translation quality that in turn also influences the MBR decoding leading to much worse results than beam search.,Sampling from character-level models leads to very poor translation quality that in turn also influences the MBR decoding that leads to much worse results than beam search.,"Modify,Clarity",Clarity
3705,35-ARR,35-ARR_v2_66@2,35-ARR_v1_56@2,"For the Lee-style encoder, we double the hidden layer sizes compared to the IWSLT experiments (following the hidden size increase between the Transformer Base and Big architectures).","For the Lee-style encoder, we double the hidden layer sizes compared to the IWSLT experiments (following the hidden size increase between the Transormer Base and Big archtiectures).","Modify,Grammar",Grammar
3706,35-ARR,35-ARR_v2_66@4,35-ARR_v1_56@4,Our code is available on Github 5 .,Our code and systems outputs are attached to the submission.,"Split+Modify,Fact/Evidence",Fact/Evidence
3707,35-ARR,35-ARR_v2_66@5,35-ARR_v1_56@4,System outputs are attached to the paper in the ACL anthology.,Our code and systems outputs are attached to the submission.,"Split+Modify,Fact/Evidence",Fact/Evidence
3708,35-ARR,35-ARR_v2_75@4,35-ARR_v1_65@4,The higher recall of novel forms also suggests slightly better morphological generalization.,Recall of novel forms suggest also slightly better morphological generalization.,"Modify,Clarity",Clarity
3709,35-ARR,35-ARR_v2_78@1,35-ARR_v1_68@1,We speculate that the computational cost is the reason why virtually none of the recent WMT systems used character-level methods or mentioned them as a reasonable alternative.,We speculate that the computational cost is the reason why virtually none of the recent WMT systems used character-level methods nor mention them as a reasonable alternative.,"Modify,Grammar",Grammar
3710,35-ARR,35-ARR_v2_82@1,35-ARR_v1_72@1,"Character models do not suffer from the beam search curse and decoding methods based on sampling perform poorly, here.",Character models do not suffer from the beam search curse and decoding methods based on sampling perform poorly.,"Modify,Clarity",Clarity
3711,35-ARR,35-ARR_v2_10@0,35-ARR_v1_9@0,The original sequence-to-sequence models used word-based vocabularies of a limited size and which led to a relatively frequent occurrence of out-of-vocabulary tokens.,The original sequence-to-sequence models used word-based vocabularies of a limited size and thus relatively frequent occurrence of out-of-vocabulary tokens.,"Modify,Clarity",Clarity
3712,35-ARR,35-ARR_v2_84@2,35-ARR_v1_74@2,Character-level decoding which is both accurate and efficient remains an open research question.,Both accurate and efficient character-level decoding remains an open research question.,"Modify,Clarity",Clarity
3713,35-ARR,35-ARR_v2_93@0,35-ARR_v1_84@0,We set the beta parameters of the Adam optimizer to 0.9 and 0.998 and gradient clipping to 5.,We set the beta parameters of Adam optimizer to 0.9 and 0.998 and gradient clipping to 5.,"Modify,Grammar",Grammar
3714,35-ARR,35-ARR_v2_94@1,35-ARR_v1_85@1,"After model training, we use grid search to estimate the best value of length normalization on the validation set.","After model training, we use grid search to estimate the best value of length normalization on a validation set.","Modify,Grammar",Grammar
3715,35-ARR,35-ARR_v2_11@8,35-ARR_v1_11@5,"Hybrid approaches combining tokenization into words with the computation of character-based word representations were successfully used with RNNs (Luong and Manning, 2016;Grönroos et al., 2017;Ataman et al., 2019).","Hybrid approaches combining tokenization into words followed by the computation of characterbased word representations were successfully used with RNNs (Luong and Manning, 2016;Grönroos et al., 2017;Ataman et al., 2019).","Modify,Clarity",Clarity
3716,35-ARR,35-ARR_v2_11@9,35-ARR_v1_11@6,"Later, Cherry et al. (2018) showed that RNNs perform on par with subword models without changing the model architecture if the models are sufficiently large.","Later, Cherry et al. (2018) showed that with sufficiently large models RNNs do not need architecture modification and perform on par with subword models.","Modify,Clarity",Clarity
3717,35-ARR,35-ARR_v2_12@5,35-ARR_v1_12@5,Banar et al. (2020) reused the convolutional preprocessing layer with constant-size segments of Lee et al. (2017),Banar et al. (2020) reused the convolutional preprocessing layer with constant step segments of Lee et al. (2017) in a Transformer model for translation into English.,"Modify,Fact/Evidence",Fact/Evidence
3718,35-ARR,35-ARR_v2_14@1,35-ARR_v1_12@8,"Their results show that character-level and bytelevel models are usually worse than BPE models, but byte-based models without embedding layers often outperform BPE-based models in the out-of-English direction.","Their results show that although character-level and byte-level models are usually worse than BPE models, byte-based models without embedding layers often outperform BPE-based models in the out-of-English direction.","Modify,Clarity",Clarity
3719,35-ARR,35-ARR_v2_14@2,35-ARR_v1_12@9,"Using similarly small datasets, Li et al. (2021) claim that character-level modeling outperforms BPE when translating into fusional, agglutinative, and introflexive languages.","Using similarly small datasets, Li et al. (2021) outperforms BPE when translating into fusional, agglutinative, and introflexive languages.","Modify,Fact/Evidence",Fact/Evidence
3720,35-ARR,35-ARR_v2_17@2,35-ARR_v1_15@2,"The model shrinks character sequences into fewer hidden states (similar to Lee et al., 2017).","The model shrinks character sequences into less hidden states (similar to Lee et al., 2017).","Modify,Grammar",Grammar
3721,35-ARR,35-ARR_v2_17@5,35-ARR_v1_15@5,Both methods reach a representation quality comparable to similar subword models.,Both reach a representation quality comparable to similar subword models.,"Modify,Clarity",Clarity
3722,35-ARR,35-ARR_v2_18@2,35-ARR_v1_15@8,"These models mostly reach similar results to sub-word models, occasionally outperforming a few of them, in the case of Charformer without a significant slowdown.","These models mostly reach similar results to sub-word models, occasionally outperforming few of them, in the case of Charformer without a significant slowdown.","Modify,Grammar",Grammar
3748,355-ARR,355-ARR_v2_52@0,,All the results are obtained by collecting the predicted boundaries at the end of the last sampling iteration of one single run.,,"Add,Fact/Evidence",Fact/Evidence
3749,355-ARR,355-ARR_v2_61@0,,"Table 2 displays our experimental results for the 5K Mboshi corpus for SentencePiece (SP), dpseg and pypseg with various amounts of supervision.",,"Add,Fact/Evidence",Fact/Evidence
3750,355-ARR,355-ARR_v2_62@0,,"First, the unsupervised dpseg model has better results than SP on all three levels by a significant margin.",,"Add,Fact/Evidence",Fact/Evidence
3751,355-ARR,355-ARR_v2_62@1,,"SP, on the other hand, produces more types as it 'knows' the actual number of types to generate.",,"Add,Fact/Evidence",Fact/Evidence
3752,355-ARR,355-ARR_v2_71@2,,"It gives this model an initial edge over o.regular that remains significant for the first 3,000 sentences.",,"Add,Fact/Evidence",Fact/Evidence
3753,355-ARR,355-ARR_v2_71@3,,"Here again, the benefits of improving the base distribution (character-based model) as much as possible in the early training iterations clearly appear.",,"Add,Claim",Claim
3754,355-ARR,355-ARR_v2_75@2,,"Looking at the detailed results (see appendix A.1, Table 7), one can see that this is due to an undersegmentation, which yields a poor recall at the boundary and token levels.",,"Add,Claim",Claim
3755,355-ARR,355-ARR_v2_76@0,,These preliminary results suggest that considering only one type of boundary is a too naive view of the segmentation process and does not allow us to fully benefit from annotated data.,,"Add,Claim",Claim
3756,355-ARR,355-ARR_v2_76@1,,"They call for models that would carefully distinguish boundaries within words and between words, with appropriate supervision for each of these levels.",,"Add,Claim",Claim
3757,355-ARR,355-ARR_v2_91@0,,"Finally, Table 7 displays the complete results for the word and morpheme experiment (Table 4).",,"Add,Fact/Evidence",Fact/Evidence
3758,355-ARR,355-ARR_v2_25@4,355-ARR_v1_24@4,"They may contain morphs, morphemes, lexemes or fully inflected forms, with various levels of information (part-ofspeech, gloss, translation, etc.).","They may contain morphs, morphemes, lexemes or fully inflected forms, with various levels of information (part-ofspeech, gloss, translation, etc).","Modify,Grammar",Grammar
3759,355-ARR,355-ARR_v2_25@6,355-ARR_v1_24@6,"A related question is about the relative interest of word and morph lists, which we study in Section 5.3.","A related question is about the relative interest of words and morph lists, which we study in Section 5.3.","Modify,Grammar",Grammar
3760,355-ARR,355-ARR_v2_44@2,355-ARR_v1_43@2,"Templates for verb structure are also quite rigid, with affixes following a strict ordering (Godard et al., 2018a).","Templates for verb structure are also quite rigid with affixes following a strict ordering (Godard et al., 2018a).","Modify,Grammar",Grammar
3761,355-ARR,355-ARR_v2_48@0,355-ARR_v1_46@2,"Even though these processes are quite regular, they contribute to generating a large number of possible word forms.","Even though these processes are quite regular, they contribute to generate a large number of possible word forms.","Modify,Grammar",Grammar
3762,355-ARR,355-ARR_v2_49@3,355-ARR_v1_47@3,"The sentences used for semi-supervision correspond to the first 200 sentences of each dataset, which is a realistic amount of data.","The sentences used for semi-supervision are corresponding to the first 200 first sentences of each dataset, which is a realistic amount of data.","Modify,Grammar",Grammar
3763,355-ARR,355-ARR_v2_49@4,355-ARR_v1_47@4,"Likewise, lexical supervision corresponds to the list of words observed in the same 200 sentences, and respectively contain 517 words for Mboshi, 664 words and 493 morphemes for Japhug.","Likewise, lexical supervision corresponds to the list of words observed in the same 200 sentences, and respectively contain 517 words for Mboshi, 664 for Japhug (words), 493 for Japhug (morphemes).","Modify,Clarity",Clarity
3764,355-ARR,355-ARR_v2_58@3,355-ARR_v1_55@3,"As a reminder, our supervision here consists of the first 200 sentences in the text, either directly given as observed boundaries or used to generate the initial word list.","As a reminder, our supervision here consists of the 200 first sentences in the text, either directly given as observed boundaries or used to generate the initial word list.","Modify,Clarity",Clarity
3765,355-ARR,355-ARR_v2_70@1,355-ARR_v1_64@1,"As previously observed, supervision noticeably improves the results for both models, with pypseg outperforming dpseg by a small margin on all metrics.","As previously observed supervision noticeably improves the results for both models, with pypseg outperforming dpseg by a small margin on all metrics.","Modify,Grammar",Grammar
3766,355-ARR,355-ARR_v2_80@1,355-ARR_v1_73@1,"It has been studied in multiple ways, and we report here recent work related to word discovery for language documentation, noting that the same methods also apply to the unsupervised segmentation of continuous speech into 'words' (de Marcken, 1996) which has given rise to a vast literature on language acquisition.","It has been studied in multiple ways and we report here recent work related to word discovery for language documentation, noting that the same methods also apply to the unsupervised segmentation of continuous speech into 'words' (de Marcken, 1996) which has given rise to a vast literature on language acquisition.","Modify,Grammar",Grammar
3767,355-ARR,355-ARR_v2_80@4,355-ARR_v1_74@1,"They were extended with nesting in (Mochihashi et al., 2009), where the base distribution of the Dirichlet Process is a char-based nonparametric model; and in (Uchiumi et al., 2015;Löser and Allauzen, 2016), who consider hidden state variables in the word generation process.","They were extended with nesting in (Mochihashi et al., 2009), where the base distribution of the DP is a char-based non-parametric model; and in (Uchiumi et al., 2015;Löser and Allauzen, 2016), who consider hidden state variables in the word generation process.","Modify,Clarity",Clarity
3768,355-ARR,355-ARR_v2_80@7,355-ARR_v1_74@4,"Finally, (Börschinger and Johnson, 2012) (with particle filtering techniques) and (Neubig, 2014) (with block sampling) study ways to speed up inference.","Finally (Börschinger and Johnson, 2012) (with particle filtering techniques) and (Neubig, 2014) (with block sampling) study ways to speed up inference.","Modify,Grammar",Grammar
3769,355-ARR,355-ARR_v2_82@2,355-ARR_v1_76@2,"Their use necessitates a context-free description of the language, which enables to integrate information regarding word and syllable structures.",Their use necessitates a context-free description of the language which enables to integrate information regarding word and syllable structures.,"Modify,Grammar",Grammar
3770,355-ARR,355-ARR_v2_82@7,355-ARR_v1_76@7,"As our goal is to integrate learning techniques in interactive annotation tools, AGs were not deemed appropriate, and we explored simpler alternatives.","As our goal is to integrate learning techniques in interactive annotation tools, AGs were not deemed appropriate and we explored simpler alternatives.","Modify,Grammar",Grammar
3771,355-ARR,355-ARR_v2_85@2,355-ARR_v1_79@2,"Bayesian non-parametric models lend themselves well to this setting, and our experiments have shown that two variants of a simple unigram model were getting a substantial boost from weak supervision, a result that has been obtained with two languages currently being documented.","Bayesian non-parametric models lend themselves well to this setting, and our experiments have shown that two variants of a simple unigram model were getting a substantial boost from weak supervision.","Modify,Fact/Evidence",Fact/Evidence
3772,355-ARR,355-ARR_v2_85@4,355-ARR_v1_79@4,"Based on this observation, we have further evaluated the longer-term benefits of an incremental training regime and also contrasted the improvement obtained using a word-based vs a morpheme-based vocabulary list.","Based on this observation, we have further evaluated the longer-term benefits of an incremental training regime, and also contrasted the improvement obtained using a wordbased vs. a morpheme-based vocabulary list.","Modify,Grammar",Grammar
3773,355-ARR,355-ARR_v2_86@0,355-ARR_v1_80@0,"Our future work will continue to explore the interplay between word and morpheme segmentations, as both are required in actual documentation settings, possibly extending our analyses on additional languages.","Our future work will continue to explore the interplay between word and morpheme segmentations, as both are required in actual documentation settings.","Modify,Claim",Claim
3774,355-ARR,355-ARR_v2_86@1,355-ARR_v1_80@1,"We will also consider supervising the annotation process with lists of non-inflected forms, which requires to jointly learn inflectional patterns and segmentation.","We will also consider lists of non-inflected forms, which requires to jointly learn inflectional patterns and segmentation.","Modify,Clarity",Clarity
3775,355-ARR,355-ARR_v2_88@2,355-ARR_v1_82@2,"The 'Morf' column displays the performance of Morfessor 2.0 (Creutz and Lagus, 2002;Smit et al., 2014).","The 'morf' column displays the performance of Morfessor 2.0 (Creutz and Lagus, 2002;Smit et al., 2014).","Modify,Grammar",Grammar
3776,355-ARR,355-ARR_v2_88@5,355-ARR_v1_82@5,"The Morfessor model outperforms SentencePiece significantly for both boundary (BF) and token (WF) F-scores, while it lags behind for the type-based metrics.","The Morfessor model outperforms Senten-cePiece significantly for both boundary (BF) and token (WF) F-scores, while it lags behind for the type based metrics.","Modify,Grammar",Grammar
3777,355-ARR,355-ARR_v2_89@0,355-ARR_v1_83@0,"Table 6, in turn, displays the complete results of Table 3, again with both precision and recall for the three evaluation levels.",Table 6 in turn displays the complete results of Table 3 again with both precision and recall for the three evaluation levels.,"Modify,Grammar",Grammar
3778,355-ARR,355-ARR_v2_90@0,355-ARR_v1_84@0,"The 'Morf' column in Table 6 also represents the Morfessor results, with a morph-length parameter of 4.73.","The 'morf' column in Table 6 also represents the Morfessor results, with a morph-length parameter of 4.73.","Modify,Grammar",Grammar
3779,355-ARR,355-ARR_v2_90@1,355-ARR_v1_84@1,"Here again, Morfessor outperforms Senten-cePiece on the boundary and token-level F-scores (to a smaller extent) but not at type level.","Here also, Morfessor outperforms SentencePiece on the boundary and token-level Fscores (to a smaller extent) but not at type level.","Modify,Clarity",Clarity
3780,355-ARR,355-ARR_v2_92@2,355-ARR_v1_84@4,"In the unsupervised model (unsupervised line), the word was wrongly segmented, affecting the second word, 'amipasa'.","In the unsupervised model (unsupervised line), the word was wrongly segmented, affecting the second word 'amipasa'.","Modify,Grammar",Grammar
3781,355-ARR,355-ARR_v2_92@3,355-ARR_v1_84@5,"In the supervised model with d.mix+2gram, the word is correctly segmented as 'obengi', and the second word is also correct, although not in the supervision dictionary.","In the supervised model with d.mix+2gram, the word is correctly segmented as 'obengi' and the second word is also correct, although not in the supervision dictionary.","Modify,Grammar",Grammar
3782,355-ARR,355-ARR_v2_11@0,355-ARR_v1_11@0,"We rely on Bayesian non-parametric approaches to word segmentation (see (Cohen, 2016) for a thorough exposition), and our baselines are the unigram version of the dpseg model and a variant where the underlying Dirichlet Process is replaced by a Pitman-Yor Process as in (Neubig, 2014).","We rely on Bayesian non-parametric approaches to word segmentation (see (Cohen, 2016) for a thorough exposition), and our baselines are the unigram version of the dpseg model (Goldwater et al., 2009) and a variant where the underlying Dirichlet Process is replaced by a Pitman-Yor Process as in (Neubig, 2014).","Modify,Fact/Evidence",Fact/Evidence
3783,355-ARR,355-ARR_v2_11@2,355-ARR_v1_11@2,"While using higher-order models or more sophisticated models of the same family (Teh, 2006b;Mochihashi et al., 2009) may improve the performance (see for an experimental comparison), we believe that in our low-resource conditions, these variations would be small 2 and would not change our main conclusions.","While using higher order models or more sophisticated models of the same family (Teh, 2006b;Mochihashi et al., 2009) may improve the performance (see for an experimental comparison), we believe that in our low-resource conditions these variations would be small, 2 and would not change our main conclusions.","Modify,Grammar",Grammar
3784,355-ARR,355-ARR_v2_18@0,355-ARR_v1_18@0,"An extension of dpseg, denoted pypseg, uses a Pitman-Yor Process (PYP) instead of the Dirichlet Process and generalises equation (1) with an additional discount parameter, which enables to better control the generation of new words.","An extension of dpseg, denoted pypseg, uses a Pitman-Yor Process (PYP) instead of the DP and generalises equation (1) with an additional discount parameter, which enables to better control the generation of new words.","Modify,Clarity",Clarity
3785,355-ARR,355-ARR_v2_20@1,355-ARR_v1_18@3,This implementation is available at https://github.com/ shuokabe/pyseg.,This implementation will be publicly released.,"Modify,Fact/Evidence",Fact/Evidence
3786,360-ARR,,360-ARR_v1_39@0,,Morphology in NLP.,"Delete,Other",Other
3787,360-ARR,360-ARR_v2_10@0,,Narrowing the low-resource category.,,"Add,Other",Other
3788,360-ARR,360-ARR_v2_10@1,,"Lowresource languages have recently gained attention in NLP/CL research, both due to the engineering problems of a data-scarce context and also in recognition of the historical focus on English in the field to the detriment of other languages (Hedderich et al., 2021;Ranathunga et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
3789,360-ARR,360-ARR_v2_10@2,,"This has been accompanied by debate on what languages the label encompasses (e.g. Hämäläinen, 2021).",,"Add,Fact/Evidence",Fact/Evidence
3790,360-ARR,360-ARR_v2_11@0,,"In the South Asian context, even Hindi has been labelled low-resource in some recent work.",,"Add,Fact/Evidence",Fact/Evidence
3791,360-ARR,360-ARR_v2_11@1,,"While it is true that for certain tasks a large institutionallybacked language like Hindi can be low-resource, we propose that 'low-resource' languages can be better described with two kinds of situations:",,"Add,Claim",Claim
3792,360-ARR,360-ARR_v2_13@4,,"Truly data-scarce langauges (e.g. Kangri, Tulu) lack instituational status and have been largely unstudied because the challenges are different and harder to surmount.",,"Add,Claim",Claim
3793,360-ARR,360-ARR_v2_14@1,,"Historical linguistics is concerned with describing change of all kinds (phonological, morphological, syntactic, etc.) in language over time and the factors (social, cognitive, evolutionary) that contribute to that change.",,"Add,Claim",Claim
3794,360-ARR,360-ARR_v2_14@2,,"Comparative linguistics aims to use this historical study to relate languages and reconstruct earlier stages and common ancestors of related languages (Campbell, 2013).",,"Add,Fact/Evidence",Fact/Evidence
3795,360-ARR,360-ARR_v2_28@0,,"In other words, dependency trees are arborescences (directed, rooted trees) equipped with the root constraint (C3).",,"Add,Fact/Evidence",Fact/Evidence
3796,360-ARR,360-ARR_v2_30@0,,"In terms of modern South Asian languages, there has been recent diversification from combined efforts, such as an upcoming dependency parsing shared task at the WILDRE 2022 workshop based on new treebanks (Nallani et al., 2020;Ojha and Zeman, 2020).",,"Add,Fact/Evidence",Fact/Evidence
3797,360-ARR,360-ARR_v2_39@1,,"Historical linguistics work needs data, and in South Asia too much work has progressed without including data from nonstandardised (even if documented) languages, to the detriment of our understanding of South Asian linguistic history post-Sanskrit (Pystenen, 2022).",,"Add,Fact/Evidence",Fact/Evidence
3798,360-ARR,360-ARR_v2_59@0,,A substrate language is one that loans words into a language of higher prestige.,,"Add,Claim",Claim
3799,360-ARR,360-ARR_v2_29@0,360-ARR_v1_22@0,"In a similar vein, we are currently working towards filling other chronological gaps in corpora (e.g. the Old Sinhala Sīgiri Graffiti of the Early New Indo-Aryan stage) through treebanking in parallel with their modern stages (e.g. Sinhala).","In a similar vein, we are currently working towards filling other chronological gaps in corpora (e.g. the Old Sinhala Sīgiri Graffiti of the Early New Indo-Aryan stage) through treebanking in parallel with their low-resourced, modern stages (e.g. Sinhala).","Modify,Clarity",Clarity
3800,360-ARR,360-ARR_v2_30@2,360-ARR_v1_23@1,"More broadly, we are interested in cross-lingual transfer models (Duong et al., 2015;Guo et al., 2015;Schuster et al., 2019) as a means of expediting dependency parsing for data-scarce South-Asian languages.","More broadly, we are interested in cross-lingual transfer models (Duong et al., 2015;Guo et al., 2015;Schuster et al., 2019) as a means of expediting dependency parsing for low-resourced, South-Asian languages.","Modify,Clarity",Clarity
3801,360-ARR,360-ARR_v2_4@1,360-ARR_v1_4@1,"With members of at least four top-level major linguistic families 2 and several putative linguistic isolates, this region is a fascinating arena for linguistic research.","With members of at least five major linguistic families 2 and several putative linguistic isolates, this region is a fascinating arena for linguistic research.","Modify,Claim",Claim
3802,360-ARR,360-ARR_v2_34@3,360-ARR_v1_28@3,Subrahmanyam (2011) published an update to the DEDR utilizing new data on several non-literary languages that became available after 1984.,Subrahmanyam (2013) published an update to the DEDR utilises new data on serveral non-literary languages that became available after 1984.,"Modify,Fact/Evidence",Fact/Evidence
3803,360-ARR,360-ARR_v2_2@0,360-ARR_v1_2@0,"South Asia is home to a plethora of languages, many of which severely lack access to new language technologies.","South Asia is home to a plethora of languages, most of which are severely lacking access to language technologies that have been developed with the maturity of NLP/CL.","Modify,Claim",Claim
3804,360-ARR,360-ARR_v2_36@1,360-ARR_v1_30@1,The obvious benefit of cognate databases for upstream NLP tasks is for data-scarce languages that lack adequate corpora on the web.,The obvious benefit of cognate databases for upstream NLP tasks is for low-resourced languages that lack adequate corpora on the web.,"Modify,Clarity",Clarity
3805,360-ARR,360-ARR_v2_36@3,360-ARR_v1_30@3,"Cognate data can be used for transfer learning, where a data-scarce language can map onto existing models for higherresource languages, such as a distributional semantic model which generally requires massive corpora to train (Sharoff, 2017).","Cognate data can be used for transfer learning, where a lowresourced language can map onto existing models for high-resource languages, such as a distributional semantic model which generally requires massive corpora to train (Sharoff, 2017).","Modify,Clarity",Clarity
3806,360-ARR,360-ARR_v2_40@0,360-ARR_v1_33@1,"Below, we highlight two such projects we are currently engaged in involving three data-scarce languages of northern Pakistan: Burushaski, Gawri, and Torwali (Torwali, 2018).","Below, we highlight two such projects we are currently engaged in involving three low-resourced languages of northern Pakistan: Burushaski, Gawri, and Torwali (Torwali, 2018).","Modify,Clarity",Clarity
3807,360-ARR,360-ARR_v2_42@0,360-ARR_v1_35@0,The languages of northern Pakistan have been synchronically analyzed to have phonemic tonal contrasts.,The languages of northern Pakistan have synchronically been analyzed to have phonemic tonal contrasts.,"Modify,Grammar",Grammar
3808,360-ARR,360-ARR_v2_7@2,360-ARR_v1_7@1,"This data scatteredness persists despite long native traditions of linguistic description, continued language vitality with active use on the internet, and vast numbers of speakers (Rahman, 2008;Groff, 2017).","This data scarcity persists despite long native traditions of linguistic description, continued language vitality with active use on the internet, and vast numbers of speakers (Rahman, 2008;Groff, 2017).","Modify,Fact/Evidence",Fact/Evidence
3809,360-ARR,360-ARR_v2_8@1,360-ARR_v1_8@1,"There is much data to be extracted for even the most endangered languages (e.g., Burushaski, a language isolate of the northwest), from annotated corpora and grammatical descriptions compiled by linguists, if only one is willing to wrangle idiosyncratic data formats and digitise existing texts.","There is much data to be extracted for even the most endangered languages (e.g. Burushaski, a language isolate of the northwest), from annotated corpora and grammatical descriptions compiled by linguists, if only one is willing to wrangle idiosyncratic data formats and digitise existing texts.","Modify,Grammar",Grammar
3810,360-ARR,360-ARR_v2_9@0,360-ARR_v1_9@0,Background,Related work,"Modify,Other",Other
3811,360-ARR,360-ARR_v2_2@1,360-ARR_v1_2@1,"This linguistic diversity also results in a research environment conducive to the study of comparative, contact, and historical linguistics-fields which necessitate the gathering of extensive data from many languages.","This linguistic diversity, however, also results in a research environment conducive to the study of comparative, contact, and historical linguistics-fields which necessitate the gathering of extensive data from many languages.","Modify,Clarity",Clarity
3812,360-ARR,360-ARR_v2_13@1,360-ARR_v1_10@1,"So far, initiatives for improving language technology in South Asia have largely focused on data-scattered (not data-scarce) languages with official status and some degree of standardisation.","So far, initiatives for improving language technology in South Asia have largely focused on languages with official status and some degree of standardisation.","Modify,Fact/Evidence",Fact/Evidence
3813,360-ARR,360-ARR_v2_13@8,360-ARR_v1_11@3,"For example, Hindi, the highest-resourced South Asian language, has massive hand-annotated dependency treebanks (Bhatt et al., 2009), state-of-the-art neural distributional semantic transformer models (Jain et al., 2020;Khanuja et al., 2021), and machine translation models to and from English (Saini and Sahula, 2018).","For example, Hindi, the highest-resourced South Asian language, has massive hand-annotated dependency treebanks , state-of-the-art neural distributional semantic transformer models (Jain et al., 2020;Khanuja et al., 2021), and machine translation models to and from English (Saini and Sahula, 2018).","Modify,Fact/Evidence",Fact/Evidence
3814,360-ARR,360-ARR_v2_13@9,360-ARR_v1_11@4,"This is not to say that there are no resources at all for the languages Joshi et al. (2020) terms ""the Left-Behinds"".","This is not to say that there are no resources at all for the languages (Joshi et al., 2020) terms ""the Left-Behinds"".","Modify,Grammar",Grammar
3815,360-ARR,360-ARR_v2_14@0,360-ARR_v1_12@0,Historical/comparative linguistics.,Comparative linguistics in South Asia.,"Modify,Other",Other
3816,360-ARR,360-ARR_v2_17@0,360-ARR_v1_14@0,"The sole South Asia-wide linguistic data collection effort ever be undertaken was the Linguistic Survey of India, completed about a century ago (Grierson, 1903(Grierson, -1928.","The sole South Asia-wide linguistic data collection effort to ever be undertaken was the Linguistic Survey of India, completed about a century ago (Grierson, 1903(Grierson, -1928.","Modify,Grammar",Grammar
3817,360-ARR,360-ARR_v2_20@0,360-ARR_v1_17@0,"Having established the issue of data scatteredness, the mutual benefit inherent to data collection (for historical/comparative linguistic work and other NLP tasks), as well as possible interesting avenues for future research, we present a compilation of our ongoing projects in this direction, most involving languages that have not been studied in NLP before.","Having established the issue of data scarcity, the mutual benefit inherent to data collection (for historical/comparative linguistic work and other NLP tasks), as well as possible interesting avenues for future research, we present a compilation of our ongoing projects in this direction, most involving languages that have not been studied in NLP before.","Modify,Fact/Evidence",Fact/Evidence
3818,360-ARR,360-ARR_v2_2@3,360-ARR_v1_2@3,"We review recent developments in and at the intersection of South Asian NLP and historical-comparative linguistics, describing our and others' current efforts in this area.","We review recent developments in, and the intersection of, South Asian NLP and historicalcomparative linguistics, explaining our current efforts in this area while also offering new paths towards breaking the data barrier.","Split+Modify,Clarity",Clarity
3819,360-ARR,360-ARR_v2_2@4,360-ARR_v1_2@3,We also offer new strategies towards breaking the data barrier.,"We review recent developments in, and the intersection of, South Asian NLP and historicalcomparative linguistics, explaining our current efforts in this area while also offering new paths towards breaking the data barrier.","Split+Modify,Clarity",Clarity
3820,360-ARR,360-ARR_v2_28@9,360-ARR_v1_21@1,"As the first study of MIA from a computational perspective, this work calls for an analysis of Indo-Aryan regional fragmentation through dialectometry, approaching contentious linguistic issues with statistical arguments curated using treebank data.","As the first study of MIA from a computational perspective, their work calls for an analysis of Indo-Aryan regional fragmentation through dialectometry, approaching contentious linguistic issues with statistical arguments curated using treebank data.","Modify,Clarity",Clarity
3821,361-ARR,,361-ARR_v1_53@1,,Multimodal embeddings are then fed to a Transformer as above.,"Delete,Fact/Evidence",Fact/Evidence
3822,361-ARR,,361-ARR_v1_53@2,,We label this variant encapsulating both visual and temporal context +TEMPORALEMBED-DINGS.,"Delete,Fact/Evidence",Fact/Evidence
3823,361-ARR,,361-ARR_v1_66@0,,Conclusions and Future Work,"Delete,Other",Other
3824,361-ARR,,361-ARR_v1_67@0,,"We created a new challenge, Image Retrieval from Contextual Descriptions (IMAGECODE), which is designed to evaluate the ability of vision-andlanguage models to integrate visual, pragmatic, and temporal context into their predictions.","Delete,Fact/Evidence",Fact/Evidence
3825,361-ARR,,361-ARR_v1_67@1,,"In particular, given a complex and nuanced contextual description, a model is required to retrieve the corresponding image from a set of highly similar candidates.","Delete,Fact/Evidence",Fact/Evidence
3826,361-ARR,,361-ARR_v1_67@2,,"We benchmarked state-of-the-art biencoder and cross-encoder models, such as CLIP and ViLBERT.","Delete,Fact/Evidence",Fact/Evidence
3827,361-ARR,,361-ARR_v1_67@3,,"Moreover, we proposed new variants of these models that are more suitable to solve this task, by augmenting them with a module to attend on the other images in a set and temporal embeddings.","Delete,Fact/Evidence",Fact/Evidence
3828,361-ARR,,361-ARR_v1_67@5,,Images sourced from video frames display the largest gap in performance.,"Delete,Fact/Evidence",Fact/Evidence
3829,361-ARR,,361-ARR_v1_67@6,,"The most challenging phenomena in IMAGECODE include pragmatics, negation, fine-grained distinctions between images, and occlusion among others.","Delete,Fact/Evidence",Fact/Evidence
3830,361-ARR,,361-ARR_v1_72@5,,There is a small amount of dark space between the right bottom corner of the photo and the edge of the cake.,"Delete,Fact/Evidence",Fact/Evidence
3831,361-ARR,,361-ARR_v1_72@7,,Note this phenomena is often linked with very minimally contrastive images.,"Delete,Claim",Claim
3832,361-ARR,361-ARR_v2_17@0,,"We do not claim to explicitly model pragmatics in this paper, i.e. with Rational Speech Acts (Goodman and Frank, 2016).",,"Add,Fact/Evidence",Fact/Evidence
3833,361-ARR,361-ARR_v2_17@2,,"The reasoning in our task and data collection is therefore also similar to ReferItGame and subsequent work (Kazemzadeh et al., 2014;Mao et al., 2016) where one crowdworker generates a referring expressing for an object in a single image and another worker picks an object based on the expression.",,"Add,Fact/Evidence",Fact/Evidence
3834,361-ARR,361-ARR_v2_29@0,,Data Analysis,,"Add,Other",Other
3835,361-ARR,361-ARR_v2_37@6,,"A common example we find in the data are ""gradable"" scenarios, i.e. ""The person is looking down"" might be semantically true for more than one image but it fits best to the image where the person is looking down the most.",,"Add,Claim",Claim
3836,361-ARR,361-ARR_v2_61@4,,Additionally UNITER slightly outperforms ViLBERT as its single-stream architecture might enable richer cross-modal interactions.,,"Add,Claim",Claim
3837,361-ARR,361-ARR_v2_64@0,,"By focusing on the 1000 annotated examples in Table 2 we observe a stark drop from overall performance on the subset of examples containing nuances, visibility/occlusion, and negation (Figure 4).",,"Add,Fact/Evidence",Fact/Evidence
3838,361-ARR,361-ARR_v2_64@1,,This confirms insights from Kassner and Schütze (2020) and Hosseini et al. (2021) on the difficulty of modeling negation in text-only models.,,"Add,Fact/Evidence",Fact/Evidence
3839,361-ARR,361-ARR_v2_53@3,361-ARR_v1_40@3,⊛ represents dot product for CLIP and element-wise multiplication followed by a linear layer for ViLBERT/UNITER.,⊛ represents dot product for CLIP and element-wise multiplication followed by a linear layer for ViLBERT.,"Modify,Fact/Evidence",Fact/Evidence
3840,361-ARR,361-ARR_v2_40@1,361-ARR_v1_41@0,"It is worth noting that ViLBERT and UNITER are more expressive due to their architecture, whereas CLIP boasts a higher parameter count, is pre-trained on a larger dataset and uses a contrastive objective.","BERT is more expressive due to its architecture, whereas CLIP boasts a higher parameter count and is pre-trained on a larger dataset.","Modify,Fact/Evidence",Fact/Evidence
3841,361-ARR,361-ARR_v2_43@1,361-ARR_v1_43@1,"First, we use an alternative objective where all three models are trained on 10-class classification, but the 1 positive and 9 negatives are sourced from the same image set.","First, we use an alternative objective where both CLIP and ViL-BERT are trained on 10-class classification, but the 1 positive and 9 negatives are sourced from the same image set.","Modify,Fact/Evidence",Fact/Evidence
3842,361-ARR,361-ARR_v2_55@1,361-ARR_v1_55@1,"14 We train the full models with a batch size of 360 examples (i.e., 36 image sets) for CLIP and 150 examples for ViLBERT/UNITER.","12 We train the full models with a batch size of 360 examples (i.e., 36 image sets) for CLIP and 150 examples for ViLBERT.","Modify,Fact/Evidence",Fact/Evidence
3843,361-ARR,361-ARR_v2_55@3,361-ARR_v1_55@3,"In the variants that adopt the base version of a model, we select a learning rate of 4 ⋅ 10 −6 for CLIP, 5 ⋅ 10 −6 for ViLBERT, 4 ⋅ 10 −5 for ViL-BERT+CONTEXTBATCH, 8 ⋅ 10 −6 for UNITER, and 7 ⋅ 10 −6 for UNITER++CONTEXTBATCH.","In the variants that adopt the base version of a model, we select a learning rate of 4⋅10 −6 for CLIP, 5⋅10 −6 for ViLBERT, and 4⋅10 −5 for ViLBERT +CONTEXTBATCH.","Modify,Fact/Evidence",Fact/Evidence
3844,361-ARR,361-ARR_v2_56@0,361-ARR_v1_57@0,"For CLIP variants that modify the model architecture, we adopt the following setup: first, we fine-tune the full model in the +CONTEXTBATCH regime as detailed above.","For all the model variants that modify the model architecture, we adopt the following setup: first, we fine-tune the full model in the +CONTEXTBATCH regime as detailed above.","Modify,Fact/Evidence",Fact/Evidence
3845,361-ARR,361-ARR_v2_57@0,361-ARR_v1_58@0,All descriptions in IMAGECODE exceeding the maximum length of the three models are truncated.,All descriptions in IMAGECODE exceeding the maximum length of CLIP and ViLBERT are truncated.,"Modify,Fact/Evidence",Fact/Evidence
3846,361-ARR,361-ARR_v2_59@0,361-ARR_v1_60@0,"In Table 5, we report the performance of the models from Section 5 for all the test examples in IMAGE-CODE as well as for the subsets containing only video frames or static pictures (see Appendix E for validation scores).","In Table 5, we report the performance of the models from Section 5 for all the examples in IMAGE-CODE as well as for the subsets containing only video frames or static pictures.","Modify,Fact/Evidence",Fact/Evidence
3847,361-ARR,361-ARR_v2_59@4,361-ARR_v1_61@1,"In the zero-shot setting, we observe that CLIP representations are surprisingly superior to UNITER/ViLBERT even though CLIP has separate streams to encode an image and its description.","In the zero-shot setting, we observe that CLIP representations are surprisingly superior to ViLBERT even though CLIP has separate streams to encode an image and its description.","Modify,Fact/Evidence",Fact/Evidence
3848,361-ARR,361-ARR_v2_59@5,361-ARR_v1_61@2,"In the simplest fine-tuning setting (i.e., if negatives are randomly sampled independent of the image set), we find that overall there is only a small increase in performance compared to zero-shot inference.","In the simplest fine-tuning setting (i.e., if negatives are randomly sampled independent of the image set), we find that there is only a small increase in performance for both CLIP and ViL-BERT (+5.4% and +8.3%, respectively) compared to zero-shot inference.","Modify,Fact/Evidence",Fact/Evidence
3849,361-ARR,361-ARR_v2_59@9,361-ARR_v1_62@2,"On the other hand, ViLBERT's performance remains the same.","On the other hand, ViLBERT's performance remains the same, as this variant is beneficial for video frames but detrimental for static pictures.","Modify,Fact/Evidence",Fact/Evidence
3850,361-ARR,361-ARR_v2_59@10,361-ARR_v1_62@3,"Stacking a special module for contextualizing multimodal representations on top of the encoders (+CONTEXTMODULE), instead, yields gains for ViLBERT compared to +CON-TEXTBATCH, whereas CLIP and UNITER are unaffected (slight drop).","Stacking a special module for contextualizing multimodal representations on top of the encoders (+CONTEXTMODULE), instead, yields gains for ViLBERT compared to +CON-TEXTBATCH, whereas CLIP is almost unaffected.","Modify,Fact/Evidence",Fact/Evidence
3851,361-ARR,361-ARR_v2_60@0,361-ARR_v1_62@5,"Finally, all three models achieve the highest performance when fine-tuned with both visual and temporal context.","Finally, both CLIP and ViLBERT achieve the highest performance when fine-tuned with both visual and temporal context.","Modify,Fact/Evidence",Fact/Evidence
3852,361-ARR,361-ARR_v2_60@1,361-ARR_v1_62@6,"Adding temporal positional embeddings on top of the contextual module (+TEMPORALEMBEDDINGS) yields an accuracy of 29.9 for CLIP, 25.7 for UNITER and 24.5 for ViL-BERT.",Adding temporal positional embeddings on top of the contextual module (+TEMPORALEMBEDDINGS) yields an accuracy of 28.9 for CLIP and 24.5 for ViLBERT.,"Modify,Fact/Evidence",Fact/Evidence
3853,361-ARR,361-ARR_v2_61@1,361-ARR_v1_63@1,"Across all model variants and training regimes, CLIP consistently achieves higher accuracy than ViLBERT or UNITER.","Across all model variants and training regimes, CLIP consistently achieves higher accuracy than ViLBERT.","Modify,Fact/Evidence",Fact/Evidence
3854,361-ARR,361-ARR_v2_61@2,361-ARR_v1_63@2,"This implies that a larger amount of parameters, pretraining examples or the contrastive objective are more beneficial than ViLBERT's or UNITER's more expressive model architecture.",This implies that a larger amount of parameters and pre-training examples are more beneficial than ViLBERT's more expressive model architecture.,"Modify,Fact/Evidence",Fact/Evidence
3855,361-ARR,361-ARR_v2_61@3,361-ARR_v1_63@3,"Thus, these results violate the expectations that attention between vision and language would be more suitable to jointly encode highly nuanced visual details and descriptions (Miech et al., 2021).","Thus, these results violate the expectations that ViLBERT's cross-attention would be more suitable to jointly encode highly nuanced visual details and descriptions (Miech et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
3856,361-ARR,361-ARR_v2_2@1,361-ARR_v1_2@1,"In order to measure to what extent current vision-and-language models master this ability, we propose a new multimodal challenge, Image Retrieval from Contextual Descriptions (IMAGECODE).","In order to measure to what extent current vision-and-language models master this ability, we devise a new multimodal challenge, Image Retrieval from Contextual Descriptions (IMAGECODE).","Modify,Clarity",Clarity
3857,361-ARR,361-ARR_v2_68@0,361-ARR_v1_71@0,"The Transformer consists of 2 layers in CLIP variants and 4/5 layers in the ViLBERT/UNITER variants, both employing gelu activation.","The Transformer consists of 2 layers in CLIP variants and 4 layers in the ViLBERT variants, both employing gelu activation.","Modify,Fact/Evidence",Fact/Evidence
3858,361-ARR,361-ARR_v2_68@1,361-ARR_v1_71@1,"The learning rate for the fine-tuning of the Transformer and linear heads is 2 ⋅ 10 −6 for the CLIP +CON-TEXTMODULE, 10 −4 for CLIP +TEMPORALEM-BEDDINGS, 2 ⋅ 10 −5 for both ViLBERT variants, and 6 ⋅ 10 −6 for both UNITER variants.","The learning rate for the fine-tuning of the Transformer and linear heads is 2 ⋅ 10 −6 for the CLIP +CONTEXTMODULE, 10 −4 for CLIP +TEMPORALEMBEDDINGS, and 2 ⋅ 10 −5 for both ViLBERT variants.","Modify,Fact/Evidence",Fact/Evidence
3859,361-ARR,361-ARR_v2_68@2,361-ARR_v1_71@2,We use the Volta-framework for the standardized ViLBERT and UNITER model.,We use the Voltaframework for the standardized ViLBERT model.,"Modify,Fact/Evidence",Fact/Evidence
3860,361-ARR,361-ARR_v2_10@0,361-ARR_v1_9@0,"On our new dataset IMAGECODE, we benchmark a series of vision-and-language models that achieve state-of-the-art performance on other multimodal tasks, specifically ViLBERT (Lu et al., 2019) and UNITER (Chen et al., 2020) as two cross-encoder variants and CLIP as a strong biencoder (Radford et al., 2021).","On our new dataset IMAGECODE, we benchmark a series of vision-and-language models that achieve state-of-the-art performance on other multimodal tasks, including both cross-encoders such as ViLBERT (Lu et al., 2019) and bi-encoders such as CLIP (Radford et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
3861,361-ARR,361-ARR_v2_2@10,361-ARR_v1_11@1,We make code and dataset publicly available.,The dataset and models would be publicly released with the cameraready version.,"Modify,Fact/Evidence",Fact/Evidence
3862,361-ARR,361-ARR_v2_17@1,361-ARR_v1_15@0,"Instead we present a dataset that is naturally suitable for pragmatic reasoning (Andreas and Klein, 2016;Cohn-Gordon et al., 2018) as a listener has to consider the context, assume a Gricean speaker and resolve ambiguities resulting from nuanced differences.","IMAGECODE elicits pragmatic reasoning (Andreas and Klein, 2016;Cohn-Gordon et al., 2018) as a listener has to consider the context and resolve ambiguities resulting from nuanced differences to solve the task.","Modify,Fact/Evidence",Fact/Evidence
3863,37-ARR,37-ARR_v2_24@11,,"We compute the inter-annotator agreement on annotation of test sets for KofLU through Fleiss' kappa (κ) (Fleiss and Cohen, 1973), and result in 0.55, where 0.4 < κ < 0.6 indicates moderate agreement.",,"Add,Fact/Evidence",Fact/Evidence
3864,37-ARR,37-ARR_v2_48@0,,Emp-RFT consists of hierarchical structures of encoders through word-level and utterance-level encoders.,,"Add,Fact/Evidence",Fact/Evidence
3865,37-ARR,37-ARR_v2_48@1,,"This structure makes Emp-RFT comprehend each utterance at the fine-grained level, and understand the context by integrating information based on comprehension of each utterance.",,"Add,Claim",Claim
3866,37-ARR,37-ARR_v2_49@1,,Emp-RFT fuses context with keywords as the process illustrated in Figure 4.,,"Add,Fact/Evidence",Fact/Evidence
3867,37-ARR,37-ARR_v2_49@8,,This mechanism makes Emp-RFT not only capture relationships between nodes but also manage influences of each appended node through attention architecture:,,"Add,Fact/Evidence",Fact/Evidence
3868,37-ARR,37-ARR_v2_58@1,,AN o is the appended node.,,"Add,Fact/Evidence",Fact/Evidence
3869,37-ARR,37-ARR_v2_58@2,,Some symbols and edges are omitted for simplicity.,,"Add,Fact/Evidence",Fact/Evidence
3870,37-ARR,37-ARR_v2_91@10,,"Without CP, NEKD, and FCK, Emp-RFT produced a generic response.",,"Add,Fact/Evidence",Fact/Evidence
3871,37-ARR,37-ARR_v2_91@11,,"With the utilization of FCK, Emp-RFT perceived the word 'cancer' in u 3 but expressed excessive emotion by mentioning 'scary'.",,"Add,Fact/Evidence",Fact/Evidence
3872,37-ARR,37-ARR_v2_91@12,,"When Emp-RFT additionally conducted NEKD, Emp-RFT generated emotionally appropriate responses by mentioning 'sorry' and 'hard', and utilized the keyword 'lost'.",,"Add,Fact/Evidence",Fact/Evidence
3873,37-ARR,37-ARR_v2_91@13,,"Lastly, with CP, Emp-RFT generated a diverse response, actively using ky .",,"Add,Fact/Evidence",Fact/Evidence
3874,37-ARR,37-ARR_v2_96@0,,"Our model is implemented by Pytorch 10 , and based on two encoders of BART-base and a decoder of BART-base 11 .",,"Add,Fact/Evidence",Fact/Evidence
3875,37-ARR,37-ARR_v2_24@6,37-ARR_v1_24@6,A tail word of a kp is regarded as a keyword of the listener utterances joined to extract that keyword pair.,A tail word of a kp is regarded as a keyword of the listener utterances used to extract the keyword pair.,"Modify,Clarity",Clarity
3876,37-ARR,37-ARR_v2_24@9,37-ARR_v1_24@9,"Thus, we randomly sample 100 test dialogues in EmpatheticDialogues and ask 3 human workers to annotate whether each word plays important role for empathizing in the listener utterances.","Thus, we randomly sample 100 test dialogues in EmpatheticDialogues and ask 3 human workers to annotate whether each word plays important role in empathizing in the listner utterances.","Modify,Grammar",Grammar
3877,37-ARR,37-ARR_v2_49@4,37-ARR_v1_51@3,Edges are built across the below cases: (1) between two keywords from the same utterance and (2) between a keyword from a certain utterance and another keyword from the previous two utterances.,Edges are built between across the below cases: (1) between two keywords from the same utterance and (2) between a keyword from a certain utterance and another keyword from the previous two utterances.,"Modify,Grammar",Grammar
3878,37-ARR,37-ARR_v2_49@7,37-ARR_v1_51@6,"To obtain keyword representation vi o from the keyword graph(o is the index for nodes.), nodes are updated based on multi-head graph-attention mechanism (Veličković et al., 2018;Li et al., 2022).","To obtain keyword representation vi o (o is the index for nodes.), nodes are updated based on multi-head graph-attention mechanism to capture relationships between nodes (Veličković et al., 2018;Li et al., 2022):","Modify,Fact/Evidence",Fact/Evidence
3879,37-ARR,37-ARR_v2_68@1,37-ARR_v1_67@1,Analysis on the generated responses of the trained Emp-RFT shows that an active reflection of ky is demanded.,Analysis on the generated resopnses of the trained Emp-RFT shows that an active reflection of ky is necessary.,"Modify,Clarity",Clarity
3880,37-ARR,37-ARR_v2_68@2,37-ARR_v1_67@2,"Thus, inspired by Dathathri et al. (2020); , we propose Contrastive PPLM with a discriminator using contrastive loss.","Thus, inspired by Dathathri et al. (2020); Chen et al. ( 2020), we propose Contrastive PPLM with a discriminator using contrastive loss.","Modify,Fact/Evidence",Fact/Evidence
3881,37-ARR,37-ARR_v2_82@4,37-ARR_v1_81@4,"While the utilization of pretrained models yielded significant improvements compared to models only trained on EmpatheticDialogues, Emp-RFT showed even greater performance when compared to Blender+Focused S1 endowed with more significant number of dialogues.","While the utilization of pretrained models yielded significant improvements compared to models only trained on EmpatheticDialogues, Emp-RFT showed even greater performance when compared to Bledner+Focused S1 endowed with more significant number of dialogues.","Modify,Grammar",Grammar
3882,37-ARR,37-ARR_v2_91@6,37-ARR_v1_87@6,"Also, Blender+Focused S1 disregarded the features of u 5 , and therefore overlooked the speaker's sadness.","Also, Blender+Focused S1 disregarded the features of u 5 , and therfore overlooked the speaker's sadness.","Modify,Grammar",Grammar
3883,37-ARR,37-ARR_v2_95@6,37-ARR_v1_91@6,"Lastly, we anticipate our model make potential users be interested and consoled by generating empathetic responses.","Lastly, we anticipate our model make potential users interested and consoled by generating empathetic responses.","Modify,Grammar",Grammar
3884,37-ARR,37-ARR_v2_96@7,37-ARR_v1_92@6,"Through represenations derived from the last token of BART decoder whose parameters are frozen, we can obtain each response representation r a and each keyword set representation ks a , where the keyword set corresponds to the response.","Through represenations derived from the last token of BART decoder whose parameters are frozen, we can obtain each response r a and each keyword set representation ks a , where the keyword set corresponds to the response.","Modify,Clarity",Clarity
3885,37-ARR,37-ARR_v2_13@2,37-ARR_v1_13@2,"Majumder et al. (2020) propose emotion grouping, emotion mimicry, and stochastic sampling.","Majumder et al. (2020) propose emotion grouping, emotion mimicry and stochastic sampling.","Modify,Grammar",Grammar
3886,37-ARR,37-ARR_v2_15@0,37-ARR_v1_15@0,Task Formulation,Task formulation,"Modify,Grammar",Grammar
3887,370-ARR,,370-ARR_v1_48@3,,4 Using a single test set for the whole volume of research on this topic may however produce misleading results.,"Delete,Claim",Claim
3888,370-ARR,,370-ARR_v1_57@6,,"On one hand, larger batches open up the parallelization possibilities to AR models.","Delete,Fact/Evidence",Fact/Evidence
3889,370-ARR,,370-ARR_v1_57@7,,"On the other hand, limited parallelization potential (in form of CPU decoding) reduces the differences between AR and NAR models.","Delete,Fact/Evidence",Fact/Evidence
3890,370-ARR,,370-ARR_v1_57@9,,"We show the results of automatic translation quality evaluation using three different metrics, and the decoding time to translate the test set using a GPU and 36-core CPU with either latency (b=1) or batched (b>1) decoding.","Delete,Fact/Evidence",Fact/Evidence
3891,370-ARR,370-ARR_v2_53@4,,Another reason might be that the different errors of NAR models are causing a domain mismatch between the COMET training data and the data being evaluated.,,"Add,Claim",Claim
3892,370-ARR,370-ARR_v2_23@0,370-ARR_v1_22@0,"We choose the CTC-based architecture for our models because it has been previously shown to be effective for NAR NMT (Gu and Kong, 2021;Saharia et al., 2020) and performs well in the context of non-autoregressive research.","We choose the CTC-based architecture for our models because it has been previously shown to be effective for NAR NMT (Gu and Kong, 2021;Saharia et al., 2020) and performs well in the context of the non-autoregressive research.","Modify,Grammar",Grammar
3893,370-ARR,370-ARR_v2_25@0,370-ARR_v1_24@0,The research goal of the non-autoregressive methods is to improve translation quality while maintaining the speedup brought by the conditional independence assumption.,The research goal of the non-autoregressive methods is to improve the translation quality while maintaining the speedup brought by the conditional independence assumption.,"Modify,Grammar",Grammar
3894,370-ARR,370-ARR_v2_2@6,370-ARR_v1_2@6,"Our results show that, although NAR models are faster on GPUs, with small batch sizes, they are almost always slower under more realistic usage conditions.","Our results show that, although NAR models are faster on GPUs, with small batch sizes, they are nearly always slower under more realistic usage conditions.","Modify,Clarity",Clarity
3895,370-ARR,370-ARR_v2_4@0,370-ARR_v1_4@0,"Non-autoregressive neural machine translation (NAR NMT, or NAT; Gu et al., 2018;Lee et al., 2018) is an emerging subfield of NMT which focuses on increasing the translation speed by changing the model architecture.","Non-autoregressive neural machine translation (NAR NMT, or NAT; Gu et al., 2018;Lee et al., 2018) is an emerging subfield of NMT which focuses on lowering the decoding time complexity by changing the model architecture.","Modify,Fact/Evidence",Fact/Evidence
3896,370-ARR,370-ARR_v2_37@2,370-ARR_v1_36@2,We consider these three parallel datasets clean.,We consider these three parallel dataset clean.,"Modify,Grammar",Grammar
3897,370-ARR,370-ARR_v2_38@3,370-ARR_v1_37@4,"Then, we select the best-scoring 75% of sentence pairs for the final parallel portion of the training dataset.","Then, we select 75% of the best-scoring sentence pairs into the final parallel portion of the training dataset.","Modify,Grammar",Grammar
3898,370-ARR,370-ARR_v2_41@1,370-ARR_v1_40@1,"We used the inverted squareroot learning rate decay with 8,000 steps of linear warm-up and initial learning rate of 10 -4 .","We used the inverted squareroot learning rate decay with 8,000 of linear warmup and initial learning rate of 10 -4 .","Modify,Clarity",Clarity
3899,370-ARR,370-ARR_v2_48@0,370-ARR_v1_47@0,"In this section, we try to view the results of the NAR and efficiency research in a shared perspective.","In this section, we try and view the results of the NAR and efficiency research in a shared perspective.","Modify,Grammar",Grammar
3900,370-ARR,370-ARR_v2_6@0,370-ARR_v1_6@0,The decoding speed is assessed by translating a test set and measuring the overall time the process takes.,The speed of the decoding is assessed by translating a test set and measuring the overall time the process takes.,"Modify,Clarity",Clarity
3901,370-ARR,370-ARR_v2_54@5,370-ARR_v1_54@0,"To amortize the various computation overheads, the models submitted to the shared task are evaluated on a million sentence benchmark dataset.","To amortize for the various computation overheads, the models submitted to the shared task are evaluated on a million sentence benchmark dataset.","Modify,Grammar",Grammar
3902,370-ARR,370-ARR_v2_57@1,370-ARR_v1_57@1,"In Table 5, we present a comparison on the million sentence test set with ""Edinburgh base"", one of the leading submissions in the WMT 21 efficiency task (Behnke et al., 2021), which uses the deep encoder -shallow decoder architecture (Kasai et al., 2021).","In Table 5, we present a comparison on the million sentence test set with ""Edinburgh base"", one of the leading submissions in the WMT 21 efficiency task (Behnke et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
3903,370-ARR,370-ARR_v2_6@3,370-ARR_v1_6@3,"Unlike translation quality, decoding speed can be measured exactly.","Unlike the translation quality, decoding speed can be measured exactly.","Modify,Grammar",Grammar
3904,370-ARR,370-ARR_v2_6@4,370-ARR_v1_6@4,"However, also unlike translation quality, different results are obtained from the same system under different evaluation environments.","However, also unlike the translation quality, different results are obtained under different evaluation environments.","Modify,Clarity",Clarity
3905,370-ARR,370-ARR_v2_7@0,370-ARR_v1_7@0,"In the development of NAR models, modeling error and its subsequent negative effect on translation quality remains the biggest issue.","Over the course of research on NAR models, modeling error and its subsequent negative effect on translation quality remains the biggest issue.","Modify,Clarity",Clarity
3906,370-ARR,370-ARR_v2_8@1,370-ARR_v1_8@1,"To prevent methods from eventually overfitting to a single test set, new test sets are published each year as part of the WMT News Translation Shared Task.","To prevent the methods from eventually overfitting a single test set, new test sets are published each year as part of the WMT News Translation Shared Task.","Modify,Grammar",Grammar
3907,370-ARR,370-ARR_v2_8@2,370-ARR_v1_8@2,"In contrast, translation quality evaluation in NAR research is measured almost exclusively on the WMT 14 English-German test set, using only BLEU scores.","In contrast, translation quality evaluation in NAR research is often measured using BLEU scores only, measured almost exclusively on the WMT 14 English-German test set, which is highly problematic.","Modify,Claim",Claim
3908,370-ARR,370-ARR_v2_8@3,370-ARR_v1_8@3,"Automatic evaluation of translation quality remains an open research problem, but current research advises against relying on a single metric, and especially against relying on only BLEU (Mathur et al., 2020;Kocmi et al., 2021).","Automatic evaluation of translation quality however remains an open research problem (Mathur et al., 2020;Kocmi et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
3909,370-ARR,370-ARR_v2_11@1,370-ARR_v1_10@1,"We train nonautoregressive models based on connectionist temporal classification (CTC), an approach previously shown to be effective (Libovický and Helcl, 2018;Ghazvininejad et al., 2020;Gu and Kong, 2021).","We train nonautoregressive models based on connectionist temporal classification (CTC), an approach previously shown to be effective (Libovický and Helcl, 2018;Gu and Kong, 2021;Ghazvininejad et al., 2020).","Modify,Clarity",Clarity
3910,370-ARR,370-ARR_v2_2@3,370-ARR_v1_2@3,"In this paper, we point out flaws in the evaluation methodology present in the literature on NAR models and we provide a fair comparison between a stateof-the-art NAR model and the autoregressive submissions to the shared task.","In this paper, we point out flaws in the evaluation methodology present in the literature on NAR models and we provide fair comparison between a state-of-the-art NAR model and the autoregressive submissions to the shared task.","Modify,Grammar",Grammar
3911,370-ARR,370-ARR_v2_12@3,370-ARR_v1_11@3,"Second, we link the worlds of non-autoregressive translation and optimization of autoregressive models to provide a better understanding of the results achieved in the related work.","Second, we link the worlds of non-autoregressive translation and model optimization to provide a better understanding of the results achieved in the related work.","Modify,Fact/Evidence",Fact/Evidence
3912,370-ARR,370-ARR_v2_15@0,370-ARR_v1_14@0,"Non-autoregressive models use output distributions which are conditionally independent of each other, which opens up the possibility of parallelization.","Non-autoregressive models use output distributions which are conditionally independent on each other, which opens up the possibility of parallelization.","Modify,Grammar",Grammar
3913,370-ARR,370-ARR_v2_2@4,370-ARR_v1_2@4,"We make the case for consistent evaluation of NAR models, and also for the importance of comparing NAR models with other widely used methods for improving efficiency.","We make the case for consistent evaluation of NAR models, and also for the importance of comparing NAR models with other widely used efficiency approaches.","Modify,Clarity",Clarity
3914,370-ARR,370-ARR_v2_22@0,370-ARR_v1_21@0,"The schema of the CTC-based model, as proposed by Libovický and Helcl (2018), is shown in Figure 1.","The schema CTC-based model, as proposed by Libovický and Helcl (2018), is shown in Figure 1.","Modify,Grammar",Grammar
3915,380-ARR,,380-ARR_v1_52@6,,The python implementations of REM and CEM are available in the supplementary file.,"Delete,Fact/Evidence",Fact/Evidence
3916,380-ARR,380-ARR_v2_12@1,,Sec. 3 introduce our method in details.,,"Add,Fact/Evidence",Fact/Evidence
3917,380-ARR,380-ARR_v2_12@2,,"Sec. 4 presents the results of performance evaluation, and Sec. 5 concludes the paper.",,"Add,Fact/Evidence",Fact/Evidence
3918,380-ARR,380-ARR_v2_28@1,,"Here, x i is a sample, y i is its label.",,"Add,Fact/Evidence",Fact/Evidence
3919,380-ARR,380-ARR_v2_64@1,,"1. For each input sample x i , EPiDA outputs m augmented samples.",,"Add,Fact/Evidence",Fact/Evidence
3920,380-ARR,380-ARR_v2_76@0,,Ablation Study,,"Add,Other",Other
3921,380-ARR,380-ARR_v2_77@0,,Here we conduct ablation study to check the effectiveness of different EPiDA configurations.,,"Add,Fact/Evidence",Fact/Evidence
3922,380-ARR,380-ARR_v2_77@1,,"We take CNN as the classifier, EDA as the DA algorithm and report the Macro-F1 score over five repeated experiments on TREC 1% and Irony 1%.",,"Add,Fact/Evidence",Fact/Evidence
3923,380-ARR,380-ARR_v2_77@2,,Tab. 5 shows the experimental results.,,"Add,Fact/Evidence",Fact/Evidence
3924,380-ARR,380-ARR_v2_78@0,,Effect of REM and CEM.,,"Add,Other",Other
3925,380-ARR,380-ARR_v2_78@1,,"The 4th and 5th rows show the results with only REM and CEM, respectively.",,"Add,Fact/Evidence",Fact/Evidence
3926,380-ARR,380-ARR_v2_24@4,380-ARR_v1_19@4,"Thus, we do not conduct performance comparison between EPiDA and LearnDA.","Thus, we do not have performance comparison between EPiDA and LearnDA.","Modify,Clarity",Clarity
3927,380-ARR,380-ARR_v2_24@5,380-ARR_v1_19@5,"Nevertheless, in our ablation study, we replace REM and CEM with PPL and cosine similarity in EPiDA, and our experimental results show that EPiDA with REM and CEM performs better than that with PPL and cosine similarity.","Nevertheless, in our ablation study, we replace REM and CEM with PPL and cosine similarity in EPiDA, and our experimental results show that EPiDA with REM and CEM performs better than with PPL and cosine similarity.","Modify,Grammar",Grammar
3928,380-ARR,380-ARR_v2_2@6,380-ARR_v1_2@6,"Extensive experiments show that EP-iDA outperforms existing SOTA methods in most cases, though not using any agent network or pre-trained generation network, and it works well with various DA algorithms and classification models.","Extensive experiments show that EPiDA outperforms existing SOTA methods in most cases, though not using any agent networks or pre-trained generation networks, and it works well with various DA algorithms and classification models.","Modify,Grammar",Grammar
3929,380-ARR,380-ARR_v2_39@1,380-ARR_v1_34@1,The problem turns to solve Eq. ( 4) and Eq. ( 5).,The problem turns to solve Eq. (4) and Eq. (5).,"Modify,Grammar",Grammar
3930,380-ARR,380-ARR_v2_51@1,380-ARR_v1_45@1,"Furthermore, to meet Eq. ( 8), we select samples {t j i } by solving the following optimization problem:","Furthermore, to meet Eq. ( 8), we select samples {t j i } by solving the following optizimation problem:","Modify,Grammar",Grammar
3931,380-ARR,380-ARR_v2_56@1,380-ARR_v1_48@1,"Eq. ( 9) can also be expanded to the difference between Shannon entropy H and mutual information I, i.e., H(X|Y )=H(X)-I(X, Y ).","Eq. ( 9) can also be expanded to the difference between shannon entropy H and mutual information I, i.e., H(X|Y )=H(X)-I(X, Y ).","Modify,Grammar",Grammar
3932,380-ARR,380-ARR_v2_56@2,380-ARR_v1_48@2,"In other words, CEM minimizes the entropy of the selected sample t j i and maximizes the mutual information between t j i and the original sample x i , which means that CEM tries to augment samples of high prediction probability and high similarity with the original sample.","In other words, CEM minimizes the entropy of the selected sample t j i and maximizes the mutual information between t j i and the original sample x i , which means that CEM tries to augment samples of high prediction probability and high similarity.","Modify,Clarity",Clarity
3933,380-ARR,380-ARR_v2_4@1,380-ARR_v1_4@2,"In natural language processing (NLP), (Xie et al., 2017;Coulombe, 2018;Niu and Bansal, 2018;Wei and Zou, 2019) find that native augmentation skills such as spelling errors, synonym replacement, deleting and swapping, can bring considerable performance improvement.","In natural language processing (NLP), (Xie et al., 2017;Coulombe, 2018;Niu and Bansal, 2018;Wei and Zou, 2019) find that native augmentation skills such as spelling errors, synonyms replacement, deleting and swapping, can bring considerable performance improvement.","Modify,Grammar",Grammar
3934,380-ARR,380-ARR_v2_2@0,380-ARR_v1_2@0,"Recent works have empirically shown the effectiveness of data augmentation (DA) for NLP tasks, especially for those suffering from data scarcity.","Recent works have empirically shown the effectiveness of data augmentation (DA) in NLP tasks, especially for those suffering from data scarcity.","Modify,Grammar",Grammar
3935,380-ARR,380-ARR_v2_64@7,380-ARR_v1_52@7,"By nature, the goals of REM and CEM are conflicting, i.e., a sample of high diversity is more probably of low quality, and vice versa.","By nature, the goals of REM and CEM are conflicting, i.e., a sample of high diversity is more probably of low quality, and vise versa.","Modify,Grammar",Grammar
3936,380-ARR,380-ARR_v2_64@10,380-ARR_v1_52@10,"REM encourages to change salient words, which is prone to break the semantic consistency (see the 3rd row, ""excited"" is changed to ""mad"", leading to large diversity score but small quality score).","REM encourages to change salient words, which is prone to break the semantic consistency (see the 2nd row, 'excited' is changed to 'mad', leading to large diversity score but small quality score).","Modify,Fact/Evidence",Fact/Evidence
3937,380-ARR,380-ARR_v2_64@11,380-ARR_v1_52@11,"However, CEM tends to make the augmented samples keep semantic consistency, i.e., has large quality score but small diversity score (see the 4th row, ""comes"" is deleted).","However, CEM tends to make the augmented samples keep semantic consistency, i.e., has large quality score but small diversity score (see the 3rd row, 'comes' is deleted).","Modify,Fact/Evidence",Fact/Evidence
3938,380-ARR,380-ARR_v2_67@0,380-ARR_v1_56@0,"In this section, we conduct extensive experiments to evaluate EPiDA, including performance comparison with SOTA methods, performance evaluation when working with different DA algorithms and classification models, ablation study, and qualitative visualization of samples augmented by EPiDA.","Here we conduct extensive experiments to evaluate EPiDA, including performance comparison with SOTA methods, performance evaluation when working with different DA algorithms and classification models, ablation study, and qualitative visualization of samples augmented by EPiDA.","Modify,Clarity",Clarity
3939,380-ARR,380-ARR_v2_73@4,380-ARR_v1_61@4,"3) The variants of EPiDA that utilize only REM or CEM to enhance diversity or quality are inferior to using both, which demonstrates the effectiveness of joint enhancement.","3) The variants of EPiDA that utilize only REM or CEM to enhance diversity or quliaty are inferior to using both, which demonstrates the effectiveness of joint enhancement.","Modify,Grammar",Grammar
3940,380-ARR,380-ARR_v2_73@8,380-ARR_v1_61@8,We also provide experimental comparisons with other DA approaches (SUB 2 and VDA) and generation speed results in the supplementary file.,We also provide experimental comparasions with other DA approaches (SUB 2 and VDA) and generation speed results in the supplementary file.,"Modify,Grammar",Grammar
3941,380-ARR,380-ARR_v2_5@2,380-ARR_v1_4@5,"The reason lies in that data augmentation for NLP is in discrete space, so it can easily incur large deviation of semantics (e.g. in sentiment classification task, deleting emotional words from a sentence will make its meaning completely different).","The reason lies in that data augmentation for NLP is in discrete space, so it can easily incur large deviation in semantics (e.g. in sentiment classification task, deleting emotional words from a sentence will make its meaning completely different).","Modify,Grammar",Grammar
3942,380-ARR,380-ARR_v2_6@0,380-ARR_v1_5@0,"Generally, given the size of generated data, their diversity and quality are crucial to the performance of targeted tasks (Ash et al., 2019).","Generally, given the size of generated data, their diversity and quality are crucial to the performance of targeted tasks.","Modify,Fact/Evidence",Fact/Evidence
3943,380-ARR,380-ARR_v2_89@2,380-ARR_v1_73@2,"EPiDA is general, effective, efficient, and easy-to-deploy.","EPiDA is easy-to-deploy, effective and efficient.","Modify,Fact/Evidence",Fact/Evidence
3944,380-ARR,380-ARR_v2_89@3,380-ARR_v1_73@3,"In the future, more verification of our method is expected to be conducted on other classification tasks.","In future, more verification of our method is expected to be conducted on other classification tasks.","Modify,Grammar",Grammar
3945,380-ARR,380-ARR_v2_6@4,380-ARR_v1_5@4,"In addition, some works (Morris et al., 2020) in NLP utilize adversarial augmentation to enrich the diversity of the samples.","In addition, some works (Morris et al., 2020) in NLP utilize adversarial augmentation to enrich the diveristy of the samples.","Modify,Grammar",Grammar
3946,380-ARR,380-ARR_v2_6@6,380-ARR_v1_5@6,"Besides, recent existing DA methods for NLP tasks usually resort to pre-trained language models, are extremely inefficient due to huge model complexity and tedious finetuning, which limits the scope of their applications.","Besides, existing DA methods for NLP usually resort to pre-trained language models, are extremely inefficient due to huge model complexity and tedious finetuning, which limits their applications.","Modify,Clarity",Clarity
3947,380-ARR,380-ARR_v2_9@0,380-ARR_v1_6@3,"EPiDA can work with various existing DA algorithms and classification models, it is general, efficient, and easy-to-deploy.","EP-iDA can work with various existing DA algorithms and classification models, it is easy-to-deploy, general and efficient.","Modify,Clarity",Clarity
3948,380-ARR,380-ARR_v2_10@0,380-ARR_v1_6@4,2. We design two mechanisms relative entropy maximization (REM) and conditional entropy minimization (CEM) to boost the diversity and quality of augmented data simultaneously in an explicit and controllable way.,2) We design two mechanisms relative entropy maximization (REM) and conditional entropy minimization (CEM) to boost the diversity and quality of augmented data simultaneously in an explicit and controllable way.,"Modify,Grammar",Grammar
3949,380-ARR,380-ARR_v2_2@2,380-ARR_v1_2@2,"However, to the best of our knowledge, most existing methods consider only either the diversity or the quality of augmented data, thus cannot fully tap the potential of DA for NLP.","However, to the best of our knowledge, most existing methods consider only either the diversity or the quality of augmented data, thus cannot fully mine the potential of DA for NLP.","Modify,Clarity",Clarity
3950,380-ARR,380-ARR_v2_11@0,380-ARR_v1_6@5,3. We conduct extensive experiments to evaluate EPiDA.,3) We conduct extensive experiments to evaluate EPiDA.,"Modify,Grammar",Grammar
3951,380-ARR,380-ARR_v2_14@0,380-ARR_v1_8@0,"In this section, we first review the related work of DA for NLP, then expound the differences between our method and the major existing ones.","Here we first review the related work of DA for NLP, then expound the differences between our method and the major existing ones.","Modify,Clarity",Clarity
3952,380-ARR,380-ARR_v2_16@2,380-ARR_v1_10@2,"EDA (Wei and Zou, 2019) and AEDA (Karimi et al., 2021) introduce random insertions, swaps, and deletions.","EDA (Wei and Zou, 2019) and AEDA (Karimi et al., 2021) introduces random insertions, swaps, and deletions.","Modify,Grammar",Grammar
3953,380-ARR,380-ARR_v2_18@2,380-ARR_v1_12@2,"Due to the discrete nature of inputs of NLP tasks, such methods can be applied to NLP tasks only via padding and mixing embeddings or higher hidden layers (Chen et al., 2020;Si et al., 2021).","Due to the discrete input of NLP tasks, such methods can be applied to NLP tasks via padding and mixing embeddings or higher hidden layers (Chen et al., 2020;Si et al., 2021).","Modify,Clarity",Clarity
3954,380-ARR,380-ARR_v2_20@1,380-ARR_v1_14@1,"Among these approaches, Back-translation (Sennrich et al., 2016;Yu et al., 2018) translates sentences into another language and then translates it back to the original language.","Among these approaches, BACKTRANSLATION (Sennrich et al., 2016;Yu et al., 2018) translates sentences into another language and then translates it back to the original language.","Modify,Grammar",Grammar
3955,380-ARR,380-ARR_v2_23@1,380-ARR_v1_18@1,"Only the recent LearnDA (Zuo et al., 2021) and VDA consider both diversity and quality, and only AA uses feedback of the classifier.","Only the recent LearnDA (Zuo et al., 2021) and VDA (Zhou et al., 2021) consider both diversity and quality, and only AA uses feedback of the classifier.","Modify,Fact/Evidence",Fact/Evidence
3956,383-ARR,,383-ARR_v1_43@10,,9 The maximum number of explored states per sentence was set to 1M.,"Delete,Fact/Evidence",Fact/Evidence
3957,383-ARR,,383-ARR_v1_43@11,,This threshold was reached for less than 1.45% of the German-English sentences.,"Delete,Fact/Evidence",Fact/Evidence
3958,383-ARR,,383-ARR_v1_43@12,,See Appendix A for other language directions.,"Delete,Fact/Evidence",Fact/Evidence
3959,383-ARR,383-ARR_v2_2@6,383-ARR_v1_2@6,By using smaller beam sizes we can speed up inference by a factor of 3.9x and still match or improve the BLEU score obtained using softmax.,By using smaller beam sizes we can speed up inference by a factor of 3.9x and still match or improve the softmax BLEU score.,"Modify,Clarity",Clarity
3960,383-ARR,383-ARR_v2_38@5,383-ARR_v1_39@5,We expect further speed-ups when comparing models with larger vocabularies.,We expect further speed-ups from SCONES when comparing models with larger vocabularies.,"Modify,Clarity",Clarity
3961,383-ARR,383-ARR_v2_40@4,383-ARR_v1_41@4,Stahlberg et al. (2022) provided strong evidence that this length deficiency is due to the intrinsic uncertainty of the MT task.,Anonymous (2022) provided strong evidence that this length deficiency is due to the intrinsic uncertainty of the MT task.,"Modify,Fact/Evidence",Fact/Evidence
3962,383-ARR,383-ARR_v2_41@4,383-ARR_v1_43@3,"Fig. 4, which displays the length ratio (the hypothesis length divided by the reference length) versus beam size, suggests that the differences in BLEU trajectories are partly due to translation lengths.","Fig. 4, which displays the length ratio (the hypothesis length divided by the reference length) versus beam size, suggests that the differences in BLEU trajectories arise due to translation lengths.","Modify,Claim",Claim
3963,383-ARR,383-ARR_v2_41@5,383-ARR_v1_43@4,"Translations obtained using softmax become shorter at higher beam sizes whereas for SCONES with α = 0.2, there is no such steep decrease in length.","Translations obtained using softmax become abruptly shorter at higher beam sizes whereas for SCONES with α = 0.2, there is no such steep decrease in length.","Modify,Clarity",Clarity
3964,383-ARR,383-ARR_v2_4@2,383-ARR_v1_4@2,"Therefore, learning a single distribution over all target language sentences does not allow the model to naturally express intrinsic uncertainty 2 (Padó et al., 2009;Dreyer and Marcu, 2012;Ott et al., 2018;Stahlberg et al., 2022), the nature of the translation task to allow multiple semantically equivalent translations for a given source sentence.","Therefore, learning a single distribution over all target language sentences does not allow the model to naturally express intrinsic uncertainty 2 (Padó et al., 2009;Dreyer and Marcu, 2012;Ott et al., 2018), the nature of the translation task to allow multiple semantically equivalent translations for a given source sentence.","Modify,Fact/Evidence",Fact/Evidence
3965,383-ARR,383-ARR_v2_49@8,383-ARR_v1_50@8,"We formulate the next word prediction at each time step as an MLC problem to handle intrinsic uncertainty, but our models are predicting ordered target sequences, not bags of words.","We formulate the next word prediction at each time step as a MLC problem to handle intrinsic uncertainty, but our models are predicting ordered target sequences, not bags of words.","Modify,Grammar",Grammar
3966,383-ARR,383-ARR_v2_4@3,383-ARR_v1_4@3,"A single distribution over all sequences represents uncertainty by assigning probabilities, but it cannot distinguish between different kinds of uncertainty (e.g. model uncertainty versus intrinsic uncertainty).","Single distributions over all sequences represent uncertainty by assigning probabilities, but they cannot distinguish between different kinds of uncertainty (e.g. model uncertainty versus intrinsic uncertainty).","Modify,Grammar",Grammar
3967,383-ARR,383-ARR_v2_7@0,383-ARR_v1_7@0,SCONES can be tuned to mitigate some of the pathologies of traditional NMT models.,SCONES mitigates some of the pathologies of traditional NMT models.,"Modify,Clarity",Clarity
3968,383-ARR,383-ARR_v2_17@2,383-ARR_v1_18@2,"However, using such a multi-label classification view requires a different training loss function because, unlike the probabilities from a softmax, the probabilities in Eq. 4 do not provide a normalized distribution over the vocabulary.","However, using such a multi-label classification view requires a different training loss function because, unlike the logits from a softmax, the logits in Eq. 4 do not provide a normalized distribution over the vocabulary.","Modify,Clarity",Clarity
3969,39-ARR,39-ARR_v2_13@0,,"The rest of this paper is organized as follows: section 2 provides an thorough description of our proposed model, section 3 presents and analyses the results from our experiments, section 4 provides a brief review of related work, and section 5 includes our conclusions.",,"Add,Fact/Evidence",Fact/Evidence
3970,39-ARR,39-ARR_v2_46@2,,"Of course, this can only be done for samples in the source language as the labels for the target-language data are unavailable:",,"Add,Fact/Evidence",Fact/Evidence
3971,39-ARR,39-ARR_v2_64@0,,Hyper-parameters,,"Add,Other",Other
3972,39-ARR,39-ARR_v2_65@0,,We fine-tune the hyper-parameters for our OA-CLED model using the development data.,,"Add,Fact/Evidence",Fact/Evidence
3973,39-ARR,39-ARR_v2_65@1,,We apply the following values based on the fine-tuning process:,,"Add,Fact/Evidence",Fact/Evidence
3974,39-ARR,39-ARR_v2_66@0,,"• AdamW as the optimizer. • 5 warm up epochs. • A learning rate of 1e −5 for the transformer parameters and of 1e −4 for the rest of the parameters. • A batch size of 16. • 300 for the dimensionality of the layers in feed-forwards networks. • A γ = 0.5 for the percentage of samples used in adversarial training. • A λ = 0.001 as the scaling factor of the GRL layer. • An α = 1 and β = 0.001 as the trade-off parameters of the LD loss and ED loss, respectively. • A dropout of 10% for added regularization during training.",,"Add,Fact/Evidence",Fact/Evidence
3975,39-ARR,39-ARR_v2_70@1,,"First, the previous state-of-the-art CLED model BERT-CRF (M'hamdi et al., 2019) as described in section 2.2.",,"Add,Fact/Evidence",Fact/Evidence
3976,39-ARR,39-ARR_v2_70@2,,"Second, the mBERT-2TA model (Majewska et al., 2021) which aims at improving cross-lingual performance by incorporating language-independent verb knowledge via task-specific adapters.",,"Add,Fact/Evidence",Fact/Evidence
3977,39-ARR,39-ARR_v2_86@2,,Figure 2 shows the results of our experiments when using different amounts of labeled target data during training.,,"Add,Fact/Evidence",Fact/Evidence
3978,39-ARR,39-ARR_v2_97@3,,"We also note that, while this work focuses on the event detection task, our proposed optimization of the adversarial training process is task independent and can be generalized to other related IE tasks when leveraging ALA is deemed beneficial.",,"Add,Claim",Claim
3979,39-ARR,39-ARR_v2_21@0,39-ARR_v1_20@0,"Our goal is to define a model able to generate language-invariant word representations that are refined enough so that cross-lingual issues, such as the ones described in section 1, are properly handled.","Our goal is to define a model able to generate language-invariant word representations that are refined enough so that cross-lingual issues, such as the ones described previously, are properly handled.","Modify,Clarity",Clarity
3980,39-ARR,39-ARR_v2_23@0,39-ARR_v1_22@0,"Here, we briefly describe the BERT-CRF model proposed by M'hamdi et al. ( 2019) which was the previous state-of-the-art and serves as our main baseline.","Here we briefly describe the BERT-CRF model (M'hamdi et al., 2019) which was the previous state-of-the-art and serves as our baseline.","Modify,Clarity",Clarity
3981,39-ARR,39-ARR_v2_23@1,39-ARR_v1_22@1,"Using multilingual BERT (mBERT, (Devlin et al., 2019)) as its encoder, BERT-CRF generates robust, contextualized representations for words from different languages.","Using mBERT (Devlin et al., 2019) as its encoder, BERT-CRF generates robust, contextualized representations for words from different languages.","Modify,Clarity",Clarity
3982,39-ARR,39-ARR_v2_24@1,39-ARR_v1_23@1,"In summary, the contextualized representation vectors h i generated by the mBERT encoder from the words in the sequence are then fed to a CRF layer which finds the optimal label sequence.","As such, the representation vectors h i of the words in the sequence are fed to a CRF layer which finds the optimal label sequence.","Modify,Fact/Evidence",Fact/Evidence
3983,39-ARR,39-ARR_v2_26@3,39-ARR_v1_25@3,"Majewska et al. (2021), for instance, propose to address this issue by injecting external verb knowledge into the encoder via taskspecific adapter modules (Pfeiffer et al., 2020).","Majewska et al. (2021), for instance, propose to address this issue by injecting external verb knowledge into the encoder via adapter modules (Pfeiffer et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
3984,39-ARR,39-ARR_v2_2@7,39-ARR_v1_2@8,"Thus, we propose leveraging Optimal Transport as a solution to naturally combine these two distinct information sources into the selection process.","Thus, we propose using Optimal Transport as a solution to naturally combine these two distinct information sources into the selection process.","Modify,Clarity",Clarity
3985,39-ARR,39-ARR_v2_2@8,39-ARR_v1_2@9,"Extensive experiments on 8 different language pairs, using 4 languages from unrelated families, show the flexibility and effectiveness of our model that achieves state-of-the-art results.","Extensive experiments on 8 different language pairs, using 4 languages from unrelated families, show the flexibility and effectiveness of our model that achieves new state-of-the-art results.","Modify,Clarity",Clarity
3986,39-ARR,39-ARR_v2_40@0,39-ARR_v1_40@0,One challenge of using the two mentioned criteria for the ALA sample selection process is that they come with two different measures which are hard to combine.,One challenge of using these two criteria for ALA sample selection process is that they come with two different measures which are hard to combine.,"Modify,Clarity",Clarity
3987,39-ARR,39-ARR_v2_40@1,39-ARR_v1_40@1,"To address this, we propose using Optimal Transport (OT) (Villani, 2008) as a natural way to combine these two metrics into a single framework for sample selection.","We propose using Optimal Transport (OT) (Villani, 2008) as a natural way to combine these two metrics into a single framework for sample selection.","Modify,Clarity",Clarity
3988,39-ARR,39-ARR_v2_46@1,39-ARR_v1_48@1,"Thus, the auxiliary dataset D aux is augmented to include an event-presence label e i for each sample.","Thus, the auxiliary dataset D aux is augmented to include an event-presence label e i for each sample, D aux = {(w 1 , l 1 , e 1 ), . . . , (w 2m , l 2m , e 2m )}, and the EP module is trained to optimize the following loss:","Split+Modify,Fact/Evidence",Fact/Evidence
3989,39-ARR,39-ARR_v2_48@0,39-ARR_v1_48@1,The EP module is then trained to optimize the following loss:,"Thus, the auxiliary dataset D aux is augmented to include an event-presence label e i for each sample, D aux = {(w 1 , l 1 , e 1 ), . . . , (w 2m , l 2m , e 2m )}, and the EP module is trained to optimize the following loss:","Split+Modify,Clarity",Clarity
3990,39-ARR,39-ARR_v2_63@1,39-ARR_v1_63@1,"To include an additional language in our experiments, we also evaluate on the ERE dataset which has annotated data in English and Spanish.","To include an additional language in our experiments, we also evaluate on the ERE version of ACE05 which has annotated data in English and Spanish.","Modify,Clarity",Clarity
3991,39-ARR,39-ARR_v2_63@2,39-ARR_v1_63@2,Note that the ACE05 and ERE datasets do not share the same label set: ACE05 involves 33 distinct event types while ERE involves 38 event types.,"The ACE05 and ACE05-ERE versions, however, do not share the same label set: ACE05 involves 33 distinct event types while ACE05-ERE involves 38 event types.","Modify,Clarity",Clarity
3992,39-ARR,39-ARR_v2_69@0,39-ARR_v1_65@1,"The Chinese-Spanish, Spanish-Chinese, Arabic-Spanish, and Spanish-Arabic language combinations are unavailable due the previously mentioned incompatibility between the event type sets in ACE05 and ERE.","The Chinese-Spanish, Spanish-Chinese, Arabic-Spanish, and Spanish-Arabic language combinations are unavailable due the previously mentioned incompatibility between the event type sets in ACE05 and ACE05-ERE.","Modify,Clarity",Clarity
3993,39-ARR,39-ARR_v2_71@0,39-ARR_v1_66@0,"Table 2 and Table 3 show the results of our experiments on the ACE05 and ERE datasets, respectively.","Tables 1 and 2 show the results of our experiments on the ACE05 and ACE05-ERE datasets, respectively.","Modify,Clarity",Clarity
3994,39-ARR,39-ARR_v2_70@0,39-ARR_v1_66@1,We compare our OACLED model against 3 relevant baselines.,We compare our OACLED model against 2 relevant baselines.,"Modify,Fact/Evidence",Fact/Evidence
3995,39-ARR,39-ARR_v2_70@3,39-ARR_v1_66@2,"And third, XLM-R-CRF which is equivalent in all regards to BERT-CRF except that it uses XLM-RoBERTa (Conneau et al., 2019) as the encoder.","BERT-CRF (M'hamdi et al., 2019), and XLM-R-CRF which is equivalent in all regards to BERT-CRF except that it uses XLM-RoBERTa as the encoder 2 .","Modify,Fact/Evidence",Fact/Evidence
3996,39-ARR,39-ARR_v2_71@1,39-ARR_v1_66@3,"In all our experiments, we use the base transformer versions bert-base-cased and xlm-robertabase as the encoders, parameters are tuned on the development data of the source language, and all entries are the average of five runs.","In our experiments, we use bertbase-cased and xlm-roberta-base for the encoders, parameters are tuned on the development data of the source language, and all entries are the average of five runs.","Modify,Clarity",Clarity
3997,39-ARR,39-ARR_v2_72@0,39-ARR_v1_67@0,"From Tables 2 and 3, it should be noted that there is a substantial performance increase by performing the trivial change of replacing mBERT with XLM-RoBERTa as the encoder.","From Tables 1 and 2, we can observe a substantial performance increase by performing the trivial change of replacing BERT with XLM-RoBERTa as the encoder.","Modify,Fact/Evidence",Fact/Evidence
3998,39-ARR,39-ARR_v2_72@3,39-ARR_v1_67@3,"Most importantly, OACLED's improvement over the XLM-R-CRF baseline is present in every configuration, which validates the effectiveness of our optimized approach to ALA training.","Most importantly, OA-CLED's improvement over the XLM-R-CRF baseline is present in every configuration, which confirms the effectiveness of our optimized approach to ALA training.","Modify,Clarity",Clarity
3999,39-ARR,39-ARR_v2_74@3,39-ARR_v1_69@3,"In order to understand the contribution of these aspects, we explore four different models: OACLED-OT presents the effects of removing sample selection entirely and using all available samples to train the LD; OACLED-L2 uses a constant distance between the unlabeled samples instead the standard L2 distance used in the Sinkhorn algorithm; OACLED-EP completely removes the EP module and a uniform distribution is used as the probability distributions for both languages; finally, OACLED-ED-Loss keeps the EP module, but removes its EP loss term from Equation 10.","In order to understand the contribution of these aspects, we explore four different models: OACLED-OT the effects of removing sample selection entirely and using all available samples to train the LD; OACLED-L2 uses a constant distance between the unlabeled samples instead the standard L2 distance used in the Sinkhorn algorithm; OACLED-EP completely removes the EP module and a uniform distribution is used as the probability distributions for both languages; finally, OACLED-ED-Loss keeps the EP module, but removes its EP loss term from Equation 10.","Modify,Clarity",Clarity
4000,39-ARR,39-ARR_v2_84@0,39-ARR_v1_80@0,"We observe that OACLED representations are closer, by several orders of magnitude, than those obtained by the baseline.","We observe that OACLED representations are closer, by several orders of magnitude, those obtained by the baseline.","Modify,Clarity",Clarity
4001,39-ARR,39-ARR_v2_6@0,39-ARR_v1_6@0,"Alternatively, Cross-Lingual ED (CLED) proposes the scenario of creating models that effectively perform ED on data belonging to more than one language, which brings about additional challenges.","Alternatively, Cross-Lingual ED (CLED) proposes the scenario of creating models that effectively perform ED on data belonging to more than one language, which entails additional challenges.","Modify,Clarity",Clarity
4002,39-ARR,39-ARR_v2_93@2,39-ARR_v1_89@2,"More recent efforts have primarily made use of deep learning techniques such as convolutional neural networks (Nguyen and Grishman, 2015;Chen et al., 2015;Nguyen et al., 2016b), recurrent neural networks (Nguyen et al., 2016a;Sha et al., 2018;Lai et al., 2020), graph convolutional networks (Nguyen and Grishman, 2018;Yan et al., 2019;Nguyen et al., 2021a), adversarial networks (Hong et al., 2018;Zhang et al., 2019b), and pre-trained language models (Wadden et al., 2019;Zhang et al., 2019a;Yang et al., 2019;Zhang et al., 2020;Liu et al., 2020;Pouran Ben Veyseh et al., 2021b,a).","More recent efforts have primarily made use of deep learning techniques such as convolutional neural networks (Nguyen and Grishman, 2015;Chen et al., 2015;Nguyen et al., 2016b), recurrent neural networks (Nguyen et al., 2016a;Sha et al., 2018;Nguyen andNguyen, 2019), graph convolutional networks (Nguyen andGrishman, 2018a;Yan et al., 2019), adversarial networks (Hong et al., 2018;Zhang et al., 2019b), and pre-trained language models (Wadden et al., 2019;Zhang et al., 2019a;Yang et al., 2019;Zhang et al., 2020;Liu et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
4004,39-ARR,39-ARR_v2_6@3,39-ARR_v1_6@2,Accurate verb handling is of particular importance for the ED task as event triggers are usually related to the verbs in a sentence.,"An example of this phenomenon are verb conjugations where some tenses only exist in some languages, which is commonplace in ED as event triggers are usually related to the verbs in a sentence.","Split+Modify,Fact/Evidence",Fact/Evidence
4005,39-ARR,39-ARR_v2_94@2,39-ARR_v1_91@0,"Adversarial Language Adaptation, inspired by models in domain adaptation research (Ganin and Lempitsky, 2015;Naik and Rose, 2020;Ngo Trung et al., 2021), has been successfuly applied at generating language-invariant models (Joty et al., 2017;Chen et al., 2018;Nguyen et al., 2021b).","Adversarial Language Adaptation, inspired by models in domain adaptation research (Ganin and Lempitsky, 2015;Naik and Rose, 2020), has been successfuly applied at generating languageinvariant models (Joty et al., 2017;Chen et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
4006,39-ARR,39-ARR_v2_97@0,39-ARR_v1_94@0,"We present OACLED, a new model for crosslingual event detection that learns fine-grained language-invariant representations by optimizing the standard ALA training through optimaltransport-based sample selection.",We present a new model for Cross-Lingual Event Detection that leverages unlabeled data through ALA and OT to achieve new state-of-the-art performance.,"Modify,Fact/Evidence",Fact/Evidence
4007,39-ARR,39-ARR_v2_97@1,39-ARR_v1_94@1,Our model achieves new state-of-the-art performance in our experiments on 8 different language pairs which demonstrate its robustness and effectiveness at generating refined language-invariant representations that allow for better event detection results.,Our experiments on 8 different language pairs demonstrate our approach's robustness and effectiveness at generating refined language-invariant representations that allow for better event detection results.,"Modify,Clarity",Clarity
4008,39-ARR,39-ARR_v2_97@2,39-ARR_v1_94@2,Our analysis of its intermediate outputs and predictions confirm that OACLED's representations are indeed closer to each other and that this proximity translates into better handling of difficult cross-lingual instances.,Our analysis of its intermediate outputs and predictions confirm that our model's representations are indeed closer to each other and that this proximity translates into better handling of difficult cross-lingual instances.,"Modify,Clarity",Clarity
4009,39-ARR,39-ARR_v2_6@4,39-ARR_v1_6@3,"Some recent work (Majewska et al., 2021) has attempted to address this issue by injecting external verb knowledge into the training process.","Some recent work (Majewska et al., 2021) attempts to address this issue by injecting external linguistic knowledge into the training process.","Modify,Grammar",Grammar
4010,39-ARR,39-ARR_v2_6@5,39-ARR_v1_6@4,Another similar problematic issue for CLED are triggers with different meanings that are each distinct words in different languages.,Another problematic issue are triggers with different meanings that are each distinct words in other languages.,"Modify,Clarity",Clarity
4011,39-ARR,39-ARR_v2_6@6,39-ARR_v1_6@5,"For instance, the word ""juicio"" in Spanish can either mean ""judgement"" or ""trial"" in English, depending on the context.","For instance, the word ""juicio"" in Spanish can be either ""judgement"" or ""trial"" in English, depending on the context.","Modify,Clarity",Clarity
4012,39-ARR,39-ARR_v2_7@3,39-ARR_v1_7@3,"Yet, their performance still shows room for improvement as they sometimes struggle to handle the difficult instances, unique to cross-lingual settings, mentioned earlier.","Yet, their performance still shows room for improvement as they are unable to handle the difficult instances, unique to cross-lingual settings, mentioned earlier.","Modify,Clarity",Clarity
4013,39-ARR,39-ARR_v2_2@2,39-ARR_v1_2@2,"Their performance, however, reveals there is room for improvement as the crosslingual setting entails particular challenges.","Their performance, however, reveals there is room for improvement as they mishandle delicate cross-lingual instances.","Modify,Claim",Claim
4014,39-ARR,39-ARR_v2_7@5,39-ARR_v1_7@5,"It is our intuition that by integrating unlabeled target-language data into the training process, the model is exposed to more language context which should help deal with issues such as verb variation and multiple connotations.","It is our intuition that by integrating unlabeled data into the training process, the model is exposed to more language context which should help deal with issues such as verb variation and multiple connotations.","Modify,Clarity",Clarity
4015,39-ARR,39-ARR_v2_8@1,39-ARR_v1_8@1,The key idea is to generate language-invariant representations that are not indicative of language but remain informative for the ED task.,The key idea is to generate language-invariant representations that are not indicative of language but remain informative for the task.,"Modify,Clarity",Clarity
4016,39-ARR,39-ARR_v2_10@3,39-ARR_v1_10@3,"Thus, we suggest presenting the LD with examples that have similar contextual semantics, i.e., similar contextualized representations.","Thus, we suggest presenting the LD with examples that have similar contextual semantics, i.e., similar representations.","Modify,Clarity",Clarity
4017,39-ARR,39-ARR_v2_10@4,39-ARR_v1_10@4,"Second, we consider that sentences containing events should provide an ED system with additional task-relevant information when compared against non-event samples.","Second, we consider sentences containing events to be more relevant for the LD.","Modify,Claim",Claim
4018,39-ARR,39-ARR_v2_10@5,39-ARR_v1_10@5,"Accordingly, we argue that event-containing sentences should have a larger probability of being selected for ALA training.","Accordingly, such sentences should have a larger probability of being selected for ALA training.","Modify,Clarity",Clarity
4019,39-ARR,39-ARR_v2_11@0,39-ARR_v1_11@0,"With these intuitions in mind, we propose Optimal Transport (OT) (Villani, 2008) as a natural solution to simultaneously incorporate both the similarity between sample representations and the likelihood of the samples containing an event into a single framework.","As such, we suggest using Optimal Transport (OT) (Villani, 2008) as a natural solution to simultaneously incorporate both the similarity between sample representations and the likelihood of the samples containing an event into a single framework.","Modify,Clarity",Clarity
4020,39-ARR,39-ARR_v2_12@0,39-ARR_v1_12@0,"For our experiments, we focus on the widely used ACE05 (Walker et al., 2006) and ERE (Song et al., 2015) datasets which, in conjuction, contain event-annotations in 4 different languages: English, Spanish, Chinese, and Arabic.","For our experiments, we focus on the widely used ACE05 and ACE05-ERE datasets (Walker et al., 2006) which, in conjuction, contain eventannotations in 4 different languages: English, Spanish, Chinese, and Arabic.","Modify,Fact/Evidence",Fact/Evidence
4021,39-ARR,39-ARR_v2_12@3,39-ARR_v1_12@3,We believe these results demonstrate our model's efficacy and applicability at creating CLED systems.,These results demonstrate our model's efficacy and applicability at creating CLED systems.,"Modify,Clarity",Clarity
4022,39-ARR,39-ARR_v2_18@0,39-ARR_v1_17@0,"Using such representations as input, a prediction network P computes a distribution over the set of possible labels and is trained in a supervised manner using the negative log-likelihood function L P :","Then, we feed the representations h i into a prediction network P to compute a distribution over the set of possible labels and train it in a supervised manner using the negative log-likelihood function L P :","Modify,Clarity",Clarity
4023,39-ARR,39-ARR_v2_2@5,39-ARR_v1_2@5,"More importantly, we optimize the adversarial training process by only presenting the discriminator with the most informative samples.","More importantly, we optimize the adversarial training .","Modify,Fact/Evidence",Fact/Evidence
4024,390-ARR,,390-ARR_v1_69@1,,"When both steps are all removed, the few-shot learning is performed on CLIP with question irrelevant prompts.","Delete,Fact/Evidence",Fact/Evidence
4025,390-ARR,,390-ARR_v1_71@6,,"Results marked with "" * "" are lower than the zero-shot performance.","Delete,Fact/Evidence",Fact/Evidence
4026,390-ARR,,390-ARR_v1_71@7,,Full-FT is short for full fine-tuning.,"Delete,Fact/Evidence",Fact/Evidence
4027,390-ARR,,390-ARR_v1_71@8,,"Besides BiNor's good performance, it improves ResNet CLIPs more significantly due to the number of normalization parameters.","Delete,Fact/Evidence",Fact/Evidence
4028,390-ARR,,390-ARR_v1_79@2,,"In our experiments, we leverage two kinds of pretrained models: the CLIP variants and the T5.","Delete,Fact/Evidence",Fact/Evidence
4029,390-ARR,,390-ARR_v1_79@3,,We brief these models as follows.,"Delete,Fact/Evidence",Fact/Evidence
4030,390-ARR,,390-ARR_v1_82@0,,All CLIP models we used are from the official CLIP repository 2 .,"Delete,Fact/Evidence",Fact/Evidence
4031,390-ARR,,390-ARR_v1_82@1,,"For the language model T5, we use a publicly available T5 large checkpoint from the Huggingface repository 3 .","Delete,Fact/Evidence",Fact/Evidence
4032,390-ARR,,390-ARR_v1_82@2,,"The T5 large has 24 hidden layers, 16 self-attention heads, 1024 hidden size, and a total of 770M parameters.","Delete,Fact/Evidence",Fact/Evidence
4033,390-ARR,,390-ARR_v1_82@3,,It is trained on Colossal Clean Crawled Corpus (C4).,"Delete,Fact/Evidence",Fact/Evidence
4034,390-ARR,,390-ARR_v1_83@1,,"We performed grid searches on the combination of the learning rate, batch size, and dropout.","Delete,Fact/Evidence",Fact/Evidence
4035,390-ARR,,390-ARR_v1_83@2,,The CLIP variants reached the best performances under different parameter combinations.,"Delete,Fact/Evidence",Fact/Evidence
4036,390-ARR,390-ARR_v2_59@2,390-ARR_v1_57@2,"We report the statistics of the two datasets in appendix A. For the VQA task's evaluation, we follow the Frozen model (Tsimpoukelli et al., 2021) to calculate the vqa scores on the VQAv2 validation set.","We report the statistics of the two datasets in appendix A. For the VQA task's evaluation, we follow the Frozen model (Menick et al., 2021) to calculate the vqa scores on the VQAv2 validation set.","Modify,Fact/Evidence",Fact/Evidence
4037,390-ARR,390-ARR_v2_67@6,390-ARR_v1_63@6,"As we can see, the results are similar to a random guess of three relations, indicating the images are of importance in the cross-modality evaluation.","As we can, the results are similar to a random guess of three entailment relations, indicating the images are of importance in the cross-modality evaluation.","Modify,Grammar",Grammar
4038,390-ARR,390-ARR_v2_77@1,390-ARR_v1_75@1,"Leveraging aligned caption data, vision-language models pre-trained by an image-text discriminative loss have recently enabled strong zero-shot generalization on image classification and cross-modality retrieval tasks (Jia et al., 2021;Radford et al., 2021).","Leveraging aligned image and caption data, visionlanguage models pre-trained by an image-text discriminative loss have recently enabled strong zeroshot generalization on image classification and cross-modality retrieval tasks (Jia et al., 2021;Radford et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
4039,390-ARR,390-ARR_v2_77@2,390-ARR_v1_75@2,"Different from the discriminative manner, Tsimpoukelli et al. ( 2021) prompt a large frozen language model with vision prefix in a generative way, which is the first vision-language few-shot model.","Different from the discriminative manner, Menick et al. (2021) prompt a large language model with vision prefix in a generative way, which is the first vision-language few-shot model.","Modify,Fact/Evidence",Fact/Evidence
4040,390-ARR,390-ARR_v2_10@1,390-ARR_v1_9@1,"We find that optimizing only bias and normalization (BiNor) parameters would make better use of limited examples and yield better results than the latest few-shot model Frozen (Tsimpoukelli et al., 2021).","We find that optimizing only bias and normalization (BiNor) parameters would make better use of limited examples and yield better results than the latest few-shot model Frozen (Menick et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
4041,390-ARR,390-ARR_v2_13@3,390-ARR_v1_12@3,"However, directly applying CLIP as a vision-language understanding model is still difficult (Kim et al., 2021;Shen et al., 2022).","However, directly applying CLIP as a vision-language understanding model is still difficult (Kim et al., 2021;Shen et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
4042,390-ARR,390-ARR_v2_14@0,390-ARR_v1_13@0,Vision-Language Understanding Tasks,Visual-Language Understanding Tasks,"Modify,Grammar",Grammar
4043,390-ARR,390-ARR_v2_18@0,390-ARR_v1_17@0,"Previous works (Kim et al., 2021;Shen et al., 2022) have found that directly applying CLIP models for zero-shot VL tasks are infeasible.","Previous works (Kim et al., 2021;Shen et al., 2021) have found that directly applying CLIP models for zero-shot VL tasks are infeasible.","Modify,Fact/Evidence",Fact/Evidence
4044,394-ARR,,394-ARR_v1_16@10,,More hyper-parameter settings are discussed in Section .1 in the Appendix.,"Delete,Fact/Evidence",Fact/Evidence
4045,394-ARR,,394-ARR_v1_50@0,,Ethical Statement,"Delete,Other",Other
4046,394-ARR,,394-ARR_v1_51@1,,We did not collect any new dataset.,"Delete,Fact/Evidence",Fact/Evidence
4047,394-ARR,,394-ARR_v1_53@0,,Narratives dataset can be dowloaded from https://datasets.datalad.org/ ?dir=/labs/hasson/narratives.,"Delete,Fact/Evidence",Fact/Evidence
4048,394-ARR,,394-ARR_v1_53@1,,Please read their terms of use 2 for more details.,"Delete,Fact/Evidence",Fact/Evidence
4049,394-ARR,,394-ARR_v1_54@0,,We do not foresee any harmful uses of this technology. .,"Delete,Claim",Claim
4050,394-ARR,,394-ARR_v1_55@0,,Reproducibility Information,"Delete,Other",Other
4051,394-ARR,394-ARR_v2_22@0,,Syntactic reasoning is rather shallow compared to deep semantic reasoning.,,"Add,Claim",Claim
4052,394-ARR,394-ARR_v2_22@1,,Syntactic reasoning follows somewhat objective grammar rules.,,"Add,Claim",Claim
4053,394-ARR,394-ARR_v2_22@2,,Comparatively semantic reasoning is often subjective in nature and complex.,,"Add,Claim",Claim
4054,394-ARR,394-ARR_v2_22@4,,"Thus, in this work, we explore syntactic and semantic tasks separately.",,"Add,Fact/Evidence",Fact/Evidence
4055,394-ARR,394-ARR_v2_49@2,,"But encoding models (especially for the listening task), scrambled order would be detrimental to making sense of what is being heard.",,"Add,Claim",Claim
4056,394-ARR,394-ARR_v2_49@3,,It is an interesting future task to see if the opposite result is seen in the case of brain encoding models.,,"Add,Claim",Claim
4057,394-ARR,394-ARR_v2_49@4,,"It is plausible that brain uses encoding models in a flexible way when it comes to decoding (Kriegeskorte and Douglas, 2019).",,"Add,Fact/Evidence",Fact/Evidence
4058,394-ARR,394-ARR_v2_49@5,,"Kriegeskorte and Douglas (2019) mention that ""Decoding models can help reveal whether particular information is present in a brain region in a format the decoder can exploit. Encoding models make comprehensive predictions about representational spaces.""",,"Add,Fact/Evidence",Fact/Evidence
4059,394-ARR,394-ARR_v2_49@6,,"In this sense, results of current work are not directly comparable to those of Gauthier and Levy (2019).",,"Add,Claim",Claim
4060,394-ARR,394-ARR_v2_15@10,394-ARR_v1_14@3,We list number of voxels per ROI in this dataset in Table 2.,We list number of voxels per ROI in this dataset in Table 3 (refer to appendix).,"Modify,Fact/Evidence",Fact/Evidence
4061,394-ARR,394-ARR_v2_22@5,394-ARR_v1_21@0,"Of the above mentioned tasks, NER and SS are syntactic, while the others involve semantic reasoning.","Of these, NER and SS are syntactic, while the others involve semantic reasoning.","Modify,Clarity",Clarity
4062,394-ARR,394-ARR_v2_4@3,394-ARR_v1_4@3,"Some recent studies (Nishida et al., 2015;Huth et al., 2016) have been able to identify brain ROIs (Region of Interest) that respond to words that have a similar meaning and have thus built a ""semantic atlas"" of how the human brain organizes language.","Some recent studies (Nishida et al., 2015;Huth et al., 2016) have been able to identify brain ROIs that respond to words that have a similar meaning and have thus built a ""semantic atlas"" of how the human brain organizes language.","Modify,Clarity",Clarity
4063,394-ARR,394-ARR_v2_48@3,394-ARR_v1_47@3,Models can be pretrained for more such tasks to check if other tasks are better predictive of voxel activations.,Models can be pretrained models for more such tasks to check if other tasks are better predictive of voxel activations.,"Modify,Clarity",Clarity
4064,394-ARR,394-ARR_v2_6@0,394-ARR_v1_5@0,"Despite the recent advances in mapping between language Transformers and the brain activity recorded with reading (Schrimpf et al., 2021), the Transformer features themselves are notoriously difficult to interpret.","Despite the recent advances in mapping between language transformers and the brain activity recorded with reading (Schrimpf et al., 2021), the Transformer features themselves are notoriously difficult to interpret.","Modify,Grammar",Grammar
4065,394-ARR,394-ARR_v2_7@0,394-ARR_v1_6@0,"Recently, a study using multiple computer vision tasks has shown that 3D vision task models predict better fMRI brain activity than 2D vision task models for visual stimuli.","Recently, a study using multiple computer vision tasks has shown that 3D vision task models predict better fMRI brain activity than 2D vision task models (Wang et al., 2019) for visual stimuli.","Modify,Fact/Evidence",Fact/Evidence
4066,394-ARR,394-ARR_v2_7@1,394-ARR_v1_6@1,"Inspired by the success of correlations in the vision field , and brain encoding study of a variety of language Transformer models (Schrimpf et al., 2021;Caucheteux et al., 2021b,a), we build neural language taskonomy models for brain encoding and aim to find NLP tasks that are most explanatory of brain activations for reading and listening tasks.","Inspired by the success of correlations in the vision field (Wang et al., 2019), and brain encoding study of a variety of language Transformer models (Schrimpf et al., 2021;Caucheteux et al., 2021b,a), we build neural language taskonomy models for brain encoding and aim to find NLP tasks that are most explanatory of brain activations for reading and listening tasks.","Modify,Fact/Evidence",Fact/Evidence
4067,394-ARR,394-ARR_v2_12@2,394-ARR_v1_9@2,"Semantic representation models include distributed word embeddings (Pereira et al., 2016;Anderson et al., 2017a;Pereira et al., 2018;Hollenstein et al., 2019;Wang et al., 2020), sentence representation models (Sun et al., 2019;Sun et al., 2020), recurrent neural networks (Jain and Huth, 2018;Oota et al., 2019), and Transformer-based language models (Gauthier and Levy, 2019;Schwartz et al., 2019;Oota et al., 2022a,b).","Semantic representation models include distributed word embeddings (Pereira et al., 2016;Anderson et al., 2017a;Pereira et al., 2018;Toneva and Wehbe, 2019;Hollenstein et al., 2019;Wang et al., 2020), sentence representation models (Sun et al., 2019;Toneva and Wehbe, 2019;Sun et al., 2020), recurrent neural networks (Jain and Huth, 2018;Oota et al., 2019), and Transformer-based language models (Gauthier and Levy, 2019;Toneva and Wehbe, 2019;Schwartz et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
4068,394-ARR,394-ARR_v2_12@4,394-ARR_v1_9@4,"Fine-grained details such as lexical, compositional, syntactic, and semantic representations of narratives are factorized from Transformer-based models and utilized for training encoding models.","Fine-grained details such as lexical, compositional, syntactic, and semantic representations of narratives are factorized from transformerbased models and utilized for training encoding models.","Modify,Grammar",Grammar
4166,405-ARR,405-ARR_v2_50@8,,We perform prompt-based finetuning using different lightweight finetuning schemes.,,"Add,Fact/Evidence",Fact/Evidence
4167,405-ARR,405-ARR_v2_50@9,,We show the accuracy or F 1 on each dataset for RoBERTa-large.,,"Add,Fact/Evidence",Fact/Evidence
4168,405-ARR,405-ARR_v2_50@10,,BitFit achieves the highest accuracy on average and only modifies 0.1% of the parameters.,,"Add,Fact/Evidence",Fact/Evidence
4169,405-ARR,405-ARR_v2_53@1,,They also finetune additional parameters in intermediate layers of the model.,,"Add,Fact/Evidence",Fact/Evidence
4170,405-ARR,405-ARR_v2_24@1,405-ARR_v1_25@1,"Since transformers' performance in few-shot settings can be highly dependent on weight initialization (Dodge et al., 2020), we initialize the weights with 10 different random seeds and report the mean and variance of the model performance.","Since transformers have been observed can be high variance (Dodge et al., 2020), we initialize the model parameters with 10 different random seeds and report the mean and variance of the model performance.","Modify,Fact/Evidence",Fact/Evidence
4171,405-ARR,405-ARR_v2_27@0,405-ARR_v1_28@0,"Following past work (Schick and Schütze, 2021b), we use the RoBERTa (large, 330M params, Liu et al., 2019) and ALBERT (xxl-v2, 223M params, Lan et al., 2020) masked LMs provided by the Hug-gingFace transformers library (Wolf et al., 2020).","Following past work (Schick and Schütze, 2021b), we use the RoBERTa (large, 330M params, Liu et al., 2019) and ALBERT (xxl-v2, 223M params, Lan et al., 2019) masked LMs provided by the Hug-gingFace transformers library (Wolf et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
4172,405-ARR,405-ARR_v2_28@0,405-ARR_v1_29@0,Comparing Few-Shot Methods by # Wins,Comparing Few-shot Methods by # Wins,"Modify,Grammar",Grammar
4173,405-ARR,405-ARR_v2_45@2,405-ARR_v1_46@2,"In this section, we investigate how to achieve both memory efficiency and simple prompts.","In this section, we investigate how to memory efficiency and simple prompts.","Modify,Clarity",Clarity
4174,405-ARR,405-ARR_v2_53@2,405-ARR_v1_51@8,These differences may explain the difference in prompting accuracies.,This may explain the difference in the results.,"Modify,Clarity",Clarity
4175,405-ARR,405-ARR_v2_62@2,405-ARR_v1_61@2,"First, we show that it performs comparably across different prompt choices.","First, we show that it is robust to different choices of the prompt.","Modify,Clarity",Clarity
4176,405-ARR,405-ARR_v2_7@7,405-ARR_v1_7@3,"Taken together, our results show that prompt-based finetuning is preferable because it is more accurate, works well for different types of prompts, and can be made nearly as efficient as using frozen LMs.","Taken together, our results show that prompt-based finetuning is preferable because it is more accurate, more robust across prompts, and can be made nearly as efficient as using frozen LMs.","Modify,Clarity",Clarity
4177,405-ARR,405-ARR_v2_18@0,405-ARR_v1_19@0,"Prompt-Based Finetuning Rather than using frozen LMs, prompt-based finetuning methods finetune all of the LM's parameters (Schick and Schütze, 2021a;Le Scao and Rush, 2021;Gao et al., 2021).","Prompt-Based Finetuning Rather than using frozen LMs, prompt-based finetuning methods finetune all of the LM's parameters (Schick and Schütze, 2021a;Scao and Rush, 2021;Gao et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
4178,405-ARR,405-ARR_v2_20@1,405-ARR_v1_21@1,We will also show that the memory inefficiency of prompt-based finetuning can be drastically mitigated using lightweight finetuning alternatives.,"Moreover, we will show that the memory inefficiency of prompt-based finetuning can be drastically mitigated using lightweight finetuning alternatives.","Modify,Clarity",Clarity
4179,405-ARR,405-ARR_v2_2@4,405-ARR_v1_2@4,"All in all, we recommend finetuning LMs for few-shot learning as it is more accurate, has relatively stable performance across different prompts, and can be made nearly as efficient as using frozen LMs.","All in all, we recommend finetuning LMs for fewshot learning as it is more accurate, robust to different prompts, and can be made nearly as efficient as using frozen LMs.","Modify,Clarity",Clarity
4180,409-ARR,,409-ARR_v1_63@6,,"This phenomenon is known in the literature (Yanaka et al., 2019), but we show that metamorphic testing can independently detect it.","Delete,Fact/Evidence",Fact/Evidence
4181,409-ARR,,409-ARR_v1_63@7,,"If we aggregate the results by insertion pair (see Table 4), the picture does not change.","Delete,Fact/Evidence",Fact/Evidence
4182,409-ARR,,409-ARR_v1_63@8,,"The overall safety is 0.5936, which is barely above random chance.","Delete,Fact/Evidence",Fact/Evidence
4183,409-ARR,,409-ARR_v1_63@9,,Any deviations from this baseline can be interpreted as noise.,"Delete,Fact/Evidence",Fact/Evidence
4184,409-ARR,409-ARR_v2_23@1,,"In the same vein, Fadaee and Monz (2020) and Dankers et al. (2021) shows the volatility of neural translation models to minor word-level transformations of the input.",,"Add,Fact/Evidence",Fact/Evidence
4185,409-ARR,409-ARR_v2_56@0,,Let us stress here that such geometric constraints are a direct consequence of the metamorphic relation we choose.,,"Add,Claim",Claim
4186,409-ARR,409-ARR_v2_56@1,,"This is a fundamentally different mechanism to the one explored by Allen and Hospedales (2019), where the linear relationship between the representations of related words is explained as an emergent behaviour of the probability of words occurring in similar contexts.",,"Add,Fact/Evidence",Fact/Evidence
4187,409-ARR,409-ARR_v2_58@4,,"To this end, we turn towards a stricter definition of mathematical compositionality of the neural network behaviour, rather than global linguistic compositionality, which is harder to define (Dankers et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
4188,409-ARR,409-ARR_v2_62@0,,Illustrative example: pairwise compositionality of NLI,,"Add,Other",Other
4189,409-ARR,409-ARR_v2_63@0,,"Here, we apply the metamorphic relation in Figure 4 to test a natural language inference (NLI) model.",,"Add,Fact/Evidence",Fact/Evidence
4190,409-ARR,409-ARR_v2_63@2,,"The model's goal is to predict whether x b logically follows from x a , i.e. their entailment.",,"Add,Fact/Evidence",Fact/Evidence
4191,409-ARR,409-ARR_v2_50@4,409-ARR_v1_49@4,Note how the proportion of violated relations varies across different transformations.,"Note how the proportion of satisfied relations (""Safety"") varies across different transformations.","Modify,Fact/Evidence",Fact/Evidence
4192,409-ARR,409-ARR_v2_53@4,409-ARR_v1_54@4,"Recall, that model f outputs a sentiment score s(y), which is a one-dimensional projection of the hidden representations (see Figure 3).","Recall, that model f outputs a sentiment score s(y), which is a one-dimensional projection of the embedding space (see Figure 3).","Modify,Clarity",Clarity
4193,409-ARR,409-ARR_v2_53@5,409-ARR_v1_54@5,"Accordingly, the premise P src and hypothesis P f lw are only concerned with the position of each representation y along direction s.","Accordingly, the premise P src and hypothesis P f lw are only concerned with the position of each embedding y along direction s.","Modify,Clarity",Clarity
4194,409-ARR,409-ARR_v2_6@0,409-ARR_v1_6@0,"In general, such extreme reliance on groundtruth data limits the quantity of test cases we can produce, which is a known problem in the software testing community (Barr et al., 2015).","In general, such extreme reliance on groundtruth data limits the quantity and quality of test cases we can produce, which is a known problem in the software testing community (Barr et al., 2015).","Modify,Fact/Evidence",Fact/Evidence
4195,409-ARR,409-ARR_v2_56@2,409-ARR_v1_56@0,"In the following Section 5, we introduce a class of pairwise relations where the output premise and hypothesis are defined over separate embedding spaces.",The following section introduces a class of pairwise relations where the output premise and hypothesis are defined over different embedding spaces.,"Modify,Grammar",Grammar
4196,409-ARR,409-ARR_v2_58@2,409-ARR_v1_59@0,"The presence of such building blocks can be a sign that an NLP model exhibits compositional behaviour (Baroni, 2020).","The presence of such building blocks is a necessary condition for an NLP model to exhibit compositional behaviour (Baroni, 2020).","Modify,Fact/Evidence",Fact/Evidence
4197,409-ARR,409-ARR_v2_65@4,409-ARR_v1_61@9,"We can test whether the NLI model builds its output by reasoning over the monotonicity of C i and the lexical relation of ( a , b ) j as follows:","We can test whether the NLI model build its output by reasoning over the monotonicity of C i and the lexical relation of the insertion pairs ( a , b ) j as follows:","Modify,Clarity",Clarity
4198,409-ARR,409-ARR_v2_68@0,409-ARR_v1_65@0,"An NLP model that generalises correctly should exhibit transitive behaviour under the right circumstances (Yanaka et al., 2021).",An NLP model that generalises correctly should exhibit transitive behaviour under the right circumstances Yanaka et al. (2021).,"Modify,Grammar",Grammar
4199,41-ARR,,41-ARR_v1_91@0,,"Here, we compare our choice of contrastive loss SupCon (Khosla et al., 2020) to an unsupervised version SimCLR (Chen et al., 2020a SimCLR in all tasks.","Delete,Fact/Evidence",Fact/Evidence
4200,41-ARR,,41-ARR_v1_91@1,,"In many cases, SimCLR even underperforms the baselines by large margins (see LM-BFF in Table 1), indicating that learning discriminative features at instance level only can hurt the fine-tuning process.","Delete,Fact/Evidence",Fact/Evidence
4201,41-ARR,,41-ARR_v1_92@0,,SupCon takes the representations of inputs to perform contrastive learning.,"Delete,Fact/Evidence",Fact/Evidence
4202,41-ARR,,41-ARR_v1_92@1,,We use the hidden states at [MASK] tokens as the representations of sentences in the main experiments.,"Delete,Fact/Evidence",Fact/Evidence
4203,41-ARR,,41-ARR_v1_92@2,,Another common choice is to take the hidden states at [CLS] tokens.,"Delete,Claim",Claim
4204,41-ARR,,41-ARR_v1_92@3,,"For example, in standard fine-tuning, the algorithm takes the representation of a sentence at [CLS] token and attaches a linear classifier on top of it.","Delete,Claim",Claim
4205,41-ARR,,41-ARR_v1_93@0,,"Based on Table J.1, applying the contrastive loss at [MASK] tokens is generally better than applying it at [CLS].","Delete,Claim",Claim
4206,41-ARR,,41-ARR_v1_93@1,,"This is fairly intuitive, as the final classifications are performed at [MASK] tokens and enforcing class-level discriminative representations explicitly at [MASK] tokens helps models generalize better after fine-tuning.","Delete,Claim",Claim
4207,41-ARR,41-ARR_v2_2@6,,The code will be made available at: https://github.com/yiren-jian/LM-SupCon.,,"Add,Fact/Evidence",Fact/Evidence
4208,41-ARR,41-ARR_v2_13@1,,"Besides the standard prompt-base MLM loss on label words ""great"" and ""terrible"", we introduce a SupCon loss on multi-views of input text.",,"Add,Fact/Evidence",Fact/Evidence
4209,41-ARR,41-ARR_v2_13@2,,"The positive pair is sentences (with sampled templates and/or demonstrations) in the same class, e.g. sent 1 and sent 3 , or itself with a different template and demonstrations, e.g. sent 1 and sent 2 .",,"Add,Fact/Evidence",Fact/Evidence
4210,41-ARR,41-ARR_v2_13@3,,"The negative sentence pair is input sentences (with sampled templates and/or demonstrations) in different classes, e.g. sent 1 and sent 0 .",,"Add,Fact/Evidence",Fact/Evidence
4211,41-ARR,41-ARR_v2_13@5,,"Inspired by the in-context learning of GPT-3, prompt-based fine-tuning Tam et al., 2021;Schick and Schütze, 2021) recently becomes dominant in NLP.",,"Add,Fact/Evidence",Fact/Evidence
4212,41-ARR,41-ARR_v2_39@0,,Improvements vs. Task Difficulty,,"Add,Other",Other
4213,41-ARR,,41-ARR_v1_26@1,,"Because L SupCon requires one additional forward and backward pass in each tuning iteration (see Appendix D), we observe that the training cost is raised by a factor 1.5 compared to the baselines.","Delete,Fact/Evidence",Fact/Evidence
4214,41-ARR,,41-ARR_v1_27@0,,Experiments,"Delete,Other",Other
4215,41-ARR,,41-ARR_v1_28@0,,Evaluation datasets and protocol.,"Delete,Other",Other
4218,41-ARR,41-ARR_v2_53@2,41-ARR_v1_52@2,Experiments with RoBERTa-large require 4x NVIDIA RTX-8000 (or RTX-A6000) with 192 (4x 48) GB of momery.,Experiments with RoBERTa-large require 4x NVIDIA RTX-8000 with 192 (4x 48) GB of momery.,"Modify,Fact/Evidence",Fact/Evidence
4219,41-ARR,41-ARR_v2_4@4,41-ARR_v1_4@4,"Recently, LM-BFF shows that appending demonstrations (e.g.""This is an amazing movie, a truly great one"") to inputs can help the model to better understand the label word, leading to further improved results.","Recently, LM-BFF (Gao et al., 2021) shows that appending demonstrations (e.g.""This is an amazing movie, a truly great one"") to inputs can help the model to better understand the label word, leading to further improved results.","Modify,Fact/Evidence",Fact/Evidence
4220,41-ARR,41-ARR_v2_71@1,41-ARR_v1_85@1,Those prompts are manually chosen by LM-BFF .,"Those prompts are manually chosen by LM-BFF (Gao et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
4221,41-ARR,41-ARR_v2_72@1,41-ARR_v1_86@1,"We also include results directly reported from LM-BFF (henceforth referred to as LM-BFF †) , though the comparison between them could be unfair since the results reported in the original LM-BFF paper are:","We also include results directly reported from LM-BFF (Gao et al., 2021) (henceforth referred to as LM-BFF †) , though the comparison between them could be unfair since the results reported in the original LM-BFF paper are:","Modify,Fact/Evidence",Fact/Evidence
4222,41-ARR,41-ARR_v2_0@0,41-ARR_v1_0@0,Contrastive Learning for Prompt-Based Few-Shot Language Learners,Contrastive Learning for Prompt-based Few-shot Language Learners,"Modify,Grammar",Grammar
4223,41-ARR,41-ARR_v2_16@4,41-ARR_v1_17@4,"LM-BFF further appends demonstrations of label words to improve the results: x prompt+demo = sent 0 , temp 0 ([mask]), sent i , temp 0 (word i ) , where word i is the label word for sent i , and sent i is sampled from the training set.","LM-BFF (Gao et al., 2021) further appends demonstrations of label words to improve the results: x prompt+demo = sent 0 , temp 0 ([mask]), sent i , temp 0 (word i ) , where word i is the label word for sent i , and sent i is sampled from the training set.","Modify,Fact/Evidence",Fact/Evidence
4295,414-ARR,,414-ARR_v1_61@1,,"For dataset settings, we use all available bitext of WMT14 corpus without any filtering on sentence length or source/target length ratio, this will result in a 4.5 million parallel corpus.","Delete,Fact/Evidence",Fact/Evidence
4296,414-ARR,,414-ARR_v1_67@1,,Gamma criterion based method outperform beam search based and sampling based back-translation NMT models.,"Delete,Fact/Evidence",Fact/Evidence
4297,414-ARR,,414-ARR_v1_67@2,,The result marked with * denotes that it is significantly better than sampling BT with p < 0.0010.,"Delete,Fact/Evidence",Fact/Evidence
4298,414-ARR,,414-ARR_v1_81@0,,3 Singular value spectrum analysis is a widely used method to measure the representation distribution.,"Delete,Claim",Claim
4299,414-ARR,,414-ARR_v1_81@1,,"Gao et al. (2019) firstly introduces this method to measure the isotropy of representation, and directly employ spectrum control for better NMT performance.","Delete,Fact/Evidence",Fact/Evidence
4300,414-ARR,,414-ARR_v1_81@2,,"The idea is, representations of high linguistic variety usually are more isotropic, thus to have a relatively uniform singular value distribution.","Delete,Claim",Claim
4301,414-ARR,,414-ARR_v1_81@3,,We employ this method here to measure the variety of sentence level information.,"Delete,Fact/Evidence",Fact/Evidence
4302,414-ARR,,414-ARR_v1_87@3,,Their contribution shows that sampling or noisy synthetic data gives a much stronger training signal.,"Delete,Fact/Evidence",Fact/Evidence
4303,414-ARR,,414-ARR_v1_87@4,,"Graça et al. (2019) reformulate backtranslation in the context of optimization and clarifying to improve sampling based decoding method search space, thus proposing N best list sampling.","Delete,Fact/Evidence",Fact/Evidence
4304,414-ARR,,414-ARR_v1_87@5,,"Recently, Nguyen et al. (2020) diversify the training data by multiple forward and backward models translations and combine them with the original datasets.","Delete,Fact/Evidence",Fact/Evidence
4305,414-ARR,414-ARR_v2_60@1,,"For dataset settings, since datasets WMT14 EN-DE and DE-EN are widely used (Li et al., 2019b;Zhu et al., 2020;Fan et al., 2021;Le et al., 2021), we follow both standard benchmarks and additionally we employ WMT14 RU-EN as the third dataset to validate the effectiveness of the proposed methods.",,"Add,Fact/Evidence",Fact/Evidence
4306,414-ARR,414-ARR_v2_61@1,,"We use the same hyperparameter settings across all the experiments, i.e., 1024 word representation size, 4096 inner dimensions of feed-forward layers, and dropout is set to 0.3 for all the experiments.",,"Add,Fact/Evidence",Fact/Evidence
4307,414-ARR,414-ARR_v2_61@3,,2 The detailed hyperparameters used for training translation and language models are shown in Appendix.,,"Add,Fact/Evidence",Fact/Evidence
4308,414-ARR,414-ARR_v2_71@1,,"Recently, Edunov et al. (2020) point out that BLEU might overlook the contributions from back translation since it poorly correlates with human evaluation on the data generated in back translation scenario.",,"Add,Fact/Evidence",Fact/Evidence
4309,414-ARR,414-ARR_v2_71@2,,"Follow their suggestions, to better reflect the scenario of back translation, we also evaluate our experiment using COMET metric suggested by Rei et al. (2020).",,"Add,Fact/Evidence",Fact/Evidence
4310,414-ARR,414-ARR_v2_71@3,,The results are shown in table 6 and we can see that the proposed methods perform well in terms of COMET.,,"Add,Fact/Evidence",Fact/Evidence
4311,414-ARR,414-ARR_v2_37@2,414-ARR_v1_38@2,"However, this is difficult because both factors are mutually exclusive as discussed in Section 3.","However, this is difficult because both factors are mutually exclusive.","Modify,Fact/Evidence",Fact/Evidence
4312,414-ARR,414-ARR_v2_42@0,414-ARR_v1_43@0,"Where xb denotes a translation of y generated by p(x|y; π) with beam search and xs is a translation with sampling, | • | means the size of the corpus, and γ is the combination ratio for beam and sampling synthetic corpora.","Where xb denotes a translation of y generated by p(x|y; π) with beam search and xs is a translation with sampling, | • | means the size of the corpus, and γ is the combination ratio of beam and sampling synthetic corpora.","Modify,Grammar",Grammar
4313,414-ARR,414-ARR_v2_4@1,414-ARR_v1_4@1,"This is because 1) it provides a simple yet effective approach to advance the supervised NMT by leveraging monolingual data (Edunov et al., 2018) and it also serves as a key learning objective in unsupervised NMT (Artetxe et al., 2018;Lample et al., 2018); 2) back translation even plays a significant role in other NLP re-search fields beyond translation such as paraphrasing (Mallinson et al., 2017) and style transfer (Prabhumoye et al., 2018;Zhang et al., 2018).","This is because 1) it provides a simple yet effective approach to advance the supervised NMT by leveraging monolingual data (Edunov et al., 2018) and it also serves as a key learning objective in unsupervised NMT (Artetxe et al., 2017;Lample et al., 2018); 2) back-translation even plays a significant role in other NLP research fields beyond translation such as paraphrasing (Mallinson et al., 2017) and style transfer (Prabhumoye et al., 2018;Zhang et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
4314,414-ARR,414-ARR_v2_47@1,414-ARR_v1_48@1,"With the help of this score, one may optimize the x by beam search whose interpolation score is the best among all possible translations of y ∈ M. Unfortunately, such an implementation leads to limited performance in our preliminary experiments, due to two major challenges.","With the help of this score, one may optimize the x through beam search whose interpolation score is the best among all possible translations of y ∈ M. Unfortunately, such an implementation leads to limited performance in our preliminary experiments, due to two major challenges.","Modify,Grammar",Grammar
4315,414-ARR,414-ARR_v2_49@1,414-ARR_v1_50@1,"Specifically, firstly, instead of beam search with the interpolation score, we simply utilize the backward translation p(x|y; π) to randomly sample a set of candidate translations which is denoted by A(y) = {x i } N i (N = 50 in this paper as it works well).","Specifically, firstly, instead of beam search with the interpolation score, we simply utilize the backward translation p(x|y; π) to randomly sample a set of candidate translations which is denoted by A(y) = {x i } N i (N = 50 in this paper).","Modify,Clarity",Clarity
4316,414-ARR,414-ARR_v2_60@0,414-ARR_v1_61@0,"We run all the experiments by using fairseq (Ott et al., 2019) framework.","We run all the experiments using WMT14 datasets with fairseq (Ott et al., 2019) framework.","Modify,Clarity",Clarity
4317,414-ARR,414-ARR_v2_60@2,414-ARR_v1_61@2,"For back translation experiment, we use an equal scale monolingual corpus randomly sampled from Newscrawl 2020 (Barrault et al., 2019) comprising 4.5 million monolingual sentences for DE-EN language pair and 2.5 million for RU-EN direction, thus total 9 million sentences for DE-EN pair and 5 million for RU-EN direction are used.","For back translation experiment, we use equal scale monolingual corpus randomly sampled from Newscrawl 2020 (Barrault et al., 2019) comprising 4.5 million monolingual sentences, thus total 9 million sentences are used.","Modify,Fact/Evidence",Fact/Evidence
4318,414-ARR,414-ARR_v2_5@1,414-ARR_v1_5@1,"Various contributions have been made on improving back translation, for instance, iterative back translation (Hoang et al., 2018), tagged back translation (Caswell et al., 2019), confidence weighting , data diversification (Nguyen et al., 2020).","Various contributions have been made on improving back translation, for instance, iterative backtranslation (Hoang et al., 2018), tagged backtranslation (Caswell et al., 2019), confidence weighting , data diversification (Nguyen et al., 2020).","Modify,Grammar",Grammar
4319,414-ARR,414-ARR_v2_0@0,414-ARR_v1_0@0,On Synthetic Data for Back Translation *,On Synthetic Data for Back Translation,"Modify,Other",Other
4320,414-ARR,414-ARR_v2_68@1,414-ARR_v1_70@1,"From the table, we can see that our proposed gamma sampling significantly outperforms the sampling based and beam search based back-translation baselines by 0.9 and 2.3 BLEU scores in terms of SacreBLEU. And our two proposed gamma score based methods outperform the data manipulation method as well.","From the table, we can see that our proposed gamma sampling significantly outperforms the sampling based and beam search based backtranslation baselines by 0.9 and 2.3 BLEU scores in terms of SacreBLEU. And our two proposed gamma score based methods outperform data manipulation method as well.","Modify,Grammar",Grammar
4321,414-ARR,414-ARR_v2_77@2,414-ARR_v1_80@2,"Between them, sampling and gamma selection generate almost the same sequence length, which means gamma selection candidates provide more learning signals than random sampling under the same length.","Between them, sampling and gamma selection generate almost the same sequence length, which means gamma selection candidates provide more learning signal than random sampling under the same length.","Modify,Grammar",Grammar
4322,414-ARR,414-ARR_v2_84@1,414-ARR_v1_91@1,Edunov et al. (2020) show that back-translation improves translation quality of both naturally occurring text and translationese according professional human translators.,Edunov et al. (2020) show that back-translation improves translation quality of both naturally occurring text and translationese according to professional human translators.,"Modify,Grammar",Grammar
4323,414-ARR,414-ARR_v2_7@0,414-ARR_v1_7@0,"In this paper, we attempt to take a step forward toward the above fundamental question.","Consequently, we attempt to exploit such a fundamental question in this paper.","Modify,Clarity",Clarity
4324,414-ARR,414-ARR_v2_7@1,414-ARR_v1_7@1,"To this end, we start from a critical objective in semi-supervised learning, which is defined by the marginal distribution of a target language.","To this end, we start from a marginal objective, which is critical to semi-supervised learning, and derive an approximate lower bound of the objective function.","Split+Modify,Clarity",Clarity
4325,414-ARR,414-ARR_v2_7@2,414-ARR_v1_7@1,"Then we derive an approximate lower bound of the objective function, which is closely related to the objective of back translation.","To this end, we start from a marginal objective, which is critical to semi-supervised learning, and derive an approximate lower bound of the objective function.","Split+Modify,Fact/Evidence",Fact/Evidence
4326,414-ARR,414-ARR_v2_7@4,414-ARR_v1_7@3,"Since both elements are mutually exclusive to some extent, it may induce contradictory observation if one judges the BT performance according to a single element.","Since both elements are mutually exclusive in essence, it may induce contradictory observation if one judges the BT performance according to a single element.","Modify,Clarity",Clarity
4327,414-ARR,414-ARR_v2_7@7,414-ARR_v1_7@6,Extensive experiments on three WMT14 tasks show that our BT consistently outperforms the standard sampling and beam search based baselines by a significant margin.,Extensive experiments on three WMT14 tasks show that our BT consistently outperforms the standard sampling and beam search based baselines with a significant margin.,"Modify,Grammar",Grammar
4328,414-ARR,414-ARR_v2_9@0,414-ARR_v1_9@0,1. We point out that importance weight and quality of synthetic candidates are two key factors that affect the NMT performance.,1. We point it out that importance weight and quality of synthetic candidates are two key factors that affect the NMT performance.,"Modify,Clarity",Clarity
4329,414-ARR,414-ARR_v2_11@0,414-ARR_v1_11@0,"3. Our experiments prove the effectiveness of the aforementioned strategy, it outperforms beam or sampling decoding methods on three benchmark tasks.","3. Our experiments prove the effectiveness of aforementioned strategy, it outperforms beam or sampling decoding methods on three benchmark tasks.","Modify,Grammar",Grammar
4330,414-ARR,414-ARR_v2_15@1,414-ARR_v1_15@1,"At a high level, back translation can be considered as a semi-supervised method because it leverages both labeled and unlabeled data.","At the high level, back translation can be considered as a semi-supervised method because it leverages both labeled and unlabeled data.","Modify,Grammar",Grammar
4331,414-ARR,414-ARR_v2_2@4,414-ARR_v1_2@4,"Furthermore, based on our findings, we propose a simple yet effective method to generate synthetic data to better trade off both factors so as to yield a better performance for BT.","Furthermore, based on our findings, we propose a simple yet effective method to generate synthetic data to better trade off both factors so as to yield the better performance for BT.","Modify,Grammar",Grammar
4332,414-ARR,414-ARR_v2_21@1,414-ARR_v1_21@1,"However, the recent studies (Edunov et al., 2018) find that NMT models with unsatisfactory BLEU score corpus, for instance, the corpus generated by sampling based strategy, also establish the state-of-the-art (SOTA) achievement among back-translation NMT models.","However, the recent studies (Edunov et al., 2018) find that NMT models with unsatisfactory BLEU score corpus, for instance the corpus generated by sampling based strategy, also establish the state-of-the-art (SOTA) achievement among back-translation NMT models.","Modify,Grammar",Grammar
4333,419-ARR,,419-ARR_v1_58@3,,"Therefore, focusing on the correlation between attention and other faithful techniques may not be enough to evaluate whether attention is explanation in real conditions.","Delete,Claim",Claim
4334,419-ARR,,419-ARR_v1_60@2,,We claim that a common ground must be found to properly analyze attention and its relation to explanation.,"Delete,Claim",Claim
4335,419-ARR,419-ARR_v2_6@1,,"Indeed, the attention weights link the input to the remaining of the network with the aim of performing a certain task, and are trained to do so through back-propagation.",,"Add,Fact/Evidence",Fact/Evidence
4336,419-ARR,419-ARR_v2_18@2,,"Table 1 presents an overview of all works discussed in our paper, with the task(s) and architecture(s) they study (when applicable), and the section(s) in which they appear.",,"Add,Fact/Evidence",Fact/Evidence
4337,419-ARR,419-ARR_v2_29@9,,Clark et al. (2019) and Vig and Belinkov (2019) are some of the few works analyzing attention as explanation in a multi-head setting.,,"Add,Fact/Evidence",Fact/Evidence
4338,419-ARR,419-ARR_v2_29@10,,Additional work is needed to establish the similarities and differences between single and multiple heads in the context of the debate.,,"Add,Claim",Claim
4339,419-ARR,419-ARR_v2_46@9,,"The first strategy imposes a constraint of orthogonality on the hidden states, while in the second strategy, the model learns to consider the hidden states separately thanks to an additional term in the objective function.",,"Add,Fact/Evidence",Fact/Evidence
4340,419-ARR,419-ARR_v2_47@7,,"The authors therefore weights the instances by w = P (y) P (y|m) to disconnect m from y, and, in turn, to encourage m to select meaningful elements of x to predict y.",,"Add,Fact/Evidence",Fact/Evidence
4341,419-ARR,419-ARR_v2_57@2,,"Furthermore, the faithfulness of attention is generally evaluated with gradient-based techniques, and other techniques like LIME, as a ground truth.",,"Add,Claim",Claim
4342,419-ARR,419-ARR_v2_57@3,,"However, several works show that these techniques can lead to unexpected (and potentially misleading) results (Feng et al., 2018;Slack et al., 2020).",,"Add,Fact/Evidence",Fact/Evidence
4343,419-ARR,419-ARR_v2_57@4,,"As human-based evaluations are used to assess the plausibility of explanations, and cannot be used for assessing faithfulness (Jacovi and Goldberg, 2020), the question of how to evaluate faithfulness is still open.",,"Add,Claim",Claim
4344,419-ARR,419-ARR_v2_22@0,419-ARR_v1_22@0,"Finally, Ethayarajh and Jurafsky (2021) show that attention weights are not Shapley values (i.e., a method for feature importance) (Lundberg and Lee, 2017).","Finally, Ethayarajh and Jurafsky (2021) show that attention weights are not Shapley values (i.e. a method for feature importance) (Lundberg and Lee, 2017).","Modify,Grammar",Grammar
4345,419-ARR,419-ARR_v2_22@2,419-ARR_v1_22@2,"The authors however note that attention flows (i.e., an extension of attention weights obtained after postprocessing) (Abnar and Zuidema, 2020) are Shapley values, which may indicate that using attention in another way could lead to explanation.","The authors however note that attention flows (i.e. an extension of attention weights obtained after postprocessing) (Abnar and Zuidema, 2020) are Shapley values, which may indicate that using attention in another way could lead to explanation.","Modify,Grammar",Grammar
4347,419-ARR,419-ARR_v2_29@2,419-ARR_v1_29@3,Clark et al. (2019) thus investigate the attention heads in BERT in the context of syntactic dependency tagging and co-reference resolution.,They explore syntactic dependency tagging and co-reference resolution.,"Merge+Modify,Clarity",Clarity
4348,419-ARR,419-ARR_v2_29@6,419-ARR_v1_31@0,"Similarly, Vig and Belinkov (2019) investigate attention in GPT-2, in particular for part-of-speech and syntactic tagging.","Similarly, Vig and Belinkov (2019) investigate attention in GPT-2, in particular for two tasks: partof-speech and syntactic tagging.","Modify,Grammar",Grammar
4349,419-ARR,419-ARR_v2_29@8,419-ARR_v1_31@2,"In general, attention shows which tokens were attended to for the task at hand and can thus be used as a global explanation.","In general, attention shows which tokens were attended to for the tasks at hand and can thus be used as a global explanation.","Modify,Grammar",Grammar
4350,419-ARR,419-ARR_v2_33@2,419-ARR_v1_35@2,"The authors find slight agreement between the different explanation methods, including attention-based explanations.","The authors find small agreement between the different explanation methods, including attention-based explanations.","Modify,Clarity",Clarity
4351,419-ARR,419-ARR_v2_38@3,419-ARR_v1_39@3,"They reported a very high agreement among judges (i.e., Cohen's κ over 0.8), which leads to think that words receiving the highest attention can form a plausible explanation.","They reported a very high agreement among judges (i.e. Cohen's κ over 0.8), which leads to think that words receiving the highest attention can form a plausible explanation.","Modify,Grammar",Grammar
4352,419-ARR,419-ARR_v2_46@5,419-ARR_v1_47@5,"They propose three learning strategies for that score (Linear TaSk, Feature-wise TaSk and Convolutional TaSk) and compare their solutions to three baseline explanations methods (Word Omission, InputXGrad and Integrated Gradients).",They propose three learning strategies for that score and compare their solutions to three baseline explanations methods.,"Modify,Fact/Evidence",Fact/Evidence
4353,419-ARR,419-ARR_v2_46@7,419-ARR_v1_47@7,"Mohankumar et al. (2020) propose the introduction of more diversity in the hidden states learned by LSTMs, enabling the observation of elements separately from their context.","Mohankumar et al. (2020) propose the introduction of more diversity in the hidden states learned by LSTMs, allowing to observe elements separately from their context.","Modify,Clarity",Clarity
4354,419-ARR,419-ARR_v2_46@10,419-ARR_v1_47@8,"The authors show that the resulting attention values offer explanations that are not only more faithful, but also more plausible.",They evaluate two different strategies and show that the resulting attention values offer explanations that are not only more faithful but also more plausible.,"Modify,Clarity",Clarity
4355,419-ARR,419-ARR_v2_47@1,419-ARR_v1_49@1,"In parallel, some researchers focus directly on the attention weights.","In parallel, some researchers focus directly on the attention weights with no constraints regarding the network architecture.","Modify,Claim",Claim
4356,419-ARR,419-ARR_v2_47@5,419-ARR_v1_49@5,Bai et al. (2021) propose to weight the elements of the input X to counter the effect of combinatorial shortcuts (see Section 5).,Bai et al. (2021) propose to weight the elements of the input X to counter the effect of combinatorial shortcuts.,"Modify,Fact/Evidence",Fact/Evidence
4357,419-ARR,419-ARR_v2_47@6,419-ARR_v1_49@6,"The weighting scheme is based on the fact that when estimating E(Y|X M) in attention, where M are masks applied ( ) to the elements of the input X, the choice of masks M is biased by X and Y because of the key and query elements when computing attention.","The weighting scheme is based on the fact that the estimation of E(Y|X M) in attention, where M are masks applied ( ) to the elements of the input X, is not the same for all elements of X.","Modify,Fact/Evidence",Fact/Evidence
4358,419-ARR,419-ARR_v2_6@2,419-ARR_v1_6@1,"This link between the input and the remaining of the network is used to work on explainability, which in machine learning and NLP is defined as the capacity to explain a non-interpretable (Bibal and Frénay, 2016), i.e., black-box, model (Guidotti et al., 2018).","Explainability in machine learning and NLP is defined as the capacity to explain a non-interpretable (Bibal and Frénay, 2016), i.e. black-box, model (Guidotti et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
4359,419-ARR,419-ARR_v2_54@0,419-ARR_v1_56@0,"As stated earlier in this paper, one of the difficulties in this debate is that the insights are brought from papers of different areas that do not always cite each other.","As stated earlier in this paper, one of the difficulties in this debate is that the insights are brought from paper of different areas that do not always cite each other.","Modify,Grammar",Grammar
4360,419-ARR,419-ARR_v2_55@0,419-ARR_v1_57@0,"First of all, like Thorne et al. (2019) who state that LIME can be used for explanation, thus questioning the need for attention, Bastings and Filippova (2020) state that saliency methods can be used for explanation, removing the need for attention.","First of all, like Thorne et al. (2019) who state that LIME can be used for explanation, thus questioning the need for attention, Bastings and Filippova (2020) state that saliency methods can be used for explanation, and so the attention is not needed in that role.","Modify,Clarity",Clarity
4361,419-ARR,419-ARR_v2_55@1,419-ARR_v1_57@1,"Therefore, according to Bastings and Filippova (2020), if explanation tools already exist, why is the debate about attention useful?","Therefore, according to Bastings and Filippova (2020), if explanation tools already exist to do the job, why is the debate about attention useful?","Modify,Clarity",Clarity
4362,419-ARR,419-ARR_v2_56@1,419-ARR_v1_58@1,"This subject is at the heart of the debate, as Wiegreffe and Pinter (2019) already mentioned the focus of Jain and Wallace (2019) on faithful explanations only.","This subject is at the very heart of the debate, as Wiegreffe and Pinter (2019) already mentioned the focus of Jain and Wallace (2019) on faithful explanations only.","Modify,Clarity",Clarity
4363,419-ARR,419-ARR_v2_56@2,419-ARR_v1_58@2,"Indeed, users may not be satisfied by explanations that are only faithful, as they need to be plausible for them too.","However, users may not be satisfied by explanations that are only faithful to the model, as they need to be plausible for them too.","Modify,Clarity",Clarity
4364,419-ARR,419-ARR_v2_58@0,419-ARR_v1_60@0,"Still on the subject of evaluation, we noted that the different contributions to the debate are often based on different setups (as outlined by Table 1).","Still the subject evaluation, we noted that the different contributions to the debate are often based on different setups.","Modify,Fact/Evidence",Fact/Evidence
4365,419-ARR,419-ARR_v2_58@3,419-ARR_v1_60@4,"However, authors like stress that the lack of a common ground when discussing faithfulness, plausibility and explanations is not conducive to finding answers to the debate.","Likewise, stress that the lack of a common ground when discussing faithfulness, plausibility and explanations is not conducive to finding answers to the debate.","Modify,Clarity",Clarity
4366,419-ARR,419-ARR_v2_61@4,419-ARR_v1_63@4,"The main cost of this solution is that it requires the participation of users, but solutions can handle few-shot user annotations (e.g., Heo et al. (2020)).","The main cost of this solution is that it requires the participation of users, but solutions using few-shot user annotations have already been introduced in the literature (e.g., Heo et al. (2020)).","Modify,Clarity",Clarity
4367,419-ARR,419-ARR_v2_61@5,419-ARR_v1_64@0,Grimsley et al. (2020) offer a philosophical perspective on the debate.,"In a complementary point of view, Grimsley et al. ( 2020) offer a philosophical perspective on the debate.","Modify,Clarity",Clarity
4368,419-ARR,419-ARR_v2_61@6,419-ARR_v1_64@1,They show that works studying attention as explanation do so in a causal framework.,The authors show that works studying attention as explanation attempt to do so in a causal framework.,"Modify,Clarity",Clarity
4369,419-ARR,419-ARR_v2_61@8,419-ARR_v1_64@3,The reason is that the link between the attention layer and the model's output cannot be isolated from the other components of the model.,The reason is that the link between the attention layer and a model's output cannot be isolated from the other components of the model.,"Modify,Grammar",Grammar
4370,419-ARR,419-ARR_v2_61@11,419-ARR_v1_64@6,"The authors propose non-causal explanation paradigms to explore the issue, such as mathematical, structural modal, and minimal-model explanations.","The authors offer other, non-causal, explanation paradigms to explore the issue, such as mathematical, structural modal, and minimal-model explanations.","Modify,Clarity",Clarity
4371,419-ARR,419-ARR_v2_63@1,419-ARR_v1_66@1,"Throughout our analysis, we highlighted various insights that can help advance the debate: theoretically refining concepts around the notion of explanation (in particular plausibility and faithfulness), developing a common ground in the evaluation setup (e.g., similar input embeddings and architectures), extending the studies and uses of effective attention, and improving the integration of users for a supervised attention.","Throughout our analysis of the existing works, we have stressed various insights that could help advance the debate: theoretically refining concepts around the notion of explanation (in particular plausibility and faithfulness), developing a common ground in the evaluation setup (e.g., similar input embeddings and architectures), extending the studies and uses of effective attention, and improving the integration of users for a supervised attention.","Modify,Clarity",Clarity
4372,419-ARR,419-ARR_v2_9@0,419-ARR_v1_9@0,This paper brings together the papers from these different areas in order to provide an outline of the quickly growing and vast literature on the subject.,This paper aims at bringing together the papers from these different areas in order to provide an outline of the quickly growing and vast literature on the subject.,"Modify,Clarity",Clarity
4373,419-ARR,419-ARR_v2_14@0,419-ARR_v1_14@0,The clash between the initial use of attention as explanation and the 2019 studies debating over the validity of considering attention as an explanation started a vast literature on the subject.,The clash between the initial use of attention as explanation and the 2019 studies showing that attention might not be explanation started a vast literature on the subject.,"Modify,Clarity",Clarity
4374,421-ARR,,421-ARR_v1_24@6,,"Finally, we provide a statement for ethical issues in the fifth page.","Delete,Fact/Evidence",Fact/Evidence
4375,421-ARR,,421-ARR_v1_34@0,,We will publicly release the code to run the models upon the acceptance of the paper.,"Delete,Fact/Evidence",Fact/Evidence
4376,421-ARR,421-ARR_v2_12@0,,Ontology Design,,"Add,Other",Other
4377,421-ARR,421-ARR_v2_22@0,,"Finally, some triggers in general-purpose datasets such as ACE05 can be type-indicative to a great extent.",,"Add,Claim",Claim
4378,421-ARR,421-ARR_v2_24@1,,All of these models leverage the pre-trained BERT model to obtain representation vectors.,,"Add,Fact/Evidence",Fact/Evidence
4379,421-ARR,421-ARR_v2_24@2,,The hyperparameters of the models are fine-tuned over the development data.,,"Add,Fact/Evidence",Fact/Evidence
4380,421-ARR,421-ARR_v2_24@3,,"Additionally, we further finetune the pre-trained BERT model over unlabeled Reddit posts from the same three subreddits (i.e., about 40K posts) using masked language modeling (Devlin et al., 2019).",,"Add,Fact/Evidence",Fact/Evidence
4381,421-ARR,421-ARR_v2_24@4,,We report the model performance when the finetuned BERT replaces the original pre-trained BERT to explore the effectiveness of domain customization of BERT for the informal texts in Reddit.,,"Add,Fact/Evidence",Fact/Evidence
4382,421-ARR,421-ARR_v2_34@0,,This research has been supported by the Army Research Office (ARO) grant W911NF-21-1-0112 and the NSF grant CNS-1747798 to the IU-CRC Center for Big Learning.,,"Add,Fact/Evidence",Fact/Evidence
4383,421-ARR,421-ARR_v2_34@1,,"This research is also based upon work supported by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via IARPA Contract No. 2019-19051600006 under the Better Extraction from Text Towards Enhanced Retrieval (BETTER) Program.",,"Add,Fact/Evidence",Fact/Evidence
4384,421-ARR,421-ARR_v2_34@2,,"The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ARO, ODNI, IARPA, the Department of Defense, or the U.S. Government.",,"Add,Claim",Claim
4385,421-ARR,421-ARR_v2_34@3,,The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.,,"Add,Fact/Evidence",Fact/Evidence
4386,421-ARR,421-ARR_v2_34@4,,This document does not contain technology or technical data controlled under either the U.S. International Traffic in Arms Regulations or the U.S. Export Administration Regulations.,,"Add,Fact/Evidence",Fact/Evidence
4387,421-ARR,421-ARR_v2_34@5,,We thank the anonymous reviewers and Tracy King for their helpful feedback.,,"Add,Fact/Evidence",Fact/Evidence
4388,421-ARR,421-ARR_v2_19@5,421-ARR_v1_17@5,The remaining 80% of documents are distributed among the annotators for individual annotation.,The remaining 80% of documents are distributed to the annotators for individual annotation.,"Modify,Grammar",Grammar
4389,421-ARR,421-ARR_v2_19@6,421-ARR_v1_17@6,"To facilitate and standardize future research, we divide SuicideED into three different portions for training, test, and development purposes.","To facilitate future research, we divide SuicideED into three different portions for training, test, and development data.","Modify,Clarity",Clarity
4390,421-ARR,421-ARR_v2_19@7,421-ARR_v1_17@7,Table 1 presents some statistics for the different data portions while Table 2 shows the event type distribution.,Table 1 presents some statistics for different data portions while Table 2 shows the event type distribution.,"Modify,Grammar",Grammar
4391,421-ARR,421-ARR_v2_21@6,421-ARR_v1_20@1,"Furthermore, the event type determination in SuicideED also necessitates appropriate identification of the entity that should be considered for the effect of an event.","Last but not least, the event type determination in Sui-cideED also necessitates appropriate identification of the entity that should be considered for the effect of an event.","Modify,Clarity",Clarity
4392,421-ARR,421-ARR_v2_22@2,421-ARR_v1_21@1,"In contrast, Figure 1 illustrates the ambiguity of the event triggers in SuicideED by presenting the label distribution of the top 5 most frequent event trigger words.","Finally, Figure 1 illustrates the ambiguity of the event triggers in SuicideED by presenting the label distribution of the top 5 most frequent event trigger words.","Modify,Clarity",Clarity
4393,421-ARR,421-ARR_v2_25@0,421-ARR_v1_24@0,Table 3 presents the performance of the models on the SuicideED test set.,Table 3 presents the performance of the models the SuicideED test set.,"Modify,Grammar",Grammar
4394,421-ARR,421-ARR_v2_25@1,421-ARR_v1_24@1,Our first observation is that fine-tuning BERT over Reddit posts can successfully improve the performance of all ED models.,"The first observation is that fine-tuning BERT over Reddit posts can further improve the performance of the ED models although this is less pronounced for recent advanced ED models, i.e., GatedGCN and EEGCN.","Split+Modify,Clarity",Clarity
4395,421-ARR,421-ARR_v2_25@2,421-ARR_v1_24@1,"This improvement, though, is less pronounced for the more recent and advanced ED models, i.e., GatedGCN and EEGCN.","The first observation is that fine-tuning BERT over Reddit posts can further improve the performance of the ED models although this is less pronounced for recent advanced ED models, i.e., GatedGCN and EEGCN.","Split+Modify,Clarity",Clarity
4396,421-ARR,421-ARR_v2_25@6,421-ARR_v1_24@5,"These results then suggests the unique challenges of Sui-cideED for ED models and highlight the need for further, domain-specific research to improve ED for suicide-related events.",It thus suggests the unique challenges of SuicideED for ED models and highlight the need for further research to improve ED for suicide-related events.,"Modify,Clarity",Clarity
4397,421-ARR,421-ARR_v2_27@1,421-ARR_v1_26@1,"Due to the privacy restrictions associated with clinical databases, researchers have used publiclyavailable data from social media with manual annotations of recognizable signals of mental health issues (Coppersmith et al., 2015;Shing et al., 2018).","Due to the privacy restrictions associated with clinical databases, researchers have used publiclyavailable data from social media with manual annotations for recognizable signals of mental health issues (Coppersmith et al., 2015;Shing et al., 2018).","Modify,Grammar",Grammar
4398,421-ARR,421-ARR_v2_27@2,421-ARR_v1_26@2,"The majority of methods, however, focus on detecting suicidal attempts or assessing suicide propensity of users based on social media posts (Coppersmith et al., 2015;Bhat and Goldman-Mellor, 2017;Shing et al., 2018;Zirikly et al., 2019).","The majority of methods, however, focus on detecting suicidal attempts or accessing suicide propensity of users based on social media posts (Coppersmith et al., 2015;Bhat and Goldman-Mellor, 2017;Shing et al., 2018;Zirikly et al., 2019).","Modify,Grammar",Grammar
4399,421-ARR,421-ARR_v2_27@3,421-ARR_v1_26@3,"As such, these prior works have only explored the setting of overall text classification which fails to explore fine-grained analysis/classification at word level required to reveal suicide-related events as this paper does.","As such, these prior work has only relied the setting of overall text classification that fails to explore fine-grained analysis/classification at word level to reveal suicide-related events as we do.","Modify,Clarity",Clarity
4400,421-ARR,421-ARR_v2_28@0,421-ARR_v1_27@0,"Prior research efforts for ED, in general-purpose settings, have introduced various methodologies to address such task, including feature engineering (Ahn, 2006;Ji and Grishman, 2008;Li et al., 2013) and deep learning (Nguyen and Grishman, 2015;Chen et al., 2015;Wang et al., 2019;Cui et al., 2020;Ngo Trung et al., 2021;Pouran Ben Veyseh et al., 2021b,a) models.","Prior research effort for ED has introduced various methods for this problem, including feature engineering (Ahn, 2006;Ji and Grishman, 2008;Li et al., 2013) and deep learning (Chen et al., 2015;Wang et al., 2019;Cui et al., 2020) models.","Modify,Fact/Evidence",Fact/Evidence
4401,421-ARR,421-ARR_v2_28@1,421-ARR_v1_27@1,"However, such prior work mainly utilizes the ED datasets with general event types and formal texts, i.e., ACE-05 (Walker et al., 2006), that might not be helpful for particular domains with unique requirements such as the one addressed in this work.","However, such prior work mainly utilizes the ED datasets with general event types and formal texts, i.e., ACE-05 (Walker et al., 2006), that might not be helpful for specific domains.","Modify,Claim",Claim
4402,421-ARR,421-ARR_v2_28@2,421-ARR_v1_27@2,"Recently, there have been some effort on creating new datasets for ED in more specific domains, including biomedical texts (Kim et al., 2009), literary texts (Sims et al., 2019), cybersecurity texts (Satyapanich et al., 2020;Trong et al., 2020), fine-grained event types (Le and Nguyen, 2021), and historical texts (Lai et al., 2021).","Recently, there have been some effort on creating new datasets for ED in more specific domains, including biomedical texts (Kim et al., 2009), literary texts (Sims et al., 2019), and cybersecurity texts (Satyapanich et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
4403,421-ARR,421-ARR_v2_30@1,421-ARR_v1_29@1,SuicideED is manually annotated for seven event types and provides enough training examples to develop large-scale deep learning models.,SuicideED is manually annotated for 7 event types and provides enough training examples to develop large-scale deep learning models.,"Modify,Clarity",Clarity
4404,421-ARR,421-ARR_v2_30@2,421-ARR_v1_29@2,We perform extensive evaluations of state-of-the-art ED models that demonstrate the challenges entailed by this difficult domain and call for further efforts to improve performance.,We perform extensive evaluations of state-of-the-art ED models to demonstrate the challenges of the dataset and call for further effort to improve performance.,"Modify,Clarity",Clarity
4405,421-ARR,421-ARR_v2_30@3,421-ARR_v1_29@3,"In the future, we plan to extend SuicideED to annotate event arguments and other event properties to better support event analysis and understanding for suicide.","In the future, we plan to extend SuicideED to annotate event arguments and other event properties better support event analysis and understanding for suicide.","Modify,Grammar",Grammar
4406,421-ARR,421-ARR_v2_35@3,421-ARR_v1_36@3,"Interestingly, it can be observed that posts can be summarized into 3 main categories: school (2, 8), work (5, 9, 10), and family (3, 4, 6, 7), which somehow reflects the sources of mental issues.","Interestingly, it can be observed that posts can be summarized into 3 main categories: school (2, 8), work (5, 9, 10), and family (3,4,6,7), which somehow reflects the sources of mental issues.","Modify,Grammar",Grammar
4407,421-ARR,421-ARR_v2_7@1,421-ARR_v1_7@1,"ED is an important task in Information Extraction (IE) whose purpose is to identify event trigger words/mentions text data (Ahn, 2006;Ji and Grishman, 2008).","ED is an important task in Information Extraction (IE) that aims to identify event trigger words/mentions in the text (Ahn, 2006;Ji and Grishman, 2008).","Modify,Clarity",Clarity
4408,421-ARR,421-ARR_v2_7@2,421-ARR_v1_7@2,"Take, for instance, the following paragraph:","Adapted to our interest in suicide-related events, in the following sentences, an ED system should be able to recognize ""date"" and ""have"" as trigger words for deteriorated personal relationship events (i.e., risk factors); ""wanna"", ""have"", and ""desirable"" as triggers for protective factor events, and ""depression"" as a trigger for a health-related risk factor event:","Split+Modify,Clarity",Clarity
4410,421-ARR,421-ARR_v2_10@0,421-ARR_v1_9@0,"The vast majority of advanced methods for ED are based on training deep neural networks on large labeled corpora (Nguyen and Grishman, 2015;Chen et al., 2015).","The vast majority of advanced methods for ED are based on training deep neural networks on large labeled corpora (Chen et al., 2015).","Modify,Fact/Evidence",Fact/Evidence
4411,421-ARR,421-ARR_v2_10@1,421-ARR_v1_9@1,"As such, to facilitate research in ED for suicide prevention, a key requirement is to have a benchmark dataset to standardize the development and evaluation of ED models.","As such, to facilitate ED in suicide prevention research, a key requirement is to have a benchmark dataset to standardize the development and evaluation of ED models.","Modify,Clarity",Clarity
4412,421-ARR,421-ARR_v2_11@0,421-ARR_v1_10@0,"To overcome such challenges, this paper introduces SuicideED, a new dataset for suicidal event detection that is manually annotated for seven distinct event types to comprehensively characterize suicide-related events regarding suicidal actions, thoughts, and risk and protective factors.","To overcome such challenges, this paper introduces SuicideED, a new dataset for suicidal event detection that is manually annotated for seven distinct event types to comprehensively characterize suicide-related events regarding actual actions, thoughts, and risk and protective factors.","Modify,Clarity",Clarity
4413,421-ARR,421-ARR_v2_11@1,421-ARR_v1_10@1,"To enable data sharing, our dataset is based on public posts from Reddit where personal information is not presented to avoid privacy issues.","To enable data sharing, our dataset is based on pubic posts from Reddit where personal information is not presented to avoid privacy issues.","Modify,Grammar",Grammar
4414,421-ARR,421-ARR_v2_11@2,421-ARR_v1_10@2,"The SuicideED dataset is challenging as it involves informal texts, and requires event factuality and affected entity reasoning.","The Sui-cideED dataset is challenging as it involves informal texts, and require event factuality and affected entity reasoning.","Modify,Grammar",Grammar
4415,421-ARR,421-ARR_v2_11@4,421-ARR_v1_10@4,"To facilitate future research in this area, SuicideED is released publicly 2 for the research community.","To facilitate future research in this area, SuicideED will be released publicly for the research community.","Modify,Grammar",Grammar
4416,421-ARR,421-ARR_v2_17@0,421-ARR_v1_11@0,Data Collection and Annotation,Annotation,"Modify,Other",Other
4417,421-ARR,421-ARR_v2_18@0,421-ARR_v1_12@0,The documents for SuicideED are collected from publicly available posts from reddit.com.,The documents for SuicideED are collected out of publicly available posts from reddit.com.,"Modify,Grammar",Grammar
4418,421-ARR,421-ARR_v2_18@2,421-ARR_v1_12@2,Each original post is considered as a separate document and only posts with more than 50 words are considered to increase the probability of an event being present.,Each original post is considered as a separate document and only posts with more than 50 words are kept to increase the probability of an event being present.,"Modify,Clarity",Clarity
4419,421-ARR,421-ARR_v2_3@3,421-ARR_v1_3@3,Our experiments with current state-of-the-art ED systems suggest that this domain poses meaningful challenges as there is significant room for improvement of ED models.,Our experiments with current state-of-the-art ED systems suggest that there is still room for improvement of ED models in this domain.,"Modify,Clarity",Clarity
4420,421-ARR,421-ARR_v2_3@4,421-ARR_v1_3@4,We publicly release SuicideED to support future research in this important area.,We will publicly release Sui-cideED to support future research in this important area.,"Modify,Grammar",Grammar
4421,421-ARR,421-ARR_v2_19@4,421-ARR_v1_17@4,"We select 20% of the documents to be used for co-annotation, leading to a Fleiss' Kappa score of 0.8 (i.e., close to the almost perfect agreement range of [0.81 − 1.0]).","20% of the documents are selected for co-annotation, leading to a Fleiss' Kappa score of 0.8 (i.e., close to the almost perfect agreement range of [0.81 − 1.0]).","Modify,Clarity",Clarity
4455,429-ARR,429-ARR_v2_36@5,,Also note that both 1.5-entmaxes (with full and partial sorting) cannot learn the English-Russian data set as well as 1.5-ReLU.,,"Add,Claim",Claim
4456,429-ARR,429-ARR_v2_43@4,,"A possible explanation for the difference in sparsity levels could be that α-ReLU, in contrast to α-entmax, behaves significantly differently on the test set than on the training set.",,"Add,Claim",Claim
4457,429-ARR,429-ARR_v2_44@0,,"Note that the sparsity of α-ReLU and α-entmax is approximately the same at the beginning of training due to how we initialize τ in 1.5-ReLU (making it as close as possible to 1.5-entmax's τ in the untrained model, Sec. 3.1).",,"Add,Fact/Evidence",Fact/Evidence
4458,429-ARR,429-ARR_v2_44@1,,"However, during training, α-ReLU's τ remains fixed, and the model can only adapt the logits themselves so that α-ReLU(z) converges to the corresponding one-hot vector.",,"Add,Fact/Evidence",Fact/Evidence
4459,429-ARR,429-ARR_v2_44@3,,"However, the logits themselves also change during training, so the increase in τ may not be the cause of greater sparsity.",,"Add,Claim",Claim
4460,429-ARR,429-ARR_v2_44@4,,"To find out, we track the dynamics of mean logit norm z and mean τ during training for both 1.5-entmax and 1.5-ReLU (Fig. 7).",,"Add,Fact/Evidence",Fact/Evidence
4461,429-ARR,429-ARR_v2_45@0,,"As we can see, the logit sizes grow in both cases.",,"Add,Fact/Evidence",Fact/Evidence
4462,429-ARR,429-ARR_v2_45@1,,"At the same time, the 1.5-entmax's τ (z) increases following the logit size, while the 1.5-ReLU's τ remains constant.",,"Add,Fact/Evidence",Fact/Evidence
4463,429-ARR,429-ARR_v2_45@2,,From this we conclude that the sparsity of 1.5-entmax is inevitably less than the sparsity of 1.5-ReLU.,,"Add,Fact/Evidence",Fact/Evidence
4464,429-ARR,429-ARR_v2_75@0,,Our standalone implementation of α-ReLU in PyTorch is available at https://github.,,"Add,Fact/Evidence",Fact/Evidence
4465,43-ARR,,43-ARR_v1_31@4,,"Finally, to verify how much the tiny amount (503 sentences) of LIV-EN parallel data brings for tuning we ran a separate experiment excluding it and achieved 11.87 BLEU for LIV-EN and 8.25 BLEU for EN-LIV, which is even slightly higher than with the data there.","Delete,Fact/Evidence",Fact/Evidence
4466,43-ARR,,43-ARR_v1_32@1,,"Results from these experiments in Table 3 show that not only ET is better than LV to pivot translate between EN and LIV, but also that this approach was able to reach the highest BLEU scores so far.","Delete,Fact/Evidence",Fact/Evidence
4467,43-ARR,,43-ARR_v1_32@2,,Tuning on the backtranslated data seemed to overwhelm the far lower amount of clean parallel data and did not produce a higher BLEU score in any direction.,"Delete,Claim",Claim
4468,43-ARR,,43-ARR_v1_5@0,,Models and corpora will also be added to the Huggingface repository after de-anonymization (https://huggingface.co/).,"Delete,Fact/Evidence",Fact/Evidence
4469,43-ARR,43-ARR_v2_7@1,,"First, we collected the majority of digitally available translation examples including Livonian into a small parallel corpus (just over 10000 sentence pairs) of mostly Livonian-Latvian and Livonian-Estonian sentence translations with very few (1000) Livonian-English examples.",,"Add,Fact/Evidence",Fact/Evidence
4470,43-ARR,43-ARR_v2_21@0,,"We also perform iterative back-translation (Pinnis et al., 2018) to make use of the large amounts of monolingual news data in EN/ET/LV, and our limited amount of monolingual data in LIV.",,"Add,Fact/Evidence",Fact/Evidence
4471,43-ARR,43-ARR_v2_21@1,,"We translate the 40k LIV sentences and different batches of 200k sentences from the other languages into all directions, filter the translations using simple heuristic filters (Rikters, 2018), and use a mix of all back-translated data with an equal amount of random clean parallel data (including all data involving Livonian) to fine-tune the base model.",,"Add,Fact/Evidence",Fact/Evidence
4472,43-ARR,43-ARR_v2_30@1,,"In all four cases the pivot translation quality dropped when compared to direct translation by the same model, so we did not further pursue this line of experiments.",,"Add,Fact/Evidence",Fact/Evidence
4473,43-ARR,43-ARR_v2_30@2,,"An interesting observation, was that pivoting through ET achieved a higher BLEU score than LV when translating into EN (13.66 vs. 11.24), but slightly lower when translating into LIV (7.99 vs. 8.56).",,"Add,Fact/Evidence",Fact/Evidence
4474,43-ARR,43-ARR_v2_31@0,,Results for four rounds of BT iterations are compiled in Table 3.,,"Add,Fact/Evidence",Fact/Evidence
4475,43-ARR,43-ARR_v2_31@1,,"The model clearly improves not only in the main language pair of EN↔LIV, but in all other translation directions as well.",,"Add,Fact/Evidence",Fact/Evidence
4476,43-ARR,43-ARR_v2_33@0,,Detailed Analysis,,"Add,Other",Other
4477,43-ARR,43-ARR_v2_34@0,,Table 4 shows BLEU scores of the separate parts of the evaluation corpus.,,"Add,Fact/Evidence",Fact/Evidence
4478,43-ARR,43-ARR_v2_34@1,,"Since most of the training data for EN-LIV comes from Satversme (Latvian Constitution), it is very clear why that part scores higher than others.",,"Add,Fact/Evidence",Fact/Evidence
4479,43-ARR,43-ARR_v2_34@2,,"The dictionary entries are overall far shorter in length than the other parts and often consist of few-word phrases, making them unfavorable to BLEU by definition.",,"Add,Fact/Evidence",Fact/Evidence
4480,43-ARR,43-ARR_v2_35@0,,The posts from Facebook and Livones.net are more general in their language and therefore more similar to data from the training set.,,"Add,Claim",Claim
4481,43-ARR,43-ARR_v2_35@1,,"However, the Trilium and Stalte books are written in a more literary language, making them slightly more challenging to translate.",,"Add,Claim",Claim
4482,43-ARR,43-ARR_v2_35@2,,"Finally, the very domain-specific part from JEFUL abstracts seems to be the most difficult to translate into English.",,"Add,Claim",Claim
4483,43-ARR,43-ARR_v2_39@0,,"In the future we are planning to experiment with cross-lingual transfer from other languages, like the resource-rich Finnish as well as resource-poor Finno-Ugric languages like Võru and Sami (Tars et al., 2021).",,"Add,Claim",Claim
4484,43-ARR,43-ARR_v2_39@1,,"Given the limited amount of existing monolingual Livonian data, generating synthetic Livonian data with other means besides backtranslation might be helpful: for example, forwardtranslation or using GPT-like language models.",,"Add,Claim",Claim
4485,43-ARR,43-ARR_v2_40@0,,"Finally, work on the already collected Livonian monolingual and parallel data is ongoing at the Institute of the Livonian Language.",,"Add,Fact/Evidence",Fact/Evidence
4486,43-ARR,43-ARR_v2_40@1,,"Adding English translations to the lexical items and example sentences is an ongoing effort and will evaluate in practice, if the MT systems created as part of the current work can facilitate that.",,"Add,Claim",Claim
4487,43-ARR,,43-ARR_v1_15@0,,Collected Data,"Delete,Other",Other
4488,43-ARR,,43-ARR_v1_16@0,,The first step in developing (supervised) machine translation is collecting parallel data.,"Delete,Claim",Claim
4489,43-ARR,,43-ARR_v1_16@1,,"While there was no pre-existing open parallel corpus with Livonian, we used all the possible sources of translations.","Delete,Fact/Evidence",Fact/Evidence
4490,43-ARR,,43-ARR_v1_16@2,,"This was limited to already digital resources, future work might include texts extracted by scanning older books and other materials.","Delete,Claim",Claim
4491,43-ARR,43-ARR_v2_24@0,43-ARR_v1_28@0,"Base models were trained on LV→EN, ET→EN, ET+LV→EN data, and a multilingual model using the tagged approach (Johnson et al., 2017) for translating in all directions between EN/ET/LV languages.","Base models were trained on LV→EN, ET→EN, ET+LV→EN data, and a multilingual model using the tagged approach (Johnson et al., 2017) for translating in all directions between ENG/EST/LAT.","Modify,Clarity",Clarity
4492,43-ARR,43-ARR_v2_24@1,43-ARR_v1_28@1,The base models were then used as initialization for tuning on Livonian-English parallel data.,The base models were then used as initialization for tuning on LIV→EN data.,"Modify,Clarity",Clarity
4493,43-ARR,43-ARR_v2_2@4,43-ARR_v1_2@4,"The resulting NMT systems and the collected monolingual and parallel data, including a manually translated and verified translation benchmark, are publicly released via the OPUS corpora collection and Huggingface model repository.","The resulting NMT systems and the collected monolingual and parallel data, including a manually translated and verified translation benchmark, are publicly released.","Modify,Fact/Evidence",Fact/Evidence
4494,43-ARR,43-ARR_v2_28@0,43-ARR_v1_30@0,Table 2 shows the results of MT experiments.,Table 2 shows results from MT experiments.,"Modify,Grammar",Grammar
4495,43-ARR,43-ARR_v2_28@4,43-ARR_v1_30@3,"However, when attempting to perform zero-shot translation from LIV into EN,ET→EN outperforms LV→EN (3.22 vs. 2.20), and the multilingual model achieved a very respectable BLEU score 13.29.","However, when attempting to perform zero-shot translation from LIV into EN, the ET→EN model was able to outperform LV→EN (3.22 vs. 2.20), and the multilingual model achieved a very respectable BLEU score 8.92.","Modify,Fact/Evidence",Fact/Evidence
4496,43-ARR,43-ARR_v2_29@2,43-ARR_v1_31@2,"This improved all scores by 1-3 BLEU points, but the multilingual model remained on top with 14.69 for LIV→EN.","This improved all scores by 1-3 BLEU points, but the multilingual model remained on top with 11.62 for LIV→EN.","Modify,Fact/Evidence",Fact/Evidence
4497,43-ARR,43-ARR_v2_29@3,43-ARR_v1_31@3,"In order to perform backtranslation models for both directions are required, so we scored the tuned multilingual model on the EN→LIV data as well, reaching 8.59 BLEU.","In order to perform backtranslation models for both directions are required, so we scored the tuned multilingual model on the EN→LIV data as well, reaching 8.10 BLEU.","Modify,Fact/Evidence",Fact/Evidence
4498,43-ARR,43-ARR_v2_32@2,43-ARR_v1_33@2,Pivot-translation trough Estonian or Latvian underperforms direct Livonian↔English translation trained in a zero-shot / few-shot manner.,"Interestingly, pivot-translation through Estonian showed higher translation quality than direct Livonian↔English trained in a zero-shot / few-shot manner.","Modify,Fact/Evidence",Fact/Evidence
4499,43-ARR,43-ARR_v2_38@1,43-ARR_v1_36@1,"While perhaps not being usable as-is in any kind of production scale, the achieved final BLEU scores of 19.01 for Livonian→English and 11.03 for English→Livonian show that some transfer of meaning can still be achieved with the currently available resources.","While perhaps not being usable as-is in any kind of production scale, the achieved BLEU scores of 13.00 and 9.47 show that some transfer of meaning can still be achieved between Livonian and English with the currently available resources.","Modify,Fact/Evidence",Fact/Evidence
4500,43-ARR,43-ARR_v2_5@0,43-ARR_v1_6@0,In this paper we set the goal of developing machine translation between English and Livonian.,In this paper we set the goal of developing usable machine translation between English and Livonian.,"Modify,Clarity",Clarity
4501,43-ARR,43-ARR_v2_5@1,43-ARR_v1_6@1,"Currently there are just over 20 fluent speakers of the language (Ernštreits, 2016).","Currently there are over 20 fluent speakers of the language (Ernštreits, 2016).","Modify,Clarity",Clarity
4502,43-ARR,43-ARR_v2_0@0,43-ARR_v1_0@0,Machine Translation for Livonian: Catering to 20 Speakers,Machine Translation for Livonian: Catering for 20 Speakers,"Modify,Grammar",Grammar
4503,43-ARR,43-ARR_v2_5@2,43-ARR_v1_6@2,"Although some digital linguistic resources exist for Livonian (including a dictionary with example sentences and a written monolingual corpus, Ernštreits, 2016), there is virtually no open parallel corpora between English and Livonian, with the single exception of 35 parallel sentences in the OPUS Tatoeba corpus (Tiedemann, 2020).","Although some digital linguistic resources exist for Livonian (including a dictionary with example sentences and a written monolingual corpus, (Ernštreits, 2016)), there is virtually no open parallel corpora with it, with the single exception of 35 parallel sentences in the OPUS Tatoeba corpus (Tiedemann, 2020).","Modify,Clarity",Clarity
4504,43-ARR,43-ARR_v2_11@5,43-ARR_v1_13@5,"Although there are just over 20 people who can speak the language, the Livonian community is active in preserving and developing the Livonian heritage (Ernštreits, 2016) and language plays a key role in this process (Ernštreits and Kl , ava, 2020).","Although there are just over 20 people who can speak the language, the Livonian community is active in preserving and developing the Livonian heritage (Ernštreits, 2016) and language plays key role in this process (Ernštreits and Kl , ava, 2020).","Modify,Grammar",Grammar
4505,43-ARR,43-ARR_v2_15@2,43-ARR_v1_19@0,The resulting amount of sentences in the resulting dataset is shown in Table 1.,The total amount of sentences in the resulting dataset is shown in Table 1.,"Modify,Clarity",Clarity
4506,43-ARR,43-ARR_v2_17@2,43-ARR_v1_22@0,The resulting benchmark and the whole corpus is published in the OPUS collection.,"The resulting benchmark and the whole corpus is published in the OPUS collection (currently, anonymously).","Modify,Fact/Evidence",Fact/Evidence
4507,431-ARR,,431-ARR_v1_2@7,,Dataset and code will be released on acceptance.,"Delete,Claim",Claim
4508,431-ARR,,431-ARR_v1_66@2,,"An interesting finding is that single-span (v2) does not drop in the overlapping scores, which seems to be because the tuned threshold t (see Section 4.1) works in this setting.","Delete,Fact/Evidence",Fact/Evidence
4509,431-ARR,431-ARR_v2_67@1,,"For the proposed span encoder, we use a multi-head self-attention layer with 4 heads followed by a linear layer to encode the spans.",,"Add,Fact/Evidence",Fact/Evidence
4510,431-ARR,431-ARR_v2_67@2,,The maximum span number is set to 30 for the input of the span encoder.,,"Add,Fact/Evidence",Fact/Evidence
4511,431-ARR,431-ARR_v2_73@1,,"In detail, for each pair of prediction p i and ground truth answer t j , we define the partial retrieved score and partial relevant score as the length of the longest common substring (LCS) between p i and t j , divided by the length of p i and t j , respectively, as:",,"Add,Fact/Evidence",Fact/Evidence
4512,431-ARR,431-ARR_v2_76@0,,Suppose there are n predictions and m ground truth answers for a question.,,"Add,Fact/Evidence",Fact/Evidence
4513,431-ARR,431-ARR_v2_76@1,,"Since we do not know the correspondence between predictions and an- swers, we compute the partial retrieved score between a prediction and all answers and keep the highest one as the retrieved score of the prediction.",,"Add,Fact/Evidence",Fact/Evidence
4514,431-ARR,431-ARR_v2_76@2,,"Similarly, for each ground truth answer, the relevant score is the highest one between it and all predictions.",,"Add,Fact/Evidence",Fact/Evidence
4515,431-ARR,431-ARR_v2_76@3,,"The precision, recall, and F1 are finally defined as follows:",,"Add,Fact/Evidence",Fact/Evidence
4516,431-ARR,431-ARR_v2_78@0,,We use micro-averaged scores for all metrics.,,"Add,Fact/Evidence",Fact/Evidence
4517,431-ARR,431-ARR_v2_81@2,,This is also the reason that:,,"Add,Claim",Claim
4518,431-ARR,431-ARR_v2_35@0,431-ARR_v1_34@4,"MultiSpanQA contains 6,536 instances with 5,230 for training, 653 for validation, and 653 for test.","MultiSpanQA contains 6,465 instances with 5,173 for training, 646 for validation, and 646 for test.","Modify,Fact/Evidence",Fact/Evidence
4519,431-ARR,431-ARR_v2_37@1,431-ARR_v1_36@1,"However, in a real-world QA scenario, single-span answer questions and unanswerable questions (i.e. the answer is not contained in the passage) would realistically exist.","However, in a real-word QA scenario, single-span answer questions and unanswerable questions (i.e. the answer is not contained in the passage) would realistically exist.","Modify,Grammar",Grammar
4520,431-ARR,431-ARR_v2_37@3,431-ARR_v1_36@3,"The total size of the expanded dataset is 19,608 instances (three times the basic version, partitioned similarly to the basic version).","The total size of the expanded dataset is 19,395 instances (three times the basic version, partitioned similarly to the basic version).","Modify,Fact/Evidence",Fact/Evidence
4521,431-ARR,431-ARR_v2_45@1,431-ARR_v1_44@1,"In our experiments, we use the popular IOB tagging scheme to mark 1254 answer spans in the passage where B denotes the first token of an answer span, I denotes subsequent tokens within a span, and O denotes tokens that are not part of an answer span.","In our experiments, we use the popular IOB tagging scheme to mark answer spans in the passage where B denotes the first token of an answer span, I denotes subsequent tokens within a span, and O denotes tokens that are not part of an answer span.","Modify,Fact/Evidence",Fact/Evidence
4522,431-ARR,431-ARR_v2_47@0,431-ARR_v1_46@0,"By investigating the failures of the sequence tagging baseline, we find there is an issue that the model struggles to capture global information.","By investigating the failures of sequence tagging baseline, we find there is an issue that the global information is hard to be captured during tagging.","Modify,Clarity",Clarity
4523,431-ARR,431-ARR_v2_47@2,431-ARR_v1_46@2,"To better use such global information, we propose a span encoder, a number of span predictor, an answer structure predictor, and a span adjustment module (as in Figure 2), which can be combined with any on-the-fly sequence tagger (encoder).","To better use such global information, we propose a span number predictor, an answer structure predictor, and a span adjustment module (as in Figure 2), which can be combined with any on-the-fly sequence tagger (encoder).","Modify,Fact/Evidence",Fact/Evidence
4524,431-ARR,431-ARR_v2_51@0,431-ARR_v1_49@0,"After encoding, we fetch the hidden states of the context tokens and input them to a linear classifier to perform a preliminary token-level answer span prediction, as:","After encoding, we fetch the hidden states of the context tokens and input them to a linear classifier to perform a preliminary answer span prediction, as:","Modify,Clarity",Clarity
4525,431-ARR,431-ARR_v2_66@0,431-ARR_v1_61@0,Setup,Experimental Setup,"Modify,Other",Other
4526,431-ARR,431-ARR_v2_68@0,431-ARR_v1_62@1,"For training, we use the BertAdam optimizer with default hyperparameters and learning rate of 3e-5.","For training, we use the BertAdam optimizer with default hyperparameters and learning rate of 5e-5.","Modify,Fact/Evidence",Fact/Evidence
4527,431-ARR,431-ARR_v2_68@1,431-ARR_v1_62@2,All models are trained with a batch size of 4 for 3 epochs.,"All models are trained with a batch size of 8 for 3,000 steps.","Modify,Fact/Evidence",Fact/Evidence
4528,431-ARR,431-ARR_v2_68@2,431-ARR_v1_62@3,We use a two-layer feed-forward network with a ReLU activation function for all linear layers.,We use a two-layer feed-forward network with a ReLu activation function for all linear layers.,"Modify,Grammar",Grammar
4529,431-ARR,431-ARR_v2_81@0,431-ARR_v1_66@0,"Single-span model From the table, we see that single-span (v1) gets very low exact match scores but higher partial match scores (compared to exact match), as it is trained to find a single long span that overlaps with all answer spans.","Single-span model From the table, we see that single-span (v1) gets very low exact match scores but higher overlapping scores (compared to exact match), as it is trained to find a single long span that overlaps with all answer spans.","Modify,Clarity",Clarity
4530,431-ARR,431-ARR_v2_83@1,431-ARR_v1_67@1,"Without changing the encoder, there is an improvement of over 30 absolute points on the exact match metrics, and about 8 for the partial match F1 metric in MultiSpanQA.","Without changing the encoder, there is an improvement of more than 30 absolute points on the exact match metrics, and about 3 for the overlapping F1 metric.","Modify,Fact/Evidence",Fact/Evidence
4531,431-ARR,431-ARR_v2_6@0,431-ARR_v1_6@0,"In this paper, we introduce MultiSpanQA, a new reading comprehension dataset consisting of 6,536 multi-span examples.","In this paper, we introduce MultiSpanQA, a new reading comprehension dataset consistinga of 6,465 multi-span examples.","Modify,Fact/Evidence",Fact/Evidence
4532,431-ARR,431-ARR_v2_87@3,431-ARR_v1_72@3,"We can see that our model tends to predict CONJUNCTION and NON-REDUNDANT, and there are no REDUNDANT or SHARE predictions.","We can see that our model tends to predict CONJUNCTION and NON-REDUNDANT, and there are no REDUNDANT and SHARE predictions.","Modify,Grammar",Grammar
4533,431-ARR,431-ARR_v2_8@2,431-ARR_v1_8@2,Experimental results show that the proposed model surpasses all baselines and achieves 59.28% exact-match F1 score and 76.50% partial-match F1 score.,Experimental results show that the proposed model surpasses all baselines and achieves 62.58% exact-match F1 score and 77.46% overlapping F1 score.,"Modify,Fact/Evidence",Fact/Evidence
4534,431-ARR,431-ARR_v2_13@4,431-ARR_v1_13@4,"TriviaQA (Joshi et al., 2017) and HotpotQA (Yang et al., 2018) extend the answer context from single passage to multiple passages, while HotpotQA further requires reasoning over multiple passages to answer the question.","TriviaQA (Joshi et al., 2017) and HothopQA (Yang et al., 2018) extend the answer context from single passage to multiple passages, while HotpotQA further requires reasoning over multiple passages to answer the question.","Modify,Fact/Evidence",Fact/Evidence
4535,434-ARR,,434-ARR_v1_3@1,,"Our method addresses cross-lingual UMLS NEL in a low resource setting, where the ontology is large, there is a lack of descriptive text defining most entities, and labeled data can only cover a small portion of the ontology.","Delete,Claim",Claim
4536,434-ARR,,434-ARR_v1_54@0,,"For future work, we intend to test whether utilizing language-specific BERT models instead of multilingual BERT (e.g., swapping m-BERT with the recently released AlephBERT (Seker et al., 2021), a Hebrew version of BERT) could improve results on the Hebrew Camoni corpus.","Delete,Claim",Claim
4537,434-ARR,,434-ARR_v1_54@1,,"In addition, taking into account the SapBERT objective which exploits the UMLS graph structure as part of either fine-tuning or pre-training in Hebrew could lead to improved generalization capabilities.","Delete,Claim",Claim
4538,434-ARR,,434-ARR_v1_54@2,,"Finally, exploring datasets with additional source languages will help understand the capabilities of our multilingual pipeline.","Delete,Claim",Claim
4539,434-ARR,,434-ARR_v1_56@1,,"We used character unigram, bigram and trigram analysis in all the reported cases (Table 8).","Delete,Fact/Evidence",Fact/Evidence
4540,434-ARR,,434-ARR_v1_57@0,,"We hypothesize that the improvement stems from Idf penalizing frequent words by taking the log of {number of docs in the corpus divided by the number of docs in which the term appears}, where in our context, a 'doc' is either a span of text or a UMLS concept from C L .","Delete,Claim",Claim
4541,434-ARR,,434-ARR_v1_57@1,,"Since no stop words can appear at either the start or end of the span/concept, we increase the odds of having meaningful words comprising each 'doc'.","Delete,Claim",Claim
4542,434-ARR,,434-ARR_v1_57@2,,"The tf-idf method may contribute to this further because it not only focuses on the frequency of words present in the corpus (tf, bag of word) but also provides an importance weight to them.","Delete,Claim",Claim
4543,434-ARR,,434-ARR_v1_2@1,,We propose a general solution that can be easily adapted to any source language and demonstrate the method on Hebrew documents.,"Delete,Claim",Claim
4544,434-ARR,434-ARR_v2_11@8,,The post contains 37 words and 6 spans that link to 4 different CUIs of UMLS concepts.,,"Add,Fact/Evidence",Fact/Evidence
4545,434-ARR,434-ARR_v2_11@9,,"Notice that a span can consist of more than 1 word (such as the term matched with ""gait abnormality"") and a single CUI can be referenced from several places in the same post (such as the CUI of ""General Treatment"").",,"Add,Fact/Evidence",Fact/Evidence
4546,434-ARR,434-ARR_v2_36@6,,"Table 1 compares our HRM results (recall) with MDTEL for each community (diabetes, depression, sclerosis).",,"Add,Fact/Evidence",Fact/Evidence
4547,434-ARR,434-ARR_v2_51@2,,We explore this trade-off and compare the performance of the high recall matching component with the final tagging results of our model using different values of R on the MedMentions dataset.,,"Add,Fact/Evidence",Fact/Evidence
4548,434-ARR,434-ARR_v2_51@3,,Figure 3 shows that there is a clear trend of increased recall of the HRM as R increases.,,"Add,Fact/Evidence",Fact/Evidence
4549,434-ARR,434-ARR_v2_51@4,,"However, Figure 4 shows the complexity of the trade-off since the tagger's performance reaches a peak and then begins to drop as R increases.",,"Add,Fact/Evidence",Fact/Evidence
4550,434-ARR,434-ARR_v2_51@5,,"The contextual model fine-tuning improvement plateaus after a certain amount of training examples, demonstrating the benefit of multi-task adaptation of pre-trained models which converge rapidly.",,"Add,Fact/Evidence",Fact/Evidence
4551,434-ARR,434-ARR_v2_51@6,,The data efficiency of the contextual relevance fine-tuning process allows the UMLS dictionary fine-tuning technique to help improve end to end linking results.,,"Add,Claim",Claim
4552,434-ARR,434-ARR_v2_53@1,,"We describe a pipeline to detect and link mentions of UMLS concepts in documents in Hebrew or in English, which improves upon existing methods.",,"Add,Fact/Evidence",Fact/Evidence
4553,434-ARR,434-ARR_v2_16@2,434-ARR_v1_15@2,"Given text W = (w 1 , ..., w n ), where w i ∈ L, for every span s i,j = (w i , ..., w j ) ⊆ W , we would like to compute F (W, s i,j ), where 0 ≤ j − i < k (we limit the span sizes to at most k), that is, we want to predict the concept associated with a span under context W in language L. Provided a dataset A L exposing a subset of F combined with linguistic knowledge and generalization capabilities of neural models, we aim at learning a larger portion of function F .","Given text W = (w 1 , ..., w n ), where w i ∈ L, for every span s i,j = (w i , ..., w j ) ⊆ W , we would like to compute F (W, s i,j ), where 0 ≤ j − i < k (we limit the span sizes to at most k), that is, we want to predict the concept associated with a span within a text in L. Provided a dataset A L exposing a subset of F combined with linguistic knowledge and generalization capabilities of neural models, we aim at learning a larger portion of function F .","Modify,Fact/Evidence",Fact/Evidence
4554,434-ARR,434-ARR_v2_2@4,434-ARR_v1_3@3,"We achieve new state-of-the-art (SOTA) results on the Hebrew Camoni corpus, +8.9 F1 on average across three communities in the dataset.","We achieve new state-of-the-art results on the Hebrew Camoni corpus, +8.9 F1 on average across three communities in the dataset.","Modify,Clarity",Clarity
4555,434-ARR,434-ARR_v2_31@0,434-ARR_v1_30@0,We introduce a UMLS dictionary finetuning (UMLS DFT) technique where some of the data in A L is removed from the training dataset and used to directly expand the learned dictionary C L .,We introduce a UMLS dictionary fine-tuning technique where some of the data in A L is removed from the training dataset and used to directly expand the learned dictionary C L .,"Modify,Clarity",Clarity
4556,434-ARR,434-ARR_v2_32@5,434-ARR_v1_34@1,We elaborate more on this trade-off in Section 5.4.2.,We elaborate more on this trade-off in 5.4.2.,"Modify,Clarity",Clarity
4557,434-ARR,434-ARR_v2_38@0,434-ARR_v1_39@0,"In the end to end linking task, our model achieves much higher precision (98% vs. 77%) without affecting the recall (73%), resulting in much improved F-score (84% vs 74%).","In the end to end linking task, our model achieves much higher precision (98% vs. 77%) at the cost of slightly lower accuracy but much improved F-score 84 vs 74.","Modify,Fact/Evidence",Fact/Evidence
4558,434-ARR,434-ARR_v2_43@1,434-ARR_v1_44@1,"Each entity annotation includes both the mention text spans and normalized concept identifiers, using MeSH (Medical Subject Headings) (Lipscomb, 2000) as the controlled vocabulary (MeSH is part of the UMLS controlled vocabulary).","Each entity annotation includes both the mention text spans and normalized concept identifiers, using MeSH (Lipscomb, 2000) as the controlled vocabulary (MeSH is part of the UMLS ontology).","Modify,Clarity",Clarity
4559,434-ARR,434-ARR_v2_44@1,434-ARR_v1_44@6,We observe that domain-specific pre-trained transformers help improve results on BC5CDR (93.5 F-measure vs. 73 for our model).,We observe that domain-specific pre-trained transformers help improve results on BC5CDR (93.5 F-measure vs. 73.0 for our model).,"Modify,Clarity",Clarity
4560,434-ARR,434-ARR_v2_44@2,434-ARR_v1_44@7,"The subset of semantic types covered in this dataset is much more technical (chemicals and chemical-disease interactions) than those covered in MedMentions, even though both BC5CDR and MedMentions include documents in the same genre of scientific biomedical articles.","The subset of semantic types covered in this dataset is much more technical (chemicals and chemicaldisease interactions) than those covered in Med-Mentions, even though both BC5CDR and Med-Mentions include documents in the same genre of scientific biomedical articles.","Modify,Grammar",Grammar
4561,434-ARR,434-ARR_v2_5@1,434-ARR_v1_5@5,"We focus in this work on biomedical NEL, i.e., identifying mentions referring to biomedical concepts such as disorders and drugs and linking them to normalized concepts, for example, concept unique identifiers (CUIs) listed in the Unified Medical Language System (UMLS) controlled vocabulary.","We focus in this work on biomedical NEL, i.e., identifying mentions referring to biomedical concepts such as disorders and drugs and linking them to normalized concepts, for example, those listed in the Unified Medical Language System (UMLS) ontology.","Modify,Fact/Evidence",Fact/Evidence
4562,434-ARR,434-ARR_v2_50@0,434-ARR_v1_50@0,We first observe that our UMLS dictionary finetuning (DFT) technique can only improve the high recall matching performance (Section 4.3) since an annotation that we do not have a good semantic match for from UMLS will be a missed match without UMLS DFT.,We first observe that our UMLS dictionary finetuning technique can only improve the high recall matching performance (Section 4.3) since an annotation that we do not have a good semantic match for from UMLS will be a missed match without UMLS DFT.,"Modify,Clarity",Clarity
4563,434-ARR,434-ARR_v2_5@4,434-ARR_v1_5@8,We address crosslingual NEL which consists of mapping mentions in a source language to concepts labeled and described in a different target language.,We address cross-lingual NEL (xNEL) which consists of mapping mentions in a source language to concepts labeled and described in a different target language.,"Modify,Clarity",Clarity
4564,434-ARR,434-ARR_v2_5@5,434-ARR_v1_5@9,"We focus on cross-lingual UMLS NEL, where mentions in the source language (we specifically test Hebrew, see Figure 1 for a Hebrew tagging example) are mapped to UMLS concepts.","We focus on UMLS xNEL, where mentions in the source language (we specifically test Hebrew, see Appendix A for a Hebrew tagging example) are mapped to UMLS concepts.","Modify,Fact/Evidence",Fact/Evidence
4565,434-ARR,434-ARR_v2_2@1,434-ARR_v1_2@2,Our crosslingual framework includes an offline unsupervised construction of a translated UMLS dictionary and a per-document pipeline which identifies UMLS candidate mentions and uses a finetuned pretrained transformer language model to filter candidates according to context.,Our crosslingual framework includes an offline unsupervised construction of a bilingual UMLS dictionary and a per-document pipeline which identifies UMLS candidate mentions and uses a finetuned pretrained transformer language model to filter candidates according to context.,"Modify,Clarity",Clarity
4566,434-ARR,434-ARR_v2_8@6,434-ARR_v1_8@6,We report our results on the same MedMentions dataset in Section 5.2.,We report our results on the same MedMentions dataset in 5.2.,"Modify,Clarity",Clarity
4567,434-ARR,434-ARR_v2_9@2,434-ARR_v1_9@2,"Liu et al. (2021) developed Sap-BERT, a pre-training scheme which exploits the graph structure of the UMLS controlled vocabulary and aims at learning an encoding of medical mentions that can align with synonym relations in the UMLS graph.","Liu et al. (2021) developed Sap-BERT, a pre-training scheme which exploits the graph structure of the UMLS ontology and aims at learning an encoding of medical mentions that can align with synonym relations in the UMLS graph.","Modify,Clarity",Clarity
4568,434-ARR,434-ARR_v2_9@4,434-ARR_v1_9@4,Experimental results demonstrated that SapBERT outperforms many domain-specific BERT-based variants (BioBERT and SciBERT) on the BC5CDR (BioCreative V CDR) corpus.,Experimental results demonstrated that SapBERT outperforms many domain-specific BERT-based variants (BioBERT and SciBERT) on the BC5CDR dataset.,"Modify,Fact/Evidence",Fact/Evidence
4569,434-ARR,434-ARR_v2_10@1,434-ARR_v1_10@1,"Mohan et al. (2021) developed a lowresource recognition and linking model of biomedical concepts (henceforth referred to as LRR) aimed at generalizing to entities unseen at training time, and incorporating linking predictions into the mention segmentation decisions.","Mohan et al. (2021) developed a lowresource recognition and linking model of biomedical concepts called LRR aimed at generalizing to entities unseen at training time, and incorporating linking predictions into the mention segmentation decisions.","Modify,Clarity",Clarity
4570,434-ARR,434-ARR_v2_10@3,434-ARR_v1_10@3,"In our work, we adopt the LRR bottom-up candidate generation approach (see Section 4.2).","In our work, we adopt the LRR bottom-up candidate generation approach (see 4.2).","Modify,Clarity",Clarity
4571,434-ARR,434-ARR_v2_10@5,434-ARR_v1_10@5,We elaborate on the motivation for the technique in Section 4.5 and demonstrate its contribution in ablation experiments (see Section 5.4).,We elaborate on the motivation for the technique in 4.5 and demonstrate its contribution in ablation experiments (see 5.4).,"Modify,Clarity",Clarity
4572,434-ARR,434-ARR_v2_12@2,434-ARR_v1_11@9,Our new components lead to significant performance improvement over MDTEL on the Camoni corpus (see Table 2).,Our new components lead to significant performance improvement over MDTEL on the Camoni corpus.,"Modify,Fact/Evidence",Fact/Evidence
4573,438-ARR,,438-ARR_v1_18@11,,"However, we are particularly motivated by how the decision boundary of each source label distinguishes the labels of the target task.","Delete,Claim",Claim
4574,438-ARR,,438-ARR_v1_4@6,,"For example, it could help improve the performance of clinical information extraction tasks.","Delete,Claim",Claim
4575,438-ARR,,438-ARR_v1_4@7,,"Also, it can serve as a building block for developing assistive technologies to automate or simplify clinical note-writing experience (Gopinath et al., 2020).","Delete,Fact/Evidence",Fact/Evidence
4576,438-ARR,,438-ARR_v1_71@0,,Conclusion and Future Work,"Delete,Other",Other
4577,438-ARR,438-ARR_v2_4@6,,"In some cases, section classification serves as an end task of automatic report segmentation.",,"Add,Claim",Claim
4578,438-ARR,438-ARR_v2_4@7,,"For example, according to an internal survey we conducted with Amazon Care providers, we found evidence that classifying sentences related to the History of Present Illness from medical encounters can greatly assist providers with their documentation.",,"Add,Fact/Evidence",Fact/Evidence
4579,438-ARR,438-ARR_v2_4@8,,"For computer-assisted report generation, understanding clinical notes from an unstructured format is an important data pre-processing (Gopinath et al., 2020).",,"Add,Fact/Evidence",Fact/Evidence
4580,438-ARR,438-ARR_v2_13@0,,"In this section, we briefly discuss several areas in machine learning that are related to our work.",,"Add,Fact/Evidence",Fact/Evidence
4581,438-ARR,438-ARR_v2_19@11,,"However, we apply the class subset selection to improve the knowledge transfer.",,"Add,Fact/Evidence",Fact/Evidence
4582,438-ARR,438-ARR_v2_19@12,,"Unlike previous work (Manjunatha et al., 2018), which does not use knowledge about the target task while finding the subset, our approach incorporates how the decision boundary of each source label distinguishes the labels of the target task.",,"Add,Fact/Evidence",Fact/Evidence
4583,438-ARR,438-ARR_v2_72@5,,We also perform the category selection with NCE to compare it with NNCE.,,"Add,Fact/Evidence",Fact/Evidence
4584,438-ARR,438-ARR_v2_72@6,,The underlined tasks in Table 4 indicate that different subsets of categories are selected if we replace NNCE with NCE.,,"Add,Fact/Evidence",Fact/Evidence
4585,438-ARR,438-ARR_v2_72@7,,"For all these tasks, NNCE achieves higher accuracies.",,"Add,Fact/Evidence",Fact/Evidence
4586,438-ARR,438-ARR_v2_72@8,,Please see Appendix C for detailed results for different target categories.,,"Add,Fact/Evidence",Fact/Evidence
4587,438-ARR,438-ARR_v2_77@2,,The multi-label sentences (1.4% of 38326 instances) are filtered out.,,"Add,Fact/Evidence",Fact/Evidence
4588,438-ARR,438-ARR_v2_79@0,,"Tables 7, 8, 9, and 10 show the category selection details for different target categories.",,"Add,Fact/Evidence",Fact/Evidence
4589,438-ARR,438-ARR_v2_79@1,,We compare the NCE and NNCE by their selected categories and the classification accuracy of Reptile.,,"Add,Fact/Evidence",Fact/Evidence
4590,438-ARR,438-ARR_v2_79@2,,"For all these tasks, we observe that NNCE achieves higher accuracies.",,"Add,Fact/Evidence",Fact/Evidence
4591,438-ARR,438-ARR_v2_79@3,,"However, the difference between the NCE and NNCE is not very evident, presumably because the number of the total source categories is small, making their subset of the selected categories similar.",,"Add,Claim",Claim
4592,438-ARR,438-ARR_v2_21@2,438-ARR_v1_20@2,"There are nearly 1,000 section labels of these categories, and most of them contain very few sentence instances.","There are near 1,000 section labels of these categories, and most of them contain very few sentence instances.","Modify,Grammar",Grammar
4593,438-ARR,438-ARR_v2_26@3,438-ARR_v1_25@3,"For sampling batches of tasks, we use the same strategy proposed in Dou et al. (2019) that the probability of selecting a task is proportional to the size of its dataset.","For sampling batches of tasks, we use the same strategy proposed in (Dou et al., 2019) that the probability of selecting a task is proportional to the size of its dataset.","Modify,Grammar",Grammar
4594,438-ARR,438-ARR_v2_4@3,438-ARR_v1_4@3,"However, many clinical notes contain narratives that are in an unstructured free-text format, (e.g., History of Present Illnesses described in paragraph form), which makes it challenging to retrieve and utilize this information.","However, many clinical notes contain narratives that are in an unstructured free-text format (e.g., History of Present Illnesses described in paragraph form), which makes it challenging to retrieve and utilize this information.","Modify,Grammar",Grammar
4595,438-ARR,438-ARR_v2_63@0,438-ARR_v1_62@0,We adopt the PyTorch (version 1.3.0) implementation of BERT 2 for our tasks and the model is initialized with BERT-base.,Our implementation is based on the PyTorch implementation of BERT 2 and the model is initialized with BERT-base.,"Modify,Fact/Evidence",Fact/Evidence
4596,438-ARR,438-ARR_v2_63@2,438-ARR_v1_62@2,"We threshold the word sequence length to 80, which covers more than 99% of the sentences.","We threshold the word sequence length to 80, which covers more than 99% of the sentences in each category.","Modify,Clarity",Clarity
4597,438-ARR,438-ARR_v2_63@5,438-ARR_v1_62@5,"We set the inner update step k to be 5, the inner learning rate to be 5e-5 and the number of sampled tasks in each step to be 8 for Reptile.",We set the inner update step k to be 5 and the inner learning rate to be 5e-5 for Reptile.,"Modify,Fact/Evidence",Fact/Evidence
4598,438-ARR,438-ARR_v2_5@1,438-ARR_v1_5@1,"First, it is difficult to collect and access a large amount of in-domain data.","First, it is difficult to collect and access a large amount of in-domain clinical note data.","Modify,Clarity",Clarity
4599,438-ARR,438-ARR_v2_5@3,438-ARR_v1_5@3,"Even though some sections exist in multiple different sources, their contents vary across clinical categories.","Even though some sections (e.g., Assessment, Diagnosis and Past Medical History) exist in multiple different clinical data sources, their contents vary across clinical categories.","Modify,Claim",Claim
4600,438-ARR,438-ARR_v2_6@5,438-ARR_v1_6@5,The target task with limited data benefits from the knowledge learned from source tasks.,The target task with limited amounts of training data benefits from the knowledge learned from many source tasks.,"Modify,Clarity",Clarity
4601,438-ARR,438-ARR_v2_6@6,438-ARR_v1_6@6,"Instead of MTL, which minimizes the loss of the source tasks, Dou et al. (2019) proposed a model-agnostic meta-learning algorithm that finds optimal model parameters for better adaptation capability to new tasks.","Instead of MTL, which minimizes the loss of the source tasks, Dou et al. (2019) proposed a modelagnostic meta-learning algorithm that finds optimal model parameters for better adaptation capability to new tasks.","Modify,Grammar",Grammar
4602,438-ARR,438-ARR_v2_6@7,438-ARR_v1_6@7,"In classification tasks, Nichol et al. (2018) proposed Reptile, an optimization-based meta-learning algorithm for section classification, and achieved comparable accuracy on well-established benchmarks on low resourced image datasets.","In classification tasks, (Nichol et al., 2018) proposed Reptile, an optimizationbased meta-learning algorithm for section classification, and achieved comparable accuracy on wellestablished benchmarks on low resourced image datasets.","Modify,Grammar",Grammar
4603,438-ARR,438-ARR_v2_9@0,438-ARR_v1_9@0,"Leveraging the NNCE, we explore strategies of source task selection to improve the performance of meta-learning.","Leveraging the NNCE score, we explore strategies of source task selection to improve the performance of meta-learning.","Modify,Clarity",Clarity
4604,438-ARR,438-ARR_v2_9@1,438-ARR_v1_9@1,The goal is to make the best use of available data from various clinical specialties for any target tasks.,The goal is to make the best use of available clinical note data from various clinical specialties for any target tasks.,"Modify,Clarity",Clarity
4605,438-ARR,438-ARR_v2_9@6,438-ARR_v1_9@6,The experiment results show that our task selection strategies improve the meta-transfer learning of section classification in low-resource scenarios.,The experiment results show that our task selection strategies improve the meta-transfer learning of clinical section classification in low-resource scenarios.,"Modify,Clarity",Clarity
4606,438-ARR,438-ARR_v2_15@5,438-ARR_v1_14@5,"In the study of Tran et al. (2015), the tasks were performed by an object-based section annotator using an ontology to describes the relationship among the section concepts.","In the study of (Tran et al., 2015), the tasks were performed by an object-based section annotator using an ontology to describes the relationship among the section concepts.","Modify,Grammar",Grammar
4607,440-ARR,,440-ARR_v1_59@1,,The loss function of our method is as follows:,"Delete,Fact/Evidence",Fact/Evidence
4608,440-ARR,440-ARR_v2_59@1,,We optimize the end-toend process with cross entropy loss and L 2 regularization.,,"Add,Fact/Evidence",Fact/Evidence
4609,440-ARR,440-ARR_v2_86@0,,Conclusion,,"Add,Other",Other
4610,440-ARR,440-ARR_v2_87@0,,"In this paper,we propose KCD, a political perspective detection approach that reasons with multi-hop external knowledge and leverages diversified implicit textual indicators.",,"Add,Fact/Evidence",Fact/Evidence
4611,440-ARR,440-ARR_v2_20@2,440-ARR_v1_20@2,"We encode each paragraph by averaging the the embeddings of words from pre-trained RoBERTa (Liu et al., 2019):","We encode each paragraph with pre-trained RoBERTa (Liu et al., 2019):","Modify,Fact/Evidence",Fact/Evidence
4612,440-ARR,440-ARR_v2_24@0,440-ARR_v1_24@0,"We firstly use TagMe (Ferragina and Scaiella, 2012) to identify mentioned KG entities in each paragraph s i .","We firstly use TagMe (Ferragina and Scaiella, 2011) to identify mentioned KG entities in each paragraph s i .","Modify,Fact/Evidence",Fact/Evidence
4613,440-ARR,440-ARR_v2_30@0,440-ARR_v1_31@0,"After obtaining multiple knowledge walks for a single news paragraph, we propose a selection and aggregation process guided by textual content to differentiate essential knowledge walks from the irrelevant ones.","After obtaining multiple knowledge walks for a single news paragraph, we propose a selection and aggregation process guided by text semantics to differentiate essential knowledge walks from the irrelevant ones.","Modify,Clarity",Clarity
4614,440-ARR,440-ARR_v2_38@0,440-ARR_v1_39@0,"After representing multi-hop knowledge reasoning for paragraph s i with v p i , we conduct documentwise multi-head self-attention to infuse knowledge walks into textual representations v s i .","After representing multi-hop knowledge reasoning for paragraph s i with v p i , we conduct documentwise multi-head self-attention to infuse knowledge walks into textaul representations v s i .","Modify,Grammar",Grammar
4615,440-ARR,440-ARR_v2_4@1,440-ARR_v1_4@1,Previous approaches generally leverage the textual content of news articles with various text modeling techniques to identify political stances.,Previous approaches generally leverage the textual content of news articles with various text modeling techniques to identify stances.,"Modify,Clarity",Clarity
4616,440-ARR,440-ARR_v2_52@2,440-ARR_v1_53@2,"We then adopt entity linking tool TagMe (Ferragina and Scaiella, 2012) to align news paragraphs with their mentioned entities and use R6 to connect V1 with V6 correspondingly.","We then adopt Tagme (Ferragina and Scaiella, 2011) to align news paragraphs with their mentioned entities and use R6 to connect V1 with V6 correspondingly.","Modify,Fact/Evidence",Fact/Evidence
4617,440-ARR,440-ARR_v2_67@0,440-ARR_v1_69@0,"We implement our KCD framework with pytorch (Paszke et al., 2019), pytorch lightning (Falcon and The PyTorch Lightning team, 2019), pytorch geometric (Fey and Lenssen, 2019), and the transformers library (Wolf et al., 2020).","We implement our KCD framework with pytorch (Paszke et al., 2019), pytorch lightning (Falcon and The PyTorch Lightning team, 2019), pytorch geometric (Fey and Lenssen, 2019) and the transformers library (Wolf et al., 2020).","Modify,Grammar",Grammar
4618,440-ARR,440-ARR_v2_67@4,440-ARR_v1_69@4,We make our code and data publicly available 3 .,We commit to make our code and data publicly available upon acceptance to facilitate reproduction.,"Modify,Fact/Evidence",Fact/Evidence
4619,440-ARR,440-ARR_v2_80@0,440-ARR_v1_82@0,Textual Cues Study,Textual Cue Study,"Modify,Grammar",Grammar
4620,440-ARR,440-ARR_v2_81@3,440-ARR_v1_85@1,"Besides, adding only part of textual cues sometimes leads to a decrease in performance, which implies that incomplete cues may be counterproductive and introduce noise.","Besides, adding only part of textual cues sometimes leads to a decrease in performance, which implies that incomplete cues may be counterproductive.","Modify,Claim",Claim
4621,440-ARR,440-ARR_v2_93@0,440-ARR_v1_95@0,We run our approach with three different aggregation strategies five times and report the average accuracy and macro F1-score with standard deviation in Table 4.,We run our approach with three different aggregation strategies five times and report the average accuracy and macro F1-score in Table 2.,"Modify,Fact/Evidence",Fact/Evidence
4622,440-ARR,440-ARR_v2_10@1,440-ARR_v1_10@1,"Early approaches leverage text analysis techniques for bias detection, such as sentiment analysis (Jiang et al., 2011;Wang et al., 2017), bias feature extraction (Horne et al., 2018), word embeddings (Jiang et al., 2019;Li and Goldwasser, 2019), and different neural network architectures (Augenstein et al., 2016;Du et al., 2017;Xu et al., 2018;Yang et al., 2016;Jiang et al., 2019;Feng et al., 2021b;Li and Goldwasser, 2021;Feng et al., 2021a).","Early approaches leverage text analysis techniques for bias detection, such as sentiment analysis (Jiang et al., 2011;Wang et al., 2017), bias feature extraction (Horne et al., 2018), word embeddings (Jiang et al., 2019;Li and Goldwasser, 2019) and different neural network architectures (Augenstein et al., 2016;Du et al., 2017;Xu et al., 2018;Yang et al., 2016;Jiang et al., 2019;Feng et al., 2021b;Li and Goldwasser, 2021;Feng et al., 2021a).","Modify,Grammar",Grammar
4623,440-ARR,440-ARR_v2_12@1,440-ARR_v1_12@1,"Generic (Fellbaum, 2010;Pellissier Tanon et al., 2020;Bollacker et al., 2008;Speer et al., 2017) and domain-specific KGs (Feng et al., 2021a;Chang et al., 2020) are widely adopted in NLP tasks as external knowledge sources.","Generic (Fellbaum, 2010;Tanon et al., 2020;Bollacker et al., 2008;Speer et al., 2017) and domain-specific KGs (Feng et al., 2021a;Chang et al., 2020) are widely adopted in NLP tasks as external knowledge sources.","Modify,Fact/Evidence",Fact/Evidence
4624,448-ARR,,448-ARR_v1_79@3,,"We report the pvalues for one-tailed paired t-tests with the alternative hypothesis ""the performance of our approach is better than the baseline approach"".","Delete,Fact/Evidence",Fact/Evidence
4625,448-ARR,,448-ARR_v1_79@4,,The results where LwR-RC performs statistically significantly better than the baselines (p-value of less than 0.05) are boldfaced.,"Delete,Fact/Evidence",Fact/Evidence
4626,448-ARR,,448-ARR_v1_82@0,,"In our study, we experimented with three humanannotated datasets, IMDb, ASRS, and AIvsCR.","Delete,Fact/Evidence",Fact/Evidence
4627,448-ARR,,448-ARR_v1_82@1,,We collected and annotated the AIvsCR dataset.,"Delete,Fact/Evidence",Fact/Evidence
4628,448-ARR,,448-ARR_v1_82@2,,"To construct this dataset, we first collected 6,000 articles equally from two categories, cs.AI and cs.CR, from arXiv.org using a custom search query in the arXiv API.","Delete,Fact/Evidence",Fact/Evidence
4629,448-ARR,,448-ARR_v1_82@3,,"We provide the code, including the custom search queries, that we used to collect the data from arXiv.org with the supplementary material.","Delete,Fact/Evidence",Fact/Evidence
4630,448-ARR,,448-ARR_v1_84@1,,"The table presents the number of rationales and the number of rationale words per document provided by the two annotators, as well as the inter-annotator agreement for their rationale annotation.","Delete,Fact/Evidence",Fact/Evidence
4631,448-ARR,,448-ARR_v1_85@0,,"We calculated the inter-annotator agreement for the rationales, where the rationales provided by the two annotators for the same document are considered as overlapping if they have at least one word in common, following the same manner of Zaidan et al. (2007).","Delete,Fact/Evidence",Fact/Evidence
4632,448-ARR,,448-ARR_v1_85@1,,The relevant statistics are shown in Table 5.,"Delete,Fact/Evidence",Fact/Evidence
4633,448-ARR,448-ARR_v2_6@1,,I actually think it is much worse than any of the other terrible Disney channel sit-coms right now.,,"Add,Claim",Claim
4634,448-ARR,448-ARR_v2_7@0,,I love this movie and have seen it quite a few times over the years.,,"Add,Claim",Claim
4635,448-ARR,448-ARR_v2_7@1,,It does get better with every viewing.,,"Add,Claim",Claim
4636,448-ARR,448-ARR_v2_7@2,,I agree with all of the positive reviews here.,,"Add,Claim",Claim
4637,448-ARR,448-ARR_v2_58@1,,We used a TensorFlow implementation of BERT 2 .,,"Add,Fact/Evidence",Fact/Evidence
4638,448-ARR,448-ARR_v2_65@0,,Figure 3 presents learning curves comparing the average accuracy of the methods over five different runs with up to 210 documents for improved readability.,,"Add,Fact/Evidence",Fact/Evidence
4639,448-ARR,448-ARR_v2_65@1,,The learning curves with a larger budget of up to 310 documents are included in the appendix.,,"Add,Fact/Evidence",Fact/Evidence
4640,448-ARR,448-ARR_v2_66@0,,3 The complete t-test results are presented in the appendix.,,"Add,Fact/Evidence",Fact/Evidence
4641,448-ARR,448-ARR_v2_48@1,448-ARR_v1_41@1,"It can also work with several representations, including one-hot encoding of the words, word2vec (Mikolov et al., 2013), and doc2vec (Le and Mikolov, 2014), as well as more recent language models such as BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019), and XLNet (Yang et al., 2019).","It can also work with several representations, including one-hot encoding of the words, word2vec (Mikolov et al., 2013), and doc2vec (Le and Mikolov, 2014), as well as more recent language models such as BERT (Devlin et al., 2018), RoBERTa (Liu et al., 2019), and XLNet (Yang et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
4642,448-ARR,448-ARR_v2_9@0,448-ARR_v1_6@0,"An effective approach to make the best use of the human's time and maximize classifier performance with a small labeled dataset is to elicit rich feedback, in the form of rationales for classification, during the labeling process (Zaidan et al., 2007; Donahue and Grauman, 2011;Sharma and Bilgic, 2018).","An effective approach to make the best use of the human's time and maximize classifier performance with a small labeled dataset is to elicit rich feedback, in the form of rationales for classification, during the labeling process (Zaidan et al., 2007Donahue and Grauman, 2011;Sharma and Bilgic, 2018).","Modify,Grammar",Grammar
4643,448-ARR,448-ARR_v2_58@0,448-ARR_v1_50@0,"For training LwR-RC, we fine-tuned a pre-trained 'bert-base-uncased' version of the BERT (Devlin et al., 2019) model on downstream classification task using our ranking-constrained loss function.","For training LwR-RC, we fine-tuned a pre-trained 'bert-base-uncased' version of the BERT (Devlin et al., 2018) model on downstream classification task using our ranking-constrained loss function.","Modify,Fact/Evidence",Fact/Evidence
4644,448-ARR,448-ARR_v2_60@2,448-ARR_v1_52@2,"The Lw/oR-BERT baseline fine-tunes the BERT model for downstream classification tasks, and optimizes the model by only minimizing the classification loss function, L clf , without utilizing any ranking constraints, L DvM or L RvM , according to Equation (1).","The Lw/oR-BERT baseline fine-tunes the BERT model for downstream classification tasks, and optimizes the model by only minimizing the classification loss function, L clf , according to Equation (1).","Modify,Fact/Evidence",Fact/Evidence
4645,448-ARR,448-ARR_v2_9@1,448-ARR_v1_6@1,"For sentiment classification, for example, the annotators might highlight certain segments of the text that convinced them to label the review as positive or negative (Figure 1).","For sentiment classification, for example, the annotators might highlight certain segments of the text that convinced them to label the review as positive.","Modify,Fact/Evidence",Fact/Evidence
4646,448-ARR,448-ARR_v2_65@5,448-ARR_v1_56@3,"Still, a finetuned BERT model that does not use rationales is able to outperform these two strong baselines that used rationales but did not utilize the BERT embeddings.","Still, a finetuned BERT model that does not use rationales is able to outperform two strong baselines that used rationales but did not utilize the BERT embeddings.","Modify,Clarity",Clarity
4647,448-ARR,448-ARR_v2_13@0,448-ARR_v1_10@0,"As deep learning achieved the state-of-the-art performance on text classification (e.g., (Sun et al., 2019;Devlin et al., 2019;Zhang et al., 2015;Yang et al., 2016)), recent work proposed methods specifically for training deep learning models using rationale supervision.","As deep learning achieved the state-of-the-art performance on text classification (e.g., (Sun et al., 2019;Devlin et al., 2018;Zhang et al., 2015;Yang et al., 2016)), recent work proposed methods specifically for training deep learning models using rationale supervision.","Modify,Fact/Evidence",Fact/Evidence
4648,448-ARR,448-ARR_v2_13@4,448-ARR_v1_10@4,Errica et al. (2021) proposed a representation learning approach to leverage rationales by learning to focus on relevant input tokens in the embedding space.,Errica et al. (2020) proposed a representation learning approach to leverage rationales by learning to focus on relevant input tokens in the embedding space.,"Modify,Fact/Evidence",Fact/Evidence
4649,453-ARR,,453-ARR_v1_55@7,,"For example, if the target sentiment is positive and the target topic is an album, the prepended guiding sentence is ""This is a positive review on an album:"".","Delete,Fact/Evidence",Fact/Evidence
4650,453-ARR,,453-ARR_v1_58@3,,We intend to make our implementation freely available online to facilitate future research and downstream applications.,"Delete,Claim",Claim
4651,453-ARR,453-ARR_v2_25@1,,We use a pretrained GPT-2 model followed by a linear layer as the encoder.,,"Add,Fact/Evidence",Fact/Evidence
4652,453-ARR,,453-ARR_v1_11@3,,"Controlling these attributes of text generation has manifold applications, such as knowledge-grounded conversation (Dinan et al., 2019) and poetry generation (Ghazvininejad et al., 2017).","Delete,Fact/Evidence",Fact/Evidence
4653,453-ARR,453-ARR_v2_56@2,,"However, such datasets are usually not readily available since most of the datasets are labeled for a single task.",,"Add,Claim",Claim
4654,453-ARR,453-ARR_v2_64@0,,Ethical Considerations,,"Add,Other",Other
4655,453-ARR,453-ARR_v2_65@0,,"With our controlling methods, it is not one hundred percent guaranteed that the generations will have the desired attributes, but the probability for the generations to exhibit the desired attributes will increase.",,"Add,Claim",Claim
4656,453-ARR,453-ARR_v2_65@1,,"When applied to detoxification, although the probability of toxicity degeneration will decrease, the controlled language model may still produce unsafe text.",,"Add,Claim",Claim
4657,453-ARR,453-ARR_v2_65@2,,We would like to clarify that the offensive language generated by the language model controlled with our methods does not represent any opinion of the authors.,,"Add,Claim",Claim
4658,453-ARR,453-ARR_v2_66@0,,"Besides, our proposed methods control the highlevel attributes of the generation, such as toxicity, topic, or sentiment, but there is no guarantee of factual accuracy for the generation, which is a wellknown problem in NLG models.",,"Add,Claim",Claim
4659,453-ARR,453-ARR_v2_66@1,,Our controlling methods may not be used for factual accuracy controlling.,,"Add,Claim",Claim
4660,453-ARR,453-ARR_v2_66@2,,"While reducing hallucination is not the focus of this work, knowledge-grounded generation techniques can be used to alleviate this problem.",,"Add,Claim",Claim
4661,453-ARR,453-ARR_v2_23@3,453-ARR_v1_23@3,"In other words, the index of the prefix corresponding to x is a latent variable z, whose posterior distribution follows a categorical distribution.","Inspired by VQ-VAE (van den Oord et al., 2017), we consider the index of the prefix as a latent variable z.","Split+Modify,Fact/Evidence",Fact/Evidence
4662,453-ARR,453-ARR_v2_23@4,453-ARR_v1_23@3,"Inspired by VQ-VAE (van den Oord et al., 2017), we consider the prefixes as discrete latent representations.","Inspired by VQ-VAE (van den Oord et al., 2017), we consider the index of the prefix as a latent variable z.","Split+Modify,Fact/Evidence",Fact/Evidence
4663,453-ARR,453-ARR_v2_23@6,453-ARR_v1_23@5,"According to q(z|x), a prefix index z is selected and the prefix H θ [z, :, :] is then fed into the decoder to reconstruct the input text x.","According to q(z|x), a prefix index z is sampled and the prefix H θ [z, :, :] is then fed into the decoder to reconstruct the input text x.","Modify,Clarity",Clarity
4664,453-ARR,453-ARR_v2_23@7,453-ARR_v1_23@6,"Since the selection process of the prefixes is non-differentiable, we use Gumbel-Softmax (GS) relaxation (Jang et al., 2017;Maddison et al., 2017) following Sønderby et al. (2017); Ramesh et al. (2021).","Since the sampling process of the prefixes is non-differentiable, we use Gumbel-Softmax (GS) relaxation (Jang et al., 2017;Maddison et al., 2017) following Sønderby et al. ( 2017); Ramesh et al. (2021).","Modify,Clarity",Clarity
4665,453-ARR,453-ARR_v2_30@4,453-ARR_v1_27@4,Optimizing these two loss terms improves the evidence lower bound of log p(x).,Optimizing these two loss terms improves the Evidence Lower BOund (ELBO) of log p(x).,"Modify,Grammar",Grammar
4666,453-ARR,453-ARR_v2_30@6,453-ARR_v1_27@6,"Instead, we introduce an unsupervised contrastive loss L c .","Instead, we introduce an unsupervised contrastive loss L c during training.","Modify,Clarity",Clarity
4667,453-ARR,453-ARR_v2_38@2,453-ARR_v1_34@2,We focus on English text in all the experiments and we experiment with GPT2-medium (345M parameters) for all the methods.,We experiment with GPT2-medium (345M parameters) for all the methods.,"Modify,Fact/Evidence",Fact/Evidence
4668,453-ARR,453-ARR_v2_56@5,453-ARR_v1_52@3,This method is denoted as Ours (concatenation) in the result table.,This is denoted as Ours (concatenation) in the result table.,"Modify,Clarity",Clarity
4669,453-ARR,453-ARR_v2_14@0,453-ARR_v1_14@0,"Our method uses prefixes to guide GPT2 generation, where a prefix is a continuous attributespecific vector prepended to the activations of GPT2.","Our method uses prefixes to guide GPT2 generation, where a prefix is a continuous attributespecific vector prepended to the activations of the GPT2 model.","Modify,Clarity",Clarity
4670,453-ARR,453-ARR_v2_14@3,453-ARR_v1_14@3,"In single-aspect control, N equals the number of attributes in the concerned aspect.","In single-aspect control, N equals the number of attributes in the concerned aspect while in multiaspect control, N equals the product of the number of attributes in each aspect.","Modify,Fact/Evidence",Fact/Evidence
4672,453-ARR,453-ARR_v2_14@5,453-ARR_v1_14@4,"D = 2 × L × E is the dimension of the activation in GPT2, where L is the number of transformer layers, E is the hidden size, and 2 indicates one key vector and one value vector.","M is the length of a prefix, and D is the dimension of the activation in GPT2.","Split+Modify,Fact/Evidence",Fact/Evidence
4673,454-ARR,,454-ARR_v1_51@0,,3 All code used for experiments in this paper can be found at https://anonymous.4open.science/r/ AbductionRules-D89D. be prohibitively expensive.,"Delete,Fact/Evidence",Fact/Evidence
4674,454-ARR,454-ARR_v2_10@2,,"Note that only deduction is fully reliable, induction may go in either direction in this case, and only abduction produces new knowledge.",,"Add,Claim",Claim
4675,454-ARR,454-ARR_v2_51@0,,"Finally, we use the existing pretrained T5 model with no additional training as our baseline model.",,"Add,Fact/Evidence",Fact/Evidence
4676,454-ARR,454-ARR_v2_62@0,,"The untrained T5 model performs abysmally and merits little discussion, indicating that this abduction task is non-trivial (at least in the way we present it here).",,"Add,Claim",Claim
4677,454-ARR,454-ARR_v2_48@0,454-ARR_v1_50@0,"If our approach were adapted to models extensively trained to reason on many domains, we expect that teaching abduction in every domain would be prohibitively expensive.","If our approach were adapted to models extensively trained to reason on many domains, we expect that teaching abduction in every domain would cussing the AbductionRules datasets within this paper.","Modify,Claim",Claim
4678,454-ARR,454-ARR_v2_48@2,454-ARR_v1_51@2,"To this end, we train two more multi-domain models.","To this end, we train two more cross-domain models.","Modify,Clarity",Clarity
4679,454-ARR,454-ARR_v2_50@0,454-ARR_v1_53@0,"While we are interested in these multi-domain models' performance on all datasets, we are particularly interested in their results on the most complex dataset on which they were not trained (Abduction-Animal and Abduction-Person, respectively).","While we are interested in these cross-domain models' performance on all datasets, we are particularly interested in their results on the most complex dataset on which they were not trained (Abduction-Animal and Abduction-Person, respectively).","Modify,Clarity",Clarity
4680,454-ARR,454-ARR_v2_53@1,454-ARR_v1_55@1,4 Note that no model ever gave a correct answer in a domain on which it was not trained.,4 Note that no model ever gave a correct explanation outside the domain(s) in which it was trained.,"Modify,Clarity",Clarity
4681,454-ARR,454-ARR_v2_59@6,454-ARR_v1_63@4,"The multi-domain models again saw no visible improvement, further suggesting that these inferior results were avoidable from seeing facts, rules, and explanations in different formats at training time.","The cross-domain models again saw no visible improvement, further suggesting that these inferior results were avoidable from seeing facts, rules, and explanations in different formats at training time.","Modify,Clarity",Clarity
4682,454-ARR,454-ARR_v2_61@1,454-ARR_v1_65@1,"Meanwhile, those trained on combined multi-domain datasets achieve performance superior to the sum of models trained on their parts and easily apply skills outside domains in which they were learned.","Meanwhile, those trained on combined cross-domain datasets achieve performance superior to the sum of models trained on their parts and easily apply skills outside domains in which they were learned.","Modify,Clarity",Clarity
4683,454-ARR,454-ARR_v2_71@0,454-ARR_v1_77@0,Multi-domain models,Cross-domain models,"Modify,Clarity",Clarity
4684,454-ARR,454-ARR_v2_72@0,454-ARR_v1_78@0,"Our multi-domain models are our best-performing models by far, achieving superior performance on unseen datasets than the sum of models trained on their combined training sets' parts.","Our cross-domain models are our best-performing models by far, achieving superior performance on unseen datasets than the sum of models trained on their combined training sets' parts.","Modify,Clarity",Clarity
4685,454-ARR,454-ARR_v2_73@0,454-ARR_v1_79@0,"The Person+Animal-0.1 model, being trained on our simplest dataset and having its most complex training set come from the worse of our two training domains, is the worse of our two multi-domain models.","The Person+Animal-0.1 model, being trained on our simplest dataset and having its most complex training set come from the worse of our two training domains, is the worse of our two cross-domain models.","Modify,Clarity",Clarity
4686,454-ARR,454-ARR_v2_75@0,454-ARR_v1_81@0,"Extrapolating these multi-domain results, it seems likely that finetuning Transformers that have received extensive pretraining (such as GPT-3 (Brown et al., 2020)) on datasets covering more varied and complex examples of abduction would make these models capable of much more generalised natural-language abductive reasoning.","Extrapolating these cross-domain results, it seems likely that finetuning Transformers that have received extensive pretraining (such as GPT-3 (Brown et al., 2020)) on datasets covering more varied and complex examples of abduction would make these models capable of much more generalised natural-language abductive reasoning.","Modify,Clarity",Clarity
4687,454-ARR,454-ARR_v2_77@1,454-ARR_v1_83@1,Our more complex datasets train abduction more generally and reliably than our less complex datasets.,Our more complex datasets train abduction more generally reliably than our less complex datasets.,"Modify,Grammar",Grammar
4688,454-ARR,454-ARR_v2_8@0,454-ARR_v1_8@0,Our goal is to train Transformers to perform abductive reasoning with the following properties:,Our goal is to use the natural-language logic approach to train Transformers to perform abductive reasoning with the following properties:,"Modify,Fact/Evidence",Fact/Evidence
4689,454-ARR,454-ARR_v2_3@0,454-ARR_v1_3@0,"We present AbductionRules, a group of natural language datasets designed to train and test generalisable abduction over natural-language knowledge bases.","This paper presents AbductionRules, a group of natural language datasets designed to train and test generalisable abduction over naturallanguage knowledge bases.","Modify,Clarity",Clarity
4690,461-ARR,,461-ARR_v1_41@0,,Experiments in Supplements,"Delete,Other",Other
4691,461-ARR,,461-ARR_v1_42@0,,"We analyze the influence of two hyperparameters (i.e., M and P ) on the model performance in supplements.","Delete,Fact/Evidence",Fact/Evidence
4692,461-ARR,,461-ARR_v1_42@1,,The results show that it is appropriate to set the number of basis user embeddings M to 20 and the number of basis user embeddings P for composing user embedding for recall to 5.,"Delete,Fact/Evidence",Fact/Evidence
4693,461-ARR,,461-ARR_v1_45@0,,Our experiments are conducted on a work station with the Ubuntu 16.04 operation system.,"Delete,Fact/Evidence",Fact/Evidence
4694,461-ARR,,461-ARR_v1_45@1,,The Python language version is 3.7.,"Delete,Fact/Evidence",Fact/Evidence
4695,461-ARR,,461-ARR_v1_45@2,,The server has 7 Nvidia 1080ti GPUs and each of them has a memory of 11GB.,"Delete,Fact/Evidence",Fact/Evidence
4696,461-ARR,,461-ARR_v1_45@3,,The system running memory is 64GB.,"Delete,Fact/Evidence",Fact/Evidence
4697,461-ARR,,461-ARR_v1_45@4,,We use the Keras 2.2.4 library to implement our experiments.,"Delete,Fact/Evidence",Fact/Evidence
4698,461-ARR,,461-ARR_v1_45@5,,We use a single GPU to run each experiment.,"Delete,Fact/Evidence",Fact/Evidence
4699,461-ARR,,461-ARR_v1_46@0,,The values of hyperparameters used in our approach are listed in Table 4.,"Delete,Fact/Evidence",Fact/Evidence
4700,461-ARR,461-ARR_v2_30@5,,The batch size is 32.,,"Add,Fact/Evidence",Fact/Evidence
4701,461-ARR,461-ARR_v2_38@0,,Hyperparameter Analysis,,"Add,Other",Other
4702,461-ARR,,461-ARR_v1_7@0,,We introduce our UniRec approach in this section.,"Delete,Fact/Evidence",Fact/Evidence
4703,461-ARR,461-ARR_v2_20@1,461-ARR_v1_24@1,"Thus, motivated by Principal Component Analysis (PCA), in the test phase we propose to only use the top P basis user embeddings with the highest attention weights to compose the user embedding for recall.","Thus, motivated by Principal Component Analysis (PCA), in the test phase we propose to only use top P basis user embeddings with the highest attention weights to compose the user embedding for recall.","Modify,Grammar",Grammar
4704,461-ARR,461-ARR_v2_27@4,461-ARR_v1_31@3,"Thus, the total computational complexity can be effectively reduced.","Thus, the total computational complexity of recall and ranking can be effectively reduced.","Modify,Clarity",Clarity
4705,461-ARR,461-ARR_v2_30@0,461-ARR_v1_34@0,"We conduct experiments on a large-scale public dataset named MIND (Wu et al., 2020b) In our experiments, following (Wu et al., 2020b) we use news titles to learn news embeddings.","We conduct experiments on a large-scale public dataset named MIND (Wu et al., 2020) In our experiments, following (Wu et al., 2020) we use news titles to learn news embeddings.","Modify,Fact/Evidence",Fact/Evidence
4706,461-ARR,461-ARR_v2_30@1,461-ARR_v1_34@1,"The number of basis user embeddings is 20, and they are randomly initialized.",The number of basis user embedding is 20.,"Modify,Fact/Evidence",Fact/Evidence
4707,461-ARR,461-ARR_v2_30@7,461-ARR_v1_34@6,"Following (Wu et al., 2020b), we use AUC, MRR, nDCG@5 and nDCG@10 to evaluate news ranking performance.","Following (Wu et al., 2020), we use AUC, MRR, nDCG@5 and nDCG@10 to evaluate news ranking performance.","Modify,Fact/Evidence",Fact/Evidence
4708,461-ARR,461-ARR_v2_4@0,461-ARR_v1_4@0,"News recommendation techniques are widely used by many online news websites and Apps to provide personalized news services (Wu et al., 2020b).","News recommendation techniques are widely used by many online news websites and Apps to provide personalized news services (Okura et al., 2017;Wu et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
4709,461-ARR,461-ARR_v2_35@1,461-ARR_v1_38@1,We show the recall performance of different methods in Table 3.,"We show the recall performance of different methods in Table 3, from which we have several findings.","Modify,Clarity",Clarity
4710,461-ARR,461-ARR_v2_35@2,461-ARR_v1_38@2,We find YoutubeNet is less performant than other recall methods.,"First, compared with YoutubeNet, other recall methods such as Pinnersage and UniRec usually perform better.","Modify,Clarity",Clarity
4711,461-ARR,461-ARR_v2_35@4,461-ARR_v1_38@4,"In addition, both UniRec(top) and UniRec(all) outperform other baseline methods.","Second, both UniRec and UniRec(all) outperform other baseline methods.","Modify,Clarity",Clarity
4712,461-ARR,461-ARR_v2_35@7,461-ARR_v1_38@7,"Besides, UniRec(top) outperforms its variant UniRec(all).","Third, UniRec outperforms its variant UniRec(all).","Modify,Clarity",Clarity
4713,461-ARR,461-ARR_v2_35@9,461-ARR_v1_38@9,The above results validate the effectiveness of our method in both news ranking and recall.,The above results validate the effectiveness of UniRec in both news ranking and recall.,"Modify,Clarity",Clarity
4714,461-ARR,461-ARR_v2_4@1,461-ARR_v1_4@1,"Recall and ranking are two critical steps in personalized news recommender systems (Karimi et al., 2018;Wu et al., 2021a).","Recall and ranking are two critical steps in personalized news recommender systems (Karimi et al., 2018).","Modify,Fact/Evidence",Fact/Evidence
4715,461-ARR,461-ARR_v2_37@3,461-ARR_v1_40@3,"We find the recall result of UniRec covers user interest categories of clicked news, but also keeps some diversity with them.",We find the recall result of UniRec effectively cover all interests of this user.,"Modify,Claim",Claim
4716,461-ARR,461-ARR_v2_37@4,461-ARR_v1_40@4,It shows that UniRec can generate accurate and diverse personalized news recall results.,It shows that UniRec can effectively model user interests for personalized news recall.,"Modify,Clarity",Clarity
4717,461-ARR,461-ARR_v2_4@2,461-ARR_v1_4@2,"As shown in Fig. 1, when a user visits a news platform, the recommender system first recalls a set of candidate news from a large-scale news pool, and then ranks candidate news for personalized news display (Wu et al., 2020b).","As shown in Fig. 1, when a user visits a news platform, the recommender system first recalls a set of candidate news from a large-scale news pool, and then ranks candidate news for personalized news display (Wu et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
4718,461-ARR,461-ARR_v2_39@0,461-ARR_v1_47@0,"Finally, we study the influence of two important hyperparameters in our UniRec method, including the total number M of basis user embeddings and the number P of basis user embeddings for composing the user embeddings for recall.","In this section, we study the influence of two important hyperparameters in our UniRec method, including the total number M of basis user embeddings and the number P of basis user embeddings for composing the user embeddings for recall.","Modify,Clarity",Clarity
4719,461-ARR,461-ARR_v2_4@3,461-ARR_v1_4@3,"Both news recall and ranking have been widely studied (Elkahky et al., 2015;Liu et al., 2019Wu et al., 2020a;Wang et al., 2020;Qi et al., 2021a,b,c,d).","Both news recall and ranking have been widely studied (Elkahky et al., 2015;Liu et al., , 2020bOkura et al., 2017;Wang et al., 2018;Wu et al., 2019a,b;Liu et al., 2020a;Wang et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
4720,461-ARR,461-ARR_v2_4@5,461-ARR_v1_4@5,"However, maintaining separate models for news recall and ranking in large-scale news recommender systems usually leads to heavy computation and memory cost (Tan et al., 2020), and it may be difficult to meet the latency requirement of online news services.","However, maintaining separate models for news recall and ranking in large-scale news recommender systems usually leads to heavy computation and memory cost, and it may be difficult to meet the latency requirement of online news services.","Modify,Fact/Evidence",Fact/Evidence
4721,461-ARR,461-ARR_v2_4@7,461-ARR_v1_4@7,"However, it is a non-trivial task because the goals of recall and ranking are not the same (Covington et al., 2016;Malkov and Yashunin, 2018).","However, it is a non-trivial task because the goals of recall and ranking are not the same (Covington et al., 2016;Malkov and Yashunin, 2018;Zhou et al., 2019a,b).","Modify,Fact/Evidence",Fact/Evidence
4722,461-ARR,461-ARR_v2_4@8,461-ARR_v1_4@8,"Ranking usually aims to accurately rank candidates based on their relevance to user interests (Wu et al., 2019b;Ge et al., 2020;Wang et al., 2020), while recall mainly aims to form a candidate pool that can comprehensively cover user interests Qi et al., 2021d).","Ranking usually aims to accurately rank candidates based on their relevance to user interests (Wu et al., 2019b), while recall mainly aims to form a candidate pool that can comprehensively cover user interests (Liu et al., 2020b).","Modify,Fact/Evidence",Fact/Evidence
4723,461-ARR,461-ARR_v2_7@0,461-ARR_v1_7@1,The overall framework of UniRec is shown in Fig. 2.,Its overall framework is shown in Fig. 2.,"Modify,Clarity",Clarity
4724,461-ARR,461-ARR_v2_7@3,461-ARR_v1_7@4,Their details are introduced as follows.,The ranking and recall details of UniRec are introduced as follows.,"Modify,Clarity",Clarity
4725,461-ARR,461-ARR_v2_9@1,461-ARR_v1_9@1,"Following (Wu et al., 2020b), UniRec uses a news encoder that learns news embeddings from news texts and a user encoder that learns user interest embedding for ranking from the embeddings of clicked news.","Following (Wu et al., 2020), UniRec uses a news encoder that learns news embeddings from news texts and a user encoder that learns user interest embedding for ranking from the embeddings of clicked news.","Modify,Fact/Evidence",Fact/Evidence
4726,461-ARR,461-ARR_v2_13@1,461-ARR_v1_17@1,"Different from additive attention (Yang et al., 2016) where the attention keys and values are equivalent, in our approach the keys (i.e., w i ) are different from the values (i.e., v i ).","Different from many attention networks whose attention keys and values are equivalent, in our approach the keys (i.e., parameters w i ) are different from the values (i.e., basis user embeddings v i ).","Modify,Fact/Evidence",Fact/Evidence
4727,461-ARR,461-ARR_v2_13@2,461-ARR_v1_17@2,This is because we expect the basis user embeddings to have different spaces with the user embeddings for ranking to better adapt to the recall task.,This is because we expect the basis user embeddings to have different spaces with the user embeddings for ranking to better adapt to the characteristics of the recall task.,"Modify,Clarity",Clarity
4728,461-ARR,461-ARR_v2_13@3,461-ARR_v1_17@3,The basis user embeddings are further synthesized into a unified user embedding u re for recall by u re = M i=1 α i v i .,The set of basis user embeddings are further synthesized into a unified user embedding u re for recall by u re = M i=1 α i v i .,"Modify,Clarity",Clarity
4837,47-ARR,47-ARR_v2_25@7,,"P l (and P u in Alg.2 as well) is sorted in order of size for confidence comparison between two different sample sets, D l and D u , in the main stage; we denoted it as P l ( P u for P u ).",,"Add,Fact/Evidence",Fact/Evidence
4838,47-ARR,47-ARR_v2_62@3,,The EBcriterion shows the statistically similar accuracy to the BUS-stop method in most datasets.,,"Add,Fact/Evidence",Fact/Evidence
4839,47-ARR,47-ARR_v2_64@2,,The macro F1-score is also reported.,,"Add,Fact/Evidence",Fact/Evidence
4840,47-ARR,47-ARR_v2_64@6,,It is observed that ratios marked with ' ' are fewer in the imbalanced setting.,,"Add,Fact/Evidence",Fact/Evidence
4841,47-ARR,47-ARR_v2_69@1,,"For example, the BUS-stop and PE-stop-epoch require a separate preliminary stage that consumes additional time.",,"Add,Fact/Evidence",Fact/Evidence
4842,47-ARR,47-ARR_v2_69@2,,We add up both the times taken in the preliminary stage and main stage.,,"Add,Fact/Evidence",Fact/Evidence
4843,47-ARR,47-ARR_v2_69@3,,We denote the average running time per epoch as g(n l ) for training the labeled samples and p(n u ) for predicting the unlabeled samples.,,"Add,Fact/Evidence",Fact/Evidence
4844,47-ARR,47-ARR_v2_69@4,,"The time complexity and the measured time are shown in the number of retrainings in the preliminary stage, which was set to five.",,"Add,Fact/Evidence",Fact/Evidence
4845,47-ARR,47-ARR_v2_69@5,,The experimental settings are the same as in Section 5.1.,,"Add,Fact/Evidence",Fact/Evidence
4846,47-ARR,47-ARR_v2_69@6,,"The time measurement was conducted on a PC with an Intel Core i7 CPU, 64-GB RAM and an NVIDIA Titan X Pascal GPU.",,"Add,Fact/Evidence",Fact/Evidence
4847,47-ARR,47-ARR_v2_70@0,,"As shown in the expression of time complexity, the running time depends on the numbers of labeled and unlabeled samples, n l and n u , respectively.",,"Add,Fact/Evidence",Fact/Evidence
4848,47-ARR,47-ARR_v2_70@1,,"In DBpedia, which has a large number of unlabeled samples, n u , the LID and BUS-stop methods take the two longest running times.",,"Add,Fact/Evidence",Fact/Evidence
4849,47-ARR,47-ARR_v2_70@2,,"On the other hand, in SST-2, the PE-stop-epoch and BUS-stop methods show the two longest running times, because the n u is relatively small such that the g(n l ) is more dominant than the p(n u ).",,"Add,Fact/Evidence",Fact/Evidence
4850,47-ARR,47-ARR_v2_70@3,,The BUS-stop requires a longer running time than other methods due to the T -times retraining and the continual prediction on the unlabeled set.,,"Add,Fact/Evidence",Fact/Evidence
4851,47-ARR,47-ARR_v2_70@4,,"To reduce the time, we can adjust the T value or sample a smaller amount of data from the unlabeled set.",,"Add,Claim",Claim
4852,47-ARR,47-ARR_v2_71@1,,Regression tasks as well can be addressed by converting into classification problems.,,"Add,Claim",Claim
4853,47-ARR,47-ARR_v2_71@2,,The continuous values normalized between 0-1 can be represented as confidences in a binary classification.,,"Add,Claim",Claim
4854,47-ARR,47-ARR_v2_71@3,,"However, it may be difficult to apply to other more complex tasks (e.g., text summarization).",,"Add,Claim",Claim
4855,47-ARR,47-ARR_v2_71@4,,This study is limited to classification tasks.,,"Add,Fact/Evidence",Fact/Evidence
4856,47-ARR,47-ARR_v2_71@5,,"Another limitation is that the BUS-stop, which is a nonvalidation stop-method, cannot make direct comparisons between two models with different runs.",,"Add,Claim",Claim
4857,47-ARR,47-ARR_v2_71@6,,Early stopping can be seen as selecting the best resulting model over the epochs.,,"Add,Claim",Claim
4858,47-ARR,47-ARR_v2_71@7,,"In a similar way, it is also possible to select the best model among multiple runs.",,"Add,Claim",Claim
4859,47-ARR,47-ARR_v2_71@8,,We refer to the former as local selection and the latter as global selection.,,"Add,Fact/Evidence",Fact/Evidence
4860,47-ARR,47-ARR_v2_71@9,,"In validationbased stopping, the global selection is simply to select the model with the lowest validation loss over multiple runs.",,"Add,Claim",Claim
4861,47-ARR,47-ARR_v2_71@10,,"However, the non-validation methods have no clear criterion for this purpose.",,"Add,Claim",Claim
4862,47-ARR,47-ARR_v2_71@11,,We repeated training five runs for each and selected the best model among the runs based on validation loss.,,"Add,Fact/Evidence",Fact/Evidence
4863,47-ARR,47-ARR_v2_71@12,,Other experimental settings are the same as in Section 5.,,"Add,Fact/Evidence",Fact/Evidence
4864,47-ARR,47-ARR_v2_71@13,,"As shown in Table 8, the global selection in validation-based stopping improves performance across the datasets in both balanced and imbalanced settings.",,"Add,Fact/Evidence",Fact/Evidence
4865,47-ARR,47-ARR_v2_71@14,,"However, in the imbalanced setting, the BUS-stop still results in better performance.",,"Add,Fact/Evidence",Fact/Evidence
4866,47-ARR,47-ARR_v2_71@15,,Note that Val-stop add(25) uses additional labeled samples.,,"Add,Fact/Evidence",Fact/Evidence
4867,47-ARR,47-ARR_v2_71@16,,"We also report that the global selections that are based on the S conf , S class , and LID did not show significant performance improvement in our experiment.",,"Add,Fact/Evidence",Fact/Evidence
4868,47-ARR,47-ARR_v2_71@17,,The development of non-validation global selection methods is left for future work.,,"Add,Claim",Claim
4869,47-ARR,47-ARR_v2_73@8,,We can also combine BUS-stop and self-training methods.,,"Add,Claim",Claim
4870,47-ARR,47-ARR_v2_73@9,,"BUS-stop can be used to improve the performance of the initial model, which plays an important role in the final self-training performance.",,"Add,Claim",Claim
4871,47-ARR,47-ARR_v2_73@10,,"Additionally, we consider applying the BUS-stop to domain adaptation tasks in the future. and denotes the test loss and accuracy, respectively.",,"Add,Claim",Claim
4872,47-ARR,47-ARR_v2_2@7,47-ARR_v1_2@7,"Our results show that the proposed model even performs better than using an additional validation set as well as the existing stop-methods, in both balanced and imbalanced data settings.","Experimental results show that the proposed model even performs better than using an additional validation set as well as the existing stopmethods, in both balanced and imbalanced data settings.","Modify,Clarity",Clarity
4873,47-ARR,47-ARR_v2_25@2,47-ARR_v1_25@2,"In the preliminary stage, the prediction confidences P l for the labeled samples in D l and the estimated class distribution C u of the unlabeled set D u are calculated.","In the preliminary stage, the distribution of the prediction confidence P l of the labeled set D l and the estimated class distribution C u of the unlabeled set D u are calculated.","Modify,Clarity",Clarity
4874,47-ARR,47-ARR_v2_25@6,47-ARR_v1_26@2,Each sample should be validated at least once; the prediction confidences are averaged for each sample.,Each sample in D l should be validated at least once; the prediction confidence is averaged for each sample.,"Modify,Clarity",Clarity
4875,47-ARR,47-ARR_v2_25@8,47-ARR_v1_26@3,"When retraining T -times, the output class distributions of the unlabeled set D u are obtained and calibrated (this calibration is defined in Section 3.3).","When retraining Ttimes, the output class distribution of the unlabeled set D u is obtained and calibrated (this calibration is defined in Section 3.3).","Modify,Grammar",Grammar
4876,47-ARR,47-ARR_v2_25@10,47-ARR_v1_27@0,"After this stage, P l and C u are used to calculate the similarities for the two stop criteria, conf-sim and class-sim, respectively.","After this stage, P l and C u are used to calculate the distribution similarities for the two stop criteria, conf-sim and class-sim, respectively.","Modify,Clarity",Clarity
4877,47-ARR,47-ARR_v2_27@0,47-ARR_v1_29@0,"After the preliminary stage, we train all the labeled samples and refer to this stage as the main stage.","After the preliminary stage, we train all the labeled samples and refer to this stage as the main stage for convenience.","Modify,Clarity",Clarity
4878,47-ARR,47-ARR_v2_29@0,47-ARR_v1_31@0,Conf-sim The first proposed stop criterion confsim S conf represents the similarity of the prediction confidences P u for the unlabeled samples with the reference confidences P l .,Conf-sim The first proposed stop criterion confsim S conf represents the similarity of the distribution of the prediction confidence P u on the unlabeled set with the reference distribution P l .,"Modify,Clarity",Clarity
4879,47-ARR,47-ARR_v2_2@8,47-ARR_v1_2@8,Our code is available at https://github. com/DMCB-GIST/BUS-stop.,Our code is available at https: //activated/after/accept.,"Modify,Fact/Evidence",Fact/Evidence
4880,47-ARR,47-ARR_v2_29@1,47-ARR_v1_31@1,"To calculate the similarity between P u and P l , their dimensions must be the same.","To calculate the similarity between these two distributions, their dimensions must be the same.","Modify,Clarity",Clarity
4881,47-ARR,47-ARR_v2_29@2,47-ARR_v1_31@2,We sample P u at regular intervals nu n l such that it is the same size as P l and denoted it as ... P u .,We sample P u at regular intervals such that it is the same size as P l and denoted it as ... P u .,"Modify,Clarity",Clarity
4882,47-ARR,47-ARR_v2_29@4,47-ARR_v1_31@4,"Then, the first stop criterion is when S conf has the lowest value, i.e., ... P u is most similar to P l .","Then, the first stop criterion for training is when S conf has the lowest value, i.e., ... P u is most similar to P l .","Modify,Clarity",Clarity
4883,47-ARR,47-ARR_v2_29@5,47-ARR_v1_31@5,"There is a natural concern that ... P u is likely to produce higher (thus dissimilar) confidences than P l because ... P u is obtained by training all the labeled samples, unlike P l .","There is a natural concern that ... P u is likely to produce higher (thus dissimilar) confidence than P l because ... P u is obtained by training all the labeled samples, unlike P l .","Modify,Grammar",Grammar
4884,47-ARR,47-ARR_v2_29@7,47-ARR_v1_31@7,"Thereby, S conf can be a rough criterion for avoiding under-and overfitting, and can reflect the trend of the loss, based on comparison with the reference confidences.","Thereby, S conf can be a rough criterion for avoiding under-and over-fitting, and can reflect the trend of the loss because it is based on the reference distribution that shows the best validation loss in the preliminary stage.","Modify,Claim",Claim
4885,47-ARR,47-ARR_v2_35@6,47-ARR_v1_39@4,"On the other hand, if the model fails to learn any inference knowledge from training, the model will output the predictions only by its sampling bias; i.e., when the accuracy is the same as the random expectation (denoted as Acc min , e.g., 0.5 in binary classification), the output class distribution will be equal to the sampling bias B. Thus, the model accuracy can reflect whether the output class distribution is closer to the sampling bias or the true distribution.","On the other hand, if the model fails to learn any inference knowledge from training, the model will output the predictions only by sampling bias; i.e., when the accuracy is the same as the random expectation (e.g., 0.5 in binary classification), the output class distribution will be equal to the sampling bias B. Thus, the model accuracy can reflect whether the output class distribution is closer to the sampling bias or the true distribution.","Modify,Fact/Evidence",Fact/Evidence
4886,47-ARR,47-ARR_v2_35@7,47-ARR_v1_39@5,"In the preliminary stage, we obtained the models ' and Ĉu , respectively.","In the preliminary stage, we obtained the models' proxy accuracy and output class distribution as Acc val and Ĉu , respectively.","Modify,Fact/Evidence",Fact/Evidence
4887,47-ARR,47-ARR_v2_43@5,47-ARR_v1_47@5,"AG-news (Zhang et al., 2015) and DBpedia (Zhang et al., 2015) are topic classification tasks for Wikipedia and news articles, respectively.","AG-news (Zhang et al., 2015) and DBpedia (Zhang al., 2015) are topic classification tasks for Wikipedia and news articles, respectively.","Modify,Grammar",Grammar
4888,47-ARR,47-ARR_v2_55@0,47-ARR_v1_59@0,"Conf-sim and class-sim can also be used as a single stop-criterion, as mentioned before.","Conf-sim and class-sim can also be used as a single stop criterion, as previously mentioned.","Modify,Clarity",Clarity
4889,47-ARR,47-ARR_v2_55@1,47-ARR_v1_59@1,We compare the single criteria with the combined BUS-stop criterion.,We compare the single stop criteria described above with the combined BUS-stop criterion.,"Modify,Clarity",Clarity
4890,47-ARR,47-ARR_v2_57@1,47-ARR_v1_61@1,"The Adam optimizer (Kingma and Ba, 2015) was applied for categorical crossentropy loss (i.e., − y i log p i ), and its learning rate was set to 3e-5.","The Adam optimizer (Kingma and Ba, 2015) was applied for categorical crossentropy loss, and its learning rate was set to 3e-5.","Modify,Fact/Evidence",Fact/Evidence
4891,47-ARR,47-ARR_v2_0@0,47-ARR_v1_0@0,Early Stopping Based on Unlabeled Samples in Text Classification,Early Stopping Based on Unlabeled Samples,"Modify,Other",Other
4892,47-ARR,47-ARR_v2_57@12,47-ARR_v1_62@10,"In our calibration method, we used Ĉval as B and macro F1-score as the Acc val .","In our calibration method, we used B as Ĉval and Acc val as the F1-score (macro).","Modify,Fact/Evidence",Fact/Evidence
4893,47-ARR,47-ARR_v2_62@1,47-ARR_v1_66@12,"On the other hand, class-sim is observed to be well responsive to the short-term fluctuation of the accuracy, but does not reflect the long-term trend.","On the other hand, class-sim is well responsive to the short-term fluctuation of the accuracy, but does not reflect the long-term trend.","Modify,Clarity",Clarity
4894,47-ARR,47-ARR_v2_62@4,47-ARR_v1_66@14,"In the EB-criterion and PE-stop-epoch, the average loss is not good enough compared to the high accuracy.",The EB-criterion results in the second-best accuracy but has the secondhighest loss on an average.,"Modify,Claim",Claim
4895,47-ARR,47-ARR_v2_62@5,47-ARR_v1_66@15,The accuracy and loss show somewhat conflicting results.,The accuracy and loss show conflicting results.,"Modify,Clarity",Clarity
4896,47-ARR,47-ARR_v2_72@0,47-ARR_v1_73@0,Conclusion and Future Work,Conclusion,"Modify,Other",Other
4897,47-ARR,47-ARR_v2_7@1,47-ARR_v1_7@1,"We are motivated by the following two considerations: (i) The probabilities of the predicted class label (i.e., the prediction confidences) can serve as an indicator for over-fitting or under-fitting.","We are motivated by the following two considerations: (i) The probabilities of the predicted class label (i.e., the distribution of the prediction confidence) can serve as an indicator for over-fitting or under-fitting.","Modify,Clarity",Clarity
4898,47-ARR,47-ARR_v2_7@6,47-ARR_v1_7@6,"The model stops when the prediction confidences for the unlabeled samples are most similar to the reference confidences, which are precalculated on the labeled set with cross-validation.","The model stops when the distribution of the prediction confidence of the unlabeled samples is most similar to the reference distribution, which is precalculated on the labeled set with cross-validation.","Modify,Clarity",Clarity
4899,47-ARR,47-ARR_v2_7@7,47-ARR_v1_7@7,"Conf-sim is observed to reflect the long-term trend of the loss curve, and thereby assist in preventing over-training.","Conf-sim can reflect the long-term trend of the loss curve, and thereby assist in preventing over-training.","Modify,Clarity",Clarity
4900,47-ARR,47-ARR_v2_7@11,47-ARR_v1_8@1,Classsim is observed to reflect the short-term trend of the accuracy.,Class-sim can reflect the short-term trend of the accuracy.,"Modify,Clarity",Clarity
4901,47-ARR,47-ARR_v2_7@12,47-ARR_v1_8@2,Our method requires several retraining steps to obtain the reference confidences for confsim and the estimated class distribution for classsim.,Our method requires several retraining steps to obtain the reference distribution for conf-sim and the estimated class distribution for class-sim.,"Modify,Clarity",Clarity
4902,47-ARR,47-ARR_v2_7@13,47-ARR_v1_8@3,"The BUS-stop method that combines classsim and conf-sim includes the advantages of both, and thereby performs with better accuracy and loss compared to each (class-sim and conf-sim).","The BUSstop method that combines class-sim and conf-sim includes the advantages of both, and thereby performs with better accuracy and loss compared to each (class-sim and conf-sim).","Modify,Grammar",Grammar
4903,470-ARR,,470-ARR_v1_76@0,,"To evaluate the model's tolerance to audio noise, we tested the performance of our model under babble noise with different SNR levels.","Delete,Fact/Evidence",Fact/Evidence
4904,470-ARR,,470-ARR_v1_76@1,,"Our audio-only and audiovisual models reach WERs of 32.5% and 24.5% when the SNR level is 0dB, respectively, which reduce the reported result in (Afouras et al., 2018a) by 25.5% and 9% 2 .","Delete,Fact/Evidence",Fact/Evidence
4905,470-ARR,,470-ARR_v1_76@2,,"When the SNR level rises to 5dB, our audio-only and audio-visual model obtain WERs of 6.8% and 6.3%.","Delete,Fact/Evidence",Fact/Evidence
4906,470-ARR,,470-ARR_v1_85@1,,The CTC prefix probability is defined as the cumulative probability of all label sequences that have h as their prefix:,"Delete,Fact/Evidence",Fact/Evidence
4907,470-ARR,,470-ARR_v1_88@1,,The CTC probability can be computed by keeping the forward hypothesis probγ The decoding algorithm is also a beam search with width W and hyperparameter α control the relative weight given to CTC and attention decoding.,"Delete,Claim",Claim
4908,470-ARR,,470-ARR_v1_88@2,,"U is a set of symbols excluding [blank], and a same token is used to represent [SOS] and [EOS] in our implementation.","Delete,Fact/Evidence",Fact/Evidence
4909,470-ARR,,470-ARR_v1_89@0,,The input images are sampled at 25 FPS and resized to 224 × 224 pixels.,"Delete,Fact/Evidence",Fact/Evidence
4910,470-ARR,,470-ARR_v1_89@1,,We crop a 120 × 120 mouth ROI from each frame.,"Delete,Fact/Evidence",Fact/Evidence
4911,470-ARR,,470-ARR_v1_89@2,,Fig. 4 shows the process to generate.,"Delete,Fact/Evidence",Fact/Evidence
4912,470-ARR,,470-ARR_v1_8@2,,We also ensure this research is reproducible by publishing our codes at anonymized_url.,"Delete,Fact/Evidence",Fact/Evidence
4913,470-ARR,470-ARR_v2_65@0,,"We present the parameters of our model, TM-CTC model (Afouras et al., 2018a) and the current state-of-the-art model (Ma et al., 2021) in Table 4.",,"Add,Fact/Evidence",Fact/Evidence
4914,470-ARR,470-ARR_v2_65@1,,"Our model back-ends and fusion module configurations follow TM-CTC model, the hyper-parameters settings in the seq2seq decoder are the same as in the back-ends.",,"Add,Fact/Evidence",Fact/Evidence
4915,470-ARR,470-ARR_v2_65@2,,"The most significant difference is that we utilize pre-trained front-ends, resulting in a larger model size.",,"Add,Fact/Evidence",Fact/Evidence
4916,470-ARR,470-ARR_v2_80@0,,"This work will not pose ethical problems, the data resources we use are all from published works and do not involve privacy issues related to data collection.",,"Add,Claim",Claim
4917,470-ARR,470-ARR_v2_80@1,,"The data is collected from BBC and contains thousands of diverse speakers, allowing the speech recognition models to generalize to all speakers.",,"Add,Fact/Evidence",Fact/Evidence
4918,470-ARR,470-ARR_v2_80@2,,"In terms of computational experiments, we used publicly available pre-trained models, which makes the training more environmentally friendly and lowers the computational requirements to reproduce our work.",,"Add,Fact/Evidence",Fact/Evidence
4919,470-ARR,470-ARR_v2_21@1,470-ARR_v1_22@1,"We use wav2vec 2.0 (Schneider et al., 2019) pre-trained on Libri-Light (Kahn et al., 2020), like it is normally used for ASR tasks, both the 1-D convolutional layers and the stacked Transformer encoder layers are transferred into our audio front-end.","We use wav2vec 2.0 (Schneider et al., 2019) pre-trained on Libri-Light (Kahn et al., 2020), like it is normally used for ASR tasks, both the 1-D convolution layers and the stacked Transformer encoder layers are transferred into our audio front-end.","Modify,Grammar",Grammar
4920,470-ARR,470-ARR_v2_25@1,470-ARR_v1_28@1,We downscale the frequency by setting the stride of 1-D convolutional layer to 2.,We downscale the frequency by setting the stride of 1-D convolution layer to 2.,"Modify,Grammar",Grammar
4921,470-ARR,470-ARR_v2_2@6,470-ARR_v1_2@6,Our model is experimentally validated on both word-level and sentence-level tasks.,Our model is experimentally validated on both word-level and sentence-level AVSR tasks.,"Modify,Clarity",Clarity
4922,470-ARR,470-ARR_v2_29@3,470-ARR_v1_34@3,"Similar 1-D convolutional layers and a subsequent Transformer encoder block of 6 layers take the fused representations as input, and encode them for the decoders.","Similar 1-D convolution layers and a subsequent Transformer encoder block of 6 layers take the fused representations as input, and encode them for the two decoders.","Modify,Clarity",Clarity
4923,470-ARR,470-ARR_v2_30@0,470-ARR_v1_35@0,Decoders,Decoder,"Modify,Grammar",Grammar
4924,470-ARR,470-ARR_v2_31@0,470-ARR_v1_36@0,"Following the setting of Petridis et al. (2018), there are two decoders trained simultaneously based on the same output in the fusion module.","Following the setting of Petridis et al. (2018), there are two decoders trained simultaneously based on the same encoder output in the fusion module.","Modify,Clarity",Clarity
4925,470-ARR,470-ARR_v2_33@1,470-ARR_v1_38@1,4 extra 1-D convolutional layers with ReLU activation are used on top of the last Transformer encoder layer output.,4 extra 1-D convolution layers with ReLU activation are used on top of the last Transformer encoder layer output.,"Modify,Grammar",Grammar
4926,470-ARR,470-ARR_v2_45@1,470-ARR_v1_50@1,"Then the audio front-and back-end are trained through the audio-only (AO) setting, together with dedicated decoders.","Then the audio backend is trained through the audio-only (AO) setting, together with a dedicated decoder.","Modify,Fact/Evidence",Fact/Evidence
4927,470-ARR,470-ARR_v2_46@0,470-ARR_v1_51@0,"For the visual modality, the visual front-end is first pre-trained through self-supervised learning, then modified and trained through sequence classification at word level video clips in LRW data.","For the visual modality, we first pre-train the 3-D convolution layer and visual back-end through sequence classification at word level video clips in LRW data.","Modify,Fact/Evidence",Fact/Evidence
4928,470-ARR,470-ARR_v2_46@1,470-ARR_v1_51@1,"After that, the visual front-end is inherited by the visual-only (VO) model, where visual back-end and dedicated decoders are used.","After that, the visual front-end are inherited by the visual-only (VO) model, where dedicated visual back-end and decoder are used.","Modify,Grammar",Grammar
4929,470-ARR,470-ARR_v2_48@0,470-ARR_v1_53@0,"Due to computational constraints, we pre-compute the audio and visual back-end outputs, and only learn the parameters in the fusion module and decoders part in this final stage.","Due to computational constraints, we pre-compute the audio and visual back-end outputs, and only learn the parameters in the fusion model and decoder part in this final stage.","Modify,Clarity",Clarity
4930,470-ARR,470-ARR_v2_56@1,470-ARR_v1_61@1,"During training, we also use the Lip Reading in the Wild (LRW) (Chung and Zisserman, 2016) as a word-level video classification task to pre-train our visual front-end.","During training, we also use the Lip Reading in the Wild (LRW) (Chung and Zisserman, 2016) as a word-level video classification task to pre-train our visual encoder.","Modify,Fact/Evidence",Fact/Evidence
4931,470-ARR,470-ARR_v2_2@0,470-ARR_v1_2@0,"Training Transformer-based models demands a large amount of data, while obtaining aligned and labelled data in multimodality is rather cost-demanding, especially for audio-visual speech recognition (AVSR).","Training Transformer-based models demands a large amount of data, while obtaining parallel aligned and labelled data in multimodality is rather cost-demanding, especially for audiovisual speech recognition (AVSR).","Modify,Grammar",Grammar
4932,470-ARR,470-ARR_v2_60@0,470-ARR_v1_65@0,"Our implementation is based on the Pytorch library (Paszke et al., 2019) and trained on four NVIDIA A100 GPUs with a total of 160GB memory for 1 week.","Our implementation is based on the Pytorch library (Paszke et al., 2019) and trained on four NVIDIA A100 GPUs with a total of 160GB memory.","Modify,Fact/Evidence",Fact/Evidence
4933,470-ARR,470-ARR_v2_60@1,470-ARR_v1_65@1,"The network is trained using the Adam optimizer (Kingma and Ba, 2015) with β 1 = 0.9, β 2 = 0.999 and = 10 −8 and an initial learning rate of 10 −4 .","The network is trained using the Adam optimiser (Kingma and Ba, 2014) with β 1 = 0.9, β 2 = 0.999 and = 10 −8 and an initial learning rate of 10 −4 .","Modify,Fact/Evidence",Fact/Evidence
4934,470-ARR,470-ARR_v2_60@2,470-ARR_v1_65@2,"We use label smoothing with a weight set to 0.01, learning rate warm up and reduce on plateau scheduler.","We use label smoothing with a weight set to 0.01, learning rate warm up and reduce on plateau.","Modify,Clarity",Clarity
4935,470-ARR,470-ARR_v2_4@2,470-ARR_v1_4@2,"Due to the limited amount of labeled, multimodal aligned data and the difficulty of recognition from the visual inputs (i.e., lip reading), it is a challenging task to tackle.","Due to the limited amount of labeled, multi-modal parallel data and the difficulty of recognition from the visual inputs (i.e., lip reading), it is a challenging task to tackle.","Modify,Clarity",Clarity
4936,470-ARR,470-ARR_v2_61@1,470-ARR_v1_66@1,"To remove differences related to face rotation and scale, the faces are aligned to a neural reference frame using a similarity transformation following Martínez et al. (2020).","To remove differences related to face rotation and scale, the faces are aligned to a neural reference frame using a similarity transformation following (Martinez et al., 2020).","Modify,Grammar",Grammar
4937,470-ARR,470-ARR_v2_61@4,470-ARR_v1_66@4,The cropped frames are further converted to gray-scale and normalized with respect to the overall mean and variance of the train set.,The cropped frame is further converted to gray-scale and normalized with respect to the overall mean and variance of the train set.,"Modify,Grammar",Grammar
4938,470-ARR,470-ARR_v2_61@5,470-ARR_v1_66@5,Each raw audio waveform is normalized to zero mean and unit variance following Baevski et al. (2020).,"Each raw audio waveform is normalized to zero mean and unit variance following (Baevski et al., 2020).","Modify,Grammar",Grammar
4939,470-ARR,470-ARR_v2_64@0,470-ARR_v1_69@0,"We present results for all experiments in Table 3, reporting WERs on visual-only, audio-only and audio-visual models.","We present results for all experiments in Table 3, reporting WERs on audio-only, visual-only and audio-visual models.","Modify,Clarity",Clarity
4940,470-ARR,470-ARR_v2_67@1,470-ARR_v1_71@1,"Our model also achieves a WER of 2.7%, which reduces the WER of the current state-of-the-art (Ma et al., 2021) by 1.2%, indicating a relative improvement of 31%.","Our model also achieves a WER of 2.7%, which reduces the WER of the current stateof-the-art (Ma et al., 2021) by 1.2%, indicating a relative improvement of 30%.","Modify,Fact/Evidence",Fact/Evidence
4941,470-ARR,470-ARR_v2_0@0,470-ARR_v1_0@0,Leveraging Unimodal Self-Supervised Learning for Multimodal Audio-Visual Speech Recognition,Leveraging Uni-Modal Self-Supervised Learning for Multimodal Audio-visual Speech Recognition,"Modify,Grammar",Grammar
4942,470-ARR,470-ARR_v2_68@1,470-ARR_v1_72@1,"The visual-only model achieves a WER of 43.2%, lagging behind the current stateof-the-art E2E Conformer model (Ma et al., 2021) with 5.3%.","The visual-only model achieves a WER of 43.8%, lagging behind the current stateof-the-art (E2E Conformer) with 5.3%.","Modify,Fact/Evidence",Fact/Evidence
4943,470-ARR,470-ARR_v2_68@2,470-ARR_v1_72@2,"Compared to E2E Conformer, the main difference is that a large Transformer language model is used during decoding, which itself brings a 4.5% difference compared with a normal RNN language model in their ablation studies (Ma et al., 2021).","Compared to E2E Conformer, the main difference is that a big Transformer language model is used during decoding, which itself brings a 4.5% difference compared with a normal RNN language model in their ablation study (Ma et al., 2021).","Modify,Clarity",Clarity
4944,470-ARR,470-ARR_v2_68@4,470-ARR_v1_72@4,"Additionally, we use a 6-layers Transformer encoder for temporal modelling instead of a 12-layers conformer encoder, which resulted in a smaller back-end size.","Additionally, we use a 6-layers Transformer encoder for temporal modelling instead of a 12-layers conformer encoder, which resulted in a smaller model size.","Modify,Fact/Evidence",Fact/Evidence
4945,470-ARR,470-ARR_v2_71@0,470-ARR_v1_75@0,"In this section, we investigate the impact of every individual building block by testing them in LRW, audio-only and visual-only settings.","In this section, we investigate the impact of every individual building block by testing them in LRW, visual-only and audio-only settings.","Modify,Clarity",Clarity
4946,470-ARR,470-ARR_v2_72@1,470-ARR_v1_75@1,"We first train a model by replacing the ResNet-18 front-end in Stafylakis and Tzimiropoulos (2017) with a ResNet-50 frontend, matching the size of MoCo v2 but with fresh weights.","4. We first train a model by replacing the ResNet-18 front-end in (Stafylakis and Tzimiropoulos, 2017) with a ResNet-50 frontend, matching the size of MoCo v2 but with fresh weights.","Modify,Grammar",Grammar
4947,470-ARR,470-ARR_v2_72@4,470-ARR_v1_75@4,"Additionally, When Using 6 layers of Transformer encoder instead of TCN as back-end, we can observe another absolute improvement of 6.0%.","Additionally, When Using 6 layers of Transformer encoder instead of TCN as back-end, we can observe another absolute improvement of 5.0%.","Modify,Fact/Evidence",Fact/Evidence
4948,470-ARR,470-ARR_v2_72@8,470-ARR_v1_75@9,"We further train the model with a hybrid CTC/attention decoder during the training stage, which results in another absolute improvement of 0.9%.","We further train the model with hybrid CTC/attention decoder during the training stage, which results in another absolute improvement of 0.9%.","Modify,Grammar",Grammar
4949,470-ARR,470-ARR_v2_73@1,470-ARR_v1_76@4,"The human noise is extremely challenging because the noise itself contains some words, while the model cannot easily distinguish which audio signal is the one to be recognized.","The human noise is extremely challenging cause the noise itself contains some words, while the model cannot easily distinguish which audio signal is the one to be recognized.","Modify,Grammar",Grammar
4950,470-ARR,470-ARR_v2_79@2,470-ARR_v1_82@2,"We hope this work could pave the way towards multimodality self-supervised learning, especially for various aspects in AVSR.","We hope this work could pave the way towards multimodality self-supervised learning, especially for various aspects in audio-visual speech recognition.","Modify,Clarity",Clarity
4951,470-ARR,470-ARR_v2_6@0,470-ARR_v1_6@0,"Although self-supervised learning could enable leveraging unlabelled or even unaligned data, it hasn't been adequately explored on this task.","Although self-supervised learning could enable leveraging unlabelled or even non-parallel data, it hasn't been adequately explored on this task.","Modify,Clarity",Clarity
4952,470-ARR,470-ARR_v2_6@4,470-ARR_v1_6@4,"In another scenario, selfsupervised learning in unimodality has been well established as a paradigm to learn general representations from unlabelled examples, such as in natural language processing (Brown et al., 2020;Devlin et al., 2019), speech recognition (Baevski et al., 2020), and computer vision (He et al., 2019;Chen et al., 2020a;Grill et al., 2020).","In another scenario, selfsupervised learning in uni-modality has been well established as a paradigm to learn general representations from unlabelled examples, such as in natural language processing (Brown et al., 2020;Devlin et al., 2018), speech recognition (Baevski et al., 2020), and computer vision (He et al., 2019;Chen et al., 2020a;Grill et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
4953,470-ARR,470-ARR_v2_7@2,470-ARR_v1_7@2,"For visual front-end, we found that it is not as straight-forward for it to leverage pre-trained models, as we have to substitute the first convolutional layer in MoCo v2 (Chen et al., 2020b) by a 3-D convolutional layer and finetune it through LRW.","For visual front-end, we found that it is not as straight-forward for it to leverage pre-trained models, as we have to substitute the first ResNet block in MoCo v2 (Chen et al., 2020b) by 3-D convolution layer and fine-tune it through LRW.","Modify,Clarity",Clarity
4954,470-ARR,470-ARR_v2_11@3,470-ARR_v1_11@3,"Most of the works are devoted into the architectural improvements, for example, Zhang et al. (2019) proposed temporal focal block and spatio-temporal fusion, and Lee et al. (2020) explored to use crossmodality attentions with Transformer.","Most of the works are devoted into the architectural improvements, for example, Zhang et al. (2019) proposed temporal focal block and spatio-temporal fusion, and Lee et al. (2020a) explored to use crossmodality attentions with Transformer.","Modify,Fact/Evidence",Fact/Evidence
4955,470-ARR,470-ARR_v2_15@2,470-ARR_v1_15@2,"In natural language processing, uni-or bi-directional language modelling (Brown et al., 2020;Devlin et al., 2019) have been used to significantly increase performances on various tasks.","In natural language processing, uni-or bi-directional language modelling (Brown et al., 2020;Devlin et al., 2018) have been used to significantly increase performances on various tasks.","Modify,Fact/Evidence",Fact/Evidence
4956,470-ARR,470-ARR_v2_2@4,470-ARR_v1_2@4,"In particular, audio and visual front-ends are trained on large-scale unimodal datasets, then we integrate components of both front-ends into a larger multimodal framework which learns to recognize parallel audio-visual data into characters through a combination of CTC and seq2seq decoding.","In particular, we first train audio and visual encoders on a large-scale uni-modal dataset, then we integrate components of both encoders into a larger multimodal framework which learns to recognize paired audio-visual data into characters through a combination of CTC and seq2seq decoding.","Modify,Clarity",Clarity
4957,470-ARR,470-ARR_v2_20@0,470-ARR_v1_21@0,"To overcome the aforementioned problem while still being able to utilize the pre-trained model, we truncate the first convolutional layer in MoCo v2 (Chen et al., 2020b), which is pre-trained on Im-ageNet (Deng et al., 2009), and replace it with a layer of 3-D convolution.","To overcome the aforementioned problem while still being able to utilize the pre-trained model, we truncate the first convolutional layer in MoCo v2 (Chen et al., 2020b), which is pre-trained on Ima-geNet (Deng et al., 2009), and replace it by a layer of 3-D convolution.","Modify,Grammar",Grammar
4958,470-ARR,470-ARR_v2_20@1,470-ARR_v1_21@1,"The outputs of 3-D convolutional layer are intentionally made identical to the input of the first ResBlock in MoCo v2 (see Table 1), thus providing a compatible interface to transfer higher layers of MoCo v2 into this task.","The outputs of 3-D convolution layer are intentionally made identical to the input of the first ResBlock in MoCo v2 (see Table 1), thus providing a compatible interface to transfer higher layers of MoCo v2 into this task.","Modify,Grammar",Grammar
4996,49-ARR,,49-ARR_v1_65@0,,BERT.,"Delete,Other",Other
4997,49-ARR,,49-ARR_v1_65@1,,"With BS, BERT achieves the best or second best result on all human evaluation metrics, except for specificity.","Delete,Claim",Claim
4998,49-ARR,49-ARR_v2_9@8,,"Instead, in our work we take a more foundational perspective, which is relevant for all the LM-based pipelines described above.",,"Add,Claim",Claim
4999,49-ARR,49-ARR_v2_22@4,,"It should be noted that RR is calculated as a corpus-based repetition score , i.e. inter-CN, instead of calculating intra-CN repetition of n-grams only.",,"Add,Fact/Evidence",Fact/Evidence
5000,49-ARR,49-ARR_v2_33@4,,This poor grammaticality can also explain the syntactic scores since the spaCy dependency parser was not trained to handle ungrammatical text and this could actually inflates the ASD and MSD scores.,,"Add,Claim",Claim
5001,49-ARR,49-ARR_v2_39@7,,Of course more repetitive and conservative outputs can be preferred when high precision of suitable CNs are required at the expense of being more generic and less novel.,,"Add,Claim",Claim
5002,49-ARR,49-ARR_v2_41@1,,"Even if it reaches high scores in most of the human evaluation metrics, it fails to produce specific CNs ending up in generating suitable, yet generic responses.",,"Add,Fact/Evidence",Fact/Evidence
5003,49-ARR,49-ARR_v2_41@2,,"On the contrary, stochastic decoding mechanisms produce more novel and specific responses.",,"Add,Fact/Evidence",Fact/Evidence
5004,49-ARR,49-ARR_v2_59@3,,"These experts were already trained for the CN generation task and employed for the work presented by (Fanton et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
5005,49-ARR,49-ARR_v2_73@0,,"Table 9 displays the distribution of the examples with respect to the targets, in the reference dataset and in the configurations for the LOTO experiments (Section 5.3).",,"Add,Fact/Evidence",Fact/Evidence
5006,49-ARR,49-ARR_v2_73@1,,"Table 10 presents the detailed results for the novelty of the reference CNs discussed in Section 5.3, while the RR for the CNs generated with the LOTO models and for the reference CNs are shown in Table 11.",,"Add,Fact/Evidence",Fact/Evidence
5007,49-ARR,49-ARR_v2_73@2,,"The rankings for these two RR computations are the same, and the ranges are almost overlapping.",,"Add,Fact/Evidence",Fact/Evidence
5008,49-ARR,49-ARR_v2_73@3,,"This means that leaving one target out does not impact the intra-corpora repetitiveness: instead, the CNs generated with a LOTO model gain a lower RR than the reference CNs.",,"Add,Fact/Evidence",Fact/Evidence
5009,49-ARR,49-ARR_v2_73@4,,"For the target MUSLIMS a high RR is recorded, both in candidate and in the reference CNs.",,"Add,Fact/Evidence",Fact/Evidence
5010,49-ARR,49-ARR_v2_18@6,49-ARR_v1_19@6,"Also known as Nucleus Sampling, the parameter p indicates the total probability for the pooled candidates, at each time step (Holtzman et al., 2020).","Also known as Nucleus Sampling, the parameter p indicates the total probability for the pooled candidates, at each time step (Holtzman et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
5011,49-ARR,49-ARR_v2_19@0,49-ARR_v1_20@0,In our experiments we used the following parameters as default: Beam-Search with 5 beams and repetition penalty = 2; Top-k with k = 40; Top-p with p = .92; Top pk with k = 40 and p = .92.,In our experiments we used the following parameters: Beam-Search with 5 beams and repetition penalty = 2; Top-k with k = 40; Top-p with p = .92; Top pk with k = 40 and p = .92.,"Modify,Clarity",Clarity
5012,49-ARR,49-ARR_v2_22@3,49-ARR_v1_23@3,"In particular, we utilized Repetition Rate (RR) to measure the repetitiveness across generated CNs, in terms of the average ratios of non-singleton n-grams present in the corpus (Bertoldi et al., 2013).","In particular, we utilized Repetition Rate (RR) to measure the repetitiveness among generated CNs, in terms of the average ratios of non-singleton n-grams present in the corpus (Bertoldi et al., 2013).","Modify,Clarity",Clarity
5013,49-ARR,49-ARR_v2_22@5,49-ARR_v1_23@4,"We also used Novelty (NOV) (Wang and Wan, 2018), based on Jaccard similarity, to compute the amount of novel content that is present in the generated CNs as compared to the training data.","We also used Novelty (NOV), based on Jaccard similarity (Wang and Wan, 2018;Dziri et al., 2019), to compute the amount of novel content that is present in the generated CNs as compared to the training data.","Modify,Fact/Evidence",Fact/Evidence
5014,49-ARR,49-ARR_v2_22@7,49-ARR_v1_23@6,"Albeit more difficult to attain, human judgments provide a more reliable evaluation and a deeper understanding than automatic metrics (Belz and Reiter, 2006;Novikova et al., 2017).","Albeit more difficult to attain, human judgements provide a more reliable evaluation and a deeper understanding than automatic metrics (Belz and Reiter, 2006;Novikova et al., 2017).","Modify,Grammar",Grammar
5015,49-ARR,49-ARR_v2_27@0,49-ARR_v1_28@0,"For the first round of experiments, in order to avoid possible unfair assessments given by the open nature of the generative task (i. e. a highly suitable CN candidate could be scored low due to its difference from the single reference/gold CN), at test time we allowed the generation of several candidates for each HS+LM+decoding mechanism combination.","For the first round of experiments, in order to avoid possible unfair assessments given by the open nature of the generative task (i. e. a highly suitable CN candidate could be scored low due to its difference from the reference CN), at test time we allowed the generation of several candidates for each HS/LM/decoding mechanism combination.","Modify,Clarity",Clarity
5016,49-ARR,49-ARR_v2_28@2,49-ARR_v1_29@2,"Then, we selected the best ones according to the following criteria: Best LM selects the single best CN for an HS among the 20 generated by the 4 models.","Then, we selected the best ones according to the following criteria: Best LM selects the single best CN among the 20 generated by each model for an HS.","Modify,Fact/Evidence",Fact/Evidence
5017,49-ARR,49-ARR_v2_28@3,49-ARR_v1_29@3,Best D selects the single best CN for an HS among the 25 generated by the 5 decoding configurations.,Best D selects the single best CN among the 25 generated by each decoding for an HS.,"Modify,Fact/Evidence",Fact/Evidence
5018,49-ARR,49-ARR_v2_4@4,49-ARR_v1_5@0,"An alternative strategy, that is looming on the horizon, is based on the use of Counter Narratives.","An alternative strategy, that is looming on the horizon, is based on the use of Counter Narratives (CN).","Modify,Clarity",Clarity
5019,49-ARR,49-ARR_v2_2@0,49-ARR_v1_2@0,"In this work, we present an extensive study on the use of pre-trained language models for the task of automatic Counter Narrative (CN) generation to fight online hate speech in English.","In this work, we present an extensive study on the use of pre-trained language models for the task of automatic Counter Narrative (CN) generation to fight online hate speech.","Modify,Clarity",Clarity
5020,49-ARR,49-ARR_v2_39@6,49-ARR_v1_40@6,"In this set of experiments, we found that the autoregressive models perform the best according to a combination of several metrics that we deem particularly relevant (e.g. more novel, diverse, and informative outputs).","In this set of experiments, we found that the autoregressive models perform the best according to a combination of several metrics.","Modify,Claim",Claim
5021,49-ARR,49-ARR_v2_40@0,49-ARR_v1_40@7,"Still, for what concerns autoregressive models it could be argued that the good performance of the GPT-2 model we fine-tuned is due to the fact that generated CNs and gold CNs derive from a similar distribution (GPT-2 was employed in the humanin-the-loop process used to create the reference dataset from Fanton et al. ( 2021)).","Still, it could be argued that the good performance of the GPT-2 model we fine-tuned is due to the fact that generated CNs and gold CNs derive from a similar distribution (GPT-2 was employed in the human-in-the-loop process used to create the reference dataset from Fanton et al. ( 2021)).","Modify,Clarity",Clarity
5022,49-ARR,49-ARR_v2_4@7,49-ARR_v1_5@3,"An example of <HS, CN > pair is shown below: HS: Women are basically childlike, they remain this way most of their lives.","An example <HS, CN > pair is shown below: HS: Women are basically childlike, they remain this way most of their lives.","Modify,Grammar",Grammar
5023,49-ARR,49-ARR_v2_0@0,49-ARR_v1_0@0,Using Pre-Trained Language Models for Producing Counter Narratives Against Hate Speech: a Comparative Study,Using Pre-trained Language Models for Producing Counter Narratives Against Hate Speech: a Comparative Study,"Modify,Grammar",Grammar
5024,49-ARR,49-ARR_v2_49@4,49-ARR_v1_47@5,"Most importantly, this connection is not arbitrarily decided but it is based on an a-priori semantic similarity of the targets as exemplified before.","Most importantly, this connection is not arbitrarily decided but it is based on an a priori semantic similarity of the targets.","Modify,Clarity",Clarity
5025,49-ARR,49-ARR_v2_53@0,49-ARR_v1_51@0,"Thus, as a final experiment, we propose to further improve the CN generation by moving from an end-to-end framework to a two stage pipeline, by decoupling CN generation from its 'final refinement'.","Thus, as a final experiment, we propose further improving CN generation by moving from an endto-end framework to a two stage pipeline, by decoupling CN generation from its 'final refinement'.","Modify,Grammar",Grammar
5026,49-ARR,49-ARR_v2_5@1,49-ARR_v1_6@1,"Since for NGO operators it is impossible to manually write responses to all instances of hate, a line of NLP research has recently emerged, focusing on designing systems to automatically generate CN suggestions (Qian et al., 2019;Tekiroglu et al., 2020;Fanton et al., 2021;Chung et al., 2021a;Zhu and Bhat, 2021).","Since for NGO operators it is impossible to manually write responses to all instances of hate, a line of NLP research has recently emerged, focusing on designing systems to automatically generate CN suggestions to fight online hateful messages (Qian et al., 2019;Tekiroglu et al., 2020;Fanton et al., 2021;Chung et al., 2021a;Zhu and Bhat, 2021).","Modify,Fact/Evidence",Fact/Evidence
5027,49-ARR,49-ARR_v2_53@2,49-ARR_v1_51@2,"APE, which is used for automatically correcting errors made by machine translation (MT) systems before performing actual human post-editing, has been an important tool for MT (Knight and Chander, 1994;do Carmo et al., 2021).","APE, which is used for automatically correcting errors made by MT systems before performing actual human post-editing, has been an important tool for machine translation (Knight and Chander, 1994;do Carmo et al., 2021).","Modify,Clarity",Clarity
5028,49-ARR,49-ARR_v2_57@0,49-ARR_v1_56@0,"Then, we investigate the performances of LMs in zero-shot generation for unseen targets of hate.","Then, we investigate the performance of LMs in zero-shot generation for unseen targets of hate.","Modify,Grammar",Grammar
5029,49-ARR,49-ARR_v2_57@4,49-ARR_v1_56@4,The notable human evaluation results paves the way for a future direction that decouples CN generation from its 'final refinement'.,The notable human evaluation results paves the way for a promising future direction that decouples CN generation from its 'final refinement'.,"Modify,Clarity",Clarity
5030,49-ARR,49-ARR_v2_59@1,49-ARR_v1_58@1,"Therefore, we strictly followed the guidelines created for CN studies (Fanton et al., 2021) that were adapted from (Vidgen et al., 2019).","Therefore, we strictly followed the guidelines created for CN studies (Fanton et al., 2021) that were previously adapted from (Vidgen et al., 2019).","Modify,Clarity",Clarity
5031,49-ARR,49-ARR_v2_59@4,49-ARR_v1_58@3,"We further instructed them in the aims of each experiment, clearly explained the evaluation tasks, and then we exemplified proper evaluation of <HS, CN > pairs using various types of CNs.","We instructed the annotators in the aims of each evaluation, clearly explained the tasks, and then we exemplified proper <HS, CN > pairs with various types of CNs.","Modify,Clarity",Clarity
5032,49-ARR,49-ARR_v2_5@3,49-ARR_v1_6@3,"Thus, we use various automatic metrics and manual evaluations with expert judgments to assess several LMs, representing the main categories of the model architectures, and decoding methods.","Thus, we use various automatic metrics and manual evaluations with expert judgments to assess several LMs, representing the main categories of the model mechanisms, and decoding methods.","Modify,Clarity",Clarity
5033,49-ARR,49-ARR_v2_64@0,49-ARR_v1_62@0,"A.1 Fine-tuning details Since LM sizes are very different for each model and since our main focus is not studying performances according to LM dimension growth, as a rule-of-thumb, we chose one version smaller than the large version of each model provided that they all have the same order of magnitude.","A.1 Fine-tuning details As a rule-of-thumb, we chose one version smaller than the large version of each model, this corresponds to the medium versions for both DialoGPT and GPT-2, and base versions for the other models.","Split+Modify,Claim",Claim
5035,49-ARR,49-ARR_v2_2@1,49-ARR_v1_2@1,We first present a comparative study to determine whether there is a particular Language Model (or class of LMs) and a particular decoding mechanism that are the most appropriate to generate CNs.,We first present a comparative study to determine whether there is a particular Language Model (or class of LMs) and a particular decoding mechanism which is the most appropriate to generate CNs.,"Modify,Grammar",Grammar
5036,49-ARR,49-ARR_v2_5@6,49-ARR_v1_6@6,"Furthermore, in out-of-target experiments we find that the similarity of targets (e.g. JEWS and MUSLIMS as religious groups) plays a crucial role for the effectiveness of portability to new targets.","Furthermore, in out-of-target experiments we find that the similarity of targets (e.g. JEWS and MUSLIMS as religious groups) in training data plays a crucial role for the effectiveness of portability to new targets.","Modify,Clarity",Clarity
5037,49-ARR,49-ARR_v2_8@1,49-ARR_v1_9@1,"NLP has started addressing the phenomenon of the proliferation of HS by creating datasets for automatic detection (Mathew et al., 2021;Cao et al., 2020;Hosseinmardi et al., 2015;Waseem, 2016;Burnap and Williams, 2016).","NLP has started addressing the phenomenon of the proliferation of HS by creating datasets for automatic detection (Mathew et al., 2021;Cao et al., 2020;Kumar et al., 2018;Hosseinmardi et al., 2015;Waseem, 2016;Burnap and Williams, 2016).","Modify,Fact/Evidence",Fact/Evidence
5038,49-ARR,49-ARR_v2_8@2,49-ARR_v1_9@2,"Several surveys provide a review on the existing approaches on the topic (Poletto et al., 2020;Schmidt and Wiegand, 2017;Fortuna and Nunes, 2018), also addressing the ethical challenges of the task (Kiritchenko et al., 2021).","Several surveys provide a review on the existing approaches on the topic (Poletto et al., 2020;Schmidt and Wiegand, 2017;Nunes and Fortuna, 2018), also addressing the ethical challenges of the task (Kiritchenko et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
5039,49-ARR,49-ARR_v2_8@3,49-ARR_v1_9@3,"Still, automatic detection of HS presents some drawbacks (Vidgen and Derczynski, 2020).","Automatic detection of HS presents some drawbacks (Vidgen and Derczynski, 2020).","Modify,Clarity",Clarity
5040,49-ARR,49-ARR_v2_8@7,49-ARR_v1_9@7,"CNs have been shown to be effective in reducing linguistic violence (Benesch, 2014;Gagliardone et al., 2015;Schieb and Preuss, 2016;Silverman et al., 2016;Mathew et al., 2019); moreover, even if they might not influence the view of extremists, they are still effective in presenting alternative and non-hateful viewpoints to bystanders (Allison and Bussey, 2016;Anderson et al., 2014).","CNs have been shown to be effective in reducing linguistic violence (Benesch, 2014;Gagliardone et al., 2015;Schieb and Preuss, 2016;Silverman et al., 2016;Mathew et al., 2019); moreover, even if they might not influence the view of the extremists, they are still effective in presenting alternative and non-hateful viewpoints to the bystanders (Allison and Bussey, 2016;Anderson et al., 2014).","Modify,Grammar",Grammar
5041,49-ARR,49-ARR_v2_9@6,49-ARR_v1_10@6,Zhu and Bhat (2021) propose an entirely automated pipeline of candidate CN generation and filtering.,Zhu and Bhat (2021) propose an entirely automated pipeline for synthetic CN generation.,"Modify,Fact/Evidence",Fact/Evidence
5042,49-ARR,49-ARR_v2_9@9,49-ARR_v1_10@7,"Therefore, we compare and assess various state of the art pre-trained LMs in an end-to-end setting, which is developed as a downstream task for CN generation.","Instead, our work aims at an end-to-end system for CN generation, which is developed as a downstream task after comparing the state of the art pre-trained LMs.","Modify,Fact/Evidence",Fact/Evidence
5043,49-ARR,49-ARR_v2_15@3,49-ARR_v1_16@3,"The Generative Pre-trained Transformer 2 is an autoregressive model built for text generation (Radford et al., 2019).","The Generative Pre-trained Transformer 2 is an autoregressive model and it is specifically built for text generation (Radford et al., 2019).","Modify,Clarity",Clarity
5044,49-ARR,49-ARR_v2_15@7,49-ARR_v1_16@7,"BART is a denoising autoencoder for pretraining seq2seq models (Lewis et al., 2020).","BART is a seq2seq model that combines two different Transformer architectures (Lewis et al., 2020): a bidirectional encoder and a leftto-right autoregressive decoder.","Split+Modify,Fact/Evidence",Fact/Evidence
5045,49-ARR,49-ARR_v2_15@8,49-ARR_v1_16@7,The encoder-decoder architecture of BART is composed of a bidirectional encoder and an autoregressive decoder.,"BART is a seq2seq model that combines two different Transformer architectures (Lewis et al., 2020): a bidirectional encoder and a leftto-right autoregressive decoder.","Split+Modify,Clarity",Clarity
5046,49-ARR,49-ARR_v2_16@1,49-ARR_v1_17@1,"While all the other models could be fine-tuned directly for the generation task, for BERT we warmstarted an encoder-decoder model using BERT checkpoints similar to the BERT2BERT model defined by (Rothe et al., 2020).","While all the other models could be fine-tuned directly for the generation task, for BERT we needed to warmstart an encoder-decoder model using BERT checkpoints.","Modify,Fact/Evidence",Fact/Evidence
5047,50-ARR,,50-ARR_v1_36@2,,We show the results of different number of passages in Appendix B.,"Delete,Fact/Evidence",Fact/Evidence
5048,50-ARR,,50-ARR_v1_40@2,,"As stated in Rogers et al. (2021), Trivia questions are more like probing questions.","Delete,Fact/Evidence",Fact/Evidence
5049,50-ARR,,50-ARR_v1_45@0,,Figure 3 shows the performance of our model and FiD reader with regard to different number of retrieved training passages.,"Delete,Fact/Evidence",Fact/Evidence
5050,50-ARR,,50-ARR_v1_45@1,,"We train both models with top-k passages (k ∈ {1, 5, 10, 25}) and evaluate on the development sets with the same number of passages.","Delete,Fact/Evidence",Fact/Evidence
5051,50-ARR,50-ARR_v2_31@4,,"It can be seen that TriviaQA has on average longer question length than NQ, indicating that questions in TriviaQA are relatively more complex.",,"Add,Fact/Evidence",Fact/Evidence
5052,50-ARR,50-ARR_v2_4@1,50-ARR_v1_4@1,"With the pioneering work of DrQA (Chen et al., 2017), modern approaches to ODQA commonly adopt a simple two-stage retriever-reader pipeline, that firstly retrieve a relatively small number of support passages (Karpukhin et al., 2020;Min et al., 2021b;Yamada et al., 2021), followed by the reader identifying the answer.","With the pioneering work of DrQA (Chen et al., 2017), modern approaches to ODQA commonly adopt a simple two-stage retriever-reader pipeline, that firstly retrieve a relatively small number of support passages (Karpukhin et al., 2020;Yamada et al., 2021;Min et al., 2021b), followed by the reader identifying the answer.","Modify,Clarity",Clarity
5053,50-ARR,50-ARR_v2_40@1,50-ARR_v1_42@1,"The study of test-train overlap (Lewis et al., 2021) provides valuable insights into the model's question answering behavior.","The study of test-train overlap (Lewis et al., 2020b) provides valuable insights into the model's question answering behavior.","Modify,Fact/Evidence",Fact/Evidence
5054,50-ARR,50-ARR_v2_40@2,50-ARR_v1_42@2,We evaluate our model on the same test data splits as in Lewis et al. (2021).,We evaluate our model on the same test data splits as in Lewis et al. (2020b).,"Modify,Fact/Evidence",Fact/Evidence
5055,50-ARR,50-ARR_v2_40@7,50-ARR_v1_45@3,"Moreover, the two models show comparative performance when the number of training passages is small, but when more passages are included, our model outperforms FiD, especially on the NQ dataset.","Moreover, the two models show comparative performance when the number of training passages is small, but when more passages included, our model outperforms FiD, especially on the NQ dataset.","Modify,Grammar",Grammar
5056,50-ARR,50-ARR_v2_5@0,50-ARR_v1_5@0,"The reader models can be broadly categorized into two classes: extractive (Chen et al., 2017;Asai et al., 2020;Karpukhin et al., 2020) and generative (Izacard and Grave, 2021b;Lewis et al., 2020b;Wu et al., 2021).","The reader models can be broadly categorized into two classes: extractive (Chen et al., 2017;Asai et al., 2019;Karpukhin et al., 2020) and generative (Lewis et al., 2020a;Izacard and Grave, 2020b;Wu et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5057,50-ARR,50-ARR_v2_6@0,50-ARR_v1_6@0,"Compared to extractive models, generative models generate text more freely, which makes it often suffer from the problem of producing hallucinated text that is factual inaccuracy or inconsistent to the input.","Compared to extractive models, generative models generate text more freely, which makes it often suffer from the problem of producing hallucinated text that is inconsistent to the input or factual inaccuracy.","Modify,Clarity",Clarity
5058,50-ARR,50-ARR_v2_6@1,50-ARR_v1_6@1,"This problem has been addressed in tasks like text summarization (Maynez et al., 2020) and machine translation (Zhou et al., 2021).","This problem has been addressed in tasks like text summarization and machine translation (Maynez et al., 2020;Zhou et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5059,50-ARR,50-ARR_v2_6@3,50-ARR_v1_6@3,"As shown in Table 1, the answer ""Dubai in Germany"" produced by the generative model FiD (Izacard and Grave, 2021b) is factual incorrect and the answer ""33"" in the second example is not coherent to the question.","As shown in Table 1, the answer ""Dubai in Germany"" produced by the generative model FiD (Izacard and Grave, 2020b) is factual incorrect and the answer ""33"" in the second example is not coherent to the question.","Modify,Fact/Evidence",Fact/Evidence
5060,50-ARR,50-ARR_v2_11@5,50-ARR_v1_11@5,"Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 (Raffel et al., 2019) have become a common approach (Yang et al., 2019;Izacard and Grave, 2021b;Karpukhin et al., 2020).","Later, with the emergence of large-scale pre-trained language models, readers based on pre-trained models such as BERT and T5 Raffel et al., 2019) have become a common approach (Yang et al., 2019;Karpukhin et al., 2020;Izacard and Grave, 2020b).","Modify,Fact/Evidence",Fact/Evidence
5061,50-ARR,50-ARR_v2_13@0,50-ARR_v1_13@0,"Compared to extractive models which extract spans from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework. and Lewis et al. (2020b) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2020a).","Compared to extractive models which extract existing words from the retrieved passages, generative models are able to produce new words out of the retrieved passages, and thus provide a more flexible modeling framework. and Lewis et al. (2020a) concatenate the given question with top retrieved passages and feed the concatenation to the BART model (Lewis et al., 2019).","Modify,Fact/Evidence",Fact/Evidence
5062,50-ARR,50-ARR_v2_13@1,50-ARR_v1_13@1,"Izacard and Grave (2021b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder.","Izacard and Grave (2020b) separately encodes the question with each top retrieved passage, then takes the concatenation of the encoder outputs as input to the decoder.","Modify,Fact/Evidence",Fact/Evidence
5063,50-ARR,50-ARR_v2_2@3,50-ARR_v1_2@3,"In particular, our model is built upon the powerful generative model FiD (Izacard and Grave, 2021b).","In particular, our model is built upon the powerful generative model FiD (Izacard and Grave, 2020b).","Modify,Fact/Evidence",Fact/Evidence
5064,50-ARR,50-ARR_v2_13@3,50-ARR_v1_13@3,"FiD-KD (Izacard and Grave, 2021a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.","FiD-KD (Izacard and Grave, 2020a) is an extension of FiD model that increases the accuracy of passage retrieval by training the dense retriever with the guidance of the FiD reader iteratively.","Modify,Fact/Evidence",Fact/Evidence
5065,50-ARR,50-ARR_v2_15@0,50-ARR_v1_15@0,"Pointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism into the generator.","Pointer-Generator Network (See et al., 2017) is an extension of the sequence-to-sequence model by integrating a copy mechanism (Vinyals et al., 2017) into the generator.","Modify,Fact/Evidence",Fact/Evidence
5066,50-ARR,50-ARR_v2_15@2,50-ARR_v1_15@2,"It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See al., 2017;Gehrmann et al., 2018) and neural machine translation (Luong et al., 2015;Gu et al., 2018), but its application to ODQA has been less explored.","It has been frequently used in natural language tasks like summarization (Gu et al., 2016;See et al., Gehrmann et al., 2018) and neural machine translation (Luong et al., 2014;Gu et al., 2017), but its application to ODQA has been less explored.","Modify,Fact/Evidence",Fact/Evidence
5067,50-ARR,50-ARR_v2_17@0,50-ARR_v1_17@0,Our model follows the standard two-stage retrieverreader framework with a focus on the enhancement of the reader module built upon the FiD reader.,Our model follows the standard two-stage retrieverreader framework with a focus on the enhancement of the reader module built upon the FiD model.,"Modify,Clarity",Clarity
5068,50-ARR,50-ARR_v2_18@3,50-ARR_v1_18@3,"Next, we pass each x i individually to the reader encoder, i.e., the encoder of T5 or BART model, and obtain the hidden representations h i = (h i,1 , h i,2 , . . . , h i,n ) of the questionpassage pair where h i,j ∈ R d and d is the model dimension.","Next, we pass each x i individually to the reader encoder, i.e., the encoder of T5 or BART model, and obtain the hidden representations h i = h i,1 , h i,2 , . . . , h i,n of the question-passage pair where h i,j ∈ R d and d is the model dimension.","Modify,Grammar",Grammar
5069,50-ARR,50-ARR_v2_18@4,50-ARR_v1_18@4,"Finally, we concatenate all the hidden representations of top-k passages {h 1 , . . . , h k } as input to the decoder.","Finally, we concatenate all the hidden representations {h 1 , . . . , h k } as input to the decoder.","Modify,Fact/Evidence",Fact/Evidence
5070,50-ARR,50-ARR_v2_26@1,50-ARR_v1_27@1,"If y t is not present in the top-k retrieved passages, P ctx (y t ) will be zero.","If y t is not present in the top-k retrieved passages, the P ctx (y t ) will be zero.","Modify,Grammar",Grammar
5071,52-ARR,52-ARR_v2_2@9,,Our code is available on github 1 .,,"Add,Fact/Evidence",Fact/Evidence
5072,52-ARR,52-ARR_v2_63@1,,The performance of ToDKAT in MELD was re-released on github 3 .,,"Add,Fact/Evidence",Fact/Evidence
5073,52-ARR,52-ARR_v2_65@2,,"PM used alone is not used as a memory module, but the same backbone is used.",,"Add,Fact/Evidence",Fact/Evidence
5074,52-ARR,52-ARR_v2_65@6,,CoMPM(k) is a model in which PM is trained on ConceptNet.,,"Add,Fact/Evidence",Fact/Evidence
5075,52-ARR,52-ARR_v2_65@7,,"Following previous studies, we use the average vector for each token in PM(k) as the feature of the utterance.",,"Add,Fact/Evidence",Fact/Evidence
5076,52-ARR,52-ARR_v2_65@8,,We use the pre-trained model provided by the site 4 as PM(k).,,"Add,Fact/Evidence",Fact/Evidence
5077,52-ARR,52-ARR_v2_68@6,,"In addition, CoMPM(k) shows better performance than CoM, PM, and CoMPM(s) except for IEMOCAP.",,"Add,Fact/Evidence",Fact/Evidence
5078,52-ARR,52-ARR_v2_68@8,,"In other words, ConceptNet improves the performance of CoMPM, but is not as effective as pretrained memory.",,"Add,Claim",Claim
5079,52-ARR,52-ARR_v2_74@3,,Figure 3 shows the performance of the model according to the ratio of the training data.,,"Add,Fact/Evidence",Fact/Evidence
5080,52-ARR,52-ARR_v2_74@4,,"In MELD and EmoryNLP, even if only 60% and 80% are used, respectively, the performance decreases by only 3 points.",,"Add,Fact/Evidence",Fact/Evidence
5081,52-ARR,52-ARR_v2_25@1,52-ARR_v1_23@1,"In many natural language processing tasks, the effectiveness of the pre-trained language model has been proven, and we also set the initial state of the model to RoBERTa (Liu et al., 2019).","In many natural language processing tasks, the effectiveness of the pre-trained language model has been proven, and we also set the initial state of the model to RoBERTa .","Modify,Fact/Evidence",Fact/Evidence
5082,52-ARR,52-ARR_v2_26@1,52-ARR_v1_24@1,The <cls> token is concatenated at the beginning of the input and the output of the context model is as follows:,The <cls> token is concatenated at the end of the input and the output of the context model is as follows:,"Modify,Fact/Evidence",Fact/Evidence
5083,52-ARR,52-ARR_v2_65@3,52-ARR_v1_64@2,PM used alone predicts emotion only with the utterance of the current turn without considering the context.,"PM, if used alone, does not consider the context and predicts emotions only with the utterance of the current turn.","Modify,Clarity",Clarity
5084,52-ARR,52-ARR_v2_68@9,52-ARR_v1_66@7,"As a result, we regard pre-trained memory as compressed knowledge, which can play a role similar to external knowledge used in cuttingedge systems.","We regard pre-trained memory as compressed knowledge, which can play a role similar to external knowledge used in cutting-edge systems.","Modify,Clarity",Clarity
5085,52-ARR,52-ARR_v2_81@3,52-ARR_v1_77@6,Our approach simply shows a significant performance improvement on baselines that are fine-tuned to the language model and works well for other languages as well as for English.,Our approach simply shows a significant performance improvement on baselines that are fine-tuned to the language model and works well for other languages as well as for English data.,"Modify,Clarity",Clarity
5086,54-ARR,,54-ARR_v1_54@3,,"We report ROUGE-1, ROUGE-2, and ROUGE-L for each dataset.","Delete,Fact/Evidence",Fact/Evidence
5087,54-ARR,,54-ARR_v1_54@4,,"The speedup ratios for English and Chinese models are calculated by the FLOPs reduction relative to BART BASE and CPT BASE , respectively, and averaged over the performed datasets.","Delete,Fact/Evidence",Fact/Evidence
5088,54-ARR,,54-ARR_v1_64@0,,Here we list the statistics of our used language understanding and generation datasets in Table 6 and Table 7.,"Delete,Fact/Evidence",Fact/Evidence
5089,54-ARR,,54-ARR_v1_65@0,,"For small datasets in ELUE, i.e. SST-2, MRPC, and STS-B, we conduct grid search over batch sizes of {16, 32}, learning rates of {2e-5, 3e-5, 5e-5}, number of epochs of {3, 4, 5}, warmup step ratios of {0.1, 0.01}, and weight decays of {0.1, 0.01} with an AdamW optimizer.","Delete,Fact/Evidence",Fact/Evidence
5090,54-ARR,,54-ARR_v1_65@1,,"We select the hyperparameters that achieved the best performance on the development sets, and perform 5 runs with different random seeds to obtain the mean performance and standard deviation.","Delete,Fact/Evidence",Fact/Evidence
5091,54-ARR,,54-ARR_v1_65@2,,"For SNLI, SciTail, and IMDb, we use the same hyperparameters.","Delete,Fact/Evidence",Fact/Evidence
5092,54-ARR,,54-ARR_v1_65@3,,All of the hyperparameters used in our language understanding experiments are given in Table 8.,"Delete,Fact/Evidence",Fact/Evidence
5093,54-ARR,,54-ARR_v1_65@4,,"For English summarization tasks, i.e., CNN/DailyMail and Reddit, we use the same hyperparameters as BART.","Delete,Fact/Evidence",Fact/Evidence
5094,54-ARR,,54-ARR_v1_65@5,,"For Chinese summarization tasks, i.e., TTNews and CSL, we use the same hyperparameters as CPT.","Delete,Fact/Evidence",Fact/Evidence
5095,54-ARR,,54-ARR_v1_66@0,,In previous experiments we assign tokens to the same number of buckets as the number of layers.,"Delete,Fact/Evidence",Fact/Evidence
5096,54-ARR,54-ARR_v2_44@1,,Note that STS-B is a regression task.,,"Add,Fact/Evidence",Fact/Evidence
5097,54-ARR,54-ARR_v2_51@3,,All of the experiments are conducted on GeForce RTX 3090 GPUs.,,"Add,Fact/Evidence",Fact/Evidence
5098,54-ARR,54-ARR_v2_51@4,,More experimental details are given in Appendix A.2.,,"Add,Fact/Evidence",Fact/Evidence
5099,54-ARR,54-ARR_v2_52@0,,Results and Analysis,,"Add,Other",Other
5100,54-ARR,54-ARR_v2_53@3,,"For small datasets, i.e., SST-2 and MRPC, we report the mean and standard deviation over five runs.",,"Add,Fact/Evidence",Fact/Evidence
5101,54-ARR,54-ARR_v2_72@0,,"Copy(H l , h l+1 ) is to copy the hidden states of the exited tokens from H l and concatenate with the updated hidden states h l+1 .",,"Add,Fact/Evidence",Fact/Evidence
5102,54-ARR,54-ARR_v2_72@1,,"By this token-level early exiting, the computation in self-attention and the following feed-forward network is reduced.",,"Add,Fact/Evidence",Fact/Evidence
5103,54-ARR,54-ARR_v2_73@0,,"In particular, we show in Table 10 the saved MACs (Multiply-Accumulate Operations) in each module of one Transformer encoder layer.",,"Add,Fact/Evidence",Fact/Evidence
5104,54-ARR,54-ARR_v2_73@1,,We estimate FLOPs with twice the MACs.,,"Add,Fact/Evidence",Fact/Evidence
5105,54-ARR,54-ARR_v2_53@5,54-ARR_v1_55@3,Table 2 shows that HASHEE achieves a new state-of-the-art ELUE score.,Table 2 shows that HASHEE achieved a new state-of-the-art ELUE score.,"Modify,Grammar",Grammar
5106,54-ARR,54-ARR_v2_54@8,54-ARR_v1_56@8,"To make a more intuitive comparison of these hash functions with different speedup ratios, we also show the ELUE scores on SST-2 and SNLI with ElasticBERT-6L as backbone in Figure 4 .","To make a more intuitive comparison of these hash functions with different speedup ratios, we also show in Figure 4 the ELUE scores on SST-2 and SNLI with ElasticBERT-6L as backbone.","Modify,Clarity",Clarity
5107,54-ARR,54-ARR_v2_58@5,54-ARR_v1_59@5,Results on CSL and TTNews depict that HASHEE can achieve 2.2× speedup relative to CPT while maintaining 97% ROUGE-1.,Results on CSL and TTNews depict that HASHEE can achieve 2.3× speedup relative to CPT while maintaining 97% ROUGE-1.,"Modify,Fact/Evidence",Fact/Evidence
5108,54-ARR,54-ARR_v2_60@2,54-ARR_v1_61@2,"To accelerate PLM inference, there are currently two streams of work: (1) Compressing a cumbersome PLM through knowledge distillation (Sanh et al., 2019;Sun et al., 2019;Jiao et al., 2020), model pruning (Gordon et al., 2020;Michel et al., 2019), quantization (Shen et al., 2020), module replacing (Xu et al., 2020a), etc. (2) Selectively activating parts of the model conditioned on the input, such as Universal Transformer (Dehghani et al., 2019), FastBERT (Liu et al., 2020a), DeeBERT , PABEE , LeeBERT (Zhu, 2021), CascadeBERT (Li et al., 2021a), ElasticBERT (Liu et al., 2021a) and other similar methods (Elbayad et al., 2020;Schwartz et al., 2020;Liao et al., 2021;Xin et al., 2021;Sun et al., 2021b).","To accelerate PLM inference, there are currently two streams of work: (1) Compressing a cumbersome PLM through knowledge distillation (Sanh et al., 2019;Sun et al., 2019;Jiao et al., 2020), model pruning (Gordon et al., 2020;Michel et al., 2019), quantization (Shen et al., 2020), module replacing (Xu et al., 2020a), etc. (2) Selectively activating parts of the model conditioned on the input, such as Universal Transformer (Dehghani et al., 2019), FastBERT (Liu et al., 2020a), DeeBERT , PABEE , LeeBERT (Zhu, 2021), CascadeBERT (Li et al., 2021a), ElasticBERT (Liu et al., 2021a) and other similar methods (Elbayad et al., 2020;Schwartz et al., 2020;Liao et al., 2021;Xin et al., 2021;Sun et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5109,54-ARR,54-ARR_v2_2@5,54-ARR_v1_2@5,"Based on this observation, we propose a simple-yeteffective Hash-based Early Exiting approach (HASHEE) that replaces the learn-to-exit modules with hash functions to assign each token to a fixed exiting layer.","Based on this observation, we propose a simple-yet-effective Hashbased Early Exiting approach (HASHEE) that replaces the learn-to-exit modules with hash functions to assign each token to a fixed exiting layer.","Modify,Grammar",Grammar
5110,55-ARR,,55-ARR_v1_24@2,,"Within a coarse-grained mention, we include nested fine-grained information to each nested named-entity element to give more detail.","Delete,Fact/Evidence",Fact/Evidence
5111,55-ARR,,55-ARR_v1_24@3,,"For example, we annotated Apart from the description for each entity class, 5 we will provide the link to the guideline in the camera ready version.","Delete,Fact/Evidence",Fact/Evidence
5112,55-ARR,,55-ARR_v1_24@4,,We have attached our guideline along with the dataset in this submission we provided annotators with case studies for common annotating complications.,"Delete,Fact/Evidence",Fact/Evidence
5113,55-ARR,,55-ARR_v1_59@0,,"The results show that both WangchanBERTa and XLM-R, while they perform poorer on the head part of the long-tailed distribution, they perform much better on less frequent classes.","Delete,Fact/Evidence",Fact/Evidence
5114,55-ARR,,55-ARR_v1_74@0,,Table 7 shows the mention frequency of each finegrained entity type in our corpus before the traintest split.,"Delete,Fact/Evidence",Fact/Evidence
5115,55-ARR,,55-ARR_v1_74@1,,"For each nested structure, we count all annotated mentions, not just the outermost mention.","Delete,Fact/Evidence",Fact/Evidence
5116,55-ARR,,55-ARR_v1_74@2,,This table reveals classes with extremely low frequency which contribute to poor performances on the tail part of the long-tailed distribution.,"Delete,Fact/Evidence",Fact/Evidence
5117,55-ARR,,55-ARR_v1_75@0,,Incorrect span prediction: mismatches between the length of the predicted spans and the ground truths contribute to a large chunk of prediction errors.,"Delete,Fact/Evidence",Fact/Evidence
5118,55-ARR,,55-ARR_v1_76@0,,"Figure 5 shows that out of 48,009 predicted mentions, 5,165 are incorrect.","Delete,Fact/Evidence",Fact/Evidence
5119,55-ARR,,55-ARR_v1_76@1,,"2,977 out of 5,165 incorrect predicted mentions are due to the fact that the positions of the predicted spans are not correctly aligned with the positions of the ground truths.","Delete,Fact/Evidence",Fact/Evidence
5120,55-ARR,,55-ARR_v1_76@2,,"Often, we can find this error in the predictions for entity mentions that are very long.","Delete,Fact/Evidence",Fact/Evidence
5121,55-ARR,,55-ARR_v1_76@3,,"For example, consider the following text segment:","Delete,Other",Other
5122,55-ARR,55-ARR_v2_23@5,,Appendix A.4 provides an example of how syllable-segmented data can help improve annotation experience.,,"Add,Fact/Evidence",Fact/Evidence
5123,55-ARR,55-ARR_v2_43@3,,The graph shows the distribution of mentions per class in training set sorted by frequency.,,"Add,Fact/Evidence",Fact/Evidence
5124,55-ARR,55-ARR_v2_43@4,,"To analyse the severity of class imbalance, we divided the classes into three groups follow Pareto principle: head, body and tail with samples per classes are 80%, 15% and 5% respectively.",,"Add,Fact/Evidence",Fact/Evidence
5125,55-ARR,55-ARR_v2_43@5,,"More precisely, in body and tail parts, they contain only 20% of samples in training set, but consist of 84 classes from 104 classes.",,"Add,Fact/Evidence",Fact/Evidence
5126,55-ARR,55-ARR_v2_67@3,,"We use the last checkpoint for WanchanBERTa-sh and XLM-R-sh to evaluate, but for the WanchanBERTa-sp and XLM-R-sp, we use the epoch that model does not further improve when training.",,"Add,Fact/Evidence",Fact/Evidence
5127,55-ARR,55-ARR_v2_72@1,,This would violate the tree structure.,,"Add,Claim",Claim
5128,55-ARR,55-ARR_v2_73@1,,"As far as compositional semantics is considered, the nested structure of named entities should not contain overlapping entities in the same level.",,"Add,Claim",Claim
5129,55-ARR,55-ARR_v2_74@0,,Syllable segmentation enhances the annotation experience since there are fewer choices than selecting named-entity boundaries at character-level.,,"Add,Claim",Claim
5130,55-ARR,55-ARR_v2_74@1,,"In addition, Thai syllable segmentation also has a near-perfect accuracy which makes it more suitable word segmentation.",,"Add,Claim",Claim
5131,55-ARR,55-ARR_v2_76@0,,"As for the dataset, we present the word-level version because it is a common preprocess technique.",,"Add,Fact/Evidence",Fact/Evidence
5132,55-ARR,55-ARR_v2_76@1,,We combine the results from word segmentation with the NE boundaries from annotators to ensure that the boundaries for NEs are guaranteed to be correct.,,"Add,Fact/Evidence",Fact/Evidence
5133,55-ARR,55-ARR_v2_23@0,55-ARR_v1_22@0,"To ease and reduce annotation errors, we provide our annotators with syllable-segmented data instead.","To ease and reduce annotation errors from entity span for the annotators, we provided our annotators with syllable-segmented data instead.","Modify,Clarity",Clarity
5134,55-ARR,55-ARR_v2_23@1,55-ARR_v1_22@1,Aroonmanakun (2002) shows that syllable segmentation can resolve many word-level ambiguities in Thai.,Aroonmanakun (2002) shows that syllable level could resolve many word-level ambiguities in Thai.,"Modify,Clarity",Clarity
5135,55-ARR,55-ARR_v2_25@4,55-ARR_v1_24@5,One frequent complication during the annotation process is ambiguous named entities that change their categories depending on the context.,One frequent complication that we found during the annotation process is ambiguous named entities that change their categories depending on the context.,"Modify,Clarity",Clarity
5136,55-ARR,55-ARR_v2_29@0,55-ARR_v1_28@0,"To make our dataset reliable, we require that annotators have a background in linguistics and are properly trained to annotate under our guidelines.","To make our dataset reliable, we required that annotators have a background in linguistics and are properly trained to annotate under our guidelines.","Modify,Grammar",Grammar
5137,55-ARR,55-ARR_v2_29@1,55-ARR_v1_28@1,We also do quality control and evaluation to verify the quality of our dataset.,We also did quality control and evaluation to verify the quality of our dataset.,"Modify,Grammar",Grammar
5138,55-ARR,55-ARR_v2_31@0,55-ARR_v1_30@0,The dataset is manually annotated by 47 linguistically trained annotators.,The dataset was manually annotated by 47 linguistically trained annotators.,"Modify,Grammar",Grammar
5139,55-ARR,55-ARR_v2_31@1,55-ARR_v1_30@1,The annotators have the necessary linguistic background and have passed the N-NER guideline understanding test.,The annotators met the linguistic background requirement and passed the N-NER guideline understanding test.,"Modify,Clarity",Clarity
5140,55-ARR,55-ARR_v2_31@2,55-ARR_v1_30@2,We provide a communication channel to discuss annotation issues among the annotators and the project manager.,We provided a communication channel to discuss annotation issues among the annotators and the project manager.,"Modify,Grammar",Grammar
5141,55-ARR,55-ARR_v2_31@3,55-ARR_v1_30@3,"We use Datasaur.ai 5 platform for the annotators to label the data according to our guideline, using syllable span highlighting to designate each span as a specific entity.","We used Datasaur.ai 6 platform for the annotators to label the data according to our guideline, using syllable span highlighting to designate each span as a specific entity.","Modify,Fact/Evidence",Fact/Evidence
5142,55-ARR,55-ARR_v2_33@0,55-ARR_v1_32@0,"Firstly, we manually check the quality of annotated randomly data to find common mistakes.","Firstly, we manually checked the quality of annotated randomly data to find common mistakes.","Modify,Grammar",Grammar
5143,55-ARR,55-ARR_v2_33@1,55-ARR_v1_32@1,"To find more annotation errors, we extract only the first layer to train a simple flatten CRF model.","To find more annotation errors, we extracted only the first layer to train a simple flatten CRF model.","Modify,Grammar",Grammar
5144,55-ARR,55-ARR_v2_33@3,55-ARR_v1_32@3,"Combining the errors found by both humans and the model, we conduct an error analysis to find the pattern of mistakes from annotators.","Combining the errors found by both humans and the model, we conducted an error analysis to find the pattern of mistakes from annotators.","Modify,Grammar",Grammar
5145,55-ARR,55-ARR_v2_33@4,55-ARR_v1_32@4,"Frequent annotation mistakes are inconsistency tagging, incorrect tagging, and failure to follow the guideline.","We found prominent annotation mistake patterns, for example, inconsistency tagging, incorrect tagging, and failure to follow the guideline.","Modify,Clarity",Clarity
5146,55-ARR,55-ARR_v2_33@5,55-ARR_v1_32@5,Then we compile a list of annotation errors and send it back to the annotators to reassess.,Then we compiled a list of annotation errors and sent it back to the annotators to reassess.,"Modify,Grammar",Grammar
5147,55-ARR,55-ARR_v2_33@6,55-ARR_v1_33@0,"After the first update, we use a rule-based program to filter overlapping annotations, which violate our guideline, then list all the documents with overlapping annotations.","After the first update, we used a rule-based program to filter overlapping annotations, which did not follow our guideline, then listed all the documents with overlapping annotations.","Modify,Clarity",Clarity
5148,55-ARR,55-ARR_v2_33@7,55-ARR_v1_33@1,"Moreover, we employ a gazetteer to filter mislabeled entities.","Moreover, we employed a gazetteer to filter mislabeled entities.","Modify,Grammar",Grammar
5149,55-ARR,55-ARR_v2_33@8,55-ARR_v1_33@2,"Later, we report the list of overlapping documents and the list of mislabeled entities to the annotators to correct all the annotation errors.","Later, we reported the list of overlapping documents and the list of mislabeled entities to the annotators to correct all the annotation errors.","Modify,Grammar",Grammar
5150,55-ARR,55-ARR_v2_34@0,55-ARR_v1_34@0,"After the second update, to inspect our dataset quality, we train an N-NER model from Shibuya and Hovy (2020) to see whether our data can be used to train the model and to filter out more annotation errors.","After the second update, to inspect our dataset quality, we trained an N-NER model from Shibuya and Hovy (2020) to see whether our data can be used to trained the model and to filter out more annotation errors.","Modify,Grammar",Grammar
5151,55-ARR,55-ARR_v2_34@2,55-ARR_v1_35@0,We then use the model's prediction errors to filter out more annotation mistakes and report them to the annotators for another correction session.,We then used the model's prediction errors to filter out more annotation mistakes and reported them to the annotators for another correction session.,"Modify,Grammar",Grammar
5152,55-ARR,55-ARR_v2_35@0,55-ARR_v1_36@0,"Then, we split our dataset into 80% for a training set and 20% for a test set, then re-annotate the test set with two annotators to validate.","Then, we split our dataset into 80% for a training set and 20% for a testing set, then re-annotated all the testing set with two annotators to validate.","Modify,Clarity",Clarity
5153,55-ARR,55-ARR_v2_35@1,55-ARR_v1_36@1,"Finally, the third annotator correct the annotation mismatches between the first two annotators.","Finally, the third annotator corrected the annotation mismatches between the first two annotators.","Modify,Grammar",Grammar
5154,55-ARR,55-ARR_v2_36@0,55-ARR_v1_37@0,We use the Cohen's Kappa agreement score to benchmark the reliability of our dataset.,We used the Cohen's Kappa agreement score to benchmark the reliability of our dataset.,"Modify,Grammar",Grammar
5155,55-ARR,55-ARR_v2_36@1,55-ARR_v1_37@1,"We compute the inter-annotator agreement using eight sampled documents composed of 2,922 tokens.","We computed the inter-annotator agreement using eight sampled documents composed of 2,922 tokens.","Modify,Grammar",Grammar
5156,55-ARR,55-ARR_v2_2@1,55-ARR_v1_2@1,"Thai N-NER consists of 264,798 mentions, 104 classes, and a maximum depth of 8 layers obtained from news articles and restaurant reviews, a total of 4894 documents.","Thai N-NER consists of 264,798 mentions, 104 classes, and a maximum depth of 8 layers obtained from 4,894 documents in the domains of news articles and restaurant reviews.","Modify,Clarity",Clarity
5157,55-ARR,55-ARR_v2_58@0,55-ARR_v1_58@0,"Interestingly, the deep learning baseline models, WangchanBERTa and XLM-R, can perform on par with all the current SOTA models.","Interestingly, the deep learning baseline model, WangchanBERTa-sh, outperforms all the current SOTA models.","Modify,Fact/Evidence",Fact/Evidence
5158,55-ARR,55-ARR_v2_59@0,55-ARR_v1_60@0,"By having better performances on body and tail parts, while maintaining a high performance on the head part, both of the deep learning baseline models can obtain competitive results compared to all the SOTA models on our corpus.","By having better performances on body and tail parts, while maintaining a competitive performance on the head part, WangchanBERTa-sh outperforms all the SOTA models on our corpus.","Modify,Fact/Evidence",Fact/Evidence
5159,55-ARR,55-ARR_v2_60@1,55-ARR_v1_61@1,"However, compared to the monolingual encoder (WangchanBERTa), XLM-R models' performances are better than the monolingual models.","However, compared to the monolingual encoder (WangchanBERTa), XLM-R models' performances are only slightly poorer than the monolingual models.","Modify,Fact/Evidence",Fact/Evidence
5160,55-ARR,55-ARR_v2_60@5,55-ARR_v1_61@5,"The performances across all models quickly deteriorate as we move from the part of the long-tailed distribution, which represents common classes, to the tail part, which represents infrequent classes.","The performances across all models quickly deteriorate as we move from the head part of the long-tailed distribution, which represents common classes, to the tail part, which represents infrequent classes.","Modify,Clarity",Clarity
5161,55-ARR,55-ARR_v2_60@6,55-ARR_v1_61@6,"Additionally, there are gaps between precision and recall for all models.","Additionally, notice there are gaps between precision and recall for all models.","Modify,Clarity",Clarity
5162,55-ARR,55-ARR_v2_60@9,55-ARR_v1_61@9,"This result suggests that in order to improve the overall performance, we should pay attention to recall.","This result suggests that to improve the overall performance, we should pay attention to the recall.","Modify,Clarity",Clarity
5163,55-ARR,55-ARR_v2_63@2,55-ARR_v1_64@2,"(3) Ambiguity between fine-grained classes: there are 1,160 fewer errors when evaluated with coarse-grained ground truths.","(3) Ambiguity between fine-grained classes: there are 1,149 fewer errors when evaluated with coarse-grained ground truths.","Modify,Fact/Evidence",Fact/Evidence
5164,55-ARR,55-ARR_v2_63@3,55-ARR_v1_64@3,"(4) Scarcity of training samples: the model only made 1,380 prediction attempts for mentions in tail classes.","(4) Scarcity of training samples: the model only made 1,422 prediction attempts for mentions in tail classes.","Modify,Fact/Evidence",Fact/Evidence
5165,55-ARR,55-ARR_v2_63@4,55-ARR_v1_64@4,"While 1,081 of the predictions are correct, there are 3,511 ground truths.","While 1,101 of the predictions are correct, there are 3,680 ground truths.","Modify,Fact/Evidence",Fact/Evidence
5166,55-ARR,55-ARR_v2_66@11,55-ARR_v1_67@11,It is also the dialect for official usage and is often used as a written language by Thai internet users.,It is also the dialect for official usage and is often used as a written language by Thai users.,"Modify,Clarity",Clarity
5167,55-ARR,55-ARR_v2_66@15,55-ARR_v1_67@15,We will also publish the source code and the models' weights from our experiments to assist the NLP community in N-NER research and reduce unnecessary energy usage from training the models.,We will also publish the source code and all the models' weights from our experiments to assist the NLP community in N-NER research and reduce unnecessary energy usage from training the models.,"Modify,Clarity",Clarity
5168,55-ARR,55-ARR_v2_14@0,55-ARR_v1_14@0,"In terms of the number of classes, it is also worthnoting that three out of six corpora has less than ten classes and only NNE (Ringland et al., 2019) has more than 100 classes.","In terms of the number of classes, it is also worthnoting that three out of six corpora has less than ten and only NNE (Ringland et al., 2019) has more than 100 classes.","Modify,Clarity",Clarity
5169,55-ARR,55-ARR_v2_14@7,55-ARR_v1_14@7,"The dataset is composed of 2,000 abstracts, 92,681 mentions from 9,533 sentences with 32 entity types.","The dataset composed of 2,000 abstracts, 92,681 mentions from 9,533 sentences with 32 entity types.","Modify,Grammar",Grammar
5170,55-ARR,55-ARR_v2_2@4,55-ARR_v1_2@4,"From the experimental results, we obtain two key findings.","From the experimental results, we obtained two key findings.","Modify,Grammar",Grammar
5171,55-ARR,55-ARR_v2_17@2,55-ARR_v1_15@9,"On the other hand, for Thai, there are only coarsegrained flatten-NER datasets which are publicly available (Tirasaroj andAroonmanakun, 2009; Boonkwan et al., 2020).","On the other hand, for Thai, there are only coarsegrained flatten-NER datasets which are publicly available.","Modify,Fact/Evidence",Fact/Evidence
5172,55-ARR,55-ARR_v2_2@5,55-ARR_v1_2@5,"First, all models produce poor F1 scores in the tail region of the class distribution.","First, all models produced poor F1 scores in the tail region of the class distribution.","Modify,Grammar",Grammar
5173,55-ARR,55-ARR_v2_21@0,55-ARR_v1_20@0,"To create the dataset, we gather 4,894 documents from two different domains: news articles and restaurant reviews.","To create the dataset, we gathered 4,894 documents from two different domains: news articles and restaurant reviews.","Modify,Grammar",Grammar
5174,55-ARR,55-ARR_v2_21@1,55-ARR_v1_20@1,"In particular, we obtain 4,396 news articles from Prachathai 3 , a news website, and 498 restaurant reviews from Wongnai 4 , a crowd-sourced restaurant review platform.","In particular, we obtained 3,196 news articles from Prachathai 3 , a news website, and 1,698 restaurant reviews from Wongnai 4 , a crowd-sourced restaurant review platform.","Modify,Fact/Evidence",Fact/Evidence
5175,56-ARR,,56-ARR_v1_68@0,,Ethical Consideration,"Delete,Other",Other
5176,56-ARR,,56-ARR_v1_69@0,,We do not anticipate any major ethical concerns; topic mining is a fundamental problem in natural language processing.,"Delete,Claim",Claim
5177,56-ARR,,56-ARR_v1_69@1,,"A minor consideration is the potential for certain types of hidden biases to be introduced into our results (i.e., performance regressions for some subset of the data in spite of overall performance gains), for example by a biased selection of topical phrases.","Delete,Claim",Claim
5178,56-ARR,,56-ARR_v1_69@2,,"We did not observe any such issues in our experiments, and indeed these considerations seem low-risk for the specific datasets studied here.","Delete,Claim",Claim
5179,56-ARR,56-ARR_v2_47@0,,"To generate the training corpus, we use English Wikipedia 3 and extract text with hyper links as phrases.",,"Add,Fact/Evidence",Fact/Evidence
5180,56-ARR,56-ARR_v2_47@1,,"Phrases have the same entity ids from Wikidata 4 or have the same mentions are considered as the same phrases (i.e., phrases have the same semantics).",,"Add,Fact/Evidence",Fact/Evidence
5181,56-ARR,56-ARR_v2_47@2,,We enumerate all sentence pairs containing the same phrase as positive pairs in contrastive learning.,,"Add,Fact/Evidence",Fact/Evidence
5182,56-ARR,56-ARR_v2_47@3,,"After processing, the pre-training dataset has 11.6 million sentences and 108.8 million training instances.",,"Add,Fact/Evidence",Fact/Evidence
5183,56-ARR,56-ARR_v2_48@2,,"Our pretraining learning rate is 5e-5, batch size is 100 and our model is optimized by AdamW in 1 epoch.",,"Add,Fact/Evidence",Fact/Evidence
5184,56-ARR,56-ARR_v2_50@5,,"It contains 18,307 sentences from PubMed articles, with 15,953 chemical and 13,318 disease entities.",,"Add,Fact/Evidence",Fact/Evidence
5185,56-ARR,56-ARR_v2_50@6,,"(3) MIT Movie (MIT-M) (Liu et al., 2013) contains 12,218 sentences with Title and Person entities.",,"Add,Fact/Evidence",Fact/Evidence
5186,56-ARR,56-ARR_v2_50@8,,Finetuning Setup.,,"Add,Other",Other
5187,56-ARR,56-ARR_v2_50@9,,The learning rate for finetuning is 1e-5.,,"Add,Fact/Evidence",Fact/Evidence
5188,56-ARR,56-ARR_v2_50@10,,"We select t (percent of instances) from {5, 10, 20, 50}.",,"Add,Fact/Evidence",Fact/Evidence
5189,56-ARR,56-ARR_v2_50@11,,The probability p of keeping phrase mentions unchanged and temperature τ in contrastive loss are the same as in pre-training settings.,,"Add,Fact/Evidence",Fact/Evidence
5190,56-ARR,56-ARR_v2_50@12,,We apply K-Means to get pseudo labels for all experiments.,,"Add,Fact/Evidence",Fact/Evidence
5191,56-ARR,56-ARR_v2_50@13,,"Because UCTOPIC is an unsupervised method, we use all data to finetune and evaluate.",,"Add,Claim",Claim
5192,56-ARR,56-ARR_v2_50@14,,All results for finetuning are the best results during training process.,,"Add,Claim",Claim
5193,56-ARR,56-ARR_v2_50@15,,"We follow previous clustering works (Xu et al., 2017;Zhang et al., 2021) and adopt Accuracy (ACC) and Normalized Mutual Information (NMI) to evaluate different approaches.",,"Add,Fact/Evidence",Fact/Evidence
5194,56-ARR,56-ARR_v2_50@16,,Compared Baseline Methods.,,"Add,Other",Other
5195,56-ARR,56-ARR_v2_50@17,,"To demonstrate the effectiveness of our pre-training method and finetuning with cluster-assisted contrastive learning (CCL), we compare baseline methods from two aspects:",,"Add,Fact/Evidence",Fact/Evidence
5196,56-ARR,56-ARR_v2_51@0,,(1) Pre-trained token or phrase representations:,,"Add,Other",Other
5197,56-ARR,56-ARR_v2_53@0,,(2) Fine-tuning methods based on pre-trained representations of UCTOPIC.,,"Add,Other",Other
5198,56-ARR,56-ARR_v2_55@0,,Experimental Results.,,"Add,Other",Other
5199,56-ARR,56-ARR_v2_70@2,,Results are shown in table 5.,,"Add,Fact/Evidence",Fact/Evidence
5200,56-ARR,56-ARR_v2_70@3,,"PNTM and UCTOPIC achieve similar tf-idf scores, because the two methods use the same phrase lists extracted from spaCy.",,"Add,Fact/Evidence",Fact/Evidence
5201,56-ARR,56-ARR_v2_70@4,,"UCTOPIC extracts the most diverse phrases in a topic, because our phrase representations are more context-aware.",,"Add,Claim",Claim
5202,56-ARR,56-ARR_v2_45@0,56-ARR_v1_45@0,"In this section, we evaluate the effectiveness of UCTOPIC pre-training by contrastive learning.","In this section, we evaluate the effectiveness of contrastive learning.","Modify,Fact/Evidence",Fact/Evidence
5203,56-ARR,56-ARR_v2_55@2,56-ARR_v1_50@4,There are two reasons: (1) All words in MIT-M dataset are lower case which is inconsistent with our pretraining dataset.,There are two reasons: (1) All words in MIT-M are lower case which is inconsistent with our pretraining dataset.,"Modify,Clarity",Clarity
5204,56-ARR,56-ARR_v2_55@5,56-ARR_v1_50@7,"Hence, UCTOPIC can obtain limited contextual information with short sentences.",UCTOPIC can obtain limited contextual information with short sentences.,"Modify,Clarity",Clarity
5205,56-ARR,56-ARR_v2_55@6,56-ARR_v1_50@8,"However, the performance decay caused by the two reasons can be eliminated by our CCL finetuning on datasets since on MIT-M UCTOPIC achieves better results (0.661 NMI) than Phrase-BERT (0.575 NMI) after CCL.","However, the performance decay caused by the two reasons can be eliminated by our CCL finetuning on dataset since on MIT-M UCTOPIC achieves better results (0.661 NMI) than Phrase-BERT (0.575 NMI) after CCL.","Modify,Grammar",Grammar
5206,56-ARR,56-ARR_v2_59@0,56-ARR_v1_54@0,"In this section, we apply UCTOPIC on topical phrase mining and conduct human evaluation to show our model outperforms previous topic model baselines.","In this section, we apply UCTOPIC on topical phrase mining and conduct human evaluation to show our model outperforms previous baselines.","Modify,Clarity",Clarity
5207,56-ARR,56-ARR_v2_59@3,56-ARR_v1_54@3,"Before CCL finetuning, we obtain the number of topics for each dataset by computing the Silhouette Coefficient (Rousseeuw, 1987).","Before CCL finetuning, we obtain the number of topics for each dataset by computing the Silhouette Coefficient (Rousseeuw, 1987) (details in Appendix A.1).","Modify,Fact/Evidence",Fact/Evidence
5208,56-ARR,56-ARR_v2_64@2,56-ARR_v1_57@12,TopMine uses phrases produced by itself.,TopMine produced phrases by itself.,"Modify,Clarity",Clarity
5209,56-ARR,56-ARR_v2_67@1,56-ARR_v1_60@1,The phrase intrusion task involves a set of questions asking humans to discover the 'intruder' phrase from other phrases.,The phrase intrusion task involves a set of questions asking humans to discover the 'intruder' phrase from other phrases (details in Appendix B.1).,"Modify,Fact/Evidence",Fact/Evidence
5211,56-ARR,56-ARR_v2_68@7,56-ARR_v1_61@6,UCTOPIC can maintain high precision with a large n when the precision of other models decreases.,Figure 4 shows the results; we can see that UCTOPIC substantially outperforms other models and maintain high precision with a large n when the precision of other models decreases.,"Split+Modify,Clarity",Clarity
5212,56-ARR,56-ARR_v2_60@0,56-ARR_v1_70@0,"Specifically, we randomly sample 10K phrases from the dataset and apply K-Means clustering on pre-trained UCTOPIC phrase representations with different numbers of cluster.",We randomly sample 10K phrases from dataset and apply K-Means clustering on pre-trained UCTOPIC phrase representations with different cluster numbers.,"Modify,Clarity",Clarity
5213,56-ARR,56-ARR_v2_60@1,56-ARR_v1_70@1,We compute Silhouette Coefficient scores for different topic numbers; the number with the largest score will be used as the topic number in a dataset.,We compute Silhouette Coefficient score for different topic numbers and the number with the largest score will be used as the topic number in a dataset.,"Modify,Grammar",Grammar
5214,56-ARR,56-ARR_v2_67@4,56-ARR_v1_71@2,We sample 50 questions for each method and each dataset (600 questions in total) and shuffle all questions.,We sample 50 questions for each method and each dataset (600 questions total) and shuffle all questions.,"Modify,Grammar",Grammar
5215,56-ARR,56-ARR_v2_67@5,56-ARR_v1_71@3,"Because these questions are sampled independently, we asked 4 annotators to answer these questions and each annotator answers 150 questions on average.","Because these questions are sampled independently, we asked 4 annotators to answer these questions and each annotator answers 150 questions in average.","Modify,Grammar",Grammar
5216,56-ARR,56-ARR_v2_68@9,56-ARR_v1_72@0,"Basically, informative phrases cannot be very common phrases in a corpus (e.g., ""good food"" in Gest) and we use tf-idf to evaluate the ""importance"" of a phrase.","Informative phrases cannot be very common phrases in a corpus (e.g., ""good food"" in Gest) and we use tf-idf to evaluate the ""importance"" of a phrase.","Modify,Clarity",Clarity
5217,56-ARR,56-ARR_v2_68@12,56-ARR_v1_72@3,"In our experiments, a document is a sentence in a review.","In our experiments, a document is a sentence is a review.","Modify,Grammar",Grammar
5218,56-ARR,56-ARR_v2_69@0,56-ARR_v1_73@0,"In addition, we hope that our phrases are diverse enough in a topic instead of expressing the same meaning (e.g., ""good food"" and ""great food"").","Furthermore, we hope that our phrases are diverse enough in a topic instead of expressing the same meaning (e.g., ""good food"" and ""great food"").","Modify,Clarity",Clarity
5219,56-ARR,56-ARR_v2_69@2,56-ARR_v1_73@2,"Formally, given a list of phrases [p 1 , p 2 , . . . , p n ], we tokenize the phrases into a word list w = [w p 1 1 , w p 1 2 , . . . , w pn m ]; w is the set of unique words in w.","Formally, given a list of phrases [p 1 , p 2 , . . . , p n ], we tokenize the phrases into a word list w = [w p 1 1 , w p 1 2 , . . . , w pn m ] and w is the set of unique words in w.","Modify,Grammar",Grammar
5220,56-ARR,56-ARR_v2_69@4,56-ARR_v1_73@4,"We only evaluate coherent topics labeled in phrase coherence; the coherent topic numbers of Phrase-LDA are smaller than others, hence we evaluate the other three models.","We only evaluate coherent topics labeled in phrase coherence and the coherent topics numbers of Phrase-LDA are obviously smaller than others, hence we evaluate the other three models.","Modify,Grammar",Grammar
5221,57-ARR,,57-ARR_v1_17@1,,"For different operations, we use different trainable parameters W α and b α .","Delete,Fact/Evidence",Fact/Evidence
5222,57-ARR,,57-ARR_v1_23@0,,Experimental Setup,"Delete,Other",Other
5223,57-ARR,,57-ARR_v1_24@0,,"We evaluate our model on four IUR benchmarks from different domains and languages: REWRITE (Chinese, Su et al., 2019), Restoration-200K (Chinese, Pan et al., 2019), TASK (English, Quan et al., 2019), CANARD (English, Elgohary et al., 2019).","Delete,Fact/Evidence",Fact/Evidence
5224,57-ARR,,57-ARR_v1_24@1,,More statistical details for datasets are shown in the Appendix.,"Delete,Fact/Evidence",Fact/Evidence
5225,57-ARR,57-ARR_v2_8@9,,"Although these methods maintain some similarities between the incomplete utterance and the rewritten utterance (i.e., the overlap between them), it is difficult for these methods to explicitly model the semantic structure, especially the difference between the two utterances, ignoring the information in the incomplete utterance, such as which tokens are more likely to be replaced and which positions are more likely to require the insertion of new tokens.",,"Add,Claim",Claim
5226,57-ARR,57-ARR_v2_13@3,,"For example, the parsing result of the incomplete utterance ""No, he does not care"" (''不，他不关心"") is an S-V structure and lack object element, thus we put [ELLIP] at the end of the sentence to get the ellipsis-oriented query template as ""No, he does not care [ELLIP]"" (''不, 他不关心 [ELLIP]"").",,"Add,Fact/Evidence",Fact/Evidence
5227,57-ARR,57-ARR_v2_13@4,,Other circumstances are detailed in the Appendix.,,"Add,Fact/Evidence",Fact/Evidence
5228,57-ARR,57-ARR_v2_25@4,,"Since Chinese is a pro-drop language where coreference and ellipsis often happen, the improvement confirms that QUEEN is superior in finding the correct ellipsis and referring back positions.",,"Add,Claim",Claim
5229,57-ARR,57-ARR_v2_25@5,,The results on data sets of different domains and languages also show that our model is robust and effective.,,"Add,Fact/Evidence",Fact/Evidence
5230,57-ARR,57-ARR_v2_25@7,,It is clear that query is important to improve performance on all evaluation metrics.,,"Add,Claim",Claim
5231,57-ARR,57-ARR_v2_25@8,,"Meanwhile, only using coreference-oriented or ellipsis-oriented template still improves the performance, as it can also bring semantic structure information.",,"Add,Fact/Evidence",Fact/Evidence
5232,57-ARR,57-ARR_v2_25@10,,"As we remove the heavy model U-net of RUN and apply the simple network, our Edit Operation Scoring Network is faster than previous SOTA RUN.",,"Add,Fact/Evidence",Fact/Evidence
5233,57-ARR,57-ARR_v2_26@0,,We also do a case study in the Appendix.,,"Add,Fact/Evidence",Fact/Evidence
5234,57-ARR,57-ARR_v2_26@1,,"Our model avoids the uncontrolled situations that the generation-based model is prone to, and our model can more easily capture the correct semantic span.",,"Add,Claim",Claim
5235,57-ARR,57-ARR_v2_29@0,,Acknowledgements,,"Add,Other",Other
5236,57-ARR,57-ARR_v2_30@0,,"This paper is supported by the National Science Foundation of China under Grant No.61876004, 61936012, the National Key R&D Program of China under Grand No.2020AAA0106700.",,"Add,Fact/Evidence",Fact/Evidence
5237,57-ARR,57-ARR_v2_31@0,,Ethics Consideration,,"Add,Other",Other
5238,57-ARR,57-ARR_v2_32@0,,We collect our data from public datasets that permit academic use.,,"Add,Fact/Evidence",Fact/Evidence
5239,57-ARR,57-ARR_v2_32@1,,The open-source tools we use are freely accessible online without copyright conflicts.,,"Add,Fact/Evidence",Fact/Evidence
5240,57-ARR,57-ARR_v2_34@5,,"Extra findings During the experiment, we find two interesting points: (i) As [COREF] and [ELLIP] are sparse respectively, we use a unified token [UNK] to replace [COREF] and [ELLIP] in the query to relieve the sparsity.",,"Add,Fact/Evidence",Fact/Evidence
5241,57-ARR,57-ARR_v2_34@6,,"(ii) In most cases, if there is the referring back in the utterance, there is generally no ellipsis in the utterance.",,"Add,Fact/Evidence",Fact/Evidence
5242,57-ARR,57-ARR_v2_34@7,,Redundant [ELLIP] tokens can't bring correct guided information in this case.,,"Add,Fact/Evidence",Fact/Evidence
5243,57-ARR,57-ARR_v2_34@8,,"Therefore, once we construct Coreference-oriented Query Template successfully, we will not try to construct the Ellipsis-oriented Query Template.",,"Add,Fact/Evidence",Fact/Evidence
5244,57-ARR,57-ARR_v2_34@9,,Our experimental results are improved by the above two tricks.,,"Add,Fact/Evidence",Fact/Evidence
5245,57-ARR,57-ARR_v2_34@11,,CANARD is constructed from English Context Question Answering.,,"Add,Fact/Evidence",Fact/Evidence
5246,57-ARR,57-ARR_v2_34@12,,We fellow the same data split as their original paper.,,"Add,Fact/Evidence",Fact/Evidence
5247,57-ARR,57-ARR_v2_36@0,,We initialize QUEEN with bert-base-uncased for English and bert-base-chinese for Chinese.,,"Add,Fact/Evidence",Fact/Evidence
5248,57-ARR,57-ARR_v2_36@1,,"We use Adam (Kingma and Ba, 2015) with learning rate 1e-5. 2021) and Su 2 .",,"Add,Fact/Evidence",Fact/Evidence
5249,57-ARR,57-ARR_v2_36@2,,We refer readers to their paper for more details.,,"Add,Fact/Evidence",Fact/Evidence
5250,57-ARR,57-ARR_v2_37@1,,Both models are implemented in PyTorch on a single NVIDIA V100.,,"Add,Fact/Evidence",Fact/Evidence
5251,57-ARR,57-ARR_v2_37@2,,The batch size is set to 16.,,"Add,Fact/Evidence",Fact/Evidence
5252,57-ARR,57-ARR_v2_37@3,,"Meanwhile, In order to fairly compare the speed of the two networks, we performed Distant Supervision and Query Construction before comparing.",,"Add,Fact/Evidence",Fact/Evidence
5253,57-ARR,57-ARR_v2_37@4,,The results are shown in Table 7.,,"Add,Fact/Evidence",Fact/Evidence
5254,57-ARR,57-ARR_v2_16@0,57-ARR_v1_15@0,"Since pre-trained language models have been proven to be strongly effective on several natural language processing tasks, we employ BERT (Devlin et al., 2019) to encode our input text to get the contextualized hidden representation H = (h q 1 , ..., h q k , ..., h q M , h 1 1 , ..., h n i , ..., h N L N ).","Since pre-trained language models have been proven to be effective on several NLP tasks, we employ BERT (Devlin et al., 2019) to encoding our input text to get the contextualized hidden representation H = (h q 1 , ..., h q k , ..., h q M , h 1 1 , ..., h n i , ..., h N L N )) for each token.","Modify,Clarity",Clarity
5255,57-ARR,57-ARR_v2_18@1,57-ARR_v1_17@2,R is a transformation matrix from RoPE to inject position information and s α ij is the score for α-th edit operation from i-th token in dialogue history to j-th token in incomplete utterance.,R i is a transformation matrix from RoPE to inject position information and s α ij is the score for α-th edit operation from i-th token in dialogue history to j-th token in incomplete utterance.,"Modify,Grammar",Grammar
5256,57-ARR,57-ARR_v2_23@3,57-ARR_v1_34@2,"Above methods need to generate rewritten utterances from scratch, neglecting the semantic structure between a rewritten utterance and the original incomplete utterance.","Above methods need to generate rewritten utterances from scratch, neglecting the main semantic structure of rewritten utterances.","Modify,Claim",Claim
5257,57-ARR,57-ARR_v2_39@1,57-ARR_v1_35@1,The first example illustrates cases when RUN inserts unexpected characters into the wrong places.,The first example illustrates the cases when RUN inserts unexpected characters into the wrong places.,"Modify,Grammar",Grammar
5258,57-ARR,57-ARR_v2_2@1,57-ARR_v1_2@1,"However, previous works do not consider the semantic structural information between incomplete utterance and rewritten utterance or model the semantic structure implicitly and insufficiently.","However, previous works do not consider the semantic structural information in utterances or use it implicitly.","Modify,Claim",Claim
5259,57-ARR,57-ARR_v2_3@0,57-ARR_v1_2@2,"To address this problem, we propose a QUEry-Enhanced Network (QUEEN).",We propose a QUEry-Enhanced Network (QUEEN) to solve this problem.,"Modify,Clarity",Clarity
5260,57-ARR,57-ARR_v2_3@1,57-ARR_v1_2@3,"Firstly, our proposed query template explicitly brings guided semantic structural knowledge between the incomplete utterance and the rewritten utterance making model perceive where to refer back to or recover omitted tokens.","Firstly, our proposed query template explicitly brings guided semantic structural knowledge between the incomplete utterance and the rewritten utterance.","Modify,Claim",Claim
5261,57-ARR,57-ARR_v2_8@15,57-ARR_v1_8@4,"We regard the rewritten utterance as the output from a series of edit operations on the incomplete utterance by constructing a token-pair edit operation matrix, which attempts to model the the overlap between the incomplete utterance between the rewritten utterance.",We regard the rewritten utterance as the output from a series of edit operations on the incomplete utterance by constructing a token-pair edit operation matrix.,"Modify,Claim",Claim
5262,57-ARR,57-ARR_v2_3@2,57-ARR_v1_2@4,"Then, we adopt a fast and effective edit operation scoring network to model the relation between two tokens.","Then, we adopt a fast and effective edit operation scoring network for decoding.","Modify,Fact/Evidence",Fact/Evidence
5263,57-ARR,57-ARR_v2_10@3,57-ARR_v1_10@3,The latter module tries to capture the semantic structural relations between tokens by constructing an edit operation matrix.,The latter module tries to capture the semantic structural relations between words by constructing an edit operation matrix.,"Modify,Clarity",Clarity
5264,57-ARR,57-ARR_v2_3@3,57-ARR_v1_2@5,"Benefiting from extra information and the well-designed network, QUEEN achieves state-of-the-art performance on several public datasets.","Benefiting from extra semantic structural information and the well-designed network, QUEEN achieves state-of-the-art performance on several public datasets.","Modify,Clarity",Clarity
5265,58-ARR,58-ARR_v2_32@9,,Transfer-based DocNMT could successfully identify and translate the correct number of input sentences for student languages.,,"Add,Claim",Claim
5266,58-ARR,58-ARR_v2_33@0,,Results and Analysis,,"Add,Other",Other
5267,58-ARR,58-ARR_v2_17@0,58-ARR_v1_17@0,"For training, we adopt a two-stage method: we first pretrain a multilingual SenNMT on sentence level data for all languages; then, we finetune it to obtain multilingual DocNMT on a mix of document level data from teacher languages and sentence level data from student languages.","For training, we adopt a two-stage method where we first pretrain a multilingual SenNMT followed by finetuning on document data to obtain multilingual DocNMT.","Modify,Fact/Evidence",Fact/Evidence
5268,58-ARR,58-ARR_v2_17@2,58-ARR_v1_17@2,"For evaluation, we distinguish sentencelevel inference (SenInfer) from its document-level counterpart (DocInfer).","For evaluation, we distinguish sentence-level (SenInfer) with document-level (DocInfer) inference.","Modify,Clarity",Clarity
5269,58-ARR,58-ARR_v2_22@3,58-ARR_v1_24@2,"For evaluation, we use the WMT dev and test sets (Barrault et al., 2020) available for each language pair (from 2013 to 2020).","For evaluation, we use the latest WMT evaluation sets (dev and test set) (Barrault et al., 2020) available for each language pair.","Modify,Fact/Evidence",Fact/Evidence
5270,58-ARR,58-ARR_v2_2@6,58-ARR_v1_2@6,We observe that more teacher languages and adequate data balance both contribute to better transfer quality.,We observe that more teacher languages and adequate data schedule both contribute to better transfer quality.,"Modify,Clarity",Clarity
5271,58-ARR,58-ARR_v2_2@7,58-ARR_v1_2@7,"Surprisingly, the transfer is less sensitive to the data condition, where multilingual DocNMT delivers decent performance with either backtranslated or genuine document pairs.","Surprisingly, the transfer is less sensitive to the data type, where multilingual DocNMT delivers decent performance with either back-translated or genuine document pairs.","Modify,Clarity",Clarity
5272,58-ARR,58-ARR_v2_32@1,58-ARR_v1_34@1,"We work on En-De, Europarl-7, where we sample 50 source documents from the test set, and translate them into the target language using the corresponding models and decoding techniques.","For each source language, we sampled 50 test documents which were translated into the target language using the corresponding models and decoding techniques.","Modify,Fact/Evidence",Fact/Evidence
5273,58-ARR,58-ARR_v2_32@2,58-ARR_v1_34@2,The translated documents are presented to bilingual human raters who are native in the non-English locale.,The translated documents were presented to bilingual human raters who are native in the non-English locale.,"Modify,Grammar",Grammar
5274,58-ARR,58-ARR_v2_32@3,58-ARR_v1_34@3,The raters are asked to evaluate translation qualities while taking the full source document context into account.,The raters were asked to evaluate translation qualities while taking the full source document context into account.,"Modify,Grammar",Grammar
5275,58-ARR,58-ARR_v2_32@5,58-ARR_v1_34@5,"For each model, the scores are aggregated across the entire test corpus and the average scores are reported.","For each model, the scores were aggregated across the entire test corpus and the average scores were reported.","Modify,Grammar",Grammar
5276,58-ARR,58-ARR_v2_32@6,58-ARR_v1_34@6,"To ensure a fair diversity of ratings, each rater rates no more than 6 documents per model; an average of 18 raters evaluated each model independently.","To ensure a fair diversity of ratings, each rater has rated no more than 6 documents per model; an average of 18 raters evaluated each model independently.","Modify,Grammar",Grammar
5277,58-ARR,58-ARR_v2_49@3,58-ARR_v1_49@3,"Besides, whether the gains really come from contextual modeling is still unclear.","Besides, whether the gains really come from contextual modeling is unclear.","Modify,Clarity",Clarity
5278,58-ARR,58-ARR_v2_58@3,58-ARR_v1_57@3,We observe that different teacher languages yield slightly different transfer behaviors and transferring to Fr looks more promising. .,We observe that different teacher languages yield slightly different transfer behavior and transferring to Fr looks more promising. .,"Modify,Grammar",Grammar
5279,58-ARR,58-ARR_v2_5@0,58-ARR_v1_5@0,"In this paper, we study zero-shot generalization for DocNMT -the ability to attain plausible Doc-NMT quality for some focused (student) language pair(s), with only parallel sentences for the student but parallel documents for other (teacher) languages in the multilingual mix.","In this paper, we study zero-shot generalization for DocNMT -the ability to attain plausible Doc-NMT quality for some focused (student) language pair(s) with only parallel sentences for the student, but parallel documents for other (teacher) languages in the multilingual mix.","Modify,Grammar",Grammar
5280,58-ARR,58-ARR_v2_5@1,58-ARR_v1_5@1,The high-level research question we seek to answer is illustrated in Figure 1.,The high-level research question we seek to answer is in Figure 1.,"Modify,Clarity",Clarity
5281,58-ARR,58-ARR_v2_6@1,58-ARR_v1_6@1,"We perform our analysis using a simple concatenation based DocNMT, where consecutive sentences are chained into one sequence for translation.",We perform our analysis using simple concatenation based Doc-NMT with consecutive sentences chained into one sequence for translation.,"Modify,Grammar",Grammar
5282,58-ARR,58-ARR_v2_7@4,58-ARR_v1_7@4,Our main findings are summarized below:,Our main findings:,"Modify,Clarity",Clarity
5283,58-ARR,58-ARR_v2_8@0,58-ARR_v1_8@0,"• Zero-shot transfer from sentences to documents is feasible through multilingual Doc-NMT modeling, particularly when evaluated with document-specific metrics. This is partially supported by human evaluation. • Transfer quality is strongly affected by the number of teacher languages that use document level data and the data balance for documents. Higher quality is achieved with more teacher languages and adequate document schedule, where the optimal balance varies across scenarios. • Surprisingly, transfer via back-translated documents performs comparable to transfer via genuine parallel documents. • Zero-shot transfer from high-resource document level languages and to low-resource sentence level ones is relatively easier, resulting in better transfer results.","• Zero-shot transfer from sentences to documents is feasible through multilingual Doc-NMT modeling, particularly when evaluated with document-specific metrics. This is partially supported by human evaluation. • Transfer quality is strongly affected by the number of teacher languages that use document level data and the data schedule for documents. Higher quality is achieved with more teacher languages and adequate document schedule, where the optimal schedule varies across scenarios. • Surprisingly, transfer via back-translated documents performs comparable to transfer via genuine parallel documents. • Zero-shot transfer from high-resource document level languages to low-resource sentences level ones is easier, resulting in better quality compared to other scenarios.","Modify,Clarity",Clarity
5284,58-ARR,58-ARR_v2_10@0,58-ARR_v1_10@0,"Document-level MT Integrating document-level information meaningfully into NMT is a challenging task, which has inspired research not only on exploring advanced context-aware neural architectures, including simple concatenation-based models (Tiedemann and Scherrer, 2017;Junczys-Dowmunt, 2019;Lopes et al., 2020), multi-source models (Jean et al., 2017;Bawden et al., 2018;Zhang et al., 2018), hierarchical models (Miculicich et al., 2018;Zheng et al., 2020;, multi-pass models (Voita et al., 2019;Yu et al., 2020;Mansimov et al., 2021) and dynamic context models (Kang et al., 2020), to name a few.","Document-level MT Integrating document-level information meaningfully into NMT is a challenging task and has inspired research not only on exploring advanced context-aware neural architectures, including simple concatenation-based models (Tiedemann and Scherrer, 2017;Junczys-Dowmunt, 2019;Lopes et al., 2020), multi-source models (Jean et al., 2017;Bawden et al., 2018;Zhang et al., 2018), hierarchical models (Miculicich et al., 2018;Zheng et al., 2020;, multi-pass models (Voita et al., 2019;Mansimov et al., 2020) and dynamic context models (Kang et al., 2020), to name a few.","Modify,Fact/Evidence",Fact/Evidence
5285,58-ARR,58-ARR_v2_12@0,58-ARR_v1_12@0,"Zero-Shot Transfer via Multilinguality Multilingual modeling often clusters sentences of similar meaning from different languages within a shared semantic space (Kudugunta et al., 2019;. Such representation space is hypothesized to enable zero-shot transfer, delivering improved performance in many cross-lingual tasks (Eriguchi et al., 2018;Hu et al., 2020;Chi et al., 2021;Ruder et al., 2021), especially based on large-scale pretrained multilingual Transformers (Devlin et al., 2019;Conneau and Lample, 2019;Xue et al., 2021).","Zero-Shot Transfer via Multilinguality Multilingual modeling often clusters sentences of similar meaning from different languages within a shared semantic space (Kudugunta et al., 2019;. Such representation space hypothesized to enable zero-shot transfer, delivering improved performance in many cross-lingual tasks (Eriguchi et al., 2018;Hu et al., 2020;Chi et al., 2021;Ruder et al., 2021), especially based on large-scale pretrained multilingual Transformers (Devlin et al., 2019;Conneau and Lample, 2019;Xue et al., 2021).","Modify,Grammar",Grammar
5286,58-ARR,58-ARR_v2_2@4,58-ARR_v1_2@4,"Using simple concatenation-based DocNMT, we explore the effect of 3 factors on the transfer: the number of teacher languages with document level data, the balance between document and sentence level data at training, and the data condition of parallel documents (genuine vs. backtranslated).","Using simple concatenation-based DocNMT, we explore the effect of 3 factors on the transfer: the number of teacher languages with document level data, the balance between document and sentence level data at training, and the data type of document level data (genuine vs. back-translated).","Modify,Fact/Evidence",Fact/Evidence
5287,58-ARR,58-ARR_v2_16@0,58-ARR_v1_16@0,"We employ the concatenation-based method with a D2D structure for DocNMT, where D consecutive sentences in a document are concatenated into one sequence for translation (Junczys-Dowmunt, 2019;Sun et al., 2020).","We employ the concatenation-based method with D2D structure for DocNMT, where D consecutive sentences in a document are concatenated into one sequence for translation (Junczys-Dowmunt, 2019;Sun et al., 2020).","Modify,Grammar",Grammar
5288,59-ARR,,59-ARR_v1_37@5,,We can see that the standard deviations are small and the performance over different sets of samples shows the similar trend.,"Delete,Fact/Evidence",Fact/Evidence
5289,59-ARR,,59-ARR_v1_37@6,,This further highlights that the probing success of Contrastive-Probe is not due the selected pre-training sentences.,"Delete,Fact/Evidence",Fact/Evidence
5290,59-ARR,,59-ARR_v1_37@7,,"Intuitively, the contrastive self-retrieving game ( §4) is equivalent to the formulation of the cloze-style filling task, hence tuning the underlying PLMs makes them better suited for knowledge elicitation needed during probing (like 'rewiring' the switchboards).","Delete,Fact/Evidence",Fact/Evidence
5291,59-ARR,,59-ARR_v1_37@8,,"Additionally, from Figure 4 we can also observe that different relations exhibit very different trends during pre-training steps of Contrastive-Probe and peak under different steps, suggesting that we need to treat different types of relational knowledge with different tuning depths when infusing knowledge.","Delete,Fact/Evidence",Fact/Evidence
5292,59-ARR,,59-ARR_v1_37@9,,We leave further exploration of this to future work.,"Delete,Claim",Claim
5293,59-ARR,,59-ARR_v1_37@10,,Probing by Relations.,"Delete,Other",Other
5294,59-ARR,,59-ARR_v1_45@3,,"They each propose decoding methods that generate multi-token answers, which we have shown to work poorly on MedLAMA.","Delete,Fact/Evidence",Fact/Evidence
5295,59-ARR,,59-ARR_v1_45@4,,"BioLAMA (Sung et al., 2021) is a concurrent work that also releases a benchmark for biomedical knowledge probing.","Delete,Fact/Evidence",Fact/Evidence
5296,59-ARR,,59-ARR_v1_45@5,,"We provide a comparison between LAMA, BioLAMA and MedLAMA in terms of (# relations, # queries, avg # answers per query, avg # characters per answer) in the Appendix. 12 Probing via Prompt Engineering.","Delete,Fact/Evidence",Fact/Evidence
5297,59-ARR,,59-ARR_v1_45@6,,"Knowledge probing is sensitive to what prompt is used (Jiang et al., 2020b).","Delete,Fact/Evidence",Fact/Evidence
5298,59-ARR,,59-ARR_v1_45@7,,"To bootstrap the probing performance, Jiang et al. (2020b) mine more prompts and ensemble them during inference.","Delete,Fact/Evidence",Fact/Evidence
5299,59-ARR,,59-ARR_v1_45@8,,"Later works parameterised the prompts and made them trainable (Shin et al., 2020b;Fichtel et al., 2021;Qin and Eisner, 2021).","Delete,Fact/Evidence",Fact/Evidence
5300,59-ARR,,59-ARR_v1_45@9,,"We have opted out promptengineering methods that require training data in this work, as tuning the prompts are essentially tuning an additional (parameterised) model on top of PLMs.","Delete,Fact/Evidence",Fact/Evidence
5301,59-ARR,,59-ARR_v1_45@10,,"As pointed out by Fichtel et al. (2021), prompt tuning requires large amounts of training data from the task.","Delete,Fact/Evidence",Fact/Evidence
5302,59-ARR,,59-ARR_v1_45@11,,"Since task training data is used, the additional model parameters are exposed to the target data distribution and can solve the set set by overfitting to such biases .","Delete,Fact/Evidence",Fact/Evidence
5303,59-ARR,,59-ARR_v1_45@14,,Biomedical Knowledge Probing.,"Delete,Other",Other
5304,59-ARR,,59-ARR_v1_45@15,,Nadkarni et al. (2021) train PLMs as KB completion models and test on the same task to understand how much knowledge is in biomedical PLMs.,"Delete,Fact/Evidence",Fact/Evidence
5305,59-ARR,,59-ARR_v1_45@16,,"BioLAMA focuses on the continuous prompt learning method OptiPrompt (Zhong et al., 2021), which also requires ground-truth training data from the task.","Delete,Fact/Evidence",Fact/Evidence
5306,59-ARR,,59-ARR_v1_45@17,,"Overall, compared to BioLAMA, we have provided a more comprehensive set of probing experiments and analysis, including proposing a novel probing technique and providing human evaluations of model predictions.","Delete,Fact/Evidence",Fact/Evidence
5307,59-ARR,,59-ARR_v1_50@0,,Table 5 shows the detailed relation names and their manual prompts of our MedLAMA.,"Delete,Fact/Evidence",Fact/Evidence
5308,59-ARR,,59-ARR_v1_53@3,,"Moreover, Sung et al. (2021) only use two existing probing approach on their proposed BioLAMA, while in this paper we further proposed a new probing approach Contrastive-Probe.","Delete,Fact/Evidence",Fact/Evidence
5309,59-ARR,59-ARR_v2_5@1,,This work was done at the University of Cambridge.,,"Add,Fact/Evidence",Fact/Evidence
5310,59-ARR,59-ARR_v2_19@4,,"Specifically, we utilize the cloze-style query with a single [Mask] token as the model input.",,"Add,Fact/Evidence",Fact/Evidence
5311,59-ARR,59-ARR_v2_19@5,,The model then predicts the answer entities that correspond to the [Mask] token in an autoregressive manner.,,"Add,Fact/Evidence",Fact/Evidence
5312,59-ARR,59-ARR_v2_19@6,,An illustration is provided in Figure 2(b).,,"Add,Fact/Evidence",Fact/Evidence
5313,59-ARR,59-ARR_v2_20@4,,"Alternatively, the retrieval-based probing are applied to address this issue.",,"Add,Fact/Evidence",Fact/Evidence
5314,59-ARR,59-ARR_v2_20@5,,"Instead of generating answers based on the PLM vocabulary, the retrieval-based approach finds answers by ranking the knowledge graph candidate entities based on the query and entity representations, or the entity generating scores.",,"Add,Fact/Evidence",Fact/Evidence
5315,59-ARR,59-ARR_v2_21@0,,"To probe PLMs on MedLAMA, we use mask average , an approach that takes the average log probabilities of entity's individual tokens to rank the candidates.",,"Add,Fact/Evidence",Fact/Evidence
5316,59-ARR,59-ARR_v2_21@1,,The retrieval-based approaches address the multi-token issue by restricting the output space to the valid answer set and can be used to probe knowledge in different types of PLMs (e.g. BERT vs. fastText; ).,,"Add,Fact/Evidence",Fact/Evidence
5317,59-ARR,59-ARR_v2_21@2,,"However, previous works only report results based on the type-restricted candidate set (e.g. relation) which we observed to decay drastically under the full entity set.",,"Add,Claim",Claim
5318,59-ARR,59-ARR_v2_29@1,,This objective function encourages f to create similar representations for any query-answer pairs from the same sentence and dissimilar representations for queries/answers belonging to different sentences.,,"Add,Fact/Evidence",Fact/Evidence
5319,59-ARR,59-ARR_v2_30@0,,Retrieval-based Probing.,,"Add,Other",Other
5320,59-ARR,59-ARR_v2_30@1,,"For probing step, the query is created based on the prompt-based template for each knowledge triple , as shown in the following:",,"Add,Fact/Evidence",Fact/Evidence
5321,59-ARR,59-ARR_v2_39@3,,"In Figure 7, we further plot the layer-wise probing performance of PubMedBERT over different relations.",,"Add,Fact/Evidence",Fact/Evidence
5322,59-ARR,59-ARR_v2_39@4,,"Surprisingly, we find that different relations do not show the same probing performance trends over layers.",,"Add,Fact/Evidence",Fact/Evidence
5323,59-ARR,59-ARR_v2_39@5,,"For example, with only the first 3 layers, PubMedBERT achieves the best accuracy (>15%) on relation 11 queries.",,"Add,Fact/Evidence",Fact/Evidence
5324,59-ARR,59-ARR_v2_39@6,,"This result demonstrates that both relation types and PLM layers are confounding variables in capturing factual knowledge, which helps to explain the difference of training steps over relations in Figure 4.",,"Add,Fact/Evidence",Fact/Evidence
5325,59-ARR,59-ARR_v2_39@7,,This result also suggests that layer-wise and relation-wise training could be the key to effectively infuse factual knowledge for PLMs.,,"Add,Claim",Claim
5326,59-ARR,59-ARR_v2_40@0,,In-depth Analysis of Contrastive-Probe,,"Add,Other",Other
5327,59-ARR,59-ARR_v2_45@0,,Comparing with BioLAMA,,"Add,Other",Other
5328,59-ARR,59-ARR_v2_46@3,,"We can see that, without additional training data from the biomedical knowledge facts, Contrastive-Probe reaches a promising performance compared with OptiPrompt approach, which needs further training data.",,"Add,Claim",Claim
5329,59-ARR,59-ARR_v2_46@4,,"Additionally, since Mask Predict and OptiPrompt require using the MLM head, it is impossible to compare a model without MLM head being released (e.g. PubMedBERT).",,"Add,Claim",Claim
5330,59-ARR,59-ARR_v2_46@5,,"In contrast, our Contrastive-Probe not only provides a good indicator of comparing these models in terms of their captured knowledge, but also makes layerwise knowledge probing possible.",,"Add,Claim",Claim
5331,59-ARR,59-ARR_v2_47@0,,Limitations of Contrastive-Probe,,"Add,Other",Other
5332,59-ARR,59-ARR_v2_48@1,,"However, we have noticed that different models and different probing datasets have different optimal training steps.",,"Add,Fact/Evidence",Fact/Evidence
5333,59-ARR,59-ARR_v2_48@2,,"To truly 'rewire' the most knowledge out of each PLMs, we need a unified validation set for checkpoint selection.",,"Add,Fact/Evidence",Fact/Evidence
5334,59-ARR,59-ARR_v2_48@3,,What the validation set should be and how to guarantee its fairness require further investigation.,,"Add,Claim",Claim
5335,59-ARR,59-ARR_v2_49@0,,Performance not very stable.,,"Add,Other",Other
5336,59-ARR,59-ARR_v2_49@1,,We have noticed that using different contrastive tuning corpus as well as different random seeds can lead to a certain variance of their probing performances (see Table 5).,,"Add,Fact/Evidence",Fact/Evidence
5337,59-ARR,59-ARR_v2_49@2,,"To mitigate such issue, we use average perfor-Probe Model CTD wikidata UMLS acc@1 acc@5 acc@1 acc@5 acc@1 acc@5 mance of 10 runs on 10 randomly sampled corpus.",,"Add,Fact/Evidence",Fact/Evidence
5338,59-ARR,59-ARR_v2_50@0,,Improving the stability of Contrastive-Probe and investigating its nature is a future challenge.,,"Add,Claim",Claim
5339,59-ARR,59-ARR_v2_60@0,,We train our Contrastive-Probe based on 10k sentences which are randomly sampled from the original pre-training corpora of the corresponding PLMs.,,"Add,Fact/Evidence",Fact/Evidence
5340,59-ARR,59-ARR_v2_60@1,,"Since most of the biomedical BERTs use PubMed texts as their pre-training corpora, for all biomedical PLMs we sampled random sentences from a version of PubMed corpus used by BlueBERT model (Peng et al., 2019), while for BERT we sampled sentences from its original Wikitext corpora.",,"Add,Fact/Evidence",Fact/Evidence
5341,59-ARR,59-ARR_v2_60@2,,"For the hyperparamters of our Contrastive-Probe, Table 8 lists our search options and the best parameters used in our paper.",,"Add,Fact/Evidence",Fact/Evidence
5342,59-ARR,59-ARR_v2_2@6,59-ARR_v1_2@6,"While Contrastive-Probe pushes the acc@10 to 24%, the performance gap remains notable.","While Contrastive-Probe pushes the acc@10 to 28%, the performance gap still remains notable.","Modify,Fact/Evidence",Fact/Evidence
5343,59-ARR,59-ARR_v2_2@7,59-ARR_v1_2@7,Our human expert evaluation suggests that the probing performance of our Contrastive-Probe is underestimated as UMLS does not comprehensively cover all existing factual knowledge.,Our human expert evaluation suggests that the probing performance of our Contrastive-Probe is still under-estimated as UMLS still does not include the full spectrum of factual knowledge.,"Modify,Clarity",Clarity
5344,59-ARR,59-ARR_v2_35@4,59-ARR_v1_31@4,"Both mask predict and retrieval-based approaches are tested under both the general domain and biomedical domain BERT models, i.e. Bert-based-uncased (Devlin et al., 2019), BlueBERT (Peng et al., 2019), BioBERT , PubMedBERT (Gu et al., 2020).","Both mask predict and retrieval-based approaches are tested under both the general domain and biomedical domain BERT models, i.e. Bert-based-uncased (Devlin et al., 2019), BlueBERT , BioBERT that are pre-trained on large biomedical corpora.","Modify,Fact/Evidence",Fact/Evidence
5345,59-ARR,59-ARR_v2_4@0,59-ARR_v1_4@0,"Pre-trained language models (PLMs; Devlin et al. 2019;) have orchestrated incredible progress on myriads of few-or zero-shot language understanding tasks, by pre-training model parameters in a task-agnostic way and transferring knowledge to specific downstream tasks via finetuning (Brown et al., 2020;Petroni et al., 2021).","Pre-trained language models (PLMs; ) have orchestrated incredible progress on myriads of few-or zero-shot language understanding tasks, by pre-training model parameters in a task-agnostic way and transferring knowledge to specific downstream tasks via finetuning (Brown et al., 2020;Petroni et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5346,59-ARR,59-ARR_v2_37@3,59-ARR_v1_33@3,"In contrast, our Contrastive-Probe obtains absolute improvements by up-to ∼ 5% and ∼ 21% on acc@1 and acc10 respectively comparing with the three existing approaches, which validates its effectiveness on measuring the knowledge probing performance.","In contrast, our Contrastive-Probe obtains absolute improvements by up-to ∼ 6% and ∼ 25% on acc@1 and acc10 respectively comparing with the three existing approaches, which validates its effectiveness on measuring the knowledge probing performance.","Modify,Fact/Evidence",Fact/Evidence
5347,59-ARR,59-ARR_v2_37@4,59-ARR_v1_33@4,"In particular, PubMedBERT model obtains the best probing performance (5.71% in accuracy) for these biomedical queries, validating its effectiveness of capturing biomedical knowledge comparing with other PLMs (i.e. BERT, BlueBERT and BioBERT).","In particular, PubMedBERT model obtains the best probing performance (7.32% in accuracy) for these biomedical queries, validating its effectiveness of capturing biomedical knowledge comparing with other PLMs (i.e. BERT, BlueBERT and BioBERT).","Modify,Fact/Evidence",Fact/Evidence
5348,59-ARR,59-ARR_v2_37@7,59-ARR_v1_36@1,Table 5 shows the probing results over the full and hard sets.,Table 4 shows the probing results over the full and hard sets (detailed macro and micro accuracies are provided in Appendix).,"Modify,Fact/Evidence",Fact/Evidence
5349,59-ARR,59-ARR_v2_37@10,59-ARR_v1_36@4,"While PubMedBERT performs the best among all the pure pre-trained models, SapBERT (Liu et al., 2021a) and CoderBERT (Yuan et al., 2020) (which are the knowledge infused PubMedBERT) further push performance to 8% and 30.41% on acc@1 and acc@10 metrics respectively, highlighting the benefits of knowledge infusion pre-training.","While PubMedBERT performs the best under all metrics, CoderBERT (which is the knowledge infused PubMedBERT) achieves better performance on micro acc@1, highlighting the benefits of knowledge infusion pre-training.","Modify,Fact/Evidence",Fact/Evidence
5350,59-ARR,59-ARR_v2_55@2,59-ARR_v1_47@2,"To reduce the gap, we further proposed a novel contrastive recipe which rewires the underlying PLMs without using any probing-specific data and illustrated that with a lightweight pre-training their accuracies could be pushed to 24%.","To reduce the gap, we further proposed a novel contrastive recipe which rewires the underlying PLMs without using any probing-specific data and illustrated that with a lightweight pre-training their accuracies could be pushed to 28%.","Modify,Fact/Evidence",Fact/Evidence
5351,59-ARR,59-ARR_v2_46@0,59-ARR_v1_53@0,"During the writing of this work, we noticed a concurrent work to ours that also released a biomedical knowledge probing benchmark, called Bio-LAMA Sung et al. (2021).","During the writing of this work, we notice that Sung et al. (2021) also released a biomedical knowledge probing benchmark, called BioLAMA, which is a work concurrent to ours.","Modify,Clarity",Clarity
5352,59-ARR,59-ARR_v2_46@1,59-ARR_v1_53@1,"In Table 6, we compare MedLAMA with LAMA (Petroni et al., 2019) and BioLAMA in terms of data statistics.","In Table 6, we compare our MedLAMA with LAMA (Petroni et al., 2019) and BioLAMA (Sung et al., 2021) in terms of their statistics.","Modify,Fact/Evidence",Fact/Evidence
5353,59-ARR,59-ARR_v2_46@2,59-ARR_v1_53@2,"We found that there is only 1 overlapped relation (i.e., may treat) between BioLAMA and MedLAMA, and no overlap exists on the queries.","We found that there is only 1 overlapped relation (i.e. may treat) between BioLAMA and our MedLAMA, and no same query can be found.","Modify,Clarity",Clarity
5354,59-ARR,59-ARR_v2_10@0,59-ARR_v1_11@0,"We further highlight that the elicited knowledge by Contrastive-Probe is not gained from the additional random sentences, but from the original pre-trained parameters, which echos the previous finding of Liu et al. (2021b); Glavaš and Vulić (2021); Su et al. (2021Su et al. ( , 2022.","We further highlight that the elicited knowledge by Contrastive-Probe is not gained from the additional random sentences, but from the original pretrained parameters, which echos the previous finding of Liu et al. (2021b); Glavaš and Vulić (2021).","Modify,Fact/Evidence",Fact/Evidence
5355,59-ARR,59-ARR_v2_14@7,59-ARR_v1_15@7,Table 2 shows the detailed relation names and their corresponding prompts.,See Appendix for the detailed relation names and their corresponding prompts.,"Modify,Fact/Evidence",Fact/Evidence
5356,6-ARR,,6-ARR_v1_36@2,,"By guiding the language model to continue generating slot values naturally, we leverage knowledge from pretrained language models to our slot tagging tasks.","Delete,Fact/Evidence",Fact/Evidence
5357,6-ARR,,6-ARR_v1_39@0,,"The inference procedure can be concluded as the following steps: (1) We use the label mapping to map all labels {l 1 , ..., l |L| } in the label set to { l1 , ..., l|L| }.","Delete,Fact/Evidence",Fact/Evidence
5358,6-ARR,,6-ARR_v1_39@1,,"(2) For each mapped label lj , we sample one input sentence s i , then fill them in the prepared template to get prompted input x ij .","Delete,Fact/Evidence",Fact/Evidence
5359,6-ARR,,6-ARR_v1_39@2,,"(3) We use the fine-tuned pre-trained language model to conduct a controlled generation procedure in which generation word-list is constraint in the original sentence along with structure control tokens t ∈ ŝi = s i ∪ {<NONE>, <SEP>, <END>}.","Delete,Fact/Evidence",Fact/Evidence
5360,6-ARR,,6-ARR_v1_39@3,,"Specially, for the control tokens, we use ""none"" as <NONE> token if there's no corresponding slot value in s; we use "";"" as <SEP> token to divide more than one corresponding slot values and we use ""."" as <END> token to indicate the end of the generation.","Delete,Fact/Evidence",Fact/Evidence
5361,6-ARR,,6-ARR_v1_41@2,,(3) We feed the prompted inputs into our model to generate corresponding slot values following the textgeneration procedure until reaching the max length or having a full stop generated.,"Delete,Fact/Evidence",Fact/Evidence
5362,6-ARR,,6-ARR_v1_43@0,,"The Iterative Prediction Strategy completes the whole prediction process by revising the slot values that were ""none"" in the first iteration.","Delete,Fact/Evidence",Fact/Evidence
5363,6-ARR,,6-ARR_v1_43@3,,"Motivated by this, we construct another template for the Iterative Prediction Strategy, which concatenates those predicted prompts and places them before the unpredicted prompted inputs.","Delete,Fact/Evidence",Fact/Evidence
5364,6-ARR,,6-ARR_v1_43@4,,Below we introduce the strategy for the inference and training stages in detail.,"Delete,Fact/Evidence",Fact/Evidence
5365,6-ARR,,6-ARR_v1_44@0,,"At the inference time, as shown in Figure 3, we take the predicted slot labels in the first round into inputs for models to process.","Delete,Fact/Evidence",Fact/Evidence
5366,6-ARR,,6-ARR_v1_44@1,,"We denote the original input as s, and the i-th recognized labels in the first iteration as l r i ∈ L R , the j-th unpredicted labels (whose slot values are ""none"") as l u j ∈ L U (L U = L \ L R ).","Delete,Fact/Evidence",Fact/Evidence
5367,6-ARR,,6-ARR_v1_44@2,,So for unrecognized slot label l u j the prompted inputs are constructed as:,"Delete,Fact/Evidence",Fact/Evidence
5368,6-ARR,,6-ARR_v1_46@0,,"During the training time, we simulate the cases where the slots are not recognized so as to enable the model to revise the none slot values.","Delete,Fact/Evidence",Fact/Evidence
5369,6-ARR,,6-ARR_v1_46@1,,We do this by manually constructing none slot value examples.,"Delete,Fact/Evidence",Fact/Evidence
5370,6-ARR,,6-ARR_v1_46@2,,"Specifically, for each original sentence s, we randomly select some occurred labels l s (e.g., ""arrival"" in Fig. 3) and combine them with the nonoccurred labels (e.g., ""price"" in Fig. 3) to construct the unrecognized set L U .","Delete,Fact/Evidence",Fact/Evidence
5371,6-ARR,,6-ARR_v1_46@3,,"The rest of the occurred labels (e.g., ""departure"" and ""time"" in Fig. 3) form the recognized set L R .","Delete,Fact/Evidence",Fact/Evidence
5372,6-ARR,,6-ARR_v1_47@0,,"Given the i-th recognized slot label l r i ∈ L R and the j-th unrecognized slot label l u j ∈ L U , the prompted inputs are constructed as follows:","Delete,Fact/Evidence",Fact/Evidence
5373,6-ARR,,6-ARR_v1_48@3,,"It outputs the corresponding slot values if l u j is the selected label l s (If multiple slot values are generated, we separate them with "";"" ).","Delete,Fact/Evidence",Fact/Evidence
5374,6-ARR,,6-ARR_v1_52@0,,Setting with Only In-domain data,"Delete,Other",Other
5375,6-ARR,,6-ARR_v1_53@0,,"Datasets To evaluate our proposed method in only few-shot in-domain data without source domain knowledge transfer, we conduct experiments on three few-shot datasets: MIT-Restaurant Review (Liu et al., 2013), MIT-Movie Review (Liu et al., 2013) and MIT-Movie-Hard.","Delete,Fact/Evidence",Fact/Evidence
5376,6-ARR,,6-ARR_v1_54@0,,"Implements We conduct experiments with K ∈ {10, 20, 50, 100, 200, 500} shot few-shot settings to fully evaluate the performance of our method in all three datasets.","Delete,Fact/Evidence",Fact/Evidence
5377,6-ARR,,6-ARR_v1_54@1,,"Our proposed method employs GPT2-small (Radford et al., 2019) pre-trained model as the base model for fine-tuning, and no new parameters are introduced.","Delete,Fact/Evidence",Fact/Evidence
5378,6-ARR,,6-ARR_v1_54@2,,"Besides, we set the learning rate=6.25e − 5 and batch size=2 for few-shot training.","Delete,Fact/Evidence",Fact/Evidence
5379,6-ARR,,6-ARR_v1_54@3,,"For all our experiments, we finetune the model only on few-shot support set for 2~4 epochs with the AdamW optimizer and linear decaying scheduler.","Delete,Fact/Evidence",Fact/Evidence
5380,6-ARR,,6-ARR_v1_55@0,,"Baselines In our experiments, we provide competitive conventional sequence labeling method, forward template-based method and some methods pretrained on data-rich source domains.","Delete,Fact/Evidence",Fact/Evidence
5381,6-ARR,,6-ARR_v1_71@1,,Noting that we can directly compare with TransferBERT for both our methods first pretrained on source domains and then finetuned on each few-shot domain respectively without any fewshot learning tricks.,"Delete,Fact/Evidence",Fact/Evidence
5382,6-ARR,,6-ARR_v1_77@1,,"Unlike sentence-level tasks, prompting method is very complicated for slot tagging and NER tasks.","Delete,Claim",Claim
5383,6-ARR,,6-ARR_v1_78@4,,"Different from directly learning the few-shot slot tagging model, some researches explore to reformulate the slot tagging into other NLP tasks, Ma et al. (2021a) reforms slot tagging into a reading comprehension task, treats slot tagging as a retrieval task, Coope et al. (2020) uses span extracting task to extract slot and predict corresponding label and Cui et al. (2021) leverages prompts for few-shot NER.","Delete,Fact/Evidence",Fact/Evidence
5384,6-ARR,,6-ARR_v1_78@5,,"Different from those methods above, we are the first to reformulate slot tagging task into a prompt-based generation task.","Delete,Claim",Claim
5385,6-ARR,6-ARR_v2_15@0,,"Slot tagging aims at finding key slots within a sentence, such as time or location entities.",,"Add,Claim",Claim
5386,6-ARR,6-ARR_v2_15@1,,"Given an input sentence x = (x 1 , x 2 , . . . , x n ) as a sequence of words, a slot tagging model extracts all M slot label-values pairs y = {(l i , s i )} M i=1 in the sentence, where l i is the ith label in the label set L and s k j = {x j , ..., x k } is a word span starting from x j and ending with x k .",,"Add,Fact/Evidence",Fact/Evidence
5387,6-ARR,6-ARR_v2_24@1,,"Given sentence x = (x 1 , x 2 , . . . , x n ) as input, these method predicts the best-match sequence labels y = (y 1 , y 2 , ..., y n ).",,"Add,Fact/Evidence",Fact/Evidence
5388,6-ARR,6-ARR_v2_24@2,,"To predict slots with multiple words, sequence labeling approaches adopt a ""BIO"" labeling strategy, which uses ""B"" to mark the begin word of a slot, ""I"" to mark the inner words of a slot and ""O"" to mark non-slot words.",,"Add,Fact/Evidence",Fact/Evidence
5389,6-ARR,6-ARR_v2_28@1,,"To identify the slot label for a word span s j i = {x i , ..., x j } in sentence x, previous works construct templates, e.g., ""[x] [s j i ] is a [z] entity"", and prompt a pretrained language model with such templates to predict label-related words [z] (Cui et al., 2021).",,"Add,Fact/Evidence",Fact/Evidence
5390,6-ARR,6-ARR_v2_28@2,,"For example in the Fig. 2(b), predicting the time slot can be achieved as ""book a flight from Beijing to New York tomorrow morning. tomorrow morning is a time entity.""",,"Add,Fact/Evidence",Fact/Evidence
5391,6-ARR,6-ARR_v2_31@1,,The overview of proposed method is shown in Fig. 3.,,"Add,Fact/Evidence",Fact/Evidence
5392,6-ARR,6-ARR_v2_34@0,,"Label Mapping Before prompt construction, we first need to convert each label into a word form that can be easily understood by the pre-trained language model.",,"Add,Fact/Evidence",Fact/Evidence
5393,6-ARR,6-ARR_v2_34@2,,"For example, in Fig. 3, we convert the label set L = {from.Loc, to.Loc, Time, Price} to a natural language label set L = { departure, arrival, time, price}.",,"Add,Fact/Evidence",Fact/Evidence
5394,6-ARR,6-ARR_v2_35@0,,"Inverse Template Prompt template is a piece of sentence with blanks, which is used to modify the original inputs and get prompting inputs for a pretrained language model.",,"Add,Fact/Evidence",Fact/Evidence
5395,6-ARR,6-ARR_v2_35@1,,"To achieve inverse prompting, our template fills in an original sentence and a label as prefixes and subsequently leaves blanks for the LM to generate the corresponding slot values.",,"Add,Fact/Evidence",Fact/Evidence
5396,6-ARR,6-ARR_v2_35@3,,"In order to recognize the case that there's no corresponding entity of the queried slot type, we introduce <NONE> token to pad the output, and in practice, we use ""none"" as <NONE> token to make the model output more natural.",,"Add,Fact/Evidence",Fact/Evidence
5397,6-ARR,6-ARR_v2_37@0,,"Till now, we have presented the construction of the inverse prompt.",,"Add,Fact/Evidence",Fact/Evidence
5398,6-ARR,6-ARR_v2_38@0,,"Training At the training time, we pre-construct the prompt with answers such as ""book a flight from beijing to new york tomorrow morning"" departure refers to new york .",,"Add,Fact/Evidence",Fact/Evidence
5399,6-ARR,6-ARR_v2_38@1,,"Then we finetune a pre-trained language model with the answered prompts, and we only calculate loss on the answer tokens (i.e. new york) instead of the loss on the whole sentence.",,"Add,Fact/Evidence",Fact/Evidence
5400,6-ARR,6-ARR_v2_41@0,,"Inference At the inference time, we feed the prompted inputs into the fine-tuned pre-trained language model and let LM generate the appeared slot values.",,"Add,Fact/Evidence",Fact/Evidence
5401,6-ARR,6-ARR_v2_41@1,,"During generation, we restrict LM to generate only words that appear in the original input sentence or predefined control words.",,"Add,Fact/Evidence",Fact/Evidence
5402,6-ARR,6-ARR_v2_43@0,,Note that restricting the scope of output tokens is crucial to the performance.,,"Add,Claim",Claim
5403,6-ARR,6-ARR_v2_45@0,,"In the previous section, different slot types are predicted separately.",,"Add,Fact/Evidence",Fact/Evidence
5404,6-ARR,6-ARR_v2_45@1,,"To consider the relations between different slot types, we introduce the Iterative Prediction Strategy, which also provides the model a second chance to revise those unrecognized entities.",,"Add,Fact/Evidence",Fact/Evidence
5405,6-ARR,6-ARR_v2_45@4,,"Motivated by this, as shown in the Fig. 3 We randomly select some occurred labels (e.g., ""arrival"") pretending it was not predicted, and construct a second round prompt: ""book a flight from beijing to new york tomorrow morning"" departure refers to beijing .",,"Add,Fact/Evidence",Fact/Evidence
5406,6-ARR,6-ARR_v2_45@8,,"By using these second round prompts for model training, we encourage the language model to find those unrecognized slots in the first round prediction and allow the model to consider relationships between labels.",,"Add,Fact/Evidence",Fact/Evidence
5407,6-ARR,6-ARR_v2_46@0,,"Inference During the inference time, we construct the second-round prompts and revise the slots that are not recognized in the first round.",,"Add,Fact/Evidence",Fact/Evidence
5408,6-ARR,6-ARR_v2_46@1,,"For example in the Fig. 3, the model predict none value for ""price"" and ""arrival"" slot in the first round.",,"Add,Fact/Evidence",Fact/Evidence
5409,6-ARR,6-ARR_v2_46@2,,"We then construct another iteration of the prompted inputs that query the unrecognized slots, given all the labels and slot values that have been predicted: ""book a flight from beijing to new york tomorrow morning"" departure refers to beijing .",,"Add,Fact/Evidence",Fact/Evidence
5410,6-ARR,6-ARR_v2_47@0,,"The model is expected to predict the first-round missed slots during the second iteration, considering relations between labels.",,"Add,Fact/Evidence",Fact/Evidence
5411,6-ARR,6-ARR_v2_62@6,,Data and code used are public available.,,"Add,Fact/Evidence",Fact/Evidence
5412,6-ARR,6-ARR_v2_66@1,,"Despite using less training data, our model still achieves comparable results with Covex, proving its superiority.",,"Add,Claim",Claim
5413,6-ARR,6-ARR_v2_72@0,,"When Iterative Revise Strategy is added, we can get a rise in recall score about 4 points in 10-shot, 2~4 points in 20 shot and more than 1 points in other shot settings in exchange for a slight precision drop, resulting in a rise in overall F1 score by about 2 points in 10 and 20 shots.",,"Add,Fact/Evidence",Fact/Evidence
5414,6-ARR,6-ARR_v2_72@1,,"We further explore the effect of jointly learning of the first-round prediction and the second-round revising, and learn two abilities separately with two models.",,"Add,Fact/Evidence",Fact/Evidence
5415,6-ARR,6-ARR_v2_72@3,,"Besides, we find no significant correlation between the number of labels and our performance.",,"Add,Fact/Evidence",Fact/Evidence
5416,6-ARR,6-ARR_v2_78@0,,"All the scientific artifacts used/created are properly cited/licensed, and the usage is consistent with their intended use.",,"Add,Fact/Evidence",Fact/Evidence
5417,6-ARR,6-ARR_v2_78@1,,"This paper does not collect new datasets, nor does the data used contain sensitive information.",,"Add,Fact/Evidence",Fact/Evidence
5418,6-ARR,,6-ARR_v1_25@1,,"For the example in the Figure 2, B-time is tagged to the first word in a time slot, I-time is tagged to a non-begin word within a time slot, and O label refers to non-slot tokens.","Delete,Fact/Evidence",Fact/Evidence
5419,6-ARR,,6-ARR_v1_25@2,,"Few-shot slot tagging is then defined as: given a K-shot support set S and an input query sequence x = (x 1 , x 2 , ..., x n ), find x's best label sequence y * .","Delete,Fact/Evidence",Fact/Evidence
5420,6-ARR,,6-ARR_v1_35@0,,We create the inverse prompt P and turn slot tagging into a generation task by filling a template combined with input text and slot labels.,"Delete,Fact/Evidence",Fact/Evidence
5421,6-ARR,6-ARR_v2_36@0,6-ARR_v1_37@0,Training and Inference with Inverse Prompts,Reverse Inference with Prompts,"Modify,Fact/Evidence",Fact/Evidence
5422,6-ARR,6-ARR_v2_37@1,6-ARR_v1_38@0,This section will show how to perform training and inference with the prompts.,"In this section, we will introduce how the generative slot tagging is conducted in the inference procedure with proposed inverse prompts.","Modify,Fact/Evidence",Fact/Evidence
5423,6-ARR,6-ARR_v2_41@2,6-ARR_v1_39@4,"For each prompted input p, the next token t k ∈ x ∪ C is determined by language model probability:","For each prompted input x ij , the next token t k is determined by:","Modify,Fact/Evidence",Fact/Evidence
5424,6-ARR,6-ARR_v2_2@8,6-ARR_v1_2@8,"We find, somewhat surprisingly, the proposed method not only predicts faster but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.","We find, somewhat surprisingly, the proposed method not only predicts faster, but also significantly improves the effect (improve over 6.1 F1-scores on 10-shot setting) and achieves new state-of-the-art performance.","Modify,Grammar",Grammar
5425,6-ARR,6-ARR_v2_45@2,6-ARR_v1_43@1,"We assume that different labels are interactive, so the predicted slots could be used as a hint to help predict the missed slots.","We assume that different labels are interactive, so the predicted slot values could be used as a hint to help predict those ""none"" ones.","Modify,Clarity",Clarity
5426,6-ARR,6-ARR_v2_45@3,6-ARR_v1_43@2,"For example in Fig. 3, it is often easier to generate the ""arrival"" slot given the results of ""departure"" and ""time"".","For example, the model tends to successfully generate the slot value of ""arrival"" given the results of ""departure"" and ""time"" in the first iteration (Figure 3).","Modify,Clarity",Clarity
5427,6-ARR,6-ARR_v2_49@0,6-ARR_v1_50@0,"We evaluate the performance of the proposed method on two classic few-shot scenarios: (1) Setting with Only In-domain data, where all training data are only a few labeled support data.","We evaluate the performance of the proposed method on two types of few-shot learning benchmarks: (1) Setting with Only In-domain data, where all training data are only a few labeled support data.","Modify,Clarity",Clarity
5428,6-ARR,6-ARR_v2_51@0,6-ARR_v1_51@0,"Evaluation To use same evaluation criteria as conventional sequence labeling methods, we need to label tokens reversely and get output in same format.","Evaluation To directly compare with conventional sequence labeling methods, we need to label tokens reversely.","Modify,Claim",Claim
5429,6-ARR,6-ARR_v2_53@0,6-ARR_v1_51@4,"(3) Use BIO labels: add ""B-"" to the beginning token of the slot span, add ""I-"" to the non-begin token of the slot span, and label non-slot tokens with ""O"".","(3) Use BIO labels: add 'B-' to the beginning token of the slot span, add 'I-' to the non-begin token of the slot span and label non-slot tokens with 'O'.","Modify,Grammar",Grammar
5430,6-ARR,6-ARR_v2_55@0,6-ARR_v1_57@0,Results Table 1 shows the results of the proposed method only finetuned on few-shot in-domain data.,Results Table 1 shows the results of the proposed method only finetuned on few-shot in-domain data and baselines under few-shot setting.,"Modify,Fact/Evidence",Fact/Evidence
5431,6-ARR,6-ARR_v2_55@1,6-ARR_v1_57@1,"Among these results, we can observe that:","Among these methods, we can observe that:","Modify,Clarity",Clarity
5432,6-ARR,6-ARR_v2_56@1,6-ARR_v1_58@1,It outperforms the strongest baseline Template-based BART which uses BART-large by average F1 scores on three datasets of 11.96 in 10shot setting even with a much smaller pre-trained language model (the smallest GPT2).,It outperforms the strongest baseline Template-based BART which uses BART-large by average F1 scores on three datasets of 11.96 in 10shot setting even with a 40% smaller pretrained language model GPT2-small.,"Modify,Fact/Evidence",Fact/Evidence
5433,6-ARR,6-ARR_v2_57@0,6-ARR_v1_59@0,(2) Our proposed method is even comparable or outperforms those baselines with data-rich domain pre-training.,(2) Our proposed method is even comparable or outperforms those baselines with data-rich domain pretrained.,"Modify,Grammar",Grammar
5434,6-ARR,6-ARR_v2_58@1,6-ARR_v1_61@0,"(4) Our method significantly outperformed Sequence Labeling BERT whose performance is quite poor on 10 and 20 shot settings, which indicates that the number of labeled data is too scarce for conventional sequence labeling tasks, and proves that the prompt-based method is effective in few-shot slot tagging tasks.","(4) Our method significantly outperformed Sequence Labeling BERT whose performance is quite poor on 10 and 20 shot settings, which indicates that the number of labeled data under the few-shot setting is scarce for conventional sequence labeling task, and proves that the prompt-based method is effective in few-shot slot tagging tasks.","Modify,Clarity",Clarity
5435,6-ARR,6-ARR_v2_59@0,6-ARR_v1_62@0,(5) The proposed Iterative Strategy consistently improves the slot tagging performance.,"(5) The proposed Iterative Prediction Strategy improves our method by average F1 score on three datasets of 2.23 and 1.44 in 10 and 20 shot setting respectively and even sees improvements in 200 and 500 shot settings, which proves the effectiveness of the Iterative Prediction Strategy in very few labeled data settings and it may still work in middle size labeled data scenarios.","Split+Modify,Clarity",Clarity
5436,6-ARR,6-ARR_v2_59@1,6-ARR_v1_62@0,The improvements become greater with fewer learning shots and the averaged improvement in 10 and 20 shot setting on three datasets are 2.23 and 1.44.,"(5) The proposed Iterative Prediction Strategy improves our method by average F1 score on three datasets of 2.23 and 1.44 in 10 and 20 shot setting respectively and even sees improvements in 200 and 500 shot settings, which proves the effectiveness of the Iterative Prediction Strategy in very few labeled data settings and it may still work in middle size labeled data scenarios.","Split+Modify,Fact/Evidence",Fact/Evidence
5437,6-ARR,6-ARR_v2_59@2,6-ARR_v1_62@0,"This shows that when there is less data, the iterative revising mechanism is more important.","(5) The proposed Iterative Prediction Strategy improves our method by average F1 score on three datasets of 2.23 and 1.44 in 10 and 20 shot setting respectively and even sees improvements in 200 and 500 shot settings, which proves the effectiveness of the Iterative Prediction Strategy in very few labeled data settings and it may still work in middle size labeled data scenarios.","Modify,Claim",Claim
5438,6-ARR,6-ARR_v2_60@0,6-ARR_v1_63@0,Setting with Meta Source Tasks,Setting with Meta Source Task,"Modify,Grammar",Grammar
5439,6-ARR,6-ARR_v2_61@0,6-ARR_v1_64@0,"Datasets We also evaluate the model ability of transferring from data-rich domains to unseen few-shot domains and conduct experiments on SNIPS (Coucke et al., 2018) dataset.","Datasets To evaluate the transferability from data-rich domains to unseen few-shot domains of our proposed model, we conduct experiments on SNIPS (Coucke et al., 2018) dataset.","Modify,Clarity",Clarity
5440,6-ARR,6-ARR_v2_61@2,6-ARR_v1_64@2,"The few-shot SNIPS dataset consists of 7 domains with different label sets: GetWeather (We), Music (Mu), PlayList (Pl), Rate-Book (Bo), SearchScreenEvent (Se), BookRestaurant (Re), and SearchCreativeWork (Cr).","The few-shot SNIPS dataset consists of 7 domains with different label sets: GetWeather (We), Music (Mu), PlayList (Pl), Rate-Book (Bo), SearchScreenEvent (Se), BookRestaurant (Re) and SearchCreativeWork (Cr).","Modify,Grammar",Grammar
5441,6-ARR,6-ARR_v2_5@1,6-ARR_v1_5@1,"For example, when classifying the sentiment of the movie review ""no reason to watch"", prompting methods insert a piece of text ""It was"", i.e. prompts, to the input example, getting ""No reason to watch. It was __"".","For example, when classifying the sentiment of the movie review ""no reason to watch"", prompting methods insert a piece of text ""It was"", i.e. prompts, to the input examples, getting ""No reason to watch. It was __"".","Modify,Grammar",Grammar
5442,6-ARR,6-ARR_v2_61@3,6-ARR_v1_64@3,"Each domain contains 100 few-shot episodes, and each episode consists of a support set and a query.","Each domain contains 100 episodes, and each episode consists of a support set with a batch of labeled samples and query samples to evaluate.","Modify,Clarity",Clarity
5443,6-ARR,6-ARR_v2_62@1,6-ARR_v1_65@1,"For our proposed method, same as in-domain settings, we use the smallest GPT2 as the base model, and no new parameters are introduced.","For our proposed method, same as in-domain settings, we use GPT2small pre-trained model as the base model for pretraining in source domain and fine-tuning in target few-shot domain, and no new parameters are introduced.","Split+Modify,Clarity",Clarity
5444,6-ARR,6-ARR_v2_62@2,6-ARR_v1_65@1,We pretrain the model in source domains and fine-tune it on the target fewshot domain.,"For our proposed method, same as in-domain settings, we use GPT2small pre-trained model as the base model for pretraining in source domain and fine-tuning in target few-shot domain, and no new parameters are introduced.","Split+Modify,Clarity",Clarity
5445,6-ARR,6-ARR_v2_62@3,6-ARR_v1_65@2,We set learning rate as 6.25e − 5 and batch size as 16 for pretraining and batch size as 2 for 5-shot finetuning.,We set learning rate=6.25e − 5 and batch size=16 for pretraining and batch size=2 for 5-shot finetuning.,"Modify,Grammar",Grammar
5446,6-ARR,6-ARR_v2_63@0,6-ARR_v1_67@0,"Baselines We provided competitive strong baselines, including traditional finetune-based methods and advanced few-shot learning methods.","Baselines We provided competitive strong baselines, including traditional methods, finetune-based methods and advanced few-shot learning methods.","Modify,Clarity",Clarity
5448,6-ARR,6-ARR_v2_65@0,6-ARR_v1_69@1,"Table 2 shows the results of the crossdomain few-shot setting, from which we can observe that:","Among these methods in the table, we can observe that:","Merge+Modify,Clarity",Clarity
5449,6-ARR,6-ARR_v2_66@0,6-ARR_v1_70@0,(1) Our proposed method outperforms all the baselines except ConVEx which uses extra Reddit data in the cross-domain 5-shot setting.,(1) Our proposed method outperforms all the baselines except ConVEx which uses extra Reddit data in cross-domain 5-shot setting.,"Modify,Grammar",Grammar
5450,6-ARR,6-ARR_v2_67@0,6-ARR_v1_71@0,(2) We outperform TransferBERT by 42.36 F1 scores which strongly proved that the prompt-based method can transfer more knowledge from the source domain and is more data-efficient than conventional methods.,(2) We outperform TransferBERT by 42.36 F1 scores which strongly proved that prompt-based method can transfer more knowledge from source domain and more data-efficient than conventional methods.,"Modify,Grammar",Grammar
5451,6-ARR,6-ARR_v2_0@0,6-ARR_v1_0@0,Inverse is Better! Fast and Accurate Prompt for Few-shot Slot Tagging,Inverse is Better! Fast and Accurate Prompt for Slot Tagging,"Modify,Fact/Evidence",Fact/Evidence
5452,6-ARR,6-ARR_v2_2@1,6-ARR_v1_2@1,"These methods modify input samples with prompt sentence pieces, and decode label tokens to map samples to corresponding labels.",These methods embed input samples with prompt sentence pieces and decode label-related tokens to map samples to the label.,"Modify,Clarity",Clarity
5453,6-ARR,6-ARR_v2_68@0,6-ARR_v1_72@0,"(3) Our method outperforms metric-based few-shot learning baselines, for example, 2.24 F1 scores higher than L-TapNet+CDT, which proves its competitiveness compared to classical few-shot learning methods.","(3) Our method outperforms some metric-based few-shot learning baselines, for example, 2.24 F1 scores higher than L-TapNet+CDT, which demonstrate the effectiveness of prompt method in the slot tagging task.","Modify,Claim",Claim
5454,6-ARR,6-ARR_v2_69@0,6-ARR_v1_73@0,"(4) Our Iterative Prediction Strategy improved Our method by about 0.5 F1 scores, demonstrating that the revising ability is likely to be transferable and is effective under cross-domain scenarios.","(4) Our Iterative Prediction Strategy improved Our method by about 0.5 F1 scores, demonstrating its effectiveness under cross-domain scenarios.","Modify,Claim",Claim
5455,6-ARR,6-ARR_v2_71@0,6-ARR_v1_75@0,"Effects of Iterative Prediction Strategy As shown in Table 1, the proposed Iterative Prediction Learning brings consistent improvement, especially in low-resource settings.","Effects of Iterative Prediction Learning As shown in Table 1, the proposed Iterative Prediction Learning brings consistent improvement ,especially in low-resource settings.","Modify,Clarity",Clarity
5456,6-ARR,6-ARR_v2_5@3,6-ARR_v1_5@3,"Such conversion reduces the gap between pretraining and target tasks, which allows less dependency on target task data and helps to achieve better performance in low data scenarios (Gao et al., 2021).","Such conversion reduces the gap between pretraining and target tasks, which allows depending less on target task data and helps to achieve better performance in low data scenarios (Gao et al., 2021).","Modify,Clarity",Clarity
5457,6-ARR,6-ARR_v2_74@1,6-ARR_v1_77@3,"Different from them, we introduce an inverse paradigm for prompting slot tagging tasks.","Different from them, we introduce an inverse paradigm for prompting slot tagging task.","Modify,Grammar",Grammar
5458,6-ARR,6-ARR_v2_74@5,6-ARR_v1_77@7,"By contrast, we focus on a different task for sequence labeling and first introduce an Iterative Prediction Strategy to prompting models.","By contrast, we focus on a different task sequence labeling and first to introduce an Iterative Prediction Strategy to prompting models.","Modify,Grammar",Grammar
5459,6-ARR,6-ARR_v2_75@0,6-ARR_v1_78@0,"Few-shot slot tagging Previous few-shot slot tagging methods focus on metric learning based methods, which classify tokens by word-label similarity (Snell et al., 2017;Vinyals et al., 2016).","Few-shot slot tagging Previous few-shot slot tagging methods focus on metric learning based methods, which classify tokens with word-label similarity (Snell et al., 2017;Vinyals et al., 2016).","Modify,Grammar",Grammar
5460,6-ARR,6-ARR_v2_75@1,6-ARR_v1_78@1,Hou et al. (2020) leverage label name semantics to get better label representation and model label dependency in few-shot settings.,Hou et al. (2020) leverage label name semantics to get better label representation and model label dependency in few-shot setting.,"Modify,Grammar",Grammar
5461,6-ARR,6-ARR_v2_75@2,6-ARR_v1_78@2,Yang and Katiyar (2020) make a prediction based on the nearest neighbor sample instead of the nearest label representation.,Yang and Katiyar (2020) uses make a prediction based on the nearest neighbor sample instead of the nearest label representation.,"Modify,Grammar",Grammar
5462,6-ARR,6-ARR_v2_75@3,6-ARR_v1_78@3,"Besides, some works also explore training a model with additional data from non-slot-tagging task Henderson and Vulic, 2021)","Besides, some works also explore training a model with additional data from non-slottagging task Henderson and Vulic, 2021).","Modify,Grammar",Grammar
5463,6-ARR,6-ARR_v2_5@4,6-ARR_v1_6@0,"However, while achieving great success in sentence level tasks, prompting-based methods show incompatibility for sequence labeling tasks, such as slot tagging.","However, while achieving great success in sentence-level tasks, prompting-based methods show incompatibility for sequence labeling task, such as slot tagging.","Modify,Grammar",Grammar
5464,6-ARR,6-ARR_v2_77@0,6-ARR_v1_80@0,"In this paper, to liberate the prompting methods from the burdensome prediction of slot-tagging tasks, we introduce a novel inverse prediction manner to prompting methods of slot-tagging, which significantly improves both the efficiency and accuracy.","In this paper, to liberate the prompting methods from burdensome prediction of slot-tagging tasks, we introduce a novel inverse prediction manner to prompting methods of slot-tagging, which significantly improves both the efficiency and accuracy.","Modify,Grammar",Grammar
5465,6-ARR,6-ARR_v2_77@1,6-ARR_v1_81@0,"To further improve performance, we propose an Iterative Prediction Strategy for learning, which enables the prompting model to consider dependency between labels and refine prediction.","To further improve performance, we propose an Iterative Prediction Strategy for learning, which enable the prompting model to consider dependency between labels and refine prediction.","Modify,Grammar",Grammar
5466,6-ARR,6-ARR_v2_5@5,6-ARR_v1_6@1,"Firstly, the aforementioned prompting paradigm is quite inefficient for slot tagging tasks.","Firstly, the aforementioned prompting paradigm is quite inefficient for slot tagging task.","Modify,Grammar",Grammar
5467,6-ARR,6-ARR_v2_5@7,6-ARR_v1_6@3,"Therefore, as shown in Fig. 1, to find all the possible slots, prompt-based methods have to enumerate all n-gram word spans, and then query LM for each of them, which greatly slows down the prediction (Cui et al., 2021).","Therefore, as shown in Figure 1, to find all the possible slots, prompt-based methods have to enumerate all n-gram word spans, and then query LM for each of them, which greatly slows down the prediction (Cui et al., 2021).","Modify,Clarity",Clarity
5468,6-ARR,6-ARR_v2_5@10,6-ARR_v1_6@5,Such label dependency is hard to be captured by current prompting methods since they predict labels one-by-one independently.,"Such label dependency is hard to be captured by current prompting methods, since they predict labels one-by-one independently.","Modify,Grammar",Grammar
5469,6-ARR,6-ARR_v2_6@1,6-ARR_v1_7@1,"Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types.","Different from the classic prompts map tokens to labels, we reversely predict slot values given slot types.","Modify,Grammar",Grammar
5470,6-ARR,6-ARR_v2_6@2,6-ARR_v1_7@2,"For the example in Fig. 1, we use an inverse prompt to modify the input as ""book a flight from Beijing to New York tomorrow morning. arrival refers to __"", and then LM is able to decode multi-word span ""New York"" at a time.","For the example in Figure 1, we embed the input with an inverse prompt as ""book a flight from Beijing to New York tomorrow morning. arrival refers to __"", and then LM is able to decode multi-word span ""New York"" at a time.","Modify,Clarity",Clarity
5471,6-ARR,6-ARR_v2_6@3,6-ARR_v1_7@3,"Compared to the classic prompts that require predictions for every n-gram word span (55-times in Fig. 1), we only need to perform decoding for V -times, where V is the number of label types (4-times in Fig. 1), which therefore greatly speeds up the prediction.","Compared to the classic prompts that require predictions for every n-gram word span (55-times in Figure 1), we only need to perform decoding for V -times, where V is the number of label types (4-times in Figure 1), and therefore greatly speed up the prediction.","Modify,Clarity",Clarity
5472,6-ARR,6-ARR_v2_6@4,6-ARR_v1_7@4,"Surprisingly, experiments show the proposed method not only predicts faster but also significantly improves the performance, indicating that prompting LM reversely is a better fit for the slot tagging task.","Surprisingly, experiments show the proposed method not only predicts faster, but also significantly improve the performance, indicating that prompting LM reversely is a better fit for the slot tagging task.","Modify,Grammar",Grammar
5473,6-ARR,6-ARR_v2_2@3,6-ARR_v1_2@3,"Since slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token spans to find all the possible slots, which greatly slows down the prediction.","Because the slot tagging samples are multiple consecutive words in a sentence, the prompting methods have to enumerate all n-grams token span to find all the possible slots, which greatly slows down the prediction.","Modify,Clarity",Clarity
5474,6-ARR,6-ARR_v2_8@0,6-ARR_v1_9@0,"(1) We introduce the idea of inverse prediction to prompting methods for slot tagging tasks, which greatly speeds up the prediction process.","(1) We introduce the idea of inverse prediction to prompting-methods for slot tagging task, which greatly speeds up the prediction process.","Modify,Grammar",Grammar
5475,6-ARR,6-ARR_v2_9@0,6-ARR_v1_10@0,"(2) We propose an Iterative Prediction Strategy for learning and prediction with slot tagging prompts, which allows the prompting model to consider dependency between different slot types and refine prediction.","(2) We propose an Iterative Prediction Strategy for learning and prediction for slot tagging prompt, which allows the prompting model to consider dependency between different slot types and refine prediction.","Modify,Grammar",Grammar
5476,6-ARR,6-ARR_v2_10@0,6-ARR_v1_11@0,"(3) We extensively evaluate the proposed method in various few-shot settings, where the proposed method brings significant improvements not only in speed but also in accuracy.","(3) We extensively evaluate the proposed method in various few-shot settings, where the proposed method brings significant improvements not only for the speed, but also for the accuracy.","Modify,Grammar",Grammar
5477,6-ARR,6-ARR_v2_11@0,6-ARR_v1_12@0,The code and data are available at https://github.com/AtmaHou/ PromptSlotTagging.,All code and data will be publicly available.,"Modify,Fact/Evidence",Fact/Evidence
5478,6-ARR,6-ARR_v2_13@0,6-ARR_v1_14@0,"In this section, we begin with a formal definition of the few-shot slot tagging task ( §2.1), and then introduce the conventional sequence labeling approaches ( §2.2) and recent prompts-based methods ( §2.3) for this task.","In this part, we first present a formal definition of the few shot slot tagging task in Section 2.1, followed by an introduction of the conventional sequence labeling approaches in Section 2.2 and Sequence Labeling with Prompts in Section 2.3.","Modify,Clarity",Clarity
5479,6-ARR,6-ARR_v2_19@1,6-ARR_v1_20@1,"Each target domain D (j) L only contains a few labeled instances called support set S = {(x (i) , y (i) )} N S i=1 , which usually includes K examples (K-shot) for each of N labels (N-way).","In few shot scenarios, there are a set of lowresource domains {D L only contains a few labeled instances called support set S = {(x (i) , y (i) )} N S i=1 , which usually includes K examples (K-shot) for each of N labels (N-way).","Modify,Fact/Evidence",Fact/Evidence
5480,6-ARR,6-ARR_v2_24@0,6-ARR_v1_25@0,"Conventional approaches often formulate slot tagging as a sequence labeling problem, where each word in input is associated with a sequence label.",Conventional approaches regard slot tagging as a sequence labeling problem where each word in a sentence is assigned with a BIO-based label.,"Modify,Clarity",Clarity
5481,6-ARR,6-ARR_v2_2@5,6-ARR_v1_2@5,"Different from the classic prompts mapping tokens to labels, we reversely predict slot values given slot types.","Different from the classic prompts map tokens to labels, we reversely predict slot values given slot types.","Modify,Grammar",Grammar
5482,6-ARR,6-ARR_v2_24@3,6-ARR_v1_25@3,For the example in the Fig. sequence labeling model is usually formulated as:,"As shown in Figure 2(a), this method can be formulated as:","Modify,Fact/Evidence",Fact/Evidence
5483,6-ARR,6-ARR_v2_28@0,6-ARR_v1_29@0,"Prompt-based methods have been proven effective in many NLU tasks, especially in few-shot settings, but things become complicated when it comes to slot tagging tasks.","Prompt-based methods have been proven effective in many NLU tasks especially in few-shot settings, but things become complicated when it comes to slot tagging tasks.","Modify,Grammar",Grammar
5484,6-ARR,6-ARR_v2_28@3,6-ARR_v1_31@1,"However, to find all possible slots, these methods need to traverse all the n-gram spans s j i , i, j ∈ [1, n] in a sentence, which is quite expensive in time and computation.","In their method, to construct templates, we need to traverse all the n-gram spans s i j , i, j ∈ [1, n] in a sentence with each label in the label set which is quite expensive in time and compute resources.","Modify,Fact/Evidence",Fact/Evidence
5485,6-ARR,6-ARR_v2_30@0,6-ARR_v1_33@0,"To remedy the high cost of prompt prediction mentioned in the previous section, we introduce a novel inverse paradigm for prompting of slot tagging task, which significantly improves the speed of prediction by transforming the past fill-in-the-blank problem into a generative task.","In this section, we propose a new paradigm for few-shot slot tagging using an inverse prompt to convert slot tagging into a generation task.","Modify,Claim",Claim
5486,6-ARR,6-ARR_v2_30@1,6-ARR_v1_33@1,"Specifically, we first introduce the construction of our inverse prompts templates ( §3.1), and then describe how to use inverse prompts during training and inference ( §3.2).","We first introduce how to create our reverse prompts in Section 3.1, then show the inference details in Section 3.2 and the Iterative Prediction Strategy in Section 3.3, respectively.","Split+Modify,Fact/Evidence",Fact/Evidence
5487,6-ARR,6-ARR_v2_31@0,6-ARR_v1_33@1,"Further, we propose an Iterative Prediction Strategy to refine prediction by considering the relation between different slot types ( §3.3).","We first introduce how to create our reverse prompts in Section 3.1, then show the inference details in Section 3.2 and the Iterative Prediction Strategy in Section 3.3, respectively.","Split+Modify,Fact/Evidence",Fact/Evidence
5488,6-ARR,6-ARR_v2_33@0,6-ARR_v1_35@1,"In this section, we introduce the creation of the proposed inverse prompts, which includes three main components: the label mapping, the inverse template and the control tokens.","Our prompt P consists of two parts, i,e., the label mapping and the inverse prompt template.","Modify,Fact/Evidence",Fact/Evidence
5527,65-ARR,,65-ARR_v1_28@1,,Intra-sentential dependencies are discovered first and inter-sentential dependencies are constructed after that to form a complete dependency tree.,"Delete,Fact/Evidence",Fact/Evidence
5528,65-ARR,,65-ARR_v1_46@1,,"( 6) BERT + Sent-First (shared) incorporate different contextualized embeddings from BERT into the Sent-First framework for parsing at intra-and inter-sentential levels, with the same BERT layer shared across intra-sentential and inter-sentential parsing.","Delete,Fact/Evidence",Fact/Evidence
5529,65-ARR,,65-ARR_v1_46@2,,( 7) BERT + Sent-First fine-tunes separate BERT layers for intra-sentential and inter-sentential parsing independently.,"Delete,Fact/Evidence",Fact/Evidence
5530,65-ARR,,65-ARR_v1_47@0,,"(2) Two-stage exploits careful feature engineering and trains an SVM to classify the relations for pairs of EDUs (Cheng et al., 2021;Yang and Li, 2018).","Delete,Fact/Evidence",Fact/Evidence
5531,65-ARR,,65-ARR_v1_48@1,,"BERT (Cheng21) is our implementation of the state-of-the-art method for relation classification in discourse dependency parsing, which improves the baseline by a large margin.","Delete,Claim",Claim
5532,65-ARR,,65-ARR_v1_49@0,,Main Results,"Delete,Other",Other
5533,65-ARR,,65-ARR_v1_50@0,,"Although BERT is still a very strong baseline in many NLP tasks, direct classification with BERT neglects the contextual clues in the discourse that can be exploited to aid discourse relation identification, as have been discussed in section 1.","Delete,Claim",Claim
5534,65-ARR,65-ARR_v2_2@4,,Our code is publicly available 1 .,,"Add,Fact/Evidence",Fact/Evidence
5535,65-ARR,65-ARR_v2_41@5,,"Because of the inherent difference between constituency parsing and dependency parsing, we only adopt the encoding strategy of ( 4) and ( 5) into our arc-eager transition system.",,"Add,Fact/Evidence",Fact/Evidence
5536,65-ARR,65-ARR_v2_42@0,,"We also implement several model variants for can be exploited to aid discourse relation identification, as have been discussed in section 1.",,"Add,Fact/Evidence",Fact/Evidence
5537,65-ARR,65-ARR_v2_4@0,65-ARR_v1_4@0,Discourse dependency parsing (DDP) is the task of identifying the structure and relationship between Elementary Discourse Units (EDUs) in a document.,Discourse dependency parsing (DDP) is the task of identifying the structure and relationship between Elementary Discourse Units (EDU) in a document.,"Modify,Grammar",Grammar
5538,65-ARR,65-ARR_v2_4@1,65-ARR_v1_4@1,"It is a fundamental task of natural language understanding and can benefit many downstream applications, such as dialogue understanding (Perret et al., 2016;Takanobu et al., 2018) and question answering (Ferrucci et al., 2010;Verberne et al., 2007).",It is a fundamental task of natural language understanding and can benefit many downstream applications.,"Modify,Fact/Evidence",Fact/Evidence
5539,65-ARR,65-ARR_v2_5@0,65-ARR_v1_5@0,"Although existing works have achieved much progress using transition-based systems (Jia et al., 2018b,a;Hung et al., 2020) or graph-based models (Li et al., 2014a;Shi and Huang, 2018;Afantenos et al., 2015), this task still remains a challenge.","Although existing works have achieved much progress using transition systems (Jia et al., 2018b,a;Hung et al., 2020) or graph-based models (Li et al., 2014a;Shi and Huang, 2018;Afantenos et al., 2015), this task still remains a challenge.","Modify,Clarity",Clarity
5540,65-ARR,65-ARR_v2_26@1,65-ARR_v1_31@1,"Although discourse relation identification in discourse dependency parsing is traditionally treated as a classification task, where the common practice is to use feature engineering or neural language models to directly compare two EDUs involved isolated from the rest of the context (Li et al., 2014a;Shi and Huang, 2018;Yi et al., 2021), sometimes relations between EDU pairs can be hard to be classified in isolation, as global information from the context like how EDUs are organized to support the claim in the discourse is sometimes required to infer the implicit discourse relations without explicit connectives.","Although discourse relation identification in discourse dependency parsing is traditionally treated as a classification task, where the common practice is to use feature engineering or neural language models to directly compare two EDUs involved isolated from the rest of the context (Li et al., 2014a;Shi and Huang, 2018;Cheng et al., 2021), sometimes relations between EDU pairs can be hard to be classified in isolation, as global information from the context like how EDUs are organized to support the claim in the discourse is sometimes required to infer the implicit discourse relations without explicit connectives.","Modify,Fact/Evidence",Fact/Evidence
5541,65-ARR,65-ARR_v2_2@0,65-ARR_v1_2@0,"Recent works show that discourse analysis benefits from modeling intra-and inter-sentential levels separately, where proper representations for text units of different granularities are desired to capture both the meaning of text units and their relations to the context.","Recent works show that discourse analysis benefits from modeling intra-and inter-sentential levels separately, where proper representations for text units of different granularities are desired to capture both the meaning of text units and their relation to the context.","Modify,Grammar",Grammar
5542,65-ARR,65-ARR_v2_5@2,65-ARR_v1_5@2,Predicting the dependency and relationship between EDUs sometimes necessitates the help of a global understanding of the context so that contextualized EDU representations in the discourse are needed.,Predicting the dependency and relationship between EDUs sometimes necessitates the help of a global understanding of the context so that contextualized EDU representations in the discourse is needed.,"Modify,Grammar",Grammar
5543,65-ARR,65-ARR_v2_33@1,65-ARR_v1_38@1,We train the tree constructor and the relation labeling models separately.,"We train the tree constructor first, while relation labeling models are trained separately after that.","Modify,Clarity",Clarity
5544,65-ARR,65-ARR_v2_36@0,65-ARR_v1_41@1,"We evaluate our models on two manually labeled discourse treebanks of different language, i.e., Discourse Dependency Treebank for Scientific Abstracts (SciDTB) (Yang and Li, 2018) in English and Chinese Discourse Treebank (CDTB) (Li et al., 2014b).","We evaluate our models on two discourse treebanks of different language, i.e., Discourse Dependency Treebank for Scientific Abstracts (SciDTB) (Yang and Li, 2018) in English and Chinese Discourse Treebank (CDTB) (Li et al., 2014b).","Modify,Fact/Evidence",Fact/Evidence
5545,65-ARR,65-ARR_v2_37@0,65-ARR_v1_41@4,"On the other hand, CDTB was originally annotated as connective-driven constituent trees, and manually converted into a dependency style by Yi et al. (2021).","On the other hand, CDTB was originally annotated as connectivedriven constituent trees, and manually converted into a dependency style by Cheng et al. (2021).","Modify,Fact/Evidence",Fact/Evidence
5546,65-ARR,65-ARR_v2_5@3,65-ARR_v1_5@3,"Furthermore, previous studies have shown the benefit of breaking discourse analysis into intra-and inter-sentential levels (Wang et al., 2017), building sub-trees for each sentence first and then assembling sub-trees to form a complete discourse tree.","Furthermore, previous studies have shown the benefit of breaking discourse analysis into intra-and inter-sentential levels, building sub-trees for each sentence first and then assembling sub-trees to form a complete discourse tree.","Modify,Fact/Evidence",Fact/Evidence
5547,65-ARR,65-ARR_v2_39@1,65-ARR_v1_43@1,Our relation labeling models are all trained with an Adam optimizer until convergence.,Our relation labeling models are all trained with an Adam optimizer for 15-20 epochs.,"Modify,Fact/Evidence",Fact/Evidence
5548,65-ARR,65-ARR_v2_39@2,65-ARR_v1_43@2,"Learning rate is set to one of {1e-5, 2e-5, 4e-5}.","Learning rate is set to 2e-5, weight-decay is set to be 1e-4.","Modify,Fact/Evidence",Fact/Evidence
5549,65-ARR,65-ARR_v2_41@1,65-ARR_v1_45@1,"(1) Graph adopts the Eisner's algorithm to predict the most probable dependency tree structure (Li et al., 2014a;Yang and Li, 2018;Yi et al., 2021).","(1) Graph adopts the Eisner's algorithm to predict the most probable dependency tree structure (Li et al., 2014a;Yang and Li, 2018;Cheng et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5550,65-ARR,65-ARR_v2_41@2,65-ARR_v1_45@2,"(2) Two-stage, which is the state-of-the-art model on CDTB and SciDTB, uses an SVM to construct a dependency tree (Yang and Li, 2018;Yi et al., 2021).","(2) Two-stage, which is the stateof-the-art model on CDTB and SciDTB, uses an SVM to construct a dependency tree (Yang and Li, 2018;Cheng et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5551,65-ARR,65-ARR_v2_41@4,65-ARR_v1_45@4,"(4) Complete Parser is modified from a state-of-the-art constituent discourse parser on CDTB (Hung et al., 2020), using a transition system with BERT as the EDU encoder to construct a dependency tree.","(4) Complete Parser is modified from the best constituent discourse parser on CDTB (Hung et al., 2020), using a transition system with BERT as the EDU encoder to construct a dependency tree.","Modify,Clarity",Clarity
5552,65-ARR,65-ARR_v2_6@1,65-ARR_v1_6@1,This is often measured by correlation with human judgement.,This is often measured by correlation with human judgment .,"Modify,Grammar",Grammar
5553,65-ARR,65-ARR_v2_2@1,65-ARR_v1_2@1,"In this paper, we propose to take advantage of transformers to encode contextualized representations of units of different levels to dynamically capture the information required for discourse dependency analysis on intra-and inter-sentential levels.","In this paper, we propose to take advantage of transformers to encode contextualized representations to dynamically capture the information required for discourse dependency analysis on intra-and inter-sentential levels.","Modify,Claim",Claim
5554,65-ARR,65-ARR_v2_2@2,65-ARR_v1_2@2,"Motivated by the observation of writing patterns commonly shared across articles, we propose a novel method that treats discourse relation identification as a sequence labelling task, which takes advantage of structural information from the context of extracted discourse trees, and substantially outperforms traditional directclassification methods.","Motivated by the observation of writing patterns shared across articles, we propose to design sequence labeling methods to take advantage of such structural information from the context, which substantially outperforms traditional direct classification methods.","Modify,Clarity",Clarity
5555,66-ARR,,66-ARR_v1_85@0,,We study whether intermediate pre-training on visual knowledge can help transfer visual knowledge into LMs.,"Delete,Fact/Evidence",Fact/Evidence
5556,66-ARR,,66-ARR_v1_85@1,,We investigate text knowledge transfer and cross-modal knowledge transfer using images and captions.,"Delete,Fact/Evidence",Fact/Evidence
5557,66-ARR,,66-ARR_v1_85@2,,"In our empirical analysis, we observe that intermediate pre-training on captions can help improving performance and cross-modal knowledge transfer approaches consistently improve performance.","Delete,Fact/Evidence",Fact/Evidence
5558,66-ARR,,66-ARR_v1_85@3,,"When the transfer methods are equipped with additional positive and negative samples, they show better performance.","Delete,Fact/Evidence",Fact/Evidence
5559,66-ARR,,66-ARR_v1_85@4,,Future works include improving both commonsense reasoning and general language understanding.,"Delete,Claim",Claim
5560,66-ARR,,66-ARR_v1_86@0,,"PIQA is a multiple-choice question answering task, which chooses the most appropriate solution for physical commonsense questions, which may need illustration or description of physical interaction in the real world.","Delete,Fact/Evidence",Fact/Evidence
5561,66-ARR,,66-ARR_v1_86@1,,VP is to tell if two descriptions are describing the same scene or two different scenes.,"Delete,Fact/Evidence",Fact/Evidence
5562,66-ARR,,66-ARR_v1_87@0,,"While they seem like purely textual tasks, they require visual common sense to answer.","Delete,Claim",Claim
5563,66-ARR,,66-ARR_v1_87@1,,CSQA is a multiple-choice question answering task that requires commonsense reasoning to answer.,"Delete,Fact/Evidence",Fact/Evidence
5564,66-ARR,,66-ARR_v1_87@2,,"It is built from ConceptNet (Speer et al., 2017).","Delete,Fact/Evidence",Fact/Evidence
5565,66-ARR,,66-ARR_v1_87@3,,"OBQA is a multiple-choice question answering task, which is modeled after open book exams on elementarylevel core science questions.","Delete,Fact/Evidence",Fact/Evidence
5566,66-ARR,,66-ARR_v1_87@4,,The task generally requires open book fact but also additional commonsense which can be learnt from scientific illustration.,"Delete,Claim",Claim
5567,66-ARR,,66-ARR_v1_87@5,,RiddleSense is a multiple-choice riddlestyle question answering which requires complex commonsense reasoning ability and understanding of figurative language which may benefit from visual knowledge.,"Delete,Fact/Evidence",Fact/Evidence
5568,66-ARR,66-ARR_v2_20@3,,"Here, we want to present which strategy is best suited for cross-modal knowledge transfer.",,"Add,Claim",Claim
5569,66-ARR,66-ARR_v2_31@1,,Note that we use the same text encoder.,,"Add,Fact/Evidence",Fact/Evidence
5570,66-ARR,66-ARR_v2_68@1,,We continue to pre-train the encoders in our experiments.,,"Add,Fact/Evidence",Fact/Evidence
5571,66-ARR,,66-ARR_v1_15@0,,Analysis Setup,"Delete,Other",Other
5572,66-ARR,,66-ARR_v1_16@0,,"In this work, we study how to transfer the visual knowledge into language models.","Delete,Fact/Evidence",Fact/Evidence
5573,66-ARR,66-ARR_v2_70@3,,"We argue that if a model obtains better performance in the low-resource setup, then it is a faster learner and has better generalization on downstream tasks.",,"Add,Claim",Claim
5574,66-ARR,,66-ARR_v1_16@1,,"For this study, we introduce our analysis setup: problem formulation, analysis questions, and knowledge corpora.","Delete,Fact/Evidence",Fact/Evidence
5575,66-ARR,,66-ARR_v1_17@0,,Problem Formulation,"Delete,Other",Other
5576,66-ARR,66-ARR_v2_74@1,,We sample 250k sentences from each corpus for a fair comparison.,,"Add,Fact/Evidence",Fact/Evidence
5577,66-ARR,66-ARR_v2_74@2,,We notice that caption datasets are useful on OBQA and RiddleSense datasets while GenericsKB are the most helpful on PIQA datasets.,,"Add,Fact/Evidence",Fact/Evidence
5578,66-ARR,,66-ARR_v1_18@0,,We focus on a pre-trained text encoder f L and an image encoder f V if images are available.,"Delete,Fact/Evidence",Fact/Evidence
5579,66-ARR,66-ARR_v2_24@3,66-ARR_v1_26@3,"Moreover, We additionally test on GLUE (Wang et al., 2019) to evaluate the general text understanding.","Moreover, We additionally test on GLUE (Wang et al., 2018) to evaluate the general text understanding.","Modify,Fact/Evidence",Fact/Evidence
5580,66-ARR,66-ARR_v2_26@2,66-ARR_v1_28@2,"In the fully supervised setting, we evaluate models with 3 different random seeds and report the average accuracy.","In fully supervised setting, we evaluate models with 3 different random seeds and report the average accuracy.","Modify,Grammar",Grammar
5581,66-ARR,66-ARR_v2_26@3,66-ARR_v1_28@3,"In the lowresource setting, we set the size of the train data to 64 or 128.","In a low-resource setting, we consider the size of train data to 64 or 128.","Modify,Clarity",Clarity
5582,66-ARR,66-ARR_v2_34@0,66-ARR_v1_36@0,"Masked Language Modeling (MLM) Following BERT (Devlin et al., 2019), we select 15% of input tokens and replace them with [MASK].","Masked Language Modeling (MLM) Following BERT (Devlin et al., 2018), we select 15% of input tokens and replace them with [MASK].","Modify,Fact/Evidence",Fact/Evidence
5583,66-ARR,66-ARR_v2_4@0,66-ARR_v1_4@0,"Pre-trained language models (PTLMs) such as BERT (Devlin et al., 2019), RoBERTa , and T5 (Raffel et al., 2020) have shown impressive results in various conventional natural language understanding (NLU) tasks by capturing syntactic and semantic knowledge from the pretraining tasks of masked language modeling and masked span infilling tasks on massive text corpora.","Pre-trained language models (PTLMs) such as BERT (Devlin et al., 2018), RoBERTa , and T5 (Raffel et al., 2020) have shown impressive results in various conventional natural language understanding (NLU) tasks by capturing syntactic and semantic knowledge from the pretraining tasks of masked language modeling and masked span infilling tasks on massive text corpora.","Modify,Fact/Evidence",Fact/Evidence
5584,66-ARR,66-ARR_v2_46@1,66-ARR_v1_48@1,"It aligns language tokens to their related images (called ""vokens"") to transfer visual knowledge into LMs, and call it ""voken classification"".","It aligns language tokens to their related images (called ""vokens"") to transfer visual knowledge into LMs, and call ""voken classification"".","Modify,Clarity",Clarity
5585,66-ARR,66-ARR_v2_49@0,66-ARR_v1_51@0,"Masked Language Modeling with Visual Clues VL-BERT (Su et al., 2020) adopts masked language modeling with visual clues in which models are given a caption with masked tokens and an image and predict the masked tokens using visual clues.","Masked Language Modeling with Visual Clues VL-BERT (Su et al., 2019) adopts masked language modeling with visual clues in which models are given a caption with masked tokens and an image and predict the masked tokens using visual clues.","Modify,Fact/Evidence",Fact/Evidence
5586,66-ARR,66-ARR_v2_52@0,66-ARR_v1_54@0,"Then the contrastive learning objective contains two loss functions: an image-to-text contrastive loss ℓ (v,l) and a text-to-image contrastive loss ℓ (l,v) .","Then the contrastive learning objective contains two loss functions: an image-to-text contrastive loss ℓ (v,l) and and a text-to-image contrastive loss ℓ (l,v) .","Modify,Grammar",Grammar
5587,66-ARR,66-ARR_v2_5@0,66-ARR_v1_5@0,"Though yielding good performance on various NLU downstream tasks, these pre-training objectives suffer from a lack of out-of-domain knowledge that is not explicitly present in the pre-training corpus (Gururangan et al., 2020a;Petroni et al., 2021;Schick and Schütze, 2020).","Though yielding good performance on various NLU downstream tasks, these pre-training objectives suffer from a lack of out-of-domain knowledge that is not explicitly present in the pre-training corpus (Gururangan et al., 2020;Petroni et al., 2021;Schick and Schütze, 2020).","Modify,Fact/Evidence",Fact/Evidence
5588,66-ARR,66-ARR_v2_60@7,66-ARR_v1_63@7,"We use WordNet (Miller, 1992) to find synonyms and hypernyms.","We use WordNet (Miller, 1995) to find synonyms and hypernyms.","Modify,Fact/Evidence",Fact/Evidence
5589,66-ARR,66-ARR_v2_64@0,66-ARR_v1_68@0,"Cross-modal knowledge distillation is to transfer knowledge between different modalities, e.g., image modality and text modality.","Cross-model knowledge distillation is to transfer knowledge between different modalities, e.g., image modality and text modality.","Modify,Grammar",Grammar
5590,66-ARR,66-ARR_v2_66@1,66-ARR_v1_71@1,"We adopt masked language modeling on Wikitext103 (Merity et al., 2017), a subset of English Wikipedia, in the knowledge distillation step.","We adopt masked language modeling on Wikitext103 (Merity et al., 2016), a subset of English Wikipedia, in the knowledge distillation step.","Modify,Fact/Evidence",Fact/Evidence
5591,66-ARR,66-ARR_v2_68@0,66-ARR_v1_73@0,"For all the approaches, we use bert-base-uncased (Devlin et al., 2019) as text encoder f L and ResNeXt101 (Xie et al., 2017) as an image encoder f V .","For all the approaches, we use bert-base-uncased (Devlin et al., 2018) as text encoder f L and ResNeXt101 (Xie et al., 2017) as an image encoder f V .","Modify,Fact/Evidence",Fact/Evidence
5592,66-ARR,66-ARR_v2_68@2,66-ARR_v1_73@1,"For text knowledge transfer, (1) MLM follows the exact setting of codebase in huggingface 2 which uses dynamic masking strategy to conduct language modeling task.","For text knowledge transfer, (1) MLM follows the exact setting of codebase in huggingface 2 which uses dynamic masking strategy to conduct language modling task.","Modify,Grammar",Grammar
5593,66-ARR,66-ARR_v2_68@13,66-ARR_v1_74@3,"We filter out synonyms and hypernyms of original words using WordNet (Miller, 1992).","We filter out synonyms and hypernyms of original words using WordNet (Miller, 1995).","Modify,Fact/Evidence",Fact/Evidence
5594,66-ARR,66-ARR_v2_70@9,66-ARR_v1_76@7,"In low-resource setting, we find that cross-modal knowledge transfer helps better initialization and lets models learn new tasks faster.","In low-resource setting, we find that cross-modal knowledge transfer helps better initialization and let models learn new tasks faster.","Modify,Grammar",Grammar
5595,66-ARR,66-ARR_v2_71@3,66-ARR_v1_77@3,This suggests that exploiting images in masked language modeling task help transfer the knowledge to language models.,This suggesting that exploiting images in masked language modeling task help transfer the knowledge to language models.,"Modify,Grammar",Grammar
5596,66-ARR,66-ARR_v2_76@3,66-ARR_v1_82@3,"There have been efforts of using knowledge graph to inject entity and relation representations, which are pre-computed from external source, into PTLMs (Zhang et al., 2019;Xu et al., 2021a;Peters et al., 2019;He et al., 2020;Xu et al., 2021b).","There have been efforts of using knowledge graph to inject entity and relation representations, which are pre-computed from external source, into PTLMs (Zhang et al., 2019;Peters et al., 2019;He et al., 2020).","Modify,Fact/Evidence",Fact/Evidence
5597,66-ARR,66-ARR_v2_76@6,66-ARR_v1_82@6,"Works that use such corpus present knowledge-related pre-training objectives such as concept order recovering (Zhou et al., 2021), entity category prediction (Yu et al., 2020) and source of knowledge prediction (Wang et al., 2021;Calixto et al., 2021).","Works that use such corpus present knowledge-related pre-training objectives such as concept order recovering (Zhou et al., 2021), entity category prediction (Yu et al., 2020) and source of knowledge prediction (Wang et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5598,66-ARR,66-ARR_v2_77@0,66-ARR_v1_83@0,"There is a extensive line of works for a variety of vision-language tasks, such as VL-BERT (Su et al., 2020), VisualBert (Li et al., 2019), and Uniter (Chen et al., 2020b).","There is a extensive line of works for a variety of vision-language tasks, such as VL-BERT (Su et al., 2019), VisualBert (Li et al., 2019), and Uniter (Chen et al., 2020b).","Modify,Fact/Evidence",Fact/Evidence
5599,66-ARR,66-ARR_v2_77@1,66-ARR_v1_83@1,"These models aim to improve vision-language tasks, e.g., VQA (Goyal et al., 2017) and event understanding (Li et al., 2022), and they are found to be not effective in improving language tasks (Tan and Bansal, 2020).","These models aim to improve vision-language tasks, e.g., VQA (Goyal et al., 2017), and they are found to be not effective in improving language tasks (Tan and Bansal, 2020).","Modify,Fact/Evidence",Fact/Evidence
5600,66-ARR,66-ARR_v2_79@1,66-ARR_v1_83@4,"For this, Vokenization introduces 30k vokens and matches each token into the limited voken space.","For this, Vokenization introduces 30k vokens and matches each token into the limited voken space; it may have approximation errors.","Modify,Claim",Claim
5601,66-ARR,66-ARR_v2_9@1,66-ARR_v1_8@1,"We leverage two training objectives for the language model: (1) masked language modeling follows the domain adaptive pre-training scheme (Gururangan et al., 2020a), assuming the corpus contains enriched visual knowledge or physical commonsense knowledge;","We leverage two training objectives for the language model: (1) masked language modeling follows the domain adaptive pre-training scheme (Gururangan et al., 2020), assuming the corpus contains enriched visual knowledge or physical commonsense knowledge;","Modify,Fact/Evidence",Fact/Evidence
5602,66-ARR,66-ARR_v2_11@0,66-ARR_v1_10@0,"For the cross-modal knowledge transfer, we explore multiple methods to transfer visual-related knowledge to LMs: (1) masked language modeling with visual clues incorporates visual clues to capture dependencies between visual and linguistic contents (Su et al., 2020); (2) voken classification contextually aligns language tokens to their related images (called ""vokens"") to transfer visual knowledge into LMs (Tan and Bansal, 2020); (3) cross-modal contrastive learning aims to improve text representations by maximizing the agreement between correct image-text pairs versus random (inbatch) and adversarial negative pairs by contrastive learning between image and text modalities; and (4) cross-modal knowledge distillation transfers the knowledge from the teacher model, which is trained by cross-modal contrastive learning on image and text modalities, to the student language model using knowledge distillation.","For the cross-modal knowledge transfer, we explore multiple methods to transfer visual-related knowledge to LMs: (1) masked language modeling with visual clues incorporates visual clues to capture dependencies between visual and linguistic contents (Su et al., 2019); (2) voken classification contextually aligns language tokens to their related images (called ""vokens"") to transfer visual knowledge into LMs (Tan and Bansal, 2020); (3) cross-modal contrastive learning aims to improve text representations by maximizing the agreement between correct image-text pairs versus random (inbatch) and adversarial negative pairs by contrastive learning between image and text modalities; and (4) cross-modal knowledge distillation transfers the knowledge from the teacher model, which is trained by cross-modal contrastive learning on image and text modalities, to the student language model using knowledge distillation.","Modify,Fact/Evidence",Fact/Evidence
5603,66-ARR,66-ARR_v2_12@0,66-ARR_v1_11@0,"We perform comprehensive comparisons on five downstream tasks that may require visual or physical commonsense knowledge, including PIQA (Bisk et al., 2020), Visual Paraphrasing (VP) (Lin and Parikh, 2015), CSQA (Talmor et al., 2019), OBQA (Mihaylov et al., 2018), and Rid-dleSense (Lin et al., 2021).","We perform comprehensive comparisons on five downstream tasks that may require visual or physical commonsense knowledge, including PIQA (Bisk et al., 2020), Visual Paraphrasing (VP) (Lin and Parikh, 2015), CSQA (Talmor et al., 2018), OBQA (Mihaylov et al., 2018), and Rid-dleSense (Lin et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5604,66-ARR,66-ARR_v2_22@1,66-ARR_v1_24@1,MS COCO contains images reflecting the composition of actual everyday scenes and corresponding captions which describe contextual reasoning between objects in the scene.,MS COCO is a large scale dataset that contains images reflecting the composition of actual everyday scenes and corresponding captions which describe contextual reasoning between objects in the scene.,"Modify,Clarity",Clarity
5605,66-ARR,66-ARR_v2_22@3,66-ARR_v1_24@3,"As an ablation study, we explore other text corpora such as Generic-sKB (Bhakthavatsalam et al., 2020), Wiki103 (Merity et al., 2017 and BookCorpus (Zhu et al., 2015a).","As an ablation study, we explore other text corpora such as GenericsKB (Bhakthavatsalam et al., 2020), Wiki103 (Merity et al., 2016) and BookCorpus (Zhu et al., 2015a).","Modify,Fact/Evidence",Fact/Evidence
5606,66-ARR,66-ARR_v2_24@0,66-ARR_v1_26@0,"For downstream benchmarks, we find tasks that can benefit from visual knowledge: multiple choice question answering tasks including PIQA (Bisk et al., 2020) which requires physical commonsense reasoning, CSQA (Talmor et al., 2019) for general understanding of commonsense reasoning, OBQA (Mihaylov et al., 2018) that needs elemenatry-level science knowledge, and Riddle-Sense (RS) (Lin et al., 2021) for complex understanding of figurative language, and binary classification task including Visual Paraphrasing (VP) (Lin and Parikh, 2015) that needs scene understanding.","For downstream benchmarks, we find tasks that can benefit from visual knowledge: multiple choice question answering tasks including PIQA (Bisk et al., 2020) which requires physical commonsense reasoning, CSQA (Talmor et al., 2018) for general understanding of commonsense reasoning, OBQA (Mihaylov et al., 2018) that needs elemenatry-level science knowledge, and Riddle-Sense (RS) (Lin et al., 2021) for complex understanding of figurative language, and binary classification task including Visual Paraphrasing (VP) (Lin and Parikh, 2015) that needs scene understanding.","Modify,Fact/Evidence",Fact/Evidence
5658,69-ARR,,69-ARR_v1_103@8,,We observe the metric closely follows value of L till 0.1.,"Delete,Fact/Evidence",Fact/Evidence
5659,69-ARR,,69-ARR_v1_103@9,,We note that L will equal θ in this case and the optimal value of θ in the absence of any constraint is 0.1.,"Delete,Fact/Evidence",Fact/Evidence
5660,69-ARR,,69-ARR_v1_104@0,,Training a PSM classifier requires access to gender labels which might not be available for the dataset used to train the model under evaluation.,"Delete,Claim",Claim
5661,69-ARR,,69-ARR_v1_104@1,,"To overcome this, we evaluate training a PSM classifier on a different dataset and then applying it on the dataset of interest.","Delete,Fact/Evidence",Fact/Evidence
5662,69-ARR,,69-ARR_v1_104@2,,"In Table 5, the last two rows record the correlation and mutual information values of a PSM classifier trained on Bias in Bios (tested on Jigsaw) and trained on Jigsaw Toxicity (tested on Bias in Bios), respectively.","Delete,Fact/Evidence",Fact/Evidence
5663,69-ARR,,69-ARR_v1_104@3,,"While we beat the CF baseline using the PSM trained on another dataset, comparison to the setting where v is set using gendered words presents a mixed picture.","Delete,Fact/Evidence",Fact/Evidence
5664,69-ARR,,69-ARR_v1_104@4,,P3 (v set using PSM trained on Jigsaw Toxicity) has a slightly higher correlation of 0.365 compared to 0.363 in the P5 setting.,"Delete,Fact/Evidence",Fact/Evidence
5665,69-ARR,,69-ARR_v1_104@5,,"However, P3 has a slightly worse MI of 0.091 compared to P5.","Delete,Fact/Evidence",Fact/Evidence
5666,69-ARR,,69-ARR_v1_104@6,,The related experiment for Jigsaw toxicity where v is set using PSM trained on Bias in Bios yields similar mixed observations when compared to P5.,"Delete,Fact/Evidence",Fact/Evidence
5667,69-ARR,,69-ARR_v1_105@0,,We also conducted a synthetic experiment wherein we deliberately add bias to the PSM classifier.,"Delete,Fact/Evidence",Fact/Evidence
5668,69-ARR,,69-ARR_v1_105@1,,We reduce the number of 'female' datapoints by 50% leading to about 18% reduction in the recall for the 'female' class (while the 'male' class accuracy remains the same).,"Delete,Fact/Evidence",Fact/Evidence
5669,69-ARR,,69-ARR_v1_105@2,,"We observe that the metric quality also degrades in this case, leading to a correlation of 0.259 with human judgement, in case of the Bias in Bios data.","Delete,Fact/Evidence",Fact/Evidence
5670,69-ARR,,69-ARR_v1_105@3,,This correlation is worse than the CF baseline.,"Delete,Fact/Evidence",Fact/Evidence
5671,69-ARR,,69-ARR_v1_106@0,,"Given these results, we observe that using the PSM classifier improves upon other baselines only when it is relatively un-biased in performance across genders and matched to the dataset at hand.","Delete,Fact/Evidence",Fact/Evidence
5672,69-ARR,,69-ARR_v1_106@1,,"Therefore, we recommend setting v using gendered words if a strong PSM classifier is difficult to obtain.","Delete,Claim",Claim
5673,69-ARR,69-ARR_v2_9@2,,Another set of works focus on group fairness.,,"Add,Claim",Claim
5674,69-ARR,69-ARR_v2_9@3,,Corbett-Davies et al. (2017) present fair classification to ensure population from different race groups receive similar treatment.,,"Add,Fact/Evidence",Fact/Evidence
5675,69-ARR,69-ARR_v2_9@4,,Hardt et al. (2016) focus on shifting the cost of incorrect classification from disadvantaged groups.,,"Add,Fact/Evidence",Fact/Evidence
5676,69-ARR,69-ARR_v2_4@1,69-ARR_v1_4@1,"These methods come under the umbrella of algorithmic fairness which has been quantitatively expressed with numerous definitions (Mehrabi et al., 2019;Jacobs and Wallach, 2019).","These methods come under the umbrella of algorithmic fairness which has been quantitatively expressed with numerous definitions (Mehrabi et al., 2019b;Jacobs and Wallach, 2021).","Modify,Fact/Evidence",Fact/Evidence
5677,69-ARR,69-ARR_v2_4@4,69-ARR_v1_4@4,"On the other hand, group fairness (e.g., statistical parity (Dwork et al., 2012)) evaluates fairness across cohorts with same protected attributes instead of individuals (Mehrabi et al., 2019).","On the other hand, group fairness (e.g., statistical parity (Dwork et al., 2012)) evaluates fairness across cohorts with same protected attributes instead of individuals (Mehrabi et al., 2019b).","Modify,Fact/Evidence",Fact/Evidence
5678,69-ARR,69-ARR_v2_82@0,69-ARR_v1_79@0,"In the future, one can associate the proposed formulation with other categories of group and individual fairness (Mehrabi et al., 2019).","In the future, one can associate the proposed formulation with other categories of group and individual fairness (Mehrabi et al., 2019a).","Modify,Fact/Evidence",Fact/Evidence
5679,69-ARR,69-ARR_v2_83@0,69-ARR_v1_80@0,Broader Impact and Ethics Statement,Broader Impact,"Modify,Other",Other
5680,69-ARR,69-ARR_v2_9@0,69-ARR_v1_9@0,"Multiple efforts have looked into defining, measuring, and mitigating biases in NLP models (Sun et al., 2019;Mehrabi et al., 2019;Sheng et al., 2019).","Multiple efforts have looked into defining, measuring, and mitigating biases in NLP models (Sun et al., 2019;Mehrabi et al., 2019a;Sheng et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5681,69-ARR,69-ARR_v2_9@8,69-ARR_v1_9@4,"Majority of these bias metrics are automatically computed, for example, using a regard classifier (Sheng et al., 2019), sentiment classifier , toxicity classifier (Dixon et al., 2018) or true positive rate difference between privileged and underprivileged groups (De-Arteaga et al., 2019).","Majority of these bias metrics are automatically computed, for example, using a regard classifier (Sheng et al., 2019), sentiment classifier , toxicity classifier (Dixon et al., 2018) or true positive rate difference between privileged and underprivileged groups (De-Arteaga et al., 2019b).","Modify,Fact/Evidence",Fact/Evidence
5682,69-ARR,69-ARR_v2_12@0,69-ARR_v1_12@0,"Below, we define accumulated prediction sensitivity, a metric that captures the sensitivity of a model to protected attributes.","Below, we define accumulated prediction sensitivity, a metric that capture the sensitivity of a model to protected attributes.","Modify,Grammar",Grammar
5718,86-ARR,,86-ARR_v1_70@0,,"Inference Promotion: We can achieve 11.73 and 2.06 absolute inference accuracy improvements compared to the baselines for the NLI and CQA task, respectively.","Delete,Fact/Evidence",Fact/Evidence
5719,86-ARR,,86-ARR_v1_70@1,,"For the NLI task, with our MPII framework, the Transformer baseline model can improve over 5 absolute accuracy score.","Delete,Fact/Evidence",Fact/Evidence
5720,86-ARR,,86-ARR_v1_70@2,,"The ablation study shows the contribution comes from not only the mutual interaction of inference and interpretation in the Stepwise Integration Mechanism (SIM), but also the adversarial mutual information training objective introduced in the Adversarial Fidelity Regularization (AFiRe).","Delete,Fact/Evidence",Fact/Evidence
5721,86-ARR,,86-ARR_v1_70@3,,"Moreover, with parameters initialized with the pretrained BART model, the accuracy can be further improved by a 4.53 absolute score.","Delete,Fact/Evidence",Fact/Evidence
5722,86-ARR,,86-ARR_v1_70@4,,"For the CQA task, we observe that better performance is still achieved compared with the CAGE baseline model.","Delete,Fact/Evidence",Fact/Evidence
5723,86-ARR,,86-ARR_v1_70@5,,"If we remove the AFiRe, a significant inference degradation would be witnessed.","Delete,Claim",Claim
5724,86-ARR,,86-ARR_v1_70@6,,It also indicates the effectiveness of AFiRe for utilizing interpretability to improve the inference ability.,"Delete,Claim",Claim
5725,86-ARR,,86-ARR_v1_71@0,,Interpretation Promotion: The quality of generated interpretation can also be significantly improved with our mutual promotion method on both NLI and CQA tasks.,"Delete,Fact/Evidence",Fact/Evidence
5726,86-ARR,,86-ARR_v1_71@1,,"For NLI task, combined with our MPII, the Transformer baseline model can provide more accurate, fluent and diverse interpretation with much better results in all metrics.","Delete,Fact/Evidence",Fact/Evidence
5727,86-ARR,,86-ARR_v1_71@2,,"Similar with the inference results, the ablation study shows that both SIM and AFiRe contribute to the performance improvement.","Delete,Fact/Evidence",Fact/Evidence
5728,86-ARR,,86-ARR_v1_71@3,,"With the pretrained BART model, we further improve the BLEU and Inter-Rep performance and get comparable PPL compared with the e-INFERSENT model.","Delete,Fact/Evidence",Fact/Evidence
5729,86-ARR,,86-ARR_v1_71@4,,"For CQA task, our method performs better in terms of BLEU score and the diversity of generated explanations.","Delete,Fact/Evidence",Fact/Evidence
5730,86-ARR,,86-ARR_v1_71@5,,"We notice that the BLEU scores are pretty low for CQA task, which may stem from the free form of expression for explanations in the dataset, i.e. several different explanations share the same commonsense knowledge.","Delete,Claim",Claim
5731,86-ARR,86-ARR_v2_73@1,,"The input of the model is ""[CLS] a couple standing on what looks like a peer or boardwalk [SEP] a couple hugging each other at the park"", of which the ground truth label is ""contradiction"".",,"Add,Fact/Evidence",Fact/Evidence
5732,86-ARR,86-ARR_v2_75@1,,"For the second example, our MPII and MPII with AFiRe removed still capture the entailment relation well, and explain that ""at the beach"" and ""at restaurant"" can not be done at the same time.",,"Add,Fact/Evidence",Fact/Evidence
5733,86-ARR,86-ARR_v2_75@2,,"As we can see, these explanations generated by our method are also fluent.",,"Add,Fact/Evidence",Fact/Evidence
5734,86-ARR,86-ARR_v2_76@4,,"Our MPII still explains well, but fails to explain properly with AFiRe removed, even if the explanation contains the correct answer, which reveals the importance of AFiRe for promotion of interpretation.",,"Add,Claim",Claim
5735,86-ARR,,86-ARR_v1_16@1,,Both prediction label and explanation token are generated at every decoding step.,"Delete,Fact/Evidence",Fact/Evidence
5736,86-ARR,,86-ARR_v1_16@2,,Two fusion gates are attached to enable deep interaction of their hidden representations.,"Delete,Fact/Evidence",Fact/Evidence
5737,86-ARR,86-ARR_v2_21@1,86-ARR_v1_22@1,"ReLU(•) here denotes the ReLU activation function (Nair and Hinton, 2010), σ(•) represents the sigmoid function.","ReLU(.) here denotes the ReLU activation function (Nair and Hinton, 2010), σ(.) represents the sigmoid function.","Modify,Grammar",Grammar
5738,86-ARR,86-ARR_v2_35@2,86-ARR_v1_38@0,"The step-by-step explanation helps the model to do better inference, and the stepwise inference in turn guides the generation of better explanation.","Step-by-step interpretation helps the model to better inference, stepwise inference in turn guides the generation of better explanation.","Modify,Clarity",Clarity
5739,86-ARR,86-ARR_v2_40@0,86-ARR_v1_44@0,"Because of the intractability of directly estimating the mutual information in high-dimensional space, we approximate the optimization objective with a Variational Information Maximization lower bound (Chen et al., 2016b;Zhang et al., 2018;Poole et al., 2019):","Because of the intractability of directly estimating the mutual information in high-dimensional space, we approximate the optimization objective with a Variational Information Maximization (Chen et al., 2016b;Zhang et al., 2018) lower bound (Poole et al., 2019):","Modify,Clarity",Clarity
5740,86-ARR,86-ARR_v2_42@1,86-ARR_v1_46@1,"P θ (L, E|X) and Q ϕ (X|L, E) denote the forward network (generating L, E conditioned on X) and the backward network (generating X conditioned on L, E) respectively.","P θ (L, E|X) and Q ϕ (X|L, E) denote the forward network (generating L, R conditioned on X) and the backward network (generating X conditioned on L, E) respectively.","Modify,Fact/Evidence",Fact/Evidence
5741,86-ARR,86-ARR_v2_4@1,86-ARR_v1_4@1,"In order to break the black-box of neural networks, many works explore the interpretability of neural networks through providing interpretations to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2019;Thorne et al., 2019;Kumar and Talukdar, 2020).","In order to break the black-box of neural networks, many works explore the interpretability of neural networks through providing interpretation to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2018;Thorne et al., 2019;Kumar and Talukdar, 2020).","Modify,Fact/Evidence",Fact/Evidence
5742,86-ARR,86-ARR_v2_51@0,86-ARR_v1_55@0,"Besides, we add an objective term P θ (L, E|X) of maximize the negative likelihood of P θ to balance the positive samples as teacher-forcing algorithm (Li et al., 2017).","We also add an objective term P θ (L, E|X) of maximum the negative likelihood of P θ to balance the positive samples as teacher-forcing algorithm (Li et al., 2017).","Modify,Other",Other
5743,86-ARR,86-ARR_v2_57@0,86-ARR_v1_61@0,"We use six datasets as our testbeds: SNLI (Bowman et al., 2015), e-SNLI (Camburu et al., 2018), CQA (Talmor et al., 2019), CoS-E (Rajani et al., 2019, MultiNLI (Williams et al., 2018), and SICK-E (Marelli et al., 2014).","We use six datasets as our testbeds: SNLI (Bowman et al., 2015), e-SNLI (Camburu et al., 2018), CQA (Talmor et al., 2018), CoS-E (Rajani et al., 2019), MultiNLI (Williams et al., 2018), and SICK-E (Marelli et al., 2014).","Modify,Fact/Evidence",Fact/Evidence
5744,86-ARR,86-ARR_v2_58@3,86-ARR_v1_62@3,"SICK-e (Sentences Involving Compositional Knowledge for entailment) provides sentence pairs that are rich in the lexical, syntactic and semantic phenomena.","SICKe(Sentences Involving Compositional Knowledge for entailment) provides sentence pairs that are rich in the lexical, syntactic and semantic phenomena.","Modify,Grammar",Grammar
5745,86-ARR,86-ARR_v2_58@4,86-ARR_v1_62@4,The latter two datasets are used for out-of-domain evaluation.,The latter two datasets are used for out-of-domain test.,"Modify,Clarity",Clarity
5746,86-ARR,86-ARR_v2_60@3,86-ARR_v1_64@3,"The Transformer model (Vaswani et al., 2017) adds a MLP layer for making predictions.","The Transformer model (Vaswani et al., 2017) adds a MLP layer for generating sentencelevel interpretations.","Modify,Fact/Evidence",Fact/Evidence
5747,86-ARR,86-ARR_v2_67@0,86-ARR_v1_73@0,"As shown in Table 2, we evaluate our method with the Transformer baseline model on two outof-domain datasets: MultiNLI and SICK-E. The results show that our mutual promotion method enables the Transformer model to be more robust, and achieves about 3 absolute accuracy improvement on both of the out-of-domain datasets without fine-tuning.","As shown in Table 2, we evaluate our method with the Transformer baseline model on two outof-domain datasets: MultiNLI and SICK-E. The results show that our mutual promotion method enables the Transformer model to be more robust, and achieve more than 3 accuracy improvement on both of the out-of-domain datasets without fine-tuning.","Modify,Fact/Evidence",Fact/Evidence
5748,86-ARR,86-ARR_v2_67@2,86-ARR_v1_74@1,The ablation results demonstrate both the adversarial mutual information training strategy in AFiRe and deep integration in SIM is very effective to improve the model's generalization and robustness.,The ablation results demonstrate the adversarial mutual information training strategy in AFiRe is very effective to improve the model's generalization and robustness.,"Modify,Fact/Evidence",Fact/Evidence
5749,86-ARR,86-ARR_v2_8@1,86-ARR_v1_8@1,"Considering readability and comprehensibility for humans, some works turn to generate token-level explanations (Liu et al., 2019;Thorne et al., 2019), which are nevertheless prone to cause ambiguity.","Considering readability and comprehensibleness for human, some works turn to generate token-level explanations (Liu et al., 2018;Thorne et al., 2019), which nevertheless prone to cause ambiguity.","Modify,Fact/Evidence",Fact/Evidence
5750,86-ARR,86-ARR_v2_73@4,86-ARR_v1_80@1,"From the clear split of the red and blue lines when ""does"" and ""not"" are generated, we can see that the prediction is very sensitive to explanation, which demonstrates the faithfulness (Kumar and Talukdar, 2020).","From the clear split of the red and blue lines when 'does' and 'not' are generated, we can see that the prediction is very sensitive to explanation, which demonstrates the faithfulness (Kumar and Talukdar, 2020).","Modify,Grammar",Grammar
5751,86-ARR,86-ARR_v2_76@1,86-ARR_v1_82@1,"For the first example, CAGE makes wrong prediction, and generates explanation that obviously conflicts with common knowledge.","For the first exapmle, CAGE makes wrong prediction, and generates explanation that obviously conflicts with common knowledge.","Modify,Grammar",Grammar
5752,86-ARR,86-ARR_v2_79@0,86-ARR_v1_86@0,"With the great success of natual language inference, many recent works explore the interpretability of neural networks through providing interpretation to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2019;Thorne et al., 2019;Kumar and Talukdar, 2020).","With the great success of natual language inference, many recent works explore the interpretability of neural networks through providing interpretation to support their inference results (Ribeiro et al., 2016;Chen et al., 2018;Liu et al., 2018;Thorne et al., 2019;Kumar and Talukdar, 2020).","Modify,Fact/Evidence",Fact/Evidence
5753,86-ARR,86-ARR_v2_8@6,86-ARR_v1_8@6,"Intuitively, human language sentence-level interpretations containing reasoning logic are the best form for human to understand.","Intuitively, human language sentence-level interpretations containing reasoning logic is the best form for human to understand.","Modify,Grammar",Grammar
5754,86-ARR,86-ARR_v2_9@0,86-ARR_v1_9@0,"With annotated natural language interpretation datasets available (Camburu et al., 2018;Rajani et al., 2019), methods of generating sentence-level interpretation have been explored recently.","With the annotated natural language interpretation datasets available (Camburu et al., 2018;Rajani et al., 2019), methods of generating sentencelevel interpretation have been explored recently.","Modify,Grammar",Grammar
5755,86-ARR,86-ARR_v2_9@2,86-ARR_v1_9@2,"Kumar and Talukdar (2020) proposed to first generate sentence-level interpretations with deep pre-trained language models (such as BERT and GPT), then fed those interpretations as extra knowledge to help improve inference performance.","Kumar and Talukdar (2020) proposed to first generate sentence-level interpretation with deep pre-trained language models (such as BERT and GPT), then fed those interpretation as extra knowledge to help improve inference performance.","Modify,Grammar",Grammar
5756,86-ARR,86-ARR_v2_12@0,86-ARR_v1_12@0,"• Different from the previous works that only include one-side promotion, we mutually promote the inference and sentence-level interpretation from both the model-level and the optimization-level. • We propose a Stepwise Integration Mechanism to tightly fuse latent prediction and interpretation information at every decoding step, and an Adversarial Fidelity Regularization to further improve the fidelity with the adversarial training strategy. • Experiment results show that our method achieves significant improvement in both inference accuracy and interpretation quality compared with baseline models.","• Different from the previous works that only include one-side promotion, we mutually promote the inference and sentence-level interpretation from both the model-level and the optimization-level. • We propose a Stepwise Integration Mechanism to tightly fuse latent prediction and interpretation information at every decoding step, and an Adversarial Fidelity Regularization to further improve the fidelity with the adversarial training strategy. • Experiment results show that our method achieve significant improvement in both inference accuracy and interpretation quality compared with baseline models.","Modify,Grammar",Grammar
5757,86-ARR,86-ARR_v2_14@1,86-ARR_v1_14@1,"Utilizing the autoregressive nature of Transformer decoder, SIM enables deep interaction at every decoding step between inference and interpretation.","Utilizing the autoregressive nature of Transformer decoder, SIM allows deep interaction at every decoding step between inference and interpretation.","Modify,Clarity",Clarity
5758,86-ARR,86-ARR_v2_14@2,86-ARR_v1_14@2,"With the adversarial training strategy, AFiRe enables further integration of latent semantic information between inference and interpretation, and also improves the quality of explanation sentences by bringing them closer to human expressions.","With the adversarial training strategy, AFiRe allows further integration of latent semantic information between inference and interpretation, and also improves the quality of explanation sentences, bringing them closer to human expressions.","Modify,Clarity",Clarity
5759,89-ARR,,89-ARR_v1_26@6,,Our results alert investors who use text-based stock prediction models to deploy defense systems to guard against loss caused by potential adversarial attack.,"Delete,Claim",Claim
5760,89-ARR,,89-ARR_v1_29@0,,"In summary, we show that financial forecast models are vulnerable to adversarial attack even if it is subject to certain physical constraints.","Delete,Claim",Claim
5761,89-ARR,,89-ARR_v1_12@4,,"A directional financial forecast model takes domains of tweets and numerical factors as input, and yields prediction for stocks' directional movement y ∈ {−1, 1}:","Delete,Fact/Evidence",Fact/Evidence
5762,89-ARR,89-ARR_v2_19@1,89-ARR_v1_20@1,"Specifically, the boolean variables (for tweet and word selection) are relaxed into the continuous space so that they can be optimized by gradientbased methods over a convex hull.","Specifically, the boolean variables (for tweet and word selection) would be relaxed into the continuous space so that they can be optimized by gradient-based methods over a convex hull.","Modify,Clarity",Clarity
5763,89-ARR,89-ARR_v2_21@1,89-ARR_v1_22@1,"We evaluate our adversarial attack on a stock prediction dataset consisting of 10,824 instances including relevant tweets and numerical features of 88 stocks from 2014 to 2016 (Xu and Cohen, 2018).","We evaluate our adversarial attack on a stock prediction dataset consisting of 10824 instances including relevant tweets and numerical features of 88 stocks from 2014 to 2016 (Xu and Cohen, 2018).","Modify,Grammar",Grammar
5764,89-ARR,89-ARR_v2_4@0,89-ARR_v1_4@0,"The advance of deep learning based language models are playing a more and more important role in the financial context, including convolutional neutral network (CNN) (Ding et al., 2015), recurrent neutral network (RNN) (Minh et al., 2018), long short-term memory network (LSTM) (Hiew et al., 2019;Sawhney et al., 2021;Hochreiter and Schmidhuber, 1997), graph neutral network (GNN) (Sawhney et al., 2020a,b), transformer , autoencoder (Xu and Cohen, 2018), etc.","The advance of deep learning based language models are playing a more and more important role in the financial context, including convolutional neutral network (CNN) (Ding et al., 2015), recurrent neutral network (RNN) (Minh et al., 2018), long short-term memory network (LSTM) (Hiew et al., 2019;Sawhney et al., 2021;Hochreiter and Schmidhuber, 1997), graph neutral network (GNN) (Sawhney et al., 2020a,b), transformer (Yang et al., 2020), autoencoder (Xu and Cohen, 2018), etc.","Modify,Fact/Evidence",Fact/Evidence
5765,89-ARR,89-ARR_v2_21@3,89-ARR_v1_22@3,We apply our attack to instances on which the victim models make correct predictions.,We apply our attack to instances on which the victim models make correct prediction.,"Modify,Grammar",Grammar
5766,89-ARR,89-ARR_v2_24@2,89-ARR_v1_25@2,"For both JO and AGO, ASR increases by roughly 10% and F1 drops by 0.1 on average in comparison to the random attack.","As we can see, for both JO and AGO, ASR increases by roughly 10% and F1 drops by 0.1 on average in comparison to random attack.","Modify,Clarity",Clarity
5767,89-ARR,89-ARR_v2_24@6,89-ARR_v1_25@6,It appears that the attack performance becomes saturated if we keep increasing the attack budgets.,It appears that the attack performance becomes saturated if we keep increasing the attack budget.,"Modify,Grammar",Grammar
5768,89-ARR,89-ARR_v2_24@7,89-ARR_v1_25@7,"In fact, the attack with budget of one tweet and one word is the most cost effective, provided that it introduces minimum perturbation but achieves a relatively similar ASR.","In fact, the attack with budget of one tweet and one word is most cost effective, provided that it introduces minimum perturbation but achieves relatively similar ASR.","Modify,Grammar",Grammar
5769,89-ARR,89-ARR_v2_26@3,89-ARR_v1_26@4,"For each simulation, the investor has $10K (100%) to invest; the results show that the proposed attack method with a retweet with only a single word replacement can cause the investor an additional $3.2K (75%-43%) loss to their portfolio after about 2 years.","For each simulation, net values are set as 100% at the beginning.","Merge+Modify,Fact/Evidence",Fact/Evidence
5770,89-ARR,89-ARR_v2_26@3,89-ARR_v1_26@5,"For each simulation, the investor has $10K (100%) to invest; the results show that the proposed attack method with a retweet with only a single word replacement can cause the investor an additional $3.2K (75%-43%) loss to their portfolio after about 2 years.",The results show that even replacement of a single word in one tweet can cause a 32% (75%-43%) additional loss to the portfolio.,"Merge+Modify,Fact/Evidence",Fact/Evidence
5771,89-ARR,89-ARR_v2_28@0,89-ARR_v1_29@1,This work demonstrates that our adversarial attack method consistently fools various financial forecast models even with physical constraints that the raw tweet can not be modified.,The experiments demonstrate that our adversarial attack method consistently fools various models.,"Modify,Claim",Claim
5772,89-ARR,89-ARR_v2_28@1,89-ARR_v1_29@2,"Adding a retweet with only one word replaced, the attack can cause 32% additional loss to our simulated investment portfolio.","Moreover, with replacement of a single word on one tweet, the attack can cause 32% additional loss to our simulated portfolio.","Modify,Fact/Evidence",Fact/Evidence
5773,89-ARR,89-ARR_v2_28@2,89-ARR_v1_29@3,"Via studying financial model's vulnerability, our goal is to raise financial community's awareness of the AI model's risks, so that in the future we can develop more robust human-in-theloop AI architecture (Wang et al., 2019) to cope with this and other real-world attacks, including black-box attack, unknown input domains, etc.","Through studying vulnerability of financial forecast models, our goal is to raise financial community's awareness of the model robustness.","Merge+Modify,Clarity",Clarity
5774,89-ARR,89-ARR_v2_28@2,89-ARR_v1_29@4,"Via studying financial model's vulnerability, our goal is to raise financial community's awareness of the AI model's risks, so that in the future we can develop more robust human-in-theloop AI architecture (Wang et al., 2019) to cope with this and other real-world attacks, including black-box attack, unknown input domains, etc.","In the future, we plan to introduce more real-world constraints, including black-box attack, unknown input domains, etc.","Merge+Modify,Claim",Claim
5775,89-ARR,89-ARR_v2_2@0,89-ARR_v1_2@0,"More and more investors and machine learning models rely on social media (e.g., Twitter and Reddit) to gather real-time information and sentiment to predict stock price movements.","More and more investors and machine learning models rely on social media (e.g., Twitter and Reddit) to gather information and predict movements stock prices.","Modify,Claim",Claim
5776,89-ARR,89-ARR_v2_40@1,89-ARR_v1_41@1,"An computationally efficient fashion is to optimize over a convex hull constructed with linear combination of candidate set, and the optimal replacement goes with word with highest weight (Dong et al., 2021).","An computationally efficient fashion is to optimize over a convex hull constructed with linear combination of candidate set, and optimal replacement goes with word with highest weight (Dong et al., 2021).","Modify,Grammar",Grammar
5777,89-ARR,89-ARR_v2_5@1,89-ARR_v1_5@1,"The perturbation can be at the sentence level (e.g., Xu et al., 2021;Iyyer et al., 2018;Ribeiro et al., 2018), the word level (e.g., Zhang et al., 2019;Alzantot et al., 2018;Zang et al., 2020;Jin et al., 2020;Lei et al., 2019;Zhang et al., 2021;Lin et al., 2021), or both (Chen et al., 2021).","The perturbation can be done at the sentence level (e.g., Xu et al., 2021;Iyyer et al., 2018;Ribeiro et al., 2018), the word level (e.g., Zhang et al., 2019;Alzantot et al., 2018;Zang et al., 2020;Jin et al., 2020;Lei et al., 2018;Zhang et al., 2021;Lin et al., 2021), or both (Chen et al., 2021).","Modify,Fact/Evidence",Fact/Evidence
5778,89-ARR,89-ARR_v2_5@2,89-ARR_v1_5@2,"We are interested in whether such adversarial attack vulnerability also exists in stock prediction models, as these models embrace more and more human-generated media data (e.g., Twitter, Reddit, Stocktwit, Yahoo News (Xu and Cohen, 2018;Sawhney et al., 2021)).","We are interested in whether such adversarial attack vulnerability also exists in stock prediction models, as these models embrace more and more user-generated public data (e.g., Twitter, Reddit, or Stocktwit (Xu and Cohen, 2018;Sawhney et al., 2021)).","Modify,Fact/Evidence",Fact/Evidence
5779,89-ARR,89-ARR_v2_5@3,89-ARR_v1_5@3,The adversarial robustness is a more critical issue in the context of stock prediction as anyone can post perturbed tweets or news to influence forecasting models.,The adversarial robustness may be a more critical topic in the context of stock prediction as anyone can post perturbed tweets to influence forecast models.,"Modify,Clarity",Clarity
5780,89-ARR,89-ARR_v2_5@4,89-ARR_v1_5@4,"For example, a fake news (""Two Explosions in the White House and Barack Obama is Injured"") posted by a hacker using the Associated-Press's Twitter account on 04/23/2013 erased $136 billion market value in just 60 seconds (Fisher, 2013).","As one example, a fake news (""Two Explosions in the White House and Barack Obama is Injured"") posted by a hacker using the AssociatedPress's Twitter account on 04/23/2013 erased $136 billion in stock market in just 60 seconds (Fisher, 2013).","Modify,Clarity",Clarity
5781,89-ARR,89-ARR_v2_5@5,89-ARR_v1_5@5,"Although the event doesn't fall into the category of adversarial attack, it rings the alarm for traders who use (social) media information for their trading decisions.","Although the event doesn't fall into the category of adversarial attack, it rings the alarm for traders who take information from social media to back their trading decision.","Modify,Clarity",Clarity
5782,89-ARR,89-ARR_v2_62@7,89-ARR_v1_63@7,The results show that loss smoothing does not contribute to attack performance in our experiment as it does in Srikant et al. (2021).,"The results show that loss smoothing does not contribute to attack performance in our experiment as it does in (Srikant et al., 2021).","Modify,Grammar",Grammar
5783,89-ARR,89-ARR_v2_63@2,89-ARR_v1_64@2,We then run Kmeans clustering on these 18 corpora based on the feature matrix from LIWC.,We then run Kmeans clustering these 18 corpora based on the feature matrix from LIWC.,"Modify,Grammar",Grammar
5784,89-ARR,89-ARR_v2_2@1,89-ARR_v1_2@1,"Although text-based models are known to be vulnerable to adversarial attacks, whether stock prediction models have similar vulnerability is underexplored.","Although textbased models are known to be vulnerable to adversarial attacks, whether stock prediction models have similar vulnerability given necessary constraints is underexplored.","Modify,Clarity",Clarity
5785,89-ARR,89-ARR_v2_6@1,89-ARR_v1_6@1,"Many attacks modify benign text directly (manipulation attack) and use them as model input; However, in our case, adversarial retweets enter the model along with benign tweets (concatenation attack), which is more realistic as malicious Twitter users can not modify others' tweets.","Many attack modifies benign text directly (manipulation attack) and use them as model input; However, in our case, adversarial retweets enter the model along with benign tweets (concatenation attack), which is more realistic as malicious Twitter users can not modify others' tweets.","Modify,Grammar",Grammar
5786,89-ARR,89-ARR_v2_6@2,89-ARR_v1_6@2,"In other words, we formulate the task as a text-concatenating attack (Jia and Liang, 2017;Le et al., 2021): we implement the attack by injecting new tweets instead of manipulating existing benign tweets.","In other words, we formulate the task as text-concatenating attack (Jia and Liang, 2017;Le et al., 2021): we implement the attack by injecting new tweets instead of manipulating existing benign tweets.","Modify,Grammar",Grammar
5787,89-ARR,89-ARR_v2_6@3,89-ARR_v1_6@3,"Our task is inspired and mimics the retweet function on social media, and uses it to feed the adversarial samples into the dataset.","Our task is inspired and mimics the retweet function on social media, and use it to feed the adversarial samples into the dataset.","Modify,Grammar",Grammar
5788,89-ARR,89-ARR_v2_6@4,89-ARR_v1_6@4,"Despite various algorithms are proposed to generate manipulation attack, literature of concatenation attack on classification models is rare, with exceptions Le et al. (2021), Song et al. (2021) and Wang et al. (2020).","Despite various algorithms are proposed to generate manipulation attack, literature of concatenation attack on classification model is rare, with exceptions Le et al. (2021), Song et al. (2021) and Wang et al. (2020).","Modify,Grammar",Grammar
5789,89-ARR,89-ARR_v2_6@5,89-ARR_v1_6@5,Our paper provides extra evidence of their difference by investigating their performances in the financial domain.,Our paper provides extra evidence of their difference by investigating their performances in the domain of finance.,"Modify,Clarity",Clarity
5790,89-ARR,89-ARR_v2_7@0,89-ARR_v1_7@0,The main challenge is to craft new and effective adversarial tweets.,The main challenge is to craft new adversarial tweets.,"Modify,Claim",Claim
5791,89-ARR,89-ARR_v2_7@1,89-ARR_v1_7@1,We solve the task by aligning the semantics with benign tweets so that the potential human and machine readers can't detect our adversarial tweets.,"While the adversarial tweets can be arbitrary given that they are newly posted, we solve the task by aligning the semantics with benign tweets so that potential human and machine readers can not detect our adversarial tweets.","Modify,Claim",Claim
5792,89-ARR,89-ARR_v2_7@3,89-ARR_v1_7@3,"Specific tweets are first selected, which are used as the target of perturbation on a limit number of words within the tweets.","Specific tweets are first selected, which are used as target of perturbation on a limit number of words within the tweets.","Modify,Grammar",Grammar
5793,89-ARR,89-ARR_v2_7@6,89-ARR_v1_7@6,"More astonishingly, the attack can cause additional loss of 23% to 32% if an investor trades on the predictions of the victim models (Fig. 4).","More astonishingly, the attack can cause additional loss of 23% to 32% if the investor trades on predictions of the victim models (Fig. 4).","Modify,Grammar",Grammar
5794,89-ARR,89-ARR_v2_10@3,89-ARR_v1_10@3,"Secondly, adversarial tweets are optimized to be semantically similar to the original tweets so that they are not counterfactual and very likely to fool human sanity checks as well as the Twitter's content moderation system.","Secondly, adversarial tweets are optimized to be semantically similar to original tweets so that they are not counterfactual and very likely fool human sanity checks as well as the Twitter's content moderator mechanisms.","Modify,Clarity",Clarity
5795,89-ARR,89-ARR_v2_11@1,89-ARR_v1_11@1,The challenge of our attack method centers around how to select the optimal tweets and the token perturbations with the constraints of semantic similarity.,The challenge of our attack method centers around how to select the optimal tweets and the token perturbations with constraints of semantic similarity.,"Modify,Grammar",Grammar
5796,89-ARR,89-ARR_v2_11@3,89-ARR_v1_11@3,"In the first step, a set of optimal tweets is first selected as the target tweets to be perturbed and retweeted.","In the first step, a set of optimal tweets is first selected as target tweets to be perturbed and retweeted.","Modify,Grammar",Grammar
5797,89-ARR,89-ARR_v2_11@4,89-ARR_v1_11@4,"For each selected tweet in the pool, the word selection problem is then solved to find one or more optimal words to apply perturbation.","For each selected tweet in the pool, the word selection problem is then solved to find one or more best words to apply perturbation.","Modify,Clarity",Clarity
5798,89-ARR,89-ARR_v2_11@5,89-ARR_v1_11@5,Word and tweet budgets are also introduced to quantify the strength of the perturbation.,Word and tweet budgets are also introduced to quantifies the strength of perturbation.,"Modify,Grammar",Grammar
5799,89-ARR,89-ARR_v2_12@0,89-ARR_v1_12@0,"We consider the word replacement and deletion for word perturbation (Garg and Ramakrishnan, 2020;Li et al., 2020).","We consider word replacement and deletion for word perturbation (Garg and Ramakrishnan, 2020;Li et al., 2020).","Modify,Grammar",Grammar
5800,89-ARR,89-ARR_v2_12@2,89-ARR_v1_12@2,"A synonym as replacement is widely adopted in the word-level attack since it is a natural choice to preserve semantics (Zang et al., 2020;Dong et al., 2021;Zhang et al., 2019;Jin et al., 2020).","Synonym as replacement is widely adopted in the word-level attack since it is a natural choice to preserve semantics (Zang et al., 2020;Dong et al., 2021;Zhang et al., 2019;Jin et al., 2020).","Modify,Grammar",Grammar
5801,89-ARR,89-ARR_v2_17@1,89-ARR_v1_18@1,"Consequently, given attack loss L, generation of adversarial retweets can be formulated as the optimization program min m,z,u and c) 1 T u i,j = 1, ∀i, j, where b s and b w denote the tweet and word budgets.","Consequently, given attack loss L, generation of adversarial retweets can be formulated as the optimization program min m,z,u and c) 1 T u i,j = 1, ∀i, j, where b s and b w denote the tweet and word budget.","Modify,Grammar",Grammar
5802,89-ARR,89-ARR_v2_17@2,89-ARR_v1_18@2,It is worth to stress that perturbation is only applied to the date (t) when the attack is implemented to preserve the temporal order.,It is worth to stress that perturbation is only applied to the date (t) when the attack is implemented to preserve temporal order.,"Modify,Grammar",Grammar
5932,91-ARR,,91-ARR_v1_49@1,,"Assume that there are D news articles {d 1 , d 2 , . . . , d D }, where each article d i contains a maximum number of N tokens t i 1 , t i 2 , ..., t i N , and the vocabulary size among the corpus is V .","Delete,Fact/Evidence",Fact/Evidence
5933,91-ARR,,91-ARR_v1_50@0,,"For a head h k , its attention weight distribution from each document is combined to form a document-token weight matrix M k with size of D × V , as illustrated in Figure 2.","Delete,Fact/Evidence",Fact/Evidence
5934,91-ARR,,91-ARR_v1_72@4,,We also plan to apply our model to other NLP tasks in the future.,"Delete,Claim",Claim
5935,91-ARR,91-ARR_v2_2@5,,We release the source code here 1 .,,"Add,Fact/Evidence",Fact/Evidence
5936,91-ARR,91-ARR_v2_49@1,,"The resulting topic distribution takes the form of a V × K weight matrix, calculated from a trained MHA layer using embedded word vectors as inputs.",,"Add,Fact/Evidence",Fact/Evidence
5937,91-ARR,91-ARR_v2_19@0,91-ARR_v1_18@0,"There are two popular embedding methods: wordlevel embedding and contextual embedding, in general.","In general, there are two popular embedding methods: word-level embedding and contextual embedding.","Modify,Clarity",Clarity
5938,91-ARR,91-ARR_v2_19@1,91-ARR_v1_18@1,"Word-level embedding methods, such as GloVe, project different words into a word vector space and acquire a fixed-length word vector through a pre-trained embedding matrix.","Word-level embedding methods, such as Glove, project different words into a highdimensional space and acquires a fixed-length word vector through a pre-trained embedding matrix.","Modify,Clarity",Clarity
5939,91-ARR,91-ARR_v2_19@2,91-ARR_v1_18@2,"Contextual embedding models, such as BERT, generate different word vectors based on each word's context, so that the same word in different contexts can produce very different word vectors.","Contextual embedding models, such as BERT, generates different word vectors based on each word's context, so that the same word in different contexts can produce very different word vectors.","Modify,Grammar",Grammar
5940,91-ARR,91-ARR_v2_4@0,91-ARR_v1_4@0,The attention mechanism is one of the most important components in recent deep learning-based architectures in natural language processing (NLP).,The attention mechanism is one of the most important components in recent deep learning-based architectures in the field of natural language processing (NLP).,"Modify,Clarity",Clarity
5941,91-ARR,91-ARR_v2_21@1,91-ARR_v1_20@1,We compute the weight distribution g k of the head vector h k through a single-layer feed-forward network first:,We compute the weight distribution of the head h k through a singlelayer feed-forward network first:,"Modify,Fact/Evidence",Fact/Evidence
5942,91-ARR,91-ARR_v2_23@0,91-ARR_v1_22@0,We then use the softmax function to get the normalized weights distribution α k among the document:,We then use the softmax function to get the normalized weights distribution among the document:,"Modify,Fact/Evidence",Fact/Evidence
5943,91-ARR,91-ARR_v2_4@1,91-ARR_v1_4@1,"In the early stages of its development, the encoderdecoder models (Bahdanau et al., 2015;Xu et al., 2015) often adopted an attention mechanism to improve the performance achieved by capturing different areas of the input sequence when generating an output in the decoding process to solve issues arising in encoding long-form inputs.","In the early stages of its development, the attention mechanism is often adopted to enhance encoder-decoder models (Bahdanau et al., 2015;Xu et al., 2015).","Merge+Modify,Clarity",Clarity
5944,91-ARR,91-ARR_v2_38@0,91-ARR_v1_37@0,Classification Layer,Classifier Layer,"Modify,Clarity",Clarity
5945,91-ARR,91-ARR_v2_39@0,91-ARR_v1_38@0,"Since the representation of each document d will be a dense vector containing a mixture of information about the document's content, we can use it as the feature vector for the final news classification task:","Since the representation of each document d will be a high-dimensional vector containing a mixture of information about the document's content, we can use it as the feature vector for the final news classification task:","Modify,Fact/Evidence",Fact/Evidence
5946,91-ARR,91-ARR_v2_42@0,91-ARR_v1_41@0,"In order to further improve the explainability of our base model as described above, we now adjust the model so that each head only focuses on a specific set of words -i.e. we enforce topic-word weights distribution α k not to spread over the document widely.","In order to further improve the explainability of our base model as described above, we now adjust the model so that each head only focuses on a specific set of words -i.e. we enforce topic-word weights distribution α k not to widely spread over the document.","Modify,Clarity",Clarity
5947,91-ARR,91-ARR_v2_4@1,91-ARR_v1_4@2,"In the early stages of its development, the encoderdecoder models (Bahdanau et al., 2015;Xu et al., 2015) often adopted an attention mechanism to improve the performance achieved by capturing different areas of the input sequence when generating an output in the decoding process to solve issues arising in encoding long-form inputs.","This is achieved by capturing different areas of the input sequence when generating an output in the decoding process, to solve issues arising in encoding long-form inputs.","Merge+Modify,Clarity",Clarity
5948,91-ARR,91-ARR_v2_48@0,91-ARR_v1_48@0,Generating the Topic Distribution,Generating Global Topic Representations,"Modify,Fact/Evidence",Fact/Evidence
5949,91-ARR,91-ARR_v2_50@0,91-ARR_v1_50@1,"Moreover, to identify the most important words for each topic (which we can view as being the topic's descriptor), we extract the top-T words from the topic distribution, which can help us understand the heads and interpret them as topics.","Moreover, to identify the most significant tokens of the topic (which we can view as being the topic's descriptor), we can adopt a strategy such as taking the average on M k along all documents.","Merge+Modify,Fact/Evidence",Fact/Evidence
5950,91-ARR,91-ARR_v2_50@0,91-ARR_v1_50@2,"Moreover, to identify the most important words for each topic (which we can view as being the topic's descriptor), we extract the top-T words from the topic distribution, which can help us understand the heads and interpret them as topics.","After summarizing the top-T words from different heads, we can understand the head's meaning.","Merge+Modify,Fact/Evidence",Fact/Evidence
5951,91-ARR,91-ARR_v2_50@1,91-ARR_v1_50@3,We examine the interpretations of these topic descriptors and display some examples in Section 4.5.,"Furthermore, we examine the meanings of topic descriptors and display some examples in Section 4.5.","Modify,Clarity",Clarity
5952,91-ARR,91-ARR_v2_54@6,91-ARR_v1_54@6,"The second one is the News Category Dataset 3 , which contains approximately 200k news articles (each of them include a headline and a short news description) from 2012 to 2018 obtained from HuffPost.","The second one is the News Category Dataset 2 , which contains around 200K news articles (each of them include a headline and a short news description) from 2012 to 2018 obtained from HuffPost.","Modify,Clarity",Clarity
5953,91-ARR,91-ARR_v2_54@7,91-ARR_v1_54@7,"The original dataset has 41 categories, but some of these are duplicates.","The original dataset has 41 categories, but some of them are duplicates.","Modify,Clarity",Clarity
5954,91-ARR,91-ARR_v2_54@8,91-ARR_v1_54@8,"After merging the duplicated categories, there are 26 categories remain, which is denoted as News-26.","After merging these duplicated categories, there are 26 categories remain, which is denoted as News-26.","Modify,Clarity",Clarity
5955,91-ARR,91-ARR_v2_54@9,91-ARR_v1_54@9,We randomly split these two datasets into training/validation/test sets with a 80/10/10 split.,We randomly split these two datasets into training/validation/test sets with a 80/20/20 split.,"Modify,Fact/Evidence",Fact/Evidence
5956,91-ARR,91-ARR_v2_54@10,91-ARR_v1_54@10,Table 1 summarizes the divisions and the key statistics of the datasets.,Table 1 summarises the divisions and the key statistics of the datasets.,"Modify,Grammar",Grammar
5957,91-ARR,91-ARR_v2_58@2,91-ARR_v1_58@2,"For the attention-based model, Fastformer, we initialize its embedding matrix using GloVe embedding and follow the hyper-parameter settings in (Wu et al., 2021).","For the attention-based model, Fastformer, we initialize its embedding matrix using Glove embedding and follow the hyper-parameter settings in (Wu et al., 2021).","Modify,Grammar",Grammar
5958,91-ARR,91-ARR_v2_59@0,91-ARR_v1_59@0,Experimental Settings,Experimental Setting,"Modify,Grammar",Grammar
5959,91-ARR,91-ARR_v2_60@0,91-ARR_v1_60@0,"In our experiments, we consider two ways to initialize our embedding matrix: GloVe embedding (Pennington et al., 2014) and context embeddings from a pre-trained language model DistilBERT (Sanh et al., 2019), where embedding weights are not fixed during the training procedure.","In our experiments, we consider two ways to initialize our embedding matrix, Glove embedding (Pennington et al., 2014) and context embeddings from a pre-trained language model DistilBERT (Sanh et al., 2019) respectively.","Modify,Fact/Evidence",Fact/Evidence
5960,91-ARR,91-ARR_v2_60@1,91-ARR_v1_60@1,"We examine how different number of heads would influence the performance of our proposed model on the validation set, the details is shown in Figure 3.","We have examined how different number of heads would influence the performance of our proposed model on the validation set, the details is shown in Figure 3.","Modify,Grammar",Grammar
5961,91-ARR,91-ARR_v2_4@4,91-ARR_v1_4@5,"However, the inherent characteristics of deep learning models and the flexibility of the attention mechanism increase these models' complexity, thus leading to challenges in model explainability.","However, the inherent characteristics of deep learning models and the flexibility of the attention mechanism increases the complexity of these models, thus leading to challenges in terms of model explainability.","Modify,Clarity",Clarity
5962,91-ARR,91-ARR_v2_60@2,91-ARR_v1_60@2,"Unsurprisingly, on the MIND data set, the model needs to set a relatively larger number of topics, because the average length of news articles in the MIND dataset and its vocabulary size are much larger than the News-26 dataset, as indicated in Table 1.","Not surprisingly, on the MIND data set, the model needs to set a relatively larger number of topics, because the average length of news articles in the MIND dataset and its vocabulary size are much larger than the News-26 dataset, as indicated in Table 1.","Modify,Grammar",Grammar
5963,91-ARR,91-ARR_v2_2@0,91-ARR_v1_2@0,Many recent deep learning-based solutions have adopted the attention mechanism in various tasks in the field of NLP.,Many recent deep learning-based solutions have widely adopted the attention-based mechanism in various tasks of the NLP discipline.,"Modify,Clarity",Clarity
5964,91-ARR,91-ARR_v2_62@0,91-ARR_v1_62@0,"The large pre-trained transformer variants perform better than the model with GloVe embedding, both for MIND-15 and News-26.","The large pre-trained transformer variants perform better than the model with Glove embedding, both for MIND-15 and News-26.","Modify,Grammar",Grammar
5965,91-ARR,91-ARR_v2_62@1,91-ARR_v1_62@1,"Compared to Fastformer-GloVe, our BATM-Base-GloVe model achieves a similar result (variance in 0.3% of accuracy and 0.4% of Macro-F) for MIND-15 and a better result (variance in almost 0.4% of accuracy and 0.6% of Macro-F) for News-26.","Compared to Fastformer-Glove, our BATM-Base-Glove model achieves a similar result (variance in 0.3% of accuracy and 0.4% of Macro-F) for MIND-15 and a better result (variance in almost 0.4% of accuracy and 0.6% of Macro-F) for News-26.","Modify,Grammar",Grammar
5966,91-ARR,91-ARR_v2_62@4,91-ARR_v1_62@4,"Using the pre-trained transformer-based embedding greatly improves the performance of our proposed BATM-Base model compared to the GloVe embedding, although it adds to the difficulty of interpretation.","Using the pre-trained transformer-based embedding greatly improves the performance of our proposed BATM-Base model compared to the Glove embedding, although it adds to the difficulty of interpretation.","Modify,Grammar",Grammar
5967,91-ARR,91-ARR_v2_65@1,91-ARR_v1_65@1,"The average coherence scores of all topics of the BATM-Base-GloVe model are 0.58 and 0.56 on the MIND dataset and the news category datasets, respectively.","The average coherence scores of all topics of the BATM-Base-Glove model are 0.58 and 0.56 on the MIND dataset and the news category datasets, respectively.","Modify,Grammar",Grammar
5968,91-ARR,91-ARR_v2_65@4,91-ARR_v1_65@4,"However, some topics with a score in the range of 0.55 ∼ 0.8 are still tough to surmise the focus, as the unknown topic (labeled as ""Unknown"" with C v value is 0.61) suggest, where the correlation of topic descriptors is non-intuitive.","However, some topics with a score in the range of 0.55 ∼ 0.8 are still tough to surmise the focus, as the unknown topic (labeled as ""Unknown"" with C v value is 0.61) suggest, where the correlation of topic descriptors is against human intuition.","Modify,Clarity",Clarity
5969,91-ARR,91-ARR_v2_65@7,91-ARR_v1_66@2,"Therefore, with the auxiliary of topic coherence measurement and manual verification, we are firmly convinced that topic descriptors extracted by the BATM-Base-GloVe model indeed have specific meanings.","Therefore, with the auxiliary of topic coherence measurement and manual verification, we are firmly convinced that topic descriptors extracted by the BATM-Base-Glove model indeed have specific meanings.","Modify,Grammar",Grammar
5970,91-ARR,91-ARR_v2_67@0,91-ARR_v1_68@0,"In the previous sections, the proposed BATM-Base-GloVe model demonstrates its competitive classification performance and excellent explainability.","In the previous sections, the proposed BATM-Base-Glove model demonstrates its competitive classification performance and excellent explainability.","Modify,Grammar",Grammar
5971,91-ARR,91-ARR_v2_68@1,91-ARR_v1_69@1,"In the extended model, referred to as BATM-EC, λ determines the degree of constraint that is imposed, so the BATM-Base-GloVe model is a special case when λ is zero.","In the extended model, referred to as BATM-EC, λ determines the degree of constraint that is imposed, so the BATM-Base-Glove model is a special case when λ is zero.","Modify,Grammar",Grammar
5972,91-ARR,91-ARR_v2_68@4,91-ARR_v1_69@4,"Therefore, we observe the dynamic of two entropy metrics E doc and E token (see calculation in Eqn. 8 and Eqn. 9) by setting different values of λ.","Therefore, we observe the dynamic of two entropy metrics E doc and E token (see calculation in Eqn 8 and Eqn 9) by setting different values of λ.","Modify,Grammar",Grammar
5973,91-ARR,91-ARR_v2_68@6,91-ARR_v1_69@6,"When λ reaches le-4, both entropy indicators decrease significantly with an acceptable trade-off in classification performance.","When λ reaches le-4, both entropy indicators decrease significantly with an accepted trade-off of classification performances.","Modify,Grammar",Grammar
5974,91-ARR,91-ARR_v2_68@7,91-ARR_v1_69@7,"When continually increasing the impact of entropy constraints, both entropy indicators and classification performance decrease dramatically.","With continually increasing the impact of entropy constraints, both entropy indicators and classification performance decreased dramatically.","Modify,Clarity",Clarity
5975,91-ARR,91-ARR_v2_68@9,91-ARR_v1_69@9,"When attention focuses on a minimal number of topics, and the number of topics does not increase accordingly, information within article texts is likely to be lost, affecting the classification performance.","When attention focuses on a minimal topic, and the number of topics does not increase accordingly, much information in the article will be lost, affecting the classification performance.","Modify,Clarity",Clarity
5976,91-ARR,91-ARR_v2_70@0,91-ARR_v1_71@0,"While the variant of our proposed model, BATMbase-DB, which is initialized by the contextual embeddings, can outperform all alternatives, the meaning of its topics is much worse than BATM-Base-GloVe.","While the variant of our proposed model, BATMbase-DB, which is initialized by the contextual embeddings, can outperform all alternatives, the meaning of its topics is much worse than BATMbase-Glove.","Modify,Grammar",Grammar
5977,91-ARR,91-ARR_v2_71@3,91-ARR_v1_72@3,"We will consider increasing the number of heads and the extending entropy constraint further, to improve classification performance while maintaining strong explainability.",We will consider increasing the number of heads and the entropy constraint properly to make better classification performance with excellent explainability by considering these three factors.,"Modify,Fact/Evidence",Fact/Evidence
5978,91-ARR,91-ARR_v2_73@2,91-ARR_v1_74@2,"Compared with a number of state-of-the-art alternatives on a text classification task, our model can not only achieve a competitive performance, but also demonstrates a strong ability to capture intuitive meanings in the form of topical features, thus improving its explainability and transparency.","Compared with a number of state-of-the-art alternatives on a text classification task, our model can not only achieve a competitive performance, but demonstrate a strong ability to capture intuitive meanings in the form of topical features as well, thus improving its explainability and transparency.","Modify,Clarity",Clarity
5979,91-ARR,91-ARR_v2_73@3,91-ARR_v1_74@3,"In addition, by initializing it with contextual embeddings, our model outperforms all the baseline models.","In addition, by initializing it with contextual embeddings, our model outperforms all baseline models.","Modify,Grammar",Grammar
5980,91-ARR,91-ARR_v2_5@4,91-ARR_v1_5@4,"Some researchers have supported this viewpoint (Serrano and Smith, 2019), but treated with skepticism by others (Wiegreffe and Pinter, 2019).","This viewpoint has been supported by some researchers (Serrano and Smith, 2019), but treated with skepticism by others (Wiegreffe and Pinter, 2019).","Modify,Clarity",Clarity
5981,91-ARR,91-ARR_v2_6@1,91-ARR_v1_6@1,"Inspired by the idea of topic models (Blei et al., 2003), our proposed solution decouples the complexity of explanation and the decision-making process by adopting two attention layers to capture topicword distribution and document-topic distribution, respectively.","Inspired by the idea of topic models (Blei et al., 2003), our proposed solution decouples the complexity of explanation and the decision-making process by adopting two attention layers to capture topic-word distribution and document-topic distribution respectively.","Modify,Grammar",Grammar
5982,91-ARR,91-ARR_v2_6@2,91-ARR_v1_6@2,"Specifically, the first layer contains multiple attentions, and each attention is expected to focus on specific words from a topic.","Specifically, the first layer contains multiple attentions and each attention is expected to focus on specific words from a topic.","Modify,Grammar",Grammar
5983,91-ARR,91-ARR_v2_6@5,91-ARR_v1_6@5,"To prove the effectiveness of our proposed solution, we apply it in the context of a news article classification task and conduct experiments on two largescaled news article datasets.","To demonstrate the effectiveness of our proposed solution, we apply it in the context of a news article classification task and conduct experiments on two large-scaled news article datasets.","Modify,Clarity",Clarity
5984,91-ARR,91-ARR_v2_6@6,91-ARR_v1_6@6,"The results presented later in Section 4 show that our model can achieve competitive performance with many state-of-the-art transformer-based models and pre-trained language models, while also demonstrating its appropriateness from an explainability perspective.","The results show that our model is able to not only achieve competitive performance with many state-of-the-art transformer-based models and pre-trained language models, but demonstrate its appropriateness from an explainability perspective too.","Modify,Fact/Evidence",Fact/Evidence
5985,91-ARR,91-ARR_v2_2@2,91-ARR_v1_2@2,"To address this challenge, we propose a novel practical framework by utilizing a two-tier attention architecture to decouple the complexity of explanation and the decision-making process.","In this paper, to address this challenge, we proposed a novel practical framework by utilizing a two-tier attention architecture to decouple the complexity of explanation and the decision-making process.","Modify,Clarity",Clarity
5986,91-ARR,91-ARR_v2_10@3,91-ARR_v1_9@8,"The improvement of using the transformer-based language model for generating representations is significant compared with popular word embedding methods such as GloVe (Pennington et al., 2014).","The improvement of using the transformer-based language model for generating representations is significant compared with popular word embedding methods such as Glove (Pennington et al., 2014).","Modify,Grammar",Grammar
5987,91-ARR,91-ARR_v2_12@4,91-ARR_v1_11@4,"However, Wiegreffe and Pinter (2019) claimed that, despite the fact that explanations provided by attention mechanisms are not always faithful, in practice, this does not invalidate the plausibility of using attention as an explanation.","However, Wiegreffe and Pinter (2019) claimed that, despite the fact that explanations provided by attention mechanisms are not always faithful, in practice this does not invalidate the plausibility of using attention as an explanation.","Modify,Grammar",Grammar
5988,91-ARR,91-ARR_v2_14@0,91-ARR_v1_13@0,"Compared to simple additive attention, the Multi-Head Attention (MHA) mechanism, the core component of the big Transformer-based language model, is more complicated when attempting to interpret model behavior with complex weights distribution.","Compared to simple additive attention, Multi-Head Attention (MHA) mechanism, the core component of the big Transformer-based language model, are more complicated when attempting to interpret model behavior with complex weights distribution.","Modify,Grammar",Grammar
5989,91-ARR,91-ARR_v2_15@3,91-ARR_v1_14@3,"However, unlike the topic attention model (TAN), which uses a bag-of-words (BOW) model based on variational inference to align the topic space and word space with extracting meaningful topics (Panwar et al., 2021), we assume that these multiple attention heads represent multiple topics in terms of their semantics.","However, unlike the topic attention model (TAN), which uses a bagof-words (BOW) model based on variational inference to align the topic space and word space with extracting meaningful topics (Panwar et al., 2021), we assume that these multiple attention heads represent multiple topics in terms of their semantic meaning.","Modify,Clarity",Clarity
5990,91-ARR,91-ARR_v2_17@0,91-ARR_v1_16@0,This section describes our proposed architecture Bi-level Attention-based Topical Model (BATM) as illustrated in Figure 1.,This section describes our proposed architecture which uses two attention layers to uncover a latent representation of the data and then makes use of attention weights as a form of topic distribution.,"Split+Modify,Fact/Evidence",Fact/Evidence
5991,91-ARR,91-ARR_v2_17@1,91-ARR_v1_16@0,It uses two attention layers to uncover a latent representation of the data and then makes use of attention weights as a form of topic distribution.,This section describes our proposed architecture which uses two attention layers to uncover a latent representation of the data and then makes use of attention weights as a form of topic distribution.,"Split+Modify,Clarity",Clarity
5992,91-ARR,91-ARR_v2_17@3,91-ARR_v1_16@2,"Our architecture consists of three components: an embedding layer, two attention layers, and a classification layer.","Our architecture consists of three components: an embedding layer, two attention layers, and a classifier layer.","Modify,Clarity",Clarity
5993,1-12,1-12_v2_16@3,,"Since the N-terminal hydrophobic domain of plasmepsin V is not cleaved <REF-12> , it is likely a transmembrane signal anchor.",,"Add,Claim",Claim
5994,1-12,1-12_v2_16@4,,Both TMHMM and TopPred predict it to insert into the ER membrane with the N-terminus in the lumen such that the subsequent soluble region containing the active site would be in the cytoplasm.,,"Add,Fact/Evidence",Fact/Evidence
5995,1-12,1-12_v2_28@3,1-12_v1_28@3,Membrane proteins would be transported by vesicular transport from the PVM to Maurer's clefts where their release from the PI3P patches could be triggered by a PI3P-phosphatase.,Membrane proteins would be transported by vesicular transport from the PVM to Maurer’s clefts where their release from the PI3P patches could be triggered by a PI3P-phosphatase.,"Modify,Grammar",Grammar
5996,1-12,1-12_v2_32@6,1-12_v1_32@6,"The authors' interpretation of the data was that proteins must be unfolded in order to be transported across the PVM into the erythrocyte, that the PVM therefore contained a protein-conducting channel with similar requirements for transport as the Sec61 channel in the ER membrane, and that the time window after synthesis during which proteins were transport-competent was limited.","The authors’ interpretation of the data was that proteins must be unfolded in order to be transported across the PVM into the erythrocyte, that the PVM therefore contained a protein-conducting channel with similar requirements for transport as the Sec61 channel in the ER membrane, and that the time window after synthesis during which proteins were transport-competent was limited.","Modify,Grammar",Grammar
5997,1-12,1-12_v2_10@4,1-12_v1_10@4,- The uncleaved targeting signal binds PI3P at the ER membrane with the same specificity required for protease cleavage and host cell targeting; the cleaved signal no longer binds PI3P <REF-13> .,- The uncleaved targeting signal binds phosphoinositol-3-phosphate (PI3P) at the ER membrane with the same specificity required for protease cleavage and host cell targeting; the cleaved signal no longer binds PI3P <REF-13> .,"Modify,Clarity",Clarity
5998,1-12,1-12_v2_10@5,1-12_v1_10@5,"- A putative 'translocator' complex resides in the PV membrane (PVM); it consists of 5 proteins that coprecipitate some of the proteins bearing a host cell targeting signal, but a function of the complex has not been demonstrated in any way, nor has it been investigated whether the association of the complex and the PEXEL proteins is mediated by the PEXEL signal <REF-14> , <REF-15> .","- A putative ‘translocator’ complex resides in the PV membrane (PVM); it consists of 5 proteins that coprecipitate some of the proteins bearing a host cell targeting signal, but a function of the complex has not been demonstrated in any way, nor has it been investigated whether the association of the complex and the PEXEL proteins is mediated by the PEXEL signal <REF-14> , <REF-15> .","Modify,Grammar",Grammar
5999,1-12,1-12_v2_12@1,1-12_v1_12@1,"This cannot be right: N-acetylation is a cytosolic modification, based on the biochemical and sequence data characterizing the protease plasmepsin V, its active site is almost certainly on the cytoplasmic face of the membrane, and the only possible location for PI3P at the ER membrane is in the cytosolic leaflet.","This cannot be right: N-acetylation is a cytosolic modification, the active site of plasmepsin V is almost certainly on the cytoplasmic face of the ER membrane (based on the biochemical & sequence data characterizing the protease), and the only possible location for PI3P at the ER membrane is in the cytosolic leaflet and the only possible location for PI3P at the ER membrane is in the cytosolic leaflet.","Modify,Clarity",Clarity
6000,1-12,1-12_v2_16@2,1-12_v1_16@2,"Russo and colleagues showed later (2010) <REF-10> that fusion of this region of plasmepsin V to a fluorescent reporter protein resulted in ring-shaped staining around the parasite cytoplasm indicative of location in the PV or at the parasite plasma membrane, and suggesting entry of the protein into the ER and transport to the cell surface.","Russo and colleagues (2010) <REF-10> showed later that this region of plasmepsin V was not able to target the protein to the ER, which demonstrates that it is not a signal sequence.","Modify,Fact/Evidence",Fact/Evidence
6001,1-12,1-12_v2_16@5,1-12_v1_16@3,In the same paper Russo and colleagues demonstrated that the C-terminal hydrophobic region of plasmepsin V was required for ER retention of the protein <REF-10> .,In the same paper Russo and colleagues demonstrated that the C-terminal hydrophobic region of plasmepsin V was required to anchor the protein to the ER membrane.,"Modify,Fact/Evidence",Fact/Evidence
6002,1-12,1-12_v2_16@6,1-12_v1_16@4,"Both Russo and colleagues and Klemba and Goldberg describe this region as a transmembrane domain, but Klemba and Goldberg show that 50% of plasmepsin V can be extracted from the membrane by carbonate, pH 11.0 <REF-12> .","Both Russo and colleagues and Klemba and Goldberg describe this region as a transmembrane domain, but Klemba & Goldberg show that 50% of plasmepsin V can be extracted from the membrane by carbonate, pH 11.0 <REF-12> .","Modify,Grammar",Grammar
6003,1-12,1-12_v2_16@8,1-12_v1_16@6,"Altogether these data suggest that plasmepsin V is tethered to the ER membrane by hydrophobic regions at both termini, and that its active site is in the cytoplasm.",Altogether these data suggest that plasmepsin V is a carboxy-terminally membrane-anchored or membrane-associated protein with its entire N-terminal domain including the active site in the cytoplasm.,"Modify,Claim",Claim
6004,1-21,1-21_v2_13@3,,"Namely, whereas the bacterial populations differed with regards the side scatter parameter, forward scatter showed no change in its distribution.",,"Add,Fact/Evidence",Fact/Evidence
6005,1-21,1-21_v2_18@3,,An alternative explanation is that phage binding decreases resource uptake by bacterial cells.,,"Add,Claim",Claim
6006,1-21,1-21_v2_18@4,,"However, this seems unlikely in our experiment.",,"Add,Claim",Claim
6007,1-21,1-21_v2_18@5,,"Because bacteria were exposed to inactivated phages only, the total number of viral particles is predicted to stay constant (or possibly degrade) throughout the experiment.",,"Add,Claim",Claim
6008,1-21,1-21_v2_18@6,,"When bacteria divide, the number of phages bound to a daughter cell should be roughly half the number on the mother cell; thus, the number of bound phages per cell will decrease exponentially with cell divisions.",,"Add,Claim",Claim
6009,1-21,1-21_v2_18@7,,"Using the density of phages and bacteria employed in our experiment, we predict that there will be, on average, less than one phage individual per bacterial cell after 9 to 10 cell divisions, which based on the mean doubling time presented in Figure 1 , is reached in the first 48 hours of the experiment.",,"Add,Claim",Claim
6010,1-21,1-21_v2_18@8,,Our results can explain previous observations on phage-associated increases in population size in P. fluorescens <REF-32> .,,"Add,Fact/Evidence",Fact/Evidence
6011,1-21,1-21_v2_18@9,,"Specifically, we predict that a significant number of phage in the experiments of Gomez and Buckling <REF-32> did not kill their bacterial hosts before some of the latter were able to accelerate their cell cycle and produce daughter cells.",,"Add,Claim",Claim
6012,1-21,1-21_v2_18@14,,"This response is expected to result in smaller individual size, because energy allocated to growth is directed to reproduction when the stressor is present.",,"Add,Claim",Claim
6013,1-21,1-21_v2_28@9,,Observations of c. 50 cells using TEM (Zeis EM10) showed no bound phages after the centrifugation treatment.,,"Add,Fact/Evidence",Fact/Evidence
6014,1-21,1-21_v2_30@3,,"KB medium containing UV-inactivated phages was obtained through centrifugation of inactivated phage, which were further added into pure KB, so that the medium used in the treatments only differs from the control by the presence of phages.",,"Add,Fact/Evidence",Fact/Evidence
6015,1-21,1-21_v2_36@0,,Measures of OD will be affected by changes in particle size.,,"Add,Claim",Claim
6016,1-21,1-21_v2_36@1,,"At equal bacterial density, a population of smaller cells will yield a lower OD value, because fewer particles will block less of the incoming light.",,"Add,Claim",Claim
6017,1-21,1-21_v2_36@2,,"The practical conclusion is that whenever bacteria get smaller, we understimate their count, and thus their growth rate.",,"Add,Claim",Claim
6018,1-21,1-21_v2_36@3,,"Because this means that we are more conservative about the impact of phage exposure on growth rate (i.e., if there were any bias in our results, it would be an underestimation of the increase in growth rate), we did not correct for this effect.",,"Add,Claim",Claim
6019,1-21,1-21_v2_16@0,1-21_v1_16@0,"We did not observe any difference in the impact of live phage on bacterial populations exposed to the different treatments (KW, df = 2, P = 0.153), suggesting that the inducible response does not alter bacteria resistance to phage predation.","We did not observe any difference in the impact of live phage on bacterial populations exposed to the different treatments (KW, df=2, P = 0.153), suggesting that the inducible response does not alter bacteria resistance to phage predation.","Modify,Grammar",Grammar
6020,1-21,1-21_v2_18@1,1-21_v1_18@1,We hypothesize that this response increases the survival chances of bacterial progeny under natural conditions and demonstrate that this behaviour comes at a fitness cost of reduced size of daughter cells.,We hypothesize that this response increases the survival chances of progeny under natural conditions and demonstrate that this behaviour comes at a fitness cost of reduced size of daughter cells.,"Modify,Claim",Claim
6021,1-21,1-21_v2_18@10,1-21_v1_19@0,"Furthermore, our results support and extend both theoretical <REF-33> and empirical <REF-34> , <REF-35> predictions that victims may lessen the fitness impact of their natural enemies through early reproduction, to cases where phenotypic responses are plastic and temporary.","These results support and extend both theoretical <REF-32> and empirical <REF-33> , <REF-34> predictions that victims may lessen the fitness impact of their natural enemies through early reproduction, to cases where phenotypic responses are plastic and temporary.","Modify,Clarity",Clarity
6022,1-21,1-21_v2_18@11,1-21_v1_19@1,Increased allocation to reproduction in stressful environments–termed “fecundity compensation” or “terminal investment” <REF-31> –although never studied in bacteria-phage associations to our knowledge–has been extensively studied for other host-parasite (or organism-stressor) interactions.,Increased allocation to reproduction in stressful environments–termed “fecundity compensation” or “terminal investment” <REF-31> – although never studied in bacteria-phage associations to our knowledge – has been extensively studied for other host-parasite (or organism - stressor) interactions.,"Modify,Grammar",Grammar
6023,1-21,1-21_v2_21@3,1-21_v1_22@3,"Assuming that the physiological mechanisms involved in fission rate increases are the same in the two experiments, this suggests that rapid multiplication is not adaptive for the bacterium, and indeed we report no advantage of being exposed to inactived phage in terms of a lessened population impact during live phage exposure.","Assuming that the physiological mechanisms involved in fission rate increases are the same in the two experiments, this suggests that rapid multiplication is not adaptive for the bacterium.","Modify,Fact/Evidence",Fact/Evidence
6024,1-21,1-21_v2_21@7,1-21_v1_22@7,"Future studies should therefore focus on the possible adaptive nature of this response for both bacterium and phage, by investigating in greater depth how it affects the mechanisms of infection, recovery, and resistance.",Future studies should therefore focus on the possible adaptive nature of this response for both bacterium and phage.,"Modify,Claim",Claim
6025,1-21,1-21_v2_28@4,1-21_v1_29@4,Inactivated phage were allowed 4 h to attach to the bacterial outer membrane.,Inactivated phage were allowed 4h to attach to the bacterial outer membrane.,"Modify,Grammar",Grammar
6026,1-21,1-21_v2_28@7,1-21_v1_29@7,"PCR was done using TPV1f (GATGTGAGAAAGCGATACACGG) and TPV1r (GAGAGAAGCGGGAGAGTGAA) sequences developed for this study, which selectively amplify a 550 bp fragment of the phage DNA and a 1200 bp fragment of the bacterial DNA (see Supplementary Figure 1 for detailed protocols).","PCR was done using TPV1f (GATGTGAGAAAGCGATACACGG) and TPV1r (GAGAGAAGCGGGAGAGTGAA) sequences developed for this study, which selectively amplify a 550 bp fragment of the phage DNA and a 1200 bp fragment of the bacterial DNA (see Supplement Figure 1 for detailed protocols).","Modify,Grammar",Grammar
6027,1-21,1-21_v2_28@8,1-21_v1_29@8,"We did not find any evidence that UV-inactivated phage was present in samples putatively containing bacteria only, thus confirming that (i) the DNA of inactivated phage was not incorporated in the bacterial cell and (ii) our centrifugation method removed both bound and unbound phage.","We did not find any evidence that UV-inactivated phage was present in samples putatively containing bacteria only, thus confirming that the DNA of inactivated phage was not incorporated in the bacterial cell.","Modify,Claim",Claim
6028,1-21,1-21_v2_30@1,1-21_v1_31@1,Fixed SBW25 bacteria of the smooth morphotype were first cultivated in 6 ml KB in 30 mL universal glass vials.,Fixed smooth SBW25 bacteria were first cultivated in 6 ml KB in 30 mL universal glass vials.,"Modify,Clarity",Clarity
6029,1-21,1-21_v2_34@1,1-21_v1_35@1,"Exponential phase was determined by conducting a series of windowed linear regressions over the full growth curve, and retaining the part of the curve with the largest slope (computer code given in Supplementary materials part 3 ).","Exponential phase was determined by conducting a series of windowed linear regressions over the full growth curve, and retaining the part of the curve with the largest slope (computer code given in suppl. materials part 3).","Modify,Clarity",Clarity
6030,1-21,1-21_v2_8@8,1-21_v1_8@7,"Terminal investment is well characterised for other host-parasite associations <REF-31> , but to our knowledge has not previously been observed in bacteria subject to phage infection.","Terminal investment is well characterised for other host-parasite associations <REF-31> , but to our knowledge has not previously been observed in bacteria and phage.","Modify,Claim",Claim
6031,1-21,1-21_v2_10@0,1-21_v1_10@0,"Bacteria exposed to UV-inactivated phage display a statistically significant higher growth rate over the first 24 hours post-exposure than non-phage controls (Kruskal-Wallis, df = 3, P = 0.006; Figure 1 ).","Bacteria exposed to UV-inactivated phage display a statistically significant higher growth rate over the first 24 hours post-exposure than non-phage controls (Kruskal-Wallis, df=3, P = 0.006; Figure 1 ).","Modify,Grammar",Grammar
6032,1-21,1-21_v2_10@3,1-21_v1_10@3,"During the fourth day post-exposure, control and treatment bacteria showed no significant differences in doubling time (KW, df = 3, P > 0.05).","During the fourth day post-exposure, control and treatment bacteria showed no significant differences in doubling time (KW, df=3, P > 0.05).","Modify,Grammar",Grammar
6033,1-21,1-21_v2_10@5,1-21_v1_10@5,"There was a marginally significant effect on population growth for bacteria exposed to different phage concentrations (KW, df = 2, P < 0.02), suggesting that the encounter rate between bacteria and phage is important in determining the population-level strength of the fission response.","There was a marginally significant effect on population growth for bacteria exposed to different phage concentrations (KW, df=2, P < 0.02), suggesting that the encounter rate between bacteria and phage is important in determining the population-level strength of the fission response.","Modify,Grammar",Grammar
6034,1-21,1-21_v2_13@0,1-21_v1_13@0,"We hypothesized that faster doubling times would come at a cost to cell size, since cells would have less time to metabolize and convert absorbed nutrients into cell structure twenty-four hours post-exposure, we found that phage-treated bacteria were two to three times smaller (as measured by mean cellular width) than the control (KW, df = 3, P < 0.0001; Figure 2 ).","We hypothesized that faster doubling times would come at a cost to cell size, since cells would have less time to metabolize and convert absorbed nutrients into cell structure Twenty-four hours post-exposure, we found that phage-treated bacteria were two to three times smaller (as measured by mean cellular width) than the control (KW, df=3, P < 0.0001; Figure 2 ).","Modify,Grammar",Grammar
6035,1-21,1-21_v2_13@2,1-21_v1_13@2,Analyses of the distribution of several flow cytometry profiles showed that a difference in cell shape is unlikely to explain this result (see Data File below).,Analyses of the distribution of several flow cytometry profiles showed that a difference in cell shape is unlikely to explain this result (see data associated to this article).,"Modify,Clarity",Clarity
6036,1-21,1-21_v2_13@4,1-21_v1_13@3,"This implies that bacterial shape remained unchanged throughout the experiment, and indeed, additional observations using a transmission electron microscope showed that the cells remained rod-shaped for all treatments.","Finally, observations using a transmission electron microscope showed that the cells remained rod-shaped for all treatments.","Modify,Claim",Claim
6037,1-23,,1-23_v1_19@10,,Data about health hazards linked to FGC were not derived from any of these studies.,"Delete,Fact/Evidence",Fact/Evidence
6038,1-23,,1-23_v1_19@12,,"If a new test or a drug is to be prescribed for a patient, it should pass through a complicated series of tests and randomized comparisons before getting approved.","Delete,Claim",Claim
6039,1-23,,1-23_v1_19@13,,The same occurs with any surgical procedure.,"Delete,Claim",Claim
6040,1-23,,1-23_v1_19@14,,No procedure can be considered superior to another or blamed for complications except after randomized controlled trials comparing the new to standard surgery.,"Delete,Claim",Claim
6041,1-23,,1-23_v1_19@15,,It therefore seems unrealistic to consider data about FGC not derived from randomized or cohort studies are true and conclusive.,"Delete,Claim",Claim
6042,1-23,,1-23_v1_22@0,,"The ban against FGC seems to be gender based, especially because no similar act was taken against male circumcision.","Delete,Claim",Claim
6043,1-23,,1-23_v1_22@1,,"If male circumcision is considered safe by anti FGC groups, they should advise how to render FGC as safe as male circumcision instead of enforcing the ban against it.","Delete,Claim",Claim
6044,1-23,1-23_v2_19@5,,"In the era of evidence based medicine, level I evidence, derived from either systematic reviews or randomized controlled trials (RCTs), to support the ban against FGC is not available.",,"Add,Claim",Claim
6045,1-23,1-23_v2_19@7,,"In fact, the design and implementation of a RCT to address the effects of FGC cannot be justified and seems to be unethical.",,"Add,Claim",Claim
6046,1-23,,1-23_v1_19@8,,Research including reported data about past experiences will always be threatened by the individual’s memory and the influence of exposure status on the recalling process <REF-21> .,"Delete,Fact/Evidence",Fact/Evidence
6047,1-23,,1-23_v1_19@9,,The strongest evidence comes from randomized controlled trials followed by cohort studies.,"Delete,Claim",Claim
6048,1-23,1-23_v2_23@0,1-23_v1_24@0,Conclusions,Final remarks,"Modify,Other",Other
6049,1-23,1-23_v2_17@8,1-23_v1_17@8,Claims for increased Cesarean deliveries in cut women were attributed to obstructed labor most likely due to excessive scarring at the pelvic outlet probably resulting from the imperfect healing of the genital cutting and possible associated infection.,Claims for increased Cesarean deliveries in cut women were attributed to obstructed labor most likely due to excessive scarring at the pelvic outlet.,"Modify,Claim",Claim
6050,1-23,1-23_v2_17@9,1-23_v1_17@9,"However, the high Cesarean rate in this population cannot be attributed solely to obstruction due to excessive outlet scarring; obstructed labor may occur due to a variety of reasons.",The high Cesarean rate in this population cannot be attributed solely to obstruction due to excessive outlet scarring; obstructed labor may occur due to a variety of reasons.,"Modify,Clarity",Clarity
6051,1-23,1-23_v2_19@8,1-23_v1_19@5,"In light of this fact and in the absence of any scientific evidence to support the practice of female circumcision, the available level III evidence, derived from retrospective studies and studies depended on self-reported FGC and its health consequences, should be taken into consideration in spite of their imprecision and low reliability <REF-19> , <REF-20> .",It is the author’s view that none of these studies hold solid evidence to rely upon.,"Merge+Modify,Claim",Claim
6052,1-23,1-23_v2_19@8,1-23_v1_19@6,"In light of this fact and in the absence of any scientific evidence to support the practice of female circumcision, the available level III evidence, derived from retrospective studies and studies depended on self-reported FGC and its health consequences, should be taken into consideration in spite of their imprecision and low reliability <REF-19> , <REF-20> .",These studies were either of retrospective design or studies depended on self-reported FGC and its health consequences.,"Merge+Modify,Clarity",Clarity
6053,1-23,1-23_v2_19@8,1-23_v1_19@7,"In light of this fact and in the absence of any scientific evidence to support the practice of female circumcision, the available level III evidence, derived from retrospective studies and studies depended on self-reported FGC and its health consequences, should be taken into consideration in spite of their imprecision and low reliability <REF-19> , <REF-20> .","Such studies are imprecise and have low reliability <REF-19> , <REF-20> .","Merge+Modify,Clarity",Clarity
6054,1-62,,1-62_v1_16@0,,The 16S rRNA PCR product sequencing was carried out by modified Sanger’s dideoxy chain termination cycle sequencing method <REF-21> .,"Delete,Fact/Evidence",Fact/Evidence
6055,1-62,,1-62_v1_16@1,,"Electropherogram was read by an automated DNA sequencer ( Applied Biosystems ABI3500 XL Genetic Analyzer, Big Dye Terminator version 3.1 Cycle sequencing kit ) for 1.5 kb amplicon of the isolate.","Delete,Fact/Evidence",Fact/Evidence
6056,1-62,,1-62_v1_16@2,,The resulting final DNA sequence of isolate was subjected to BLAST analysis on the NCBI web server.,"Delete,Fact/Evidence",Fact/Evidence
6057,1-62,,1-62_v1_16@3,,The phylogenetic tree of 16S rRNA of the isolate was constructed by using a neighbor-joining (NJ) method with 1000 replicates of bootstrap in MEGA4.1 software <REF-22> .,"Delete,Fact/Evidence",Fact/Evidence
6058,1-62,,1-62_v1_16@4,,The bootstrap consensus tree inferred from 1000 replicates was selected to represent the evolutionary history of the taxa for 16S rRNA sequence analysis.,"Delete,Fact/Evidence",Fact/Evidence
6059,1-62,,1-62_v1_17@1,,The NCBI Blast server was used for the identification of the ATP synthase a -subunit and the phylogenetic analysis of the a -subunit was carried out with the help of MEGA4.1.,"Delete,Fact/Evidence",Fact/Evidence
6060,1-62,,1-62_v1_17@2,,The blastx was used to get the amino acid sequence of the a -subunit.,"Delete,Fact/Evidence",Fact/Evidence
6061,1-62,,1-62_v1_17@3,,"The a -subunit of isolate was compared with that of established alkaliphiles, acidophiles and neutrophiles with the help of ClustalW.","Delete,Fact/Evidence",Fact/Evidence
6062,1-62,,1-62_v1_20@1,,"Out of these, some bacterial colonies were found with pink and orange pigmentation along with no pigmentation i.e. white colonies.","Delete,Fact/Evidence",Fact/Evidence
6063,1-62,,1-62_v1_20@4,,"However, the pH range of growth was pH 7.0 to 12.0 (Supplementary figure 1) .","Delete,Fact/Evidence",Fact/Evidence
6064,1-62,,1-62_v1_33@0,,"Comparison of a -subunit of Stenotrophomonas species DL18 with acidophiles, alkaliphiles and neutrophiles","Delete,Other",Other
6065,1-62,,1-62_v1_37@0,,"However, Ala 198 from the Stenotrophomonas species DL 18 and Ala 196 from T. cyclicum were found to correspond with Gly 208 in E. coli and Gly 170 in Bacillus pseudofirmus OF4 in alignment of the a -subunit as shown in Figure 2 .","Delete,Fact/Evidence",Fact/Evidence
6066,1-62,,1-62_v1_37@1,,"In a similar way, Gly 207 was observed in Stenotrophomonas species DL 18, while in this respective position alanine was found in alkaliphiles and neutrophiles.","Delete,Fact/Evidence",Fact/Evidence
6067,1-62,,1-62_v1_37@2,,But both amino acids correspond from the same amino acid family.,"Delete,Fact/Evidence",Fact/Evidence
6068,1-62,,1-62_v1_38@4,,"However, exchange mutations at Gly 120 and Lys 180 to Lys 120 and Gly 180 showed ATP synthase activity in Bacillus pseudofirmus OF4.","Delete,Fact/Evidence",Fact/Evidence
6069,1-62,,1-62_v1_39@0,,"After comparison with acidophiles, neutrophiles and alkaliphiles, Leu 197 of the Stenotrophomonas species DL 18 was found to be conserved in TMH-4 (Figure 3) .","Delete,Fact/Evidence",Fact/Evidence
6070,1-62,1-62_v2_2@2,,Various studies have reported alkaliphiles from different alkaline habitats other than Lonar Lake with alkaliphile specific amino acid residues in the F 1 F o ATP synthase a-subunit.,,"Add,Fact/Evidence",Fact/Evidence
6071,1-62,1-62_v2_4@14,,"Hence, the cytoplasmic pH needs to be maintained 1.5 to 2.3 pH units below the external environment, which generates an optimal condition for ATP synthesis.",,"Add,Claim",Claim
6072,1-62,1-62_v2_9@0,,Further polymerase chain reaction (PCR) and sequencing of 16S rRNA was carried out for identification of bacterium <REF-11> .,,"Add,Fact/Evidence",Fact/Evidence
6073,1-62,1-62_v2_11@4,,"The amplified PCR product of 1.7 kbp was visualized on 1% agarose gel and the results were documented by Bio-Rad gel documentation system with Quantity One software (Bio-Rad, USA).",,"Add,Fact/Evidence",Fact/Evidence
6074,1-62,1-62_v2_11@6,,"An ATP synthase comparative study was performed by multiple sequence alignment with other strains from different categories i.e. acidophiles, neutrophiles and alkaliphiles, as shown in Figure 1 .",,"Add,Fact/Evidence",Fact/Evidence
6075,1-62,1-62_v2_19@0,,Table 1 lists the bacterial species used in the comparative studies.,,"Add,Fact/Evidence",Fact/Evidence
6076,1-62,,1-62_v1_6@1,,"The c 11 ring from Ilyobacter tartaricus has Na + ion binding specificity, while the c 13 ring from Bacillus pseudofirmus OF4 and the c 15 ring from Spirulina platensis has H + ion binding specificity <REF-6> .","Delete,Fact/Evidence",Fact/Evidence
6077,1-62,,1-62_v1_6@2,,Ion coordination geometry and distances determine the ion specificity.,"Delete,Claim",Claim
6078,1-62,,1-62_v1_6@3,,"Translocated ions bind to conserved carboxylate of aspartate or glutamate (D/E) in the outer α-helices of c-rings <REF-5> , <REF-6> .","Delete,Fact/Evidence",Fact/Evidence
6079,1-62,,1-62_v1_6@4,,"However, ions are further coordinated by a network of residues.","Delete,Claim",Claim
6080,1-62,,1-62_v1_6@5,,The inner and outer α-helices are in a staggered position.,"Delete,Claim",Claim
6081,1-62,1-62_v2_26@1,,"In addition, exchange mutations at a E219-H and a H245-E showed similar ATP synthase activity in E. coli .",,"Add,Fact/Evidence",Fact/Evidence
6082,1-62,1-62_v2_26@2,,"Moreover, the aG218-K substitution effect was suppressed by a H245-G mutation in E. coli.",,"Add,Fact/Evidence",Fact/Evidence
6083,1-62,1-62_v2_26@4,,"In addition, equivalent amino acid residue studies were also reported from the facultative alkaliphile B. pseudofirmus OF4 a -subunit <REF-7> – <REF-9> .",,"Add,Fact/Evidence",Fact/Evidence
6084,1-62,,1-62_v1_6@6,,"Out of these, the inner helices are hydrophobic in nature and in contact with the phospholipids, while outer helices are hydrophilic with a -subunit interaction for ion translocation <REF-2> , <REF-6> .","Delete,Fact/Evidence",Fact/Evidence
6085,1-62,,1-62_v1_6@7,,"The transmembrane electric potential controls the kinetics of rotary motion, which seems to be independent of the ionic gradient <REF-5> .","Delete,Fact/Evidence",Fact/Evidence
6086,1-62,,1-62_v1_6@9,,"For this, there are some crucial amino acid residue adaptations in the a - and c -subunit solving the problem of proton capture from an alkaline environment and subsequent translocation to the binding sites on the c-ring <REF-6> .","Delete,Fact/Evidence",Fact/Evidence
6087,1-62,,1-62_v1_7@0,,"Various studies based on the mechanism of proton binding <REF-7> , <REF-8> , through hydronium ion proton retention and transportation for ATP synthesis in the bacterial system including alkaliphiles <REF-9> , <REF-10> suggest the presence of alkaliphile specific conserved amino acid motifs in transmembrane helix-4 (TMH-4) and TMH-5 of the a -subunit and the inner and the outer helix of the c -subunit <REF-3> , <REF-11> – <REF-14> of the ATP synthase F o subunit as well as Na + /H + antiporter <REF-15> and other cation binding proton transporters including multiple drug transporters <REF-6> , <REF-16> .","Delete,Fact/Evidence",Fact/Evidence
6088,1-62,,1-62_v1_7@1,,The presence of the above mentioned alkaliphile specific sequences of ATP synthase F o subunit along with Na + /H + antiporters and other multiple drug transporters are the major strategies for pH homeostasis of extremely alkaliphilic species.,"Delete,Claim",Claim
6089,1-62,,1-62_v1_8@1,,"The arginine residue of the a -subunit, which transfers protons to the c -subunit, is conserved in almost all bacterial species <REF-3> .","Delete,Fact/Evidence",Fact/Evidence
6090,1-62,,1-62_v1_8@2,,"Recent developments in molecular studies of facultative alkaliphiles suggests the presence of a highly conserved A X A X A X A motif in the amino terminal helix and a P XX E XX P motif in the carboxy terminal helix of the ATP synthase c -subunit in Bacillus pseudofirmus OF4, an established facultative alkaliphile <REF-6> , <REF-17> , <REF-18> .","Delete,Fact/Evidence",Fact/Evidence
6091,1-62,,1-62_v1_2@3,,"Attempts were made to isolate and identify alkaliphiles from their naturally occurring original habitat, i.e. Lonar Lake, India with high alkaline conditions of pH 10.5.","Delete,Claim",Claim
6092,1-62,,1-62_v1_8@5,,"The present study deals with the isolation, identification and analysis of alkaliphile specific amino acid motifs in the a -subunit of ATP synthase.","Delete,Fact/Evidence",Fact/Evidence
6093,1-62,,1-62_v1_11@2,,"After mix culture was obtained by the spread plate method, pure culture of each type of colony was maintained for further studies.","Delete,Fact/Evidence",Fact/Evidence
6094,1-62,,1-62_v1_12@0,,DNA extraction and Polymerase Chain Reaction (PCR),"Delete,Other",Other
6095,1-62,,1-62_v1_13@1,,DNA quantization and quality control for protein contamination was carried out by spectrophotometric absorbance at A 260 and A 280 .,"Delete,Fact/Evidence",Fact/Evidence
6096,1-62,,1-62_v1_13@2,,The small subunit ribosomal RNA (16S rRNA) PCR for identification of bacterium was performed with forward primer (16S20F: 5’ATGTTGATCATGGCTCA3’) and reverse primer (16S1540R: 5’AAGGAGGTGATCCAACCGCA 3’) <REF-20> .,"Delete,Fact/Evidence",Fact/Evidence
6097,1-62,,1-62_v1_13@3,,"Briefly, master mix was prepared for 16S rRNA PCR: 10x PCR Rxn Buffer without MgCl 2 (Invitrogen, P/N Y02028B Lot no. WK1B1b, USA), 1mM MgCl 2 (Invitrogen, P/N Y02016B Lot no. WK2B1a, USA), 200 µM dNTP mix (Merck, India), 100 picomoles of each reverse and forward primers (Integrated DNA technologies, USA), 2.5U of Taq Polymerase enzyme (Invitrogen, USA, 11615-010 Lot No. VKRB1E) and nuclease free water (Merck, India) was added to make up a final volume of 100 µl.","Delete,Fact/Evidence",Fact/Evidence
6098,1-62,,1-62_v1_13@4,,"Following thermal cycling conditions were used for PCR: Initial denaturation at 94°C for 5 min, followed by 30 cycles of denaturation at 94°C for 1 min, primer annealing at 55°C for 1 min and primer extension at 72°C for 2 min.","Delete,Fact/Evidence",Fact/Evidence
6099,1-62,,1-62_v1_13@5,,Thirty cycles of PCR were followed by final extension at 72°C for 5 min followed by cooling at 4°C.,"Delete,Fact/Evidence",Fact/Evidence
6100,1-62,,1-62_v1_14@0,,ATP synthase F o amplification primers were designed based on S. maltophilia K279a as follows: forward primer Steno atp1F: 5’CCTGGCGGATCCTTAGATCTCCG 3’ and reverse primer Steno atp1R: 5’CAGTGAGGATCCTTAGATCTCCGAGGCCAGCT 3’.,"Delete,Fact/Evidence",Fact/Evidence
6101,1-62,,1-62_v1_14@4,,"Results of 16S rRNA and ATP synthase F o amplicons were visualized on 1% agarose gel with 200 ng/ml ethidium bromide (sd fine, India) and results were observed and analyzed with the help of Bio-Rad gel documentation system XR with Bio-Rad Quantity-One 4.6.5 software.","Delete,Fact/Evidence",Fact/Evidence
6102,1-62,,1-62_v1_2@5,,"Although the a-subunit of Stenotrophomonas DL18 showed significant similarity with neutrophiles, the isolated bacterium is an alkaliphile and optimally grows at pH 10.5.","Delete,Fact/Evidence",Fact/Evidence
6103,1-62,1-62_v2_11@5,1-62_v1_17@0,"Further, the DNA sequencing of the ATP F o subunit of the selected isolate was performed via primer walking.","Further, the DNA sequencing of the ATP F o subunit of selected isolates was performed by primer walking method.","Modify,Clarity",Clarity
6104,1-62,1-62_v2_15@0,1-62_v1_19@0,Bacterial identification and ATP synthase F o subunit amplification,Bacterial identification,"Modify,Other",Other
6105,1-62,1-62_v2_8@3,1-62_v1_20@0,"Across the pH gradient, morphologically different pink, orange and white bacterial colonies were observed.","Across the pH gradient, growth of morphologically different bacterial colonies was observed.","Modify,Fact/Evidence",Fact/Evidence
6106,1-62,1-62_v2_16@0,1-62_v1_20@2,The orange pigmented bacterium was identified as Stenotrophomonas sp. based on a NCBI BLAST analysis of the 16S rRNA gene sequence and titled Stenotrophomonas sp. DL18 (GenBank Accession number: JN995612 ).,The orange pigmented bacterium was identified as Stenotrophomonas species based on BLAST analysis of 16S rRNA gene sequence and titled as Stenotrophomonas species DL18 (GenBank Accession number: JN995612 ).,"Modify,Fact/Evidence",Fact/Evidence
6107,1-62,1-62_v2_16@1,1-62_v1_20@3,"Microbiological studies we performed showed that Stenotrophomonas sp. DL18, which optimally grows at pH 9.5, is an aerobic, facultative alkaliphilic with curved rod morphology.",Stenotrophomonas species DL18 optimally grow at the pH 9.0 to 10.0.,"Merge+Modify,Clarity",Clarity
6108,1-62,1-62_v2_16@1,1-62_v1_20@5,"Microbiological studies we performed showed that Stenotrophomonas sp. DL18, which optimally grows at pH 9.5, is an aerobic, facultative alkaliphilic with curved rod morphology.","The Stenotrophomonas species DL18 is known to be an aerobic, facultative alkaliphilic curved rod (Supplementary figure 2) .","Merge+Modify,Fact/Evidence",Fact/Evidence
6109,1-62,1-62_v2_4@0,1-62_v1_4@0,"ATP is molecular currency for a living cell, which is not only growing and dividing but also continuously responding to external environmental stimuli.","ATP is the molecular currency for a living cell, which is not only merely growing and dividing but also continuously responding to external environmental stimuli.","Modify,Clarity",Clarity
6110,1-62,1-62_v2_18@0,1-62_v1_25@0,Comparative studies of ATP synthase a -subunit of Stenotrophomonas species DL18,ATP synthase a -subunit of Stenotrophomonas species DL18,"Modify,Other",Other
6111,1-62,1-62_v2_17@0,1-62_v1_26@0,A BLAST analysis of the ATP synthase a -subunit of the Stenotrophomonas species DL18 suggests maximum identity with Stenotrophomonas species SKA14 (GenBank Accession number: ZP_05136035 ) at the amino acid level (259 amino acid residues were identical from a total of 266 amino acid residues in the SKA14 species).,BLAST analysis of the ATP synthase a -subunit of the Stenotrophomonas species DL 18 suggests maximum identity at the amino acid level (259 identical amino acids from a total of 266 amino acids of Stenotrophomonas species SKA14; GenBank Accession number: ZP_05136035 ).,"Modify,Clarity",Clarity
6112,1-62,1-62_v2_19@1,1-62_v1_26@1,"The amino acid residue arginine, which was found to be conserved in almost all bacterial species in the a -subunit, was observed at position 200 (Arg 200 ) in DL18.","The amino acid residue arginine, which was found to be conserved in almost all bacterial species in the a -subunit, was observed at position 200 (Arg 200 ) (Supplementary figure 3) .","Modify,Fact/Evidence",Fact/Evidence
6113,1-62,1-62_v2_19@2,1-62_v1_26@2,"Moreover, other amino acid residues that were conserved in most of the bacteria include Leu 207 , Arg 210 , Leu 211 , Gly 213 , Asn 214 , Gly 218 , Gln 252 , Ala 253 and Phe 255 ( E. coli numbering system for ATP synthase a -subunit) in the trans-membrane helix-4 ( a TMH-4), a TMH-5 and the corresponding amino acids were also found in the DL18 alignment ( Figure 1 and Figure 2 ).","Moreover, other amino acids that were conserved in most of the bacteria include Leu 207 , Arg 210 , Leu 211 , Gly 213 , Asn 214 , Gly 218 , Gln 252 , Ala 253 , Phe 255 ( E. coli numbering system for ATP synthase a -subunit) in TMH-4 and TMH-5 and the corresponding amino acids were also found in the Stenotrophomonas species DL 18 in alignment ( Figure 1 , Figure 2 ).","Modify,Clarity",Clarity
6114,1-62,1-62_v2_4@1,1-62_v1_4@1,"To survive in extreme conditions, microorganisms devise specific adaptive mechanisms.","To sustain life in extreme conditions, microorganisms devise specific mechanisms for their adaptation.","Modify,Clarity",Clarity
6115,1-62,1-62_v2_4@2,1-62_v1_4@2,"Along with other transporter proteins, ATP synthase is widely considered one of the key molecules for adaptation at alkaline conditions.","Along with other transporter proteins, ATP synthase is widely considered as one of the key molecules for adaptation at alkaline conditions.","Modify,Grammar",Grammar
6116,1-62,1-62_v2_4@3,1-62_v1_5@0,"Hydrolysis of nucleoside triphosphates, specifically ATP, provides the chemical energy to drive a wide variety of cellular reactions.","Hydrolysis of nucleoside tri-phosphates, specifically ATP, provides the chemical energy to drive a wide variety of cellular reactions.","Modify,Grammar",Grammar
6117,1-62,1-62_v2_24@0,1-62_v1_34@0,It was observed that the most conserved arginine residue of the a -subunit (Arg 200 of Stenotrophomonas sp. DL18) was aligned with the expected position of the facultative alkaliphile Bacillus pseudofirmus OF4 (i.e. Arg 172 ).,It was observed that the most conserved arginine residue of the a -subunit (Arg 200 of Stenotrophomonas species DL18) was aligned with the expected position of the facultative alkaliphile Bacillus pseudofirmus OF4 (i.e. Arg 172 ; GenBank Accession number: YP_003426326 ).,"Modify,Fact/Evidence",Fact/Evidence
6118,1-62,1-62_v2_24@2,1-62_v1_34@2,Lys 180 in B. pseudofirmus OF4 was replaced by Gly 208 in the DL18 strain.,Amino acid Lys 180 of Bacillus pseudofirmus OF4 was replaced by Gly 208 in the Stenotrophomonas species DL 18.,"Modify,Clarity",Clarity
6119,1-62,1-62_v2_24@3,1-62_v1_34@3,"In addition, glycine and alanine residues were observed at the same position in other alkaliphiles including Gly 206 in Thioalkalimicrobium cyclicum ALM1, and Ala 230 in Theoalkalivibrio sp. K90mix, as shown in Figure 1 .","In addition, a glycine residue was observed at the same position in other alkaliphiles, T. cyclicum (Gly 206 ; GenBank Accession number: YP_004537849 ), and same amino acid family Ala 230 in Theoalkalivibrio species K90mix (GenBank Accession number: YP_003461818 ) as shown in Figure 2 .","Modify,Fact/Evidence",Fact/Evidence
6120,1-62,1-62_v2_24@5,1-62_v1_34@6,"As reported by Ivey DM et al. , Lys 180 and corresponding amino acids were located in a TMH-4 in Bacillus pseudofirmus OF4 and other alkaliphiles <REF-12> , <REF-13> .","Lys 180 and corresponding amino acids were located in transmembrane helix-4 ( a TMH-4) in Bacillus pseudofirmus OF4 and other alkaliphiles <REF-23> , <REF-24> .","Modify,Fact/Evidence",Fact/Evidence
6121,1-62,1-62_v2_24@6,1-62_v1_34@7,"In the DL18 strain, a histidine residue, which is conserved in other reference species of the same genus (e.g. Stenotrophomonas species K279a, Stenotrophomonas sp. SKA14 and other alkaliphiles including T. cyclicum ALM1 (His 244 ), and Theoalkalivibrio sp. K90mix (His 262 ), was present at position 240 (His 240 ) ( Figure 1 ).","In the Stenotrophomonas species DL 18, a histidine residue, which is conserved in other reference species of the same genus ( S. maltophilia K279a GenBank Accession number: YP_001973793 ; and S . sp. SKA14) and other alkaliphiles T. cyclicum (His244), and Theoalkalivibrio species K90mix (His 262 ), was present at position 240 (His 240 ) (Figure 2) .","Modify,Fact/Evidence",Fact/Evidence
6122,1-62,1-62_v2_4@4,1-62_v1_5@1,ATP synthesis is central to ATP production during oxidative phosphorylation.,ATP synthases are central to ATP production during oxidative phosphorylation.,"Modify,Grammar",Grammar
6123,1-62,1-62_v2_26@0,1-62_v1_34@8,"E. coli K12 DH10B considered a neutrophile, can adapt to slightly alkaline conditions up to pH 8.0 and this may be due to the presence of His 245 .","However, E. coli K12 DH10B (GenBank Accession number: YP_001732559 ), considered as neutrophile, can adapt to slightly alkaline conditions i.e. up to pH 8.0 and this may be due to the presence of His 245 .","Modify,Fact/Evidence",Fact/Evidence
6124,1-62,1-62_v2_25@0,1-62_v1_34@9,It has been proposed that Gly 120 and Lys 180 forms a channel for the proton uptake pathway of the a -subunit through which protons pass onto the neighboring c -subunit in B. pseudofirmus OF4 <REF-7> .,It was proposed that Gly 120 and Lys 180 form a channel residing within the proton uptake pathway of the a -subunit through which protons pass onto the neighboring c -subunit in Bacillus pseudofirmus OF4 <REF-18> .,"Modify,Clarity",Clarity
6125,1-62,1-62_v2_2@0,1-62_v1_2@0,"Lonar Lake, an Indian soda lake with high alkaline conditions of pH 10.5, is well known for its biodiversity of extremophiles including alkaliphiles.","Lonar Lake, an Indian Soda Lake, is well known for its biodiversity of extremophiles including alkaliphiles.","Modify,Fact/Evidence",Fact/Evidence
6126,1-62,1-62_v2_4@6,1-62_v1_5@3,"The F o integral membrane protein complex provides a transmembrane pore for protons, whereas the peripheral protein F <REF-1> is involved in catalysis <REF-1> .","The F o integral membrane protein complex (the subscript ‘o’ denotes its inhibition by the drug oligomycin) provides a transmembrane pore for protons, whereas the peripheral protein F <REF-1> (the subscript ‘1’ indicates that it was the first of several factors isolated from mitochondria) is involved in catalysis <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
6127,1-62,1-62_v2_25@1,1-62_v1_37@3,"However, one study has reported that His 245 along with the Gly 218 and Glu 219 positioning plays a critical role in F o ion translocations in E. coli <REF-8> , and in the present study on Stenotrophomonas sp. DL18, His 240 , Gly 208 and Glu 209 were observed at the same corresponding positions as shown in Figure 1 .","However, one of the studies reported the His 245 along with the Glu 219 positioning plays a critical role in ion translocation in E. coli <REF-25> , while in Stenotrophomonas species DL 18 these were at His 240 and Glu 209 as shown in Figure 2 .","Modify,Fact/Evidence",Fact/Evidence
6128,1-62,1-62_v2_25@2,1-62_v1_38@0,McMillan <REF-14> et al demonstrated the importance of residues with a basic side chain along with its pKa value in ATP synthesis in alkaline environments.,McMillan et al <REF-25> showed the importance of the residue with a basic side chain along with its pKa value in ATP synthesis linked with alkaline environment.,"Modify,Clarity",Clarity
6129,1-62,1-62_v2_25@3,1-62_v1_38@1,"However, that mutation study was carried out in the Bacillus sp. TA2.A1, specifically involving the 180 th residue in the a -subunit.","However, these studies were carried out with a mutation study in the Bacillus pseudofirmus OF4 a -subunit, specifically with the position of the residue at 180.","Modify,Fact/Evidence",Fact/Evidence
6130,1-62,1-62_v2_25@4,1-62_v1_38@2,"In that amino acid substitution study, amino acid residue Lys 180 in the a -subunit was mutated to Gly 180 , His 180 and Arg 180 .","These studies included mutations at Lys 180 position as Gly 180 , His 180 and Arg 180 .","Modify,Fact/Evidence",Fact/Evidence
6131,1-62,1-62_v2_26@3,1-62_v1_38@5,"Hence, these studies in E. coli signified that the positions Gly 218 and His 245 along with Glu 219 had a critical interaction with the F o subunit function.","Similar studies in E. coli showed that the positions Gly 218 and His 245 along with G1u 219 had a critical interaction with F o function <REF-26> , <REF-27> .","Modify,Fact/Evidence",Fact/Evidence
6132,1-62,1-62_v2_27@0,1-62_v1_39@1,"From alignment, Glu 209 of the DL18 strain was conserved in alkaliphiles, neutrophiles and some acidophiles except His 186 in Acidiphilium cryptum ( Figure 1 ).","From alignment, Glu 209 of the Stenotrophomonas species DL 18 was conserved in alkaliphiles, neutrophiles and some acidophiles except His 186 Acidiphilium cryptum .","Modify,Fact/Evidence",Fact/Evidence
6133,1-62,1-62_v2_27@1,1-62_v1_39@2,"In addition, the position of Gly 212 in B. pseudofirmus OF4 corresponds to Ser 212 in Enterococcus hirae ATCC 9790 (neutrophile), His 245 in E. coli and His 240 in the Stenotrophomonas sp. DL18 while glutamate in acidophiles is positioned at Glu 222 in A. ferrooxidans and Glu 225 in A. cryptum as shown in Figure 1 .","In addition, the position of Gly 212 in Bacillus pseudofirmus OF4 corresponds to Ser 212 in E. hirae (neutrophile; GenBank Accession number: YP_006487510 ), His 245 in E. coli and His 240 in the Stenotrophomonas species DL 18 while glutamate in acidophiles, Glu 222 in A. ferrooxidans and Glu 225 in A. cryptum as shown in Figure 3 .","Modify,Fact/Evidence",Fact/Evidence
6134,1-62,1-62_v2_27@2,1-62_v1_39@3,"This showed that channel formation may involve a glycine residue along with other residues, specifically those with acidic, basic and neutral side chains, which play vital roles in ATP synthesis in acidophile, alkaliphiles and neutrophiles.","This showed that the channel formation may involve a glycine residue along with other residues, specifically acidic, basic and neutral side chain, which play vital roles in ATP synthesis in acidophile, alkaliphiles and neutrophiles.","Modify,Clarity",Clarity
6135,1-62,1-62_v2_27@3,1-62_v1_39@4,"Hence, these residues are found to be critical in channel formation <REF-7> – <REF-9> .","Hence, these residues are found to be critical in channel formation.","Modify,Fact/Evidence",Fact/Evidence
6136,1-62,1-62_v2_27@5,1-62_v1_39@5,Gly 208 and His 240 may form the proton translocation channel.,"In the same scenario, the Gly 208 and His 240 may be form the proton translocation channel in Stenotrophomonas species DL 18.","Modify,Clarity",Clarity
6137,1-62,1-62_v2_4@7,1-62_v1_5@4,"F <REF-1> consists of five subunits, α <REF-3> β <REF-3> γ <REF-1> δ <REF-1> ε <REF-1> , with a ring of α- and β-subunits alternating around a single γ-subunit <REF-2> .","F <REF-1> consists of five subunits α <REF-3> β <REF-3> γ <REF-1> δ <REF-1> ε <REF-1> , with a ring of α- and β-subunits alternating around a single γ-subunit <REF-2> .","Modify,Grammar",Grammar
6138,1-62,1-62_v2_4@9,1-62_v1_5@6,"Out of these subunits, a -subunit is a stator and c -ring is a rotor ring through which ions (H + or Na + ) are translocated <REF-3> – <REF-6> .","Out of these subunits, the a -subunit is a stator and c-ring is a rotor ring through which ions (H + or Na + ) are translocated <REF-3> – <REF-6> .","Modify,Grammar",Grammar
6139,1-62,1-62_v2_4@10,1-62_v1_5@7,Each c -chain from the ring consists of two α-helices traversing the membrane and the polar loop extends out of the membrane to interact with the γ-and ε-subunits.,"Each c -chain from the ring consists of two α-helices traversing the membrane, and the polar loop extends out of the membrane to interact with the γ-and ε-subunits.","Modify,Grammar",Grammar
6140,1-62,1-62_v2_4@11,1-62_v1_5@8,A cytoplasmic F <REF-1> catalytic domain is connected by a membrane-embedded F o domain by a central (γε) and peripheral (b <REF-2> δ) stalk <REF-2> – <REF-6> .,A cytoplasmic F <REF-1> catalytic domain is connected with a membrane-embedded F o domain by a central (γε) and peripheral (b <REF-2> δ) stalk <REF-2> – <REF-6> .,"Modify,Grammar",Grammar
6141,1-62,1-62_v2_4@12,1-62_v1_6@0,"In general, downhill ion translocation across the membrane through F o causes rotation of the c -ring, which induces conformational changes in the catalytic β-subunit and results in ATP synthesis.","Downhill ion translocation across the membrane through F o causes rotation of the c-ring, which induces conformational changes in the catalytic β-subunit and results in ATP synthesis.","Modify,Clarity",Clarity
6142,1-62,1-62_v2_2@1,1-62_v1_2@1,Most of the molecular studies on Lonar Lake alkaliphiles are based on identification by 16S ribosomal RNA (16S rRNA).,Most of the molecular studies on Lonar Lake alkaliphiles are based on molecular identification by 16S ribosomal RNA along with numerous applications in the biotechnology industry.,"Modify,Fact/Evidence",Fact/Evidence
6143,1-62,1-62_v2_4@13,1-62_v1_6@8,"However, in alkaline conditions, the external pH is high i.e. above pH 8.0, which poses a major thermodynamic problem for ATP synthesis.","However, alkaliphiles grow at high environmental pH, which poses the thermodynamic problem of synthesizing ATP with ATP synthase.","Modify,Fact/Evidence",Fact/Evidence
6144,1-62,1-62_v2_2@3,1-62_v1_2@2,"As the data on the alkaliphilic nature of bacteria from Lonar Lake is incompletely understood, the present report comprised of isolation and identification of alkaliphiles from Lonar Lake.","However, molecular basis of adaptation of these alkaliphiles to high alkaline conditions is incompletely understood.","Modify,Fact/Evidence",Fact/Evidence
6145,1-62,1-62_v2_5@0,1-62_v1_8@0,Most studies have focused on the proton translocation channel in the a -subunit of ATP synthase <REF-7> – <REF-9> .,Most studies have focused on the proton translocation channel in the a -subunit of ATP synthase.,"Modify,Fact/Evidence",Fact/Evidence
6146,1-62,1-62_v2_5@1,1-62_v1_8@3,"However, similar experimental evidence from other geographic locations such as highly alkaline soda lakes needs further exploration to understand pH homeostasis in facultative alkaliphiles.","However, similar experimental evidence from other geographic locations such as highly alkaline soda lakes need further exploration to understand pH homeostasis in facultative alkaliphiles.","Modify,Grammar",Grammar
6147,1-62,1-62_v2_5@2,1-62_v1_8@4,This study explores the ATP synthase a -subunit of a facultative alkaliphilic aerobe isolated from Lonar Lake.,This study explores the comparison of the ATP synthase a -subunit of facultative alkaliphilic aerobes isolated from Lonar Lake with established and reported alkaliphiles.,"Modify,Fact/Evidence",Fact/Evidence
6148,1-62,1-62_v2_6@0,1-62_v1_9@0,Methods,Materials and methods,"Modify,Other",Other
6149,1-62,1-62_v2_7@0,1-62_v1_10@0,Isolation and identification of bacteria from the soda lake,Isolation and culture of bacteria,"Modify,Other",Other
6150,1-62,1-62_v2_8@0,1-62_v1_11@0,"In the present study, underwater sediment soil samples were collected 350 meters away from the Kamalaja Devi Temple end of Lonar Lake, Buldhana, Maharashtra, India.","Underwater sediment soil samples were collected from 350 meters away from Kamalaja Devi Temple end, Lonar Lake, Buldhana, Maharashtra, India.","Modify,Clarity",Clarity
6151,1-62,1-62_v2_8@4,1-62_v1_13@0,The bacterial genomic DNA of optimally grown bacteria at pH 9.5 with orange pigmentation was isolated by the DNAzol method <REF-10> .,Bacterial genomic DNA was isolated by the DNAzol method <REF-19> .,"Modify,Fact/Evidence",Fact/Evidence
6152,1-62,1-62_v2_2@4,1-62_v1_2@4,"Further, we studied the F1FoATP synthase a- subunit, with reference to alkaliphile specific domains, of one of the facultative alkaliphiles, Stenotrophomonas sp. DL18.","One facultative alkaliphile, Stenotrophomonas species DL18, was studied for F 1 F o ATP synthase a-subunit with reference to alkaliphile-specific domains.","Modify,Clarity",Clarity
6153,1-62,1-62_v2_11@1,1-62_v1_14@1,"Briefly, a PCR reaction mixture of 100 µl was prepared: 10x PCR buffer, 50 mM MgCl 2 , 10 mM dNTP mix, 100 picomoles each of forward and reverse primers, 5 units of Taq DNA polymerase (Chromous Biotech, India) with Pfu and 200 ng of bacterial genomic DNA template in nuclease free water.","Briefly, PCR reaction mixture of 100 µl was prepared as 10x PCR Rxn Buffer (Invitrogen), 50mM MgCl 2 (Invitrogen) 1.8 µl, 10 mM dNTP mix 3.0 µl (Merck), 100 picomoles of each forward and reverse primers (Integrated DNA technologies, USA), 5U Taq DNA polymerase (Invitrogen) with pfu (Chromous biotech, India) and bacterial genomic DNA templates 200 ng, with remaining nuclease free water (Merck, India).","Modify,Fact/Evidence",Fact/Evidence
6154,1-62,1-62_v2_11@3,1-62_v1_14@3,A final extension was carried out at 72°C for 5 min.,Final extension was carried out at 72°C for 5 min and stored at 4°C.,"Modify,Fact/Evidence",Fact/Evidence
6155,1-62,1-62_v2_10@0,1-62_v1_15@0,PCR and DNA sequencing of ATP synthase a -subunit of Stenotrophomonas species DL18,DNA sequencing and analysis,"Modify,Other",Other
6156,10-25,10-25_v2_24@1,,"After the acclimation, juvenile silver pompano with mean body weight of 8.56 ± 0.18 g were randomly distributed into 15 similar 20-L plastic jars filled with 15-L water (10 fish per jar with three replication per treatment).",,"Add,Fact/Evidence",Fact/Evidence
6157,10-25,10-25_v2_29@3,,"Goblet cells, congestion and hemorrhage in the intestinal tissues among treatments was compared.",,"Add,Fact/Evidence",Fact/Evidence
6158,10-25,10-25_v2_55@5,,"Furthermore, this decrease might be due to the feeding habits of carnivorous fish such as silver pompano which is lower amylase activity than protease and lipase enzymes.",,"Add,Claim",Claim
6159,10-25,10-25_v2_3@1,10-25_v1_3@1,The diets were given to juvenile silver pompano (with average body weight of 8.56 ± 0.18 g) and stocked in 15 similar 20-L plastic jars with 10 fish per jar in a density of 100 L capacity container.,The diets were given to juvenile silver pompano (with average body weight of 8.56 ± 0.18 g) and stocked with 10 fish in a 100 L capacity container.,"Modify,Fact/Evidence",Fact/Evidence
6160,10-25,10-25_v2_24@0,10-25_v1_24@0,"The juvenile silver pompano were purchased from Batam Marine Aquaculture Center (BPBL) located in Setoko islands, Batam city were placed and acclimatised in 400- L plastic tanks for a week.","Ten juvenile silver pompano were purchased from Batam Marine Aquaculture Center (BPBL) located in Setoko islands, Batam city with mean weight of 8.56±0.18 g were placed in 100 L plastic tanks.","Modify,Fact/Evidence",Fact/Evidence
6161,10-25,10-25_v2_58@2,10-25_v1_58@2,Chor et al. <REF-24> also stated that the lipase and protease activity of omnivorous fish was higher than amylase.,Chor et al. <REF-24> also stated that the lipase and protease activity of omnivorous fish including star pomfret was higher than amylase.,"Modify,Fact/Evidence",Fact/Evidence
6162,10-25,10-25_v2_68@0,10-25_v1_68@0,"The use of FFM in feed resulted in increased activity of digestive enzymes (protease, lipase) in silver pompano.","The use of FFM in feed resulted in increased activity of digestive enzymes (protease, lipase, and amylase) in silver pompano.","Modify,Fact/Evidence",Fact/Evidence
6163,10-25,10-25_v2_2@3,10-25_v1_2@3,This study aimed to determine the digestibility of fermented feather meal (FFM) in silver pompano ( Trachinotus blochii ) diets and to observe the histological structure of their intestines after digestion.,This study aimed to determine the digestibility of fermented feather meal (FFM) in silver pompano diets and to observe the histological structure of their intestines after digestion.,"Modify,Clarity",Clarity
6164,10-77,10-77_v2_14@2,,"At each place, a 50-minute sampling effort was made by two people in a single visit.",,"Add,Fact/Evidence",Fact/Evidence
6165,10-77,10-77_v2_20@1,,The google earth Pro 7.3.3.7786 polygon was used to determine the sampled area of each zone.,,"Add,Fact/Evidence",Fact/Evidence
6166,10-77,10-77_v2_39@0,10-77_v1_39@0,"The population density of A. fulica reported in this study was between 0.0019–0.6818 ind/m 2 , these density values are similar to those obtained by De la Ossa et al .","The population density of A. fulica reported in this study was between 0.0019–0.6818 ind/m <REF-2> , these density values are similar to those obtained by De la Ossa et al .","Modify,Fact/Evidence",Fact/Evidence
6167,10-77,10-77_v2_39@2,10-77_v1_39@2,"Other similar values were reported in a study performed in Ilha Porchat, Brazil, obtaining a density of 0.07 ind/m 2 <REF-3> .","Other similar values were reported in a study performed in Ilha Porchat, Brazil, obtaining a density of 0.07 ind/m <REF-2> <REF-3> .","Modify,Fact/Evidence",Fact/Evidence
6168,10-77,10-77_v2_39@3,10-77_v1_39@3,"Investigations such as those carried out in Havana, Cuba, showed a considerably lower density of snails (0.00015 ind/m 2 ) <REF-26> .","Investigations such as those carried out in Havana, Cuba, showed a considerably lower density of snails (0.00015 ind/m <REF-2> ) <REF-25> .","Modify,Fact/Evidence",Fact/Evidence
6169,10-77,10-77_v2_39@4,10-77_v1_39@4,"In contrast, densities of 1.1–4.6 ind/m 2 have been reported in different departments of Colombia <REF-27> , 0.06–8 ind/m 2 in Northeast Brazil <REF-28> , and an average of 8.4 ind/m 2 in Puyo, Ecuador <REF-22> .","In contrast, densities of 1.1–4.6 ind/m <REF-2> have been reported in different departments of Colombia <REF-26> , 0.06–8 ind/m <REF-2> in Northeast Brazil <REF-27> , and an average of 8.4 ind/m <REF-2> in Puyo, Ecuador <REF-21> .","Modify,Fact/Evidence",Fact/Evidence
6170,10-77,10-77_v2_39@5,10-77_v1_39@5,"On the other hand, studies performed in Puerto Iguazú y Corrientes, Argentina, recorded a much higher average density, which reaches 107.6 ind/m 2 and 118.6 ind/m 2 , respectively <REF-15> , <REF-29> .","On the other hand, studies performed in Puerto Iguazú y Corrientes, Argentina, recorded a much higher average density, which reaches 107.6 ind/m <REF-2> and 118.6 ind/m <REF-2> , respectively <REF-14> , <REF-28> .","Modify,Fact/Evidence",Fact/Evidence
6171,10-77,10-77_v2_39@6,10-77_v1_39@6,"It has been mentioned that the areas highly affected by the giant African snail present densities of 10 ind/m 2 or more <REF-12> , <REF-30> ; this similarly occurs with regards to biomass, where devastating values of up to 780 kg/ha are estimated for areas which are highly affected <REF-12> , <REF-31> .","It has been mentioned that the areas highly affected by the giant African snail present densities of 10 ind/m <REF-2> or more <REF-11> , <REF-29> ; this similarly occurs with regards to biomass, where devastating values of up to 780 kg/ha are estimated for areas which are highly affected <REF-11> , <REF-30> .","Modify,Fact/Evidence",Fact/Evidence
6172,10-77,10-77_v2_9@0,10-77_v1_9@0,"In Colombia, the presence of A. fulica was registered for the first time in 2009 <REF-11> , since then the mollusk has been distributed in more than 20 departments, registering in all regions of the country <REF-12> .","In Colombia, the presence of A. fulica was registered for the first time in 2010, since then the mollusk has been distributed in more than 20 departments, registering in all regions of the country <REF-11> .","Modify,Fact/Evidence",Fact/Evidence
6173,10-77,10-77_v2_14@1,10-77_v1_14@1,The sampling consisted of visiting the zones within the neighborhoods of the city Cartagena previously informed by citizens affected by the presence of the snail in their homes and surroundings.,The sampling consisted of visiting the sites within the city of Cartagena previously informed by citizens affected by the presence of the snail in their homes and surroundings.,"Modify,Clarity",Clarity
6174,10-77,10-77_v2_14@5,10-77_v1_14@4,"As this was a monitoring study, all the snails available during collections were included for analyzes, no exclusion criteria were applied for the collection of the snails.","As this was a monitoring study, all the snails available in the study period were included for analyzes, no exclusion criteria were applied for the collection of the snails.","Modify,Clarity",Clarity
6175,10-77,10-77_v2_24@0,10-77_v1_24@0,"During the period studied 204 snails were collected, distributed in four zones of four Cartagena neighborhoods, for which the presence of A. fulica was indicated by the community ( Figure 1 ).","During the period studied 204 snails were collected, distributed in four sites in Cartagena for which the presence of A. fulica was indicated by the community ( Figure 1 ).","Modify,Clarity",Clarity
6176,10-77,10-77_v2_24@1,10-77_v1_24@1,"The inspected sites where the snails were collected corresponded principally to extensive gardens and other spaces inside of private properties and residential condominiums (Manga, Las Gavias, and Serena del Mar).","The inspected sites where the snails were collected corresponded essentially to the gardens of private properties and residential condominiums (Manga, Las Gavias, and Serena del Mar).","Modify,Clarity",Clarity
6177,10-77,10-77_v2_24@2,10-77_v1_24@2,"At these sites the snails were found in different substrates, such as plants, tree roots, grasses, under litter, flowerpots, and ornamental plants; In Zaragocilla, snails were found aggregated in rubble inside an educational institute.","At these sites the snails were found in different substrates, such as plants, tree roots, grasses, under litter, flowerpots and ornamental plants; In Zaragocilla, aggregates were found in the rubble.","Modify,Clarity",Clarity
6262,2-147,2-147_v2_11@4,,Approval for the use of clinical materials was obtained from the local Ethical Review Committee.,,"Add,Fact/Evidence",Fact/Evidence
6263,2-147,2-147_v2_15@7,,Curcumin was not used to pretreat the cells and explants prior to the addition of IL-1β.,,"Add,Fact/Evidence",Fact/Evidence
6264,2-147,2-147_v2_15@8,,Curcumin and IL-1β were added simultaneously to the cultures.,,"Add,Fact/Evidence",Fact/Evidence
6265,2-147,2-147_v2_26@1,2-147_v1_26@1,"Cartilage discs were digested in papain (Sigma-Aldrich, Gillingham, UK) for 16 hours.","Cartilage discs were digested in papain(Sigma-Aldrich, Gillingham, UK) for 16 hours.","Modify,Grammar",Grammar
6266,2-147,2-147_v2_30@6,2-147_v1_30@6,Densitometric quantification of MMP-3 bands was performed using ImageJ software.,Densitometric quantification of MMP-3 bands was performed using Image J software.,"Modify,Grammar",Grammar
6267,2-147,2-147_v2_66@0,2-147_v1_66@0,"In summary, although this study found that curcumin at concentrations of 25μM and above is cytotoxic to monolayer chondrocytes after five days in culture, lower concentrations effectively antagonize PG and PGE 2 release in vitro and exert a potent anti-inflammatory effect on cartilage explants treated with IL-1β.","In summary, although this study found that curcumin at concentrations of 25μM and above is cytotoxic to monolayer chondrocytes after five days in culture, lower concentrations effectively antagonize PG and PGE2 release in vitro and exert a potent anti-inflammatory effect on cartilage explants treated with IL-1β.","Modify,Grammar",Grammar
6268,2-147,2-147_v2_11@2,2-147_v1_11@1,The joint tissues were sourced from UK-based abattoirs and veterinary practices.,The joint tissues were sourced from two UK-based abattoirs.,"Modify,Fact/Evidence",Fact/Evidence
6269,2-147,2-147_v2_11@3,2-147_v1_11@2,Animals were euthanized for non-research purposes either in accordance with Welfare of Animals (Slaughter or Killing) Regulations 1995 or the Veterinary Surgeons Act with owner consent.,Animals were euthanized for non-research purposes having been stunned before slaughter for meat in accordance with Welfare of Animals (Slaughter or Killing) Regulations 1995 .,"Modify,Fact/Evidence",Fact/Evidence
6270,2-147,2-147_v2_17@6,2-147_v1_17@6,"Live and dead cells were counted with ImageJ Software (National Institutes of Health, Bethesda, MD) and the percentage of dead cells (expressed as a percentage of the total number of cells present) was calculated at 24 hours, 48 hours and five days for each treatment.","Live and dead cells were counted with Image J Software (National Institutes of Health, Bethesda, MD) and the percentage of dead cells (expressed as a percentage of the total number of cells present) was calculated at 24 hours, 48 hours and five days for each treatment.","Modify,Grammar",Grammar
6271,2-155,2-155_v2_9@2,,"Within each category of chicken purchased, we collected at least four samples of each brand.",,"Add,Fact/Evidence",Fact/Evidence
6272,2-155,2-155_v2_19@4,,"Over half of all strains collected exhibited resistance to one or more antibiotics: 55%, 58%, 60%, and 76% from conventional, RWA, organic, and kosher chicken samples, respectively.",,"Add,Fact/Evidence",Fact/Evidence
6273,2-155,2-155_v2_29@1,,"Based on a national survey conducted by the USDA of poultry and hog producers in the United States, use of antibiotics at sub-therapeutic levels for growth promotion is common <REF-35> , <REF-36> .",,"Add,Fact/Evidence",Fact/Evidence
6274,2-155,2-155_v2_29@2,,"One estimate places growth promotion in livestock production as the single largest sector in which antibiotics are used in the US, accounting for 70% of the total of 50 million pounds for the year 2008 <REF-37> .",,"Add,Fact/Evidence",Fact/Evidence
6275,2-155,2-155_v2_30@0,,"Our finding that brands within categories did not differ significantly in the extent of antibiotic resistant E. coli ( Table 1 ) could arise from the fact that individual brands of chicken obtain product from multiple farms whose production practices may differ, obscuring clear patterns associated with individual brands.",,"Add,Claim",Claim
6276,2-155,2-155_v2_30@1,,Our ability to detect an effect of brand might also be constrained by low statistical power.,,"Add,Claim",Claim
6277,2-155,2-155_v2_29@0,2-155_v1_29@0,"Poultry growers use antibiotics both for therapeutic purposes and for growth promotion <REF-33> , <REF-34> .","Antibiotic use is widespread in the production of chicken both for therapeutic and non-therapeutic purposes (e.g., growth promotion).","Modify,Fact/Evidence",Fact/Evidence
6278,2-155,2-155_v2_29@3,2-155_v1_29@1,"The use of antibiotics in poultry production can select for antibiotic-resistant microorganisms including Salmonella , Campylobacter , Enterococcus , and extra-intestinal pathogenic E. coli <REF-38> .","The use of antibiotics in poultry production selects for antibiotic-resistant microorganisms including Salmonella , Campylobacter , Enterococcus , and extra-intestinal pathogenic E. coli <REF-33> .","Modify,Clarity",Clarity
6279,2-155,2-155_v2_35@2,2-155_v1_35@2,Our final sample size was limited (n=184) but not atypical for the field <REF-48> – <REF-51> .,Our sample size was limited (n=184) but not atypical for the field <REF-43> – <REF-46> .,"Modify,Clarity",Clarity
6280,2-155,2-155_v2_2@1,2-155_v1_2@1,"Consumers have a range of choices for poultry, including conventional, organic, kosher, and raised without antibiotics (RWA) – designations that are perceived to indicate differences in quality and safety.","Consumers have a range of choices for poultry, including conventional, organic, kosher, and raised without antibiotics (RWA)-designations that are perceived to indicate differences in quality and safety.","Modify,Grammar",Grammar
6281,2-155,2-155_v2_12@3,2-155_v1_12@3,"The plate was incubated at 37°C for 2 h and then at 44°C for 22 h, along with QA/QC strains ATCC E. coli 35218, Klebsiella pneumoniae , Hafnia alvei , Citrobacter freundii and Serratia plymuthica.","The plate was incubated at 37°C for 2 h and then at 44°C for 22 h, along with QA/QC strains ATCC E. coli 35218, Klebsiella pneumoniae , Hafnia alvei , Citrobacter freundii, and Serratia plymuthica.","Modify,Grammar",Grammar
6282,2-173,2-173_v2_31@8,,The mechanism by which 1-ABT inhibits esterases is not known.,,"Add,Claim",Claim
6283,2-173,2-173_v2_63@2,,"Because we have not been able to evaluate this mechanism more thoroughly in primary lung cells, particularly from asthmatic subjects, the physiological and/or clinical relevance of the present study in steroid insensitive patients requires further investigation.",,"Add,Claim",Claim
6284,2-173,2-173_v2_62@2,2-173_v1_62@2,"As such, additional studies using animal models and relevant samples from human patients need to be evaluated in order to conclusively confirm or reject the hypothesis that CYP3A genes are regulated in human subjects, particularly asthmatics, in response to glucocorticoid treatment since current in vitro models remain unexplainably limited in value for such studies.","As such, additional studies using animal models and relevant samples from human patients need to be evaluated in order to conclusively confirm or reject the hypothesis that CYP3A genes are regulated in human lung cells in response to glucocorticoid treatment since current in vitro models remain unexplainably limited in value for such studies.","Modify,Claim",Claim
6285,2-173,2-173_v2_63@0,2-173_v1_63@0,"In summary, the data presented herein demonstrate that, in A549 cells, glucocorticoid binding to the glucocorticoid receptor regulates the expression of CYP3A5.","In summary, the data presented herein demonstrate that, in A549 cells, glucocorticoid binding to the glucocorticoid receptor regulates the expression of CYP3A5, and therefore, corroborates the hypothesis that increased metabolism of glucocorticoids may occur in some patients.","Modify,Claim",Claim
6286,2-173,2-173_v2_63@1,2-173_v1_63@1,"However, further research is needed to determine if changes in CYP3A5 expression occur in the human respiratory tissue similar to A549 cells, the precise mechanism by which this process occurs, and whether changes in the local metabolism of glucocorticoids by CYP3A5 ultimately impact glucocorticoid efficiency in asthma patients refractory to glucocorticoid treatment.","However, further research is needed to determine if changes in CYP3A5 expression occur in the human respiratory tissue similar to A549 cells, the precise mechanism by which this process occurs, and whether changes in the local metabolism of glucocorticoids by CYP3A5 ultimately impact glucocorticoid efficiency.","Modify,Claim",Claim
6287,2-173,2-173_v2_16@6,2-173_v1_16@6,All cells except A549 cells were plated in 12-well plates pre-coated with LHC basal medium (Life Technologies) and cultured in the presence of hydrocortisone.,All cells except A549 cells were plated in 12-well plates pre-coated with LHC basal medium (Life Technologies).,"Modify,Fact/Evidence",Fact/Evidence
6327,2-238,2-238_v2_32@6,,The assay results are reproducible in three independent experiments.,,"Add,Fact/Evidence",Fact/Evidence
6328,2-238,2-238_v2_39@0,,Statistical analysis,,"Add,Other",Other
6329,2-238,2-238_v2_40@0,,"All values are expressed as mean ± standard deviation and the graphs were generated using Graph-Pad Prism ® (Version 4) for Windows (GraphPad Software, San Diego, California, USA.",,"Add,Fact/Evidence",Fact/Evidence
6330,2-238,2-238_v2_40@1,,"Statistical analysis was performed by one-way analysis of variance (ANOVA), followed by Bonferroni multiple comparison test for all parameters.",,"Add,Fact/Evidence",Fact/Evidence
6331,2-238,2-238_v2_40@2,,Results were considered statistically significant at P < 0.05.,,"Add,Fact/Evidence",Fact/Evidence
6332,2-238,2-238_v2_68@0,,Pathogenic fungi are increasingly responsible for life threatening infections in the elderly and immunocompromised patients.,,"Add,Claim",Claim
6333,2-238,2-238_v2_68@1,,"While some species have intrinsic resistance to anti-fungals, others develop resistance during the course of treatment.",,"Add,Claim",Claim
6334,2-238,2-238_v2_68@2,,Increasing antifungal resistance and treatment failures in patients is becoming a challenge.,,"Add,Claim",Claim
6335,2-238,2-238_v2_69@0,,The Candida genome encodes at least 3 distinct classes of histone deacetylases in addition to sirtuins.,,"Add,Claim",Claim
6336,2-238,2-238_v2_69@1,,"There are 8 different histone deacetylases ( HOS1, HOS2, HOS3, HDA1, HDA2, HDA3, RPD3, RPD31 ) which all have distinct roles in the morphogenesis of C. albicans .",,"Add,Claim",Claim
6337,2-238,2-238_v2_75@1,,"The fact that, the recombinant Hos2 enzyme did not show any inhibition with the Class I inhibitor MS-275 led us to explore alternate substrates including tubulins, which are substrates for Class II histone deacetylases.",,"Add,Fact/Evidence",Fact/Evidence
6338,2-238,2-238_v2_75@4,,It has been shown that microtubules in the fungal hyphae drive nuclear dynamics and cell cycle progression to morphogenesis <REF-34> .,,"Add,Fact/Evidence",Fact/Evidence
6339,2-238,2-238_v2_75@5,,"In view of the fact that Hos2 seems to preferentially deacetylate tubulins, it would be interesting to see if Hos2 inhibitors would act as anti-fungals, either as a monotherapy or in synergy, with existing anti-tubulin agents such as benomyl, nocodazole etc.",,"Add,Claim",Claim
6340,2-238,2-238_v2_78@0,,Data availability,,"Add,Other",Other
6341,2-238,2-238_v2_79@0,,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2014 Karthikeyan G et al.,,"Add,Fact/Evidence",Fact/Evidence
6342,2-238,2-238_v2_80@0,,"Data associated with the article are available under the terms of the Creative Commons Zero ""No rights reserved"" data waiver (CC0 1.0 Public domain dedication).",,"Add,Fact/Evidence",Fact/Evidence
6343,2-238,2-238_v2_22@1,2-238_v1_22@1,"Enzymatic assay was carried out in triplicates using the fluorogenic Class I HDAC substrate, Boc-Lys (Ac)-AMC (Cat. No. I1875, Bachem AG, Bubendorf, Switzerland).","Enzymatic assay was carried out using the fluorogenic Class I HDAC substrate, Boc-Lys (Ac)-AMC (Cat. No. I1875, Bachem AG, Bubendorf, Switzerland).","Modify,Fact/Evidence",Fact/Evidence
6344,2-238,2-238_v2_22@2,2-238_v1_22@2,"Briefly, 0.5 μg of purified recombinant protein in a volume of 10 μl of assay buffer was incubated with 50 μl of appropriate concentration of HDAC inhibitors and 20 μM of substrate at 37°C for 1 hr in 100 μl reaction volume.","Briefly, 0.5 μg of purified recombinant protein in a volume of 10 μl of assay buffer was incubated with 50 μl of appropriate concentration of HDAC inhibitors and 20 μM of substrate at 37°C for 1 hr.","Modify,Fact/Evidence",Fact/Evidence
6345,2-238,2-238_v2_24@0,2-238_v1_24@0,"Female BALB/c mice were purchased from The Jackson Laboratory (Bar Harbor, ME) at 4 weeks of age and then housed at the animal facility, Orchid Chemicals and Pharmaceuticals for 2 weeks in a specific-pathogen free facility with a 12 h light cycle (6 am–6 pm) and a 12 h dark cycle (6 pm–6 am).","Female BALB/c mice were purchased from The Jackson Laboratory (Bar Harbor, ME) at 4 weeks of age and then housed at the animal facility, Orchid chemicals and Pharmaceuticals for 2 weeks in a specific-pathogen free facility with a 12 h light cycle (6 am–6 pm) and a 12 h dark cycle (6 pm–6 am).","Modify,Grammar",Grammar
6346,2-238,2-238_v2_30@0,2-238_v1_30@0,"C. albicans ATCC 90028 mycelia (~5 gm wet weight) were washed with water, centrifuged at 10,000 rpm for 10 minutes at 4°C and the mycelial pellet was resuspended in 50 ml of 0.1 mM Tris-HCl, pH 9.4, 10 mM DTT.","C. albicans ATCC 90028 mycelia (~ 5 gm wet weight) were washed with water, centrifuged at 10,000 rpm for 10 minutes at 4°C and the mycelial pellet was resuspended in 50 ml of 0.1 mM Tris-HCl, pH 9.4, 10 mM DTT.","Modify,Grammar",Grammar
6347,2-238,2-238_v2_2@0,2-238_v1_2@0,"Candida albicans is a mucosal commensal organism capable of causing superficial (oral and vaginal thrush) infections in immune normal hosts, but is a major pathogen causing systemic and mucosal infections in immunocompromised individuals.","Candida albicans is a mucosal commensal organism in normal individuals, but is a major pathogen causing systemic and mucosal infections in immunocompromised individuals.","Modify,Claim",Claim
6348,2-238,2-238_v2_32@3,2-238_v1_32@3,"Deacetylation assays were carried out in 100 μl reaction volume for 1 hr at 37°C in reaction buffer (50 mM Tris Cl, pH 8.0, 137 mM NaCl, 2.7 mM KCl, 2.5 mM MgCl 2 , 1 mg/ml BSA).","Deacetylation assays were carried out for 1 hr at 37°C in reaction buffer (50 mM Tris Cl, pH 8.0, 137 mM NaCl, 2.7 mM KCl, 2.5 mM MgCl 2 , 1 mg/ml BSA).","Modify,Fact/Evidence",Fact/Evidence
6349,2-238,2-238_v2_34@2,2-238_v1_34@2,"Deacetylation assays were carried out in 100 μl reaction volume for 3 hr at 37°C in reaction buffer (50 mM Tris-Cl, pH 8.0, 137 mM NaCl, 2.7 mM KCl, 2.5 mM MgCl 2 ).","Deacetylation assays were carried out for 3 hr at 37°C in reaction buffer (50 mM Tris-Cl, pH 8.0, 137 mM NaCl, 2.7 mM KCl, 2.5 mM MgCl 2 ).","Modify,Fact/Evidence",Fact/Evidence
6350,2-238,2-238_v2_4@0,2-238_v1_4@0,Candida albicans is a commensal organism found in the mucosa and gastrointestinal tract of most healthy individuals but can cause superficial (oral and vaginal thrush) infections in immune-normal hosts and severe systemic infection in immunocompromised patients <REF-1> .,"Candida albicans is a commensal organism found in the mucosa and gastrointestinal tract of most healthy individuals but can cause severe systemic/superficial infections, especially in immunocompromised patients <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
6351,2-238,2-238_v2_38@0,2-238_v1_38@0,"HeLa nuclear extract (2 μg) or recombinant Hos2 enzyme (300 ng) was incubated with NAD+ (500 μM), Fluor de Lys ® −Sirt1 (Enzo lifescience), varying concentrations of resveratrol (Cat. No. 0219605205, MP Biomedicals, Ohio, USA) (30, 100, 250 and 500 μM) in presence or absence of the pan-HDAC inhibitor trichostatin, in 50 μl reaction volume at 37°C for 30 min.","HeLa nuclear extract (2 μg) or recombinant Hos2 enzyme (300 ng) was incubated with NAD+ (500 μM), Fluor de Lys ® −Sirt1 (Enzo lifescience), varying concentrations of resveratrol (Cat. No. 0219605205, MP Biomedicals, Ohio, USA) (30, 100, 250 and 500 μM) in presence or absence of the pan-HDAC inhibitor trichostatin, at 37°C for 30 min.","Modify,Fact/Evidence",Fact/Evidence
6352,2-238,2-238_v2_38@1,2-238_v1_38@1,The reaction was carried out in triplicate following manufacturer’s protocol (Enzo lifescience).,The reaction was carried out following manufacturer’s protocol (Enzo lifescience).,"Modify,Fact/Evidence",Fact/Evidence
6353,2-238,2-238_v2_45@0,2-238_v1_43@0,"The Hos2 enzyme was expressed in the baculoviral-insect cell expression system as a NH 2 -terminal hexa histidine tagged fusion protein, which is detected on Western blot as a ~52 kDa protein using our own polyclonal anti-Hos2 anti-sera raised against Hos2 protein in mice.","The Hos2 enzyme was expressed in the baculoviral-insect cell expression system as a NH 2 -terminal hexa histidine tagged fusion protein, which is detected on Western blot as a ~ 52 kDa protein using our own polyclonal anti-Hos2 anti-sera raised against Hos2 protein in mice.","Modify,Grammar",Grammar
6354,2-238,2-238_v2_45@1,2-238_v1_43@1,SDS-PAGE analysis of purified protein revealed a major band at ~52 kDa ( Figure 1A ).,SDS-PAGE analysis of purified protein revealed a major band at ~ 52 kDa ( Figure 1A ).,"Modify,Grammar",Grammar
6355,2-238,2-238_v2_49@1,2-238_v1_47@1,The total activity with Boc-Lys (ac) AMC showed the enzyme to be active in deacetylating the lysine residue and the activity increased significantly ( P < 0.05 ) with an increase in Hos2 concentration ( Figure 1B ).,The total activity with Boc-Lys (ac) AMC showed the enzyme to be active in deacetylating the lysine residue and the activity increased with an increase in Hos2 concentration ( Figure 1B ).,"Modify,Fact/Evidence",Fact/Evidence
6356,2-238,2-238_v2_5@0,2-238_v1_5@0,"Azole resistance in Candida sp. is mediated by up regulation of genes encoding ERG11 , a lanosterol demethylase <REF-4> – <REF-6> , MDR1 <REF-5> , <REF-7> and by CDR (Candida drug resistance) efflux pumps <REF-5> , <REF-7> – <REF-9> .","Azole resistance in Candida sp. is mediated by up regulation of genes encoding ERG11, a lanosterol demethylase <REF-4> – <REF-6> , MDR1 <REF-5> , <REF-7> and by CDR (Candida drug resistance) efflux pumps <REF-5> , <REF-7> – <REF-9> .","Modify,Grammar",Grammar
6357,2-238,2-238_v2_69@2,2-238_v1_67@0,"HDAC inhibitors, by virtue of their ability to prevent antifungal resistance in vitro, have been proposed as antifungal adjuvants.",HDAC inhibitors by virtue of their ability to prevent antifungal resistance in vitro have been proposed as antifungal adjuvants.,"Modify,Grammar",Grammar
6358,2-238,2-238_v2_74@2,2-238_v1_71@2,"Our studies with the Class I HDAC inhibitor MS-275 showed that this inhibitor did not inhibit Hos2 deacetylase as effectively as the pan HDAC inhibitors SAHA or TSA, suggesting that Candida Hos2 is more similar to Class II deacetylases.","Our studies with the class I HDAC inhibitor MS-275 showed that this inhibitor did not inhibit Hos2 deacetylase as effectively as the pan HDAC inhibitors SAHA or TSA, suggesting that Candida Hos2 is more similar to class II deacetylases.","Modify,Grammar",Grammar
6359,2-238,2-238_v2_75@3,2-238_v1_72@2,"Hos2 in essence resembles the Class II mammalian HDACs, specifically HDAC6 in its preference for tubulin deacetylation.","Hos2 in essence resembles the class II mammalian HDACs, specifically HDAC6 in its preference for tubulin deacetylation.","Modify,Grammar",Grammar
6360,2-238,2-238_v2_76@6,2-238_v1_73@6,"We did not observe any significant ( P value 0.5317 and 0.4411, in the presence and absence of trichostatin respectively) activation of NAD+ dependent deacetylase activity with the fluor-de-lys substrate.",We did not observe any significant activation of NAD+ dependent deacetylase activity with the fluor-de-lys substrate.,"Modify,Fact/Evidence",Fact/Evidence
6361,2-238,2-238_v2_7@1,2-238_v1_7@1,"For example the HDAC Class I specific inhibitor MS-275 is in advanced clinical trials (clinical trial Nos. NCT00020579, NCT00866333) for several forms of cancer, and the HDAC Class II specific inhibitor ACY-1215 is at an advanced clinical phase (clinical trial Nos. NCT01323751 , NCT01583283 ) for myeloma.","For example the HDAC Class I specific inhibitor MS-275 is in advanced clinical trials (clinical trial Nos. NCT00020579, NCT00866333) for several forms of cancer, and the HDAC class II specific inhibitor ACY-1215 is at an advanced clinical phase (clinical trial Nos. NCT01323751 , NCT01583283 ) for myeloma.","Modify,Grammar",Grammar
6362,2-238,2-238_v2_9@0,2-238_v1_9@0,"Hos2, a Class I HDAC enzyme plays an important role in gene activation in the yeast Saccharomyces cerevisiae by binding to open reading frames (ORFs) of active genes <REF-20> .","Hos2, a class I HDAC enzyme plays an important role in gene activation in the yeast Saccharomyces cerevisiae by binding to open reading frames (ORFs) of active genes <REF-20> .","Modify,Grammar",Grammar
6363,2-238,2-238_v2_2@5,2-238_v1_2@5,"Inhibition studies showed that Hos2 is susceptible to pan inhibitors such as trichostatin A (TSA) and suberoylanilide hydroxamic acid (SAHA), but is not inhibited by class I inhibitors such as MS-275.","Inhibition studies showed that Hos2 is susceptible to pan inhibitors such as trichostatin A (TSA) and suberoylanilide hydroxamic acid (SAHA), but is not inhibited by class I inhibitors such MS-275.","Modify,Grammar",Grammar
6364,2-242,2-242_v2_54@2,2-242_v1_54@2,"Mutations in several human genes have now been identified as causative of abnormal heart looping, such as ACVR2B , LEFTY2 , GJA1 and ZIC3 <REF-49> – <REF-52> , and some of the ‘jogging ortholog’ genes ( CCDC103 , CCDC40 , DNAAF1 , LRRC6 , NPHP3 and PKD2 ) are also associated with heart looping defects.","Although, mutations in several human genes have now been identified as causative of abnormal heart looping, such as ACVR2B , LEFTY2 , GJA1 and ZIC3 <REF-49> – <REF-52> , only a few of the ‘jogging ortholog’ genes, CCDC103 , CCDC40 , DNAAF1 , LRRC6 , NPHP3 and PKD2 , are associated with heart looping defects, and thus provide evidence which suggests an involvement of these genes in left-right asymmetry determination in the heart.","Split+Modify,Clarity",Clarity
6365,2-242,2-242_v2_54@3,2-242_v1_54@2,Thus providing evidence to support an involvement of these genes in left-right asymmetry determination in the heart.,"Although, mutations in several human genes have now been identified as causative of abnormal heart looping, such as ACVR2B , LEFTY2 , GJA1 and ZIC3 <REF-49> – <REF-52> , only a few of the ‘jogging ortholog’ genes, CCDC103 , CCDC40 , DNAAF1 , LRRC6 , NPHP3 and PKD2 , are associated with heart looping defects, and thus provide evidence which suggests an involvement of these genes in left-right asymmetry determination in the heart.","Split+Modify,Clarity",Clarity
6366,2-242,2-242_v2_54@5,2-242_v1_54@4,"However, there are other possible reasons why there is a poor association of heart defects with the ‘jogging ortholog’ gene list.","However, there are numerous other reasons why there is a poor association of heart defects with the ‘jogging ortholog’ gene list.","Modify,Clarity",Clarity
6367,2-242,2-242_v2_13@0,2-242_v1_13@0,A list of 30 zebrafish genes that affect heart jogging was compiled using a variety of approaches.,A list of 30 zebrafish heart jogging genes was compiled using a variety of approaches.,"Modify,Clarity",Clarity
6368,2-242,2-242_v2_13@1,2-242_v1_13@1,"Twelve zebrafish proteins were identified as they were already annotated to the ‘heart jogging’ GO terms, the remaining 18 proteins were then identified using the ZFIN ( http://zfin.org/ ) Site Search, with the search phrase 'heart jogging', and filtering using the 'Expression/Phenotypes' category.","Twelve zebrafish proteins were identified as they were already annotated to the ‘heart jogging’ GO terms, a further 18 proteins were then identified using the ZFIN database, using a keyword search (heart jogging).","Modify,Fact/Evidence",Fact/Evidence
6369,2-242,2-242_v2_13@2,2-242_v1_13@2,"This search retrieves figures from papers that have ‘heart jogging’ in the figure legend, and thus are likely to be describing specific zebrafish genes (and proteins) involved in this process.","The ZFIN ( http://zfin.org/ ) browser searches figure legends of papers that are known to describe specific zebrafish genes (and proteins), but which have not yet been curated with GO terms.","Split+Modify,Fact/Evidence",Fact/Evidence
6370,2-242,2-242_v2_13@3,2-242_v1_13@2,Many of these genes had not yet been curated with GO terms.,"The ZFIN ( http://zfin.org/ ) browser searches figure legends of papers that are known to describe specific zebrafish genes (and proteins), but which have not yet been curated with GO terms.","Split+Modify,Clarity",Clarity
6371,2-242,2-242_v2_13@4,2-242_v1_13@3,"Each of the papers identified in this way were reviewed; of the 23 zebrafish genes identified in these papers five (Bmpr1aa, Tbx1, unm_hu119, unm_hu202, unm_hu304) were eliminated, as none of these papers provided experimental evidence for the involvement of these genes in heart jogging.","This search identified a further 23 zebrafish genes, however manual review of these publications led to 5 being disregarded, as the evidence for an involvement in heart jogging was not strong enough.","Modify,Fact/Evidence",Fact/Evidence
6372,2-259,2-259_v2_8@6,,"The immunological screening included antinuclear antibodies, anti-smooth muscles antibodies, anti-mitochondria antibodies, anti LKM antibodies, anti-hepatic cytosol antibodies, complement (C3, C4, CH50), rheumatoid factor, antineutrophil cytoplasmic antibody (ANCA), antiganglioside antibodies (GM1, GM2, GD1a, GD1b, GQ1b) and onconeuronal antibodies (Hu, Ri, Yo, PNMA2, CV2, Amphiphysine).",,"Add,Fact/Evidence",Fact/Evidence
6373,2-259,2-259_v2_8@8,,The prothrombin time stayed within the normal range throughout the monitoring period.,,"Add,Fact/Evidence",Fact/Evidence
6374,2-259,2-259_v2_10@3,,Ribavirin treatment was discontinued after 35 days.,,"Add,Fact/Evidence",Fact/Evidence
6375,2-259,2-259_v2_13@2,,The present case concerned genotype 3f virus that is predominant in France <REF-8> .,,"Add,Fact/Evidence",Fact/Evidence
6376,2-259,2-259_v2_13@4,,"Moreover, several authors suggest treating severe acute HEV infections in order to preclude the development of acute liver failure <REF-9> .",,"Add,Fact/Evidence",Fact/Evidence
6377,2-259,,2-259_v1_9@6,,"Antiganglioside antibodies were negative (GM1, GM2, GD1a, GD1b, GQ1b).","Delete,Fact/Evidence",Fact/Evidence
6378,2-259,2-259_v2_8@0,2-259_v1_8@0,"We report the case of a 36-year-old French man, Caucasian truck driver, without any significant medical history.","We report the case of a 36-year-old French, Caucasian truck driver, without any significant medical history.","Modify,Clarity",Clarity
6379,2-259,2-259_v2_0@0,2-259_v1_0@0,Case Report: Severe bilateral amyotrophic neuralgia associated with major dysphagia secondary to acute hepatitis E,Severe bilateral amyotrophic neuralgia associated with major dysphagia secondary to acute hepatitis E,"Modify,Other",Other
6380,2-259,2-259_v2_9@5,2-259_v1_9@5,"The cerebrospinal fluid (CSF) was normal (2 white blood cells/mm3; CSF Protein= 0.37 g/L) and there was no intrathecal antibody synthesis, although it was not tested for the synthesis of specific anti-HEV antibodies.",The cerebrospinal fluid (CSF) was normal (2 white blood cells/mm 3 ; CSF Protein= 0.37 g/L) and there was no intrathecal antibody synthesis.,"Modify,Fact/Evidence",Fact/Evidence
6381,2-259,2-259_v2_9@9,2-259_v1_9@10,The PCR was negative in the CSF and was not initially performed in stools.,The PCR was negative in the CSF.,"Modify,Fact/Evidence",Fact/Evidence
6382,2-259,2-259_v2_10@0,2-259_v1_10@0,"A treatment with intravenous immunoglobulins (Tegeline ® , LFB laboratory, France; 0.4 g/kg/day) was given for 5 days.","A treatment with intravenous immunoglobulins (Tegeline®, LFB laboratory, France; 0.4 g/kg/day) was given for 5 days.","Modify,Grammar",Grammar
6383,2-259,2-259_v2_10@2,2-259_v1_10@2,"Nine days after ribavirin initiation, the PCR showed 2.02 log-copies/ml and was negative after 18 days in both blood and stools.","Nine days after ribavirin initiation, the PCR showed 2.02 log-copies/ml and was negative after 18 days.","Modify,Fact/Evidence",Fact/Evidence
6384,2-259,2-259_v2_12@6,2-259_v1_12@6,The only proposed treatment (with a low level of evidence) is corticosteroids but this may have been dangerous in this case of acute hepatitis E <REF-3> .,The only validated treatment is corticosteroids but this may have been dangerous in this case of acute hepatitis E <REF-3> .,"Modify,Claim",Claim
6385,2-259,2-259_v2_16@0,2-259_v1_16@0,Post-infectious neurological diseases following HEV infection must be recognized to avoid unnecessary and potentially invasive procedures such as liver biopsy.,Post-infectious neurological diseases following HEV infection must be recognized to avoid unnecessary and potentially invasive procedures.,"Modify,Claim",Claim
6386,2-260,2-260_v2_3@0,,Introduction,,"Add,Other",Other
6387,2-260,2-260_v2_5@0,,"Ever since Jensen emphasized the role of promiscuity or ‘substrate ambiguity’ in evolution through ‘fortuitous error and gain of multistep pathways’, promiscuity in proteins has been the subject of intense and detailed research <REF-7> .",,"Add,Fact/Evidence",Fact/Evidence
6388,2-260,2-260_v2_5@1,,It was demonstrated in 1976 that replacing the zinc metal ion by copper in Carboxypeptidase A introduced oxidase catalysis properties <REF-11> .,,"Add,Fact/Evidence",Fact/Evidence
6389,2-260,2-260_v2_5@2,,"Dioxygenases promiscuously hydrolyse esters <REF-12> , while the enolase superfamily is also known to catalyze numerous catalytic reactions <REF-13> , <REF-14> .",,"Add,Fact/Evidence",Fact/Evidence
6390,2-260,2-260_v2_5@3,,"Alkaline phosphatases (AP), one of the key proteins in our research, are one of the most widely researched promiscuous enzymes <REF-15> .",,"Add,Fact/Evidence",Fact/Evidence
6391,2-260,2-260_v2_5@4,,"APs are known to have sulfate monoesterase, phosphate diesterase, and phosphonate monoesterase activities <REF-16> – <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
6392,2-260,2-260_v2_5@5,,"A phosphite-dependent hydrogenase activity was also found in Escherichia coli AP (ECAP), but was absent in APs from other organisms <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
6393,2-260,2-260_v2_5@6,,"Interestingly, proteins from the AP superfamily show cross activity - Pseudomonas aeruginosa arylsulfatase (PAS) which has the primary activity of hydrolyzing sulfate monoesters also catalyzes the hydrolysis of phosphate monoesters <REF-20> , <REF-21> .",,"Add,Fact/Evidence",Fact/Evidence
6394,2-260,2-260_v2_6@3,,"For example, the catalytic Ser-His-Asp triad has virtually the same geometry in the major families of serine proteases (chymotrypsin and subtilisin), which have no sequence or structural homology <REF-26> - a classical example of convergent evolution <REF-27> , <REF-28> .",,"Add,Fact/Evidence",Fact/Evidence
6395,2-260,2-260_v2_6@6,,The choice of methods for binding site comparisons and methods for binding site detection as well as function prediction has been recently reviewed in detail <REF-31> .,,"Add,Fact/Evidence",Fact/Evidence
6396,2-260,2-260_v2_6@7,,"Notably, most of these methods are based on structural properties of the binding or the active site.",,"Add,Fact/Evidence",Fact/Evidence
6397,2-260,2-260_v2_11@0,,"Another fascinating aspect of enzymes, although strictly not defined as promiscuity, is their ability to catalyze the reaction of a range of similar substrates of the same class <REF-51> .",,"Add,Fact/Evidence",Fact/Evidence
6398,2-260,2-260_v2_11@1,,"We have hypothesized that duplicate residues, each of which results in slightly modified replicas of the active site scaffold, are responsible for the broad substrate specificity of proteins <REF-52> , <REF-53> .",,"Add,Fact/Evidence",Fact/Evidence
6399,2-260,2-260_v2_15@2,2-260_v1_13@2,"For example in a catalytic site consisting of n residues, the existence of a congruent n −1 motif does not imply that it is easy or even possible to add another residue in the structure and obtain the n residue motif.","For example in a catalytic site consisting of n residues, the existence of a congruent n − 1 motif does not imply that it is easy or even possible to add another residue in the structure and obtain the n residue motif.","Modify,Grammar",Grammar
6400,2-260,2-260_v2_15@3,2-260_v1_13@3,"This complexity is best exemplified in the failure to induce β -lactamase activity in a penicillin-binding protein (PBP-5) from E. coli <REF-58> , <REF-59> by generating the L153E mutant of this protein, as proposed by our previous analysis <REF-47> (unpublished results).","This complexity is best exemplified in the failure to induce β -lactamase activity in a penicillin-binding protein (PBP-5) from E. coli <REF-43> , <REF-44> by generating the L153E mutant of this protein, as proposed by our previous analysis <REF-35> (and unpublished results).","Modify,Clarity",Clarity
6401,2-260,2-260_v2_7@3,2-260_v1_5@3,"For example, we detected the presence of the serine protease (SPASE) catalytic triad motif (Ser195, His57, Asp102) in alkaline phosphatases (AP) from various organisms using the spatial and electrostatic congruence, and validated this by inhibition of the native phosphatase activity using inhibitors (AEBSF/PMSF) <REF-32> , known to be active on many serine proteases by reaction with the nucleophilic serine <REF-36> .","For example, we detected the presence of the serine protease (SPASE) catalytic triad motif (Ser195, His57, Asp102) in alkaline phosphatases (AP) from various organisms using the spatial and electrostatic congruence, and validated this by inhibition of the native phosphatase activity using serine protease inhibitors (AEBSF/PMSF) <REF-20> .","Modify,Fact/Evidence",Fact/Evidence
6402,2-260,2-260_v2_7@5,2-260_v1_5@5,"Recently, the crown domain in the E. coli expressed rat intestinal AP protein was shown to be prone to protease cleavage, which the authors have ascribed to self-cleavage <REF-37> .","Recently, the crown domain in the Escherichia coli expressed rat intestinal AP protein was shown to be prone to protease cleavage, which the authors have ascribed to self-cleavage <REF-24> .","Modify,Clarity",Clarity
6403,2-260,2-260_v2_8@3,2-260_v1_6@3,"We thus concluded that one should exert caution before ruling out protease activity in an enzyme since theoretically proteases have a large number of possible substrates due to the possible variation in residues flanking the sissile bond, and the corresponding folds that harbor a recognition site for a particular protease <REF-39> .",We thus concluded that one should exert caution before ruling out protease activity in an enzyme since theoretically proteases have unenumerable number of possible substrates due to the infinite possible DNA sequences that can result in proteins and their corresponding infinite folds <REF-27> .,"Modify,Fact/Evidence",Fact/Evidence
6404,2-260,2-260_v2_8@4,2-260_v1_6@4,"Thus, it is possible that we have not found the ideal proteolytic substrate for APs <REF-32> .","Thus, it is possible that we have not found the correct proteolytic substrate for APs <REF-20> .","Modify,Clarity",Clarity
6405,2-260,2-260_v2_9@2,2-260_v1_8@2,"Several β -lactam compounds failed to inhibit E. coli or shrimp AP, as was expected by the lower congruence indicated by CLASP as compared to VAP.","Several β -lactam compounds failed to inhibit E. coli or shrimp AP, as was expected by the lower congruence indicated by CLASP.","Modify,Clarity",Clarity
6406,2-260,2-260_v2_10@1,2-260_v1_9@1,The search for an elastase-like motif in a plant protein <REF-47> led us to the pathogenesis-related protein P14a <REF-49> .,The search for an elastase-like motif in a plant protein led us to the pathogenesis-related protein P14a <REF-37> .,"Modify,Fact/Evidence",Fact/Evidence
6502,2-288,2-288_v2_59@6,,"“Inner” and “outer” loops provide two levels of nesting, when needed.",,"Add,Fact/Evidence",Fact/Evidence
6503,2-288,2-288_v2_79@6,,"Given that the model code has been verified for mathematical accuracy over the full range of parameter space used for the Monte Carlo evaluation, the result gives an informative measure of the degree of validity of the model.",,"Add,Fact/Evidence",Fact/Evidence
6504,2-288,2-288_v2_79@7,,"This is the first step of uncertainty quantification ( Smith, 2014 ).",,"Add,Fact/Evidence",Fact/Evidence
6505,2-288,2-288_v2_88@0,,Run-time performance,,"Add,Other",Other
6506,2-288,2-288_v2_89@0,,"Run-time performance of JSim is dependent on numerous factors: model complexity, mathematical formulation, numeric methods used, use of parallel processing, and the fineness of time and spatial grids used.",,"Add,Fact/Evidence",Fact/Evidence
6507,2-288,2-288_v2_89@1,,"PDEs generally run faster than ODEs providing similar spatial resolution even though they include diffusion terms, but in general can be slower than ODEs representing simplified geometries, and are slower using high resolution general purpose solvers like TOMS731.",,"Add,Claim",Claim
6508,2-288,2-288_v2_89@2,,A direct solver-to-solver comparison on a problem which can be formulated as either an ODE or PDE model (a convection-diffusion model) is provided in Table 4 .,,"Add,Fact/Evidence",Fact/Evidence
6509,2-288,2-288_v2_92@0,,"The times reported in Table 4 are extraordinarily variable, and depend upon parameter values and on the values of the variable themselves, as the solvers can become highly efficient if a variable is not changing.",,"Add,Claim",Claim
6510,2-288,2-288_v2_92@2,,"In general, linear systems of implicit equations run faster than non-linear systems.",,"Add,Claim",Claim
6511,2-288,2-288_v2_92@3,,"Runs requiring stiff ODE solvers (e.g. CVode, Radau) typically run slower than non-stiff solvers (e.g. Dopri5, RK4).",,"Add,Claim",Claim
6512,2-288,2-288_v2_92@4,,"Analyses involving JSim loops, sensitivity analysis, optimization and Monte Carlo methods run faster when JSim multiprocessing is activated.",,"Add,Claim",Claim
6513,2-288,2-288_v2_92@5,,Models requiring fine temporal or spatial grids to capture relevant detail run slower than those for which coarse grids are sufficient.,,"Add,Claim",Claim
6514,2-288,2-288_v2_93@0,,"Computation time equivalent to real time was shown on a laptop computer for a cardiorespiratory system model with about 120 variables ( Neal & Bassingthwaighte, 2007 ).",,"Add,Fact/Evidence",Fact/Evidence
6515,2-288,2-288_v2_93@1,,"Models available at physiome.org typically run somewhere between a fraction of a second to several minutes, depending upon these various complications.",,"Add,Fact/Evidence",Fact/Evidence
6516,2-288,2-288_v2_93@2,,Some example model simulation execution times (“run times”) are compared to the real time duration of the events being modeled (“model times”) in Table 5 .,,"Add,Fact/Evidence",Fact/Evidence
6517,2-288,2-288_v2_93@3,,All the runs below were single model runs performed on a mid-range workstation (Dell Precision T3500 Xeon x86-64 2.5GHz).,,"Add,Fact/Evidence",Fact/Evidence
6518,2-288,2-288_v2_93@4,,"The Beeler-Reuter action potential model (#78 at physiome.org) has only 4 ionic currents and 28 time-dependent variables; the ( Winslow et al. , 1999 ) model (#217) has 126 time-dependent variables.",,"Add,Fact/Evidence",Fact/Evidence
6519,2-288,2-288_v2_93@5,,"Timing calculations are unreliable, dependent on the model, computational methods, and the values of the variables, and the timestep length.",,"Add,Fact/Evidence",Fact/Evidence
6520,2-288,2-288_v2_93@6,,"For the Winslow et al. , 1999 model, using a 1 microsec timestep took 96 seconds, only 100 times slower, not 1000 times, compared to that with Δt = 1 ms.",,"Add,Fact/Evidence",Fact/Evidence
6521,2-288,2-288_v2_96@0,,Code verification,,"Add,Other",Other
6522,2-288,2-288_v2_97@0,,We use a variety of strategies to verify the JSim code stack.,,"Add,Fact/Evidence",Fact/Evidence
6523,2-288,2-288_v2_97@1,,Some calculations such as values for transcendental functions and algebraic expansion of symbolic derivatives have known closed form solutions that can be compared exactly.,,"Add,Claim",Claim
6524,2-288,2-288_v2_97@2,,Our general policy is to write the code for analytical solutions into the JSim model to use the comparison to verify specifiable cases.,,"Add,Fact/Evidence",Fact/Evidence
6525,2-288,2-288_v2_97@3,,"In simple cases, e.g. respiratory mechanics models, exponential equations match numerical solutions for 7 decimal points.",,"Add,Fact/Evidence",Fact/Evidence
6526,2-288,2-288_v2_97@4,,Some ODE and PDE models such as exponential washout have known closed form analytic solutions which can be numerically compared to solutions generated by JSim’s numeric integrators.,,"Add,Claim",Claim
6527,2-288,2-288_v2_97@5,,"Even when a complete analytic solution is not available, certain statistics of the solution, such as mean transit time in blood-tissue flow models, can be calculated analytically and compared with the same statistic calculated from the model output.",,"Add,Claim",Claim
6528,2-288,2-288_v2_98@0,,"Parameter changes to models causing output changes that don’t correspond to expectation from induction, need to be evaluated qualitatively by the user.",,"Add,Claim",Claim
6529,2-288,2-288_v2_98@1,,"When modelers observe unexpected behavior, checking at deeper levels is required.",,"Add,Claim",Claim
6530,2-288,2-288_v2_98@2,,"While most such anomalies are due to user coding errors, over the 15 years of JSim’s existence, some subtle computation bugs in JSim have been diagnosed in this manner.",,"Add,Fact/Evidence",Fact/Evidence
6531,2-288,2-288_v2_98@3,,JSim cannot be proven bug-free even though finding anomalies is now rare: queries regarding problems in computation are welcomed at staff@physiome.org .,,"Add,Fact/Evidence",Fact/Evidence
6532,2-288,2-288_v2_99@0,,JSim models are sometimes exported in SBML format and run in other SBML supporting simulators as a comparison check.,,"Add,Fact/Evidence",Fact/Evidence
6533,2-288,2-288_v2_99@1,,Models are also sometimes entirely recoded in a different computational environment (Matlab is often used) as a comparison check.,,"Add,Fact/Evidence",Fact/Evidence
6534,2-288,2-288_v2_99@2,,"Model translations to other languages (e.g. SBML, CellML, Antimony) are verified via round-tripping (exporting to the target language and then reimporting).",,"Add,Fact/Evidence",Fact/Evidence
6535,2-288,2-288_v2_100@0,,Tests of JSim’s optimization and Monte Carlo functionality are based on convergence to solutions of known parameterization.,,"Add,Fact/Evidence",Fact/Evidence
6536,2-288,2-288_v2_100@1,,The optimizers are all very different; we advocate that users try a variety of optimizers for any given problem.,,"Add,Claim",Claim
6537,2-288,2-288_v2_100@2,,"There is no magic in an optimizer; the key in fitting a model solution to data, when the data are reliable, is in designing a carefully weighted distance function to fit as many computed model variables to simultaneously obtained experimental data functions as possible.",,"Add,Claim",Claim
6538,2-288,2-288_v2_101@0,,Tests of JSim’s multi-processing are based on comparisons to single processor computations.,,"Add,Fact/Evidence",Fact/Evidence
6539,2-288,2-288_v2_102@0,,The JSim verification suite consists of over 1200 individual tests drawn from the above methodologies.,,"Add,Fact/Evidence",Fact/Evidence
6540,2-288,2-288_v2_102@1,,"The suite is expanded when new computational or translation facilities are added, or when a bug has been found and fixed.",,"Add,Fact/Evidence",Fact/Evidence
6541,2-288,2-288_v2_102@2,,Most tests consist of comparing jsbatch output with user-verified reference data.,,"Add,Fact/Evidence",Fact/Evidence
6542,2-288,2-288_v2_102@3,,The verification suite is run before every official JSim release to ensure consistency of operation.,,"Add,Fact/Evidence",Fact/Evidence
6543,2-288,2-288_v2_110@0,,Using archived models for analyzing one’s own data,,"Add,Other",Other
6544,2-288,2-288_v2_111@0,,All the archived models may be downloaded so that an experimentalist can import his own data into the project file and analyze it.,,"Add,Fact/Evidence",Fact/Evidence
6545,2-288,2-288_v2_111@1,,"The JSim Home Page is an operations manual for downloading, running models and analyzing data.",,"Add,Fact/Evidence",Fact/Evidence
6546,2-288,2-288_v2_111@2,,For parameter evaluation the number of trial optimizations can be set to 1 (so there is no optimization done) but the covariance matrix is calculated to provide estimates of confidence limits from the local linear combination of sensitivity functions.,,"Add,Fact/Evidence",Fact/Evidence
6547,2-288,2-288_v2_111@3,,"For greater generality one should set up the optimizer to evaluate the set of parameters desired, then run the Monte Carlo (tab at bottom) to repeat the optimization many times in the presence of added noise; this provides realistic probability density functions of parameter values.",,"Add,Fact/Evidence",Fact/Evidence
6548,2-288,2-288_v2_112@0,,Some Alternative Simulation Platforms,,"Add,Other",Other
6549,2-288,2-288_v2_113@0,,A comprehensive feature-by-feature analysis of alternative simulation platforms is beyond the scope of this paper.,,"Add,Fact/Evidence",Fact/Evidence
6550,2-288,2-288_v2_113@1,,"Listed below are brief descriptions of some simulation systems using procedural methods, as opposed to JSim declarative approach.",,"Add,Fact/Evidence",Fact/Evidence
6551,2-288,2-288_v2_113@2,,All can be used to fit model solutions to data.,,"Add,Fact/Evidence",Fact/Evidence
6552,2-288,2-288_v2_114@0,,"Virtual Cell ( Loew & Schaff, 2001 ) is a computational environment designed for the construction and simulation of cellular-based models.",,"Add,Fact/Evidence",Fact/Evidence
6553,2-288,2-288_v2_114@1,,"Models can be created iteratively in the GUI, or via VCell’s custom mathematical language VCMDL which supports ODEs & PDEs.",,"Add,Fact/Evidence",Fact/Evidence
6554,2-288,2-288_v2_114@2,,Both deterministic and stochastic simulations are supported.,,"Add,Fact/Evidence",Fact/Evidence
6555,2-288,2-288_v2_114@3,,Model computations are performed via client accounts on VCell’s computational server farm.,,"Add,Fact/Evidence",Fact/Evidence
6556,2-288,2-288_v2_115@0,,"COPASI ( Hoops et al. , 2006 ) (for COmplex PAthway SImulator) is an integrated modeling and simulation environment aimed at metabolic networks, cell-signaling pathways, regulatory networks, infectious diseases and similar systems.",,"Add,Fact/Evidence",Fact/Evidence
6557,2-288,2-288_v2_115@1,,Models are typically created via a table-driven GUI and results viewed via embedded graphs.,,"Add,Fact/Evidence",Fact/Evidence
6558,2-288,2-288_v2_115@2,,"COPASI supports SBML and currently runs on Linux, MacOS and Windows.",,"Add,Fact/Evidence",Fact/Evidence
6559,2-288,2-288_v2_117@0,,"Chaste ( Mirams et al. , 2013 ) is C++ library for computational physiology and biology.",,"Add,Fact/Evidence",Fact/Evidence
6560,2-288,2-288_v2_117@1,,"Computational modules include mesh generation, linear algebra, ODEs, PDEs and continuum mechanics.",,"Add,Fact/Evidence",Fact/Evidence
6561,2-288,2-288_v2_117@2,,"I/O modules provide support for various file formats, including HDF5 ( Folk et al. , 1999 ).",,"Add,Fact/Evidence",Fact/Evidence
6562,2-288,2-288_v2_117@3,,"Chaste is available for Windows, MacOS, Linux and Solaris.",,"Add,Fact/Evidence",Fact/Evidence
6563,2-288,2-288_v2_118@0,,"PCenv, COR, OpenCell and OpenCOR ( CellML, 2014 ) are a related set of tools supporting CellML modeling.",,"Add,Fact/Evidence",Fact/Evidence
6564,2-288,2-288_v2_118@1,,PCenv is an interactive modeling editing and simulation environment running on Windows.,,"Add,Fact/Evidence",Fact/Evidence
6565,2-288,2-288_v2_118@2,,COR an alternative CellML modeling environment for Windows.,,"Add,Fact/Evidence",Fact/Evidence
6566,2-288,2-288_v2_118@3,,"OpenCell is a merger of PCenv and COR built upon the Mozilla platform, and running on Linux, Windows and MacOS.",,"Add,Fact/Evidence",Fact/Evidence
6567,2-288,2-288_v2_118@4,,OpenCell development has been stopped in favor of its replacement OpenCOR.,,"Add,Fact/Evidence",Fact/Evidence
6568,2-288,2-288_v2_119@0,,"Continuity ( Continuity, 2014 ) is problem-solving environment for multi-scale modeling in bioengineering and physiology - especially biomechanics, transport and electrophysiology.",,"Add,Fact/Evidence",Fact/Evidence
6569,2-288,2-288_v2_119@1,,Finite element and PDEs are supported.,,"Add,Fact/Evidence",Fact/Evidence
6570,2-288,2-288_v2_119@2,,"The Continuity language integrates with Python ( VanRossum & Drake, 2003 ) scripts to create multi-scale models.",,"Add,Fact/Evidence",Fact/Evidence
6571,2-288,2-288_v2_119@3,,"Continuity runs on Windows, MacOS, Linux and Linux clusters.",,"Add,Fact/Evidence",Fact/Evidence
6572,2-288,2-288_v2_129@0,,"SED-ML Support: SED-ML ( Kohn & Le Novere, 2008 ) (for Simulation Experiment Description) is an emerging standard for to promote reproducibility by capturing all the details of an in silico experiment.",,"Add,Fact/Evidence",Fact/Evidence
6573,2-288,2-288_v2_129@1,,"Major entities described in SED-ML are models, simulation setup (i.e. time and numeric solver parameters), tasks (a model run with specified a simulation setup), data generators (methods for combining model outputs from different tasks) and outputs (plots & tables).",,"Add,Fact/Evidence",Fact/Evidence
6574,2-288,2-288_v2_129@2,,"JSim projects support these entities, but not in a scripted form.",,"Add,Fact/Evidence",Fact/Evidence
6575,2-288,2-288_v2_129@3,,"To support SED-ML, we are currently developing a feature called Second Level Analysis (SLA) that will allow JSim users to script common JSim activities (e.g. model runs with different parameter sets, data combinatorics, plotting and export), in a way that maps to SED-ML.",,"Add,Fact/Evidence",Fact/Evidence
6576,2-288,2-288_v2_129@4,,SED-ML files will be read into JSim as SLA scripts and run there.,,"Add,Fact/Evidence",Fact/Evidence
6577,2-288,2-288_v2_129@5,,"Conversely, JSim SLA scripts may be exported to SED-ML for use in other simulators that support SED-ML.",,"Add,Fact/Evidence",Fact/Evidence
6578,2-288,2-288_v2_132@0,,Data and software availability,,"Add,Other",Other
6579,2-288,2-288_v2_133@0,,"Zenodo: JSim downloads and models Version 2, doi: http://dx.doi.org/10.5281/zenodo.8652 ( Butterworth et al. , 2014 )",,"Add,Fact/Evidence",Fact/Evidence
6580,2-288,,2-288_v1_32@7,,"If a particular model absolutely requires procedural code, this can be developed in C, or Fortran or Java, and invoked as part of the model computation.","Delete,Fact/Evidence",Fact/Evidence
6581,2-288,,2-288_v1_78@7,,(JSim’s confidence limit calculations support modeling step 12 above.),"Delete,Fact/Evidence",Fact/Evidence
6582,2-288,,2-288_v1_88@7,,"F1000s founder, Victor Tracz, is featured as the “Seer of Science Publishing”, prodding us to do better.","Delete,Fact/Evidence",Fact/Evidence
6583,2-288,,2-288_v1_104@1,,Software is also permanently available from: 10.5281/zenodo.7635 .,"Delete,Fact/Evidence",Fact/Evidence
6584,2-288,2-288_v2_7@1,,"The more realistic the model, the more accurate the prediction.",,"Add,Claim",Claim
6585,2-288,2-288_v2_31@10,,"In general, using Matlab without Simulink takes 6 to 20 times as long as JSim solutions.",,"Add,Fact/Evidence",Fact/Evidence
6586,2-288,2-288_v2_33@0,,Declarative languages such as MML describe the logic of a computer program rather than the explicit flow of control.,,"Add,Claim",Claim
6587,2-288,2-288_v2_33@1,,In traditional procedural languages such as C and Fortran the flow of control is explicit in the code.,,"Add,Claim",Claim
6588,2-288,2-288_v2_33@2,,Declarative languages have advantages and disadvantages relative to procedural languages.,,"Add,Claim",Claim
6589,2-288,2-288_v2_33@3,,"They allow for clear exposition of the intentions of computation, since only the equations (without the numerical details) are specified.",,"Add,Claim",Claim
6590,2-288,2-288_v2_33@4,,"Because they generally represent a top-down view of the mathematics, they allow automated handling of computational complexities such as parallel processing without distracting the user with complex details.",,"Add,Claim",Claim
6591,2-288,2-288_v2_33@5,,"On the other hand, it is difficult for a procedural translation of declarative code, as going from MML to compute using Java, to be as general and efficient as optimized procedural code.",,"Add,Claim",Claim
6592,2-288,2-288_v2_33@6,,Consequently MML is designed to permit use of procedural code when circumstances demand it.,,"Add,Fact/Evidence",Fact/Evidence
6593,2-288,2-288_v2_31@0,2-288_v1_31@0,"JSim is designed centrally for evaluating models against experimental data, for describing biological systems, for designing experiments, and for the teaching of integrative systems approaches to biological, chemical and physical systems.","JSim is quite general, and while designed for evaluating models against experimental data, it also serves pure model development quite well.","Modify,Fact/Evidence",Fact/Evidence
6594,2-288,2-288_v2_32@0,2-288_v1_32@0,MML (Mathematical Modeling Language) is a declarative modeling language developed for JSim and used for composing models.,MML (Mathematical Modeling Language) is the declarative modeling language developed for JSim and used for composing models.,"Modify,Grammar",Grammar
6595,2-288,2-288_v2_37@0,2-288_v1_36@0,"JSim’s mathematical modeling language, MML","JSim’s Mathematical Modeling Language, MML","Modify,Grammar",Grammar
6596,2-288,2-288_v2_38@1,2-288_v1_37@1,"When JSim imports other model formats (e.g. SBML, CellML, Antimony ( Smith et al. , 2013 )), it translates them to MML.","When JSim imports other model formats (e.g. SBML, CellML, Antimony), it translates them to MML.","Modify,Fact/Evidence",Fact/Evidence
6597,2-288,2-288_v2_44@2,2-288_v1_41@2,At present JSim provides 8 algorithms for solving ODEs [ Table 1 ) and 3 for PDEs [ Table 2 ).,At present JSim provides 8 algorithms for solving ODEs ( Table 1 ) and 3 for PDEs ( Table 2 ).,"Modify,Grammar",Grammar
6598,2-288,2-288_v2_49@1,2-288_v1_46@1,"Partial differential equations also require boundary conditions, as seen in the code for a two-region convection-diffusion-permeation-reaction model [ Box 2 ).","Partial differential equations require also boundary conditions, as seen in the code for a two-region convection-diffusion-permeation-reaction model ( Box 2 ).","Modify,Grammar",Grammar
6599,2-288,2-288_v2_51@4,2-288_v1_48@4,"When there is no consumption and the system is linear (output area equals input) and stationary (response same at another time), then the output function is the convolution of the operator’s transfer function (the response to an infinitely short pulse input) with the input function.","When the system is linear (output area equals input) and stationary (response same at another time), then the output is the convolution of the operator’s transfer function (the response to an infinitely short pulse input) with the input function.","Modify,Fact/Evidence",Fact/Evidence
6600,2-288,2-288_v2_4@2,2-288_v1_4@2,"By so doing, at least one of the hypotheses must then be rejected; the rejection marks a stepping-stone in science.","By so doing, at least one of the hypotheses must then be rejected: the rejection marks a stepping-stone in science.","Modify,Grammar",Grammar
6601,2-288,2-288_v2_63@0,2-288_v1_62@0,"Nested plots [ Figure 3 ) are JSim’s version of worlds-within-worlds graphics ( Harris et al. , 1994 ).","Nested plots ( Figure 3 ) are JSim’s version of worlds-within-worlds graphics ( Harris et al. , 1994 ).","Modify,Grammar",Grammar
6602,2-288,2-288_v2_5@2,2-288_v1_5@2,"Given that the experiment tests whether or not the working hypothesis is compatible with experimental data, then failure to fit the data within a defined level of goodness of fit leads to skepticism about the accuracy of the data or more often, about the structure of the model and leads to its modification or to its outright rejection.","Given that the experiment tests whether or not the working hypothesis is compatible with experimental data, then failure to fit leads to rejection.","Modify,Claim",Claim
6603,2-288,2-288_v2_71@1,2-288_v1_70@1,Automated parameter optimization is usually much faster; eight methods are provided [See Table 3 ]; we recommend testing several in order to test speed and reliability with respect to the particular types of data and model.,Automated parameter optimization is usually much faster; eight methods are provided (See Table 3 ); we recommend testing several in order to test speed and reliability with respect to the particular types of data and model.,"Modify,Grammar",Grammar
6604,2-288,2-288_v2_7@0,2-288_v1_7@0,"As in physics, models are posed in order to gain deeper understanding and to make predictions.","As in physics, models are posed in order to gain deeper understanding.","Modify,Claim",Claim
6605,2-288,2-288_v2_79@3,2-288_v1_78@3,"3) “Run” Monte Carlo automatically re-optimizes the model against the new set of perturbed data points to obtain another estimate for each parameter, repeating steps 2 and 3 many times (e.g. set it to 1000).",3) Re-optimize the model against the new set of perturbed data points to obtain another estimate for each parameter.,"Merge+Modify,Fact/Evidence",Fact/Evidence
6606,2-288,2-288_v2_79@3,2-288_v1_78@4,"3) “Run” Monte Carlo automatically re-optimizes the model against the new set of perturbed data points to obtain another estimate for each parameter, repeating steps 2 and 3 many times (e.g. set it to 1000).",4) Repeat steps 2 and 3 many times (e.g. 1000).,"Merge+Modify,Clarity",Clarity
6607,2-288,2-288_v2_79@4,2-288_v1_78@5,"From these many results, one obtains a histogram of estimates for each optimized parameter, and robust confidence limits can be drawn directly from these histograms without assuming symmetry and linearity as in the Jacobian method.","From these results, one obtains a histogram of estimates for each optimized parameter, and robust confidence limits can be drawn directly from these histograms without assuming symmetry and linearity as in the Jacobian method.","Modify,Clarity",Clarity
6608,2-288,2-288_v2_79@5,2-288_v1_78@6,JSim also displays these results in the form of 2-parameter scatter plots to show covariance.,"JSim displays these histograms to show the distributions of parameter estimates in full detail, and 2-parameter scatter plots to show covariance.","Modify,Fact/Evidence",Fact/Evidence
6609,2-288,2-288_v2_81@3,2-288_v1_80@3,"This feature is based on work by Yngve ( Yngve et al. , 2007 ).","This capability is based on work by Yngve ( Yngve et al. , 2007 ).","Modify,Clarity",Clarity
6610,2-288,2-288_v2_85@0,2-288_v1_84@0,"JSim is implemented in the Java computer language ( Gosling & McGilton, 1996 ).","JSim is implemented in the Java computer language ( Gosling & McGilton, 2003 ).","Modify,Fact/Evidence",Fact/Evidence
6611,2-288,2-288_v2_85@1,2-288_v1_84@1,"The major factors affecting this choice are Java’s platform independent GUI (allowing Windows, Macintosh and Linux versions to be developed in a single code base), object-oriented features and garbage collection (simplifying complex coding), advanced utilities (associative arrays, dynamic linking, remote procedure calls), strong type checking (allowing many common coding errors to be caught at compile time) and robust exception mechanism (simplifying coding and enabling a virtually crash-proof GUI).","The major factors affecting this choice are Java's platform independent GUI (allowing Windows, Macintosh and Linux versions to be developed in a single code base), object-oriented features and garbage collection (simplifying complex coding), advanced utilities (associative arrays, dynamic linking, remote procedure calls), strong type checking (allowing many common coding errors to be caught at compile time) and robust exception mechanism (simplifying coding and enabling a virtually crash-proof GUI).","Modify,Grammar",Grammar
6612,2-288,2-288_v2_86@1,2-288_v1_85@1,"These tools, similar to the classic Unix lex and yacc ( Aho & Sethi, 1988 ), were among the few parser generation tools available for Java when JSim was first developed.","These tools, similar to the classic Unix lex and yacc ( Aho et al. , 1988 ), were among the few parser generation tools available for Java when JSim was first developed.","Modify,Fact/Evidence",Fact/Evidence
6613,2-288,2-288_v2_86@3,2-288_v1_85@3,MML’s declarative structure is an intuitive expression of a model’s underlying mathematics (simplifying the modeler’s learning) and allows the overall structure of the model to be examined for mathematical correctness (detecting overspecification or underspecification) in a way that is not possible with a procedural specification.,MML's declarative structure is an intuitive expression of a model's underlying mathematics (simplifying the modeler’s learning) and allows the overall structure of the model to be examined for mathematical correctness (detecting overspecification or underspecification) in a way that is not possible with a procedural specification.,"Modify,Grammar",Grammar
6614,2-288,2-288_v2_7@4,2-288_v1_7@3,"Standard statistical methods are not central to deciding whether or not to reject the hypothesis, but are indeed helpful in assessing goodness of fit, estimating confidence ranges and co-variances among parameters, and in guiding the investigator in identifying errors or in finding ways to simplify the model.","Standard statistical methods are not central to deciding whether or not to reject the hypothesis, but are indeed very helpful in assessing goodness of fit, estimating confidence ranges and co-variances among parameters, and in guiding the investigator in identifying errors or in finding ways to simplify the model.","Modify,Clarity",Clarity
6615,2-288,2-288_v2_87@4,2-288_v1_86@4,"JSim’s remote computation is implemented using Java Remote Method Invocation (RMI) ( Harold, 1997 ), providing reliable access to networked computational servers.","JSim's remote computation is implemented using Java Remote Method Invocation (RMI) ( Harold, 1997 ), providing reliable access to networked computational servers.","Modify,Grammar",Grammar
6616,2-288,2-288_v2_104@0,2-288_v1_88@0,The all-too-frequent failures to reproduce published results are a critical problem in advancing the biological sciences.,"The issue of reproducibility, or should we say the all-too-frequent failures of attempts to reproduce published results, are beginning to be recognized as a critical problem in advancing the biological sciences.","Modify,Clarity",Clarity
6617,2-288,2-288_v2_104@1,2-288_v1_88@1,"It is easy to understand that biological laboratory studies, with inherently great variability in materials and analysis procedures, should be less exact than those in the physical sciences, but it is not so forgivable that reproducing mathematical models of biological systems is a major problem.","It is easy to understand biological studies, with inherently great variability in materials and analysis procedures, should be less exact than those in the physical sciences, but it is not so forgivable that reproducing mathematical models of biological systems is a major problem.","Modify,Clarity",Clarity
6618,2-288,2-288_v2_104@3,2-288_v1_88@3,"These models all used algebraic, ODEs, or differential-algebraic equations and so must be regarded as relatively simple, computationally, compared to finite-element models or spatially dependent models.","These models all used algebraic, ODEs, or differential-algebraic equations and so must be regarded as relatively simple computationally compared to finite-element models or spatially dependent models.","Modify,Grammar",Grammar
6619,2-288,2-288_v2_105@0,2-288_v1_89@0,Project files as vehicles for reproducible modeling and data analysis,Project files,"Modify,Other",Other
6620,2-288,2-288_v2_106@8,2-288_v1_90@8,"They are editable in any word processor, but one avoids doing that since it is easier to enter code and notes under JSim editor directly and not disturb the format in the XMML file that JSim reads.","They are editable in any word processor, but one avoids doing that since it is easier to enter code and notes under JSim and not risk disturbing the format in the XMML file that JSim reads.","Modify,Clarity",Clarity
6621,2-288,2-288_v2_107@1,2-288_v1_91@1,"Examples are that of Kuikka et al on glucose uptake by myocardium ( Kuikka et al. , 1986 , models 163 and 173), xanthine oxidase reactions ( Bassingthwaighte & Chinn, 2013 , model 324), and lung endothelial serotonin uptake ( Jardine & Bassingthwaighte, 2013 , model 198).","Examples are that of Kuikka et al. on glucose uptake by myocardium ( Kuikka et al. , 1986 ), [models 163 and 173], xanthine oxidase reactions ( Bassingthwaighte & Chinn, 2013 ), [model 324], and lung endothelial serotonin uptake ( Jardine & Bassingthwaighte, 2013 ), [model 198].","Modify,Grammar",Grammar
6622,2-288,2-288_v2_122@3,2-288_v1_96@3,"First, when it only takes a few seconds to modify a model, re-run it, and view the results, researchers are more likely to explore many “what if” scenarios and develop a deeper understanding of model behavior, and in turn, a deeper understanding of the system being modeled.","First, when it only takes a few seconds to tweak a model, re-run it, and view the results, researchers are more likely to explore many “what if” scenarios and develop a deeper understanding of model behavior, and in turn, a deeper understanding of the system being modeled.","Modify,Clarity",Clarity
6623,2-288,2-288_v2_124@0,2-288_v1_98@0,Future developments:,Future developments,"Modify,Grammar",Grammar
6624,2-288,2-288_v2_18@0,2-288_v1_18@0,(7) Explore model behavior over wide ranges of parameter values in state-space. (We think of “state space” as being the N-dimensional space enclosing the ranges of values of all of the parameters within which the model is correct numerically and sensible scientifically).,(7) Explore model behavior over wide ranges of parameter values in state-space. (We think of “state space” as being the N-dimensional space enclosing the ranges of values of all of the parameters within which the model is correct numerically and sensible scientifically.),"Modify,Grammar",Grammar
6625,2-29,2-29_v2_14@0,,Two reports dealt with large paraovarian cysts laparoscopically.,,"Add,Fact/Evidence",Fact/Evidence
6626,2-29,2-29_v2_14@1,,"The first was a simple paraovarian cyst associated with pregnancy which measured 20 cm while the second with acute lower abdominal pain measured 12 cm <REF-10> , <REF-11> .",,"Add,Fact/Evidence",Fact/Evidence
6627,2-29,2-29_v2_14@3,,They reported either cyst aspiration and forceps coagulation of small cysts or cyst wall trocar puncture followed by suction and extraction for large cysts.,,"Add,Fact/Evidence",Fact/Evidence
6628,2-29,2-29_v2_14@6,,It is the authors’ view that laparoscopic cyst decompression before its removal is associated with greater risk of cyst spillage than the technique we describe.,,"Add,Claim",Claim
6629,2-29,,2-29_v1_15@3,,In our case report we had dealt with such a huge cyst in a way not only to avoid morbidity of extending surgical incision but to guard against the risk of spillage of cyst contents as well.,"Delete,Fact/Evidence",Fact/Evidence
6630,2-29,,2-29_v1_15@5,,"However, there were two reports of large paraovarian cysts removed laparoscopically where in the first one, it was associated with acute lower abdominal pain while in the second it was associated with pregnancy <REF-11> , <REF-12> .","Delete,Fact/Evidence",Fact/Evidence
6631,2-29,,2-29_v1_15@6,,"We think that in all these laparoscopically operated cases, the implemented cyst decompression procedure before its removal had less control and precautions during it and in turn more risk of cyst spillage than our mentioned maneuver.","Delete,Claim",Claim
6632,2-29,2-29_v2_4@1,2-29_v1_4@1,Paraovarian cysts constitute 10–20% of all adnexal masses <REF-2> .,"Paraovarian cysts, constitute 10–20% of all adnexal masses <REF-2> .","Modify,Grammar",Grammar
6633,2-29,2-29_v2_4@3,2-29_v1_4@3,"These cysts are usually benign and rarely malignant <REF-4> , <REF-5> .","These cysts are usually benign with rare incidence of malignant types <REF-4> , <REF-5> .","Modify,Clarity",Clarity
6634,2-29,2-29_v2_4@4,2-29_v1_4@4,"In this report, we present how we surgically managed a case with an abnormally huge paraovarian cyst.","Here, we present a case of unusually extensive proportions.","Modify,Fact/Evidence",Fact/Evidence
6635,2-29,2-29_v2_18@0,2-29_v1_7@0,Written informed consent for publication of the clinical details and clinical images was obtained from the patient.,Written informed consent for publication of the clinical details and/or clinical images was obtained from the patient.,"Modify,Clarity",Clarity
6636,2-29,2-29_v2_6@1,2-29_v1_8@1,History revealed a gradual increase of an abdominal swelling over the preceding 6 months.,History revealed a gradual increase in an abdominal swelling over the preceding 6 months.,"Modify,Grammar",Grammar
6637,2-29,2-29_v2_6@2,2-29_v1_8@2,"Physical examination showed a non tender, tense cystic pelvi-abdominal mass of 36 weeks gestational size.",Physical examination showed a non tender tense cystic pelviabdominal mass of 36 weeks gestational size.,"Modify,Grammar",Grammar
6638,2-29,2-29_v2_6@3,2-29_v1_8@3,Computerised tomography revealed a 25 × 26 cm left ovarian simple cyst with clear contents and no septae.,Computerised tomography revealed 25×26 cm left ovarian simple cyst with clear contents and no septae.,"Modify,Grammar",Grammar
6639,2-29,2-29_v2_6@4,2-29_v1_8@4,Serum CA125 level was normal.,Serum CA125 levels were normal.,"Modify,Grammar",Grammar
6640,2-29,2-29_v2_0@0,2-29_v1_0@0,Case Report: Laparoscopic trocar management of a giant paraovarian cyst: a case report,Laparoscopic trocar management of a giant paraovarian cyst: a case report,"Modify,Other",Other
6643,2-29,2-29_v2_6@13,2-29_v1_8@12,"The collapsed cyst was found to be left paraovarian, which was exteriorized and the trocar sleeve was removed.",The collapsed cyst was found to be left paraovarian which was exteriorized and the trocar sleeve was removed.,"Modify,Grammar",Grammar
6644,2-29,2-29_v2_6@15,2-29_v1_8@14,The left broad ligament was opened and the cyst wall was completely removed from the broad ligament ( Figure 1 ).,"The left broad ligament was opened and the cyst wall was completely removed from the broad ligament, Figure 1 .","Modify,Grammar",Grammar
6645,2-29,2-29_v2_6@16,2-29_v1_8@15,The redundant peritoneum of the ligament was excised and subsequently reconstructed with preservation of the tubal integrity as seen in Figure 2 .,The redundant ligament peritoneum was excised and subsequently reconstructed with preservation of the tubal integrity as seen in Figure 2 .,"Modify,Clarity",Clarity
6646,2-29,2-29_v2_13@1,2-29_v1_15@1,We reviewed the English literature and were able to find three reports about the management of comparably huge cysts.,"On revising the literature, there were three case reports which had addressed comparable large paraovarian cysts but with implementation of larger incisions extending over the umbilicus for cyst extraction and excision without a policy to decrease its size before its exteriorization <REF-6> – <REF-8> .","Split+Modify,Clarity",Clarity
6647,2-29,2-29_v2_13@2,2-29_v1_15@1,"In these reports, surgeons utilized abdominal incisions extending over the umbilicus, much larger than the one we used, in order to allow for cyst extraction and excision <REF-6> – <REF-8> .","On revising the literature, there were three case reports which had addressed comparable large paraovarian cysts but with implementation of larger incisions extending over the umbilicus for cyst extraction and excision without a policy to decrease its size before its exteriorization <REF-6> – <REF-8> .","Split+Modify,Fact/Evidence",Fact/Evidence
6648,2-29,2-29_v2_13@3,2-29_v1_15@2,Only one report for three adolescents with large paraovarian cysts (with a range of 20–26 cm) had addressed decompression techniques before cyst exteriorization and excision using a suction cannula <REF-9> .,"However, a case report for three adolescents with large paraovarian cysts had addressed decompression technique before cyst externalization and excision but in a different way <REF-9> .","Modify,Fact/Evidence",Fact/Evidence
6649,2-29,2-29_v2_14@2,2-29_v1_15@4,Darwish et al. reported a series of smaller paraovarian cysts which had been excised laproscopically; the largest was not more than 13 cm <REF-12> .,"Concerning the endoscopic role, Darwish et al. reported a series of paraovarian cysts which had been excised laproscopically but were smaller in size with the largest not more than 13 cm <REF-10> .","Modify,Clarity",Clarity
6650,2-29,2-29_v2_14@4,2-29_v1_15@7,Laparoscopy would have been technically difficult in our case due to the huge size of the cyst reaching close to xiphesternum.,It was thought that laparoscopy would be technically difficult in this case due to huge size of the cyst reaching close to xiphesternum.,"Modify,Clarity",Clarity
6651,2-29,2-29_v2_14@5,2-29_v1_15@8,Direct abdominal entry with a Veress needle or trocar might have traumatized the cyst leading to spillage of its content.,Direct abdominal entry with a Veress needle or trocar may have traumatized the cyst leading to risk of spillage of its content.,"Modify,Grammar",Grammar
6652,2-29,2-29_v2_14@7,2-29_v1_15@9,"We therefore, through laparotomy and a small surgical incision, employed a closed drainage system to safely aspirate the cyst followed by excision.",Through laparotomy we employed a closed drainage system and safely aspirated the cyst without spillage of its content.,"Modify,Fact/Evidence",Fact/Evidence
6653,2-29,2-29_v2_4@0,2-29_v1_4@0,"Paraovarian cysts occur in the broad ligament between the ovary and the tube, predominantly arising from mesothelium covering the peritoneum (mesothelial cyst) but also occasionally arise from the paramesonephric tissue (paramesonephric cysts or Mullerian cysts) and rarely from mesonephric remnants (mesonephric cysts or Wolffian cysts) <REF-1> .","Paraovarian cysts occur in the broad ligament between the ovary and the tube, predominantly arising from mesothelium covering the peritoneum (mesothelial cyst) but occasionally also from para mesonephric tissue (paramesonephric cysts or Mullerian cysts) and rarely from mesonephric remnants (mesonephric cysts or Wolffian cysts) <REF-1> .","Modify,Clarity",Clarity
6654,2-30,2-30_v2_13@2,2-30_v1_13@2,"An example can be seen in Figure 1a) , where logical definitions are used to automatically infer that Hypoglycemia is a subclass of Decreased aldohexose concentration (blood) based on the asserted subclass relationship between 'glucose' and 'aldohexose' in ChEBI.","An example can be seen in Figure 1 a) , where logical definitions are used to automatically infer that Hypoglycemia is a subclass of Decreased aldohexose concentration (blood) based on the asserted subclass relationship between 'glucose' and 'aldohexose' in ChEBI.","Modify,Grammar",Grammar
6655,2-30,2-30_v2_27@4,2-30_v1_27@4,The translation is shown in Manchester syntax in Figure 1a) .,The translation is shown in Manchester syntax in Figure 1 a) .,"Modify,Grammar",Grammar
6656,2-30,2-30_v2_6@4,2-30_v1_6@4,"Similar approaches are being taken in zebrafish ( Danio rerio ) by the Zebrafish Mutation Project (ZMP, http://www.sanger.ac.uk/Projects/D_rerio/zmp/ ) and the data is being made available through the Zebrafish Model Organism Database (ZFIN <REF-5> ).","Similar approaches are being taken in zebrafish ( Danio rerio ) by the Zebrafish Mutation Project (ZMP, http://www.sanger.ac.uk/Projects/D_rerio/zmp/ ) and the data is being made available through the The Zebrafish Model Organism Database (ZFIN <REF-5> ).","Modify,Grammar",Grammar
6657,2-30,2-30_v2_43@0,2-30_v1_43@0,"Here, the GO process eye pigmentation ( GO:0048069 ) is logically defined as being equivalent to everything that is a pigmentation ( GO:0043473 ) and also ""occurs_in"" an eye ( UBERON:0000970 ).","Here, the GO process eye pigmentation ( G0:0048069 ) is logically defined as being equivalent to everything that is a pigmentation ( GO:0043473 ) and also ""occurs_in"" an eye ( UBERON:0000970 ).","Modify,Grammar",Grammar
6658,2-30,2-30_v2_68@0,2-30_v1_68@0,"An excerpt of the Uberpheno ontology is shown in ( Figure 1b ), demonstrating how the phenotype descriptions from different ontologies are combined and automatically organised into a single, integrated hierarchy.","An excerpt of the Uberpheno ontology is shown in ( Figure 1 b ), demonstrating how the phenotype descriptions from different ontologies are combined and automatically organised into a single, integrated hierarchy.","Modify,Grammar",Grammar
6659,2-30,2-30_v2_3@0,2-30_v1_3@0,"We have generated a cross-species phenotype ontology for human, mouse and zebrafish that contains classes from the Human Phenotype Ontology, Mammalian Phenotype Ontology, and generated classes for zebrafish phenotypes.","We have generated a cross-species phenotype ontology for human, mouse and zebra fish that contains zebrafish phenotypes.","Modify,Fact/Evidence",Fact/Evidence
6660,2-57,2-57_v2_24@0,2-57_v1_24@0,Response of cotesia vestalis females to Blend A vs. Blend B,Response of Cotesia vestalis females to Blend A vs. Blend B,"Modify,Grammar",Grammar
6661,2-57,2-57_v2_29@0,2-57_v1_29@0,Response of cotesia vestalis females to Blend A vs. Blend C,Response of Cotesia vestalis females to Blend A vs. Blend C,"Modify,Grammar",Grammar
6662,2-57,2-57_v2_15@2,2-57_v1_15@2,"Next, to test whether female wasps could discriminate the ratios of the four compounds in the blend (quantitative differences in the blend), we prepared a third blend (Blend C) of sabinene, n -heptanal, α -pinene, and ( Z )-3-hexenyl acetate at a ratio of 1.0:1.0:1.0:1.0.","Next, to test whether female wasps could discriminate the ratios of the four compounds in the blend, we prepared a third blend (Blend C) of sabinene, n -heptanal, α -pinene, and ( Z )-3-hexenyl acetate at a ratio of 1.0:1.0:1.0:1.0.","Modify,Clarity",Clarity
6663,2-58,2-58_v2_4@5,,Most relevant to the current paper are the Delboeuf and Ebbinghaus illusions that demonstrate that the size of an inner circle is overestimated or underestimated depending on the surrounding context in which it is presented.,,"Add,Fact/Evidence",Fact/Evidence
6664,2-58,2-58_v2_4@6,,"Though several explanations have been proposed for these illusions, recent research demonstrates that the effect is largely determined by the relative size of the inducer(s), their distance from the target <REF-2> , and in the case of the Ebbinghaus Illusion, the completeness of the surrounding array of elements <REF-8> .",,"Add,Fact/Evidence",Fact/Evidence
6665,2-58,2-58_v2_4@7,,"Taken together, the balance of these factors determines the magnitude of the illusion and whether the inner circle is overestimated or underestimated.",,"Add,Fact/Evidence",Fact/Evidence
6666,2-58,2-58_v2_7@4,,"To our knowledge, previous research on the Ebbinghaus Illusion has focused on the effect the surrounding elements have on the explicitly defined circle.",,"Add,Claim",Claim
6667,2-58,2-58_v2_7@5,,Here we consider the possibility of mutual influence in that the inner circle may also lead to misperceived size of the surrounding array.,,"Add,Claim",Claim
6668,2-58,2-58_v2_45@2,,"Specifically, differential effects can be obtained resulting in changes to the magnitude of the illusions depending on spatial frequency filtering.",,"Add,Fact/Evidence",Fact/Evidence
6669,2-58,2-58_v2_68@4,,This stands in contrast to several recent findings using functional and structural MRI that have implicated visual areas as early as V1 as playing a key role in the representation of perceived size <REF-31> – <REF-33> .,,"Add,Fact/Evidence",Fact/Evidence
6670,2-58,2-58_v2_68@5,,"Given the classical receptive field properties of V1 neurons, it is likely that these observations arise due to feedback to V1 from higher visual areas, that in the case of the Binding Ring Illusion may contain integrated representations of spatial frequency.",,"Add,Claim",Claim
6671,2-58,2-58_v2_68@6,,This is in line with recent research on the Müller-Lyer Illusion using dynamic causal modelling <REF-34> .,,"Add,Fact/Evidence",Fact/Evidence
6672,2-58,2-58_v2_68@7,,It was demonstrated that illusion strength could be predicted by modulating bilateral connections between the lateral occipital cortex (LOC) and right superior parietal cortex (SPC).,,"Add,Fact/Evidence",Fact/Evidence
6673,2-58,2-58_v2_68@8,,The model suggests that LOC is involved in size scaling to generate size invariant object representations that are further processed in SPC and relayed back to V1 to generate conscious illusory percepts.,,"Add,Claim",Claim
6674,2-58,2-58_v2_38@0,2-58_v1_38@0,"A) The size of the binding ring had a significant influence on the perceived size of the array (main effect of binding ring size-repeated measures ANOVA: F (4, 36) = 31.22, p < 0.001).","A) The size of the binding ring had a significant influence on the perceived size of the array (main effect of binding ring size - repeated measures ANOVA: F (4, 36) = 31.22, p < 0.001).","Modify,Grammar",Grammar
6675,2-58,2-58_v2_45@1,2-58_v1_45@1,"It is suggested that some visual illusions, including the Müller-Lyer <REF-19> and Oppel-Kundt <REF-20> , <REF-21> or filled area illusion <REF-22> , are mediated by differential processing of low- and high-spatial frequency information <REF-23> – <REF-27> .","It is suggested that some visual illusions, including the the Müller-Lyer <REF-17> , are mediated by differential processing of low- and high-spatial frequency information <REF-18> – <REF-22> .","Modify,Fact/Evidence",Fact/Evidence
6676,2-58,2-58_v2_4@3,2-58_v1_4@3,"These constructive processes are revealed through a number of classic size illusions such as the Ebbinghaus Illusion <REF-4> ( Figure 1A ), the Delboeuf Illusion <REF-5> , <REF-6> ( Figure 1B ), the Müller-Lyer Illusion <REF-7> ( Figure 1C ) and several others that illustrate how mechanisms that underlie size constancy sometimes lead to illusory percepts resulting from a discrepancy between retinal and perceived size.","These constructive processes are revealed through a number of classic size illusions such as the Ebbinghaus Illusion <REF-4> ( Figure 1A ) and the Delboeuf Illusion <REF-5> , <REF-6> ( Figure 1B ).","Modify,Fact/Evidence",Fact/Evidence
6677,2-58,2-58_v2_4@4,2-58_v1_4@4,"In each of these illusions, the perceived size of an explicitly defined object is influenced by the context in which it is presented.","In each of these illusions, the perceived size of an explicitly defined object (the inner circle) is influenced by the context in which it is presented.","Modify,Clarity",Clarity
6678,2-58,2-58_v2_52@0,2-58_v1_52@0,Experiment 4a,Experiment 4,"Modify,Other",Other
6679,2-58,2-58_v2_53@1,2-58_v1_53@1,"A number of visual illusions can be attributed to the processes of local configural features <REF-3> , <REF-8> , <REF-28> .",A number of visual illusions can be attributed to the processes of local configural features <REF-23> .,"Modify,Fact/Evidence",Fact/Evidence
6680,2-58,2-58_v2_19@2,2-58_v1_19@2,"Participants indicated by pressing one of two buttons (two-alternative forced choice), which of the two stimuli had appeared larger.","Participants indicated by pressing one of two buttons (two-alternative forced choice; AFC), which of the two stimuli had appeared larger.","Modify,Clarity",Clarity
6681,2-9,2-9_v2_52@1,,"However, in our model the local host adipocytes responded to the tumor implantation with the lipogenic rather than the erythrogenic autophagy.",,"Add,Fact/Evidence",Fact/Evidence
6682,2-9,2-9_v2_52@2,,The entire cells were converted into lipid droplets.,,"Add,Fact/Evidence",Fact/Evidence
6683,2-9,2-9_v2_52@3,,"If the tumor cells could be treated to re-direct their metabolism to lipogenesis instead of erythrogenesis, perhaps the metastatic potential of the capsular vaso-mimicry could be abolished and ultimately the entire tumor replaced with fat.",,"Add,Claim",Claim
6684,2-9,2-9_v2_52@4,,"A non-malignant type of undifferentiated cells, human mesenchymal stem cells, can accumulate lipid under hypoxia, although normally they would differentiate along several pathways to form bone, cartilage, tendon, muscle or adipose tissues.",,"Add,Claim",Claim
6685,2-9,2-9_v2_52@5,,In that case the potent lipogenic effect of hypoxia was independent of PPAR-γ2 maturation pathway <REF-80> .,,"Add,Fact/Evidence",Fact/Evidence
6686,2-9,,2-9_v1_41@1,,The ability of cells to undergo such nucleo-cytoplasmic conversion was not tumor-specific.,"Delete,Claim",Claim
6687,2-9,2-9_v2_15@2,,The mice were on Tekand global 14% protein rodent diet (Harlan) with access to water ad libitum.,,"Add,Fact/Evidence",Fact/Evidence
6688,2-9,2-9_v2_24@1,,Analyzed tissue sections were first examined at low magnification and coordinates for each hexagonal sector of a grid covered with tissue were recorded automatically.,,"Add,Fact/Evidence",Fact/Evidence
6689,2-9,2-9_v2_24@2,,Subsequently all sectors were explored at least once at variable high magnifications.,,"Add,Fact/Evidence",Fact/Evidence
6690,2-9,2-9_v2_24@3,,"Interesting images were captured at the magnification best suited to document a particular phenomenon or identify a structure, including colloidal Au grains.",,"Add,Fact/Evidence",Fact/Evidence
6691,2-9,2-9_v2_24@5,,In some cases the final images were assembled by multiple image alignment (MIA) to increase the surface area without losing the resolution.,,"Add,Fact/Evidence",Fact/Evidence
6692,2-9,2-9_v2_38@0,,At the time of tissue harvest the histomorphological features of the transplanted tumor spheroids resembled those of spontaneously grown tumors ( Figure 5 ).,,"Add,Fact/Evidence",Fact/Evidence
6693,2-9,2-9_v2_38@1,,"The malignant cells were arranged into small nodules surrounded with fibroblasts, vessel-free erythrosomes and some undifferentiated migrating cells (mesenchymal cells).",,"Add,Fact/Evidence",Fact/Evidence
6694,2-9,2-9_v2_38@2,,The nodules were not larger than the oxygen diffusion range (100–200 µm <REF-58> ).,,"Add,Fact/Evidence",Fact/Evidence
6695,2-9,2-9_v2_38@3,,A thicker fibrotic capsule surrounded the larger clusters of the small nodules.,,"Add,Fact/Evidence",Fact/Evidence
6696,2-9,2-9_v2_38@4,,The underlying host muscle cells appeared normal whereas adipocytes were commonly replaced with lipid droplets.,,"Add,Fact/Evidence",Fact/Evidence
6697,2-9,2-9_v2_11@0,2-9_v1_12@0,Two recipient mice of the 5 used in the two accompanying articles were assessed in this experiment.,Two recipient mice of the 5 used in the two accompanying articles were assessed in this report.,"Modify,Clarity",Clarity
6698,2-9,2-9_v2_15@1,2-9_v1_16@1,They were housed in the SKCC animal care facilitywith controlled 12/12 hr light/dark cycle and temperature maintained at + 22°C.,The mice were housed in the SKCC animal care facility.,"Modify,Fact/Evidence",Fact/Evidence
6699,2-9,2-9_v2_16@1,2-9_v1_17@1,J. Lustgarten and P. Borgstrom and used to form tumor spheroids by culturing 2×10 5 cells per well for 2–3 days prior to implantation.,J. Lustgarten and P. Borgstrom and used to form tumor spheroids by culturing 2 × 10 5 cells per well for 2–3 days prior to implantation.,"Modify,Grammar",Grammar
6700,2-9,2-9_v2_16@4,2-9_v1_17@4,"Their final size was about 1–3 mm in ""diameter'.",Their final size was about 1–3 mm in diameter.,"Modify,Grammar",Grammar
6701,2-9,2-9_v2_16@5,2-9_v1_17@5,The GFP-specific rabbit polyclonal IgG (ab290) was from Abcam; and non-reactive IgG (sc-34284) were from Santa Cruz.,The GFP-specific rabbit polyclonal IgG (ab290) was from Abcam; and non-reactive goat polyclonal IgG (sc-34284) were from Santa Cruz.,"Modify,Fact/Evidence",Fact/Evidence
6702,2-9,2-9_v2_18@0,2-9_v1_19@0,The tumors with some surrounding tissues were dissected out and cut in halves perpendicularly to the host skin surface while immersed in cold fixative (4% paraformaldehyde in 0.1 M Na cacodylate pH 7.4).,The tumors with some surrounding tissues were dissected out and cut in halves perpendicular to the host skin surface while immersed in cold fixative (4% paraformaldehyde in 0.1 M Na cacodylate pH 7.4).,"Modify,Grammar",Grammar
6703,2-9,2-9_v2_20@1,2-9_v1_21@1,"They were cut into 1 mm thick slices in planes perpendicular to the plain of the first cut and to the skin surface, finally, into ~ 1 mm 3 blocks, transferred into fresh portion of the fixative in which they were cut and incubated for 2 hrs at 4°C.","They were cut into 1 mm thick slices in planes perpendicular to the plain of the first cut and to the skin surface, finally, into ~ 1 mm 3 blocks, transferred into a fresh portion of the fixative in which they were cut and incubated for 2 hrs at 4°C.","Modify,Grammar",Grammar
6704,2-9,2-9_v2_20@2,2-9_v1_21@2,"The fixed tissue blocks were washed with 0.1 M Na cacodylate–HCl buffer pH 7.4 (3 × 15 min.) and post fixed in 1% OsO 4 in 0.1 M Na cacodylate buffer, pH 7.0 for 60 min on ice, washed with water and stained with 1% uranyl acetate at RT for one hour.","The fixed tissue blocks were washed with 0.1 M Na cacodylate – HCl buffer pH 7.4 (3 × 15 min) and post fixed in 1% OsO 4 in 0.1 M Na cacodylate buffer, pH 7.0 for 60 min. on ice, washed with water and stained with 1% uranyl acetate at RT for one hour.","Modify,Grammar",Grammar
6705,2-9,2-9_v2_20@4,2-9_v1_21@4,The resin embedded tissues were cut into 60 nm sections on Leica Ultracut UCT ultramicrotome and viewed without further contrasting.,"The resin-embedded tissues were cut into 60 nm sections, on a Leica Ultracut UCT ultramicrotome and stained with lead citrate <REF-42> or viewed without further contrasting.","Modify,Fact/Evidence",Fact/Evidence
6706,2-9,2-9_v2_22@0,2-9_v1_23@0,"During cutting into ~ 1 mm 3 blocks as described above, the tissues were kept in the mild fixative to protect the antigenic epitopes (4% paraformaldehyde in 0.1 M Na cacodylate pH 7.4).","During cutting into ~ 1 mm 3 blocks as described above, the tissues were kept in the mild fixative to protect the antigenic epitops (4% paraformaldehyde in 0.1 M Na cacodylate pH 7.4).","Modify,Grammar",Grammar
6707,2-9,2-9_v2_22@1,2-9_v1_23@1,"The tissue blocks were vitrified by infiltrating the pieces with 50% PVP (polyvinylpyrrolidone) containing 2.3 M sucrose in 0.1 M Na cacodylate buffer, pH 7.4, for 2 hrs or over night, mounted on metal pins and frozen in liquid nitrogen, as described by Tokuyasu <REF-47> .","The tissue blocks were vitrified by infiltrating the pieces with 50% PVP (polyvinylpyrrolidone) containing 2.3 M sucrose in 0.1 M Na-cacodylate buffer, pH 7.4, for 2 hrs or overnight, mounted on metal pins and frozen in liquid nitrogen, as described by Tokuyasu <REF-43> .","Modify,Grammar",Grammar
6708,2-9,2-9_v2_22@2,2-9_v1_23@2,"Frozen tissues were cut into 70 nm sections, on Leica Ultracut UCT ultramicrotome with the cryo-attachment.","Frozen tissues were cut into 70 nm sections, on a Leica Ultracut UCT ultramicrotome with the cryo-attachment.","Modify,Grammar",Grammar
6709,2-9,2-9_v2_22@6,2-9_v1_23@6,"After rinsing three times with water the immunostained cryosections were contrasted with mixture of uranyl acetate and methyl cellulose (25 centipoises, Sigma M-6385) in water, at final concentration of 1.3% each, for 10 min at RT.","After rinsing three times with water, the immunostained cryosections were contrasted with a mixture of uranyl acetate and methyl cellulose (25 centipoises, Sigma M-6385) in water, at final concentration of 1.3% each, for 10 min at RT.","Modify,Grammar",Grammar
6710,2-9,2-9_v2_22@7,2-9_v1_23@7,Excess of the liquid was removed and the sections were dried at RT.,Excess liquid was removed and the sections were dried at RT.,"Modify,Clarity",Clarity
6711,2-9,2-9_v2_24@4,2-9_v1_25@1,The images were transmitted from the microscope camera to iTEM imaging platform from Olympus Soft Imaging Solutions and archived in a designated Data Base.,Images were transmitted from the microscope camera to an iTEM imaging platform from Olympus Soft Imaging Solutions and archived in a designated database.,"Modify,Grammar",Grammar
6712,2-9,2-9_v2_24@6,2-9_v1_25@2,"We used graphics editing program, Adobe PhotoShop, to add cell type specific color-coding shown in the twin set of images included in the Supplement.","We used the graphics editing program, Adobe PhotoShop, to add cell type-specific color-coding shown in the twin set of images included in the Supplement.","Modify,Grammar",Grammar
6713,2-9,2-9_v2_26@0,2-9_v1_27@0,"Three weeks after the ectopic implantation of tumor spheroids, the vasculature formation, i.e., formation of tumor-supporting blood and vessels, was evidently retarded in comparison to pseudo-orthotopically implanted tumors described elsewhere <REF-41> .","Three weeks after the ectopic implantation of tumor spheroids, the vasculature formation, i.e., formation of tumor-supporting blood and vessels was evidently retarded in comparison to pseudo-orthotopicly implanted tumors described elsewhere <REF-36> .","Modify,Grammar",Grammar
6714,2-9,2-9_v2_26@2,2-9_v1_27@2,"A multi-cellular layer of connective tissue was growing between tumor and glass wall of the chamber, therefore, it was also generating its own vasculature ([A] in Figure 1 & Figure S1 ).","A multi-cellular layer of connective tissue was growing between the tumor and the glass wall of the chamber, therefore, it was also generating its own vasculature ([A] in Figure 1 & Figure S1 ).","Modify,Grammar",Grammar
6715,2-9,2-9_v2_26@3,2-9_v1_27@3,"Here, the term ""vasculature"" includes vessels and blood, and the term ""erythrosome"" is used as synonym for the ""erythrocyte"", because the latter is not a cell <REF-41> .","Here, the term ""vasculature"" includes vessels and blood and ""erythrosome"" is used as a synonym for the ""erythrocyte"", because the latter is not a cell <REF-36> .","Modify,Clarity",Clarity
6716,2-9,2-9_v2_26@7,2-9_v1_27@7,"Outside the tumor capsule, a primitive forming vessel morphologically resembled some of those seen around pseudo-orthotopically implanted tumors after only five days ([D] in Figure 1 & Figure S1 ).","Outside the tumor capsule, a primitive forming vessel morphologically resembled some of those seen around pseudo-orthotopicly implanted tumors after only five days ([D] in Figure 1 & Figure S1 ).","Modify,Grammar",Grammar
6717,2-9,2-9_v2_26@12,2-9_v1_27@12,Yet some tumor cells (CSCs?) began regenerating their vasculogenic potential that had been dormant during the years of in vitro culturing ([F & G] in Figure 1 & Figure S1 ).,Some tumor cells (CSCs?) did however begin regenerating their vasculogenic potential that had been dormant during the years of in vitro culturing ([F & G] in Figure 1 & Figure S1 ).,"Modify,Clarity",Clarity
6718,2-9,2-9_v2_26@14,2-9_v1_27@14,"Until that time, some tumor cells survived at the expense of the others.","Until that time, some tumor cells survived at the expense of others.","Modify,Grammar",Grammar
6719,2-9,2-9_v2_29@1,2-9_v1_30@1,In some locations hypoxic tumor nodules were breaking apart via prominent anoikis (loss of attachment between cells <REF-48> ) with abundant nano-tentacles.,"In some locations, hypoxic tumor nodules were breaking apart via prominent anoikis (loss of attachment between cells <REF-44> ) with abundant nano-tentacles ([A–C] in Figure 2 & Figure S2 ).","Modify,Fact/Evidence",Fact/Evidence
6720,2-9,2-9_v2_29@3,2-9_v1_30@3,They were either losing their internal cristae without shrinking and thus generating electron lucent vacuoles (seemingly empty or containing whorled membranes that might be intermediate stages of the internal membranes degradation) or becoming smaller and electron dense ([A–C] in Figure 2 & Figure S2 ).,They were either loosing their internal cristae without shrinking and thus generating electron-lucent vacuoles (seemingly empty or containing whorled membranes that might be intermediate stages of the internal membranes degradation) or becoming smaller and electron dense.,"Modify,Fact/Evidence",Fact/Evidence
6721,2-9,2-9_v2_29@5,2-9_v1_30@5,"The second type at first resembled appearance of mitochondria during mitosis and later, they were indistinguishable from the dark granules in erythroblasts ([D & F] in Figure 2 & Figure S2 ) and consistent with published images of peroxisomes <REF-50> – <REF-53> .","The second type at first resembled the appearance of mitochondria during mitosis and later, they were indistinguishable from the dark granules in erythroblasts ([D–F] in Figure 2 & Figure S2 ) and consistent with published images of peroxisomes <REF-46> – <REF-49> .","Modify,Grammar",Grammar
6722,2-9,2-9_v2_29@8,2-9_v1_30@8,That is because erythrosomes are capable of secreting anaerobically generated ATP <REF-54> .,That is because erythrosomes are capable of secreting anaerobicly generated ATP <REF-50> .,"Modify,Grammar",Grammar
6723,2-9,2-9_v2_29@10,2-9_v1_30@10,"Initially, electron dense regions of tumor cell nucleus contained chromatin in both cases.","Initially, electron-dense regions of the tumor cell nucleus contained chromatin in both cases.","Modify,Grammar",Grammar
6724,2-9,2-9_v2_29@14,2-9_v1_30@17,"The GFP-labeled mitotic chromosomes identified the tumor cell whereas the unlabeled fibroblast, on the other side of the collagen layer separating the two, must have been of host origin ([F] in Figure 2 & Figure S2 ).","The GFP-labeled mitotic chromosomes identified the tumor cell whereas the unlabeled fibroblast, on the other side of collagen layer separating the two, must have been of host origin ([F] in Figure 2 & Figure S2 ).","Modify,Grammar",Grammar
6725,2-9,2-9_v2_29@15,2-9_v1_30@18,"Together, the host fibroblasts and the encapsulated tumor-derived blood elements created the capsular vaso-mimicry that morphologically resembled veins ([G-I] in Figure 1 & Figure S1 ).","Together, the host fibroblasts and the encapsulated tumor-derived blood elements created the capsular vaso-mimicry that morphologically resembled veins ([G–I] in Figure 1 & Figure S1 ).","Modify,Grammar",Grammar
6726,2-9,2-9_v2_0@0,2-9_v1_0@0,II. Capsular vaso-mimicry formed by transgenic mammary tumor spheroids implanted ectopically into mouse dorsal skin fold: implications for cellular mechanisms of metastasis,II. Capsular vaso-mimicry formed by transgenic mammary tumor spheroids implanted ectopically into mouse dorsal skin fold: cellular mechanisms of metastasis,"Modify,Clarity",Clarity
6727,2-9,2-9_v2_32@3,2-9_v1_33@3,"The elongated cells like the one shown between the tumor nodules ( Figure 3 & Figure S3 ) had large nuclei undergoing conversion into erythrosomes and sparse, metabolically active cytoplasm generating energy and synthesizing protein.","The elongated cells like the one shown between the tumor nodules ( Figure 3 & Figure S3 ) had large nuclei undergoing conversion into erythrosomes and a sparse, metabolically active cytoplasm generating energy and synthesizing protein.","Modify,Grammar",Grammar
6728,2-9,2-9_v2_32@4,2-9_v1_33@4,"What appeared in two-dimensional image as a single file of erythrosomes between tumor nodules was not ""a rouleau of circulating erythrocytes"" <REF-18> .",What appeared in the two-dimensional image as a single file of erythrosomes between the tumor nodules was not a rouleau of circulating erythrocytes.,"Modify,Fact/Evidence",Fact/Evidence
6729,2-9,2-9_v2_35@2,2-9_v1_36@2,In some regions ECs converting into erythrosomes (hemogenic endothelium) were also seen (Figure 2 in <REF-57> ).,"In some regions, ECs converting into erythrosomes (hemogenic endothelium) were also seen (Figure 8 in <REF-54> ).","Modify,Grammar",Grammar
6730,2-9,2-9_v2_43@0,2-9_v1_41@0,Survival of the ectopically implanted breast tumor cells for three weeks without support of host circulatory system was possible due to the erythrogenic autophagy <REF-41> .,Survival of the ectopically implanted breast tumor cells for three weeks without the support of a host circulatory system was possible due to the erythrogenic autophagy <REF-36> .,"Modify,Grammar",Grammar
6731,2-9,2-9_v2_43@4,2-9_v1_42@3,"Non-vasculogenic tumors do not grow over several weeks although the tumor cells keep proliferating at rate similar to that of vasculogenic tumors; ""They have no or non-functional vessels"" <REF-59> .","Non-vasculogenic tumors do not grow over several weeks although the tumor cells keep proliferating at a rate similar to that of vasculogenic tumors; ""They have no or non-functional vessels"" <REF-55> .","Modify,Grammar",Grammar
6732,2-9,2-9_v2_43@6,2-9_v1_42@5,"That was, in fact, another experimental result demonstrating that some tumor cells could survive at the expense of the others.","That was, in fact, an experimental result demonstrating that some tumor cells could survive at the expense of others.","Modify,Clarity",Clarity
6733,2-9,2-9_v2_52@0,2-9_v1_42@6,The postnatal extramedullar erythropoiesis at the location other than bone marrow ( medulla ossea ) was observed previously in spleen <REF-75> – <REF-78> and adipocytic tissues <REF-79> .,Such postnatal extramedullar erythropoiesis at a location other than the bone marrow ( medulla ossea ) was not unprecedented; spleen <REF-56> – <REF-59> and adipocytic tissues <REF-60> have that potential as well.,"Modify,Clarity",Clarity
6734,2-9,2-9_v2_44@0,2-9_v1_43@0,The relevance of the variable metabolism within a single tumor nodule was that tumor derived erythrosomes might indeed extend viability of adjacent tumor cells by supplying them with vital energy in absence of vasculature.,The relevance of the variable metabolism within a single tumor nodule was that tumor-derived erythrosomes might indeed extend viability of adjacent tumor cells by supplying them with vital energy in the absence of vasculature.,"Modify,Grammar",Grammar
6735,2-9,2-9_v2_44@4,2-9_v1_43@1,"Hemoglobin has evolved to bind oxygen cooperatively, i.e., most efficiently when it is abundant (in lungs where the oxygen concentration is about 100 torr) and gradually less and less efficiently as erythrosomes move through arteries and veins (in peripheral tissues the oxygen concentration is about 20 torr) <REF-61> .","Hemoglobin has evolved to bind oxygen cooperatively, i.e., most efficiently when it is abundant (in lungs where the oxygen concentration is about 100 torr) and gradually less and less efficiently as erythrosomes move through arteries and veins (in peripheral tissues, the oxygen concentration is about 20 torr) <REF-61> .","Modify,Grammar",Grammar
6736,2-9,2-9_v2_5@1,2-9_v1_5@1,"A developmental regulatory program involved in embryo implantation, referred to as the ""epithelial-mesenchymal transition"" (EMT) <REF-1> – <REF-4> was adopted to explain how transformed epithelial cells could acquire ability to metastasize, i.e., to invade surrounding nonmalignant tissues and to disseminate, in a multistep process including entering and leaving the circulatory system <REF-5> , <REF-6> .","A developmental regulatory program involved in embryo implantation, referred to as the ""epithelial-mesenchymal transition"" (EMT) <REF-1> – <REF-4> was adopted to explain how transformed epithelial cells could acquire the ability to metastasize, i.e., to invade surrounding nonmalignant tissues and to disseminate, in a multistep process including entering and leaving the circulatory system <REF-5> , <REF-6> .","Modify,Grammar",Grammar
6737,2-9,2-9_v2_45@4,2-9_v1_44@0,The potential to convert into erythrosomes was not limited to erythropoietic lineage derived from myeloid precursors.,The ability to convert into erythrosomes was not limited to erythropoietic lineage derived from myeloid precursors.,"Modify,Clarity",Clarity
6738,2-9,2-9_v2_45@5,2-9_v1_44@1,"Understandably so, given that the inducing factor, hypoxia, affected the most fundamental function of living cells, i.e., the respiration, generating vital energy aerobically.","Understandably so, because the inducing factor, hypoxia, affected the most fundamental function of all living cells, i.e., the respiration, generating vital energy aerobically.","Modify,Clarity",Clarity
6739,2-9,2-9_v2_45@7,2-9_v1_44@3,That metabolic requirement being shared by all cells experiencing hypoxia imposed formation of similar ultrastructural features on all of them (convergence).,That metabolic pathway being shared by all cells experiencing hypoxia imposed the formation of similar ultrastructural features on all of them (convergence).,"Modify,Clarity",Clarity
6740,2-9,2-9_v2_47@3,2-9_v1_46@3,"In other words, the heterologous environment did not kill the transplanted tumor but gradually the exogenous tissue acquired the ability to engage in the paracrine dialog with local TSCs, (perhaps by acquiring proper cell adhesion molecules <REF-62> ) or the tumor activated its own SCs (CSCs).","In other words, the heterologous environment did not kill the transplanted tumor but gradually the exogenous tissue acquired the ability to engage in the paracrine dialog with local TSCs (perhaps by acquiring proper cell adhesion molecules <REF-62> ), or the tumor activated its own SCs (CSCs).","Modify,Grammar",Grammar
6741,2-9,2-9_v2_47@4,2-9_v1_46@4,"Trans-differentiation of tumor SCs into ECs was observed here and also reported earlier in glioblastoma <REF-14> , <REF-63> – <REF-65> .",Trans-differentiation of tumor SCs into ECs was also reported earlier in glioblastoma <REF-63> – <REF-66> .,"Modify,Fact/Evidence",Fact/Evidence
6742,2-9,2-9_v2_47@7,2-9_v1_46@7,"Reported dormant tumors had < 1 mm “diameter”, possibly including fibroblastic coats and necrotic centers <REF-66> .","Reported dormant tumors had < 1 mm diameter, possibly including fibroblastic coats and necrotic centers <REF-67> .","Modify,Grammar",Grammar
6743,2-9,2-9_v2_48@0,2-9_v1_47@0,Capsular vaso-mimicry as cellular mechanism of metastasis,Capsular vaso-mimicry as a cellular mechanism of metastasis,"Modify,Grammar",Grammar
6744,2-9,2-9_v2_49@0,2-9_v1_48@0,"Two cellular mechanisms normally beneficial to the organism when acting independently, one involved in tissue nourishing and the other in healing, i.e., erythrogenesis and scar formation (or foreign body encapsulation <REF-55> ) respectively, became deleterious by creating the capsular vaso-mimicry when they coincided in the ectopically implanted tumor.","Two cellular mechanisms normally beneficial to the organism when acting independently, one involved in tissue nourishment and the other in healing, i.e., erythrogenesis and scar formation (or foreign body encapsulation) respectively, became deleterious by creating the capsular vaso-mimicry when they coincided in the ectopically implanted tumor.","Modify,Fact/Evidence",Fact/Evidence
6745,2-9,2-9_v2_49@8,2-9_v1_48@8,"At the same time, the loss of attachment to other cells could facilitate their dissemination by breaking tumor tissue into small cell clusters or single cells that could be carried away by blood flow.","At the same time, the loss of attachment to other cells could facilitate their dissemination by breaking the tumor tissue into small cell clusters or single cells that could be carried away by blood flow.","Modify,Grammar",Grammar
6746,2-9,2-9_v2_5@2,2-9_v1_5@2,"However, no satisfactory mechanism for the spreading of non-epithelial tumors to secondary locations was proposed.","However, no satisfactory mechanism for the spread of non-epithelial tumors to secondary locations was proposed.","Modify,Grammar",Grammar
6747,2-9,2-9_v2_50@2,2-9_v1_49@2,"Clusters of the primary tumor cells could be passively carried to different tissues by blood flow and become immobilized when they reached vessels narrower than their own dimensions, in a tissue non-specific manner.","Clusters of primary tumor cells could be passively carried to different tissues by blood flow and become immobilized when they reached vessels narrower than their own dimensions, in a tissue non-specific manner.","Modify,Grammar",Grammar
6748,2-9,2-9_v2_50@5,2-9_v1_49@5,"Liver being formed relatively early during embryogenesis and later maintaining primitive vasculature might be most compatible with tumors for that reason and therefore most prone to metastases, as observed clinically and shown experimentally <REF-70> .","Liver being formed relatively early during embryogenesis and later maintaining primitive vasculature might be most compatible with tumors for that reason and therefore most prone to metastases, as observed clinically.","Modify,Fact/Evidence",Fact/Evidence
6749,2-9,2-9_v2_5@3,2-9_v1_5@3,"Therefore, an alternative to EMT regulatory programs playing a role in invasiveness of carcinoma cells should also be considered, as pointed out elsewhere <REF-7> .","Therefore, an alternative to EMT regulatory programs playing a role in invasiveness of carcinoma cells should be considered, as pointed out elsewhere <REF-7> .","Modify,Clarity",Clarity
6750,2-9,2-9_v2_51@4,2-9_v1_49@12,That is how anatomically distant but phenotypically compatible tissue could become activated by the tumor before metastasizing cells got there.,That is how anatomically distant but phenotypicly compatible tissue could become activated by the tumor before metastasizing cells got there.,"Modify,Grammar",Grammar
6751,2-9,2-9_v2_54@1,2-9_v1_51@1,"The remnants of cells that produced erythrosomes could be responsible for PAS staining due to their glyco-lipid components and, more importantly, for fusion with capillaries of main circulatory system, at stages later than analyzed here.","The remnants of cells that produced erythrosomes could be responsible for PAS staining due to their glyco-lipid components and, more importantly, for fusion with capillaries of the main circulatory system, at stages later than analyzed here.","Modify,Grammar",Grammar
6752,2-9,2-9_v2_6@0,2-9_v1_6@0,"Attempts made to elucidate the cellular mechanism of metastasis-initiating events included retrospective extrapolation from the distribution of established metastases, namely the preference of specific tumors to metastasize in certain organs but not in others.","Attempts made to elucidate the cellular mechanism of metastasis-initiating events have included retrospective extrapolation from the distribution of established metastases, namely the preference of specific tumors to metastasize in certain organs but not in others.","Modify,Grammar",Grammar
6753,2-9,2-9_v2_54@2,2-9_v1_51@2,"Our tumors were significantly smaller (""diameter"" of < 1 mm) than those described in the literature (1 cm or more).",Our tumors were significantly smaller (diameter of < 1 mm) than those described in the literature (1 cm or more).,"Modify,Grammar",Grammar
6754,2-9,2-9_v2_54@3,2-9_v1_51@3,Lack of hierarchy in the network pattern of the aggressive tumors suggested a lack of blood circulation.,A lack of hierarchy in the network pattern of the aggressive tumors suggested a lack of blood circulation.,"Modify,Grammar",Grammar
6755,2-9,2-9_v2_54@6,2-9_v1_51@6,"Therefore, that kind of mimicry is probably a form of erythrogenic autophagy of fibroblasts associated with the presence of metastatic tumors.","Therefore, that kind of mimicry probably is a form of fibroblastic autophagy associated with the presence of metastatic tumors.","Modify,Claim",Claim
6756,2-9,2-9_v2_58@5,2-9_v1_53@4,"Shunting of inspired oxygen into tumor venules, presumed to occur due to arterio-venous anastomoses (Figure 10 in <REF-83> ) could alternatively be explained by stable saturation of hemoglobin located in non-circulating erythrosomes within tumor capsule as well as within the regions mimicking vessels ( Figure 1 & Figure S1 ).","Shunting of inspired oxygen into tumor venules, presumed to occur due to arterio-venous anastomoses (Figure 10 in <REF-76> ) could alternatively be explained by stable saturation of hemoglobin located in non-circulating erythrosomes within the tumor capsule, as well as within the regions mimicking vessels ( Figure 1 & Figure S1 ).","Modify,Grammar",Grammar
6757,2-9,2-9_v2_58@10,2-9_v1_53@9,"Consequently, it should not be surprising that increased oxygenation of breast adenocarcinoma by treatment with, for example, darbepoetin alpha, had no desirable effect on the tumor’s responsiveness to radiotherapy <REF-86> .","Consequently, it shouldn’t be surprising that increased oxygenation of breast adenocarcinoma by treatment with, for example, darbepoetin alpha, had no desirable effect on the tumor’s responsiveness to radiotherapy <REF-79> .","Modify,Grammar",Grammar
6758,2-9,2-9_v2_56@0,2-9_v1_55@0,"The distance between capillaries in tissue sections suggested that, within the 100–200 µm zones, cell membranes did not present a barrier for diffusion of nutrients as well as oxygen.","The distance between capillaries in tissue sections suggested that, within the 100–200 µm zones, cell membranes did not present a barrier for diffusion of nutrients or for oxygen.","Modify,Clarity",Clarity
6759,2-9,2-9_v2_56@4,2-9_v1_55@4,"Considering what we now know about cytoevolution leading to ECs differentiation <REF-41> , one could make a premise that luminal surface of the polarized endothelial cell was a functional equivalent of the inner membrane.","Considering what we now know about cytoevolution leading to ECs differentiation <REF-36> , one could make a premise that the luminal surface of the polarized endothelial cell was a functional equivalent of the inner membrane.","Modify,Grammar",Grammar
6760,2-9,2-9_v2_56@8,2-9_v1_55@8,Vascular lumen in that context would be a functional equivalent of intracellular vesicle.,Vascular lumen in that context would be a functional equivalent of an intracellular vesicle.,"Modify,Grammar",Grammar
6761,2-9,2-9_v2_56@9,2-9_v1_55@9,One could conclude that host fibroblasts encapsulating the tumor and creating the capsular vaso-mimicry by positioning themselves around erythrosomes should not present a barrier for the diffusion process because they did not go through the process of cytoevolution resulting in polarization of outer cell membrane into luminal and abluminal.,One could conclude that host fibroblasts encapsulating the tumor and creating the capsular vaso-mimicry by positioning themselves around erythrosomes should not present a barrier for the diffusion process because they did not go through the process of cytoevolution resulting in polarization of the outer cell membrane into luminal and abluminal.,"Modify,Grammar",Grammar
6762,2-9,2-9_v2_60@4,2-9_v1_57@4,"That way, they could salvage the remaining tumor cells in two ways: by secreting lactic acid <REF-56> or ATP <REF-54> (similarly to muscle cells and erythrocytes, respectively) and by initiating the vaso-mimicry.","That way, they could salvage the remaining tumor cells: by secreting lactic acid <REF-53> or ATP <REF-50> (similar to muscle cells and erythrocytes, respectively), and by initiating the vaso-mimicry.","Modify,Clarity",Clarity
6763,2-9,2-9_v2_60@6,2-9_v1_57@6,Creating the capsular vaso-mimicry would require sufficient numbers of cancer cells in the initiating nodule.,Establishing the metastatic tumors by creating the capsular vaso-mimicry required sufficient numbers of cancer cells in the initiating nodule.,"Modify,Claim",Claim
6764,2-9,2-9_v2_60@9,2-9_v1_57@9,By definition they could be referred to as cancer stem cells (CSCs).,"By definition, they could be referred to as cancer stem cells (CSCs).","Modify,Grammar",Grammar
6765,2-9,2-9_v2_60@11,2-9_v1_57@11,"If the enzyme plays a role in degradation of chromatin during the erythrogenic conversion of erythroblasts it could be associated with growth of any tissue, not only malignant.","If the enzyme plays a role in degradation of chromatin during the erythrogenic conversion of erythroblasts it could be associated with growth of any tissue, not only malignant tissue.","Modify,Clarity",Clarity
6766,2-9,2-9_v2_61@0,2-9_v1_58@0,"Eventually, the heterologous host TSCs also engaged into paracrine dialog with the tumor (via cytokines and growth factors <REF-71> ).","Eventually, the heterologous host TSCs also engaged in paracrine dialog with the tumor (via cytokines and growth factors <REF-72> ).","Modify,Grammar",Grammar
6767,2-9,2-9_v2_61@3,2-9_v1_58@3,"Such interpretation regarding the role of homologous TSCs in neo-vasculature morphogenesis was consistent with earlier reports stating that not bone marrow derived EC precursors <REF-89> , <REF-90> but TSCs from tumor microenvironment differentiated into vasculature that supported tumor growth <REF-91> .","Such interpretation regarding the role of homologous TSCs in neo-vasculature morphogenesis was consistent with earlier reports stating that it was not bone marrow-derived EC precursors <REF-83> , <REF-84> but rather TSCs from the tumor microenvironment differentiated into vasculature that supported the tumor growth <REF-85> .","Modify,Clarity",Clarity
6768,2-9,2-9_v2_62@0,2-9_v1_59@0,"On the other hand, after pseudo-orthotopic implantation, TSCs from grafted breast tissue formed vasculature for the breast tumor sooner because malignant tissues maintained some characteristics of their tissue of origin.","On the other hand, after pseudo-orthotopic implantation, TSCs from grafted breast tissue formed vasculature for the breast tumor because malignant tissues maintained some characteristics of their tissue of origin.","Modify,Clarity",Clarity
6769,2-9,2-9_v2_62@1,2-9_v1_59@1,The two related cell types were immediately ready to cooperate in executing the tissue self-organizing potential <REF-41> .,The two related cell types cooperated in executing the tissue self-organizing potential <REF-36> .,"Modify,Fact/Evidence",Fact/Evidence
6770,2-9,2-9_v2_62@3,2-9_v1_59@3,"However, in each case hematopoiesis supporting the growing tissues was extramedullar.","However, in each case, hematopoiesis supporting the growing tissues was extramedullar.","Modify,Grammar",Grammar
6771,2-9,2-9_v2_6@5,2-9_v1_6@5,"Metastases of particularly aggressive cancers of different types (ovarian <REF-10> , <REF-11> , prostate <REF-12> , <REF-13> , glioblastoma <REF-14> , as well as melanoma <REF-15> ) were associated with patterned vasculogenic mimicry, i.e., a network of periodic acid Schiff stained (glycoproteins containing <REF-16> ) ""loops"" that represented blood-containing micro-vascular ""channels"", generated by the aggressive tumor cells without participation of endothelial cells (ECs) and independently of angiogenesis <REF-17> , <REF-18> .","Metastases of particularly aggressive cancers of different types (not only melanoma <REF-10> ) were associated with patterned vasculogenic mimicry, i.e., a network of periodic acid Schiff-stained (glycoproteins containing <REF-11> ) ""loops"" that represented blood-containing micro-vascular ""channels"", generated by the aggressive tumor cells without participation of endothelial cells (ECs) and independently of angiogenesis <REF-12> , <REF-13> .","Modify,Fact/Evidence",Fact/Evidence
6772,2-9,2-9_v2_6@7,2-9_v1_6@7,"Elevated incidence of metastasis was also correlated with autophagy of internal organelles in tumor cells, although by what mechanism was not clear <REF-21> .","Elevated incidence of metastasis was also correlated with autophagy of internal organelles in tumor cells, although the mechanism behind this was unclear <REF-16> .","Modify,Clarity",Clarity
6773,2-9,2-9_v2_6@8,2-9_v1_6@8,"Reports based on different experiments suggested that depending on the context, autophagy could either stimulate or prevent cancer <REF-22> .","Reports based on a variety of experiments have suggested that, depending on the context, autophagy could either stimulate or prevent cancer <REF-17> .","Modify,Clarity",Clarity
6774,2-9,2-9_v2_6@9,2-9_v1_6@9,"Thus, the question regarding the way in which autophagy influenced metastasis remained unanswered <REF-23> .","Thus, the question regarding the way in which autophagy influences metastasis has remained unanswered <REF-18> .","Modify,Grammar",Grammar
6775,2-9,2-9_v2_6@10,2-9_v1_6@10,Two other intriguing issues were inefficiency of tumor formation in experimental settings and targeting of a selected sub-population of tumor cells by an anticancer drug.,Two other intriguing issues were the inefficiency of tumor formation in experimental settings and the targeting of a selected sub-population of tumor cells by an anticancer drug.,"Modify,Grammar",Grammar
6776,2-9,2-9_v2_6@11,2-9_v1_6@11,"(1) Theoretically a single cell could be capable of establishing the tumor but large numbers and a latent period were actually required <REF-24> , <REF-25> .","(1) Theoretically, a single cell could be capable of establishing the tumor but large numbers and a latent period were actually required <REF-19> , <REF-20> .","Modify,Grammar",Grammar
6777,2-9,2-9_v2_6@13,2-9_v1_6@13,"Those observations together with the heterogeneity of tumors, known for a long time but not fully understood <REF-25> , <REF-27> , suggested the existence of cancer stem cells (CSCs) in spite of the undifferentiated phenotype of the malignant cells.","Those observations, together with the heterogeneity of tumors known for a long time but not fully understood <REF-20> , <REF-22> , suggest the existence of cancer stem cells (CSCs) in spite of the undifferentiated phenotype of the malignant cells.","Modify,Grammar",Grammar
6778,2-9,2-9_v2_7@2,2-9_v1_7@2,"However, crossing the endothelial barrier by molecules that successfully reached the intended vascular destinations turned out to be another problem.","However, how molecules cross the endothelial barrier and successfully reach the intended vascular destination has turned out to be another problem.","Modify,Clarity",Clarity
6779,2-9,2-9_v2_7@5,2-9_v1_7@5,The issue of the tumor vessels permeability is rather perplexing.,The issue of the tumor vessels’ permeability is rather perplexing.,"Modify,Grammar",Grammar
6780,2-9,2-9_v2_7@6,2-9_v1_7@6,"On one hand the vessels prevent anticancer drugs from penetrating the tumors, and on the other they are known to be abnormally leaky <REF-39> , <REF-40> .","On the one hand, the vessels prevent anticancer drugs from penetrating the tumors, while on the other hand, they are known to be abnormally leaky <REF-34> , <REF-35> .","Modify,Clarity",Clarity
6781,2-9,2-9_v2_8@0,2-9_v1_8@0,We had observed earlier that in our model formation of the tumor vasculature (vessels and blood) could be accelerated by availability of homologous tissue stem cells (TSCs) from co-implanted graft <REF-41> .,"We had observed earlier that in our model, formation of the tumor vasculature (vessels and blood) could be accelerated by availability of homologous tissue stem cells (TSCs) from a co-implanted graft <REF-36> .","Modify,Grammar",Grammar
6782,2-9,2-9_v2_8@3,2-9_v1_8@3,"In addition to providing answers to those questions, the results shown below suggested a new cellular mechanism for initiating metastasis.","In addition to providing answers to those questions, the results shown below suggest a new cellular mechanism for initiating metastasis.","Modify,Grammar",Grammar
6783,2-9,2-9_v2_8@8,2-9_v1_9@2,"If correct, it would bring the focus of the future studies to the energy metabolism-related initial steps (as discussed elsewhere <REF-41> ) and could result in finding new ways for inhibiting some of them before the angiogenic switch has had a chance to evolve; therefore, potentially preventing the metastases.","If correct, it would bring the focus of future studies to the energy metabolism-related initial steps (as discussed elsewhere <REF-36> ) and could result in the identification of new methods of inhibiting some of these steps before the angiogenic switch has had a chance to evolve, therefore, potentially preventing the metastases.","Modify,Clarity",Clarity
6784,3-101,3-101_v2_22@5,,"Making such approximations explicit would also encourage the consideration of alternatives, e.g. the use of interval arithmetic.",,"Add,Claim",Claim
6785,3-101,3-101_v2_29@0,,"It is important to distinguish the use of randomness in heuristics from the use of probabilistic models, i.e. models that predict observable quantities as averages over probability distributions.",,"Add,Claim",Claim
6786,3-101,3-101_v2_29@1,,"The latter are in the same category as the global-minimum example discussed above: the numbers they predict are well-defined and computable, even though their computation is often beyond the limits of today’s computing technology.",,"Add,Claim",Claim
6787,3-101,3-101_v2_29@2,,"By contrast, a method such as k -means clustering, whose initialization step requires an arbitrary random choice, yields a different result each time it is applied, and there is no reason to attribute any meaning to the statistical distribution of these results.",,"Add,Claim",Claim
6788,3-101,3-101_v2_29@3,,"In fact, the distribution used in the initialization step is hardly ever documented because it is considered irrelevant.",,"Add,Claim",Claim
6789,3-101,3-101_v2_19@6,3-101_v1_19@6,"This solution contains transcendental functions (sines and cosines), which are computable to any desired precision.","But this solution contains transcendental functions (sines and cosines), which are not computable and therefore must be replaced by computable approximations, e.g. power-series expansions.","Modify,Claim",Claim
6790,3-101,3-101_v2_19@7,3-101_v1_19@7,"However, when three or more celestial bodies are included in the model, no analytical solution is available and the differential equations must be approximated by finite difference equations <REF-12> .","When three or more celestial bodies are included in the model, no analytical solution is available and the differential equations must be approximated by finite difference equations <REF-12> .","Modify,Clarity",Clarity
6791,3-101,3-101_v2_21@4,3-101_v1_21@4,"The very fact that a program runs and produces results proves that the model specification is complete and unambiguous, assuming that the computing system itself (hardware, operating system, compiler, etc.) works correctly and that the programming language it is written in has clearly defined semantics (which, unfortunately, is not the case for widely used languages such as C <REF-15> .","The very fact that a program runs and produces results proves that the model specification is complete and unambiguous, assuming that the computing system itself (hardware, operating system, compiler, etc.) works correctly.","Modify,Fact/Evidence",Fact/Evidence
6792,3-101,3-101_v2_25@1,3-101_v1_25@1,"I use the term “tool” in a general sense that includes both physical objects (e.g. microscopes, lasers, etc.) and mathematical theorems or procedures (e.g. calculus or algebra), but not mathematical axioms and definitions, which form the language of mathematics rather than its toolbox.","I use the term “tool” in a general sense that includes both physical objects (e.g. microscopes, lasers, etc.) and mathematical theorems or procedures (e.g. calculus or algebra).","Modify,Fact/Evidence",Fact/Evidence
6793,3-101,3-101_v2_29@4,3-101_v1_28@10,The role of such heuristics in computational science remains to be clarified.,The role of such probabilistic heuristics in computational science remains to be clarified.,"Modify,Clarity",Clarity
6794,3-101,3-101_v2_45@5,3-101_v1_44@5,This doesn’t mean that knowledge is lost rapidly.,This doesn’t mean of course that knowledge is lost rapidly.,"Modify,Clarity",Clarity
6795,3-101,3-101_v2_56@3,3-101_v1_55@3,"In particular, tools that are very similar in spirit to today’s computer algebra systems can be used to create approximations and combinations of scientific models.","In particular, tools that very similar in spirit to today’s computer algebra systems can be used to create approximations and combinations of scientific models.","Modify,Grammar",Grammar
6796,3-101,3-101_v2_60@0,3-101_v1_59@0,"The specificity of floating-point arithmetic deserves a special discussion, both because of its central role in much of scientific software and because of its reputation of being the source of intractable problems.","The specificity of floating-point arithmetic deserve a special discussion, both because of its central role in much of scientific software and because of its reputation of being the source of intractable problems.","Modify,Grammar",Grammar
6797,3-101,3-101_v2_2@4,3-101_v1_2@4,"As a consequence, these crucial pieces of information no longer enter the scientific record.","As a consequence, these crucial pieces of information have disappeared from the scientific record.","Modify,Clarity",Clarity
6798,3-126,,3-126_v1_53@0,,Data for CD146-based cell sorting and telomere length in umbilical cord UC MSC and fibroblast cultures were evaluated for their expression levels of selected transcripts characterizing multiple cell fates in vivo .,"Delete,Fact/Evidence",Fact/Evidence
6799,3-126,,3-126_v1_53@1,,Ct values obtained using Taqman qPCR technology are shown in data set 1 (UC=Umbilical cord; FIB=fibroblast cell lines).,"Delete,Fact/Evidence",Fact/Evidence
6800,3-126,,3-126_v1_53@2,,The flow cytometry phenotype profiles of UC MSCs (cultures tested against a panel of MSC markers) and UC ECs (cultures tested against a panel of EC marekers) are shown in data set 2.,"Delete,Fact/Evidence",Fact/Evidence
6801,3-126,,3-126_v1_53@3,,Telomere lengths of cultured UC MSC1 and MSC2 samples are displayed in data set 3 (telomere lengths calculated as T/S ratio in different passages of UC MCS cultures).,"Delete,Fact/Evidence",Fact/Evidence
6802,3-126,3-126_v2_5@0,,"Although qPCR-based telomere length analysis in sorted populations could be limited in its sensitivity, very high frequency of CD146 + cells in UC tissue suggests that CD146 expression alone is unlikely to be sufficient to identify and purify native MSCs from the UC tissue.",,"Add,Claim",Claim
6803,3-126,3-126_v2_30@2,,Sorted fraction yields were compared using Wilcoxon matched pairs test.,,"Add,Fact/Evidence",Fact/Evidence
6804,3-126,3-126_v2_43@5,,"The yields of sorted cell subsets are shown on Figure 2B , left panel.",,"Add,Fact/Evidence",Fact/Evidence
6805,3-126,3-126_v2_46@4,,"The median difference suggested that CD146 + cells’ telomeres were 28bp longer (range 6414–7187bp) compared to CD146 - cells (range 6393–7120bp); however, the observed differences failed to reach statistical significance.",,"Add,Claim",Claim
6806,3-126,3-126_v2_46@5,,"Interestingly, the T/S ratio of the candidate MSC population falls closer to those of the adult tissues (BM MSCs and endometrial cells) than foetal tissues described by Guillot et al. <REF-21> .",,"Add,Fact/Evidence",Fact/Evidence
6807,3-126,3-126_v2_24@2,3-126_v1_23@2,"One tube was stained with 5 μl of neat CD45-FITC (#F0861), CD235α-FITC (#F0870) (both from DAKO, Cambridge, UK), CD146-PE (BD Pharmingen) and CD31-APC (#130-092-652, Miltenyi Biotec), whereas the other was stained with 2.5 μl of neat isotype controls IgG1-FITC (#550617, BD Pharmingen), IgG1-PE (#MCA928PE, Serotec) and IgG1-APC (#130-098-846, Miltenyi Biotec).","One tube was stained with 5 μl of neat CD45-FITC (#F0861), CD235α-FITC (#F0870) (both from DAKO, Cambridge, UK), CD146-PE (BD Pharmingen) and CD31-APC (#130-092-652, Miltenyi Biotec), whereas the other was stained with 2.5 μl of neat isotype controls alone.","Modify,Fact/Evidence",Fact/Evidence
6808,3-126,3-126_v2_24@3,3-126_v1_23@3,"After incubation with relevant antibodies and washes, 2 μg/ml 7-aminoactinomycin D (7-AAD) (#A1310, Invitrogen) was added to exclude dead cells before sorting into four fractions: haemopoietic cell fraction (HC), CD45 + CD235α + CD31 - ; EC fraction, CD45 - CD235α - CD31 + ; candidate MSC fraction, CD45 - CD235α - CD31 - CD146 + and non-MSC fraction, CD45 - CD235α - CD31 - CD146 - .","After incubation with relevant antibodies and washes, 2 μg/ml 7-aminoactinomycin D (7-AAD) (#A1310, Invitrogen) was added to exclude dead cells before sorting into four fractions: haemopoietic cell fraction (HC), CD45 + CD235α + CD31 - ; EC fraction, CD45 - CD235α - CD31 + ; double-negative candidate MSC fraction, CD45 - CD235α - CD31 - CD146 + and non-MSC fraction, CD45 - CD235α - CD31 - CD146 - .","Modify,Fact/Evidence",Fact/Evidence
6809,3-126,3-126_v2_26@1,3-126_v1_25@2,Samples were run in triplicate using 20 ng gDNA for expanded cells and all gDNA extracted from 1000 cells for the freshly sorted CD146 + versus CD146 - subset comparison.,Samples were run in triplicate using 20 ng gDNA.,"Modify,Fact/Evidence",Fact/Evidence
6810,3-126,3-126_v2_4@1,3-126_v1_4@1,"In five out of seven donors, telomeres in candidate native UC MSCs (CD45 - CD235α - CD31 - CD146 + ) were longer compared to donor-matched CD146 - population (CD45 - CD235α - CD31 - CD146 - ).","In three out of four donors, telomeres in candidate native UC MSCs (CD45 - CD235α - CD31 - CD146 + ) were longer compared to donor-matched CD146 - population (CD45 - CD235α - CD31 - CD146 - ).","Modify,Fact/Evidence",Fact/Evidence
6811,3-126,3-126_v2_30@1,3-126_v1_29@1,"The gene expression results were analysed with Mann-Whitney test for unpaired samples (P<0.05: high significance, 95% confidence interval).","The gene expression results were analysed with Mann-Whitney test for unpaired samples (p<0.05: high significance, 95% confidence interval).","Modify,Grammar",Grammar
6812,3-126,3-126_v2_4@2,3-126_v1_4@2,"The frequency of CD45 - CD235α - CD31 - CD146 + cells measured by flow cytometry was ~1000-fold above that of CFU-Fs (means 10.4% and 0.01%, respectively).","The frequency of CD45 - CD235α - CD31 - CD146 + cells measured by flow cytometry was ~1000-fold above that of donor-matched CFU-Fs (means 10.4% and 0.01%, respectively).","Modify,Clarity",Clarity
6814,3-126,3-126_v2_43@1,3-126_v1_42@0,"Following FSC/SSC gating to define cells (R1), live cells (R2) containing distinct populations of ECs (R3) and HCs (R4) were clearly observed.","The cell sorting strategy for these experiments is described in Figure 2A ; live cells (R1), containing distinct populations of ECs (R2) and HCs (R3) were clearly observed.","Split+Modify,Fact/Evidence",Fact/Evidence
6815,3-126,3-126_v2_43@4,3-126_v1_42@1,"Double negative cells (R5) were further subdivided into CD146 + (R6, candidate UC MSC) and CD146 - (R7, non-MSC) subsets and sorted into separate RNA lysis buffers.","Double negative cells (R4) were further subdivided into CD146 + (R5, candidate UC MSC) and CD146 - (R6, non-MSC) subsets and sorted into separate RNA lysis buffers.","Modify,Fact/Evidence",Fact/Evidence
6816,3-126,3-126_v2_43@2,3-126_v1_42@2,"In general, HCs were most abundant (mean 48% of total live cells, n=10).","In general, HCs were most abundant (mean 48% of total live cells, n=8).","Modify,Fact/Evidence",Fact/Evidence
6817,3-126,3-126_v2_46@1,3-126_v1_45@1,"When these frequencies were re-calculated in relation to total live cells, the CD146 + and CD146 - fractions represented a mean of 10.4% and 37.7%, respectively ( Figure 2B , right panel).","When these frequencies were re-calculated in relation to total live cells, the CD146 + and CD146 - fractions represented a mean of 10.4% and 37.7%, respectively ( Figure 2B ).","Modify,Clarity",Clarity
6818,3-126,3-126_v2_46@2,3-126_v1_45@2,"This was significantly higher than the frequency of CFU-Fs (as a percentage of total live cells) (mean 0.01%, Figure 2B , right panel).","This was significantly higher than the frequency of CFU-Fs (as a percentage of total live cells) in the same UC digests (mean 0.01%, Figure 2B ).","Modify,Clarity",Clarity
6819,3-126,3-126_v2_46@3,3-126_v1_45@3,"When the telomere length of both sorted subsets (CD146 + and CD146 - ) were tested, the CD146 + subset exhibited higher telomere lengths compared to the CD146 - subset in five out of seven donors ( Figure 2C ).","When the telomere length of both sorted subsets (CD146 + and CD146 - ) were tested, the CD146 + subset exhibited higher telomere lengths compared to the CD146 - subset in three out of four donors ( Figure 2C ), hence the observed differences failed to reach statistical significance.","Modify,Fact/Evidence",Fact/Evidence
6820,3-126,3-126_v2_58@3,3-126_v1_57@3,"Although evident in five out of seven experiments in our study, there was no significance to the difference in telomere length between CD146 + and CD146 - subsets potentially indicating contamination of MSCs with more mature cells in the CD146 + subset.","Although evident in three out of four cultures, in our study we observed the lack of significant difference in telomere length between CD146 + and CD146 - subsets potentially indicating contamination of MSCs with more mature cells in the CD146 + subset.","Modify,Fact/Evidence",Fact/Evidence
6821,3-126,3-126_v2_59@4,3-126_v1_58@4,"This potential technical limitation of qPCR, as well as working at the lower limit of DNA concentrations, could have affected the accuracy of the telomere analysis in the present study.",This potential technical limitation of qPCR could have affected the accuracy of the telomere analysis in the present study.,"Modify,Claim",Claim
6822,3-126,3-126_v2_10@0,3-126_v1_9@0,"The aims of this study were to confirm that CD146 could be a good MSC marker in the UC tissue and to purify candidate MSCs from UC tissue digests based on the non-haemopoietic (CD45 - CD235α - ), non-EC (CD31 - ), CD146 + phenotype.","The aims of this study were to confirm that CD146 could be a good MSC marker in the UC and to purify candidate MSCs from UC tissue digests based on the non-haemopoietic (CD45 - CD235α - ), non-EC (CD31 - ), CD146 + phenotype.","Modify,Clarity",Clarity
6823,3-126,3-126_v2_13@0,3-126_v1_12@0,UC tissue was collected from the UCs of consenting full-term caesarean section patients (n=10).,UC tissue was collected from the UCs of consenting full-term caesarean section patients (n=8).,"Modify,Fact/Evidence",Fact/Evidence
6824,3-126,3-126_v2_13@1,3-126_v1_12@1,"After delivery, UCs were immediately stored in Dulbecco’s phosphate buffered saline (DPBS, #14190-250, Invitrogen, Renfrew, UK) at 4°C.","After delivery, UCs were immediately stored in Dulbecco's phosphate buffered saline (DPBS, #14190-250, Invitrogen, Renfrew, UK) at 4°C.","Modify,Grammar",Grammar
6825,3-145,,3-145_v1_45@0,,Data availability,"Delete,Other",Other
6826,3-145,,3-145_v1_46@0,,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2014 Nersisyan L et al.,"Delete,Fact/Evidence",Fact/Evidence
6827,3-145,,3-145_v1_47@0,,"Data associated with the article are available under the terms of the Creative Commons Zero ""No rights reserved"" data waiver (CC0 1.0 Public domain dedication).","Delete,Fact/Evidence",Fact/Evidence
6828,3-145,3-145_v2_22@2,,The interactions are manually updated in the local My-SQL database and the version of String used is mentioned on the Tuning dialogue.,,"Add,Fact/Evidence",Fact/Evidence
6829,3-145,3-145_v2_32@2,3-145_v1_32@2,Gene expression threshold was set to 25 percentile of gene expression values in the dataset.,Gene expression threshold was set to 25 percentile of gene expression values of the BioGPS data.,"Modify,Clarity",Clarity
6830,3-145,3-145_v2_39@0,3-145_v1_39@0,"To further demonstrate necessity of tissue-specific tuning for assessment of pathway activity changes, we compared pathway flows in original and tuned KEGG Calcium Signaling Pathways with three gene expression datasets (norm vs B05 and B01) in CD14 monocytes, Adipocytes, and Cardiac myocytes (see Supplementary Material for details).","To further demonstrate necessity of tissue-specific tuning for assessment of pathway activity changes, we compared pathway flows in original and tuned KEGG Calcium Signaling Pathways with three gene expression Datasets (norm vs B05 and B01) in CD14 monocytes, Adipocytes, and Cardiac myocytes (see Supplementary materials for details).","Modify,Grammar",Grammar
6831,3-145,3-145_v2_4@5,3-145_v1_4@5,"Additionally, the sources of information on interactions depicted in pathways differ in quality and the nature of interactions (indirect, physical, regulatory, etc.).","Finally, the sources of information on interactions depicted in pathways differ in quality and the nature of interactions (indirect, physical, regulatory, etc.).","Modify,Clarity",Clarity
6832,3-145,3-145_v2_5@0,3-145_v1_5@0,"There is a wide variety of software that manipulate on KEGG pathways, both standalone and Cytoscape 3 apps, such as KEGGscape ( http://apps.cytoscape.org/apps/keggscape ) for KEGG pathways visualization and data integration, and others.","There is a wide variety of software that manipulate with KEGG pathways, both standalone and Cytoscape 3 apps, such as KEGGscape ( http://apps.cytoscape.org/apps/keggscape ) for KEGG pathways visualization and data integration, and others.","Modify,Grammar",Grammar
6833,3-145,3-145_v2_5@1,3-145_v1_5@1,"However, none of the available apps addresses inconsistencies in KGML files, and nor do they neither deal with abstractions of KEGG pathways.","However, none of the available apps addresses inconsistencies in KGML files, and nor do they deal with abstractions of KEGG pathways.","Modify,Other",Other
6834,3-145,3-145_v2_11@1,3-145_v1_11@1,The KEGG API can be used for individual downloads for academic use only; bulk download and non-academic usage requires a KEGG FTP subscription and license agreement ( http://www.kegg.jp/kegg/legal.html ).,The KEGG API can be used for individual downloads for academic use only; bulk download and non-acedmeic usage requires a KEGG FTP subscription and license agreement ( http://www.kegg.jp/kegg/legal.html ).,"Modify,Grammar",Grammar
6835,3-145,3-145_v2_11@2,3-145_v1_11@2,"The pathway selection dialogue provides a list of all KEGG pathways and organisms, however, if pathway KGML does not exist in the database the user will receive a warning message.","The pathway selection dialogue provides a list of all KEGG pathways and organisms, however, if pathway KGML does not exist in the database, the user will receive a warning message.","Modify,Grammar",Grammar
6836,3-145,3-145_v2_16@0,3-145_v1_16@0,"KEGG metabolic pathways, along with <relation/> entries, which characterize protein-protein interaction networks (enzyme interactions, in this case), also contain <reaction/> entries, characterizing compound interactions (chemical networks, http://www.kegg.jp/kegg/xml/docs/ ).","KEGG metabolic pathways, along with <relation> entries, which characterize protein-protein interaction networks (enzyme interactions, in this case), also contain <reaction> entries, characterizing compound interactions (chemical networks, http://www.kegg.jp/kegg/xml/docs/ ).","Modify,Grammar",Grammar
6837,3-145,3-145_v2_16@2,3-145_v1_16@2,"However, if only protein-protein interactions are of concern and if the KGML file contains respective <relation/> entries, CyKEGGParser will parse metabolic pathways similar to signaling ones.","However, if only protein-protein interactions are of concern and if the KGML file contains respective <relation> entries, CyKEGGParser will parse metabolic pathways similar to signaling ones.","Modify,Grammar",Grammar
6838,3-145,3-145_v2_22@1,3-145_v1_22@1,"The user can choose the source of interactions from the list of databases (GRID, DIP, KEGG, MINT and PDB), as well as set interaction confidence score threshold, which is computed based on various evidence channels, adjusted for probability of randomly observing an interaction <REF-3> .","The user can choose the source of interactions from the list of databases (GRID, DIP, KEGG, MINT and PDB), as well as set interaction confidence score threshold.","Modify,Fact/Evidence",Fact/Evidence
6839,3-163,3-163_v2_59@1,,"Many ectonucleotidases, including ENTPD3 ( Lavoie et al. , 2004 ), are slightly more active in biochemical assays with calcium as the divalent cation.",,"Add,Fact/Evidence",Fact/Evidence
6840,3-163,3-163_v2_59@2,,"However, we detected no difference in UTP histochemical activity in spinal cord between WT and Entpd3 -/- mice when 2 mM or 20 mM CaCl 2 was substituted for 20 mM MgCl 2 ( Figure 9 ; with deletion of ENTPD3 confirmed in these sections using immunostaining, Figure 9H ).",,"Add,Fact/Evidence",Fact/Evidence
6841,3-163,3-163_v2_59@3,,Thus Mg 2+ and Ca 2+ appear to be interchangeable in this histochemical assay.,,"Add,Fact/Evidence",Fact/Evidence
6842,3-163,3-163_v2_66@0,,"Note that FSCV cannot resolve neuronal ENTPD3 activity in the dorsal horn from spinal microglial ENTPD1 activity, so the adenosine detected by FSCV after applying ADP could originate from microglial ENTPD1 or other ectonucleotidases in the tissue.",,"Add,Claim",Claim
6843,3-163,3-163_v2_66@1,,"For example, this adenosine could originate from PAP and/or TNAP, as these enzymes are located in the same region and can also hydrolyze ADP to adenosine ( Figure 1 ).",,"Add,Claim",Claim
6844,3-163,3-163_v2_84@4,,"Our use of inhibitors ruled out the possibility that some ENTPDs, alkaline phosphatases and Na/K-ATPase compensated for the loss of ENTPD3.",,"Add,Claim",Claim
6845,3-163,3-163_v2_84@5,,"However, we cannot exclude the possibility that additional known or unknown enzymes with ectonucleotidase activity might be upregulated in Entpd3 -/- mice and compensate for the loss of ENTPD3.",,"Add,Claim",Claim
6846,3-163,3-163_v2_84@6,,Determining which enzymes act redundantly with ENTPD3 will require use of additional inhibitors and additional ectonucleotidase knockout lines.,,"Add,Claim",Claim
6847,3-169,3-169_v2_5@7,,We concentrated on investigating proliferation as the most validated sub-process of adult hippocampal neurogenesis affected by T-cell alterations.,,"Add,Fact/Evidence",Fact/Evidence
6848,3-169,3-169_v2_16@0,3-169_v1_16@0,"For RNA isolation, dentate gyri of seven- to eight-week-old Nestin GFP mice were dissected as described before <REF-36> .","For RNA isolation, dentate gyri of Nestin GFP mice were dissected as described before <REF-36> .","Modify,Fact/Evidence",Fact/Evidence
6849,3-169,3-169_v2_16@1,3-169_v1_16@1,"For hippocampal precursor cell cultures from microdissected dentate gyri of adult seven- to eight-week-old C57BL/6 mice, tissue dissection, digestion and cell enrichment were performed as previously described <REF-37> , <REF-38> .","For hippocampal precursor cell cultures from microdissected dentate gyri of adult C57BL/6 mice, tissue dissection, digestion and cell enrichment were performed as previously described <REF-37> , <REF-38> .","Modify,Fact/Evidence",Fact/Evidence
6850,3-169,3-169_v2_16@2,3-169_v1_16@2,"After enrichment, 1 × 10 4 cells/cm 2 were cultured in poly-D-lysine- and laminin-coated (Sigma-Aldrich and Roche, respectively) T25 cell culture flasks (TPP) in proliferation medium, consisting of Neurobasal Medium supplemented with B27, Glutamax and 50 U/ml Penicillin-Streptomycin (all Invitrogen), as well as 20 ng/ml human Fibroblast Growth Factor-basic (FGF-2) and 20 ng/ml human Epidermal Growth Factor (EGF; both PeproTech).","After enrichment, 1 × 10 4 cells/cm 2 were cultured in poly- D -lysine- and laminin-coated (Sigma-Aldrich and Roche, respectively) T25 cell culture flasks (TPP) in proliferation medium, consisting of Neurobasal Medium supplemented with B27, Glutamax and 50 U/ml Penicillin-Streptomycin (all Invitrogen), as well as 20 ng/ml human Fibroblast Growth Factor-basic (FGF-2) and 20 ng/ml human Epidermal Growth Factor (EGF; both PeproTech).","Modify,Grammar",Grammar
6851,3-169,3-169_v2_30@0,3-169_v1_30@0,"We first assessed steady-state levels of cell proliferation in the hippocampal dentate gyrus of adult, 8-week-old TCRα –/– mice, which are characterized by a complete lack of αβ T cells (both CD4 + and CD8 + ) due to targeted deletion of the gene encoding the TCRα subunit (TCRα –/– ).","We first assessed steady-state levels of cell proliferation in the hippocampal dentate gyrus of adult, 8-week-old TCRα –/– mice, which are characterized by a complete lack of αβ T cells (both CD4 + and CD8 + ) due to targeted deletion of the gene encoding the TCRα chain (TCRα –/– ).","Modify,Clarity",Clarity
6852,3-169,3-169_v2_32@0,3-169_v1_32@0,"To assess the impact of myelin-reactive Th17 cells on proliferation in vivo , we employed adoptive T cell transfers using six-week-old mice and quantified BrdU + cells in the hippocampus of TCRα -/- recipients two weeks later.","To assess the impact of myelin-reactive Th17 cells on proliferation in vivo , we employed adoptive T cell transfers and quantified BrdU + cells in the hippocampus of TCRα -/- recipients two weeks later.","Modify,Fact/Evidence",Fact/Evidence
6853,3-169,3-169_v2_32@1,3-169_v1_32@1,"For the generation of Th17 cells, naïve CD4 + T cells (CD4 + CD62L high CD25 − Foxp3 GFP− ) carrying the MOG 35-55 -specific 2D2 TCR as a transgene were FACS-purified from peripheral lymphoid tissues of four- to six-week-old 2D2 × Foxp3 GFP mice ( Figure 2A ) and cultured under T cell stimulatory conditions that promote efficient differentiation into Th17 cells with a ROR-γt + IL-17 + phenotype ( Figure 2B and C ).","For the generation of Th17 cells, naïve CD4 + T cells (CD4 + CD62L high CD25 − Foxp3 GFP− ) carrying the MOG 35-55 -specific 2D2 TCR as a transgene were FACS-purified from peripheral lymphoid tissues of 2D2 × Foxp3 GFP mice ( Figure 2A ) and cultured under T cell stimulatory conditions that promote efficient differentiation into Th17 cells with a ROR-γt + IL-17 + phenotype ( Figure 2B and C ).","Modify,Fact/Evidence",Fact/Evidence
6854,3-169,3-169_v2_36@2,3-169_v1_36@2,"To this end, we performed quantitative RT-PCR analysis of freshly microdissected dentate gyrus as well as isolated precursor cells from the dentate gyrus of adult, immunocompetent C57BL/6 mice ( Figure 3 ).","To this end, we performed quantitative RT-PCR analysis of freshly microdissected tissue as well as isolated precursor cells from the dentate gyrus of adult, immunocompetent C57BL/6 mice ( Figure 3 ).","Modify,Fact/Evidence",Fact/Evidence
6855,3-169,3-169_v2_37@1,3-169_v1_37@1,"Next, we extended our analysis to the type I cytokine receptor family (glycoprotein 130: gp130, CD130; common γ subunit: γc, CD132; common β subunit: βc, CD131), which is involved in the formation of more than 20 different cytokine receptors.","Next, we extended our analysis to the type I cytokine receptor family (glycoprotein 130: gp130, CD130; common γ chain: γc, CD132; common β chain: βc, CD131), which is involved in the formation of more than 20 different cytokine receptors.","Modify,Clarity",Clarity
6856,3-169,3-169_v2_43@0,3-169_v1_43@0,"In summary, the present study exemplifies that the TCRα –/– mouse represents a suitable experimental model to assess the proneurogenic potential of homogeneous Th cell populations that had been generated under well-defined in vitro conditions.","In summary, the present study exemplifies that the TCRα –/– mice represents a suitable experimental model to assess the proneurogenic potential of homogeneous Th cell populations that had been generated under well-defined in vitro conditions.","Modify,Grammar",Grammar
6857,3-169,3-169_v2_45@0,3-169_v1_45@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2017 Niebling J et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2014 Niebling J et al.,"Modify,Fact/Evidence",Fact/Evidence
6858,3-169,3-169_v2_2@1,3-169_v1_2@1,"Here, we explored the pro-proliferative potential of interleukin 17-producing T helper (Th17) cells, a developmentally and functionally distinct Th cell subset that is a key mediator of autoimmune neurodegeneration.","Here, we explored the proneurogenic potential of interleukin 17-producing T helper (Th17) cells, a developmentally and functionally distinct Th cell subset that is a key mediator of autoimmune neurodegeneration.","Modify,Fact/Evidence",Fact/Evidence
6859,3-169,3-169_v2_10@0,3-169_v1_10@0,Single cell suspensions of pooled spleen and lymph nodes (mesenteric and subcutaneous) from four- to six-week-old 2D2 × Foxp3 GFP mice were prepared using 70 µm cell strainers (BD).,Single cell suspensions of pooled spleen and lymph nodes (mesenteric and subcutaneous) from 2D2 × Foxp3 GFP mice were prepared using 70 µm cell strainers (BD).,"Modify,Fact/Evidence",Fact/Evidence
6860,3-169,3-169_v2_10@4,3-169_v1_10@4,"Intracellular cytokine staining was performed using the Cytofix/Cytoperm kit and mAbs to IL-17 (Monoclonal Rat IgG, TC11-18H10.1, eBioscience, Cat. No. 51-7172-80) and IFN-γ (Monoclonal Rat IgG, XMG1.2, BD Biosciences, Cat. No. 554412).","Intracellular cytokine staining was performed using the Cytofix/Cytoperm kit and mAbs to IL-17 (Monoclonal Rat IgG, TC11-18H10.1, eBioscience, Cat. No. 51-7172-80;) and IFN-γ (Monoclonal Rat IgG, XMG1.2, BD Biosciences, Cat. No. 554412).","Modify,Grammar",Grammar
6861,3-169,3-169_v2_2@2,3-169_v1_2@2,We found that base-line proliferation of hippocampal precursor cells in a T cell-deficient mouse model of impaired hippocampal neurogenesis can be restored upon adoptive transfer with homogeneous Th17 populations enriched for myelin-reactive T cell receptors (TCR).,We found that base-line proliferation of hippocampal precursor cells in a T cell-deficient mouse model of impaired hippocampal neurogenesis can be restored upon adoptive transfer with homogeneous Th17 populations enriched for myelin-reactive T cell receptors.,"Modify,Clarity",Clarity
6862,3-169,3-169_v2_12@5,3-169_v1_12@5,"On day 7 of Th17 differentiation cultures, 4 × 10 6 cells/200 μl PBS were injected i.v. into six-week-old TCRα −/− recipients.","On day 7 of Th17 differentiation cultures, 4 × 10 6 cells/200 μl PBS were injected i.v. into TCRα −/− recipients.","Modify,Fact/Evidence",Fact/Evidence
6863,3-169,3-169_v2_14@0,3-169_v1_14@0,Eight-week-old mice received 3 consecutive i.p. injections of BrdU (50 mg/kg body weight in 100 μl NaCl; Sigma-Aldrich) at intervals of 6 hours.,Mice received 3 consecutive i.p. injections of BrdU (50 mg/kg body weight in 100 μl NaCl; Sigma-Aldrich) at intervals of 6 hours.,"Modify,Fact/Evidence",Fact/Evidence
6864,3-169,3-169_v2_14@2,3-169_v1_14@2,"The brains were removed from the skull, postfixed overnight, washed with PBS and cryoprotected for ≥ 3 days in a 30% sucrose solution.","The brains were removed from the scull, postfixed overnight, washed with PBS and cryoprotected for ≥ 3 days in a 30% sucrose solution.","Modify,Grammar",Grammar
6865,3-172,,3-172_v1_82@2,,"For C-laurdan, however, the correlation was only moderate, mostly because of limited variations in anisotropy values between the different environments.","Delete,Fact/Evidence",Fact/Evidence
6866,3-172,3-172_v2_14@7,,"Liposomes obtained by sonication are usually mostly comprised of SUVs (15 – 50 nm in diameter), but the size of those quickly increases due to events of fusion, resulting in a population of larger vesicles comprising a mixture of relaxed SUVs, MLVs and OLVs.",,"Add,Fact/Evidence",Fact/Evidence
6867,3-172,3-172_v2_14@9,,"For simplicity, we simply refer to such vesicles as LUVs in the rest of the manuscript.",,"Add,Fact/Evidence",Fact/Evidence
6868,3-172,3-172_v2_57@7,,"C-laurdan is the only probe among the four to carry a head group which can be partially ionized, i.e. the carboxylic group.",,"Add,Fact/Evidence",Fact/Evidence
6869,3-172,3-172_v2_57@8,,This probably contributes greatly to C-laurdan's water solubility and fast membrane incorporation.,,"Add,Claim",Claim
6870,3-172,3-172_v2_65@2,,The rotational relaxation time is directly correlated with the order parameter through the Perrin-Weber equation.,,"Add,Fact/Evidence",Fact/Evidence
6871,3-172,3-172_v2_65@3,,Those were thus calculated from anisotropies and lifetimes values ( Table S2 ).,,"Add,Fact/Evidence",Fact/Evidence
6872,3-172,3-172_v2_65@4,,"Laurdan, M-laurdan and C-laurdan exhibit similar values indicating that those dyes have similar constraints in the bilayers.",,"Add,Fact/Evidence",Fact/Evidence
6873,3-172,3-172_v2_74@1,,"Also, both types of sphingomyelins used here (BSM and PSM) are derived from natural sources.",,"Add,Fact/Evidence",Fact/Evidence
6874,3-172,3-172_v2_74@2,,"As such, they contain a variety of fatty acids of different chain lengths.",,"Add,Fact/Evidence",Fact/Evidence
6875,3-172,3-172_v2_74@3,,"This will greatly impact on their phase behavior, and can thus contribute to explain why the results of anisotropy measurements do not give results which are as clear-cut as with DPPC.",,"Add,Claim",Claim
6876,3-172,3-172_v2_83@2,,We perceive that this type of phenomenon could be due to the probes being excluded from the crystalline mesh of solid phases.,,"Add,Claim",Claim
6877,3-172,3-172_v2_83@3,,The probes would consequently accumulate in the relatively disorganized environment corresponding to cracks and imperfections that form between tiles of truly organized lipids.,,"Add,Claim",Claim
6878,3-172,3-172_v2_74@0,3-172_v1_73@0,The strong contrast between the results found with DPPC and sphingomyelins might be related to the differences in their backbone structure since both types of lipids carry phosphocholine as head groups: DPPC can only accept a single hydrogen bond while sphingomyelin possesses an additional hydrogen bond accepting group.,"The strong contrast between the results found with DPPC and sphingomyelins might be related to the differences in their backbone structure since both types of lipids carry phosphocholine as head groups, but DPPC can only accept a single hydrogen bond while sphingomyelin possesses an additional hydrogen bond accepting group.","Modify,Clarity",Clarity
6879,3-172,3-172_v2_74@4,3-172_v1_73@1,"The very weak correlation between anisotropy and temperature observed for MoC-laurdan may be a consequence of the very low values of its fluorescence lifetimes in sphingomyelins (<τ> BSM =2.00 ns, <τ> PSM =2.77 ns at 20°C) compared to DPPC (<τ> DPPC =5.24 ns at 20°C), which may in turn be due to a poor insertion of the dye into the lipid bilayer as confirmed by rotational relaxation time calculation ( Table S2 ).","The very weak correlation between anisotropy and temperature observed for MoC-laurdan may be a consequence of the very low values of its fluorescence lifetimes in sphingomyelins (<τ> BSM =2.00 ns, <τ> PSM =2.77 ns at 20°C) compared to DPPC (<τ> DPPC =5.24 ns at 20°C), which may in turn be due to a poor insertion of the dye into the lipid bilayer.","Modify,Claim",Claim
6880,3-172,3-172_v2_80@0,3-172_v1_79@0,"We then prepared the very similar lipid mix as the one used by Kim et al. <REF-15> , i.e. DOPC/sphingomyelin/cholesterol (1:1:1), using either BSM or PSM, and confirmed their results showing intermediary values for GP, compared to pure So and Ld phases.","We then prepared the very similar lipid mix as the one used by Kim et al. , i.e. DOPC/sphingomyelin/cholesterol (1:1:1), using either BSM or PSM, and confirmed their results showing intermediary values for GP, compared to pure So and Ld phases.","Modify,Fact/Evidence",Fact/Evidence
6881,3-172,3-172_v2_82@0,3-172_v1_81@0,Correlating GP/relaxation time to identify lipid phases,Correlating GP/anisotropy to identify lipid phases,"Modify,Clarity",Clarity
6882,3-172,3-172_v2_83@0,3-172_v1_82@0,"When a lipid bilayer goes from fluid to solid, both GP and relaxation time are expected to increase, but those two measurements actually reflect very different characteristics: whilst GP values are mostly influenced by the hydration of the environment, relaxation time reflects on the order parameter of the bilayer related to fluidity.","When a lipid bilayer goes from fluid to solid, both GP and anisotropy are expected to increase, but those two measurements actually reflect very different characteristics: whilst GP values are mostly influenced by the hydration of the environment, anisotropy reflects on the order parameter of the bilayer related to fluidity.","Modify,Clarity",Clarity
6883,3-172,3-172_v2_83@1,3-172_v1_82@1,"When GP is plotted as a function of relaxation time for measurements made at room temperature on various model membranes ( Figure 7 and supporting information table S2 ), we find that M-laurdan is the only probe for which there is a reasonable correlation with the expected physical state of the bilayers, i.e. for which the bilayers made of just sphingomyelin (BSM or PSM), which are expected to be in solid state, do not give unexpectedly low values of GP and/or relaxation time.","When GP is plotted as a function of anisotropy for measurements made at room temperature on various model membranes ( Figure 7 ), we find the strongest correlation of these two characteristics for M-laurdan, and good correlations for laurdan and MoC-laurdan.","Modify,Fact/Evidence",Fact/Evidence
6884,3-172,3-172_v2_83@6,3-172_v1_82@5,"As a result, we think that the simultaneous measurement of GP and relaxation time with M-laurdan used as a probe will permit a true identification of the lipid phases.","As a result, we think that the simultaneous measurement of GP and anisotropy with M-laurdan used as a probe will permit a true identification of the lipid phases.","Modify,Clarity",Clarity
6885,3-172,3-172_v2_4@1,3-172_v1_4@1,"In animal cells, the external leaflet of plasma membranes (PMs) is mainly composed of phosphatidylcholine, sphingomyelin and cholesterol while the inner leaflet contains significant amounts of phosphatidylserine and phosphatidylethanolamine <REF-2> .","In animal cells, plasma membranes (PMs) are mainly composed of phosphatidylcholine, sphingomyelin and cholesterol <REF-2> .","Modify,Fact/Evidence",Fact/Evidence
6886,3-172,3-172_v2_55@0,3-172_v1_54@0,"For labelling model bilayers, we employed the most adequate procedure which consists in the direct assembly of fluorescently labelled LUVs.","For labelling model bilayers, we employed the most adequate procedure consisting of directly mixing lipids and fluorescent probes in chloroform, followed by steps of desiccation and rehydration in buffer that lead to the direct assembly of fluorescently labelled LUVs.","Split+Modify,Clarity",Clarity
6887,3-172,3-172_v2_55@1,3-172_v1_54@0,"This entails direct mixing of lipids and fluorescent probes in chloroform, followed by steps of desiccation to remove the organic solvent, and then by rehydration in buffer, which includes a sonication step (see Materials and methods).","For labelling model bilayers, we employed the most adequate procedure consisting of directly mixing lipids and fluorescent probes in chloroform, followed by steps of desiccation and rehydration in buffer that lead to the direct assembly of fluorescently labelled LUVs.","Split+Modify,Fact/Evidence",Fact/Evidence
6888,3-172,3-172_v2_56@0,3-172_v1_55@0,"Using laurdan, M-laurdan, MoC-laurdan and C-laurdan on LUVs made of DPPC, DPPC/cholesterol (6:4) and POPC, we performed GP and anisotropy measurements to compare both types of samples and we found no detectable difference, suggesting that the presence of low concentrations of DMSO in the samples does not have any significant effect on this kind of probes ( Figure S4 ).","Using laurdan and C-laurdan on LUVs made of DPPC, DPPC/cholesterol (6:4) and POPC, we performed GP and anisotropy measurements to compare both types of samples and we found no detectable difference, suggesting that the presence of low concentrations of DMSO in the samples does not have any significant effect on this kind of probes ( Figure S4 ).","Modify,Fact/Evidence",Fact/Evidence
6889,3-172,3-172_v2_57@6,3-172_v1_56@6,The large differences observed between the insertion times of the various probes probably originate from differences in their hydrophilic head volumes.,The large differences observed between the insertions times of the various probes probably originate from differences in their hydrophilic head volumes.,"Modify,Grammar",Grammar
6890,3-172,3-172_v2_65@0,3-172_v1_64@0,"The fluorescence lifetimes were thus measured and found to be very similar to one another for the first three: laurdan (<τ> POPC =3.19 ns, <τ> DOPC =3.04 ns at 20°C), M-laurdan (<τ> POPC =3.16 ns, <τ> DOPC =3.33 ns at 20°C) and MoC-laurdan (<τ> POPC =3.03 ns, <τ> DOPC =3.17 ns at 20°C).","The fluorescence lifetimes were thus measured, and found to be very similar to one another for the first three: laurdan (<τ> POPC =3.19 ns, <τ> DOPC =3.04 ns at 20°C), M-laurdan (<τ> POPC =3.16 ns, <τ> DOPC =3.33 ns at 20°C) and MoC-laurdan (<τ> POPC =3.03 ns, <τ> DOPC =3.17 ns at 20°C).","Modify,Grammar",Grammar
6891,3-172,3-172_v2_65@5,3-172_v1_64@1,"For MoC-laurdan, the lower rotational relaxation time could thus indicate a more superficial insertion of the probe that may be due to its bulky head group.","For MoC-laurdan, the lower anisotropy could thus indicate a more superficial insertion of the probe that may have come from its bulky head group.","Modify,Claim",Claim
6892,3-172,3-172_v2_65@1,3-172_v1_64@2,"For C-laurdan, fluorescence lifetimes were 30% shorter compared to the others (<τ> POPC =2.26 ns, <τ> DOPC =2.13 ns at 20°C) ( Table 3 ).","For C-laurdan, fluorescence lifetimes were reduced by 30%, compared to the others (<τ> POPC =2.26 ns, <τ> DOPC =2.13 ns at 20°C) ( Table 3 ), and the higher anisotropy may reflect a more constrained rotational mobility.","Modify,Clarity",Clarity
6893,3-172,3-172_v2_14@8,3-172_v1_14@7,Characterization of those lipid vesicles by dynamic light scattering (DLS) showed that the main population of vesicles had sizes ranging from 150 to 350 nm in diameter depending on the mix of lipids used to prepare the liposomes.,Characterization by dynamic light scattering (DLS) of the lipid vesicles showed the main population of vesicles had sizes ranging from 150 to 350 nm in diameter depending on the mix of lipids used to prepare the liposomes.,"Modify,Clarity",Clarity
6894,3-172,3-172_v2_69@0,3-172_v1_68@0,Probing model bilayers undergoing So to Ld transition,Probing model bilayers in pure So states,"Modify,Other",Other
6895,3-176,,3-176_v1_33@3,,"Four additional labs have already agreed to run these experiments using similar machines and protocols; researchers that are interested in contributing to this project can contact the corresponding author, who will provide them with further details about how to participate.","Delete,Fact/Evidence",Fact/Evidence
6896,3-176,3-176_v2_22@0,,Data availability,,"Add,Other",Other
6897,3-176,3-176_v2_38@1,,"In principle, the differences between the strains could be explained by genetic, epigenetic or environmental differences, or a combination of these factors.",,"Add,Claim",Claim
6898,3-176,3-176_v2_38@6,,"In fact, a separate replication in a different location (Regensburg instead of Berlin), new hardware and a different experimenter (Brembs instead of Colomb, manuscript in preparation, see data and project progress at https://github.com/brembslab/cs_buri ), suggests that the spatial parameters, in particular, are relatively constant between replicates, while the temporal activity parameters may vary to some degree.",,"Add,Fact/Evidence",Fact/Evidence
6899,3-176,3-176_v2_38@7,,We take these observations as evidence that the differences between the sub-strains are stable over at least several years.,,"Add,Claim",Claim
6900,3-176,3-176_v2_39@0,,The time elapsed between replicates also seems to suggest that epigenetic changes are rather unlikely.,,"Add,Claim",Claim
6901,3-176,3-176_v2_39@1,,"We thus tentatively conclude that the differences between the strains are genetic in origin and have hence begun to sequence the genomes of these five Canton S sub-strains, with marked alterations in all of them (manuscript in preparation, see data and project progress at https://github.com/brembslab/cs_buri ).",,"Add,Claim",Claim
6902,3-176,3-176_v2_39@2,,"However, epigenetic modification, as well as selection may play a much larger role when studying mutant or transgenic lines which have been outbred to, e.g. a Canton S genetic background.",,"Add,Claim",Claim
6903,3-176,3-176_v2_39@3,,In these cases there may be more or less strong evolutionary forces driving genomic changes.,,"Add,Claim",Claim
6904,3-176,3-176_v2_42@0,,"The results also raise the question, if every laboratory sub-strain is effectively different from any other strain, or if there are groups of sub-strains that remain genetically and behaviorally similar.",,"Add,Claim",Claim
6905,3-176,3-176_v2_42@1,,"To examine the degree to which different laboratory strains cluster around certain groups, we are soliciting Buridan data from other laboratories with Canton S strains.",,"Add,Fact/Evidence",Fact/Evidence
6906,3-176,3-176_v2_42@2,,"The results in Figure 4 will be updated, whenever new data is being uploaded, such that the degree of clustering between sub-strains can be observed.",,"Add,Fact/Evidence",Fact/Evidence
6907,3-176,3-176_v2_42@3,,Further research will be required to test the hypothesis that most of the variance between sub-strains of wild type flies is due to genetic differences acquired by founder effects.,,"Add,Claim",Claim
6908,3-176,3-176_v2_49@0,,Additional data can be downloaded from Figure 4 .,,"Add,Fact/Evidence",Fact/Evidence
6909,3-176,3-176_v2_21@0,3-176_v1_21@0,Twelve different parameters were calculated ( Table 1 ) and a Principal Components Analysis (PCA) was performed to visualize the results and identify potential groupings of the sub-strains.,Twelve different parameters were calculated ( Table 1 ) and a Principle Components Analysis (PCA) was performed to visualize the results and identify potential groupings of the sub-strains.,"Modify,Grammar",Grammar
6910,3-176,3-176_v2_23@0,3-176_v1_22@0,"Raw trajectory data (including outliers), the results of the CeTrAn analysis and the PCA result table are available on figshare: http://dx.doi.org/10.6084/m9.figshare.1014264 .",Raw trajectory data (including outliers) of the results of the CeTrAn analysis and the PCA result table are available on figshare: http://dx.doi.org/10.6084/m9.figshare.1014264 .,"Modify,Grammar",Grammar
6911,3-176,3-176_v2_25@3,3-176_v1_24@3,"The locomotion parameters that we calculated can be divided into three broad categories: temporal (activity/pause structure), spatial (stripe fixation, thigmotaxis, trajectory straightness) and mixed (speed, number of walks between stripes, distance travelled) measures (ref. <REF-7> , Table 1 ).","The locomotion parameters that we calculated can be divided into three broad categories: temporal (activity/pause structure), spatial (stripe fixation, thigmotaxis, trajectory straightness) and mixed (speed, number of walks between stripes, distance travelled) measures ( Table 1 <REF-7> ).","Modify,Clarity",Clarity
6912,3-176,3-176_v2_28@0,3-176_v1_27@0,"Using CeTrAn 4.0, we took twelve measurements of the flies’ walking behavior and analyzed them using PCA (for individual performance of each strain in each measurement, see supplementary materials ).","Using CeTrAn 4.0, we took twelve measurements of the flies’ walking behavior and analyzed them using PCA.","Modify,Fact/Evidence",Fact/Evidence
6913,3-176,3-176_v2_28@2,3-176_v1_27@2,"Since the first and third principal components were not normally distributed (Shapiro test), we performed an ANOVA for the second component with the fly sub-strains and the replicates as factors.","Since the first and third principle components were not normally distributed (Shapiro test), we performed an ANOVA for the second component with the fly sub-strains and the replicates as factors.","Modify,Grammar",Grammar
6914,3-176,3-176_v2_28@3,3-176_v1_27@3,"This analysis demonstrated significant main effects of the sub-strain (F = 28.305, p<2e-16) and the replicate (F = 9.35, p<0.003), while there seems to be no sub-strain × replicate interaction (F value = 2.337, p = 0.059).","This analysis demonstrated significant effects of the sub-strain (F value = 37.315 < 2e-16), the replicate (4.155 0.04374), and the interaction sub-strain × replicate (F value = 3.891 0.00527).","Modify,Fact/Evidence",Fact/Evidence
6915,3-176,3-176_v2_28@4,3-176_v1_27@4,"A Tukey HSD post hoc test of the sub-strain effect confirmed the visual impression of the PCA grouping: CS_TZ and CS_TP together in one group, CS_BS and CS_HS together and CS_JC alone.","A post hoc test of the sub-strain effect, together with a non-parametric test for the third component of the PCA, showed three groups: CS_TZ and CS_TP together in one group, CS_BS and CS_HS together and CS_JC alone (CS_TZ and CS_JC could be separated only on PC3).","Modify,Fact/Evidence",Fact/Evidence
6916,3-176,3-176_v2_34@1,3-176_v1_33@1,"In Figure 4 , we have visualized the result of a PCA over both our and submitted data.","Figure 4 currently visualizes the result of a PCA analysis over our data and one additional data set, contributed by the Botella lab in Regensburg.","Modify,Clarity",Clarity
6917,3-176,3-176_v2_34@2,3-176_v1_33@2,Additional data will constantly be added to the analysis after the publication of this article; the interactivity of this figure will allow readers to visualize the data at different points in time.,"However, in future versions of this article, data collected from other laboratories will be continuously fed into this database, with Figure 4 providing real-time visualizations of this incoming data.","Modify,Clarity",Clarity
6918,3-176,3-176_v2_38@4,3-176_v1_37@3,"Taking into account these circumstances, it is a straightforward assumption that the differences in behavior we report here are either genetic or epigenetic in origin.","Therefore, it is a straightforward assumption that the differences in behavior we report here are genetic in origin.","Modify,Claim",Claim
6919,3-176,3-176_v2_38@5,3-176_v1_37@4,"Taking all the measured parameters into account, sub-strain differences were comparable in the two replicates conducted one year apart, even though one of the Principal Components showed a statistically significant (but numerically small) replicate effect.","The sub-strain differences were comparable in the two replicates conducted one year apart, indicating that the genetic differences between the sub-strains were stable over this time span, although the CS_BS sub-strain appeared to have been modified during that time.","Modify,Fact/Evidence",Fact/Evidence
6920,3-176,3-176_v2_9@0,3-176_v1_9@0,"Flies were kept in vials (68 ml, Art.-Nr. 217101, Greiner Bio-One GmbH, Maybachstr.2, 72636 Frickenhausen) in a controlled density on standard cornmeal/molasses medium <REF-9> at 25°C in a 12 h:12 h dark/light cycle for one generation before being tested.","Flies were kept in vials (68 ml, Art.-Nr. 217101, Greiner Bio-One GmbH, Maybachstr.2, 72636 Frickenhausen) in a controlled density <REF-9> on standard cornmeal/molasses medium <REF-10> at 25°C in a 12 h:12 h dark/light cycle for one generation before being tested.","Modify,Fact/Evidence",Fact/Evidence
6921,3-176,3-176_v2_9@2,3-176_v1_9@2,"Approximately ten female flies (N=11–12 in each group) were then CO 2 -anaesthetized and their wings were cut with surgical scissors at two thirds of their length, before being taken back to their vial to recover overnight.","Approximately ten female flies (N=11-12 in each group) were then CO 2 -anaesthetized and their wings were cut with surgical scissors at two thirds of their length, before being taken back to their vial to recover overnight.","Modify,Grammar",Grammar
6922,3-176,3-176_v2_14@2,3-176_v1_14@2,"The locomotion parameters we calculated can be divided into three broad categories: temporal (activity/pause structure), spatial (stripe fixation, thigmotaxis, trajectory straightness) and mixed (speed, number of walks between stripes, distance travelled) measures (ref. <REF-7> , Table 1 ).","The locomotion parameters we calculated can be divided into three broad categories: temporal (activity/pause structure), spatial (stripe fixation, thigmotaxis, trajectory straightness) and mixed (speed, number of walks between stripes, distance travelled) measures ( Table 1 ) <REF-7> .","Modify,Clarity",Clarity
6923,3-189,,3-189_v1_19@5,,"Other species captured at this site included one cownose ray ( Rhinoptera bonasus , DW = 414 mm), one bullnose ray (DW = 458 mm), and four harvestfish ( Peprilus alepidotus ).","Delete,Fact/Evidence",Fact/Evidence
6924,3-189,,3-189_v1_19@6,,This site was 15670.63 m from the nearest inlet and 247.08 m from the nearest mapped seagrass bed.,"Delete,Fact/Evidence",Fact/Evidence
6925,3-189,,3-189_v1_24@5,,"Spiny dogfish feed primarily on schooling pelagic fishes ( Link et al. , 2002 ), and the harvestfish co-occurring with them in Core Sound may represent a potential food source within this estuary.","Delete,Claim",Claim
6926,3-189,,3-189_v1_25@0,,Little is currently known about spiny dogfish habits within estuarine waters.,"Delete,Claim",Claim
6927,3-189,,3-189_v1_25@1,,Spiny dogfish observed during this survey penetrated relatively far into the estuary (6–15 km from the nearest inlet) and were captured close to seagrass habitat areas.,"Delete,Fact/Evidence",Fact/Evidence
6928,3-189,,3-189_v1_25@2,,"Sharks can exert top-down influences that can have far-reaching direct and indirect effects on the ecology of estuarine environments ( Heithaus et al. , 2012 ).","Delete,Fact/Evidence",Fact/Evidence
6929,3-189,,3-189_v1_25@3,,Determining whether spiny dogfish are ecologically important within North Carolina inshore waters will require further observation.,"Delete,Claim",Claim
6930,3-189,,3-189_v1_8@3,,"Sampling locations were chosen with the goal of sampling three different habitat types; seagrass beds, shallow sand flats, and deep channels.","Delete,Fact/Evidence",Fact/Evidence
6931,3-189,,3-189_v1_11@1,,"Longline gear consisted of a 274.32 m mainline 6.35 mm in diameter with 50 gangions comprised of a longline clip with a swivel, a 1 m leader of 136.08 kg test monofilament line, and a size 12/0 circle hook, attached at 5–7 m intervals.","Delete,Fact/Evidence",Fact/Evidence
6932,3-189,,3-189_v1_11@4,,"Where space allowed, both gears were deployed within 100 m of each other and allowed to soak simultaneously; otherwise only one of the gear types was deployed.","Delete,Fact/Evidence",Fact/Evidence
6933,3-189,,3-189_v1_2@3,,Stations where dogfish were captured were approximately 6.5-15.7 km from the nearest inlet and 43.4-247.1 m from the nearest seagrass bed.,"Delete,Fact/Evidence",Fact/Evidence
6934,3-189,,3-189_v1_11@6,,Distance from the nearest inlet and distance from the nearest mapped seagrass bed were calculated by plotting the sampling locations in ArcGIS 10.1 and measuring the straight-line distance (m) between the sampling stations and those geographic features.,"Delete,Fact/Evidence",Fact/Evidence
6935,3-189,,3-189_v1_11@7,,"Mapped seagrass locations were taken from ArcGIS shapefiles of submerged aquatic vegetation generated by the Albemarle-Pamlico National Estuary Partnership ( APNEP, 2008 ).","Delete,Fact/Evidence",Fact/Evidence
6936,3-189,,3-189_v1_12@2,,"All batioids were identified, and sex and disc width (DW, mm) were recorded for each individual.","Delete,Fact/Evidence",Fact/Evidence
6937,3-189,,3-189_v1_12@3,,"All other bycatch organisms were identified, counted, and released.","Delete,Fact/Evidence",Fact/Evidence
6938,3-189,,3-189_v1_15@5,,"A bluntnose stingray ( Dasyatis say , DW = 450 mm) and a bullnose ray ( Myliobatis freminvillii , DW = 458 mm) were also captured in this set.","Delete,Fact/Evidence",Fact/Evidence
6939,3-189,,3-189_v1_15@6,,Spatial analysis showed that this site was 6526.40 m from the nearest inlet and 43.43 m from the nearest mapped seagrass area.,"Delete,Fact/Evidence",Fact/Evidence
6940,3-189,3-189_v2_19@4,3-189_v1_19@4,"A depth of 1.8 m, temperature of 24.2°C, salinity of 33.4 ppt, and dissolved oxygen of 6.9 mg/L were recorded at this site.","A depth of 1.77 m, temperature of 24.2°C, salinity of 33.4 ppt, and dissolved oxygen of 6.88 mg/L were recorded at this site.","Modify,Fact/Evidence",Fact/Evidence
6941,3-189,3-189_v2_22@3,3-189_v1_22@3,"In the vicinity of Cape Fear, North Carolina, Thorpe & Beresoff, (2000) captured spiny dogfish in commercial gillnet gear from December–April, though the sharks were most abundant in February and March and at temperatures less than 13.9°C.","In the vicinity of Cape Fear, North Carolina, Thorpe & Beresoff, (2000) captured spiny dogfish in commercial gillnet gear from December-April, though the sharks were most abundant in February and March and at temperatures less than 13.9°C.","Modify,Grammar",Grammar
6942,3-189,3-189_v2_23@1,3-189_v1_23@1,"Spiny dogfish occurring between Cape Hatteras and the Gulf of Maine mostly occurred in North Carolina waters during winter and spring, and were distributed between New England and Canadian waters during summer and autumn ( Campana et al. , 2007 ; Stehlik, 2007 ).","Spiny dogfish occurring between Cape Hatteras and the Gulf of Maine mostly occurred in North Carolina waters during winter and spring, and were distributed between New England and Canadian waters during summer and autumn ( Campana et al. , 2007 , Stehlik, 2007 ).","Modify,Grammar",Grammar
6943,3-189,3-189_v2_25@2,3-189_v1_26@2,"The NMFS seasonal trawl surveys only sample North Carolina waters during the early spring and autumn and may not account for spiny dogfish occurring in the area at other times of the year, but migration out of southern waters in spring has also been suggested by gillnet and longline surveys capable of capturing sharks year-round ( Thorpe & Beresoff, 2000 ; Thorpe et al. , 2004 ; Ulrich et al. , 2007 ), as well as acoustic telemetry ( Rulifson et al. , 2012 ).","The NMFS seasonal trawl surveys only sample North Carolina waters during the early spring and autumn and may not account for spiny dogfish occurring in the area at other times of the year, but migration out of southern waters in spring has also been suggested by gillnet and longline surveys capable of capturing sharks year-round ( Thorpe & Beresoff, 2000 , Thorpe et al. , 2004 , Ulrich et al. , 2007 ), as well as acoustic telemetry ( Rulifson et al. , 2012 ).","Modify,Grammar",Grammar
6944,3-189,3-189_v2_26@0,3-189_v1_27@0,"Previous studies have shown that spiny dogfish migration and habitat use patterns may be more complex than previously thought ( Campana et al. , 2007 ; Rulifson & Moore, 2009 ; Sulikowski et al. , 2010 ).","Previous studies have shown that spiny dogfish migration and habitat use patterns may be more complex than previously thought ( Campana et al. , 2007 , Rulifson & Moore, 2009 , Sulikowski et al. , 2010 ).","Modify,Grammar",Grammar
6945,3-189,3-189_v2_6@1,3-189_v1_6@1,"Spiny dogfish south of Cape Hatteras tend to occur in shallower water closer to shore than conspecifics north of Cape Hatteras ( Rulifson & Moore, 2009 ; Rulifson et al. , 2012 ).","Spiny dogfish south of Cape Hatteras tend to occur in shallower water closer to shore than conspecifics north of Cape Hatteras ( Rulifson & Moore, 2009 , Rulifson et al. , 2012 ).","Modify,Grammar",Grammar
6946,3-189,3-189_v2_6@2,3-189_v1_6@2,"Acoustic telemetry data suggest that these sharks are part of the population that migrates between Cape Hatteras and Cape Cod ( Rulifson et al. , 2012 ), and seem to occupy southern waters between November and April ( Ulrich et al. , 2007 ; Rulifson et al. , 2012 ).","Acoustic telemetry data suggest that these sharks are part of the population that migrates between Cape Hatteras and Cape Cod ( Rulifson et al. , 2012 ), and seem to occupy southern waters between November and April ( Ulrich et al. , 2007 , Rulifson et al. , 2012 ).","Modify,Grammar",Grammar
6947,3-189,3-189_v2_6@3,3-189_v1_6@3,"Despite this consistent behavior among acoustically tagged sharks, Rulifson et al. , (2012) reported the capture of several spiny dogfish by hook and line at Cape Lookout on June 1, 2010, long after the end of the overwintering period for this species, though environmental measurements were not recorded.","Despite this consistent behavior among acoustically tagged sharks, Rulifson et al. , (2012) captured several spiny dogfish by hook and line at Cape Lookout on June 1, 2010, long after the end of the overwintering period for this species.","Modify,Fact/Evidence",Fact/Evidence
6948,3-189,3-189_v2_2@2,3-189_v1_2@2,"All dogfish were females measuring 849-905 mm total length, well over the size at 50% maturity.","All dogfish were females over the size at maturity, and were caught at stations 1.77-2.74 m in depth, with temperatures 22.9-24.2 °C, 32.8-33.4 ppt salinity, and 6.9-8.0 mg/L dissolved oxygen.","Split+Modify,Fact/Evidence",Fact/Evidence
6949,3-189,3-189_v2_2@3,3-189_v1_2@2,"Dogfish were caught at stations 1.8-2.7 m in depth, with temperatures 22.9-24.2 °C, 32.8-33.4 ppt salinity, and 6.9-8.0 mg/L dissolved oxygen.","All dogfish were females over the size at maturity, and were caught at stations 1.77-2.74 m in depth, with temperatures 22.9-24.2 °C, 32.8-33.4 ppt salinity, and 6.9-8.0 mg/L dissolved oxygen.","Split+Modify,Fact/Evidence",Fact/Evidence
6950,3-189,3-189_v2_11@0,3-189_v1_11@0,Sharks were captured using bottom-set gillnet gear.,Sharks were captured using bottom-set longline and gillnet gear.,"Modify,Fact/Evidence",Fact/Evidence
6952,3-189,3-189_v2_11@1,3-189_v1_11@3,"Gillnet gear measured 50 m in length and 2.4 m in height, and was comprised of eight panel sections of monofilament mesh measuring 7.5, 10, 12.3, 15.5, 17.1, 21, 25.6, and 31 cm stretched, respectively, and was soaked for 30–60 minutes.",Both gears were soaked for 30–60 minutes.,"Merge+Modify,Clarity",Clarity
6953,3-189,3-189_v2_12@0,3-189_v1_12@0,"All captured sharks were identified to species and sex, fork length (FL, mm), and stretched total length (TL, mm) were recorded.","All captured sharks were identified to species and sex, fork length (FL, mm), and total length (TL, mm) were recorded.","Modify,Fact/Evidence",Fact/Evidence
6954,3-190,,3-190_v1_27@2,,"For R. terraenovae all age estimates (direct and backtransformed) were over double theoretical maximum longevities (7.1 and 6.9 years females and males respectively) from Loefer & Sedberry, 2003 ( Table 2 ).","Delete,Fact/Evidence",Fact/Evidence
6955,3-190,,3-190_v1_30@2,,"The backtransformed maximum longevity was below the theoretical maximum longevities (19.0 years, Driggers et al. , 2004 ) for female C. acronotus , but above theoretical longevity (16.4 years) for males ( Table 2 ).","Delete,Fact/Evidence",Fact/Evidence
6956,3-190,3-190_v2_21@0,,"From 1993 to 1998 a total of 3,419 R. terraenovae were tagged and released, of these 155 were recaptured.",,"Add,Fact/Evidence",Fact/Evidence
6957,3-190,3-190_v2_27@0,,"From 1993 to 2013 a total of 1,537 C. acronotus were tagged and released, of these 24 were recaptured.",,"Add,Fact/Evidence",Fact/Evidence
6959,3-190,3-190_v2_27@1,3-190_v1_25@1,Three C. acronotus were recaptured (two males and one female) with times at liberty ranging from 10.9 to 12.8 years (mean ± S.D. = 11.9 ± 1.0).,Time at liberty ranged from 10.9 to 12.8 years (mean ± S.D. = 11.9 ± 1.0).,"Merge+Modify,Clarity",Clarity
6960,3-190,3-190_v2_27@4,3-190_v1_25@4,Age estimates from vertebral sections ranged from 14.5 to 20.5 years ( Figure 2 ).,Age estimates from vertebral sections ranged from 14.5 to 20.5 years.,"Modify,Fact/Evidence",Fact/Evidence
6961,3-190,3-190_v2_36@2,3-190_v1_32@2,"A review of published shark age and growth studies shows that, in most studies, females have a greater or equal longevity than males (e.g. Carlson & Baremore, 2003 ; Carlson & Parsons, 1997 ; Carlson et al. , 1999 ; Driggers et al. , 2004 ; Drymon et al. , 2006 ; Frazier et al. , 2014 ).","A review of published shark age and growth studies shows that, in most studies, that females have a greater or equal longevity than males (e.g. Carlson & Baremore, 2003 ; Carlson & Parsons, 1997 ; Carlson et al. , 1999 ; Driggers et al. , 2004 ; Drymon et al. , 2006 ; Frazier et al. , 2014 ).","Modify,Grammar",Grammar
6962,3-190,3-190_v2_36@3,3-190_v1_32@3,"Therefore, we believe that we did not sample older females and suggest that the longevity estimates we observed for each species be applied to males and females.","Therefore, we believe that we did not sample older females and suggest that the longevity estimates maximum observed longevity we observed for each species be applied to males and females.","Modify,Clarity",Clarity
6963,3-190,3-190_v2_38@3,3-190_v1_34@3,The fact that eight were encountered and all exceeded published longevity estimates lends support to this assertion.,The fact that seven were encountered and all exceeded published longevity estimates lends support to this assertion.,"Modify,Fact/Evidence",Fact/Evidence
6964,3-190,3-190_v2_5@6,3-190_v1_5@6,"Based on tag-recapture data and direct age estimates, herein we report on the longevity of Atlantic Sharpnose Sharks Rhizoprionodon terraenovae (Richardson, 1836) and Blacknose Sharks Carcharhinus acronotus (Poey, 1860), both of which are common in the coastal waters off the southeastern United States.","Based on tag-recapture data and direct age estimates, herein we report on the longevity of Atlantic Sharpnose Rhizoprionodon terraenovae (Richardson, 1836) and Blacknose Carcharhinus acronotus (Poey, 1860) Sharks, both of which are common in the coastal waters off the southeastern United States.","Modify,Clarity",Clarity
6965,3-190,3-190_v2_2@1,3-190_v1_2@1,Time-at-liberty ranged from 7.7-14.0 years (mean =10.1) for R. terraenovae and 10.9-12.8 years (mean =11.9) for C. acronotus .,Time-at-liberty ranged from 7.7-12.1 years (mean =9.2) for R. terraenovae and 10.9-12.8 years (mean =11.9) for C. acronotus .,"Modify,Fact/Evidence",Fact/Evidence
6966,3-190,3-190_v2_9@1,3-190_v1_9@1,"In the case of recaptured specimens from SCDNR, a IACUC protocol approved for graduate students who had previously worked with SCDNR on elasmobranch studies was followed; the vertebral column was severed by serrated knife in two cervical locations.","In the case of recaptured specimens from SCDNR, a IACUC protocol approved for graduate students who had previously worked with SCDNR on elasmobranch studies was followed; the vertebral column was served by serrated knife in two cervical locations.","Modify,Grammar",Grammar
6967,3-190,3-190_v2_21@1,3-190_v1_21@0,Five R. terraenovae (four male and one female) were recaptured with times at liberty ranging from 7.7 to 14.0 years (mean ± S.D. = 10.1 ± 2.7).,Four R. terraenovae (three male and one female) were recaptured with times at liberty ranging from 7.7 to 12.1 years (mean ± S.D. = 9.2 ± 2.0).,"Modify,Fact/Evidence",Fact/Evidence
6968,3-190,3-190_v2_21@4,3-190_v1_21@3,Vertebrae were sampled from Shark L5242 and the direct age estimate from the vertebral section was 18.5 years old ( Figure 1 ).,Vertebrae were sampled from Shark L5242 and the direct age estimate from the vertebral section was 18.5 years old.,"Modify,Fact/Evidence",Fact/Evidence
6969,3-190,3-190_v2_21@6,3-190_v1_21@5,All five sharks were recaptured within 15 km of initial tagging.,All four sharks were recaptured within 15 km of initial tagging.,"Modify,Fact/Evidence",Fact/Evidence
6970,3-20,3-20_v2_71@11,,The response rate is not known because we do not know how many scientists actually read the invitation email and how many principal investigators forwarded the invitation to their lab members.,,"Add,Fact/Evidence",Fact/Evidence
6971,3-20,3-20_v2_71@12,,We used this approach because we wanted to maximize the sample size.,,"Add,Fact/Evidence",Fact/Evidence
6972,3-20,3-20_v2_71@13,,"By taking in consideration only the scientists that took part to the survey, the response rate was very high for all questions (on average, fewer than 2% of the respondents, with a range from 0% (Q2 and Q3) to 6.3% (Q15) skipped any of the 17 questions); this suggests that the survey did not contain difficult-to-understand or difficult-to-answer questions.",,"Add,Claim",Claim
6973,3-20,3-20_v2_71@14,,"Therefore the decision of participating (or not) in the survey was probably not based on the nature of the questions but rather on other factors (e.g. lack of time) that, conceivably, have only a marginal effect on the representativity of the sample.",,"Add,Claim",Claim
6974,3-20,3-20_v2_71@16,,"For these reasons, we believe that the sample of scientists that took part to this survey is fairly representative of the entire population of scientists working in the same setting (Harvard Medical School and affiliated institutes).",,"Add,Claim",Claim
6975,3-20,,3-20_v1_13@7,,The results of Q6 were therefore in agreement with the results of Q5.,"Delete,Fact/Evidence",Fact/Evidence
6976,3-20,,3-20_v1_16@0,,We also designed two questions (Q9 and Q10) to understand what should be the “goals” of biological and biomedical research according to the basic scientists.,"Delete,Fact/Evidence",Fact/Evidence
6977,3-20,,3-20_v1_32@0,,We also proposed two questions with the purpose to shed light on how scientists would improve current funding criteria.,"Delete,Fact/Evidence",Fact/Evidence
6978,3-20,,3-20_v1_46@4,,Indeed we believe that effective policies would be the ones that exploit the scientist’s drive to achieve a good reputation and a role in benefiting society.,"Delete,Claim",Claim
6979,3-20,,3-20_v1_7@0,,Assessing the societal impact of fundamental sciences is however more easily said than done.,"Delete,Claim",Claim
6980,3-20,,3-20_v1_7@1,,The topic is debated in the scientific and political communities <REF-9> .,"Delete,Fact/Evidence",Fact/Evidence
6981,3-20,3-20_v2_7@1,,The mindset has changed since the time when the isolation and self-referring of the scientific community was perceived in a positive way and when the concept of “scientific integrity” was equated with the concept of “social responsibility” <REF-12> – <REF-14> .,,"Add,Fact/Evidence",Fact/Evidence
6982,3-20,3-20_v2_7@2,,"Public support is no longer (or is much less) based on the myth of the “free play of free intellects” <REF-2> , <REF-12> , <REF-15> and the notion of “socially robust” knowledge has often replaced the notion of “reliable knowledge” <REF-16> , <REF-17> .",,"Add,Fact/Evidence",Fact/Evidence
6983,3-20,3-20_v2_7@3,,"Attention is now more often focused on whether public funding is used for socially beneficial activities <REF-11> , <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
6984,3-20,3-20_v2_7@4,,An increasing number of scholars and opinion leaders are proposing the training of “civic scientists” and the engagement of scientists in the public discourse <REF-19> – <REF-24> .,,"Add,Fact/Evidence",Fact/Evidence
6985,3-20,3-20_v2_7@8,,"However, some scholars think that the current system of peer reviewing and grant assignment stifles creativity and innovation <REF-6> , <REF-27> .",,"Add,Fact/Evidence",Fact/Evidence
6986,3-20,3-20_v2_8@4,,Studies on scientist’s views and values often focus on research misconduct <REF-29> – <REF-31> or on particular issues of specific biomedical fields <REF-32> – <REF-36> .,,"Add,Fact/Evidence",Fact/Evidence
6987,3-20,3-20_v2_8@5,,A few studies have collected feedback from scientists about social responsibility.,,"Add,Fact/Evidence",Fact/Evidence
6988,3-20,3-20_v2_8@6,,"Most of these studies were based on interviews and focus groups; in a few cases surveys were used to collect feedback about specific issues <REF-12> , <REF-37> – <REF-39> .",,"Add,Fact/Evidence",Fact/Evidence
6989,3-20,3-20_v2_8@7,,In this paper we expand upon the existing body of knowledge.,,"Add,Fact/Evidence",Fact/Evidence
6990,3-20,3-20_v2_8@8,,"We believe our study is the first based on a survey containing an extended set of multiple-choice and numerical questions aimed at quantitatively elucidating the motivations, values and opinions of a large group of basic researchers working in different fields of biomedicine.",,"Add,Claim",Claim
6991,3-20,3-20_v2_18@0,,What is the goal of biological and biomedical research?,,"Add,Other",Other
6992,3-20,,3-20_v1_11@6,,Q2 focused on gender.,"Delete,Fact/Evidence",Fact/Evidence
6993,3-20,3-20_v2_47@0,,Small differences between principal investigators and post-docs responses,,"Add,Other",Other
6994,3-20,3-20_v2_48@0,,"To determine if career stage impacted on the responses to the survey, we compared the answers of principal investigators with those of post-docs (see the two new files added to the Data Set) the two most represented groups in our sample.",,"Add,Fact/Evidence",Fact/Evidence
6995,3-20,,3-20_v1_11@8,,Q3 asked respondents to quantify the amount of their research time allocated to research that they consider to be “basic”.,"Delete,Fact/Evidence",Fact/Evidence
6996,3-20,3-20_v2_48@1,,We identified a few differences that are worth mentioning.,,"Add,Fact/Evidence",Fact/Evidence
6997,3-20,3-20_v2_49@0,,"Although the percentage of principal investigators and post-docs in agreement with the Q6 statement ( “Basic scientists can ponder about the future indirect practical benefits of their research without losing their “basic status”” ) were similar (96.7% and 94.3%, respectively), the percentage of principal investigators in “complete agreement” was substantially higher than post-docs (80.7% and 64.8%, respectively).",,"Add,Fact/Evidence",Fact/Evidence
6998,3-20,3-20_v2_50@0,,"For responses to (Q8) “YOUR personal motivations as a scientist are from” , on average principal investigators rated “gain of money (for personal purposes)” as less important than for post-docs (2.00 and 2.58, respectively), indicating that gain of money is a stronger motivator for researchers in the earlier stages of their career than for more senior researchers.",,"Add,Fact/Evidence",Fact/Evidence
6999,3-20,3-20_v2_50@1,,"Similarly (Q8), the rating average of “gain of prestige” for principal investigators was slightly lower than for post-docs (2.77 and 2.94, respectively), indicating that for younger researchers gain of prestige is a stronger motivator than for older researchers.",,"Add,Fact/Evidence",Fact/Evidence
7000,3-20,3-20_v2_51@0,,"When asked (Q9) “What should the most important goal of publicly funded basic BIOLOGICAL (not biomedical) research be?” the percent of principal investigators that indicated “health benefit to society (not necessarily in the near future)” was appreciably lower than the share of post-docs (18.1% and 25.0%, respectively).",,"Add,Fact/Evidence",Fact/Evidence
7001,3-20,3-20_v2_51@1,,"Similarly, when asked (Q10) “What should the most important goal of publicly funded basic BIOMEDICAL research be?” the percent of principal investigators that indicated “health benefit to society (not necessarily in the near future)” was lower than the percent of post-docs (81.0% and 86.3%, respectively).",,"Add,Fact/Evidence",Fact/Evidence
7002,3-20,3-20_v2_52@0,,"The percent of principal investigators in agreement with the following statement (Q13) “Written proposals about basic biological/biomedical research generally contain a section discussing potential future health benefits. These sections increase the likelihood that a project benefits public health” was much lower than the share of post-docs (36.6% and 58.8%, respectively) ( Figure S5 ).",,"Add,Fact/Evidence",Fact/Evidence
7003,3-20,3-20_v2_53@0,,"When asked (Q14) “What percentage of public funding should be allocated to basic biological/biomedical research proposals in which discussing the potential of future health benefits to society is not required?” principal investigators and post-docs indicated 44.4% and 40.4%, respectively.",,"Add,Fact/Evidence",Fact/Evidence
7004,3-20,3-20_v2_53@1,,"Consistent with this, when asked (Q15) “With regard to basic biological/biomedical research proposals in which discussing the potential of future health benefits to society is required, what average weight should be given to this potential in assigning scores for funding decisions?” principal investigators and post-docs indicated 31.1% and 39.3%, respectively.",,"Add,Fact/Evidence",Fact/Evidence
7005,3-20,3-20_v2_53@2,,Therefore the principal investigators are even move in favor than the post-docs in reducing the extent and the weight of discussions of the future health benefits in research proposals.,,"Add,Claim",Claim
7006,3-20,3-20_v2_54@0,,"Finally, the percent of post-docs in agreement with the use of motivational incentives (Q17) was higher than the percent of principal investigators, both for financial incentives (75.2% and 51.7%, respectively) and for non-financial incentives (71.0% and 67.8%, respectively).",,"Add,Fact/Evidence",Fact/Evidence
7007,3-20,3-20_v2_59@1,,"Policies that could be particularly effective are the ones that exploit the scientist’s drive to both achieve a good reputation and to benefit society <REF-14> , <REF-40> .",,"Add,Fact/Evidence",Fact/Evidence
7008,3-20,3-20_v2_62@1,,It would probably be wise to keep these meetings non-mandatory and conceive of ways to recognize the participating scientists (e.g. with certificates).,,"Add,Claim",Claim
7009,3-20,3-20_v2_62@2,,This incentive would fit with the increasing interest in blurring the boundaries between the scientific community and the general public discussed above <REF-21> – <REF-23> .,,"Add,Fact/Evidence",Fact/Evidence
7010,3-20,3-20_v2_62@4,,"Although non-mandatory, attendance could result in some form of credit or recognition for participation.",,"Add,Claim",Claim
7011,3-20,3-20_v2_62@5,,Another soft incentive could be provided by the presence of ethics consultation offices inside research institutes; a previous study found that most scientists view such a proposal favourably <REF-37> .,,"Add,Fact/Evidence",Fact/Evidence
7012,3-20,3-20_v2_63@5,,"Scientists would receive satisfaction from seeing their work in the list of seminal papers crucial for the design of a new drug, by perceiving their active role in public health improvement and by posting the achievement on their curriculum vitae or personal website.",,"Add,Claim",Claim
7013,3-20,3-20_v2_64@6,,"This division of basic research would be similar to the previously proposed division between “pure basic research” (also represented as the “Bohr’s quadrant” as exemplified by the work of the atomic physicist Niels Bohr) and “use-inspired basic research” (also represented as the “Pasteur’s quadrant” as exemplified by the work of the biologist Louis Pasteur) <REF-11> , <REF-43> .",,"Add,Fact/Evidence",Fact/Evidence
7014,3-20,3-20_v2_64@8,,Such a mindset would hopefully result in more basic scientists (especially younger ones) pondering the purpose of their research and being inspired by basic research avenues that are “use-inspired”.,,"Add,Claim",Claim
7015,3-20,,3-20_v1_13@1,,"To this purpose, we asked a few questions to define the concept and goals of basic research.","Delete,Fact/Evidence",Fact/Evidence
7016,3-20,3-20_v2_65@4,,"Of course, it will also be important to estimate in the best possible way and, case by case, the degree (i.e. possibility) of assessment of the transformative value, as an overestimation of our ability to assess the transformative value of research projects could have negative effects on both innovation potential and scientist satisfaction.",,"Add,Claim",Claim
7017,3-20,3-20_v2_65@5,,"Plausibly, future study and discussion will shed more light on these concepts and increase our ability to assess the social potential of fundamental investigations.",,"Add,Claim",Claim
7018,3-20,3-20_v2_66@0,,Our survey results show that basic scientists think that the major goal of biomedical research (and one of their highest motivations) is providing health benefits to society (even if not necessarily in the near future).,,"Add,Fact/Evidence",Fact/Evidence
7019,3-20,3-20_v2_66@1,,The large majority of respondents were in favor of using soft incentives to increase the health benefit potential of basic biological/biomedical research.,,"Add,Fact/Evidence",Fact/Evidence
7020,3-20,3-20_v2_66@2,,"The use of “nudges” seems to be particularly promising with the basic scientists at the earlier stages of their career; compared to principal investigators post-docs are more likely to think that the major goal of basic biological and biomedical research is to provide health benefits to society, are even more driven by prestige and financial motivations and are even more in favor of the use of soft incentives.",,"Add,Fact/Evidence",Fact/Evidence
7021,3-20,3-20_v2_66@3,,"This suggests that in the near future even more scientists will be suitable for soft motivational incentives, even if we cannot exclude that current younger scientists will slightly change their perspectives and values when they reach more advanced stages in their career.",,"Add,Claim",Claim
7022,3-20,3-20_v2_66@4,,"Even so, most principal investigators are also in favor of using soft incentives (especially non-financial ones) and are dissatisfied (substantially more so than the post-docs ( Figure S5 )) with the current policies requiring the assessment of potential health benefit.",,"Add,Fact/Evidence",Fact/Evidence
7023,3-20,3-20_v2_67@0,,Our study has various limitations.,,"Add,Claim",Claim
7024,3-20,3-20_v2_67@1,,"For example, it may not be generalizable, since it involves only scientists working at Harvard Medical School and affiliated Boston-area institutions.",,"Add,Claim",Claim
7025,3-20,3-20_v2_67@2,,"For this reason, it would be useful to sample other scientific communities (i.e. those operating in different geographical and cultural contexts).",,"Add,Claim",Claim
7026,3-20,3-20_v2_67@3,,"Moreover, in order to implement effective incentives, it would be important to analyze in depth the scientist’s perception about the specific policies ( Box 1 ).",,"Add,Claim",Claim
7027,3-20,3-20_v2_67@4,,"Furthermore, it would be strategic to collect more data to coordinate the implementation of these incentives with the improvement of current policies regulating research evaluation and funding assignments.",,"Add,Claim",Claim
7028,3-20,,3-20_v1_13@3,,"Survey participants had four options to choose: complete agreement, some agreement, some disagreement and complete disagreement.","Delete,Fact/Evidence",Fact/Evidence
7029,3-20,3-20_v2_15@3,3-20_v1_13@5,A complementary question (Q6) asked about the level of agreement with the following: “basic scientists can ponder about the future indirect practical benefits of their research without losing their “basic status”” .,"To corroborate the responses of Q5, we designed a complementary question (Q6) to determine the level of agreement on the following: “ basic scientists can ponder about the future indirect practical benefits of their research without losing their “basic status ””.","Modify,Clarity",Clarity
7030,3-20,3-20_v2_2@6,3-20_v1_2@6,"After discussing the findings, we discuss a few examples of nudges for basic researchers in the biomedical fields.","After discussing the findings, we suggest a few examples of nudges and discuss one in more detail.","Modify,Clarity",Clarity
7031,3-20,3-20_v2_15@5,3-20_v1_17@0,These results indicate that most scientists surveyed think that considering the indirect practical outcome of basic scientific investigations is compatible with the notion of basic research.,"Thus, these results clearly indicate that most scientists think that considering the indirect practical outcome of basic scientific investigations is compatible with the notion of basic research.","Modify,Clarity",Clarity
7032,3-20,3-20_v2_19@2,3-20_v1_17@2,"These results suggest that the scientists surveyed perceive the primary goals of “biological research” and “biomedical research” to be different, with a propensity to include “pure advancement of knowledge” as an important goal of “biological” research only.","Furthermore, these results suggest that scientists perceive the goals of “biological research” and “biomedical research” to be different, with a propensity to include health benefit to society as an important goal of biomedical research only.","Modify,Clarity",Clarity
7033,3-20,3-20_v2_23@3,3-20_v1_19@3,The rating average was then calculated by assigning a score from 1 to 5 to these options.,"The rating average was then calculated after assigning a score from 1 to 5, to these five options.","Modify,Clarity",Clarity
7034,3-20,3-20_v2_23@4,3-20_v1_19@4,Scientists were asked to provide feedback on (Q7) “the motivations of most basic biological/biomedical scientists are from:” .,Scientists were therefore asked to provide feedback on the following (Q7) “ the motivations of most basic biological/biomedical scientists are from: ”.,"Modify,Clarity",Clarity
7035,3-20,3-20_v2_23@6,3-20_v1_19@6,The rating for “health benefit to society (not necessarily in the near future)” was 3.93.,The rating average for “health benefit to society (not necessarily in the near future)” was 3.93.,"Modify,Clarity",Clarity
7036,3-20,3-20_v2_23@7,3-20_v1_19@7,The rating for “gain of prestige” was 3.43.,The rating average for “gain of prestige” was 3.43.,"Modify,Clarity",Clarity
7037,3-20,3-20_v2_23@8,3-20_v1_19@8,The rating for “gain of money” was 2.42.,The rating average for “gain of money” was 2.42.,"Modify,Clarity",Clarity
7038,3-20,3-20_v2_23@9,3-20_v1_19@9,The rating for “satisfaction of their curiosity” was 4.24.,The rating average for “satisfaction of their curiosity” was 4.24.,"Modify,Clarity",Clarity
7039,3-20,3-20_v2_26@0,3-20_v1_22@0,"To see if scientists perceive themselves differently from other scientists, we also asked respondents to provide feedback on the following input (Q8): “YOUR personal motivations as a scientist are from:”.","To see if scientists perceive themselves differently from other scientists, we also asked respondents to provide feedback on the following input (Q8): “ YOUR personal motivations as a scientist are from: ”.","Modify,Grammar",Grammar
7040,3-20,3-20_v2_26@1,3-20_v1_22@1,"The rating for “pure advancement of knowledge, regardless of future applicability” was 3.82.","The rating average for “pure advancement of knowledge, regardless of future applicability” was 3.82.","Modify,Clarity",Clarity
7041,3-20,3-20_v2_26@2,3-20_v1_22@2,The rating for “health benefit to society (not necessarily in the near future)” was 4.32.,The rating average for “health benefit to society (not necessarily in the near future)” was 4.32.,"Modify,Clarity",Clarity
7042,3-20,3-20_v2_26@3,3-20_v1_22@3,The rating for “gain of prestige” was 2.79.,The rating average for “gain of prestige” was 2.79.,"Modify,Clarity",Clarity
7043,3-20,3-20_v2_26@4,3-20_v1_22@4,The rating for “gain of money” was 2.29.,The rating average for “gain of money” was 2.29.,"Modify,Clarity",Clarity
7044,3-20,3-20_v2_26@5,3-20_v1_22@5,The rating for “satisfaction of their curiosity” was 4.18.,The rating average for “satisfaction of their curiosity” was 4.18.,"Modify,Clarity",Clarity
7045,3-20,3-20_v2_26@6,3-20_v1_22@6,The rating for “satisfaction from solving puzzling problems” was 4.16 ( Figure 3B ).,The rating average for “satisfaction from solving puzzling problems” was 4.16 ( Figure 2B ).,"Modify,Clarity",Clarity
7046,3-20,3-20_v2_26@8,3-20_v1_22@8,"Moreover, these results show that scientists perceive themselves as more motivated by the pursuit of “health benefit to society (not necessarily in the near future)” and less motivated from the “gain of prestige” and “gain of money” than other scientists.","Moreover, these results show that scientists perceive themselves as more motivated by the pursuit of “health benefit to society (not necessarily in the near future)” and less motivated from the “gain of prestige” and “gain of money” than the average scientist.","Modify,Clarity",Clarity
7047,3-20,3-20_v2_27@0,3-20_v1_23@0,Most basic scientists believe it is possible to estimate the potential future health benefits to society from basic biological/biomedical research,Most basic scientists think that estimating the potential future health benefits to society from basic biological/biomedical research is possible,"Modify,Clarity",Clarity
7048,3-20,3-20_v2_28@0,3-20_v1_24@0,"To design policies to increase the practical impact of basic biomedical/biological research, it is important to understand whether estimating the health benefit potential of basic research is possible, a topic that has being debated for many years <REF-11> , <REF-27> .","To design policies to increase the practical impact of basic biomedical/biological research, it is first important to understand whether estimating the health benefit potential of basic research is in any way feasible, a topic that has being debated for many years <REF-9> .","Modify,Fact/Evidence",Fact/Evidence
7049,3-20,3-20_v2_28@1,3-20_v1_24@1,We asked respondents to express their level of agreement on scientists’ ability to estimate the potential future health benefits at different stages of the research process.,We gathered feedback on this issue by asking respondents to express their level of agreement on scientists’ ability to estimate the potential future health benefits at different stages of the research process.,"Modify,Clarity",Clarity
7050,3-20,3-20_v2_28@2,3-20_v1_24@2,"Q11 stated: “Although it is difficult to assess the potential future health benefits to society from basic biological/biomedical research as described in written PROPOSALS, some degree of estimation is always possible”.","Q11 stated: “ Although it is difficult to assess the potential future health benefits to society from basic biological/biomedical research as described in written PROPOSALS, some degree of estimation is always possible ”.","Modify,Grammar",Grammar
7051,3-20,3-20_v2_31@0,3-20_v1_27@0,"Q12 stated: “Although it is difficult to assess the potential future health benefits to society from the RESULTS and FINDINGS of basic biological/biomedical research, some degree of estimation is always possible”.","Q12 stated: “ Although it is difficult to assess the potential future health benefits to society from the RESULTS and FINDINGS of basic biological/biomedical research, some degree of estimation is always possible ”.","Modify,Grammar",Grammar
7052,3-20,3-20_v2_31@2,3-20_v1_27@2,These results therefore show that the majority (83%) of the surveyed scientists believe that estimating the future health benefits to society from the proposals or outcome of basic biological/biomedical projects is somewhat feasible.,These results therefore show that the majority (83%) of the surveyed scientists think that estimating the future health benefits to society from the proposals or outcome of basic biological/biomedical projects is realistically feasible.,"Modify,Clarity",Clarity
7053,3-20,3-20_v2_32@0,3-20_v1_28@0,Most basic scientists believe that the discussion of potential medical benefits in basic research proposals is not useful and should be decreased,Most basic scientists think that the discussion of potential medical benefits in basic research proposals is not useful,"Modify,Claim",Claim
7054,3-20,3-20_v2_33@1,3-20_v1_29@1,"To understand what scientists think about this restrictive (i.e. non voluntary) policy, Q13 asked respondents to express their level of agreement with the following statement: “Written proposals about basic biological/biomedical research generally contain a section discussing potential future health benefits. These sections increase the likelihood that a project benefits future public health”.","In order to understand what scientists think about this requirement, Q13 asked respondents to express their level of agreement in the following statement: “ Written proposals about basic biological/biomedical research generally contain a section discussing potential future health benefits. These sections increase the likelihood that a project benefits future public health ”.","Modify,Fact/Evidence",Fact/Evidence
7055,3-20,3-20_v2_2@0,3-20_v1_2@0,Basic research in the biomedical field generates both knowledge that has a value per se regardless of its possible practical outcome and knowledge that has the potential to produce more practical benefits.,Basic research in the biomedical field generates both knowledge that has a value per se regardless of its possible practical outcome and that has the potential to produce more practical benefits.,"Modify,Clarity",Clarity
7056,3-20,3-20_v2_33@7,3-20_v1_33@1,"Thus, the majority of respondents believe that discussing the potential future health benefits in basic research proposals is not an effective way to increase the likelihood that a project benefits future public health.","Thus, this set of results indicates that the majority of scientists think that discussing the potential future health benefits in basic research proposals is not an effective way to increase the likelihood that a project benefits future public health.","Modify,Clarity",Clarity
7057,3-20,3-20_v2_33@8,3-20_v1_33@2,"Principal investigators were substantially more in disagreement than post-docs (63.4% and 41.2%, respectively) with regard to the effectiveness of this policy in increasing societal benefits ( Figure S5 ).","Interestingly, we noticed that principal investigators were significantly more in disagreement than post-docs (63.4% and 41.2%, respectively) with regard to the effectiveness of this policy in increasing societal benefits ( Figure S5 ).","Modify,Clarity",Clarity
7058,3-20,3-20_v2_33@9,3-20_v1_33@3,"Moreover, these scientists believe that a considerable proportion of public funding (41.6%) should be allocated to research proposals in which discussing the future health benefits to society is not required.","Moreover, scientists believe that a considerable proportion of public funding (41.6%) should be allocated to research proposals in which discussing the future health benefits to society is not required.","Modify,Clarity",Clarity
7059,3-20,3-20_v2_39@0,3-20_v1_35@0,"In order to understand if scientists believe that motivational incentives could be more effective than stricter policies (such as the mandatory discussion of the potential medical benefits in research proposals), we asked (Q16) scientists to express the level of agreement with the following statement: “Motivational INCENTIVES, which are not based on restrictive policies such as the requirement to discuss the potential of future health benefits, CAN increase the degree to which basic biological/biomedical research is likely to benefit the future health of society”.","In order to understand if scientists believe that motivational incentives could be more effective than stricter policies (such as the mandatory discussion of the potential medical benefits in research proposals), we asked (Q16) scientists to express the level of agreement on the following statement: “ Motivational INCENTIVES, which are not based on restrictive policies such as the requirement to discuss the potential of future health benefits, CAN increase the degree to which basic biological/biomedical research is likely to benefit the future health of society ”.","Modify,Grammar",Grammar
7060,3-20,3-20_v2_42@0,3-20_v1_38@0,"To understand if motivational incentives should be implemented and used, we asked respondents (Q17) to express the level of agreement on the following slightly different statement: “Motivational INCENTIVES, either “in addition to” or “in substitution of” restrictive policies, SHOULD be used to increase the degree to which basic biological/biomedical research is likely to benefit the future health of society”.","To understand if motivational incentives should be implemented and used, we also asked respondents (Q17) to express the level of agreement on the following slightly different statement: “ Motivational INCENTIVES, either “in addition to” or “in substitution of” restrictive policies, SHOULD be used to increase the degree to which basic biological/biomedical research is likely to benefit the future health of society ”.","Modify,Grammar",Grammar
7061,3-20,3-20_v2_5@4,3-20_v1_5@4,"Although it often takes decades to develop, the applied outputs of knowledge advancement (e.g. drugs) have at their roots countless basic investigations <REF-2> .","Although it often takes decades to develop, the applied outputs of knowledge advancement (e.g. drugs) have at their roots countless basic investigations.","Modify,Fact/Evidence",Fact/Evidence
7062,3-20,3-20_v2_43@0,3-20_v1_38@3,These results suggest that most responding scientists are in favor of motivational incentives (either financial or non-financial) to be used either “in addition to” or “in substitution of” more restrictive policies to increase the public health potential of basic biological/biomedical research.,"Thus, these results suggest that the vast majority of basic scientists are in favor of motivational incentives (either financial or non-financial) to be used either “in addition to” or “in substitution of” more restrictive policies to increase the public health potential of basic biological/biomedical research.","Modify,Clarity",Clarity
7063,3-20,3-20_v2_45@0,3-20_v1_40@0,The majority of the scientists who participated in the survey indicated that the most important goal of publicly funded basic “biomedical” research is the production of health benefits to society (86%) ( Figure 2B ) and that the desire to effectively benefit society is an important or very important motivation for most of them (87%) ( Figure 3B ).,The majority of the scientists who participated in the survey indicated that the most important goal of publicly funded basic biomedical research is the production of health benefits to the society (86%) ( Figure 1D ) and that the desire to effectively benefit society is an important or very important motivation for most of them (87%) ( Figure 2B ).,"Modify,Grammar",Grammar
7064,3-20,3-20_v2_45@2,3-20_v1_40@2,"Further, they indicated that, ideally, more than half of public funding should be allocated to proposals in which a discussion of the potential future health benefits to society is required ( Figure 6A ).","Further, they indicated that, ideally, more than half of public funding should be allocated to proposals in which a discussion of the potential future health benefits to society is required.","Modify,Fact/Evidence",Fact/Evidence
7065,3-20,3-20_v2_46@0,3-20_v1_41@0,"Our survey also sheds a light on scientists’ other motivations, besides contributing to the health of society.",Our data also shed a light on scientists’ motivations (besides contributing to health benefit to society).,"Modify,Clarity",Clarity
7066,3-20,3-20_v2_46@1,3-20_v1_41@1,Such information is useful for the design of incentive-based policies.,This information is useful to design incentive-based policies.,"Modify,Clarity",Clarity
7067,3-20,3-20_v2_46@3,3-20_v1_41@3,The so-called “ribbon-motivation”—the gain of prestige and recognition—was substantially more important than the gain of personal money (among our respondents 60% said that the “gain of prestige” was a “moderately” to “very important” motivation for them compared to 41% who said the same for the “gain of money”) ( Figure 3B ).,The so-called “ribbon-motivation”—the gain of prestige and recognition—was significantly more important than the gain of personal money (among our respondents 60% said that the “gain of prestige” was a “moderately” to “very important” motivation for them compared to 41% who said the same for the “gain of money”) ( Figure 2B ).,"Modify,Clarity",Clarity
7068,3-20,3-20_v2_6@1,3-20_v1_6@1,"This was particularly true in the decades that followed World War II during which basic research went through a “golden age,” being conducted primarily in research universities and paid for with public money <REF-5> .","This was particularly true in the decades that followed World War II and during which basic research went through a “golden age,” being conducted primarily in research universities and paid for with public money <REF-4> .","Modify,Grammar",Grammar
7069,3-20,3-20_v2_56@0,3-20_v1_43@0,The results of this survey provide valuable information to help create effective policies to increase the health benefit potential of basic biological and biomedical research and the work satisfaction of scientists without altering the nature and volume of scientific investigations (schematized in Figure 8 ).,The results of this survey provide valuable information to help conceive new effective policies to increase both the health benefit potential of basic biological and biomedical research and the work satisfaction of scientists without altering the nature and volume of scientific investigations (schematized in Figure 6 ).,"Modify,Clarity",Clarity
7070,3-20,3-20_v2_56@1,3-20_v1_43@1,"Building on these results, we conclude that nonfinancial soft incentives (nudges), in particular, could be valuable tools to maximize the transformative value of basic research.","Building on these results, we conclude that nonfinancial soft incentives (nudges), in particular, are perceived as valuable tools to maximize the transformative value of basic research as they would not entail much work for scientists and can be implemented without significantly increasing public spending and bureaucratic burden.","Split+Modify,Clarity",Clarity
7071,3-20,3-20_v2_56@2,3-20_v1_43@1,Creative nudges should entail little additional work for scientists and can be implemented without significantly increasing public spending and bureaucratic burden.,"Building on these results, we conclude that nonfinancial soft incentives (nudges), in particular, are perceived as valuable tools to maximize the transformative value of basic research as they would not entail much work for scientists and can be implemented without significantly increasing public spending and bureaucratic burden.","Split+Modify,Clarity",Clarity
7072,3-20,3-20_v2_56@3,3-20_v1_43@2,We also believe that soft incentives would be a valuable departure from some current policies which seem ineffective.,"We also believe that soft incentives would be a valuable departure from current policies, which according to the scientists surveyed in our study, are ineffective.","Modify,Claim",Claim
7073,3-20,3-20_v2_56@4,3-20_v1_43@3,"For example, while 92% of respondents indicated that they are in favor of an increase in public funding for basic biological/biomedical research ( Figure S4 ), a substantial majority of the principal investigators (63%) ( Figure S5 ) declared that the sections in written proposals aimed at discussing the potential future health benefits do not really increase the likelihood that a project will benefit future public health.","Indeed, despite 92% of respondents indicating that they are in favor of an increase in public funding for basic biological/biomedical research ( Figure S4 ), a significant majority of the principal investigators (63%) ( Figure S5 ) declared that the sections in written proposals aimed at discussing the potential future health benefits do not really increase the likelihood that a project will benefit future public health.","Modify,Clarity",Clarity
7074,3-20,3-20_v2_56@5,3-20_v1_43@4,Our respondents also claimed that more public funding (on average the 42% of the total public funding committed to basic biological/biomedical research) should be devoted to basic biological/biomedical research proposals in which discussing the potential of future health benefits is not required ( Figure 6A ).,Scientists also claimed that more public funding (on average the 42% of the total public funding committed to basic biological/biomedical research) should be devoted to basic biological/biomedical research proposals in which discussing the potential of future health benefits is not required ( Figure 4B ).,"Modify,Clarity",Clarity
7075,3-20,3-20_v2_59@2,3-20_v1_46@1,"One example would be placing research laboratories inside or in close proximity to hospitals to expose basic scientists to the view of patients and practicing physicians; in this regard it would be useful to know if scientists already working in laboratories inside hospitals have different views, motivations and values than those working in comparable laboratories located far away from hospitals.",One example would be placing research laboratories in the proximity of hospitals to expose basic scientists to the view of patients and practicing physicians.,"Modify,Claim",Claim
7076,3-20,3-20_v2_62@0,3-20_v1_46@2,Another example would be organizing more educational meetings in which scientists explain their work to the general public or to associations of patients.,Another one would be organizing more (non-mandatory) educational meetings in which scientists explain their work to the general public or to associations of patients (giving credit to the participating scientists).,"Modify,Claim",Claim
7077,3-20,3-20_v2_62@3,3-20_v1_46@3,A similar nudge would be organizing periodical seminars inside research institutions during which scientists could discuss the role of scientific research and scientists in society.,A similar proposal would be organizing periodical seminars inside research institutions to discuss the role of scientific research and scientists in society.,"Modify,Clarity",Clarity
7078,3-20,3-20_v2_63@0,3-20_v1_49@0,"A model of an incentive that exploits the scientist’s aspiration to achieve a good reputation and a role in benefiting public health would be to formally recognize the basic scientists when new drugs or medical devices are approved, as we recently proposed <REF-41> .","A model of such an incentive would be to formally recognize the basic scientists when new drugs or medical devices are approved, as we recently proposed <REF-14> .","Modify,Claim",Claim
7079,3-20,3-20_v2_63@3,3-20_v1_49@3,"To apply this idea, a peer review group would identify the basic papers that have been influential for the development in the drug (or other biological applications) or, alternatively, review a list proposed by the drug owner <REF-41> .","To apply this idea, a peer review group would identify the basic papers that have been influential for the development of the drug (or other biological applications) or, alternatively, review a list proposed by the drug owner <REF-14> .","Modify,Grammar",Grammar
7080,3-20,3-20_v2_63@4,3-20_v1_49@4,A list of fifty to one hundred basic research papers would be selected and appear in the public databases (like the Orange Book of FDA) and in the drug package.,A list of fifty to one hundred basic research papers would be selected and appear in the public databases (such as the Orange Book of the FDA) and in the drug package.,"Modify,Clarity",Clarity
7081,3-20,3-20_v2_6@4,3-20_v1_6@4,"For instance, in the United States, National Institutes of Health (NIH) funding has been nearly stationary since 2003 in the face of rapid expansion (as increased amount of research activity) of existing biomedical fields and the emergence of new ones <REF-1> , <REF-6> .","For instance, in the United States, National Institutes of Health (NIH) funding has been nearly stationary since 2003 in the face of rapid expansion of research activity in existing biomedical fields and the emergence of new ones <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
7082,3-20,3-20_v2_63@6,3-20_v1_49@5,"This system would be a “weak attractor” because it would not distract scientists from basic research but it would represent a small, mostly unconscious, incentive to pursue research lines that can more easily lead to future drugs and should not create imbalances in the system by pushing basic scientists towards non-basic investigations.","This system would be a “weak attractor” because it would not distract scientists from basic research but it would represent a small, mostly unconscious, incentive to pursue research lines that can more easily lead to future drugs.","Modify,Claim",Claim
7083,3-20,3-20_v2_63@7,3-20_v1_49@6,"Therefore this system would not dramatically affect the whole ""ecosystem"" of the scientific research that indeed needs to be made of a balanced mix of the different types of research, from the ""purely"" basic to the ""purely"" applied ( Figure 8 ).","Therefore this system would not dramatically affect the whole “ecosystem” of the scientific research that indeed needs to be made of a balanced mix of the different types of research, from the “purely” basic to the “purely” applied ( Figure 6 ).","Modify,Grammar",Grammar
7084,3-20,3-20_v2_65@0,3-20_v1_50@7,"We also need to revisit the claim that because the future benefits of basic research cannot be accurately predicted, all basic research is equally valuable, i.e. every imaginable basic investigation would have the same exact potential of practical outcome.","Along these lines, we must also revisit the idea that since the future benefits of basic research cannot be accurately predicted, all basic research is equally valuable, i.e. every imaginable basic investigation would have the same exact potential of practical outcome.","Modify,Clarity",Clarity
7085,3-20,3-20_v2_65@2,3-20_v1_50@9,"It follows that since the potential benefits for society are somewhat predictable, basic research can be evaluated prospectively; this does not lessen the “basic status” neither of the research nor of the scientist.","It follows that since the potential benefits for society are roughly predictable, basic research can be evaluated prospectively; this does not lessen the “basic status” of either the research or the scientist.","Modify,Clarity",Clarity
7086,3-20,3-20_v2_68@3,3-20_v1_51@3,"We believe, and the data presented in the paper support, that soft incentives can be valuable tools for increasing this potential without corrupting the spirit of fundamental investigations, thus further aligning the goals of cell and molecular biologists with those of the broader public health community.","We believe, and the data presented in the paper support, the idea that soft incentives can be valuable tools for increasing this potential without corrupting the spirit of fundamental investigations, thus further aligning the goals of cell and molecular biologists with those of the broader public health community.","Modify,Clarity",Clarity
7087,3-20,3-20_v2_70@1,3-20_v1_53@1,"The IRB made the following determinations: Research Information Security Level; the research is classified, using Harvard’s Data Security Policy, as Level 1 data.","The IRB made the following determinations: Research Information Security Level; the research is classified, using Harvard's Data Security Policy, as Level 1 data.","Modify,Grammar",Grammar
7088,3-20,3-20_v2_71@0,3-20_v1_54@0,"The survey was designed as an online questionnaire (powered by SurveyMonkey, www.surveymonkey.com ) made of 17 questions (Q1–Q17) plus one additional field for free comments (separate manuscript, submitted and under revision).","The survey was designed as an online questionnaire (powered by SurveyMonkey, www.surveymonkey.com ) made of 17 questions (Q1–Q17) plus one additional field for free comments.","Modify,Fact/Evidence",Fact/Evidence
7089,3-20,3-20_v2_71@2,3-20_v1_54@2,Each question had the option to be skipped.,Each single question had the option to be skipped.,"Modify,Clarity",Clarity
7090,3-20,3-20_v2_71@5,3-20_v1_54@5,The responses were collected during 9 consecutive weeks during 2012.,The responses were collected during 9 consecutive weeks during 2012 (end of April to the end of June).,"Modify,Fact/Evidence",Fact/Evidence
7091,3-20,3-20_v2_7@0,3-20_v1_6@7,Nowadays basic researchers are said to owe a moral duty to extract maximum transformative value (the potential to translate in novel and fruitful applied research) whenever their research is publicly funded <REF-9> – <REF-11> .,"Furthermore, basic researchers are said to owe a moral duty to extract maximum transformative value (the potential to translate into novel and fruitful applied research) whenever their research is publicly funded <REF-7> , <REF-8> .","Modify,Clarity",Clarity
7093,3-20,3-20_v2_71@15,3-20_v1_54@10,"Moreover, the survey was completely anonymous.",The survey was completely voluntary and anonymous.,"Split+Modify,Clarity",Clarity
7094,3-20,3-20_v2_7@7,3-20_v1_6@8,"Funding agencies such as the NIH, in order to assess and increase the transformative value of research, require the discussion of the health benefit potential or (social) “significance” of proposed research when assigning resources.","In an effort to maximize transformative value of research, funding agencies like the NIH already take in some consideration the health benefit potential or (social) “significance” of a research proposal when assigning resources.","Modify,Clarity",Clarity
7095,3-20,3-20_v2_7@5,3-20_v1_7@2,Specific policies have been designed with the purpose of increasing the practical output of basic academic research.,Some policies already try to achieve this goal.,"Modify,Claim",Claim
7096,3-20,3-20_v2_7@6,3-20_v1_7@3,"For example, the Bayh-Dole Act gives US universities the possibility to own their own inventions but it also raises concerns as to whether the monetary incentives are too strong and therefore distract basic scientists from focusing on fundamental questions <REF-25> , <REF-26> .","Those based on strong financial incentives, such as the Bayh-Dole Act in the United States are already being used but they raise concerns as to whether monetary incentives distract basic scientists from focusing on fundamental questions <REF-10> , <REF-11> .","Modify,Fact/Evidence",Fact/Evidence
7097,3-20,3-20_v2_8@0,3-20_v1_7@4,New strategies to successfully maximize the transformative value of basic research without compromising the nature of fundamental inquiries and the scientist’s creativity (and satisfaction) are needed.,New strategies to successfully maximize the transformative value of basic research without compromising the nature of fundamental inquiries are certainly needed.,"Modify,Claim",Claim
7098,3-20,3-20_v2_8@1,3-20_v1_7@5,"Softer incentives, not based on restrictive policies, which are often called by behavioral economists “nudges” <REF-28> , seem particularly promising.","Softer incentives, which are called by behavioral economists “nudges” <REF-12> , seem particularly promising as they have been successfully used in public health but not yet in basic research.","Modify,Claim",Claim
7099,3-20,3-20_v2_8@3,3-20_v1_7@7,"However, these “nudges” can be designed well for basic research only if we have a good grasp of what motivates basic scientists, what their values are and the intellectual frameworks in which they operate so that soft incentives can be properly tailored.","However, these “nudges” can be designed well for basic research only if we have a good grasp of what motivates the basic scientists, what their values are and the intellectual frameworks in which they operate so that the proper soft incentives can be tailored around the particular characteristics of basic scientists.","Modify,Claim",Claim
7100,3-20,3-20_v2_8@9,3-20_v1_8@0,"Data come from the responses of more than 300 basic scientists at Harvard Medical School and affiliated institutions in Boston and Cambridge, Massachusetts (USA).","In an effort to improve our understanding of basic scientists’ motivations, we designed a study to collect data from basic scientists at Harvard Medical School and affiliated institutions.","Merge+Modify,Fact/Evidence",Fact/Evidence
7101,3-20,3-20_v2_8@9,3-20_v1_8@1,"Data come from the responses of more than 300 basic scientists at Harvard Medical School and affiliated institutions in Boston and Cambridge, Massachusetts (USA).",We designed a survey that was filled out by more than 300 scientists.,"Merge+Modify,Clarity",Clarity
7102,3-20,3-20_v2_9@0,3-20_v1_8@2,"In this paper, we present the results of the survey and discuss how our findings can be used to increase the transformative value of basic biomedical research without decreasing the motivations and freedom of the scientists.","In the next sections, we present the results of this study and a discussion on how these findings can be used to increase the transformative value of basic biomedical research without decreasing the “basic” nature of these investigations and the motivations and freedom of the scientists.","Modify,Claim",Claim
7103,3-20,3-20_v2_9@1,3-20_v1_8@3,We provide examples of specific nudges that might increase the social benefit without decreasing the “basic” nature of the scientific investigations.,"Finally, we suggest a few examples of nudges and discuss one in more detail.","Modify,Fact/Evidence",Fact/Evidence
7104,3-20,3-20_v2_12@0,3-20_v1_11@0,The survey was an online questionnaire comprised of 17 questions (Q1–Q17).,The survey was designed as an online questionnaire comprised of 17 questions (Q1–Q17).,"Modify,Clarity",Clarity
7105,3-20,3-20_v2_13@0,3-20_v1_11@5,"The first question (Q1) (all questions hereinafter will be referred to as Q#) aimed at identifying the respondent’s academic position: 39.9% were principal investigators, 34.7% post-docs, 10.6% PhD students and 14.9% belonged to other categories (including “research assistants” and “research technicians”) ( Figure S1 ).","The first question (Q1) (all questions hereinafter will be referred to as Q#) aimed at identifying the respondent’s academic position: 39.9% declared themselves to be principal investigators, 34.7% to be post-docs, 10.6% to be PhD students and 14.9% to belong to other categories (including “research assistants” and “research technicians”) ( Figure S1 ).","Modify,Clarity",Clarity
7106,3-20,3-20_v2_13@1,3-20_v1_11@7,"Among the respondents, 42.1% were females and 57.9% males (Q2) ( Figure S2 ).",The sample’s gender distribution turned out to be 42.1% females and 57.9% males ( Figure S2 ).,"Modify,Fact/Evidence",Fact/Evidence
7107,3-20,3-20_v2_13@2,3-20_v1_11@9,"On average, respondents reported spending 76.3% of their research time on basic research (Q3) ( Figure S3 ), with only 3.6% of respondents stating that they were not involved (0%) in basic research.","On average, respondents reported spending 76.3% of their research time on basic research ( Figure S3 ), with only 3.6% of respondents stating that they were not involved (0%) in basic research.","Modify,Fact/Evidence",Fact/Evidence
7108,3-20,3-20_v2_13@3,3-20_v1_11@10,"Q4 asked them if they agreed/disagreed with the following statement: “Despite the current economic situation, public funding for basic biological/biomedical research should be increased”.","In order to test respondents’ commitment to basic research in general, Q4 asked them if they agreed/disagreed with the following statement: “ Despite the current economic situation, public funding for basic biological/biomedical research should be increased ”.","Modify,Fact/Evidence",Fact/Evidence
7109,3-20,3-20_v2_13@4,3-20_v1_11@11,92.4% of the respondents agreed while only 7.6% disagreed ( Figure S4 ).,92.4% of the respondents agreed with the previous sentence while only 7.6% disagreed ( Figure S4 ).,"Modify,Clarity",Clarity
7110,3-20,3-20_v2_13@5,3-20_v1_11@12,"Overall, these results show that our purposive sample was well balanced with regard to academic position and gender, significantly involved in basic investigations and supportive of increased public funding for basic biological/biomedical research.","Overall, these results show that our purposive sample was well balanced with regard to academic position and gender and that the surveyed scientists were significantly involved in basic investigations and (for the great majority) supportive of increased public funding for basic biological/biomedical research.","Modify,Clarity",Clarity
7111,3-20,3-20_v2_15@1,3-20_v1_13@2,Q5 asked respondents to express their level of agreement with the following: “basic research can be defined as the research that is not intended to yield immediate practical benefits except for advancement of knowledge” .,Q5 asked respondents to express their level of agreement with the following: “ basic research can be defined as the research that is not intended to yield immediate practical benefits except for advancement of knowledge ”.,"Modify,Grammar",Grammar
7112,3-20,3-20_v2_2@5,3-20_v1_2@5,The results of this study suggest that some soft incentives could be valuable tools to increase the transformative value of fundamental investigations without affecting the spirit of the basic research and scientists’ work satisfaction.,The study shows that basic researchers’ support for soft incentives is such that the transformative value of fundamental investigations can be increased without affecting the spirit of the basic research and scientists’ work satisfaction.,"Modify,Clarity",Clarity
7113,3-20,3-20_v2_15@2,3-20_v1_13@4,"Among respondents, 32.5% expressed complete agreement, 43.4% some agreement, 17.5% some disagreement and 6.6% complete disagreement ( Figure 1A ).","32.5% of the respondents expressed complete agreement, 43.4% some agreement, 17.5% some disagreement and 6.6% complete disagreement ( Figure 1A ).","Modify,Clarity",Clarity
7114,3-223,3-223_v2_33@2,,Be aware that scaling the densities by the total mass is not a guarantee that errors in all the inertial estimates are reduced.,,"Add,Claim",Claim
7115,3-223,3-223_v2_41@0,,"The model does not contain joints at the wrist or ankle, which is consistent with Yeadon’s model <REF-13> .",,"Add,Fact/Evidence",Fact/Evidence
7116,3-223,3-223_v2_41@1,,"Since these joints have a small effect on the inertial properties of the whole body, the exclusion of these joints should be fine for many use cases.",,"Add,Claim",Claim
7117,3-223,3-223_v2_41@2,,"However, the modular structure of the software allows one to easily modify the software to create these joints, if necessary.",,"Add,Claim",Claim
7118,3-223,3-223_v2_105@0,,Software versions,,"Add,Other",Other
7119,3-223,3-223_v2_106@0,,All of the computations in the paper were executed with the following software versions:,,"Add,Fact/Evidence",Fact/Evidence
7120,3-223,3-223_v2_33@0,3-223_v1_33@0,"Since the densities for the model are provided, one can readily estimate the human’s total mass.","Since the densities for the model are provided, we can readily estimate the human’s total mass.","Modify,Clarity",Clarity
7121,3-223,3-223_v2_35@7,3-223_v1_35@7,"The exceptions to this naming convention are somersault , tilt , and twist , which specify the orientation of the P segment with respect to the fixed coordinate frame.","The exceptions to this naming convention are somersalt , tilt , and twist , which specify the orientation of the P segment with respect to the fixed coordinate frame.","Modify,Grammar",Grammar
7122,3-223,3-223_v2_37@6,3-223_v1_37@6,"Joint center locations for segments J1 and K1 , respectively denoted as p J and p K , lie within level Ls0 and can be expressed in the local coordinate frame of the pelvis P :","Joint center locations for segments J1 and K1 , respectively denoted as p J and p K , can be expressed in the local coordinate frame of the pelvis P :","Modify,Fact/Evidence",Fact/Evidence
7123,3-223,3-223_v2_40@1,3-223_v1_40@1,"This choice is informed by calculations present in the ISEG code published in Yeadon's thesis <REF-11> ; in fact, Yeadon defines the origin of the model (and of level Ls0 ) as the midpoint of the two hip joint centers.",This choice is informed by calculations present in the ISEG code published in <REF-11> .,"Modify,Fact/Evidence",Fact/Evidence
7124,3-223,3-223_v2_43@0,3-223_v1_42@0,"There are a few ways in which our implementation of the human inertia model differs from that presented in Yeadon's papers <REF-10> , <REF-12> – <REF-14> .","There are a few ways in which our implementation of the human inertia model differs from that presented in <REF-10> , <REF-12> – <REF-14> .","Modify,Clarity",Clarity
7125,3-223,3-223_v2_57@0,3-223_v1_56@0,We implemented the inertia model in the Python programming language <REF-15> as a package named yeadon (yeadon only supports Python 2.7).,We implemented the inertia model in the Python language as a package named yeadon .,"Modify,Fact/Evidence",Fact/Evidence
7126,3-223,3-223_v2_66@2,3-223_v1_65@2,"This frame has its origin at the bottom center of solid s0 , and is aligned with the local frame of segment P when somersault , tilt , and twist are zero.","This frame has its origin at the bottom center of solid s0 , and is aligned with the local frame of segment P when somersalt , tilt , and twist are zero.","Modify,Grammar",Grammar
7127,3-223,3-223_v2_74@1,3-223_v1_73@1,"For example, the previous method’s docstring shows the three returned values in Listing 5 .",For example the previous method’s docstring shows the three returned values in Listing 5 .,"Modify,Grammar",Grammar
7128,3-223,3-223_v2_89@1,3-223_v1_88@1,This example is also included in the Yeadon 1.2.1 software source files and a rendered version is viewable with NBViewer .,This example is also included in the Yeadon 1.2.0 software source files and a rendered version is viewable with NBViewer .,"Modify,Fact/Evidence",Fact/Evidence
7129,3-238,3-238_v2_26@0,,It is unclear why GLI1 levels decrease during PDAC progression in vivo .,,"Add,Claim",Claim
7130,3-238,3-238_v2_26@1,,"As previously discussed, one potential mechanism for lowered GLI1 expression in advanced PDAC may be due to activation of the kinase DYRK1B, which inhibits GLI1 expression through expression of the repressor GLI3 ( Lauth et al. , 2010 ).",,"Add,Fact/Evidence",Fact/Evidence
7131,3-238,3-238_v2_26@2,,Activation of DYRK1B promotes a shift from autocrine to paracrine signaling in PDAC.,,"Add,Claim",Claim
7132,3-238,3-238_v2_26@3,,This shift may lead to a decrease in GLI1 expression in PDAC cells.,,"Add,Claim",Claim
7133,3-238,3-238_v2_26@4,,"In addition, HH signaling promotes GLI1 expression in part through inhibition of GLI1 repressors ( Stecca & Ruiz, 2010 ).",,"Add,Fact/Evidence",Fact/Evidence
7134,3-238,3-238_v2_26@5,,"Decreased HH signaling in advanced PDAC may allow for increased expression of GLI1 repressors, such as GLI3 and Suppressor of Fused (Sufu), leading to decreased GLI1 expression and activity ( Stecca & Ruiz, 2010 ).",,"Add,Fact/Evidence",Fact/Evidence
7135,3-238,3-238_v2_27@0,,"An alternative explanation for clinical trial failures of HH inhibitors in treatment of advanced PDAC may be due to GLI-independent effects of SMO inhibition, not necessarily due to a decrease in GLI1.",,"Add,Claim",Claim
7136,3-238,3-238_v2_27@1,,Not all HH signaling responses are mediated by GLI transcription factors.,,"Add,Claim",Claim
7137,3-238,3-238_v2_27@2,,"SMO has been demonstrated to play a role in several cellular functions, including actin stress fiber formation, endothelial tubulogenesis, fibroblast migration, and regulation of glucose uptake independent of GLI transcription ( Brennan et al. , 2012 ; Chinchilla et al. , 2010 ; Teperino et al. , 2014 ).",,"Add,Fact/Evidence",Fact/Evidence
7138,3-238,3-238_v2_27@3,,"The failure of HH inhibition in PDAC could potentially be due to the loss of these GLI-independent SMO downstream effectors, while modulation of GLI1 expression may only be a secondary effect.",,"Add,Claim",Claim
7139,3-238,3-238_v2_28@2,,Further studies are needed to fully understand the role of GLI1 in PDAC carcinogenesis.,,"Add,Claim",Claim
7140,3-238,3-238_v2_28@3,,"While there is evidence for a dual role of GLI1 in PDAC, this phenomenon has yet to be linked with other cancer types.",,"Add,Claim",Claim
7141,3-238,3-238_v2_15@2,3-238_v1_13@2,"Nye et al. demonstrated that TGFβ, in addition to controlling GLI1 expression, can also modulate its activity by promoting the formation of a transcriptional complex with the TGFβ-regulated transcription factors, SMAD2 and 4, and the histone acetyltransferase, PCAF, at the BCL2 promoter in cancer cells to regulate TGFβ-induced gene expression ( Figure 1 ) ( Nye et al. , 2014 ).","Nye et al. demonstrated that TGFβ, in addition to controlling GLI1 expression, can also modulate its activity by promoting the formation of a transcriptional complex with the TGFβ-regulated transcription factors, SMAD2 and 4, and the histone acetyltransferase, PCAF, in cancer cells to regulate TGFβ-induced gene expression ( Nye et al. , 2014 ).","Modify,Fact/Evidence",Fact/Evidence
7142,3-238,3-238_v2_15@3,3-238_v1_13@3,"Activation of TGFβ induced GLI2 expression, and subsequent GLI1 activation, is associated with epithelial to mesenchymal transition (EMT), tumor growth, and metastasis ( Javelaud et al. , 2012 ).","TGFβ induced GLI2 expression, and subsequent GLI1 activation, is associated with epithelial to mesenchymal transition (EMT), tumor growth, and metastasis ( Javelaud et al. , 2012 ).","Modify,Clarity",Clarity
7143,3-238,3-238_v2_16@1,3-238_v1_14@1,Eberl and colleagues demonstrated EGFR and HH act together to promote cancer cell proliferation by modulating gene expression through a GLI1-dependent mechanism ( Figure 1 ).,Eberl and colleagues demonstrated EGFR and HH act together to promote cancer cell proliferation by modulating gene expression through a GLI1-dependent mechanism.,"Modify,Fact/Evidence",Fact/Evidence
7144,3-238,3-238_v2_17@0,3-238_v1_15@0,Clinical Trials Targeting the Hedgehog/GLI1 axis in PDAC,Clinical trials targeting the hedgehog/GLI1 axis in PDAC,"Modify,Grammar",Grammar
7145,3-238,3-238_v2_4@2,3-238_v1_4@2,"The GLI family of transcription factors is highly conserved and is required for developmental response via transcriptional regulation of target genes ( Dennler et al. , 2007 ; Hui & Angers, 2011 ; Javelaud et al. , 2012 ).","GLI1 is highly conserved from Drosophila to humans and is required for developmental response via transcriptional regulation of target genes ( Dennler et al. , 2007 ; Hui & Angers, 2011 ; Javelaud et al. , 2012 ).","Modify,Fact/Evidence",Fact/Evidence
7146,3-238,3-238_v2_20@0,3-238_v1_18@0,GLI1 as a Tumor Suppressor in PDAC,GLI1 as a tumor suppressor in PDAC,"Modify,Grammar",Grammar
7147,3-238,3-238_v2_23@8,3-238_v1_21@8,"Manipulation of the membrane mediators of HH to reduce HH signaling leads to an increase of angiogenesis with low HH levels, but not with complete inhibition.","In fact, manipulation of the membrane mediators of HH signaling to reduce HH signaling leads to an increase of angiogenesis with low HH levels, but not with complete inhibition.","Modify,Clarity",Clarity
7148,3-238,3-238_v2_5@0,3-238_v1_5@0,GLI1 as an Oncogene in PDAC,GLI1 as an oncogene in PDAC,"Modify,Grammar",Grammar
7149,3-238,3-238_v2_7@1,3-238_v1_7@1,"For instance, GLI1 activity is mainly modulated by the canonical HH signaling in fibroblasts ( Figure 1 ) ( Yauch et al. , 2008 ).","For instance, GLI1 activity is mainly modulated by the canonical HH signaling in fibroblasts ( Yauch et al. , 2008 ).","Modify,Fact/Evidence",Fact/Evidence
7150,3-238,3-238_v2_12@0,3-238_v1_10@0,Hedgehog-Independent Mechanisms for GLI1 Expression in PDAC,Hedgehog-independent mechanisms for GLI1 expression in PDAC,"Modify,Grammar",Grammar
7151,3-238,3-238_v2_13@5,3-238_v1_11@5,"Accordingly, Ji et al. , showed that Gli1 protein degradation is blocked in a MAPK-dependent manner.","Accordingly, Ji et al. showed that Gli1 protein degradation is blocked in a MAPK-dependent manner.","Modify,Grammar",Grammar
7152,3-238,3-238_v2_13@6,3-238_v1_11@6,"Furthermore, Rajurkar et al. showed a role for GLI1 in the regulation of the NF-κB pathway, a signaling cascade linked to PDAC development ( Algül et al. , 2002 ; Ougolkov et al. , 2005 ; Pan et al. , 2008 ; Wang et al. , 1999 ), downstream of KRAS ( Figure 1 ) ( Rajurkar et al. , 2012 ).","Furthermore, Rajurkar et al. showed a role for GLI1 in the regulation of the NF-κB pathway, a signaling cascade linked to PDAC development ( Algul et al. , 2002 ; Ougolkov et al. , 2005 ; Pan et al. , 2008 ; Wang et al. , 1999 ), downstream of KRAS ( Rajurkar et al. , 2012 ).","Modify,Fact/Evidence",Fact/Evidence
7153,3-238,3-238_v2_15@1,3-238_v1_13@1,"TGFβ induces the expression of GLI1 through Smad3 and β-catenin/LEF-TCF-dependent upregulation of GLI2 independent of HH signaling ( Dennler et al. , 2007 ; Dennler et al. , 2009 ).","TGFβ induces the expression of GLI1 through Smad3 and LET-dependent upregulation of GLI2 independent of HH signaling ( Dennler et al. , 2007 ; Dennler et al. , 2009 ).","Modify,Fact/Evidence",Fact/Evidence
7154,3-240,,3-240_v1_17@4,,The 5’end of the qACE forward primer corresponds to the adapter and the last six nucleotides correspond to the target sequence downstream of the cleavage site (See Discussion for additional details).,"Delete,Fact/Evidence",Fact/Evidence
7155,3-240,,3-240_v1_43@4,,This can potentially be overcome with a gene-specific reverse primer (See below).,"Delete,Claim",Claim
7156,3-240,3-240_v2_21@9,,"The formula for calculating RCT is, 2 (C t(Full length)- C t(cleaved transcript) ) , where C t stands for threshold cycle.",,"Add,Fact/Evidence",Fact/Evidence
7157,3-240,3-240_v2_23@5,,A potential cleavage product of AtNAC1 accumulates in the roots of Arabidopsis plants over-expressing miR164 <REF-33> .,,"Add,Fact/Evidence",Fact/Evidence
7158,3-240,3-240_v2_32@0,,"As a comparison, we determined the ratio of cleaved vs. full length target transcripts using previously published northern blot data using Arabidopsis plants with increased or decreased levels of miR164 <REF-33> .",,"Add,Fact/Evidence",Fact/Evidence
7159,3-240,3-240_v2_32@1,,We performed image analysis to obtain band intensities of full length and cleaved products and calculated the ratio of cleaved transcripts to full length.,,"Add,Fact/Evidence",Fact/Evidence
7160,3-240,3-240_v2_32@2,,"In Arabidopsis plants over-expressing miR164 in a chemically inducible manner, a 48 hour induction led to a 1.5 fold increase in RCT in one of the transgenic lines ( Table S2 ).",,"Add,Fact/Evidence",Fact/Evidence
7161,3-240,3-240_v2_32@3,,"In the other transgenic line, the cleaved product was below the limit of detection at this time point and hence RCT could not be calculated.",,"Add,Fact/Evidence",Fact/Evidence
7162,3-240,3-240_v2_32@4,,"Nevertheless, increased RCT in miR164 over-expressing plants was consistent with results from our soybean miR164 over-expression experiments ( Figure 2 ).",,"Add,Fact/Evidence",Fact/Evidence
7163,3-240,3-240_v2_32@5,,"Similarly, in mir164 mutant lines, we observed a significant decrease in RCT ( Table S3 ) consistent with results from our hen1-1 experiments ( Figure 3 ).",,"Add,Fact/Evidence",Fact/Evidence
7164,3-240,3-240_v2_38@8,,The high sequence identity between the transcripts of GmNAC1a and b (~92%) precluded the use of Northern to perform such comparisons between these genes.,,"Add,Fact/Evidence",Fact/Evidence
7165,3-240,3-240_v2_46@0,,The images depict binding of the qACE forward primer (qACE-F) to cleavage products resulting from miR166h and miR166a guided cleavage of GmHD-ZIP III transcripts.,,"Add,Fact/Evidence",Fact/Evidence
7166,3-240,3-240_v2_46@1,,The primer-template combination in the top panel resulted in no amplification underscoring the specificity of the primer.,,"Add,Fact/Evidence",Fact/Evidence
7167,3-240,3-240_v2_46@2,,"However, the primer-template combination shown in the bottom panel resulted in non-specific amplification.",,"Add,Fact/Evidence",Fact/Evidence
7168,3-240,3-240_v2_46@3,,We hypothesize that the 6nt binding stretch at the 3’end was the reason for such non-specific amplification.,,"Add,Claim",Claim
7169,3-240,3-240_v2_46@4,,The oligo adapter ligated to the cleaved end is indicated in bold letters and as grey bar.,,"Add,Fact/Evidence",Fact/Evidence
7170,3-240,3-240_v2_10@3,3-240_v1_10@3,Transgenic GFP roots were collected on dry-ice and stored at -70°C until RNA isolation and cDNA synthesis.,Transgenic GFP roots were collected on dry-ice and stored at -70°C.,"Modify,Fact/Evidence",Fact/Evidence
7171,3-240,3-240_v2_12@4,3-240_v1_12@4,"For gene expression analysis in soybean nodules and adjacent root tissues, 7µg of total RNA was used in adapter-ligated cDNA synthesis.",For gene expression analysis in soybean 7µg of total RNA was used in adapter-ligated cDNA synthesis.,"Modify,Fact/Evidence",Fact/Evidence
7172,3-240,3-240_v2_2@7,3-240_v1_2@7,These experiments show that qACE can be used to discover and demonstrate tissue-specific cleavage by miRNAs to achieve specific spatio-temporal expression of target genes in plants.,These experiments show that qACE can be used to discover and demonstrate differential cleavage by miRNAs to achieve specific spatio-temporal expression of target genes in plants.,"Modify,Fact/Evidence",Fact/Evidence
7173,3-240,3-240_v2_21@3,3-240_v1_17@8,"Finally, we also expected that the use of a gene-specific reverse primer would amplify linearly and help distinguish different targets of the same miRNA even if the miRNA-binding sites are identical/highly conserved ( Figure S4a – Figure S4d ).","Finally, we also expected that the use of a gene-specific reverse primer would amplify linearly and help distinguish different targets of the same miRNA even if the miRNA-binding sites are identical/highly conserved ( Figure S4a–d ).","Modify,Clarity",Clarity
7175,3-240,3-240_v2_23@4,3-240_v1_21@3,GmNAC1b is a close ortholog of AtNAC1 ( Figure S2 ).,"We also examined the expression of GmNAC1b, a 5’-RACE-validated target of miR164 in soybean ( Figure S1 ) and a close ortholog of AtNAC1 ( Figure S2 ).","Split+Modify,Clarity",Clarity
7176,3-240,3-240_v2_23@6,3-240_v1_21@4,"To quantify the levels of GmNAC1b, we generated oligo-dT-primed cDNA and performed qPCR assays using primers designed across the miR164 binding site of GmNAC1b.",We generated oligo-dT-primed cDNA and performed qPCR assays using primers designed across the miR164 binding site of GmNAC1b.,"Modify,Fact/Evidence",Fact/Evidence
7177,3-240,3-240_v2_4@1,3-240_v1_4@1,The majority of plant miRNAs fine-tune target gene expression through precise mRNA cleavage to achieve proper spatio-temporal expression patterns during plant development as well as in response to environmental changes <REF-2> – <REF-4> .,The majority of miRNAs fine-tune target gene expression to achieve proper spatio-temporal expression patterns during plant development as well as in response to environmental changes <REF-2> – <REF-4> .,"Modify,Fact/Evidence",Fact/Evidence
7178,3-240,3-240_v2_28@1,3-240_v1_26@1,It was previously demonstrated using Northern blots that hen1-1 mutants accumulated less amounts of miRNAs and that there was an increase in the levels of miRNA targets in these plants <REF-34> .,It was previously demonstrated that hen1-1 mutants accumulated less amounts of miRNAs and that there was an increase in the levels of miRNA targets in these plants <REF-25> .,"Modify,Fact/Evidence",Fact/Evidence
7179,3-240,3-240_v2_34@5,3-240_v1_31@5,"Interestingly, miR164 had a nodule-excluded expression pattern i.e. ~40-fold lower expression in MN vs. ABMN ( Figure 4b ).","Interestingly, miR164 had a nodule-excluded expression pattern i.e. ~40-fold lower expression in MN vs ABMN ( Figure 4b ).","Modify,Grammar",Grammar
7180,3-240,3-240_v2_4@8,3-240_v1_4@8,"Similarly, miR399 plays an important role during inorganic phosphate (Pi) starvation by down regulating PHO2/UBC24 (a gene encoding a putative ubiquitin conjugating enzyme) mRNA <REF-11> , <REF-12> .","Similarly, miR399 plays an important role during inorganic phosphate (Pi) starvation by down regulating PHO2/UBC24 (a gene encoding a putative ubiquitin conjugating enzyme) mRNA <REF-11> .","Modify,Fact/Evidence",Fact/Evidence
7181,3-240,3-240_v2_20@0,3-240_v1_43@1,The forward primer had to be designed such that it does not amplify full-length cDNA molecules or bind non-specifically to other adapter-ligated molecules.,The first level of specificity is to ensure that the qACE forward primer does not amplify full-length cDNA molecules or bind non-specifically to other adapter-ligated molecules.,"Modify,Clarity",Clarity
7182,3-240,3-240_v2_20@2,3-240_v1_43@3,"A shorter design (a 4nt sequence for example), had an increased probability of non-specific binding.","A shorter design (a 4nt sequence for example), might result in non-specific binding to non-specific cleavage products due to the increased probability of binding sites (data not shown).","Modify,Claim",Claim
7183,3-240,3-240_v2_5@0,3-240_v1_5@0,"Identification, validation and quantification of the extent of regulation of specific target genes by miRNA is crucial for proper understanding of miRNA-mediated gene regulation.","Identification, validation and quantification of the extent of regulation of specific target genes by miRNA is crucial for proper understanding of their biological roles.","Modify,Claim",Claim
7184,3-240,3-240_v2_20@3,3-240_v1_43@5,"On the other hand, longer than 6nt design had a higher thermodynamic stability making it possible to bind to full-length cDNA molecules (depending on the GC content).","On the other hand, longer than 6nt design had a higher thermodynamic stability making it possible to bind to full-length cDNA molecules (depending on the GC content; data not shown).","Modify,Clarity",Clarity
7185,3-240,3-240_v2_20@4,3-240_v1_43@6,"In addition, for target genes with identical miRNA cleavage signatures (and therefore identical qACE forward primers), specificity was achieved by carefully designing gene-specific reverse primers.",The second level of specificity is distinguishing target genes with identical miRNA cleavage signatures (and therefore having identical qACE forward primers).,"Merge+Modify,Clarity",Clarity
7186,3-240,3-240_v2_20@4,3-240_v1_43@7,"In addition, for target genes with identical miRNA cleavage signatures (and therefore identical qACE forward primers), specificity was achieved by carefully designing gene-specific reverse primers.",This is again achieved by carefully designing gene-specific reverse primers.,"Merge+Modify,Clarity",Clarity
7187,3-240,3-240_v2_49@0,3-240_v1_45@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2015 Damodaran S et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2014 Damodaran S et al.,"Modify,Fact/Evidence",Fact/Evidence
7188,3-240,3-240_v2_2@2,3-240_v1_2@2,We developed a quantitative PCR method “quantitative Amplification of Cleaved Ends (qACE)” to assay levels of specific cleavage products in order to determine the extent of miRNA-directed target cleavage of a specific target gene.,We developed a quantitative PCR method “quantitative Amplification of Cleaved Ends (qACE)” to assay levels of specific cleavage products in order to determine the extent of miRNA regulation for a specific target gene.,"Modify,Fact/Evidence",Fact/Evidence
7205,3-298,,3-298_v1_2@9,,MES may help to maintain stable medium pH for bulk medium preparation.,"Delete,Claim",Claim
7206,3-298,3-298_v2_11@2,,"The basal medium was mDCR, a modified version of the MS basal salts developed for Douglas-fir by Gupta & Durzan (1985 and 1987a) which we further modified and classified as mDCR.",,"Add,Fact/Evidence",Fact/Evidence
7207,3-298,3-298_v2_11@3,,A comparison of the components between DCR vs. mDCR is provided in Table 1 .,,"Add,Fact/Evidence",Fact/Evidence
7208,3-298,3-298_v2_11@6,,This wide range of pre-adjusted medium pH levels would allow assessments of medium buffering ability and explant growth response and adjustment after placing onto corresponding medium types.,,"Add,Claim",Claim
7209,3-298,3-298_v2_11@7,,These pre-adjusted medium pH levels were also confined within the pH levels that will not interfere with gel solidification.,,"Add,Fact/Evidence",Fact/Evidence
7210,3-298,3-298_v2_11@8,,"Due to limited plant materials, the addition of one previously reported concentration of MES ( de Klerk et al. , 2008 ; Höfer et al. , 1999 ; Parfitt et al. , 1988 ; Wilson et al. , 1989 ) served as the basis for comparison in aforementioned assessment needs.",,"Add,Fact/Evidence",Fact/Evidence
7211,3-298,3-298_v2_41@8,,"Further evaluation of MES dose-response relationships and determination of the optimal MES concentration could benefit the development of Douglas-fir micropropagation system, although a wide range of successful MES concentrations have been reported previously for Douglas-fir and other conifers ( Thorpe et al. , 2008 ).",,"Add,Claim",Claim
7212,3-298,3-298_v2_42@1,,Explant weight increment across various levels of pre-adjusted medium pH was genotype dependent.,,"Add,Fact/Evidence",Fact/Evidence
7213,3-298,3-298_v2_42@2,,"A broader evaluation including more genotypes could provide stronger or more specific support for such genotype-culture interactions, although this is a generally well known and expected factor in plant tissue culture ( Thorpe et al. , 2008 ).",,"Add,Claim",Claim
7214,3-298,3-298_v2_42@3,,"Typically, explant weight increment exhibited a curvilinear relationship with pH over time in vitro .",,"Add,Fact/Evidence",Fact/Evidence
7215,3-298,3-298_v2_42@4,,After 28 days we did however observe a decreased weight gain in genotype HF210 on mDCR and a cessation of weight gain in genotype HF205 on both media.,,"Add,Fact/Evidence",Fact/Evidence
7216,3-298,3-298_v2_42@5,,"Whether this growth decline is associated with nutrient depletion, PGR degradation, medium pH, or a combination of these factors, may be resolved through further evaluations of the Douglas-fir tissue culture system.",,"Add,Claim",Claim
7217,3-298,3-298_v2_42@6,,"However, based on medium pH fluctuation after in the presence of explants and morphological observations on the explants, prolonged culture without subculturing could result in unwanted growth complications.",,"Add,Claim",Claim
7218,3-298,3-298_v2_42@7,,"Therefore, we would suggest subculturing at 21-days for Douglas-fir as a best management practice.",,"Add,Claim",Claim
7219,3-298,3-298_v2_17@0,3-298_v1_15@0,"After autoclaving, media pH shifts were found according to each pre-adjusted media pH. From 100 samples, mDCR medium showed a greater extent of pH fluctuations than mDCR+MES post-autoclaving.","After autoclaving, media pH shifts were found according to each pre-adjusted media pH. From 100 samples, mDCR medium showed a greater extend of pH fluctuations than mDCR+MES post-autoclaving.","Modify,Grammar",Grammar
7220,3-298,3-298_v2_17@1,3-298_v1_15@1,"Media initially set at pH 3.6, 5.1, and 5.7 showed increased pH for both media types (pH changes of 0.83, 0.58, 0.17 and 0.76, 0.22, 0.11 for mDCR and mDCR+MES, respectively) whereas medium initially at pH 7.8 showed decreased pH (-0.66 and -0.59 for mDCR and mDCR+MES, respectively).","Media initially set at pH 3.6, 5.1, and 5.7 were increased for both media type (pH changes of 0.83, 0.58, 0.17 and 0.76, 0.22, 0.11 for mDCR and mDCR+MES, respectively) whereas medium initially at pH 7.8 were decreased (-0.66 and -0.59 for mDCR and mDCR+MES, respectively).","Modify,Clarity",Clarity
7221,3-298,3-298_v2_17@2,3-298_v1_15@2,Medium of pre-adjusted pH 6.3 showed decreased pH in mDCR (-0.11) but increased pH for mDCR+MES (0.05).,Medium of pre-adjusted pH 6.3 showed decrease in mDCR (-0.11) but increase for mDCR+MES (0.05).,"Modify,Clarity",Clarity
7222,3-298,3-298_v2_17@5,3-298_v1_15@5,"Over the incubation times tested, media pH showed only a slight decreasing trend in the dark storage condition.","Over the incubation times tested, media pH was maintained at fairly stable condition with a slight decreasing trend in the dark storage condition.","Modify,Fact/Evidence",Fact/Evidence
7223,3-298,3-298_v2_17@7,3-298_v1_15@7,The mDCR+MES medium maintained media with less pH change over the incubation times when compared to mDCR media in the light ( Figure 1 ).,The mDCR+MES media maintained media with less pH change over the incubation times when compared to mDCR media in the light ( Figure 1 ).,"Modify,Grammar",Grammar
7224,3-298,3-298_v2_2@6,3-298_v1_2@6,"Overall, MES provided a more stable medium pH, relative to starting pH values, under both light and dark storage conditions as well as with presence of explants.","In general, medium with MES provided a more stable medium pH compared to pre-adjusted pH values under two storage conditions as well as with presence of explants over time.","Modify,Fact/Evidence",Fact/Evidence
7225,3-298,3-298_v2_20@0,3-298_v1_18@0,Medium pH change with explants,The effect of MES on medium pH,"Modify,Other",Other
7226,3-298,3-298_v2_21@0,3-298_v1_19@0,"After placing explants into the media, the pH of the medium was significantly influenced by all factors - genotype, media type, initial pH level, and incubation time (all P =0.000).","After placing explants into the media, the pH of the medium was significantly influenced by all factors, genotype, media type, initial pH level, and incubation time (all P =0.000).","Modify,Grammar",Grammar
7227,3-298,3-298_v2_21@1,3-298_v1_19@1,"Overall medium pH was 5.45 from medium incubated with genotype PS-2 explants (n=1,355), which was significantly greater than 5.41 and 5.19 pH for media incubated with explants from genotypes HF210 (n=1,384) and HF205 (n=950), respectively.","Overall medium pH was 5.45 from medium incubated with PS-2 (n=1,355), which significantly greater than 5.41 and 5.19 from those incubated with HF210 (n=1,384) and HF205 (n=950), respectively.","Modify,Fact/Evidence",Fact/Evidence
7228,3-298,3-298_v2_21@6,3-298_v1_19@6,"Overall for both types of media, mean medium pH showed the lowest value of 5.04 (n=435) at 21-day of incubation.","Combined two types of media, mean medium pH showed the lowest value of 5.04 (n=435) at 21-day of incubation.","Modify,Clarity",Clarity
7229,3-298,3-298_v2_21@7,3-298_v1_19@7,"In contrast, the highest mean medium pH 5.88 was recorded at the day 42 of incubation (n=125).","In contrast, the highest mean medium pH 5.88 was recorded at the 42-day of incubation (n=125).","Modify,Grammar",Grammar
7230,3-298,3-298_v2_21@10,3-298_v1_19@10,"Within individual genotypes, both media type, and incubation time showed significant effects on media pH for all genotypes ( P =0.000).","Within individual genotype, both media type, and incubation time showed significant effects on media pH for all genotypes ( P =0.000).","Modify,Grammar",Grammar
7231,3-298,3-298_v2_24@0,3-298_v1_22@0,The effect of MES on explant growth,The effect of MES on plant growth,"Modify,Grammar",Grammar
7232,3-298,3-298_v2_25@2,3-298_v1_23@2,"Overall, genotype HF210 (30.86 mg, n=264) and PS-2 (22.50 mg, n=190) had a significantly greater weight increment than genotype HF205 (13.83 mg, n=205) ( P =0.000).","Overall, HF210 (30.86 mg, n=264) and PS-2 (22.50 mg, n=190) had a significant weight increment greater than HF205 (13.83 mg, n=205) ( P =0.000).","Modify,Clarity",Clarity
7233,3-298,3-298_v2_25@5,3-298_v1_23@5,"Initial medium pH of 3.6 produced a significantly greater bud weight change ( P =0.005) than medium pH 7.8 (25.89 vs. 19.23 mg, n=134 vs. 130, respectively).","Initial medium pH of 3.6 had a significantly greater bud weight change ( P =0.005) than medium pH 7.8 (25.89 vs. 19.23 mg, n=134 vs. 130, respectively).","Modify,Clarity",Clarity
7234,3-298,3-298_v2_25@6,3-298_v1_23@6,"Although an increasing trend of bud explant weight change was observed, bud weight did not show significant increases during the first week of incubation.",An increasing trend of bud weight change was observed but bud weight did not show significant increase during the first week of incubation.,"Modify,Clarity",Clarity
7235,3-298,3-298_v2_2@9,3-298_v1_2@10,"Our findings suggest that a 21-day subculture practice may best sustain medium freshness, medium pH level and desirable explant growth.","Our findings suggested a 21-day subculture practice may facilitate to sustain medium freshness, medium pH level and desirable explant growth.","Modify,Clarity",Clarity
7236,3-298,3-298_v2_28@0,3-298_v1_26@0,"Comparing individual genotypes, medium type exhibited non-significant effects on explant weight increment of all three genotypes ( P >0.05).","Comparing individual genotypes, medium type exhibited non-significant effect on explant weight increment of all three genotypes ( P >0.05).","Modify,Grammar",Grammar
7237,3-298,3-298_v2_28@1,3-298_v1_26@1,"For HF205, the weight differences were observed only at the higher and lower ends of the given initial pH levels ( Figure 4 ).","For HF205, the weight differences were observed at the higher and lower ends of the given initial pH levels ( Figure 4 ).","Modify,Clarity",Clarity
7238,3-298,3-298_v2_28@4,3-298_v1_26@4,"However afterwards, explant weight growth dramatically increased for genotypes PS-2 and HF210.","However afterwards, explant weight growth dramatically increased for PS-2 and HF210.","Modify,Clarity",Clarity
7239,3-298,3-298_v2_4@1,3-298_v1_4@1,The goal of this micropropagation project was to develop a true-to-type clonal propagation system to alleviate the cost of tree-to-tree variation from conventional seedling propagation.,The goal of this micropropagation project was to develop a true-to-type clonal propagation system to alleviate the cost of tree-to-tree variation by conventional seedling propagation.,"Modify,Grammar",Grammar
7240,3-298,3-298_v2_34@3,3-298_v1_32@3,The mentioned deformities were only found at the longer times of culturing.,The mentioned problems were only found at the later times of culturing.,"Modify,Clarity",Clarity
7241,3-298,3-298_v2_2@0,3-298_v1_2@0,The medium pH level of plant tissue cultures has been shown to be essential to many aspects of explant development and growth.,The medium pH level of plant tissue culture has been shown to be essential to many aspects of explant development and growth.,"Modify,Grammar",Grammar
7242,3-298,3-298_v2_0@0,3-298_v1_0@0,Effect of environmental and cultural conditions on medium pH and explant growth performance of Douglas-fir ( Pseudotsuga menziesii ) shoot cultures,Effect of environmental and cultural conditions in medium pH and plant growth performance of Douglas-fir ( Pseudotsuga menziesii ) shoot culture,"Modify,Grammar",Grammar
7243,3-298,3-298_v2_5@0,3-298_v1_5@0,The medium pH of plant tissue cultures has been shown to be very important to many aspects of explant development and growth.,The medium pH of plant tissue culture has been shown to be very important to many aspects of explant development and growth.,"Modify,Grammar",Grammar
7244,3-298,3-298_v2_38@4,3-298_v1_36@4,"Acid-facilitated autocatalyzed sucrose hydrolysis was reported as being both pH and temperature dependent, where lower pH at a given temperature promotes more sucrose hydrolysis ( Heidt et al. , 1952 ; Wann et al. , 1997 ).","Acid facilitated autocatalyzed sucrose hydrolysis was reported as being both pH and temperature dependant, where lower pH at a given temperature promotes more sucrose hydrolysis ( Heidt et al. , 1952 ; Wann et al. , 1997 ).","Modify,Grammar",Grammar
7245,3-298,3-298_v2_5@1,3-298_v1_5@1,Sensitivity or tolerance to medium pH change in vitro varies according to specific requirements of individual species.,Sensitivity or tolerance to medium pH change in vitro varies accordingly to specific requirements of individual species.,"Modify,Grammar",Grammar
7246,3-298,3-298_v2_39@2,3-298_v1_37@2,"They also reported that other sucrose synthesis enzymes, sucrose phosphate synthase, and sucrose synthase, were pH dependent for their optimal activities (pH 7.7 and 6.7, respectively).","They also reported that other sucrose synthesis enzymes, sucrose phosphate synthase, and sucrose synthase were pH dependant for their optimal activities (pH 7.7 and 6.7, respectively).","Modify,Grammar",Grammar
7247,3-298,3-298_v2_5@2,3-298_v1_5@2,"Similar to soil pH, medium pH level may influence nutrient uptake ( Ramage & Williams, 2002 ), cellular pH adjustment ( Ballarin-Denti & Antoniotti, 1991 ), rooting and cellular growth ( de Klerk et al. , 2008 ; Leifert et al. , 1992 ), plant gene expression and transcriptional pH responses in roots ( Lager et al. , 2010 ), and the efficiency of Agrobacterium -mediated transformation ( Ogaki et al. , 2008 ; Rai et al. , 2012 ).","Similar to soil pH, medium pH level may influence nutrient uptake ( Ramage & Williams, 2002 ), cellular pH adjustment ( Ballarin-Denti & Antoniotti, 1991 ), rooting and cellular growth ( Leifert et al. , 1992 ; de Klerk et al. , 2008 ), plant gene expression and transcriptional pH responses in roots ( Lager et al. , 2010 ), and the efficiency of Agrobacterium -mediated transformation ( Ogaki et al. , 2008 ; Rai et al. , 2012 ).","Modify,Clarity",Clarity
7248,3-298,3-298_v2_41@1,3-298_v1_39@1,MES has been employed in various tissue culture systems to maintain stable medium pH over extended culture times.,MES has been employed in various tissue culture systems to maintain stable medium pH over extended cultural times.,"Modify,Grammar",Grammar
7249,3-298,3-298_v2_41@4,3-298_v1_39@4,"For conifer species, MES was also utilized as pH stabilizer for silver fir ( Abies alba L.) ( Hartmann et al. , 1992 ), white spruce ( Picea glauca (Moench) Voss) ( Wilson et al. , 1989 ) and European larch ( Larix decidua Mill.) ( Korlach & Zoglauer, 1995 ) protoplast culture systems.","For conifer species, MES was also utilized as pH stabilizer for silver fir ( Abies alba L.) ( Hartmann et al. , 1992 ) and European larch ( Larix decidua Mill.) ( Korlach & Zoglauer, 1995 ) protoplast culture systems.","Modify,Fact/Evidence",Fact/Evidence
7250,3-298,3-298_v2_41@7,3-298_v1_39@7,MES may be especially important to maintain stable medium pH for bulk medium preparation in large scale propagation projects.,"Especially, MES may help to maintain stable medium pH for bulk medium preparation in large scale aspects of a propagation project.","Modify,Clarity",Clarity
7251,3-298,3-298_v2_42@0,3-298_v1_40@0,"Overall our results suggest that a 21-day subculture practice may be most suitable for maintaining medium freshness, medium pH level, and desirable explant growth for Douglas-fir shoot culture.","Our data suggested a 21-day subculture practice may be suitable for maintaining medium freshness, medium pH level, and desirable explant growth for Douglas-fir shoot culture.","Modify,Clarity",Clarity
7252,3-298,3-298_v2_44@0,3-298_v1_42@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2015 Chen CC et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2014 Chen CC et al.,"Modify,Fact/Evidence",Fact/Evidence
7253,3-298,3-298_v2_5@3,3-298_v1_5@3,"Medium pH also can act to facilitate or inhibit nutrient availability in the medium, such as ammonium uptake in vitro being facilitated with a stable pH of 5.5 ( Thorpe et al. , 2008 ).","Medium pH also can act to facilitate or inhibit nutrient availability in the medium such as ammonium uptake in vitro can be facilitated with a stable pH of 5.5 ( Thorpe et al. , 2008 ).","Modify,Grammar",Grammar
7254,3-298,3-298_v2_6@1,3-298_v1_6@1,"Medium components may modify pH prior to and after autoclaving ( Owen et al. , 1991 ; Skirvin et al. , 1986 ).","Medium components may modify pH prior to and after autoclaving ( Skirvin et al. , 1986 ; Owen et al. , 1991 ).","Modify,Clarity",Clarity
7255,3-298,3-298_v2_2@1,3-298_v1_2@1,Sensitivity or tolerance of medium pH change in vitro varies according to specific requirements of individual species.,Sensitivity or tolerance of medium pH change in vitro varies accordingly to specific requirements of individual species.,"Modify,Grammar",Grammar
7256,3-298,3-298_v2_6@3,3-298_v1_6@3,"Williams et al. (1990) reported that adding agar significantly elevated medium pH prior to autoclaving when pre-adjusted pH ranged from 3.5 to 5.5 in MS medium ( Murashige & Skoog, 1962 ), while less pH increment was found for pre-adjusted medium pH ranging from 5.5 to 7.0, and pH decreased for pre-adjusted medium pH ranging from 7.0 to 8.0.","Williams et al. (1990) reported adding agar significantly elevated medium pH prior to autoclaving in group of pre-adjusted pH from 3.5 to 5.5 of MS medium ( Murashige & Skoog, 1962 ) but less increment was found in group of pre-adjusted medium pH from 5.5 to 7.0, or decrease in group of pre-adjusted medium pH from 7.0 to 8.0.","Modify,Clarity",Clarity
7257,3-298,3-298_v2_6@4,3-298_v1_6@4,"In contrast, post-autoclaving medium pH increased for pre-adjusted pH of 3.5–4.5, but a more significant medium pH decrease was observed with pre-adjusted pH of 5–8.","In contrast, post-autoclaving medium pH increased in group of pre-adjusted pH of 3.5–4.5 but had more significant medium pH decrease in group of pre-adjusted pH of 5–8.","Modify,Clarity",Clarity
7258,3-298,3-298_v2_6@6,3-298_v1_6@6,"Organic compounds such as 2-(N-morpholino)ethanesulfonic acid (MES) are known to help maintain suitable medium pH range for explant development ( de Klerk et al. , 2008 ; Parfitt et al. , 1988 ; Yuan et al. , 2012 ).","Organic compounds such as 2-(N-morpholino)ethanesulfonic acid (MES) could especially help to maintain suitable medium pH range for explant development ( Parfitt et al. , 1988 ; de Klerk et al. , 2008 ; Yuan et al. , 2012 ).","Modify,Clarity",Clarity
7259,3-298,3-298_v2_7@0,3-298_v1_7@0,"After placing explants on the medium, medium pH fluctuations have also been reported for various species.","After placing explants on the medium, medium pH fluctuations were also observed for various species.","Modify,Clarity",Clarity
7260,3-298,3-298_v2_2@2,3-298_v1_2@2,"The objectives of this study are to 1) determine medium pH change over time in storage conditions and with presence of explants, 2) evaluate the effects of medium pH change on explant growth performance and 3) assess the effects of adding a pH stabilizer, 2-(N-morpholino)ethanesulfonic acid (MES) that is commonly used in Douglas-fir micropropagation medium.","The objectives of this study are to 1) determine medium pH change over time in storage conditions and with presence of explants, 2) evaluate the effects of medium pH change and explant growth performance and 3) assess the effects of adding a pH stabilizer, 2-(N-morpholino)ethanesulfonic acid (MES) to Douglas-fir micropropagation medium.","Modify,Clarity",Clarity
7261,3-298,3-298_v2_7@3,3-298_v1_7@3,"According to Skirvin et al. (1986) and Thorpe et al. (2008) , explant nutrient absorption in vitro is a function of ion exchange where deposition of free hydrogen ions (H + ) and hydroxyl ion (OH - ) in the medium may contribute to acidic or alkaline medium pH. In contrast, photooxidation induced chelating events that bind free iron, reducing iron availability, may also influence medium pH ( Hangarter & Stasinopoulos, 1991 ).","According to Skirvin et al. (1986) and Thorpe et al. (2008) , explant nutrient absorption in vitro is a function of ion exchange where deposition of free hydrogen ions (H + ) and hydroxyl ion (OH - ) in the medium may contribute to acidic or alkaline medium pH. In contrast, photooxidation induced chelating event bound free iron to reduce iron availability may also influence medium pH ( Hangarter & Stasinopoulos, 1991 ).","Modify,Grammar",Grammar
7262,3-298,3-298_v2_8@0,3-298_v1_8@0,"Medium pH fluctuations can involve many factors, and can eventually become problematic for tissue culture.","Medium pH fluctuations can involve many factors, and could eventually become problematic if lacking of care attentions.","Modify,Claim",Claim
7263,3-298,3-298_v2_8@3,3-298_v1_8@3,"To ensure an optimal shoot culture development and provide high quality shoots for later development of rooting protocol, medium pH can be a key indicator in determining optimal subculture time.","To ensure an optimal shoot culture development and provide high quality shoots for later development of rooting protocol, medium pH can be a key indicator in determine subculture time.","Modify,Clarity",Clarity
7264,3-298,3-298_v2_8@4,3-298_v1_8@4,"Medium pH may be further utilized as a diagnostic tool for some abnormal growth symptoms, such as necrosis, caused by low pH induced nutrient deficiency.","It may also be further utilized as a diagnostic tool for some abnormal growth symptoms such as necrosis, caused by low pH induced nutrient deficiency.","Modify,Clarity",Clarity
7265,3-298,3-298_v2_8@5,3-298_v1_8@5,"The study of medium pH effects may also be extended to explant development and nutrient relationships in vitro (Singha et al. , 1990).","The experimental system may be applied to studies of explant development and nutrient relationship in vitro (Singha et al. , 1990).","Modify,Clarity",Clarity
7266,3-298,3-298_v2_10@0,3-298_v1_10@0,Vegetative buds from juvenile (HF205 and HF210) and mature (PS-2) donor trees collected in the spring of 2006 were utilized for this study.,Spring buds from juvenile (HF205 and HF210) and mature (PS-2) donor trees collected in 2006 were utilized for this study.,"Modify,Clarity",Clarity
7267,3-298,3-298_v2_10@2,3-298_v1_10@2,"To classify juvenility, Douglas-fir trees of Lincoln seed source planted 10 years previously and not yet producing cones at the Penn State Horticulture Research Farm of Russell E. Larson Agricultural Research and Education Center at Rock Springs were the selected as juvenile donors.","To classify juvenility, Douglas-fir trees of Lincoln seed source planted 10 years ago and not yet producing cones at the Penn State Horticulture Research Farm of Russell E. Larson Agricultural Research and Education Center at Rock Springs were the selected donors.","Modify,Clarity",Clarity
7268,3-298,3-298_v2_10@3,3-298_v1_10@3,"The selected mature donor tree, an elite Christmas tree genotype resulting from a previous genetics study conducted by Gerhold (1984) , was over 40 years old and growing in a seed orchard located on the Penn State University golf course.","The selected mature donor tree, as a result from a previous genetics study conducted by Gerhold (1984) was over 40 years old at the Penn State golf course.","Modify,Fact/Evidence",Fact/Evidence
7269,3-298,3-298_v2_10@4,3-298_v1_10@4,These bud samples were stored in a 4°C cold room until culture initiation.,These bud samples were stored in a 4ºC cold room until further culture initiation.,"Modify,Clarity",Clarity
7270,3-298,3-298_v2_10@5,3-298_v1_10@5,"Preparation, sterilization, and dissection of collected bud samples followed Traore et al. (2005) .","Preparation, sterilization, and dissection of collected bud sample were followed as per Traore et al. (2005) .","Modify,Clarity",Clarity
7271,3-298,3-298_v2_2@3,3-298_v1_2@3,Vegetative buds were collected in the spring before breaking dormancy from juvenile and mature donor trees for conducting these evaluations.,"Spring buds, collected before breaking dormancy from juvenile and mature donor trees were utilized for these evaluations.","Modify,Clarity",Clarity
7272,3-298,3-298_v2_11@9,3-298_v1_11@4,Five surface-sterilized dissected vegetative buds from each genotype were placed on each treatment combination.,Five dissected vegetative buds from each genotype were placed on each treatment combination.,"Modify,Fact/Evidence",Fact/Evidence
7273,3-298,3-298_v2_11@11,3-298_v1_11@6,They were placed in full dark versus light in 25°C growth chambers.,They were placed in full dark versus light conditions in 25°C growth chambers.,"Modify,Clarity",Clarity
7274,3-298,3-298_v2_2@4,3-298_v1_2@4,"Medium, with or without MES, was pre-adjusted to five pH levels before adding MES, agar and autoclaving.","Medium with or without MES, each at five medium pH levels was pre-adjusted before adding MES, agar and autoclaving.","Modify,Clarity",Clarity
7275,3-300,3-300_v2_19@4,,"However, the ratio of social media, such as blogs, by scientists for inreach verses outreach remains unclear.",,"Add,Claim",Claim
7276,3-300,3-300_v2_23@0,,"Although, a direct link between SOSM and benefit to scientists career may not been supported, this does not rule out indirect effects such as seeing practical applications of research, increasing overall skills in communication, or gaining expertise in additional areas of science, i.e. becoming more well rounded.",,"Add,Claim",Claim
7277,3-300,3-300_v2_23@1,,"Unfortunately, indirect effects in any system are difficult to quantify and assess but ripe for further research.",,"Add,Claim",Claim
7278,3-300,3-300_v2_4@1,3-300_v1_4@1,Many of the arguments made in support of science outreach via social media (SOSM) are simply special applications of arguments for outreach in general.,Many of the arguments made in support of using social media for science outreach (SOSM) are simply special applications of arguments for outreach in general.,"Modify,Clarity",Clarity
7279,3-300,3-300_v2_19@3,3-300_v1_19@3,Moreover blogs written by scientists for scientists are becoming more common and serve as places for the exchange of ideas <REF-45> .,Moreover blogs written by scientists for scientists are becoming common and important places for the exchange of ideas <REF-45> .,"Modify,Clarity",Clarity
7280,3-300,3-300_v2_31@0,3-300_v1_30@0,"Conversely there may be valid reasons to keep, social media, particularly inreach blogging, free from formal academic systems.","Conversely there may be valid reasons to keep, social media, particularly inreach blogging, free from academic inclusion.","Modify,Claim",Claim
7281,3-300,3-300_v2_2@2,3-300_v1_2@2,"Here, we consider the relevant but subjective questions about science outreach via social media (SOSM), specifically: (1) Does a public relations nightmare exist for science?; (2) Why (or why aren’t) scientists engaging in social media?; (3) Are scientists using social media well?; and (4) Will social media benefit a scientist’s career?","Here, we consider the relevant but subjective questions about social media for science outreach (SOSM), specifically: (1) Does a public relations nightmare exist for science?; (2) Why (or why aren’t) scientists engaging in social media?; (3) Are scientists using social media well?; and (4) Will social media benefit a scientist’s career?","Modify,Clarity",Clarity
7282,3-67,,3-67_v1_42@5,,Examination of the hsRNH-substrate complex reveals that R138 participates in a hydrogen-bonding network that includes D134 and the phosphate adjacent to the scissile phosphate ( Figure 7 ); hydrogen-bonding interactions in the apo state may thus minimize entropic costs of binding.,"Delete,Fact/Evidence",Fact/Evidence
7283,3-67,3-67_v2_17@2,,"It should be noted that the experimental pH optima for the RNase H reaction in vitro are approximately 7.5–8.5 for ecRNH and 8.5–9.5 for ttRNH <REF-4> ; however, NMR data are not available at these pH ranges due to sample precipitation.",,"Add,Fact/Evidence",Fact/Evidence
7284,3-67,3-67_v2_57@3,,"Instead, we hypothesize that this behavior is imposed by the overall protein fold, the topology of which serves to force the negatively charged active-site residues into proximity with one another.",,"Add,Claim",Claim
7285,3-67,3-67_v2_2@4,3-67_v1_2@4,"Notably, representatives of bacterial, eukaryotic, and retroviral RNases H all exhibit similar active-site rigidity, suggesting that this dynamic feature is only subtly modulated by amino acid sequence and may primarily be imposed by the distinctive RNase H protein fold.","Notably, representatives of bacterial, eukaryotic, and retroviral RNases H all exhibit similar active-site rigidity, suggesting that this dynamic feature is only subtly modulated by amino acid sequence and is primarily imposed by the distinctive RNase H protein fold.","Modify,Claim",Claim
7286,3-67,3-67_v2_51@0,3-67_v1_53@0,"In order to better understand the relationships between dynamic processes in RNase H domains of retroviral origin compared to those from cellular organisms, additional simulations in the absence of divalent ions were performed on a set of retroviral RNase H homologs, whose sequences are shown in Figure 8 .","In order to better understand the relationships between dynamic processes in RNase H domains of retroviral origin compared to those from cellular organisms, additional simulations in the absence of divalent ions were performed on a set of retroviral RNase H homologs.","Modify,Fact/Evidence",Fact/Evidence
7287,3-67,3-67_v2_51@1,3-67_v1_53@1,"In brief, no significant differences are observed between simulations initiated from the XMRV full-length structure compared to its ΔC mutant (in which helix C and the handle region are removed), between the XMRV ΔC mutant compared to the HIV homolog (which naturally lacks the handle sequence), or between any of the retroviral domains compared to ecRNH ( Figure 9 ).","In brief, no significant differences are observed between simulations initiated from the XMRV full-length structure compared to its ∆C mutant (in which helix C and the handle region are removed), between the XMRV ∆C mutant compared to the HIV homolog (which naturally lacks the handle sequence), or between any of the retroviral domains compared to ecRNH ( Figure 8 ).","Modify,Grammar",Grammar
7288,3-67,3-67_v2_51@2,3-67_v1_53@2,This result suggests that the preorganization of the active site on the ps-ns timescale is not significantly altered by differences in amino acid sequence among the subset of family members examined.,"This result suggests that the preorganization of the active site on the ps-ns timescale is not significantly altered by differences in amino acid sequence, but rather is inherently imposed by the overall protein fold.","Modify,Claim",Claim
7289,4-1145,4-1145_v2_13@0,,Stock solutions of Resveratrol (Sigma-Aldrich) (20mM) and that of CuSO 4 .5H2O (MP Biomedical) (20mM) were prepared in 60% ethanol and water respectively.,,"Add,Fact/Evidence",Fact/Evidence
7290,4-1145,4-1145_v2_13@1,,The reaction mixture contained a fixed amount of R and varying amounts of Cu (as specified in the text) and 500ng of plasmid or genomic DNA or 2µg RNA in a sterilized 1.5 ml micro-tube.,,"Add,Fact/Evidence",Fact/Evidence
7291,4-1145,4-1145_v2_13@2,,"Volume of the mixture was kept constant at 20 µl (5µl of R, 5µl of Cu and 10µl of DNA).",,"Add,Fact/Evidence",Fact/Evidence
7292,4-1145,4-1145_v2_13@3,,"Reaction mixtures were prepared containing varying starting concentrations of R as follows: 100µM, 500µM, 1mM and 5mM (see text).",,"Add,Fact/Evidence",Fact/Evidence
7293,4-1145,4-1145_v2_13@4,,The mixture was incubated at 37°C for 1 hr.,,"Add,Fact/Evidence",Fact/Evidence
7294,4-1145,4-1145_v2_15@0,,"The table summarizes our observations under 3 separate headings: 1) observations on plasmid DNA using reducing concentrations of Cu and a constant concentration of R ( Figure 1 – Figure 4 ); 2) observations on eukaryotic DNA and RNA with reducing concentrations of Cu and a constant concentration of R ( Figure 5 , Figure 6 ), and 3) observations on plasmid DNA using different solvents with reducing concentrations of Cu and a constant concentration of R ( Figure 7 – Figure 9 ).",,"Add,Fact/Evidence",Fact/Evidence
7295,4-1145,4-1145_v2_39@1,,"We undertook similar experiments under different solvent conditions, namely, 50% acetonitrile ( Figure 7 ), 3mM NaOH ( Figure 8 ) and water ( Figure 9 ).",,"Add,Fact/Evidence",Fact/Evidence
7296,4-1145,4-1145_v2_39@3,,Cleavage of plasmid DNA was most efficient in 50% acetonitrile wherein cleavage was seen to commence at a R:Cu ratio of 1:1 while complete degradation occurred in all ratios between 1:0.2 and 1:0.01.,,"Add,Fact/Evidence",Fact/Evidence
7297,4-1145,4-1145_v2_39@4,,Cleavage/degradation was less efficient in 3mM NaOH wherein cleavage of plasmid DNA was seen between 1:1 and 1:0.1; complete degradation being observed at ratios of 1:0.02 and 1:0.01.,,"Add,Fact/Evidence",Fact/Evidence
7298,4-1145,4-1145_v2_39@5,,Water proved to be the least efficient medium where degradation was not seen under any R-Cu ratios although cleavage was observed at all ratios of R-Cu between 1:1 and 1:0.0002.,,"Add,Fact/Evidence",Fact/Evidence
7299,4-1145,4-1145_v2_39@6,,The above findings suggested that reduction of Cu(II) to Cu(I) to generate free radicals can occur under diverse conditions leading to cleavage/degradation of DNA.,,"Add,Claim",Claim
7300,4-1145,,4-1145_v1_13@0,,"Plasmid pTRIPZ DNA (500ng), eukaryotic genomic DNA (500ng) and eukaryotic RNA (2μg) were suspended in Tris-EDTA buffer.","Delete,Fact/Evidence",Fact/Evidence
7301,4-1145,,4-1145_v1_13@1,,R-Cu was dissolved in 20 μl of following solvents: 50% ethanol; 50% acetonitrile; 3mM NaOH or distilled water in varying molar ratios of R to Cu as indicated in the text and incubated with plasmid or genomic DNA and eukaryotic RNA at 37°C for 1hr.,"Delete,Fact/Evidence",Fact/Evidence
7302,4-1145,4-1145_v2_39@2,4-1145_v1_28@1,We observed a similar paradoxical relationship under all three conditions ( Table ).,"A similar synergism was also observed when experiments were done using other solvents, namely, 50% acetonitrile ( Figure 7 ), 3mM NaOH ( Figure 8 ) and water ( Figure 9 ) confirming the robust nature of this synergistic phenomenon.","Modify,Fact/Evidence",Fact/Evidence
7303,4-1145,4-1145_v2_0@0,4-1145_v1_0@0,A paradoxical relationship between Resveratrol and copper (II) with respect to degradation of DNA and RNA,A paradoxical synergism between Resveratrol and copper (II) with respect to degradation of DNA and RNA,"Modify,Clarity",Clarity
7304,4-1145,4-1145_v2_2@1,4-1145_v1_2@1,"Here we report a surprising observation of a paradoxical relationship between R and Cu whereby plasmid DNA cleaving / degrading activity of R-Cu increased progressively as the ratio of R to Cu was increased i.e., the concentration of Cu was successively reduced with respect to a fixed concentration R. Whereas cleavage of plasmid DNA occurred at low molar ratios of R to Cu, at higher ratios, complete degradation of DNA was achieved.","Here we report a surprising observation of a paradoxical synergistic effect between R and Cu whereby plasmid DNA cleaving / degrading activity of R-Cu increased progressively as the ratio of R to Cu was increased i.e., the concentration of Cu was successively reduced with respect to a fixed concentration R. Whereas cleavage of plasmid DNA occurred at low molar ratios of R to Cu, at higher ratios, complete degradation of DNA was achieved.","Modify,Clarity",Clarity
7305,4-1145,4-1145_v2_12@0,4-1145_v1_12@0,Preparation of Resveratrol-Cu reaction mixture and gel electrophoresis,Preparation of Resveratrol-Cu and gel electrophoresis,"Modify,Other",Other
7306,4-1145,4-1145_v2_13@5,4-1145_v1_13@2,"In case of plasmid and genomic DNA, electrophoreses was performed on a 1% agarose gel using a horizontal electrophoresis unit (Hoefer) at a constant voltage of 100V.","After incubation, the different DNA samples were electrophoresed on a 1% agarose gel using a horizontal electrophoresis unit (Hoefer) at a constant voltage of 100V.","Modify,Fact/Evidence",Fact/Evidence
7307,4-1145,4-1145_v2_13@6,4-1145_v1_13@3,"In case of eukaryotic RNA, the mixture was electrophoresed on a 0.8% agarose gel at 75 volts for 90 minutes.","In case of eukaryotic RNA, the mixtures after incubation were subjected to 0.8% agarose gel electrophoresis at 75 volts for 90 minutes.","Modify,Fact/Evidence",Fact/Evidence
7308,4-1145,4-1145_v2_34@2,4-1145_v1_15@2,"For example, cleavage of supercoiled plasmid DNA was observed at a starting concentration of 100μM at molar ratios of 1:1 and 1:0.2 (lanes 5 and 6; Figure 1 and Table ).","For example, cleavage of supercoiled plasmid DNA was observed at a starting concentration of 100μM at molar ratios of 1:1 and 1:0.2 (lanes 5 and 6; Figure 1 ).","Modify,Fact/Evidence",Fact/Evidence
7309,4-1145,4-1145_v2_34@3,4-1145_v1_15@3,"However, with successive increases in starting concentration of R-Cu to 500μM, 1mM and 5mM, DNA cleaving activity was progressively enhanced such that complete cleavage was achieved at successively higher ratios of R to Cu (i.e., with decreasing Cu concentration) ( Figure 2 – Figure 4 and Table ).","However, with successive increases in starting concentration of R-Cu to 500μM, 1mM and 5mM, DNA cleaving activity was progressively enhanced such that complete cleavage was achieved at successively higher ratios of R to Cu (i.e., with decreasing Cu concentration) ( Figure 2 – Figure 4 ).","Modify,Fact/Evidence",Fact/Evidence
7310,4-1145,4-1145_v2_34@5,4-1145_v1_15@5,These data indicated that the DNA cleaving/degrading activity of R-Cu increases as the ratio of R to Cu is successively increased thereby suggesting the existence of a paradoxical relationship between R and Cu with respect to DNA cleavage/degradation.,These data indicated that the DNA cleaving/degrading activity of R-Cu increases as the ratio of R to Cu is successively increased thereby suggesting the existence of a paradoxical synergistic relationship between R and Cu with respect to DNA cleavage/degradation.,"Modify,Clarity",Clarity
7311,4-1145,4-1145_v2_34@7,4-1145_v1_15@7,"Figure 5 and Figure 6 , in which genomic DNA and RNA respectively were used (starting molar ratio of R to Cu of 5mM:5mM), a similar paradoxical pattern was observed ( Table ).","Figure 5 and Figure 6 , in which genomic DNA and RNA respectively were used (starting molar ratio of R to Cu of 5mM:5mM), a similar synergistic pattern was observed.","Modify,Fact/Evidence",Fact/Evidence
7312,4-1145,4-1145_v2_2@3,4-1145_v1_2@3,This paradoxical relationship is also seen with respect to eukaryotic genomic DNA and RNA.,This paradoxical synergistic effect is also seen with respect to eukaryotic genomic DNA and RNA.,"Modify,Clarity",Clarity
7334,4-1521,4-1521_v2_7@1,,"The magnitude of the effect in a given data set thus depends on the extent of DTU, and the global impact is relatively small in several real data sets analyzed in this study.",,"Add,Claim",Claim
7335,4-1521,4-1521_v2_11@0,,"In addition to Data set 1 – Data set 6 , which contain all code for reproducing our analyses, further method descriptions are given in Supplementary File 1 .",,"Add,Fact/Evidence",Fact/Evidence
7336,4-1521,,4-1521_v1_7@1,,"However, despite strong overall correlations among results obtained from various quantification pipelines, taking advantage of transcript-level abundance estimates when defining or analyzing gene-level abundances leads to improved differential gene expression results compared to simple counting.","Delete,Fact/Evidence",Fact/Evidence
7337,4-1521,4-1521_v2_19@6,,"It is worth noting that we are comparing entire (typical) workflows, and that differences may also occur if the set of reads that STAR is able to align to the genome is not identical to the set of reads that are contributing to the abundance estimation of Salmon .",,"Add,Claim",Claim
7338,4-1521,4-1521_v2_19@7,,"However, due to the large fraction of aligned reads and the high mapping rate with Salmon (both exceeding 99.8%, more than 95% of the reads were subsequently unambiguously assigned to genes by featureCounts ), we do not expect this to have a major impact on the results shown in Figure 1A .",,"Add,Claim",Claim
7339,4-1521,4-1521_v2_22@1,,"To further compare the merits of genome alignment-based vs alignment-free quantification, especially in their handling of multi-mapping reads, we investigated the accuracy of the abundance estimates within sets of paralogous genes ( Supplementary Figures 1–3 ).",,"Add,Fact/Evidence",Fact/Evidence
7340,4-1521,4-1521_v2_22@2,,"Also here, Salmon provided more consistently accurate estimates than STAR+ featureCounts .",,"Add,Fact/Evidence",Fact/Evidence
7341,4-1521,4-1521_v2_22@7,,"While some extent of coverage variability might be alleviated by corrections for sequence- or position-specific biases <REF-20> , there remain cases where transcript expression cannot be inferred from data ( Figure 1C ).",,"Add,Fact/Evidence",Fact/Evidence
7342,4-1521,4-1521_v2_24@5,,"This is not surprising given the different null hypotheses, and, in fact, for many of the genes detected as true positives with the gene-level test, only a subset of the truly changing transcripts were detected ( Supplementary Figure 8 ).",,"Add,Fact/Evidence",Fact/Evidence
7343,4-1521,4-1521_v2_31@2,,"Previous studies have also shown that some loss of sensitivity for certain genes may be encountered from discarding multi-mapping fragments, which may be recovered through the use of transcript abundance estimators such as Salmon <REF-21> .",,"Add,Fact/Evidence",Fact/Evidence
7344,4-1521,4-1521_v2_41@0,,"On the six data sets studied here, simple counting with featureCounts led to very similar conclusions as estimated gene counts from Salmon , when combined with count-based statistical inference tools such as edgeR and DESeq2 .",,"Add,Fact/Evidence",Fact/Evidence
7345,4-1521,4-1521_v2_41@1,,"Moreover, p-value distributions and mean-variance relationships were similar for actual and estimated counts.",,"Add,Fact/Evidence",Fact/Evidence
7346,4-1521,4-1521_v2_41@2,,"Taken together, this suggests that the negative binomial assumption made by the count-based tools is flexible enough to accommodate also estimated counts.",,"Add,Claim",Claim
7347,4-1521,4-1521_v2_42@0,,All evaluations in this study were performed using well-established count-based differential analysis tools.,,"Add,Fact/Evidence",Fact/Evidence
7348,4-1521,4-1521_v2_42@1,,"These methods take as input a matrix of counts, which is assumed to correctly represent the origin of each read in a particular set of libraries.",,"Add,Fact/Evidence",Fact/Evidence
7349,4-1521,4-1521_v2_42@2,,"However, due to sequence similarities among transcripts or genes, there is often a hidden uncertainty in the feature abundance estimates, even when the set of input reads is fixed.",,"Add,Fact/Evidence",Fact/Evidence
7350,4-1521,4-1521_v2_42@3,,"With the development of fast, alignment-free abundance estimation methods, this uncertainty can now be estimated rapidly using bootstrap approaches (see e.g. Figure 1b ).",,"Add,Fact/Evidence",Fact/Evidence
7351,4-1521,4-1521_v2_42@4,,"Method development is currently underway in the field to account for this uncertainty in the differential expression analysis (e.g., MetaDiff <REF-27> , sleuth <REF-6> ), which has the potential to improve performance of both DTE and DGE analyses.",,"Add,Claim",Claim
7352,4-1521,4-1521_v2_42@5,,"If such methods are based on (potentially transformed) aggregated transcript counts as gene-level abundance measures, DGE analysis will still be affected by the presence of DTU, and thus could benefit from the inclusion of average transcript length offsets, or by instead using the sum of transcript TPMs as gene abundance measures.",,"Add,Claim",Claim
7353,4-1521,4-1521_v2_2@4,4-1521_v1_2@4,We also illustrate that the presence of differential isoform usage can lead to inflated false discovery rates in differential gene expression analyses on simple count matrices but that this can be addressed by incorporating offsets derived from transcript-level abundance estimates.,"We also illustrate that while the presence of differential isoform usage can lead to inflated false discovery rates in differential expression analyses on simple count matrices and transcript-level abundance estimates improve the performance in simulated data, the difference is relatively minor in several real data sets.","Split+Modify,Fact/Evidence",Fact/Evidence
7354,4-1521,4-1521_v2_2@5,4-1521_v1_2@4,We also show that the problem is relatively minor in several real data sets.,"We also illustrate that while the presence of differential isoform usage can lead to inflated false discovery rates in differential expression analyses on simple count matrices and transcript-level abundance estimates improve the performance in simulated data, the difference is relatively minor in several real data sets.","Split+Modify,Clarity",Clarity
7355,4-1521,4-1521_v2_19@0,4-1521_v1_18@0,"To evaluate the accuracy of abundance estimation with transcript and gene resolution, we used the quasi-mapping mode of Salmon <REF-7> (v0.5.1) to estimate the TPM for each transcript in each of the data sets.","To evaluate the accuracy of abundance estimation with transcript and gene resolution, we used Salmon <REF-7> (v0.5.1) to estimate TPM values for each transcript in each of the data sets.","Modify,Clarity",Clarity
7356,4-1521,4-1521_v2_19@2,4-1521_v1_18@2,"For the two simulated data sets, the true underlying TPM of each feature was known and we could thus evaluate the accuracy of the estimates.","For the two simulated data sets, the true underlying TPM of each feature is known and we can thus evaluate the accuracy of the estimates.","Modify,Grammar",Grammar
7357,4-1521,4-1521_v2_19@4,4-1521_v1_18@4,"We also derived TPM estimates from simple gene-level counts obtained from traditional alignment of the reads to the genome using STAR followed by counting with featureCounts , by dividing the read count for each gene with a reasonable measure of the length of the gene (the length of the union of its exons) and the total number of mapped reads, and scaling the estimates to sum to 1 million.","We also derived TPM estimates from gene-level counts obtained from featureCounts by dividing each of these with a reasonable measure of the length of the gene (the length of the union of its exons) and the total number of mapped reads, and scaling the estimates to sum to 1 million.","Modify,Fact/Evidence",Fact/Evidence
7358,4-1521,4-1521_v2_22@0,4-1521_v1_18@6,"Gene-level estimates derived from both simple counts and Salmon tended to show a high degree of robustness against incompleteness of the annotation catalog, as evidenced from estimation errors after first removing (at random) 20% of the transcripts ( Figure 1A , see also Supplementary File 1 ); in contrast, Salmon ’s transcript estimate accuracies deteriorated.","However, simple counts tended to show a high degree of robustness against incompleteness of the annotation catalog, as evidenced from estimation errors after first removing (at random) 20% of the transcripts ( Figure 1A ); in contrast, Salmon transcript estimate accuracies deteriorated.","Modify,Fact/Evidence",Fact/Evidence
7359,4-1521,4-1521_v2_22@4,4-1521_v1_18@8,"The gene-level estimates showed considerably lower variability than the transcript-level estimates in both simulated and experimental data ( Figure 1B , Supplementary Figures 6,7 ).","The gene-level estimates showed considerably lower variability in both simulated and experimental data ( Figure 1B , Supplementary Figures 3,4 ).","Modify,Fact/Evidence",Fact/Evidence
7360,4-1521,4-1521_v2_22@6,4-1521_v1_18@10,A further argument in favor of gene-level analysis is the unidentifiability of transcript expression that can result from uneven coverage caused by underlying technical biases.,A further argument in favor of gene-level analysis is the unidentifiability of transcript expression that can result from uneven coverage caused by underlying technical biases ( Figure 1C ).,"Modify,Fact/Evidence",Fact/Evidence
7361,4-1521,4-1521_v2_4@0,4-1521_v1_4@0,Quantification and comparison of isoform- or gene-level expression based on high throughput sequencing reads from cDNA (RNA-seq) are arguably among the most common tasks in modern computational molecular biology.,Quantification and comparison of isoform- or gene-level expression based on high throughput sequencing reads from cDNA (RNA-seq) is arguably among the most common tasks in modern computational molecular biology.,"Modify,Grammar",Grammar
7362,4-1521,4-1521_v2_24@1,4-1521_v1_22@1,"We argue that this can lead to several complications: the first is conceptual, since the rows (transcripts) in the result table will in many cases not be interpreted independently, since the researcher is often interested in comparing the results for transcripts from the same gene locus, and the second one is more technical, since the number of transcripts is considerably larger than the number of genes, which could lead to lower power due to the portioning of the total set of reads across a larger number of features and a potentially higher multiple testing penalty.","We argue that this can lead to several complications: the first is conceptual, since the rows (transcripts) in the result table will in many cases not be interpreted independently, but will rather be grouping transcripts from the same gene, and the second one is more technical, since the number of transcripts is considerably larger than the number of genes, which could lead to lower power due to the portioning of the total set of reads across a larger number of features and a potentially higher multiple testing penalty.","Modify,Claim",Claim
7363,4-1521,4-1521_v2_24@3,4-1521_v1_22@3,"Note that the transcript-level DTE test assesses the null hypothesis that individual transcripts do not change their expression, whereas the gene-level DTE test assesses the null hypothesis that all transcripts from a given gene exhibit no change in expression.","The transcript-level DTE test assesses the null hypothesis that the individual transcript does not change its expression, whereas the gene-level DTE test assesses the null hypothesis that all transcripts exhibit no change in expression.","Modify,Clarity",Clarity
7364,4-1521,4-1521_v2_4@1,4-1521_v1_4@1,"Currently, one of the most widely used approaches amounts to defining the genomic locations of a set of non-overlapping targets (typically, genes) and using the number of aligned reads overlapping a target as a measure of its abundance, or expression level.","Currently, one of the most common approaches is to define a set of non-overlapping targets (typically, genes) and use the number of reads overlapping a target as a measure of its abundance, or expression level.","Modify,Claim",Claim
7365,4-1521,4-1521_v2_27@1,4-1521_v1_25@1,"DTE can manifest in several different ways, as an overall differential expression of the gene or differential relative usage of its transcripts, or a combination of the two ( Figure 2B ).","DTE can arise in several different ways, from an overall differential expression of the gene or from differential relative usage of its transcripts, or a combination of the two ( Figure 2B ).","Modify,Clarity",Clarity
7366,4-1521,4-1521_v2_27@3,4-1521_v1_25@3,"It has been our experience that results reported at the transcript level are still often cast to the gene level (i.e., given a differentially expressed transcript, researchers want to know whether also other isoforms of the gene are changing), suggesting that asking two specific gene-level questions (Is the overall abundance changing? Are the isoform abundances changing proportionally?) trumps the interpretability of one broad question addressing the transcript abundances (Are there changes in any of the isoform expression levels?), despite the increased need for multiple testing correction associated with performing two tests for each gene rather than one.","It has been our experience that results reported at the transcript level are still often cast to the gene level (i.e., given a differentially expressed transcript, researchers want to know whether other isoforms of the gene are changing), suggesting that asking two specific gene-level questions (Is the overall abundance changing? Are the isoform abundances changing proportionally?) trumps the interpretability of one broad question at the transcript-level inference (Are there changes in any of the transcript expression levels?).","Modify,Fact/Evidence",Fact/Evidence
7367,4-1521,4-1521_v2_27@4,4-1521_v1_25@4,"There are of course also situations when a transcript-centric approach provides superior interpretability, for example in targeted experiments where specific isoforms are expected to change due to an administered treatment.","Despite this, there are of course also situations when a transcript-centric approach is superior, for example in targeted experiments where specific isoforms are expected to change due to an administered treatment.","Modify,Clarity",Clarity
7368,4-1521,4-1521_v2_29@1,4-1521_v1_27@1,"A lot has been written about how simple counting approaches are prone to give erroneous results for genes with changes in relative isoform usage, due to the direct dependence of the observed read count on the transcript length <REF-24> , and alternatives, such as Cuffdiff <REF-24> , which utilizes estimated transcript abundances, have been proposed.","A lot has been written about how simple counting approaches are prone to give erroneous results for genes with changes in relative isoform usage, due to the direct dependence of the observed read count on the transcript length <REF-23> .","Modify,Fact/Evidence",Fact/Evidence
7369,4-1521,4-1521_v2_29@3,4-1521_v1_27@3,"Here, we show that taking advantage of transcript-resolution estimates (e.g., obtained by Salmon ) in count-based inference methods can lead to improved DGE results.","Here, we show that taking advantage of transcript-resolution estimates (e.g., obtained by Salmon ) can lead to improved DGE results.","Modify,Fact/Evidence",Fact/Evidence
7370,4-1521,4-1521_v2_29@5,4-1521_v1_27@5,Both approaches are implemented in the accompanying tximport R package (available from http://bioconductor.org/packages/tximport ).,Both approaches are implemented in the accompanying tximport R package (available from https://github.com/mikelove/tximport ).,"Modify,Fact/Evidence",Fact/Evidence
7371,4-1521,4-1521_v2_30@0,4-1521_v1_28@0,"For the DGE analyses, we defined three different gene-level count matrices for each data set (see also Supplementary File 1 ): 1) using featureCounts from the Rsubread <REF-1> R package (denoted featureCounts below), 2) summing the estimated transcript counts from Salmon within genes ( simplesum ), 3) summing the estimated transcript TPMs from Salmon within genes, and multiplying with the total library size in millions ( scaledTPM ).","We defined three different count matrices for each data set: 1) using featureCounts from the Rsubread <REF-1> R package (denoted featureCounts below), 2) summing the estimated transcript counts from Salmon within genes ( simplesum ), 3) summing the estimated transcript TPMs from Salmon within genes, and multiplying with the total library size in millions ( scaledTPM ).","Modify,Fact/Evidence",Fact/Evidence
7372,4-1521,4-1521_v2_30@2,4-1521_v1_28@2,"We further used the effective transcript lengths and estimated TPMs from Salmon to define average transcript lengths for each gene and each sample (normalization factors) as described in the Supplementary material , to be used as offsets for edgeR and DESeq2 when analyzing the featureCounts and simplesum count matrices ( featureCounts_avetxl and simplesum_avetxl ).","We further used the Salmon transcript lengths and estimated TPMs to define average transcript lengths for each gene and each sample (normalization factors) as described in the Supplementary material , to be used as offsets for edgeR and DESeq2 when analyzing the featureCounts and simplesum count matrices ( featureCounts_avetxl and simplesum_avetxl ).","Modify,Clarity",Clarity
7374,4-1521,4-1521_v2_31@1,4-1521_v1_29@2,"In general, the simplesum and featureCounts matrices led to similar conclusions in all considered data sets, even though there are differences between the two approaches in terms of how multi-mapping reads and reads partly overlapping intronic regions are handled <REF-25> .","However, there are differences between the two approaches in terms of how multi-mapping reads and reads partly overlapping intronic regions are handled <REF-24> .","Merge+Modify,Clarity",Clarity
7375,4-1521,4-1521_v2_32@0,4-1521_v1_30@0,"Accounting for the potentially varying average transcript length across samples when performing DGE, either in the definition of the count matrix (scaledTPM) or by defining offsets (featureCounts_avetxl, simplesum_avetxl), led to considerably improved false discovery rate (FDR) control compared to using the observed featureCounts or aggregated Salmon counts directly ( Figure 3A , Table 1 ).","Accounting for the potentially varying average transcript length across samples when performing DGE, either in the definition of the count matrix (scaledTPM) or by defining offsets, led to considerably improved false discovery rate (FDR) control compared to using the observed featureCounts or aggregated Salmon counts (simplesum) directly ( Figure 3A , Table 1 ).","Modify,Fact/Evidence",Fact/Evidence
7376,4-1521,4-1521_v2_4@4,4-1521_v1_4@4,"These methods provide higher resolution than simple counting, and by circumventing the computationally costly read alignment step, some (notably, kallisto and Salmon ) are also considerably faster.","These methods provide higher resolution than simple counting, and by circumventing the computationally costly read alignment step, some are considerably faster.","Modify,Fact/Evidence",Fact/Evidence
7377,4-1521,4-1521_v2_32@6,4-1521_v1_30@6,Table 1 further suggests that the lack of error control for simplesum and featureCounts matrices is more pronounced when there is a large difference in length between the differentially used isoforms.,Table 1 suggests that the lack of error control for simplesum and featureCounts matrices is more pronounced when there is a large difference in length between the differentially used isoforms.,"Modify,Clarity",Clarity
7378,4-1521,4-1521_v2_5@0,4-1521_v1_5@0,Another point of debate is the unit in which abundances are given.,Another point of debate is the unit in which abundance is given.,"Modify,Grammar",Grammar
7379,4-1521,4-1521_v2_5@1,4-1521_v1_5@1,"The traditional R/FPKM <REF-8> , <REF-9> (reads/fragments per kilobase per million reads) have been largely superseded by the TPM <REF-10> (transcripts per million), since the latter is more consistent across libraries.","The traditional R/FPKM <REF-8> , <REF-9> (reads/fragments per kilobase per million reads) has been largely superseded by the TPM <REF-10> (transcripts per million), since the latter is more consistent across libraries.","Modify,Grammar",Grammar
7380,4-1521,4-1521_v2_40@0,4-1521_v1_38@0,"In this article, we have contrasted transcript- and gene-resolution analyses in terms of both abundance estimation and statistical inference, and illustrated that gene-level results are often more accurate, powerful and interpretable than transcript-level results.","In this article, we have contrasted transcript- and gene-resolution abundance estimation and statistical inference, and illustrated that gene-level results are more accurate, powerful and interpretable than transcript-level results.","Modify,Clarity",Clarity
7381,4-1521,4-1521_v2_5@2,4-1521_v1_5@2,"Regardless, all these units attempt to “correct for” sequencing depth and feature length and thus do not reflect the influence of these on quantification uncertainty.","Regardless, both of these units attempt to “correct for” sequencing depth and feature length and thus do not reflect the influence of these on quantification uncertainty.","Modify,Clarity",Clarity
7382,4-1521,4-1521_v2_40@1,4-1521_v1_38@1,"Not surprisingly, however, accurate transcript-level estimation and inference play an important role in deriving appropriate gene-level results, and it is therefore imperative to continue improving abundance estimation and inference methods applicable to individual transcripts, since misestimation can propagate to the gene level.","Not surprisingly, however, accurate transcript-level estimation and inference plays an important role in deriving appropriate gene-level results, and it is therefore imperative to continue improving abundance estimation and inference methods applicable to individual transcripts, since misestimation can propagate to the gene level.","Modify,Grammar",Grammar
7383,4-1521,4-1521_v2_41@3,4-1521_v1_39@0,"All evaluated counting approaches, with and without the inclusion of average transcript length offsets, gave comparable DGE results for genes where DTU was not present.",All evaluated counting approaches gave comparable results for genes where DTU was not present.,"Modify,Fact/Evidence",Fact/Evidence
7384,4-1521,4-1521_v2_43@0,4-1521_v1_40@0,Our results highlight the importance of carefully specifying the question of interest before selecting a statistical approach.,Our results highlight the importance of correctly specifying the question of interest before selecting a statistical approach.,"Modify,Clarity",Clarity
7385,4-1521,4-1521_v2_5@4,4-1521_v1_5@4,"Most of these tools were designed to be applied to simple read counts, and the degree to which their performance is affected by using fractional estimated counts resulting from portioning reads aligning to multiple transcripts is still an open question.","While these tools were designed to be applied to simple read counts, the degree to which their performance is affected by using fractional estimated counts resulting from portioning reads aligning to multiple transcripts is still an open question.","Modify,Clarity",Clarity
7386,4-1521,4-1521_v2_46@3,4-1521_v1_43@0,"This being said, there may of course be situations where a direct transcript-level analysis is appropriate.","Of course, there may be situations where a direct transcript-level analysis is appropriate.","Modify,Clarity",Clarity
7387,4-1521,4-1521_v2_46@0,4-1521_v1_44@0,"Finally, we note that abundance estimation at the gene level can reduce the impact of technical biases on expression levels, which have been shown to lead to estimation errors, such as expression being attributed to the wrong isoform <REF-28> .","Finally, we note that estimation at the gene level can reduce the problem of technical biases on expression levels and unidentifiable estimation.","Merge+Modify,Clarity",Clarity
7388,4-1521,4-1521_v2_5@5,4-1521_v1_5@5,"The fact that the most common sequencing protocols provide reads that are much shorter than the average transcript implies that the observed read counts depend on a transcript’s length as well as its abundance; thus, simple counts are arguably less accurate measures than TPMs of the true abundance of RNA molecules from given genes.","The fact that the most common sequencing protocols provide reads that are much shorter than the average transcript length implies that the observed read counts depend on the transcript’s length as well as abundance; thus, simple counts are arguably less accurate measures than TPMs of the true abundance of RNA molecules from given genes.","Modify,Grammar",Grammar
7389,4-1521,4-1521_v2_46@0,4-1521_v1_44@1,"Finally, we note that abundance estimation at the gene level can reduce the impact of technical biases on expression levels, which have been shown to lead to estimation errors, such as expression being attributed to the wrong isoform <REF-28> .","Current methods for transcript-level quantification (e.g., Cufflinks , RSEM , Salmon , kallisto ) do not correct for amplification bias on fragments, which can lead to many estimation errors, such as expression being attributed to the wrong isoform <REF-27> .","Merge+Modify,Fact/Evidence",Fact/Evidence
7390,4-1521,4-1521_v2_46@2,4-1521_v1_44@3,"While correction of technical artifacts in coverage can be attempted computationally, through estimation of sequence- and position-specific biases <REF-20> , we note that such errors and estimation problems are also minimized when summarizing expression to the gene level.",Such errors and estimation problems are minimized when summarizing expression to the gene level.,"Modify,Fact/Evidence",Fact/Evidence
7391,4-1521,4-1521_v2_48@0,4-1521_v1_46@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2016 Soneson C et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2015 Soneson C et al.,"Modify,Fact/Evidence",Fact/Evidence
7392,4-1521,4-1521_v2_5@6,4-1521_v1_5@6,The use of gene counts as input to statistical tools typically assumes that the length of the expressed part of a gene does not change across samples and thus its impact can be ignored for differential analysis.,The use of gene counts as input to statistical tools typically assumes that the length of the expressed part of a gene does not change across samples and thus length can therefore be ignored for differential analysis.,"Modify,Clarity",Clarity
7393,4-1521,4-1521_v2_7@0,4-1521_v1_7@0,"In this report, we make and give evidence for three claims: 1) gene-level estimation is considerably more accurate than transcript-level; 2) regardless of the level at which abundance estimation is done, inferences at the gene level are appealing in terms of robustness, statistical performance and interpretation; 3) taking advantage of transcript-level abundance estimates when defining or analyzing gene-level abundances leads to improved DGE results compared to simple counting for genes exhibiting DTU.","In this report, we make and give evidence for three claims: 1) gene-level estimation is considerably more stable than transcript-level; 2) regardless of the level at which abundance estimation is done, inferences at the gene level are appealing in terms of robustness, statistical performance and interpretation; 3) the magnitude of the difference between results obtained by simple counting and transcript-level abundance estimation is generally small in real data sets.","Modify,Fact/Evidence",Fact/Evidence
7394,4-1521,4-1521_v2_2@2,4-1521_v1_2@2,"Various quantification approaches have been proposed, ranging from simple counting of reads that overlap given genomic regions to more complex estimation of underlying transcript abundances.","Several different quantification approaches have been proposed, ranging from simple counting of reads that overlap given genomic regions to more complex estimation of underlying transcript abundances.","Modify,Clarity",Clarity
7395,4-1521,4-1521_v2_8@0,4-1521_v1_8@0,"To facilitate a broad range of analysis choices, depending on the biological question of interest, we provide an R/Bioconductor package, tximport , to import transcript lengths and abundance estimates from several popular quantification packages and export (estimated) count matrices and, optionally, average transcript length correction terms (i.e., offsets) that can be used as inputs to common statistical engines, such as DESeq2 <REF-11> , edgeR <REF-12> and limma <REF-13> .","To facilitate a broad range of analysis choices, depending on the biological question of interest, we provide an R package, tximport , to import transcript lengths and abundance estimates from several popular quantification packages and export (estimated) count matrices and, optionally, average transcript length correction terms (i.e., offsets) that can be used as inputs to common statistical engines, such as DESeq2 <REF-11> , edgeR <REF-12> and limma <REF-13> .","Modify,Fact/Evidence",Fact/Evidence
7396,4-1521,4-1521_v2_9@0,4-1521_v1_9@0,Data and methods,Data,"Modify,Other",Other
7397,4-1521,4-1521_v2_10@3,4-1521_v1_10@3,"This data set consists of three biological replicates from each of two simulated conditions, and differential isoform usage was introduced for 1,000 genes by swapping the relative expression levels of the two most dominant isoforms between conditions.","This data set has three biological replicates from each of two simulated conditions, and differential isoform usage was introduced for 1,000 genes by swapping the relative expression levels of the two most dominant isoforms.","Modify,Fact/Evidence",Fact/Evidence
7398,4-182,,4-182_v1_10@2,,Nevertheless we decided to include them to give the reader a broader view on the matter.,"Delete,Fact/Evidence",Fact/Evidence
7399,4-182,4-182_v2_24@1,4-182_v1_26@1,We analyzed 41 articles that we managed to find according to the criteria we adopted.,We analysed 41 articles that we managed to find according to the criteria we adopted.,"Modify,Grammar",Grammar
7400,4-182,4-182_v2_26@0,4-182_v1_27@0,We wanted to include only the latest data coming from research conducted after year 2000. Due to the fact that there has been very little research done in this field in general we decided to analyze papers from the whole PubMed dataset.,We wanted to include only the latest data coming from research conducted after year 2000. Due to the fact that there has been very little research done in this field in general we decided to analyse papers from the whole PubMed dataset.,"Modify,Grammar",Grammar
7401,4-182,4-182_v2_32@1,4-182_v1_33@1,"This statement is equally consistent for both Western ( Table 2 shows percentages which range from 4% in UK to 16,1% in France; and Eastern European countries such as Poland and Ukraine ( Table 3 ).","This statement is equally consistent for both Western ( Table 2 shows percentages which range from 4% in UK to 16,1% in France; Table 4 shows the percentage in Sweden – 3,8%) and Eastern European countries such as Poland and Ukraine ( Table 3 ).","Modify,Fact/Evidence",Fact/Evidence
7402,4-182,4-182_v2_38@1,4-182_v1_39@1,An optimal control of schizophrenic symptoms is proven to lead to fewer numbers of hospitalizations and less need to use other approaches of formally organized patient care <REF-19> .,An optimal control of schizophrenic symptoms is proven to lead to fewer number of hospitalizations and less need to use other approaches of formally organized patient care <REF-19> .,"Modify,Grammar",Grammar
7403,4-182,4-182_v2_38@2,4-182_v1_39@2,"Although good adherence to treatment means no reduction in the budget for pharmaceutical interventions, this cost does not seem to represent a significant percentage when compared to total cost of the illness (drugs costs vs. total costs – see Table 2 , Table 3 ).","Although good adherence to treatment means no reduction in the budget for pharmaceutical interventions, this cost does not seem to represent a significant percentage when compared to total cost of the illness (drugs costs vs. total costs – see Table 2 , Table 3 and Table 4 ).","Modify,Fact/Evidence",Fact/Evidence
7404,4-182,4-182_v2_39@1,4-182_v1_40@1,"So it is of crucial importance to investigate whether better control of symptoms could allow patients to get a chance to attain and keep a job, and how this fact could affect their quality of life.","So it is of crucial importance to a investigate whether better control of symptoms could allow patients to get a chance to attain and keep a job, and how this fact could affect their quality of life.","Modify,Grammar",Grammar
7405,4-182,4-182_v2_8@3,4-182_v1_8@3,Therefore most individuals with schizophrenia are considered disabled and claim benefits <REF-6> .,Therefore most schizophrenic patients are considered disabled and claim benefits <REF-6> .,"Modify,Clarity",Clarity
7406,4-182,4-182_v2_25@0,4-182_v1_10@1,"We have taken into account comparable data, e.g. annual expenses on schizophrenia treatment, expenses per capita on schizophrenia treatment.","Only some of the data are comparable, e.g. annual expenses on schizophrenia treatment, expenses per capita on schizophrenia treatment, while we can not compare the other data we found in such a manner.","Modify,Claim",Claim
7407,4-182,4-182_v2_25@1,4-182_v1_10@3,"In addition, we have taken into account these possible differences concerning data collecting methods used by the particular researchers, as well as different years in which the researchers conducted their studies, the comparison can only estimate the true cost of schizophrenia treatment.","As such, taking into account these possible and obvious differences concerning data collecting methods used by the particular researchers, as well as different years in which the researchers conducted their studies, the comparison can only estimate the true cost of schizophrenia treatment.","Modify,Clarity",Clarity
7408,4-182,4-182_v2_12@0,4-182_v1_12@0,"Regardless of the authors’ origin, they all agree unanimously that the costs associated with the treatment and care of patients with schizophrenia can be divided into two important groups: direct and indirect costs <REF-2> – <REF-4> , <REF-8> , <REF-9> .","Regardless of the authors’ origin, they all agree unanimously that the costs associated with the treatment and care of schizophrenic patients can be divided into two important groups: direct and indirect costs <REF-2> – <REF-4> , <REF-8> , <REF-9> .","Modify,Clarity",Clarity
7409,4-182,4-182_v2_18@0,4-182_v1_18@0,"The main part of data used in this article come from psychiatric wards in Spain, France, Sweden, Poland, United Kingdom and Ukraine ( Table 2 and Table 3 ).","The main part of data used in this article come from psychiatric wards in Spain, France, Sweden, Poland, United Kingdom and Ukraine ( Table 2 , Table 3 and Table 4 ).","Modify,Fact/Evidence",Fact/Evidence
7410,4-45,4-45_v2_63@2,,This finding likely reflects the reduced conformational flexibility of the AB loop imposed by both crystal packing and especially by the electrostatic interactions favored by the head-to-tail arrangement of the proteins in the crystallographic structure.,,"Add,Claim",Claim
7411,4-45,4-45_v2_77@6,,"This procedure may admittedly slightly bias the kinetics since the offset extrapolated beyond 2 ns is retrieved with a limited precision, but the effect on microscopic rates is expected to be minor.",,"Add,Claim",Claim
7412,4-45,4-45_v2_77@7,,"Simulations demonstrate that an over-/under-estimate of the extrapolated signal from the subnanosecond kinetics by approximately 10%, results in changes of less than 15% in k 2 and much smaller changes in other microscopic rates.",,"Add,Fact/Evidence",Fact/Evidence
7413,4-45,4-45_v2_77@8,,The impact on k ON is less than 5%.,,"Add,Fact/Evidence",Fact/Evidence
7414,4-45,4-45_v2_84@1,,"The model was fit to the observed kinetics using a global analysis of progress curves measured at 1 and 0.1 atm CO, in order to increase the reliability of retrieved parameters.",,"Add,Fact/Evidence",Fact/Evidence
7415,4-45,4-45_v2_93@0,,"Similarly, CO rebinding to TrHbO from Mycobacterium tuberculosis occurs on the picosecond time scale with biexponential kinetics, whose apparent lifetimes are on the same order of magnitude as those observed from Thermobifida fusca TrHbO <REF-67> .",,"Add,Fact/Evidence",Fact/Evidence
7416,4-45,4-45_v2_93@1,,Molecular dynamics simulations suggest that the presence of water molecules influences the rebinding kinetics.,,"Add,Claim",Claim
7417,4-45,4-45_v2_93@2,,"Mutations at G8 and CD1 positions were found to affect lifetimes, and in some cases lead to the appearance of third kinetic phase.",,"Add,Fact/Evidence",Fact/Evidence
7418,4-45,4-45_v2_93@3,,A direct comparison of rate constants is not possible since only apparent rates were reported.,,"Add,Claim",Claim
7419,4-45,4-45_v2_95@0,,"The ultrafast dynamics of ligands within heme proteins have been the subject of several studies which were recently reviewed <REF-68> , <REF-69> .",,"Add,Fact/Evidence",Fact/Evidence
7420,4-45,4-45_v2_95@1,,"While it has long been known that ligands like O 2 and NO rebind on subnanosecond time scale, more recently a few hemeproteins were reported to rebind CO on the picoseconds time scale, some of them through multiple exponential kinetics.",,"Add,Claim",Claim
7421,4-45,4-45_v2_95@2,,"Besides TrHbO from Mycobacterium tuberculosis <REF-67> , ultrafast CO rebinding was observed for the oxygen sensor Dos from Escherichia coli <REF-70> , the heme-based GAF sensor domains of the histidine kinases DosS and DosT from Mycobacterium tuberculosis <REF-71> , and the CO-sensing transcriptional activator CooA <REF-72> .",,"Add,Fact/Evidence",Fact/Evidence
7422,4-45,4-45_v2_95@3,,"A direct comparison with microscopic rates in Table 3 is difficult, because rate constants from fully microscopic kinetic models were not obtained in those studies.",,"Add,Claim",Claim
7423,4-45,4-45_v2_99@1,,"In particular, the large structural resemblance observed in the heme pocket for liganded and unliganded forms of NP7 support the functional role as a reservoir for NO storage, as it is widely accepted for this famility of proteins.",,"Add,Claim",Claim
7424,4-45,4-45_v2_99@4,,"These features, together with the presence of tunnels and cavities in the interior of the lipocalin fold, suggest that NP7 could have specific pathways for direct exchange of NO with the membrane.",,"Add,Claim",Claim
7425,4-45,4-45_v2_100@4,,The future availability of a crystal structure of the protein mutant Leu-Pro-Gly stretch at the N-terminus may shed light on the role of this short sequence.,,"Add,Claim",Claim
7426,4-45,4-45_v2_53@7,4-45_v1_53@7,Phe43 is oriented parallel to the heme plane with a distance of 3.5 Å leading to π-stacking between the two aromatic rings.,Phe43 is oriented parallel to the heme plane with a distance of 3.5 Ǻ leading to π-stacking between the two aromatic rings.,"Modify,Grammar",Grammar
7427,4-45,4-45_v2_53@8,4-45_v1_53@8,"Moreover, the phenyl ring is perpendicularly oriented toward the His60 plane with a distance of 3.6 Å. The distance between Glu27:C β and Phe43:C β is 4.0 Å, while Glu27 also H-bonds to Phe43:NH.","Moreover, the phenyl ring is perpendicularly oriented toward the His60 plane with a distance of 3.6 Ǻ. The distance between Glu27:C β and Phe43:C β is 4.0 Ǻ, while Glu27 also H-bonds to Phe43:NH.","Modify,Grammar",Grammar
7428,4-45,4-45_v2_57@0,4-45_v1_57@0,"In the crystal structure, NO (occupancy 0.44) is bound with ∠(Fe–N–O) = 124°, which corresponds to a reduced iron, i.e. Fe II (NO).","In the crystal structure, NO is bound with ∠(Fe–N–O) = 124°, which corresponds to a reduced iron, i.e. Fe II (NO).","Modify,Fact/Evidence",Fact/Evidence
7429,4-45,4-45_v2_5@2,4-45_v1_5@2,"While NP1 has a high sequence identity with NP4 (88%) and NP2 is highly similar to NP3 (81%), NP7 exhibits notable differences, which are mostly reflected in its high p I of 9.2 compared to the range of 6.1–6.5 covered by NP1-4 <REF-8> .","While NP1 and NP2 share very high amino acid sequence identity with NP4 (88%) and NP3 (81%), respectively, NP7 exhibits notable differences, which are mostly reflected in its high p I of 9.2 compared to the range of 6.1–6.5 covered by NP1-4 <REF-8> .","Modify,Clarity",Clarity
7430,4-45,4-45_v2_2@1,4-45_v1_2@1,"Besides its ability to bind to phospholipid membranes, the N-terminus of NP7, a member of the NO transporter nitrophorin family, contains an additional Leu-Pro-Gly stretch, which is a unique sequence trait, and the heme cavity is significantly altered with respect to other nitrophorins.","Besides its ability to bind to phospholipid membranes, the N-terminus contains an additional Leu-Pro-Gly stretch, which is a unique sequence trait, and the heme cavity is significantly altered with respect to other nitrophorins.","Modify,Clarity",Clarity
7431,4-45,4-45_v2_63@1,4-45_v1_63@1,"However, no significant conformational differences were found between the X-ray structures collected at two different pHs (5.8 and 7.8; RMSD = 0.22 Å).","However, no significant conformational differences were found between the X-ray structures collected at two different pHs (5.8 and 7.8; RMSD = 0.22 Å), even though this might simply arise from the packing of NP7 molecules in the crystal.","Modify,Claim",Claim
7432,4-45,4-45_v2_63@5,4-45_v1_63@4,"However, it is unclear whether these differences may be attributed exclusively to the head-to-tail arrangement (see above and Figure 2 ), or alternatively may also be influenced to some extent by the distinct N-terminus stretch of NP7, which fills the region between A-B and G-H loops ( Figure S2 ).","However, it is unclear whether these differences are due to the head-to-tail arrangement (see above and Figure 2 ), or alternatively might be influenced by the distinct N-terminus stretch of NP7, which fills the region between A-B and G-H loops ( Figure S2 ).","Modify,Clarity",Clarity
7433,4-45,4-45_v2_6@1,4-45_v1_6@1,Here we report on six crystal structures of NP7 at low and high pH and with different heme ligands.,Here we report on seven crystal structures of NP7 at low and high pH and with different heme ligands.,"Modify,Fact/Evidence",Fact/Evidence
7434,4-45,4-45_v2_81@6,4-45_v1_81@6,"Hence, it can be expected that rebinding of photolyzed CO would occur from a variety of transient docking sites, reflecting the topological distribution of pockets located close to the heme (these are represented as the orange and magenta isocontours at around ~9 Å from the heme iron in Figure 10 ) as well as from inner cavities present at the rear of the protein (at around ~22 Å from the heme iron), which can be visited via the inner tunnel present as a distinctive feature in NP7 compared to other NPs.","Hence, it can be expected that rebinding of photolyzed CO would occur from a variety of transient docking sites, reflecting the topological distribution of pockets located close to the heme (at around ~9 Å from the heme iron) as well as from inner cavities present at the rear of the protein (at around ~22 Å from the heme iron), which can be visited via the inner tunnel present as a distinctive feature in NP7 compared to other NPs.","Modify,Fact/Evidence",Fact/Evidence
7435,4-45,4-45_v2_84@0,4-45_v1_84@0,"On the basis of the previous findings, the reaction scheme previously proposed by us <REF-59> is then expanded as shown in Figure 11 to accommodate for transient population (likely located at the orange and magenta isocontours in Figure 10 ) and T 4 (blue isocontour in Figure 10 ) of the ligand in docking sites located nearby the distal pocket (DP), and is found to describe well the rebinding kinetics under the investigated experimental conditions.","On the basis of the previous findings, the reaction scheme previously proposed by us <REF-59> is then expanded as shown in Figure 11 to accommodate for transient population T 2 , T 3 and T 4 of the ligand in docking sites located nearby the distal pocket (DP), and is found to describe well the rebinding kinetics under the investigated experimental conditions.","Modify,Fact/Evidence",Fact/Evidence
7436,4-45,4-45_v2_89@3,4-45_v1_89@3,"This nicely parallels the finding of two large and accessible pathways connecting the distal pocket and the solvent (denoted cage-to-top and cage-to-front in Figure 10b ), which can be ascribed to the larger fluctuations of the A-B and G-H loop and widening of the heme cavity in the closed form of wild type NP7 (see Figure 7b ).","This nicely parallels the finding of two large and accessible pathways connecting the distal pocket and the solvent (denoted cage-to-top and cage-to-fron in Figure 10b ), which can be ascribed to the larger fluctuations of the A-B and G-H loop and widening of the heme cavity in the closed form of wild type NP7 (see Figure 7b ).","Modify,Grammar",Grammar
7437,4-45,4-45_v2_99@2,4-45_v1_97@1,"A peculiar feature of NP7, nevertheless, is the extensive clustering of Lys side-chains at the protein surface opposite the heme pocket, which is implicated in the charge-stabilized head-to-tail interaction observed in the crystal lattice.","These structures reveal the extensive clustering of Lys side-chains at the protein surface opposite the heme pocket, which is implicated in the charge-stabilized head-to-tail interaction observed in the crystal lattice.","Modify,Clarity",Clarity
7438,4-45,4-45_v2_100@5,4-45_v1_98@4,"Finally, the role of Glu27 is still poorly understood and deserves further investigations.","In particular, the role of Glu27 is still poorly understood and deserves further investigations.","Modify,Clarity",Clarity
7439,4-45,4-45_v2_15@0,4-45_v1_13@0,Samples for kinetic investigation (both for the ultrafast and the nanosecond experiments) were prepared by equilibrating 80 μM NP solutions in a sealed 0.2×1 cm-quartz cuvette connected to a tonometer with 0.1 or 1 atm CO.,Samples for laser flash photolysis experiments were prepared by equilibrating the solutions in a sealed 0.2×1 cm-quartz cuvette connected to a tonometer with 0.1 or 1 atm CO.,"Modify,Fact/Evidence",Fact/Evidence
7440,4-76,4-76_v2_8@0,,Routes into Teaching-Focussed careers: Personal Perspectives,,"Add,Other",Other
7441,4-76,4-76_v2_9@3,,"We present our experiences as case studies below to illustrate a range of paths into teaching positions, while also identifying striking similarities in the challenges of establishing Teaching-Focussed careers.",,"Add,Fact/Evidence",Fact/Evidence
7442,4-76,4-76_v2_23@0,,"The four of us therefore represent academics who are passionate about developing an academic teaching career, and find engaging in teaching and learning to be both challenging and rewarding at a personal level.",,"Add,Claim",Claim
7443,4-76,4-76_v2_23@1,,"However, it is worth considering the broader question of how having Teaching-Focussed academics benefits the wider educational and research community, beyond offering people like ourselves the satisfaction of doing what we love.",,"Add,Claim",Claim
7444,4-76,4-76_v2_25@0,,"At the level of institutions and departments, budgets are under considerable pressure.",,"Add,Claim",Claim
7445,4-76,4-76_v2_25@1,,Recent rounds of Higher Education Funding Council for England (HEFCE) allocations have resulted in reduced funding for university teaching.,,"Add,Fact/Evidence",Fact/Evidence
7446,4-76,4-76_v2_25@2,,"In the face of institutional financial pressures, it is critically important to highlight the value that Teaching-Focussed academics can bring to departments, in addition to delivering direct teaching contact sessions.",,"Add,Claim",Claim
7447,4-76,4-76_v2_26@1,,"There is considerable variation in the extent to which academics reflect on their teaching, with most academics deliberating on personal experiences more than research-based or published knowledge of teaching and learning ( Kreber, 2005 ).",,"Add,Fact/Evidence",Fact/Evidence
7448,4-76,4-76_v2_26@3,,"Teaching-Focussed academics are also well placed to contribute to this literature through the Scholarship of Teaching and Learning (SoTL), thereby communicating ideas between institutions and providing publication opportunities for those in teaching positions ( Roxå et al. , 2007 ).",,"Add,Fact/Evidence",Fact/Evidence
7449,4-76,4-76_v2_26@4,,"Engaging in SoTL also gives the potential to influence local institutional policy ( Roxå et al. , 2007 ), meaning Teaching-Focussed academics represent a potentially powerful force to embed student-centred learning across the whole range of academic institutions.",,"Add,Claim",Claim
7450,4-76,,4-76_v1_9@3,,"As such, we have much to offer our respective institutions, independent of the type of university we work in.","Delete,Claim",Claim
7451,4-76,4-76_v2_40@0,,Conclusion,,"Add,Other",Other
7452,4-76,,4-76_v1_10@2,,Teaching-Focussed staff therefore represent a powerful force to embed student-centred learning across the whole range of academic institutions.,"Delete,Claim",Claim
7453,4-76,4-76_v2_30@3,4-76_v1_14@3,"The vocabulary and style of pedagogical literature can be quite different than that of science ( Roxå et al. , 2007 ), and the lack of immediate peers can make engaging with the literature more challenging.","The vocabulary and style of pedagogical literature can be quite different than that of bioscience, and the lack of immediate peers can make engaging with the literature more challenging.","Modify,Fact/Evidence",Fact/Evidence
7454,4-76,4-76_v2_30@5,4-76_v1_14@5,"These factors can lead to a feeling of isolation amongst Teaching-Focussed academics, which several of us have experienced during our careers (see Case study 2 and Case study 3 ) and which can be frustrating and demoralising.","These factors can lead to a feeling of isolation amongst Teaching-Focussed academics, which several of us have experienced during our careers (see case studies) and which can be frustrating and demoralising.","Modify,Clarity",Clarity
7455,4-76,4-76_v2_33@2,4-76_v1_17@2,"However, these courses can be difficult to access for the large numbers of teaching dominant staff on part-time and/or fixed term contracts, those who do not have time allocated for continuing professional development (CPD) in their positions, or are in institutions who do not offer this support.","However, these courses can be difficult to access for the large numbers of teaching dominant staff on part-time and/or fixed term contracts, those who do have time allocated for continuing professional development (CPD) in their positions, or are in institutions who do not offer this support.","Modify,Claim",Claim
7456,4-76,4-76_v2_33@3,4-76_v1_17@3,"Therefore there is a need for professional development at a national level; in the past this has been provided by the Higher Education Academy who made available a wealth of resources, primarily through the Centre for Bioscience.","There is therefore a need for professional development at a national level; in the past this has been provided by the Higher Education Academy who made available a wealth of resources, primarily through the Centre for Bioscience.","Modify,Clarity",Clarity
7457,4-76,4-76_v2_34@4,4-76_v1_18@4,Education meetings run by organisations such as SEB are hugely important in providing Teaching-Focussed academics opportunities to meet and exchange ideas; none of the authors of this piece knew each other before attending SEB meetings.,Education meetings run by organisations such as SEB are hugely important in providing Teaching-Focussed academics to meet and exchange ideas; none of the authors of this piece knew each other before attending SEB meetings.,"Modify,Clarity",Clarity
7458,4-76,4-76_v2_35@0,4-76_v1_19@0,"Discussions on supporting bioscience teaching at both the SEB education meeting (2014) and the final HEA-funded Biosciences meeting (University of Newcastle, 2014) have acknowledged the fact that the learned societies for biology in the UK are very fragmented.","Discussions on supporting bioscience teaching at both the SEB education meeting (2014) and at a recent HEA Biosciences meeting (University of Newcastle, 2014) have included the fact that the learned societies for biology in the UK are very fragmented.","Modify,Clarity",Clarity
7459,4-76,4-76_v2_35@3,4-76_v1_19@3,"For the early-career bioscience teacher, it can be unclear which society is the natural ‘home’ for them, and belonging to all societies would be prohibitively expensive.","For the early-career bioscience teacher it can be unclear which society is the natural ‘home’ for them, and belonging to all societies would be prohibitively expensive.","Modify,Grammar",Grammar
7460,4-76,4-76_v2_41@0,4-76_v1_24@0,"Early career Teaching-Focussed academics make valuable contributions to bioscience departments, and institutions should be enabling these academics to achieve their full potential, both in terms of their immediate teaching responsibilities to their students and their long term career progression.","In conclusion, early-career Teaching-Focussed academics make valuable contributions to bioscience departments, and institutions should be enabling these academics to achieve their full potential, both in terms of their immediate teaching responsibilities to their students and their long term career progression.","Modify,Clarity",Clarity
7461,4-76,4-76_v2_41@3,4-76_v1_24@3,"As the HEA is unlikely to fund subject-specific initiatives again without a major increase in funding, it falls to the learned societies to provide cross-institutional support for Teaching-Focussed academics, particularly through bioscience education conferences.","As the HEA is unlikely to fund subject-specific initiatives again without a major increase in funding, it falls to the learned societies to provide cross-institutional support for Teaching-Focussed academics, particularly through providing bioscience education conferences.","Modify,Clarity",Clarity
7462,4-76,4-76_v2_15@5,4-76_v1_30@5,"I joined a CPD course in learning and teaching run by the University of Oxford’s Learning Institute and was lucky to be mentored by an inspirational educator, Dr Chris Trevitt.","I joined a CPD course in learning and teaching run by the University of Oxford’s Learning Institute and was lucky to be mentored by an inspirational educator, Dr Chris Trevitt, who has since left Oxford.","Modify,Clarity",Clarity
7463,4-76,4-76_v2_19@0,4-76_v1_34@0,"In my current job I find that my contributions to my college, department and inter-departmental teaching are highly valued at a personal level, including by the current Head of Department and other senior academics, but that in terms of the institution I am very much a ‘square peg in a round hole’. I am the only early-career Teaching-Focussed academic in biological sciences, which often feels very isolating as I lack immediate peer support.","In my current job I find that my contributions to my college, department and inter-departmental teaching are highly valued at a personal level, including by the current Head of Department and other senior academics, but that in terms of the institution I am very much a ‘square peg in a round hole’. I am the only early-career Teaching-Focussed academic in biological sciences, which often feels very isolated as I lack immediate peer support.","Modify,Grammar",Grammar
7464,4-76,4-76_v2_4@6,4-76_v1_4@6,Here we reflect on our experiences as early-career teaching orientated academics in a range of UK Higher Education (HE) institutions.,Here we present our experiences as early-career teaching orientated academics in a range of UK Higher Education (HE) institutions to explore both the challenges and opportunities of working in teaching roles.,"Split+Modify,Clarity",Clarity
7465,4-76,4-76_v2_4@7,4-76_v1_4@6,"We also present case studies of our careers thus far, to illustrate both the challenges and opportunities of working in teaching roles.",Here we present our experiences as early-career teaching orientated academics in a range of UK Higher Education (HE) institutions to explore both the challenges and opportunities of working in teaching roles.,"Split+Modify,Fact/Evidence",Fact/Evidence
7466,4-76,4-76_v2_5@0,4-76_v1_5@0,"Teaching-Focussed academics are employed on a range of different contracts; some are on Teaching-only contracts and are responsible just for covering a given number of hours of contact time, but an increasing number are on Teaching and Scholarship contracts, with an explicit part of their role being to advance understanding of teaching and learning.","Teaching-Focussed academics are employed on a range of different bases; some are on Teaching-Focussed contracts and are responsible just for covering a given number of hours of contact time, but an increasing number are on Teaching and Scholarship contracts, with an explicit part of their role being to advance understanding of teaching and learning.","Modify,Clarity",Clarity
7467,4-76,4-76_v2_5@2,4-76_v1_5@2,The employment profiles of Teaching-Focussed academics are markedly different to those on Teaching and Research or Research-Only contracts.,The employment profiles of Teaching-Focussed academics are significantly different to those on Teaching and Research or research-only contracts.,"Modify,Clarity",Clarity
7468,4-76,4-76_v2_9@0,4-76_v1_9@0,"When preparing this article, all of us described experiencing a bias in careers advice we had received, with a heavy focus on the traditional research-dominated model of academia (see case study 1 and case study 3 ).","When preparing this article all of us described experiencing a bias in careers advice we had received, with a heavy focus on the traditional research dominated model of academia.","Modify,Fact/Evidence",Fact/Evidence
7469,4-76,4-76_v2_9@2,4-76_v1_9@2,"Teaching-Focussed academics take a diversity of routes towards their roles; some move into teaching at later career stages, but we represent a group of academics who have actively chosen to focus on teaching at an early-career stage, having recognised we have the skills and passion for it.","Teaching-Focussed academics take a diversity of routes towards their roles; some move into teaching at later career stages, but we represent a group of academics who have actively chosen to focus on teaching at an early-career stage having recognised we have the skills and passion for it.","Modify,Grammar",Grammar
7470,4-76,4-76_v2_29@1,4-76_v1_13@1,"Unlike research which has a well-defined (though not necessarily flawless) path to lectureship, currently there appears to be no clear route to a teaching dominant academic role in the sciences within most UK academic institutions (see case studies).","Unlike research which has a well-defined (though not necessarily flawless) path to lectureship, currently there appears to be no clear route to a teaching dominant academic role in the sciences within most UK academic institutions, although some have created Teaching-Focussed career paths (e.g. University of Bristol).","Split+Modify,Fact/Evidence",Fact/Evidence
7471,4-76,4-76_v2_29@2,4-76_v1_13@1,Some universities have created Teaching-Focussed career paths (e.g. University of Bristol) but the lack of clear routes makes embarking on a teaching career a potentially risky choice; we have all personally experienced this uncertainty in our careers (see case studies ).,"Unlike research which has a well-defined (though not necessarily flawless) path to lectureship, currently there appears to be no clear route to a teaching dominant academic role in the sciences within most UK academic institutions, although some have created Teaching-Focussed career paths (e.g. University of Bristol).","Split+Modify,Claim",Claim
7472,4-76,4-76_v2_29@3,4-76_v1_13@2,"Most advertised teaching fellow positions require a PhD and teaching experience, but the opportunities to gain teaching experience and/or training during a PhD or post-doctoral position are mixed and often limited, with supervisors prioritising the publication of papers over the development of non-research skills (see Case study 1 ).","Most advertised teaching fellow positions require a PhD and teaching experience, but the opportunities to gain teaching experience and/or training during a PhD or post-doctoral position are mixed and often limited, with supervisors prioritising the publication of papers over the development of non-research skills.","Modify,Fact/Evidence",Fact/Evidence
7473,4-8,4-8_v2_10@5,,"Original studies including larger sample sizes and sound methodology, and review articles based on broad set of studies (case-controlled, cross sectional, randomized trials) were given priority in the selection of studies.",,"Add,Fact/Evidence",Fact/Evidence
7474,4-8,4-8_v2_41@13,,Table 4 presents a list of studies indicating the various socioeconomic and public health impacts of dietary and epidemiological transition.,,"Add,Fact/Evidence",Fact/Evidence
7475,4-8,4-8_v2_21@0,4-8_v1_21@0,"Today, people in developing countries can afford more calories than ever before which is largely attributable to increased disposable income and greater availability of food (Josef et al. , 2005).","Today, people in developing countries can afford more calories than ever before which is largely attributable to increased disposable income and greater availability of food ( Josef et al. , 2005 ).","Modify,Grammar",Grammar
7476,4-8,4-8_v2_21@3,4-8_v1_21@3,Figure 3 shows that total meat consumption has increased significantly in all South Asian countries over past two decades.,Figure 3 shows that total meat consumption has increased significantly in all South Asian countries over past past two decades.,"Modify,Grammar",Grammar
7477,4-8,4-8_v2_21@5,4-8_v1_21@5,"Per capita GDP growth has seen a dramatic leap since 2001 [ Table 2 ] which has played a catalytic role in increasing the demand for meat, fish, egg, and dairy products (Freedman, 2002).","Per capita GDP growth has seen a dramatic leap since 2001 [ Table 2 ] which has played a catalytic role in increasing the demand for meat, fish, egg, and dairy products ( Freedman, 2002 ).","Modify,Grammar",Grammar
7478,4-8,4-8_v2_21@6,4-8_v1_21@6,"Many researchers attributed the food price inflation of 2007–08 to the rising demand from India and China as the countries are becoming major food importers to meet huge domestic demand ( Ghose, 2014 ).",Many researchers attributed the food price inflation of 2007–08 to the rising demand from India and China as the countries are becoming major food importers to meet huge domestic demand.,"Modify,Fact/Evidence",Fact/Evidence
7480,4-8,4-8_v2_6@1,4-8_v1_6@0,Changes in dietary pattern have shown to be a major underlying factor for increasing prevalence of obesity and associated NCDs.,Globalization of agrifood has brought about remarkable shifts in diet patterns especially in developing countries which has shown to be a major underlying factor for increasing prevalence of obesity and associated NCDs.,"Split+Modify,Clarity",Clarity
7481,4-8,4-8_v2_27@12,4-8_v1_27@12,"As more and more women are joining the labour force, it is very likely that households will have to rely more on precooked convenience food and fast food rather than home cooked traditional food due to increasing time constraints.","As more and more women are joining the labour force, it greatly influencing the shift from home cooked traditional food towards precooked convenience food and fast food both at home and outside.","Modify,Claim",Claim
7482,4-8,4-8_v2_27@13,4-8_v1_27@13,"A substantial increase in childhood as well as adult obesity in the urban population is therefore in line with the radical changes in lifestyle during the last few decades ( Han et al. , 2010 ).",A substantial increase in childhood as well as adult obesity in the urban population is therefore in line with the radical changes in lifestyle during the last few decades.,"Modify,Fact/Evidence",Fact/Evidence
7483,4-8,4-8_v2_31@3,4-8_v1_31@3,"Following the Uruguay Round, the average tariff on most goods fell from about 40% in 1947 to 4.7% in 1993 (Paul, 2008).","Following the Uruguay Round, the average tariff on most goods fell from about 40% in 1947 to 4.7% in 1993 ( Paul, 2008 ).","Modify,Grammar",Grammar
7484,4-8,4-8_v2_35@2,4-8_v1_35@2,"In industrialized countries, epidemiological transition emerged towards the early 1900s marked by a rising levels of NCDs and a drastic fall in the prevalence infectious disease (Detels, 1997).","In industrialized countries, epidemiological transition emerged towards the early 1900s marked by a rising levels of NCDs and a drastic fall in the prevalence infectious disease ( Detels, 1997 ).","Modify,Grammar",Grammar
7485,4-8,4-8_v2_35@3,4-8_v1_35@3,"This rising prevalence NCDs is believed to be an outcome of a complex interplay between a demographic ( Stuckler, 2008 ), socio-economic ( Thakur et al. , 2011 ), nutritional, environmental factors along with changes in lifestyle pattern ( Popkin et al. , 2012 ).","This rising prevalence NCDs is believed to be an outcome of a complex interplay between a demographic, socio-economic, nutritional, environmental factors along with changes in lifestyle pattern.","Modify,Fact/Evidence",Fact/Evidence
7486,4-8,4-8_v2_35@5,4-8_v1_35@5,"Globally, NCDs have become the leading causes of morbidity and mortality (Accounting for 43% of all disease burden in 1999) and is projected overtake that of infectious diseases within a decade (Wagner et al. , 2012).","Globally, NCDs have become the leading causes of morbidity and mortality (Accounting for 43% of all disease burden in 1999) and is projected overtake that of infectious diseases within a decade ( Wagner et al. , 2012 ).","Modify,Grammar",Grammar
7487,4-8,4-8_v2_36@0,4-8_v1_36@0,"In contrast with developed countries where the disease burden is dominated by NCDs (with lower proportion of infectious diseases), countries in the developing world are facing a double burden of malnutrition (Paul, 2008).","While in the developed countries the battle is chiefly against NCDs, people in developing countries are facing a double burden malnutrition ( Paul, 2008 ), 9].","Modify,Fact/Evidence",Fact/Evidence
7488,4-8,4-8_v2_36@1,4-8_v1_36@1,"Like other developing regions, South Asian countries are also facing a double burden of malnutrition ( Haddad et al. , 2015 ) [ Figure 5 ].","Like other developing regions, South Asian countries are also facing a double burden of malnutrition [ Figure 5 ].","Modify,Fact/Evidence",Fact/Evidence
7489,4-8,4-8_v2_39@3,4-8_v1_39@3,"Bangladesh alone accounts for 40% of all diabetes patients located in least developed countries and the number is increasing by 5–6 percent a year ( Ramachandran et al. , 2008 ).",Bangladesh alone accounts for 40% of all diabetes patients located in least developed countries and the number is increasing by 5–6 percent a year.,"Modify,Fact/Evidence",Fact/Evidence
7490,4-8,4-8_v2_41@0,4-8_v1_41@0,"NCDs are both a determinant and result of poor socio-economic status and exert an important bearing especially on the poor households as they require a long-term treatment ( Thakur et al. , 2011 ).",NCDs are both a determinant and result of poor socio-economic status and exert an important bearing especially on the poor households as they require a long-term treatment.,"Modify,Fact/Evidence",Fact/Evidence
7491,4-8,4-8_v2_41@5,4-8_v1_41@5,"Studies have shown that South Asian nations incur about a 5% loss of their annual GDP due to substandard sanitation and hygiene facilities while infections account for 20% of DALYs (Disability Adjusted Life Years) ( Basnyat & Rajapaksa, 2004 ).","Studies have shown that South Asian nations incur about a 5% loss of their annual GDP due to substandard sanitation and hygiene facilities while infections account for 20% of DALYs ( Basnyat & Rajapaksa, 2004 ).","Modify,Clarity",Clarity
7492,4-8,4-8_v2_41@7,4-8_v1_41@7,"Main direct costs of NCDs include the fees for hospitalization, transportation, drugs and some indirect costs are loss of work days, absenteeism, reduced workplace productivity ( Kankeu et al. , 2013 ).","Main direct costs of NCDs include the fees for hospitalization, transportation, drugs and some indirect costs are loss of work days, absenteeism, reduced workplace productivity.","Modify,Fact/Evidence",Fact/Evidence
7493,4-8,4-8_v2_41@12,4-8_v1_41@12,NCDs are also responsible for unhealthy aging and increases the burden of medical spending in later years which put huge pressure on savings and household assets.,NCDs are also responsible for unhealthy aging and increases the burden of medical spending in later years which put huge pressure on of savings and household assets.,"Modify,Grammar",Grammar
7494,4-8,4-8_v2_47@0,4-8_v1_45@0,"Strategic food policy making to control unhealthy dietary behaviour has been in place in many countries ( Rangel, 2013 ).",Strategic food policy making to control unhealthy dietary behaviour has been in place in many countries.,"Modify,Fact/Evidence",Fact/Evidence
7495,4-8,4-8_v2_47@6,4-8_v1_45@6,"Globally, expenditure on food advertisements has almost doubled in real terms since 1980 ($512 billion in 1980 compared to $216 billion in 2004) ( Hawkes, 2006 ).","Globally, expenditure on food advertisements has almost doubled in real terms since 1980 ($512 billion in 1980 compared to $216 billion in 2004).","Modify,Fact/Evidence",Fact/Evidence
7496,4-8,4-8_v2_6@9,4-8_v1_6@8,"Despite the global recession, India’s share in global trade increased to 1.28 per cent in 2011 compared to 0.67 per cent a decade earlier (Mubarak, 2012).","Despite the global recession, India’s share in global trade increased to 1.28 per cent in 2011 compared to 0.67 per cent a decade earlier.","Modify,Fact/Evidence",Fact/Evidence
7497,4-8,4-8_v2_53@3,4-8_v1_51@3,"A large volume of literature has been published in the last decade focusing on the importance of physical activity for the effective prevention management obesity and NCDs (Lim, 2012).","A large volume of literature has been published in the last decade focusing on the importance of physical activity for the effective prevention management obesity and NCDs ( Lim, 2012 ).","Modify,Grammar",Grammar
7498,4-8,4-8_v2_53@4,4-8_v1_51@4,"Most studies have highlighted that the decreasing space for physical activities is an important factor for the higher prevalence of NCDs in urban settings ( Tamosiunas et al. , 2014 ; Vaidya & Krettek, 2014 ).",Most studies have highlighted that the decreasing space for physical activities is an important factor for the higher prevalence of NCDs in urban settings.,"Modify,Fact/Evidence",Fact/Evidence
7499,4-8,4-8_v2_6@13,4-8_v1_6@12,"India with around 35% total population living on vegetarian diet ( Michalak et al. , 2012 ) has experienced a doubling in total poultry meat consumption since 2000 while in Pakistan total meat consumption has increased by 130% during the same period ( Tirmizi, 2012 ).","India with around 40% total population living on vegetarian diet, has experienced a doubling in total poultry meat consumption since 2000 while in Pakistan total meat consumption has increased by 130% during the same period.","Modify,Fact/Evidence",Fact/Evidence
7500,4-8,4-8_v2_6@16,4-8_v1_6@15,"Rapid urbanization, access to labor-saving technologies and rise in various non-farm sectors have reduced the need and scope for physical activities to a level a level which is contributing to a sharp rise in the prevalence of overweight and obesity.","Rapid urbanization, access to labour-saving technologies and rise in various non-farm sectors have reduced the need and scope for physical activities to a level a level which is contributing to a sharp rise in the prevalence of overweight and obesity.","Modify,Grammar",Grammar
7501,4-8,4-8_v2_6@17,4-8_v1_6@16,"However, the benefit of economic growth didn’t translate to improved nutritional status for the population at large, a phenomenon which is known as the South Asian enigma (Guha-Khasnobis et al. , 2010).","However, the benefit of economic growth didn’t translate to improved nutritional status for the population at large, a phenomenon which is known as the South Asian enigma ( Guha-Khasnobis et al. , 2010 ).","Modify,Grammar",Grammar
7502,4-8,4-8_v2_10@1,4-8_v1_10@1,"A systematic literature review was conducted in April of 2014 in the following electronic databases: PubMed, Embase, The Cochrane Library and Google Scholar; using the following search terms: ‘nutrition transition’, ‘dietary transition’, ‘epidemiological transition’, ‘obesity’, ‘diabetes’, cardiovascular diseases.","A systematic literature was conducted in April of 2014 in the following electronic databases: PubMed, Embase, The Cochrane Library and Google Scholar; using the following search terms: ‘nutrition transition’, ‘dietary transition’, ‘epidemiological transition’, ‘obesity’, ‘diabetes’, cardiovascular diseases.","Modify,Clarity",Clarity
7503,4-8,4-8_v2_10@6,4-8_v1_10@5,Owing to scarcity of relevant studies no special exclusion criteria was applied except for availability of full text articles.,No special exclusion criteria was applied.,"Modify,Fact/Evidence",Fact/Evidence
7504,4-8,4-8_v2_12@1,4-8_v1_12@1,"It houses around one fifth of global population with less than 4% of global land area and contributing to merely 2% of global income ( Jacques, 2008 ).","It houses around one fifth of mankind with less than 4% of global land area and contributing to merely 2% of global income ( Jacques, 2008 ).","Modify,Clarity",Clarity
7505,5-1005,5-1005_v2_17@0,5-1005_v1_17@0,"MZ-CRC-1 (gift from Alexander Knuth, University of Zurich) LC-2/ad (RIKEN) and HEK293 (ATCC) cells were cultured in advanced DMEM/F12 media (Invitrogen), supplemented with 5% fetal bovine serum (FBS, Invitrogen) and 2mM Glutamax (Invitrogen) and incubated at 37°C in 5% CO 2 /air.","MZ-CRC-1 and LC-2/ad cells were cultured in advanced DMEM/F12 media (Invitrogen), supplemented with 5% fetal bovine serum (FBS, Invitrogen) and 2mM Glutamax (Invitrogen) and incubated at 37°C in 5% CO 2 /air.","Modify,Fact/Evidence",Fact/Evidence
7506,5-1005,5-1005_v2_19@7,5-1005_v1_19@7,VEGF treatment does not affect levels of pRET (data not shown).,VEGFR treatment does not affect levels of pRET (data not shown).,"Modify,Grammar",Grammar
7507,5-1005,5-1005_v2_22@1,5-1005_v1_22@1,"For routine screening we compared anti-proliferative effects of the compounds in the disease model, MZ-CRC-1 (RET (M918T)) versus a control, non-RET expressing cell line, HEK293.","For routine screening we compared anti-proliferative effects of the compounds in the disease model, MZ-CRC-1 (RET (M918T)) versus a control, non-RET expressing cell line, Hek293.","Modify,Grammar",Grammar
7508,5-1005,5-1005_v2_22@3,5-1005_v1_22@3,"MZ-CRC-1 and HEK293 (control, no RET expression) cells were seeded into 384 plates at 4000 and 1000 cells per well respectively in 30µL culture medium and confluence monitored at 4 hourly intervals using the IncuCyte ZOOM live cell imaging platform (Essen).","MZ-CRC-1 and Hek293 (control, no RET expression) cells were seeded into 384 plates at 4000 and 1000 cells per well respectively in 30µL culture medium and confluence monitored at 4 hourly intervals using the IncuCyte ZOOM live cell imaging platform (Essen).","Modify,Grammar",Grammar
7509,5-1005,5-1005_v2_22@6,5-1005_v1_22@6,Non-specific toxicity margin was calculated by dividing IC 50 value obtained for the HEK293 control cells by that for the MZ-CRC-1 cells.,Non-specific toxicity margin was calculated by dividing IC 50 value obtained for the Hek293 control cells by that for the MZ-CRC-1 cells.,"Modify,Grammar",Grammar
7510,5-1005,5-1005_v2_34@0,5-1005_v1_34@0,"In order to demonstrate POP in a disease relevant cell line, we developed and validated a proliferation endpoint assay in the MTC line MZ-CRC-1; non-specific toxicity was evaluated by measuring the same endpoint in HEK293, a human embryonic kidney line which does not express RET.","In order to demonstrate POP in a disease relevant cell line, we developed and validated a proliferation endpoint assay in the MTC line MZ-CRC-1; non-specific toxicity was evaluated by measuring the same endpoint in Hek293, a human embryonic kidney line which does not express RET.","Modify,Grammar",Grammar
7511,5-1005,5-1005_v2_40@6,5-1005_v1_40@6,"Ganetespib did reduce levels of active RET, through protein degradation ( Supplementary Figure 3 ) but was not RET-selective and exhibited more toxicity (toxicity margin = 0.7x) in the control non-RET driven HEK293 cells compared to the MTC RET-driven model, MZ-CRC-1.","Ganetespib did reduce levels of active RET, through protein degradation ( Supplementary Figure 3 ) but was not RET-selective and exhibited more toxicity (toxicity margin = 0.7x) in the control non-RET driven Hek293 cells compared to the MTC RET-driven model, MZ-CRC-1.","Modify,Grammar",Grammar
7512,5-1005,5-1005_v2_7@5,5-1005_v1_7@5,"Importantly, the RET fusions are mutually exclusive with other known drivers in LAD (e.g. KRAS, epidermal growth factor receptor (EGFR), EML4-anaplastic lymphoma kinase (ALK)), further supporting a role for RET as a unique driver of malignancy in these tumors.","Importantly, the RET fusions are mutually exclusive with other known drivers in LAD (e.g. KRAS, endothelial growth factor (EGFR), EML4-anaplastic lymphoma kinase (ALK)), further supporting a role for RET as a unique driver of malignancy in these tumors.","Modify,Fact/Evidence",Fact/Evidence
7513,5-1005,5-1005_v2_8@7,5-1005_v1_8@7,"However significant toxicity ( e.g. rash, diarrhoea, hypertension) resulting from inhibition of other kinases, particularly KDR, has led to dose reductions in clinical trials (11–13) and is likely to compromise the use of both these agents in clinical settings <REF-16> .","However significant toxicity ( e.g. rash, diarrhoea, hypertension) resulting from inhibition of off-target kinases, particularly KDR, has led to dose reductions in clinical trials (11–13) and is likely to compromise the use of both these agents in clinical settings <REF-16> .","Modify,Clarity",Clarity
7514,5-1005,5-1005_v2_8@8,5-1005_v1_8@8,"Thus, there is a clear need for selective RET inhibitors which do not display the toxicities associated with the current treatments and enable more potent and sustained inhibition of RET signalling.","Thus, there is a clear need for selective RET inhibitors which do not display the non-pharmacological toxicities associated with the current treatments and enable more potent and sustained inhibition of RET signalling.","Modify,Claim",Claim
7515,5-1141,5-1141_v2_39@1,,Figure 6 shows that nodes with the same color corresponds to the sequences of a patient.,,"Add,Fact/Evidence",Fact/Evidence
7516,5-1141,5-1141_v2_39@2,,Nodes of a patient are grouped depending on the amount of mutations.,,"Add,Fact/Evidence",Fact/Evidence
7517,5-1141,5-1141_v2_39@3,,"In order to know which sequences have mutated, the analyst can place the mouse pointer over a node and the graph presents a popup message with the information of the corresponding node.",,"Add,Fact/Evidence",Fact/Evidence
7518,5-1141,5-1141_v2_39@4,,"For instance, Figure 6 also presents a popup message with the information of the node above it.",,"Add,Fact/Evidence",Fact/Evidence
7519,5-1141,5-1141_v2_39@5,,"It indicates three facts: 1) the node corresponds to the patient of the file “NS3_7.txt”, 2) the node corresponds to the sequence “FJ864759”, and 3) the sequence has at the position 170 one mutation because in this position the aminoacid should be “GTA(V)”, but it is “ATA(I)”.",,"Add,Fact/Evidence",Fact/Evidence
7520,5-1141,5-1141_v2_26@1,5-1141_v1_26@1,"Thus, possible positions are sorted in a list, which includes the number of the position, mutation, antiviral name, inhibitor class, a flag (“Yes” or “No”) that indicates whether or not the position is a main position for the selected gene, and references that can be in vitro or in vivo .","Thus, possible positions are sorted in a list, which includes the number of the position, mutation, antiviral, inhibitor, and references that can be in vitro or in vivo .","Modify,Fact/Evidence",Fact/Evidence
7521,5-1141,5-1141_v2_29@4,5-1141_v1_29@4,"BMA can recognize plain text files, which must include the symbol '>' and the sequence name in the first line of the file.","BMA can recognize plain text files, but they have to follow a specific format (see Figure 3 ).","Merge+Modify,Fact/Evidence",Fact/Evidence
7522,5-1141,5-1141_v2_29@4,5-1141_v1_29@5,"BMA can recognize plain text files, which must include the symbol '>' and the sequence name in the first line of the file.",Files must include the symbol '>' and the sequence name in the first line of the file.,"Merge+Modify,Clarity",Clarity
7523,5-1141,5-1141_v2_29@8,5-1141_v1_29@9,"In sequences, blank spaces, tabs, break lines and other symbols are not accepted (see Figure 3 ).","In sequences, blank spaces, tabs, break lines and other symbols are not accepted.","Modify,Fact/Evidence",Fact/Evidence
7524,5-1141,5-1141_v2_42@0,5-1141_v1_42@0,"For reliable calculations the sequences must contain a substantial part of the genes NS3, NS5A or NS5B (amino acids, aa 1–200).","For reliable calculations the sequences must contain a substantial part of the genes NS3, NS5A or NS5B.","Modify,Fact/Evidence",Fact/Evidence
7525,5-1141,5-1141_v2_46@1,5-1141_v1_46@1,"Moreover, BMA is freely available, which is different from others such as Bioedit, VectorNTI or MEGA, because it not only allows researchers to perform analysis for the identification of mutations, but also provides detailed information of mutations’ positions, amino acid changes as well as antiviral information and related literature of resistance mutations to the DAA.","Moreover, BMA is freely available, which is different from others such as Bioedit, VectorNTI or MEGA, because it not only allows researchers to perform analysis for the identification of mutations, but also provides detailed information of mutations’ positions, amino acid changes as well as antiviral information and related literature of resistance mutations to the AAD.","Modify,Grammar",Grammar
7526,5-1141,5-1141_v2_17@0,5-1141_v1_17@0,"The database was designed using the tool MySql Workbench version 6.3 ( https://www.mysql.com/products/workbench/ ), while the online system was developed using the tool Eclipse PHP version 3.7.0 ( https://eclipse.org/pdt/ ).","The database was design using the tool MySql Workbench version 6.3 ( https://www.mysql.com/products/workbench/ ), while the online system was developed using the tool Eclipse PHP version 3.7.0 ( https://eclipse.org/pdt/ ).","Modify,Grammar",Grammar
7586,5-1385,5-1385_v2_6@6,,"Several studies have compared the performance of these 2 commercial kits and found differences in gene expression profiles, RNA quality and yield <REF-25> – <REF-27> .",,"Add,Fact/Evidence",Fact/Evidence
7587,5-1385,5-1385_v2_6@7,,Reported yields and quality of RNA stabilized in Tempus solution was generally greater.,,"Add,Fact/Evidence",Fact/Evidence
7588,5-1385,5-1385_v2_6@8,,"Thus, the choice of RNA stabilizing reagent used to preserve samples can indeed be important and affect subsequent RNA quantity and quality.",,"Add,Claim",Claim
7589,5-1385,5-1385_v2_6@9,,Our choice of the tempus system over PaxGene dates from side-by-side comparisons we have performed over 10 years ago.,,"Add,Fact/Evidence",Fact/Evidence
7590,5-1385,5-1385_v2_6@16,,Since version 1 of our SOP came out in F1000Research <REF-30> we have published a paper describing results of a study in which weekly in home self-finger stick blood collection was undertaken by 13 subjects with type 1 diabetes and 14 controls for a period of 6 months <REF-31> .,,"Add,Fact/Evidence",Fact/Evidence
7591,5-1385,5-1385_v2_6@17,,"Subjects returned an average of 24 out of 26 total weekly samples, and transcript data were successfully obtained for >99% of samples returned.",,"Add,Fact/Evidence",Fact/Evidence
7592,5-1385,5-1385_v2_6@18,,A high degree of correlation between finger stick data and data from a standard 3 mL venipuncture sample was observed.,,"Add,Fact/Evidence",Fact/Evidence
7593,5-1385,5-1385_v2_6@19,,"RNA yields obtained from blood volumes ranging from 10, 15, 20, and 25 μL indicated that those volumes were sufficient to generate the 100 ng of RNA needed for high throughput real time-PCR <REF-31> .",,"Add,Fact/Evidence",Fact/Evidence
7594,5-1385,5-1385_v2_6@20,,"However, the detailed procedure for finger stick blood collection and RNA stabilization employed in this and other studies has never been published.",,"Add,Fact/Evidence",Fact/Evidence
7595,5-1385,5-1385_v2_7@0,,The standard operating procedure that we are sharing with this report will be published as part of our molecular profiling of pregnancy channel.,,"Add,Fact/Evidence",Fact/Evidence
7596,5-1385,5-1385_v2_10@4,,"A sufficient quantity of RNA for downstream processing was obtained when tubes were flicked, pipetted, or vortexed, but was reduced when samples were not mixed at all.",,"Add,Fact/Evidence",Fact/Evidence
7597,5-1385,5-1385_v2_17@4,,"The effect of storage temperature on RNA yield and quality will have to be evaluated further, especially over extended periods of time where storage at lower temperatures might show benefits (see also referees comments and our response for more details).",,"Add,Claim",Claim
7598,5-1385,5-1385_v2_18@0,,"7) Safety : The hazardous nature of the tempus solution would make extensive roll out of the collection procedure described in this manuscript problematic and is at the moment clearly intended for research use under well controlled conditions, with preferably collection carried out by trained personnel.",,"Add,Claim",Claim
7599,5-1385,5-1385_v2_18@1,,"However, it should be noted that it has been-field tested for in-home self-collection in a limited number of subject over a period of 6 months without incident <REF-31> .",,"Add,Fact/Evidence",Fact/Evidence
7600,5-1385,5-1385_v2_18@2,,"The fact that small volumes of solution are used may alleviate some concerns (30 microliters of solution for 15 microliters of blood in the above-mentioned study, vs 6 ml of solution for 3 ml of blood using “off the shelf” tempus collection tubes).",,"Add,Claim",Claim
7601,5-1385,5-1385_v2_18@3,,"However, other technical solutions in which liquids are better contained may indeed be preferable (e.g. microfluidics card, sponges), with one of the best example being the recently developed “DxCollect” system (DxTerity, Rancho Dominguez, CA).",,"Add,Claim",Claim
7602,5-1385,5-1385_v2_22@0,,Preparation of sample collection tubes,,"Add,Other",Other
7603,5-1385,5-1385_v2_27@3,,"- Tempus Tube RNA stabilization reagent is a potential health hazard; acute oral toxicity, skin corrosion/irritation and serious eye damage/eye irritation can occur upon contact (See MSDS for details).",,"Add,Fact/Evidence",Fact/Evidence
7604,5-1385,,5-1385_v1_7@0,,"With this report, we aim to share our standard operating procedure for stabilization of RNA from 50 μl of blood collected via a finger stick.","Delete,Fact/Evidence",Fact/Evidence
7605,5-1385,5-1385_v2_17@0,5-1385_v1_17@0,6) Storage and shipping : After collecting the blood sample should be kept cold at 4°C no longer than 48 hours and transferred to a -20°C or -80°C freezer for long-term storage.,6) Storage and shipping : By default samples are stored in the lab at -20°C.,"Split+Modify,Fact/Evidence",Fact/Evidence
7606,5-1385,5-1385_v2_17@1,5-1385_v1_17@0,"By default, samples are stored in the lab at -20°C.",6) Storage and shipping : By default samples are stored in the lab at -20°C.,"Split+Modify,Grammar",Grammar
7607,5-1385,5-1385_v2_17@2,5-1385_v1_17@1,"Data obtained using a limited set of samples frozen overnight showed that the RNA yield for samples stored at -80°C was about half the yield of same blood samples stored at -20°C, but was nevertheless still amply sufficient for downstream analyses.",We have observed that the RNA yield for samples stored at -80°C is generally about half the yield of same blood samples stored at -20°C.,"Modify,Fact/Evidence",Fact/Evidence
7608,5-1385,5-1385_v2_17@3,5-1385_v1_17@2,It should also be noted that the plastic tempus tubes are made of will become brittle at temperatures lower than -20°C.,"Furthermore, we observed that plastic tempus tubes are made of will become brittle at temperatures lower than -20°C.","Modify,Clarity",Clarity
7609,5-1385,5-1385_v2_17@7,5-1385_v1_17@5,When shipping on dry ice attention should be paid to the thickness of the walls of the polystyrene container holding the tubes along with the dry ice.,When shipping on dry ice the thickness of the walls of the polystyrene container holding the tubes along with the dry ice matters.,"Modify,Clarity",Clarity
7610,5-1385,5-1385_v2_27@0,5-1385_v1_22@0,"- Personal protective equipment (PPE) must be worn to prevent accidental exposure to blood and bloodborne pathogens, and to help reduce contamination during sample collection [ http://www.cdc.gov/niosh/topics/emres/ppe.html ].",- Personal protective equipment must be worn to prevent accidental exposure to blood and bloodborne pathogens [ http://www.cdc.gov/niosh/topics/emres/ppe.html ].,"Modify,Fact/Evidence",Fact/Evidence
7611,5-1385,5-1385_v2_32@0,5-1385_v1_27@0,"- 1. Assemble equipment and supplies, then complete the finger stick information log by recording relevant information about blood collection such as patient name, patient identity number (patient ID), date of blood collection, frequency number of blood collection (Day 1 st , Day 7 th ... Day 90 th ,…). Double check that the label on the collection tube matches with the patient ID.","- 1. Assemble equipment and supplies, then complete the Fingerstick Information Log by recording relevant information about blood collection such as patient name, patient identity number (patient ID), date of blood collection, frequency number of blood collection (Day 1 st , Day 7 th ... Day 90 th ,…). Double check that the label on the collection tube matches with the patient ID.","Modify,Grammar",Grammar
7612,5-1385,5-1385_v2_6@3,5-1385_v1_6@3,"However, the PBMC preparation procedure involves multiple steps and important variations are introduced between the time of blood draw and preparation of the cell lysates <REF-24> .",However the PBMC preparation procedure involves multiple steps and important variations are introduced between the time of blood draw and preparation of the cell lysates <REF-24> .,"Modify,Grammar",Grammar
7613,5-1385,5-1385_v2_6@5,5-1385_v1_6@5,Whole blood RNA stabilization systems; PAXgene™ (Qiagen) and Tempus™ (Life Technologies) have been adopted as they became available and are now widely used.,Whole blood RNA stabilization systems have been adopted as they became available and are now widely used.,"Modify,Fact/Evidence",Fact/Evidence
7614,5-1385,5-1385_v2_6@11,5-1385_v1_6@7,Collection of small volumes of blood via finger sticks is especially indicated for high frequency sample collection to enable monitoring of the immune status of individuals in health and disease <REF-2> .,Collection of small volumes of blood via finger sticks is especially indicated for high frequency sample collection to enable monitoring of the immune status of individuals in health and disease.,"Modify,Fact/Evidence",Fact/Evidence
7615,5-1385,5-1385_v2_6@13,5-1385_v1_6@9,"Therefore, it is more amenable to field applications and in home self-collection for proximity testing.",Therefore it is more amenable to field applications and in home self-collection for proximity testing.,"Modify,Grammar",Grammar
7616,5-1385,5-1385_v2_7@1,5-1385_v1_7@1,"Indeed, it was specifically developed for collection and stabilization of 50 μl of blood collected via a finger stick in a pregnancy monitoring study currently being conducted on the Thai-Myanmar border.",This SOP will be used specifically in a pregnancy monitoring study that will be conducted on the Thai-Myanmar border.,"Modify,Fact/Evidence",Fact/Evidence
7617,5-1385,5-1385_v2_7@2,5-1385_v1_7@2,It will consist of measuring changes in blood transcript abundance in 400 women during the second and third trimester of their pregnancy.,This study will consist of measuring changes in blood transcript abundance in 400 women during the second and third trimester of their pregnancy.,"Modify,Clarity",Clarity
7618,5-1385,5-1385_v2_10@3,5-1385_v1_10@3,"Immediately after collection, the tube is shaken vigorously to disrupt the blood cells for at least 20 seconds.","Immediately after collection, the tube is shaken vigorously to disrupt the blood cells.","Modify,Fact/Evidence",Fact/Evidence
7619,5-1385,5-1385_v2_13@1,5-1385_v1_13@1,Typical yield from 50 μl of blood is the minimum about 500 ng of total RNA.,Typical yield from 50 μl of blood is about 500 ng of total RNA.,"Modify,Fact/Evidence",Fact/Evidence
7620,5-1672,5-1672_v2_18@12,,This effect refers to the image of a butterfly that flaps its wings in South America and induces a hurricane in Texas.,,"Add,Fact/Evidence",Fact/Evidence
7621,5-1672,5-1672_v2_30@3,,This process assures that all possibly important aspects are evaluated.,,"Add,Claim",Claim
7622,5-1672,,5-1672_v1_18@7,,Attractors are sites to which the energy flow of the system may be drawn.,"Delete,Claim",Claim
7623,5-1672,5-1672_v2_21@2,5-1672_v1_21@2,"In each case a specific working-arrangement is in operation, but it is not necessarily the best solution for the system.","In each case a specific working-arrangement is operational, but it is not necessarily the best solution for the system.","Modify,Clarity",Clarity
7624,5-1672,5-1672_v2_21@4,5-1672_v1_21@4,"This indicates that energy flow may be material and immaterial, e.g. based on a desire to be loved, on a pursuit of values, or on living for a spiritual purpose.","This indicates that energy flow may also be regarded as immaterial, e.g. based on a desire to be loved, on pursuit of values, or on living for a spiritual purpose.","Modify,Claim",Claim
7625,5-1672,5-1672_v2_21@5,5-1672_v1_21@5,Investigation of the material and immaterial double nature of human energy flow may help toward a better understanding of a person´s health.,Investigation of the material and immaterial double nature of human energy flow may help to better understand the health of a person.,"Modify,Clarity",Clarity
7626,5-1672,5-1672_v2_22@0,5-1672_v1_22@0,An entire life is an evolutionary process.,The entire life is an evolutionary process.,"Modify,Grammar",Grammar
7627,5-1672,5-1672_v2_22@4,5-1672_v1_22@4,"At least, physicians and midwifes say that in a new-born it is clearly recognizable.","At the least, physicians and midwifes say that in the new-born it is clearly recognizable.","Modify,Grammar",Grammar
7628,5-1672,5-1672_v2_22@5,5-1672_v1_22@5,From then on the complete Meikirch model is fully operational throughout all the life course phases of each person.,From then on the complete Meikirch model is fully operational during all phases of the life course of each person.,"Modify,Clarity",Clarity
7629,5-1672,5-1672_v2_22@8,5-1672_v1_22@8,Within these limiting and supporting contexts individuals follow an autonomously chosen course of life.,Within these limiting and supporting contexts individuals follow an autonomously chosen life course.,"Modify,Clarity",Clarity
7630,5-1672,5-1672_v2_22@9,5-1672_v1_22@9,Under such conditions it is not surprizing that some adaptations may not be fully successful for some period of time or permanently.,Under such conditions it is not surprizing that some adaptations may not be fully successful for some time or permanently.,"Modify,Clarity",Clarity
7631,5-1672,5-1672_v2_22@11,5-1672_v1_22@11,Such changes may lead the health of an individual as a system into a state of crisis.,Such changes may lead an individual as a system into a state of crisis.,"Modify,Claim",Claim
7632,5-1672,5-1672_v2_22@12,5-1672_v1_22@12,"If it is minor, the two potentials may still manage the demands of life and the difficulties may resolve spontaneously after some time.","If it is minor, the two potentials still may manage the demands of life and the difficulties may resolve spontaneously after some time.","Modify,Clarity",Clarity
7633,5-1672,5-1672_v2_22@13,5-1672_v1_22@13,"Such situations may represent illnesses, but are not considered as disease or pathological.",Such situations are not considered to represent a disease.,"Modify,Claim",Claim
7634,5-1672,5-1672_v2_22@14,5-1672_v1_22@14,"They may, though, evolve into a chronic state that draws energy from the person and thereby may explain, for instance, insomnia, chronic fatigue, or somatoform symptoms.","Yet, they may evolve into a chronic state that draws energy from the person and thereby may explain e.g. insomnia, chronic fatigue, or somatoform symptoms.","Modify,Clarity",Clarity
7635,5-1672,5-1672_v2_22@15,5-1672_v1_22@15,If the defect becomes more severe it may lead to a disease that requires more medical attention.,If the defect gets more severe it may lead to a disease that requires more medical attention.,"Modify,Clarity",Clarity
7636,5-1672,5-1672_v2_22@16,5-1672_v1_22@16,In the Meikirch model the term “disease” implies that for some reason one or several adaptation processes are not successful enough to empower the two potentials to satisfy the demands of life.,In the Meikirch model the term disease implies that for any reason one or several adaptation processes are not successful enough to empower the two potentials to satisfy the demands of life.,"Modify,Clarity",Clarity
7637,5-1672,5-1672_v2_2@8,5-1672_v1_2@8,This may help patients to better understand their situations and to recognize possible next steps that may be useful in order to evolve toward better health by themselves.,This may help the patient to better understand his situation and to recognize possible next steps that may be useful for him to evolve toward more health by himself.,"Modify,Clarity",Clarity
7638,5-1672,5-1672_v2_24@0,5-1672_v1_24@0,"To allow for future research, hypothetical consequences of the Meikirch model and of the properties of CASs have been explored with the purpose of better understanding the state of health of patients, particularly in primary care.","Consequences of the Meikirch model and of the properties of CASs are explored with the purpose to better understand the state of health of patients, particularly in internal medicine and general practice.","Modify,Clarity",Clarity
7639,5-1672,5-1672_v2_24@1,5-1672_v1_24@1,"According to the Meikirch model, health of a healthy individual or of a patient is considered to be a nested CAS, composed of grouped CASs and being embedded in higher CASs.","The individual as a patient, according to the Meikirch model, is considered to be a nested CAS, composed of grouped CASs and being embedded in higher CASs.","Modify,Clarity",Clarity
7640,5-1672,5-1672_v2_24@2,5-1672_v1_24@2,"For the analysis of various conditions, the significance of each of the five components and of each interaction within the Meikirch model were visualized.","For this purpose, the significance of each of the five components and of each interaction within the Meikirch model must be visualized.","Modify,Clarity",Clarity
7641,5-1672,5-1672_v2_24@3,5-1672_v1_24@3,"In addition, possibilities of supporting favourable evolutions of the respective CAS and its meaning for the whole person (nested CAS) were analysed.","In addition, possibilities to support favourable evolutions of the respective CAS and its meaning for the whole person (nested CAS) were studied.","Modify,Clarity",Clarity
7642,5-1672,5-1672_v2_24@4,5-1672_v1_24@4,"In this process, the deduction (from observation to theory) and induction (from theory to observation) cycles were repeated until coherent results were achieved.","In this process, the deduction and induction cycles were repeated until coherent results were received.","Modify,Clarity",Clarity
7643,5-1672,5-1672_v2_28@1,5-1672_v1_28@1,"- 2. A more severe disturbance of the system leads it into a crisis, i.e. it becomes “chaotic”. Such states may be corrected spontaneously, for example, or by behavioural changes, or by interacting with a physician or healer, by medications, or by medical or surgical interventions. Thereafter there may not be an immediate complete recovery to health. The full adaptive evolution may take time and further interventions, i.e., convalescence or rehabilitation, may be needed. These phenomena may lead to complete healing or to healing with remaining defects.","- 2. A more relevant disturbance of the system leads it into a crisis, i.e. it becomes “chaotic”. Such states may e.g. be corrected spontaneously, or by behavioural changes, or by interacting with a physician or healer, by medications, or by operations. Thereafter there may not be an immediate complete recovery to health. The full adaptive evolution may take time and further interventions that are called convalescence or rehabilitation may be needed. These phenomena may lead to complete healing or to healing with defects.","Modify,Clarity",Clarity
7644,5-1672,5-1672_v2_28@2,5-1672_v1_28@2,"- 3. If a CAS is disturbed continuously for a prolonged time, the CAS may not be able to satisfactorily respond to the demands of life. This represents a chronic disease or invalidity. If the condition is progressive and serious, it may lead to death. Examples are rheumatic or degenerative diseases and different types of neoplasms.","- 3. If a CAS is disturbed continuously for a prolonged time, the CAS apparently is not able to satisfactorily respond to the demands of life. This represents a chronic disease or invalidity. If the condition is progressive and serious, it may lead to death. Examples are rheumatic or degenerative diseases and different types of neoplasms.","Modify,Clarity",Clarity
7645,5-1672,5-1672_v2_28@3,5-1672_v1_28@3,"- 4. Considering a disturbed state of health as a maladapted CAS implies that patients cannot simply be healed by the actions of a competent physician. Healing is much rather the result of a process of self-reorganization, enabling the two potentials to again satisfactorily fulfil the demands of life. The task of physicians and other health professionals therefore consists in being competent advisors and fellow human beings that assist the patient in realizing the necessary evolution himself.","- 4. Considering a disturbed state of health as a maladapted CAS implies that patients cannot simply be healed by the actions of a competent physician. Healing much rather is the result of a process of self-reorganization, enabling the two potentials to again satisfactorily fulfil the demands of life. The task of physicians and other health professionals therefore consists in being competent advisors and fellow human beings that assist the patient to realize the necessary evolution himself.","Modify,Clarity",Clarity
7646,5-1672,5-1672_v2_2@10,5-1672_v1_2@10,The described approach offers new possibilities for helping patients improve their health prospects.,The described approach offers new possibilities to help patients to improve their health.,"Modify,Clarity",Clarity
7647,5-1672,5-1672_v2_29@0,5-1672_v1_29@0,Assessment of a patient´s health,Assessment of the health of a patient,"Modify,Clarity",Clarity
7648,5-1672,5-1672_v2_30@0,5-1672_v1_30@0,It always is appropriate to examine patients with an ordinary medical history and physical examination to which all indicated laboratory tests and imaging procedures are added.,Initially it is appropriate to examine a patient with an ordinary medical history and physical examination to which all indicated laboratory tests and imaging procedures are added.,"Modify,Claim",Claim
7649,5-1672,5-1672_v2_30@1,5-1672_v1_30@1,Simultaneously it may be purposeful to perform an analysis of the patients´ health as a CAS.,"When this does not lead to a satisfactory and clear result, it may be purposeful to perform an analysis of the patient’s health as a CAS.","Modify,Claim",Claim
7650,5-1672,5-1672_v2_30@4,5-1672_v1_30@3,A thorough analysis will give patients a new way to look at their health and how they had conducted their lives.,A thorough analysis will give the patient a new way to look at his health and how he has led his life.,"Modify,Clarity",Clarity
7651,5-1672,5-1672_v2_30@5,5-1672_v1_30@4,"They will discover aspects they did not think about before, and this may be of therapeutic value.","He will discover aspects he did not think about before, and this may be of therapeutic value.","Modify,Clarity",Clarity
7652,5-1672,5-1672_v2_30@6,5-1672_v1_30@5,At the same time the physician may start to interpret the patients´ history and findings in a new way.,At the same time the physician may start to interpret the patient’s history and findings in a new way.,"Modify,Grammar",Grammar
7653,5-1672,5-1672_v2_30@7,5-1672_v1_30@6,This may discover further possibilities for helping a patient to autonomously evolve to a new state which hopefully comes closer to health.,He may discover further possibilities for helping the patient to autonomously evolve to a new state which hopefully comes closer to health.,"Modify,Clarity",Clarity
7654,5-1672,5-1672_v2_34@0,5-1672_v1_34@0,"Obviously, for all medically diagnosed conditions treatments are to be prescribed as indicated. Yet, in medicine, indications generally leave considerable room for judgements.","Obviously for all medically diagnosed conditions treatments are to be prescribed as indicated. Yet, in medicine, indications generally leave much room for judgements.","Modify,Clarity",Clarity
7655,5-1672,5-1672_v2_34@1,5-1672_v1_34@1,Thus the findings collected by assessing all the components and interactions of the Meikirch model must be considered and integrated as far as possible.,Therefore the findings collected by assessing all components and interactions of the Meikirch model must be considered and integrated as much as possible.,"Modify,Clarity",Clarity
7656,5-1672,5-1672_v2_4@0,5-1672_v1_4@0,"Individuals consult their physicians when they feel something is out of order, e.g. when they experience pain, fatigue or some other disorder.","Citizens consult their physicians when they feel that something is not in order, e.g. when they experience pain, fatigue or any other disorder.","Modify,Clarity",Clarity
7657,5-1672,5-1672_v2_34@3,5-1672_v1_34@3,"It must be assisted as it reorganizes itself autonomously to a new state, in order to better fulfil the demands of life and hence better health and well-being.","It must be assisted to reorganize itself autonomously to a new state, in order to better fulfil the demands of life, hence better health and well-being.","Modify,Clarity",Clarity
7658,5-1672,5-1672_v2_34@4,5-1672_v1_34@4,"The role of the physician, therefore, is to accompany the patient during the process he goes through.",Therefore the role of the physician is to accompany the patient during the process he goes through.,"Modify,Clarity",Clarity
7659,5-1672,5-1672_v2_34@5,5-1672_v1_34@5,"Some advice, assistance, or therapeutic intervention may be helpful, but only the patients are in a position to create their new future state for themselves.","Some advice, assistance, or therapeutic intervention may be helpful, but only the patient is in a position to create his new future state for himself.","Modify,Grammar",Grammar
7660,5-1672,5-1672_v2_34@8,5-1672_v1_34@7,"In this respect, a discussion with their physician of alternatives with their consequences may be useful.","In this respect, a discussion with his physician of alternatives with their consequences may be useful.","Modify,Grammar",Grammar
7661,5-1672,5-1672_v2_35@0,5-1672_v1_35@0,The process of reorientation based on the Meikirch model takes time.,The process of reorientation based on the Meikirch model will take time.,"Modify,Grammar",Grammar
7662,5-1672,5-1672_v2_35@1,5-1672_v1_35@1,During this period it may help the patient if they find in their pysician a trustworthy human beeing with whom they can discuss all sorts of alternatives.,"During this period it may help the patient, if he finds in his physician a trustful human being with whom he can discuss all sorts of alternatives.","Modify,Clarity",Clarity
7663,5-1672,5-1672_v2_35@3,5-1672_v1_35@3,"It will encourage them if they feel understood, trusted and accompanied by an experienced person with a sincere interest in their wellbeing.","It will encourage them, if they feel understood, trusted and accompanied by an experienced person with a sincere interest in their wellbeing.","Modify,Grammar",Grammar
7664,5-1672,5-1672_v2_37@1,5-1672_v1_37@1,Thus far such complaints have been explained as functional and often were regarded by physicians as unimportant.,So far such complaints are explained as functional and often are degraded by physicians as unimportant.,"Modify,Clarity",Clarity
7665,5-1672,5-1672_v2_37@2,5-1672_v1_37@2,"Patients then received drugs that may be symptomatically beneficial or placebos or, more often than not, harmful or nocebos.","Patients then receive drugs that may be symptomatically beneficial or placebos, more often than not harmful or noceboes.","Modify,Grammar",Grammar
7666,5-1672,5-1672_v2_37@4,5-1672_v1_37@4,"In many cases it will help the patients to understand their problems, to readjust their potentials and to advance their readaptation to the demands of life.","In many cases it will help the patient to understand his problems, to readjust his potentials and to advance his readaptation to the demands of life.","Modify,Grammar",Grammar
7667,5-1672,5-1672_v2_4@2,5-1672_v1_4@2,After such an investigation they make a provisional diagnosis and explore their patients further or treat them according to what has been discovered.,After investigation they make a provisional diagnosis and explore their patients further or treat them accordingly.,"Modify,Clarity",Clarity
7668,5-1672,5-1672_v2_39@0,5-1672_v1_39@0,At the present time the Meikirch model is a hypothesis grounded on a theoretical and conceptual framework.,At the present time the Meikirch model is a hypothesis grounded on a theoretical framework.,"Modify,Clarity",Clarity
7669,5-1672,5-1672_v2_39@1,5-1672_v1_39@1,"Yet, up till now much of health care has not been concerned with an understanding of the nature of health; it used instead an intuitive notion of wellbeing which did not lead to new insights.","Yet, until now much of health care has not been concerned with an understanding of the nature of health; it used instead an intuitive notion of wellbeing which did not lead to new insights.","Modify,Clarity",Clarity
7670,5-1672,5-1672_v2_39@4,5-1672_v1_39@4,"Its ultimate validity, however, will be documented only by using and evaluating it in practice.","Its ultimate validity, however, will be documented only by using it in practice.","Modify,Claim",Claim
7671,5-1672,5-1672_v2_40@1,5-1672_v1_40@1,"They are based, however, predominantly on materialism and neglect the social and spiritual features of human nature.","They are based, however, predominantly on materialism and neglect the social and spiritual features of the human nature.","Modify,Grammar",Grammar
7672,5-1672,5-1672_v2_4@3,5-1672_v1_4@3,"This approach and type of thinking goes back to the pathologist Rudolf Virchow who, in 1858, used 20 lectures to describe “cellular pathology”, a characterization of different diseases <REF-1> .","This type of thinking goes back to the pathologist Rudolf Virchow, who in 1858 used 20 lectures to describe “cellular pathology”, a characterization of different diseases <REF-1> .","Modify,Clarity",Clarity
7673,5-1672,5-1672_v2_40@5,5-1672_v1_40@5,"Particularly for the purpose of health care a phenomenological, narrative, and evolutionary holism must be added to analytical reductionism <REF-11> .","Particularly for the purpose of health care a phenomenological, narrative, evolutionary holism must be added to analytical reductionism <REF-11> .","Modify,Clarity",Clarity
7674,5-1672,5-1672_v2_40@7,5-1672_v1_40@7,"Instead considerations of the evolution of the patient’s health to its present state, earlier successes in self-management and failures in the handling of his present crises can be evaluated.","Instead considerations of the evolution of the patient’s health to the present state, earlier successes in self-management and failures in the handling of his present crises can be evaluated.","Modify,Clarity",Clarity
7675,5-1672,5-1672_v2_40@8,5-1672_v1_40@8,"Here, Antonovsky’s sense of coherence and meaningfulness also may be very helpful <REF-12> .",Antonovsky’s sense of coherence and meaningfulness also may be very helpful <REF-12> .,"Modify,Clarity",Clarity
7676,5-1672,5-1672_v2_40@9,5-1672_v1_40@9,"The necessary changes a patient has to realize must not come top-down from the physician, but rather bottom-up, originating in the patients themselves, e.g., via new insights.","Necessary changes a patient has to realize must not come top-down from the physician, but rather bottom-up, originating in the patient himself, e.g. by new insights.","Modify,Grammar",Grammar
7677,5-1672,5-1672_v2_41@4,5-1672_v1_41@4,The Meikirch model offers now a rational approach to such difficult cases and it is hoped that the five components and the ten complex interactions will lead to new opportunities for patients to move toward better health.,The Meikirch model offers now a rational approach to such difficult cases and it is hoped that it will give new opportunities for patients to move toward better health.,"Modify,Claim",Claim
7678,5-1672,5-1672_v2_4@4,5-1672_v1_4@4,"Although the foundations of medicine have evolved since then, the general principles of medical practice have remained the same.","Although the foundations of medicine have vastly changed since then, the general principles of medical practice have remained the same.","Modify,Clarity",Clarity
7679,5-1672,5-1672_v2_41@6,5-1672_v1_41@6,He was a psychiatrist and pursued the purpose of “Training General Practitioners in Psychotherapy” to better understand and respond to the needs of their difficult patients.,He was psychiatrist and pursued the purpose to train general practitioners in psychotherapy.,"Modify,Fact/Evidence",Fact/Evidence
7680,5-1672,5-1672_v2_41@7,5-1672_v1_41@7,"In contrast, the systems theory approach focusses on a new look at a patient’s possible unresolved evolutionary steps, analyses the biological given and personally acquired potentials and offers him an opportunity to progress further in his personal biography.","In contrast, the systems theory focusses on a new look at a patient’s possible unresolved evolutionary steps, analyses the biological given and personally acquired potentials and offers him an opportunity to progress further in his personal biography.","Modify,Clarity",Clarity
7681,5-1672,5-1672_v2_41@8,5-1672_v1_41@8,More research is needed to validate the promises and limitations of this methodology.,More research is needed to validate the promises and limitations of this approach.,"Modify,Clarity",Clarity
7682,5-1672,5-1672_v2_0@0,5-1672_v1_0@0,Applying a complex adaptive system's understanding of health to primary care,Health as a Complex Adaptive System: a new dimension of patient care in internal medicine and general practice,"Modify,Other",Other
7683,5-1672,5-1672_v2_4@5,5-1672_v1_4@5,"Only over the past 20 years has complexity science gradually entered into medicine <REF-2> , <REF-3> .","Only over the past 20 years, complexity science has gradually entered into medicine <REF-2> , <REF-3> .","Modify,Clarity",Clarity
7685,5-1672,5-1672_v2_42@10,5-1672_v1_42@11,It appears that the neglect of the PAP in modern medicine is well perceived by patients and they have turned to complementary or alternative medicine.,Therefore they turn to complementary or alternative medicine.,"Merge+Modify,Clarity",Clarity
7686,5-1672,5-1672_v2_42@11,5-1672_v1_42@12,"In fact, much of the success of homeopathy and other methods might be explained by the physician/patient interaction with its effects on the complex adaptive system that expresses the patient’s health.","In fact, much of the success of homeopathy and other methods might be explained by the physician patient interaction with its effects on the complex adaptive system that expresses the patient’s health.","Modify,Grammar",Grammar
7687,5-1672,5-1672_v2_43@7,5-1672_v1_43@7,The Meikirch model provides a framework for how this could be achieved.,The Meikirch model gives a framework for how this could be achieved.,"Modify,Clarity",Clarity
7688,5-1672,5-1672_v2_4@8,5-1672_v1_4@8,For such systems the concepts based on Virchow’s pathology ideas are no longer adaquate.,For such systems the concepts based on Virchow’s pathology are no longer appropriate.,"Modify,Clarity",Clarity
7690,5-1672,5-1672_v2_4@9,5-1672_v1_4@10,An understanding of health and disease now requires appreciation of complexity science which introduces a new dimension for diagnosing and treating patients.,It introduces a new dimension for diagnosing and treating patients.,"Merge+Modify,Clarity",Clarity
7691,5-1672,5-1672_v2_4@10,5-1672_v1_4@11,It includes the potential of improving health in a way that was hitherto practiced only exceptionally.,It includes the potential to improve health in a way that hitherto was practiced only exceptionally.,"Modify,Clarity",Clarity
7692,5-1672,5-1672_v2_4@11,5-1672_v1_4@12,The purpose of this paper is to summarize the relevant features of the Meikirch model and to spell out in detail how the model and complexity science may be applied for a better understanding of a patient’s disease and its treatment.,The purpose of this paper is to summarize the relevant features of the Meikirch model and to reveal in detail how the model and complexity science may be applied for a better understanding of a patient’s disease and for its treatment.,"Modify,Clarity",Clarity
7693,5-1672,5-1672_v2_6@1,5-1672_v1_6@1,This framework allows us to define health and disease as a complex adaptive system ( Box 2 ).,This framework allows to define health and disease as a complex adaptive system ( Box 2 ).,"Modify,Clarity",Clarity
7694,5-1672,5-1672_v2_6@5,5-1672_v1_6@5,"The complete description of the model with its scientific background is given in the previous publications <REF-4> , <REF-5> .","The complete description of the model with its scientific background is given in the original publications <REF-4> , <REF-5> .","Modify,Clarity",Clarity
7695,5-1672,5-1672_v2_13@0,5-1672_v1_13@0,Each human being must fullfil the demands of his or her life situation <REF-6> .,Each human must fulfil his demands of life <REF-6> .,"Modify,Clarity",Clarity
7696,5-1672,5-1672_v2_13@2,5-1672_v1_13@2,"Physiological demands are related to the homeokinetic balance of nutrients, energy and water necessary for maintaining bodily functions including procreation (examples are work, pregnancy, childbirth and brain function).","Physiological demands are related to the homeokinetic balance of nutrients, energy and water to maintain bodily functions including procreation; examples are work, pregnancy, childbirth and brain function.","Modify,Clarity",Clarity
7697,5-1672,5-1672_v2_13@3,5-1672_v1_13@3,"Psychosocial demands are the individual´s exposure and response to social conditions needed to succeed in social integration and mental, personal and spiritual development.","Psychosocial demands are the individual´s exposure and response to social conditions to succeed in social integration and mental, personal and spiritual development.","Modify,Clarity",Clarity
7698,5-1672,5-1672_v2_13@5,5-1672_v1_13@5,This also includes peace with the fact that every human being must die.,"This includes also peace with the fact, that every human being must die.","Modify,Clarity",Clarity
7699,5-1672,5-1672_v2_13@6,5-1672_v1_13@6,"Environmental demands include the availability of and immediate or latent threats from living conditions (e.g., water, nutrients, climate, radioactivity, pollutants, carcinogens, workplace conditions).","Environmental demands include availability and immediate or latent threats from living conditions (e.g. water, nutrients, climate, radioactivity, pollutants, carcinogens, workplace conditions).","Modify,Grammar",Grammar
7700,5-1672,5-1672_v2_14@0,5-1672_v1_14@0,"The potential of an individual to meet the demands of life is partly biological e.g. a gift of nature - biologically given potential (BGP) , and partly acquired during life - personally acquired potential (PAP).",The potential of an individual to meet his demands of life is partly biological e.g. a gift by nature - biologically given potential (BGP) - and partly acquired during life – personally acquired potential (PAP).,"Modify,Grammar",Grammar
7701,5-1672,5-1672_v2_14@1,5-1672_v1_14@1,"At birth the BGP is based on the genetic equipment, epigenetic regulation and quality of the pregnancy.","At the time of birth the BGP is based on the genetic equipment, epigenetic regulation and quality of the pregnancy.","Modify,Clarity",Clarity
7702,5-1672,5-1672_v2_14@3,5-1672_v1_14@3,"During the lifetime the BGP may be threatened or damaged by socioeconomic disadvantages, diseases, injuries and/or defects.","During lifetime the BGP may be threatened or damaged by socioeconomic disadvantages, diseases, injuries and defects.","Modify,Grammar",Grammar
7703,5-1672,5-1672_v2_14@4,5-1672_v1_14@4,"The PAP results from the entirety of physiological, mental, spiritual and social resources acquired during the lifetime.","The PAP results from the entirety of physiological, mental, spiritual and social resources acquired during lifetime.","Modify,Grammar",Grammar
7704,5-1672,5-1672_v2_15@1,5-1672_v1_15@1,"Equity and equality, social concerns, working conditions, autonomy and social participation affect health and longevity <REF-7> , <REF-8> and are also major determinants.","Equity and equality, social concerns, working conditions, autonomy and social participation affect health and longevity <REF-7> , <REF-8> and are major determinants of health.","Modify,Clarity",Clarity
7705,5-1672,5-1672_v2_15@2,5-1672_v1_15@2,"Likewise, environmental determinants of health are factors in living and working conditions that affect each person.","Likewise, environmental determinants of health are factors in living and working conditions affecting each person.","Modify,Clarity",Clarity
7706,5-1672,5-1672_v2_15@3,5-1672_v1_15@3,"They may sometimes be of global significance like natural resources, catastrophes, population growth and climate change <REF-9> , <REF-10> .","They may sometimes be of global significance like natural resources, population growth and climate change <REF-9> , <REF-10> .","Modify,Fact/Evidence",Fact/Evidence
7707,5-1672,5-1672_v2_16@1,5-1672_v1_16@1,Possible individual and public health care outcomes as a result of a hypothetical implementation of the Meikirch model have been discussed elsewhere and suggestions for clinical and health systems research have been made <REF-5> .,Possible outcomes on individual and public health care as a result of a hypothetical implementation of the Meikirch model have been discussed elsewhere and suggestions for clinical and health systems research have been made <REF-5> .,"Modify,Clarity",Clarity
7708,5-1672,5-1672_v2_2@5,5-1672_v1_2@5,Between these five components of health there are 10 complex interactions that justify viewing health as a CAS.,Between these five components of health there are 10 complex interactions that justify health to be viewed as a CAS.,"Modify,Clarity",Clarity
7709,5-1672,5-1672_v2_18@10,5-1672_v1_18@11,"If it does not function at all the CAS becomes chaotic, goes into a crisis or vanishes.",If it does not function at all the CAS becomes chaotic and goes into a crisis or vanishes.,"Modify,Grammar",Grammar
7710,5-1672,5-1672_v2_18@11,5-1672_v1_18@12,Repeated minor critical disturbances may lead to the so-called butterfly effect <REF-2> .,Repeated critical disturbances may lead to the so called butterfly effect <REF-2> .,"Modify,Clarity",Clarity
7711,5-1672,5-1672_v2_18@13,5-1672_v1_18@13,"Examples of medical conditions where a similar mechanism may lead from minor incidents to major consequences are ventricular fibrillation, epileptic seizures, tantrum, and psychotic states.","Examples of medical conditions are ventricular fibrillation, epileptic seizures, tantrum, or psychotic states.","Modify,Claim",Claim
7712,5-1672,5-1672_v2_2@6,5-1672_v1_2@6,"In each patient, the current state of health as a CAS evolved from the past, will move forward to a new future, and has to be analyzed and treated as an autonomous whole.","In each patient, the current state of his health as a CAS evolved from the past, will move forward to a new future, and has to be analyzed and treated as an autonomous whole.","Modify,Clarity",Clarity
7733,5-1964,,5-1964_v1_28@0,,This model can explain some surprising observations and predicts conditions under which resistance might spread to Africa.,"Delete,Claim",Claim
7734,5-1964,,5-1964_v1_29@5,,"While our data suggest that differences in the selective constraints on P. falciparum strains from SEA and Africa may contribute towards the higher propensity for resistance emergence and spread in SEA, other factors such as differences in the drug pressure, usage of artemisinin mono-therapy, social factors and host immune factors may also be important <REF-3> , <REF-4> .","Delete,Claim",Claim
7735,5-1964,5-1964_v2_23@4,,We also confirmed that N/S is SEA samples was higher than samples from Africa even when separately analysing predicted single strain and mixed strain samples ( Supplementary Figure 1 ).,,"Add,Fact/Evidence",Fact/Evidence
7736,5-1964,5-1964_v2_27@7,,"Since Africa has higher rate asymptomatic infections as well as untreated patients, this would also result in higher competition between drug resistant and drug sensitive clones in the absence of drug, further decreasing the spread of drug resistance mutations with a fitness cost.",,"Add,Claim",Claim
7737,5-1964,5-1964_v2_28@0,,This model is consistent with a number of previous studies.,,"Add,Claim",Claim
7738,5-1964,5-1964_v2_28@1,,Our observation of higher likelihood of fixation of potentially deleterious mutations in P. falciparum strains from SEA compared to African strains is consistent with the previous observation of higher rate of potentially deleterious copy number variations in P. falciparum from SEA compared to Africa <REF-21> .,,"Add,Fact/Evidence",Fact/Evidence
7739,5-1964,5-1964_v2_28@2,,These observations suggest relaxed negative selection on P. falciparum from SEA compared to Africa and that SEA strains would have lower fitness than African strains.,,"Add,Claim",Claim
7740,5-1964,5-1964_v2_28@3,,It would be fascinating to test this hypothesis experimentally e.g. by measuring the competitive asexual growth rate (an important component of fitness) of SEA and African P. falciparum strains.,,"Add,Claim",Claim
7741,5-1964,5-1964_v2_29@0,,"Mixed strain infection by P. falciparum has recently been demonstrated to lead to within-host competition in patients <REF-22> , the possible mechanisms of which might include strain-transcending immunity, resource competition (e.g. RBCs) or direct interference between strains <REF-23> – <REF-26> .",,"Add,Fact/Evidence",Fact/Evidence
7742,5-1964,5-1964_v2_29@1,,"While within-host competition seems to be the major explanation for lower N/S in African strains, mixed strain infection would also lead to higher rate of recombination between gametes of different genotypes and efficient removal of deleterious mutations in Africa.",,"Add,Claim",Claim
7743,5-1964,5-1964_v2_29@2,,"In any case, a higher rate of mixed strain infection is expected to increase the strength of purifying selection.",,"Add,Claim",Claim
7744,5-1964,5-1964_v2_30@0,,What are the implications of our model for the current wave of artemisinin resistance?,,"Add,Other",Other
7745,5-1964,5-1964_v2_30@6,,This effect might be pronounced by the greater proportion of asymptomatic and untreated patients in Africa.,,"Add,Claim",Claim
7746,5-1964,5-1964_v2_31@2,,"Mutation rate as measured by long-term in vitro culture was not higher in strains from SEA origin, either in the presence or absence of drug <REF-36> , <REF-37> .",,"Add,Fact/Evidence",Fact/Evidence
7747,5-1964,5-1964_v2_31@6,,"The authors of the MalariaGEN also wrote that at the gene level “we found virtually identical distributions of the ratio of non-synonymous to synonymous mutations (N/S ratio) in the two regions” <REF-18> , however, no statistical test was performed by the authors.",,"Add,Fact/Evidence",Fact/Evidence
7748,5-1964,5-1964_v2_31@7,,"Furthermore, no comparison of N/S at the sample level was performed in the MalariaGEN study.",,"Add,Fact/Evidence",Fact/Evidence
7749,5-1964,5-1964_v2_31@8,,Resistance to chloroquine and sulfadoxine-pyrimethamine appeared independently in SEA and South America <REF-38> .,,"Add,Fact/Evidence",Fact/Evidence
7750,5-1964,5-1964_v2_31@9,,"While there were few samples from South-America in the MalariaGEN dataset ( Figure 6 ), we find that these samples also display lower mixed infection rate ( Figure 6 ), and N/S ratio in between the African and SEA samples ( Figure 1 ).",,"Add,Fact/Evidence",Fact/Evidence
7751,5-1964,5-1964_v2_31@10,,Further analyses of a larger number of samples from South America could shed light on whether the mechanism we propose for a higher rate of resistance emergence in SEA might be applicable to South-America.,,"Add,Claim",Claim
7752,5-1964,5-1964_v2_32@0,,"In summary, we propose that the lower transmission rates in SEA lead to a lower rate of mixed strain infection, which leads to reduced strength of natural selection.",,"Add,Claim",Claim
7753,5-1964,5-1964_v2_32@1,,"This, in turn, allows a higher rate of fixation of potentially deleterious mutations including drug resistance mutation.",,"Add,Claim",Claim
7754,5-1964,5-1964_v2_32@2,,"However, other factors such as drug usage, the level of immunity, and social factors <REF-3> , <REF-5> , <REF-39> , could also contribute towards the faster development of resistance in SEA.",,"Add,Claim",Claim
7755,5-1964,5-1964_v2_32@3,,"Given the basic difference in the transmission rate between SEA and Africa, which is not easy to control, we should expect that SEA would remain a source of drug resistance malaria in the future.",,"Add,Claim",Claim
7756,5-1964,5-1964_v2_34@8,,There were 136 genes with zero synonymous SNPs in SEA and thus were excluded from the analyses.,,"Add,Fact/Evidence",Fact/Evidence
7757,5-1964,5-1964_v2_23@1,5-1964_v1_23@1,The rate of mixed strain infection is generally lower in areas of low-transmission such as SEA <REF-20> .,The rate of mixed infection is generally lower in areas of low-transmission such as SEA <REF-20> .,"Modify,Clarity",Clarity
7758,5-1964,5-1964_v2_23@3,5-1964_v1_23@3,"Indeed, the estimated rate of mixed strain infections, detected by a high proportion of heterozygous calls in the sequencing data, was much lower in South-East Asia compared to Africa ( Figure 6 ).","Indeed, the estimated rate of mixed infections, detected by a high proportion of heterozygous calls in the sequencing data, was much lower in South-East Asia compared to Africa ( Figure 6 ).","Modify,Clarity",Clarity
7759,5-1964,5-1964_v2_27@0,5-1964_v1_27@0,Here we find a higher N/S ratio in strains from SEA compared to Africa.,"Based on our observations that P. falciparum from SEA shows 1) a higher ratio of non-synonymous to synonymous polymorphism 2) a higher proportion of non-synonymous polymorphism at conserved sites and 3) a lower rate of mixed infections, we propose a model for the higher propensity of SEA populations to acquire drug resistance ( Supplementary Figure 1 ).","Split+Modify,Clarity",Clarity
7760,5-1964,5-1964_v2_27@1,5-1964_v1_27@0,We also find that non-synonymous mutations have a higher likelihood to occur at conserved sites in SEA strains compared to African strains.,"Based on our observations that P. falciparum from SEA shows 1) a higher ratio of non-synonymous to synonymous polymorphism 2) a higher proportion of non-synonymous polymorphism at conserved sites and 3) a lower rate of mixed infections, we propose a model for the higher propensity of SEA populations to acquire drug resistance ( Supplementary Figure 1 ).","Split+Modify,Clarity",Clarity
7761,5-1964,5-1964_v2_27@2,5-1964_v1_27@0,"In addition, we confirm a lower rate of mixed strain infection in SEA compared to Africa in the MalariaGEN dataset, the largest whole-genome dataset on P. falciparum till date.","Based on our observations that P. falciparum from SEA shows 1) a higher ratio of non-synonymous to synonymous polymorphism 2) a higher proportion of non-synonymous polymorphism at conserved sites and 3) a lower rate of mixed infections, we propose a model for the higher propensity of SEA populations to acquire drug resistance ( Supplementary Figure 1 ).","Split+Modify,Fact/Evidence",Fact/Evidence
7762,5-1964,5-1964_v2_27@3,5-1964_v1_27@0,"Based on these three observations, we propose a model for the higher propensity of SEA populations to acquire drug resistance ( Supplementary Figure 2 ).","Based on our observations that P. falciparum from SEA shows 1) a higher ratio of non-synonymous to synonymous polymorphism 2) a higher proportion of non-synonymous polymorphism at conserved sites and 3) a lower rate of mixed infections, we propose a model for the higher propensity of SEA populations to acquire drug resistance ( Supplementary Figure 1 ).","Split+Modify,Clarity",Clarity
7763,5-1964,5-1964_v2_27@4,5-1964_v1_27@1,Lower mixed strain infections in SEA may allow even less-fit parasites to be transmitted to the next set of hosts due to reduced level of intra-host competition.,Lower mixed infections in SEA may allow even less-fit parasites to be transmitted to the next set of hosts due to reduced level of intra-host competition between multiple genotypes.,"Modify,Clarity",Clarity
7764,5-1964,5-1964_v2_27@6,5-1964_v1_27@2,"Thus, fitness-reducing mutations including drug-resistance mutations might have a higher chance of spreading in SEA compared to Africa in patients not taking drugs.","Thus, fitness-reducing mutations including drug-resistance mutations might have a higher chance of spreading in SEA.","Modify,Claim",Claim
7765,5-1964,5-1964_v2_27@5,5-1964_v1_27@3,"In contrast, the higher mixed strain infection rate in Africa may drive more intense intra-host competetion, and may therefore reduce the probability of transmission of less-fit parasites.","In contrast, the higher mixed infection rate in Africa may drive more intense competition between genotypes within the host, and may therefore reduce the probability of transmission of less-fit parasites.","Modify,Clarity",Clarity
7766,5-1964,5-1964_v2_30@1,5-1964_v1_28@1,"The much larger population size of P. falciparum in Africa <REF-21> , as also evidenced by the high rate of mixed strain infection ( Figure 6 ) should make it easier for resistance mutations to appear.","The much larger population size of P. falciparum in Africa, as also evidenced by high rate of mixed infection ( Figure 6 ) should make it easier for resistance mutation to appear.","Modify,Fact/Evidence",Fact/Evidence
7767,5-1964,5-1964_v2_30@2,5-1964_v1_28@2,"Indeed, artemisinin resistance mutations in kelch13 gene were observed in samples from Africa, including the most common artemisinin resistance mutation C580Y <REF-18> .","Indeed, artemisinin resistance mutations in Kelch13 were observed in 10 samples from Africa, including two samples with the most common artemisinin resistance mutation C580Y <REF-18> .","Modify,Fact/Evidence",Fact/Evidence
7768,5-1964,5-1964_v2_30@5,5-1964_v1_28@5,"Since artemisinin resistance is likely to incur a fitness cost in the drug-free environment <REF-28> – <REF-30> , we propose that strains with these mutations are continuously arising in Africa but get competitively removed by the fitter drug-sensitive strains <REF-30> in hosts not taking artemisinin.","Since artemisinin resistance is likely to incur a fitness cost in the drug-free environment <REF-22> – <REF-24> , we propose that strains with these mutations are continuously arising in Africa but get competitively removed by the more fit drug-sensitive strains <REF-23> .","Modify,Claim",Claim
7769,5-1964,5-1964_v2_30@11,5-1964_v1_28@10,All chloroquine-resistant strains have the K76T mutation in CRT (chloroquine-resistance transporter) but are accompanied by a number of mutations in the same gene <REF-32> .,All chloroquine resistance strains have the K76T mutation in CRT (chloroquine-resistance transporter) but are accompanied by a number of mutations in the same gene <REF-26> .,"Modify,Grammar",Grammar
7770,5-1964,5-1964_v2_30@12,5-1964_v1_28@11,"While at present kelch13 does not appear to have multiple mutations <REF-33> , it would be critical to monitor the acquisition of additional mutations in the kelch13 which might compensate the fitness cost of kelch13 resistant mutations in the drug-free environment.","While at present Klech13 does not appear to have multiple mutations <REF-27> , it would be critical to monitor the acquisition of additional mutations in the Kelch13 protein which might compensate the fitness cost of Kelch13 resistant mutations in the drug-free environment.","Modify,Grammar",Grammar
7771,5-1964,5-1964_v2_31@3,5-1964_v1_29@2,"Thus mutation rate in SEA population appears to be similar to that of African population, but a higher fraction of mutations are observed at conserved non-synonymous positions in SEA.","Thus substitution rate in SEA population appears to be similar to that of African populations, but a higher fraction of those substitutions occur at conserved non-synonymous positions in SEA populations.","Modify,Clarity",Clarity
7772,5-1964,5-1964_v2_31@5,5-1964_v1_29@4,"It is also important to note that higher density of SNP/sample does not imply higher substitution rate in Africa, rather it reflects the higher rate of mixed strain infection in Africa, i.e. more SNPs are identified in samples from Africa because of the higher number of different parasite clones per samples ( Figure 6 ).","It is also important to note that higher density of SNP/sample does not imply higher substitution rate in Africa, rather it reflects the higher rate of mixed infection in Africa, i.e. more SNPs are identified in samples from Africa because of the higher number of different parasite clones per samples ( Figure 6 ).","Modify,Clarity",Clarity
7773,5-1964,5-1964_v2_30@14,5-1964_v1_30@1,Interestingly we observed a higher mixed strain infection rate in Bangladesh than in neighboring SEA.,Interestingly we observed higher mixed infection rates in Bangladesh than in neighboring SEA.,"Modify,Clarity",Clarity
7774,5-1964,5-1964_v2_34@3,5-1964_v1_32@3,The N/S ratio for each sample was obtained by dividing the number of non-synonymous SNPs by the number of synonymous SNPs in that sample.,The N/S ratio for each sample was obtained by dividing the number of non-synonymous SNPs by number of synonymous SNPs in that sample.,"Modify,Grammar",Grammar
7775,5-1964,5-1964_v2_6@1,5-1964_v1_6@1,To address this question we utilized a recent large global genome sequencing data from ~3400 clinical samples which identified nearly million high-quality single nucleotide polymorphisms (SNPs) in the exonic regions of P. falciparum <REF-18> .,To answer this question we utilized a recent large global genome sequencing data from ~3400 clinical samples which identified nearly million high-quality single nucleotide polymorphisms (SNPs) in the exonic regions of P. falciparum <REF-18> .,"Modify,Clarity",Clarity
7776,5-1964,5-1964_v2_9@8,5-1964_v1_9@8,"In addition to kelch13 , -the only gene known to be causally associated with artemisinin resistance- the list includes CRT (chloroquine-resistance transporter) which shows an 8-fold higher N/S in SEA samples compared to African samples and has previously been shown to be associated with artemisinin resistance in a genome-wide association studies (GWAS) study <REF-14> .","In addition to Kelch13, -the only gene known to be causally associated with artemisinin resistance- the list includes CRT (chloroquine-resistance transporter) which shows an 8-fold higher N/S in SEA samples compared to African samples and has previously been shown to be associated with artemisinin resistance in a genome-wide association studies (GWAS) study <REF-15> .","Modify,Grammar",Grammar
7777,5-1964,5-1964_v2_15@0,5-1964_v1_15@0,"Highly conserved proteins in P. falciparum show a much lower N/S, indicating the lower tolerance for non-synonymous polymorphism <REF-18> .","Highly conserved proteins in P. falciparum show a much lower N/S, indicating lower tolerance for non-synonymous polymorphism <REF-18> .","Modify,Grammar",Grammar
7778,5-1964,5-1964_v2_15@7,5-1964_v1_15@7,"This may be important for the acquisition of antimalarial drug resistance since drug-resistance mutations preferentially occur at the conserved sites <REF-19> , e.g. artemisinin resistance mutations in Kelch13 occur in the conserved region of the protein <REF-18> , resistance mutations also occur in the conserved regions in DHFR (dihydrofolate reductase), DHPS (dihydropteroate synthase), and CRT (chloroquine-resistance transporter) <REF-19> .","This may be important for the acquisition of antimalarial drug resistance since these mutations preferentially occur at the conserved sites <REF-19> , e.g. artemisinin resistance mutations in Klech13 occur in the conserved region of the protein <REF-18> , resistance mutations also occur in the conserved regions in DHFR (dihydrofolate reductase), DHPS (dihydropteroate synthase), and CRT (chloroquine-resistance transporter) <REF-19> .","Modify,Clarity",Clarity
7779,5-2003,5-2003_v2_70@0,,FASTQ files produced from closely related species are available in the NCBI SRA under accession numbers SRR4035250-SRR4035309 and are associated with BioProject accession number PRJNA325061 .,,"Add,Fact/Evidence",Fact/Evidence
7780,5-2003,5-2003_v2_0@0,5-2003_v1_0@0,"Using diverse U.S. beef cattle genomes to identify missense mutations in EPAS1, a gene associated with pulmonary hypertension","Using diverse U.S. beef cattle genomes to identify missense mutations in EPAS1, a gene associated with high-altitude pulmonary hypertension","Modify,Clarity",Clarity
7781,5-2003,5-2003_v2_4@1,5-2003_v1_4@1,There are currently 130 Mendelian traits with known causal mutations in 117 cattle genes <REF-1> .,There are currently 114 Mendelian traits with known causal mutations in 117 cattle genes <REF-1> .,"Modify,Fact/Evidence",Fact/Evidence
7782,5-2003,5-2003_v2_2@1,5-2003_v1_2@1,"However, existing bovine WGS databases do not show data in a form conducive to protein variant analysis, and tend to under represent the breadth of genetic diversity in global beef cattle.","However, existing bovine WGS databases do not show data in a form conducive to protein variant analysis, and tend to under represent the breadth of genetic diversity in U.S. beef cattle.","Modify,Claim",Claim
7783,5-2003,5-2003_v2_6@0,5-2003_v1_6@0,"Access to population-scale gene sequence data, however, has been a limiting step for biomedical veterinary researchers studying U.S. cattle.","However, access to population-scale gene sequence data has been a limiting step for biomedical veterinary researchers studying U.S. cattle.","Modify,Clarity",Clarity
7784,5-2003,5-2003_v2_43@4,5-2003_v1_43@4,"The two additional amino acid variants previously associated with PH, were also observed (A606T and G610S).","The two additional amino acid variants previously associated with high-altitude PH, were also observed (A606T and G610S).","Modify,Clarity",Clarity
7785,5-2003,5-2003_v2_49@0,5-2003_v1_49@0,"The HIF2A isoform associated with an increased risk for PH in Angus cattle (T606, S610; “variant 3”) was observed in 18 of 46 breeds, with four breeds having frequencies higher than Angus ( Table 3 ).","The HIF2A isoform associated with an increased risk for high-altitude PH in Angus cattle (T606, S610; “variant 3”) was observed in 18 of 46 breeds, with four breeds having frequencies higher than Angus ( Table 3 ).","Modify,Clarity",Clarity
7786,5-2003,5-2003_v2_49@2,5-2003_v1_49@2,"Notably, all 96 animals from the Bos indicus breeds (Brahman, Nelore, Indu-Brazil, and mini-zebu) were homozygous for the most common HIF2A “variant 1”.","Notably, all 96 animals from the Bos indicus breeds (Brahman, Nelore, Indu-Brazil, and mini-zebu) were homozygous for the most common HIF2A “variant 1” ( Table 4 ).","Modify,Fact/Evidence",Fact/Evidence
7787,5-2003,5-2003_v2_59@0,5-2003_v1_61@0,"Our primary goals were to create a searchable and publicly viewable genomics resource consisting of 96 sires representing a broad cross section of U.S. beef cattle, and demonstrate its use for identifying missense mutations in EPAS1 , a bovine gene associated with PH and RHF <REF-15> .","Our primary goals were to create a searchable and publicly viewable genomics resource consisting of 96 sires representing a broad cross section of U.S. beef cattle, and demonstrate its use for identifying missense mutations in EPAS1 , a bovine gene associated with high-altitude PH and RHF <REF-15> .","Modify,Clarity",Clarity
7788,5-2003,5-2003_v2_2@3,5-2003_v1_2@3,"Our second aim was to identify protein variants encoded by the bovine endothelial PAS domain-containing protein 1 gene ( EPAS1 ), a gene associated with pulmonary hypertension in Angus cattle.","Our second aim was to identify protein variants encoded by the bovine endothelial PAS domain-containing protein 1 gene ( EPAS1 ), a gene associated with high-altitude pulmonary hypertension in Angus cattle.","Modify,Clarity",Clarity
7789,5-2003,5-2003_v2_61@2,5-2003_v1_63@2,"Six missense mutations, including the two that were previously reported to be associated with PH <REF-15> , were readily identified by viewing the aligned raw sequence.","Six missense mutations, including the two that were previously reported to be associated with high-altitude PH <REF-15> , were readily identified by viewing the aligned raw sequence.","Modify,Clarity",Clarity
7790,5-2003,5-2003_v2_9@1,5-2003_v1_9@1,EPAS1 was selected for analysis because two linked missense mutations were reported to be associated with pulmonary hypertension (PH) in Angus cattle <REF-15> .,EPAS1 was selected for analysis because two linked missense mutations were reported to be associated with high-altitude pulmonary hypertension (PH) in Angus cattle <REF-15> .,"Modify,Clarity",Clarity
7791,5-2003,5-2003_v2_62@0,5-2003_v1_64@0,"The report by Newman et al. <REF-15> , describing an EPAS1 T606, S610 gene variant associated with PH, raises intriguing questions about the biological mechanisms leading to disease.","The report by Newman et al. <REF-15> , describing an EPAS1 T606, S610 gene variant associated with high-altitude PH, raises intriguing questions about the biological mechanisms leading to disease.","Modify,Clarity",Clarity
7792,5-2003,5-2003_v2_64@2,5-2003_v1_66@2,"Moreover, the F701 substitution was only observed in one of 1250 animals tested (Salers sire no. 19999882 in MBCDPv2.9).","Moreover, the F701 substitution was only observed in one of 1250 animals tested (Salers, no. 19999882).","Modify,Fact/Evidence",Fact/Evidence
7793,5-2003,5-2003_v2_9@4,5-2003_v1_9@4,"The linked missense mutations in EPAS1 encode threonine (T) and serine (S) at amino acid positions 606 and 610, respectively, and were associated with PH when compared to the more common allele encoding alanine (A) and glycine (G) at these positions <REF-15> .","The linked missense mutations in EPAS1 encode threonine (T) and serine (S) at amino acid positions 606 and 610, respectively, and were associated with high-altitude PH when compared to the more common allele encoding alanine (A) and glycine (G) at these positions <REF-15> .","Modify,Clarity",Clarity
7794,5-2003,5-2003_v2_69@0,5-2003_v1_71@0,Validated cattle FASTQ files are available in the NCBI SRA under accession numbers SRR4001609-SRR4002095; SRR4004613-SRR4004644; SRR4002950-SRR4003067; SRR4003069-SRR4003073; SRR4003075-SRR4003079; SRR4003081-SRR4003085; SRR4003087-SRR4003094; SRR4003096-SRR4003139; SRR4003141-SRR4003146; SRR4003148-SRR4003152; SRR4003154-SRR4003158; SRR4003160-SRR4003164; SRR4003166-SRR4003170; SRR4003172-SRR4003177; SRR4003179-SRR4003182; SRR4003184-SRR4003188; SRR4003190-SRR4003451; SRR4004645-SRR4004679; SRR4004680-SRR4004734; SRR4004736-SRR4004891; SRR4004893-SRR4004920; SRR4004922-SRR4004948; SRR4004950-SRR4004982; SRR4004991-SRR4004992; SRR4004994-SRR4004997; SRR4005006-SRR4005012; SRR4005021-SRR4005026; SRR4005044-SRR4005048; SRR4005057-SRR4005062; SRR4005071-SRR4005195.,Validated FASTQ files are available in the NCBI SRA under accession numbers SRR4001609-SRR4002095; SRR4004613-SRR4004644; SRR4002950-SRR4003067; SRR4003069-SRR4003073; SRR4003075-SRR4003079; SRR4003081-SRR4003085; SRR4003087-SRR4003094; SRR4003096-SRR4003139; SRR4003141-SRR4003146; SRR4003148-SRR4003152; SRR4003154-SRR4003158; SRR4003160-SRR4003164; SRR4003166-SRR4003170; SRR4003172-SRR4003177; SRR4003179-SRR4003182; SRR4003184-SRR4003188; SRR4003190-SRR4003451; SRR4004645-SRR4004679; SRR4004680-SRR4004734; SRR4004736-SRR4004891; SRR4004893-SRR4004920; SRR4004922-SRR4004948; SRR4004950-SRR4004982; SRR4004991-SRR4004992; SRR4004994-SRR4004997; SRR4005006-SRR4005012; SRR4005021-SRR4005026; SRR4005044-SRR4005048; SRR4005057-SRR4005062; SRR4005071-SRR4005195.,"Modify,Fact/Evidence",Fact/Evidence
7795,5-251,,5-251_v1_34@10,,"These results further support the concept that the effects of antibody modulation of Tim-1 are cell-type and context-dependent <REF-7> , <REF-16> .","Delete,Fact/Evidence",Fact/Evidence
7796,5-251,,5-251_v1_52@7,,"However, after testing six different batches of WT and Tim-1 Δmucin BMMCs, it appeared that any differences observed were due to the maturation status of BMMCs and their FcεRI surface expression, rather than any direct effect of deletion of the Tim-1 mucin domain.","Delete,Fact/Evidence",Fact/Evidence
7797,5-251,,5-251_v1_55@0,,"Taken together, our findings provide further evidence that Tim-1 signaling can promote cytokine production in IgE/Ag-activated mast cells.","Delete,Fact/Evidence",Fact/Evidence
7798,5-251,,5-251_v1_55@1,,"This is in line with a co-stimulatory role for Tim-1 in T, B and NKT cells, both in vitro and in vivo .","Delete,Fact/Evidence",Fact/Evidence
7799,5-251,,5-251_v1_55@2,,"Contrary to their previously described effects on these cell types, Tim-1 antibodies did not regulate mast cell degranulation and cytokine production in our hands.","Delete,Fact/Evidence",Fact/Evidence
7800,5-251,,5-251_v1_55@3,,"Nevertheless, Tim-1 ligation by Tim-4 consistently enhanced mast cell cytokine production, and this effect was not affected by loss of the Tim-1 mucin domain.","Delete,Fact/Evidence",Fact/Evidence
7801,5-251,,5-251_v1_55@4,,"We also showed, for the first time, that unlike in regulatory B cells, the Tim-1 mucin domain is dispensable for mast cell effector function.","Delete,Fact/Evidence",Fact/Evidence
7802,5-251,,5-251_v1_55@5,,"Mast cells play diverse roles in hypersensitivity, allergic and, as has been increasingly appreciated, non-allergic diseases <REF-17> .","Delete,Fact/Evidence",Fact/Evidence
7803,5-251,,5-251_v1_55@6,,Tim-1 blockade or cross-linking by known ligands and antibodies has been shown to ameliorate or exacerbate allergic lung inflammation in vivo .,"Delete,Claim",Claim
7804,5-251,,5-251_v1_55@7,,"Therefore, manipulation of Tim-1 activity on mast cells, particularly modulation of the Tim1-Tim4 interaction, could be a novel therapeutic target to control allergic and autoimmune disease.","Delete,Claim",Claim
7805,5-251,5-251_v2_31@2,,We first confirmed that Tim4-Fc could bind to our cultures of bone marrow derived mast cells (BMMC) from C57BL/6 mice ( Figure 1A ).,,"Add,Fact/Evidence",Fact/Evidence
7806,5-251,5-251_v2_52@7,,"However, this was not a consistent finding.",,"Add,Claim",Claim
7807,5-251,5-251_v2_34@9,5-251_v1_34@9,"Again, there was no detectable increase in IL-6 production when these antibodies were used in co-stimulation with FcεRI crosslinking by IgE/Ag, on BMMC derived from C57BL/6 mice ( Figure 2F ).","There was a small, although statistically insignificant, increase in IL-6 production when 4G8 was used in co-stimulation with FcεRI crosslinking by IgE/Ag ( Figure 2F ).","Modify,Fact/Evidence",Fact/Evidence
7808,5-251,5-251_v2_38@2,5-251_v1_38@2,"Similarly, ectopic expression of an N-terminal FLAG-tagged Tim-1 on MC/9 mast cells was able to enhance IgE/Ag-stimulated NF-κB transcriptional activation ( Figure 3A ).","Similarly, ectopic expression of Tim-1 on MC/9 mast cells was able to enhance IgE/Ag-stimulated NF-κB transcriptional activation ( Figure 3A ).","Modify,Fact/Evidence",Fact/Evidence
7809,5-251,5-251_v2_50@2,5-251_v1_50@2,"Similar to our findings on the effects of Tim-3 on mast cells <REF-18> , ectopic expression of Tim-1 expression was sufficient to promote IgE/Ag-mediated NF-κB and NF-AT/AP1 transcriptional activation (at least in MC/9 cells), without additional cross-linking antibodies or exogenous ligands.","Similar to our findings on the effects of Tim-3 on mast cells <REF-18> , Tim-1 expression alone could promote IgE/Ag-mediated NF-κB and NF-AT/AP1 transcriptional activation, without additional cross-linking antibodies or exogenous ligands.","Modify,Fact/Evidence",Fact/Evidence
7810,5-251,5-251_v2_50@5,5-251_v1_50@5,"Tim-1 has also been reported to bind LMIR5/CD300b, an activating receptor expressed on myeloid cells <REF-25> .","Tim-1 has also been reported to bind LMIR5/CD300b, a DAP12-coupled activating receptor expressed on myeloid cells <REF-25> .","Modify,Fact/Evidence",Fact/Evidence
7811,5-251,5-251_v2_50@6,5-251_v1_50@6,"Stimulation with Tim1-Fc was able to induce LMIR5-mediated ERK activation in mast cells, suggesting that LMIR5 is an endogenous ligand of Tim-1, driving the enhancement of transcriptional response.","Thus, stimulation with TIM1-Fc was able to induce LMIR5-mediated ERK activation in mast cells, suggesting that LMIR5 is another potential endogenous ligand of Tim-1, driving the enhancement of transcriptional response.","Modify,Claim",Claim
7812,5-251,5-251_v2_50@7,5-251_v1_50@7,"Finally, Tim-1 may homodimerize through its glycosylated mucin-like domain, leading to downstream signaling and function.","Finally, Tim-1 may homodimerize through its heavily glycosylated mucin domain, leading to its phosphorylation and downstream function.","Modify,Claim",Claim
7813,5-251,5-251_v2_50@8,5-251_v1_50@8,"We showed that Tim-1 co-stimulation is dependent on the tyrosine phosphorylation motif in its cytoplasmic tail, as mutation of tyrosine 276 rendered Tim-1 unable to mediate co-stimulation.","Regardless of its mode of activation, we showed that Tim-1 co-stimulation is dependent on the tyrosine phosphorylation motif of Tim-1 cytoplasmic tail as mutation of tyrosine 276 rendered Tim-1 unable to mediate its co-stimulatory function.","Modify,Clarity",Clarity
7814,5-251,5-251_v2_50@11,5-251_v1_50@11,"Therefore, Src family kinases like Lyn, Fyn or Hck are potential facilitators of Tim-1 phosphorylation upon IgE/Ag activation in mast cells.","Therefore, Src family kinases like Lyn, Fyn or Hck are potential facilitators of Tim-1 phosphorylation upon IgE/Ag activation.","Modify,Claim",Claim
7815,5-251,5-251_v2_51@4,5-251_v1_51@4,"This bimodal regulation was later reported to inhibit activation of naïve T cells, which do not express Tim-1, and to enhance activation of effector T cells, suggesting that Tim-4 binds to an unknown ligand expressed preferentially on naïve T cells <REF-27> .","This bimodal regulation was later reported to be inhibitory for naïve T cells, which do not express Tim-1, and co-stimulatory for activated T cells, suggesting that Tim-4 either binds to an unknown ligand expressed only on naïve T cells or that Tim-4 has a higher affinity for Tim-1 expressed on activated T cells <REF-27> .","Modify,Fact/Evidence",Fact/Evidence
7816,5-251,5-251_v2_52@0,5-251_v1_52@0,"To determine whether Tim-1 plays a positive or negative regulatory role in mast cells, we first attempted siRNA-mediated knockdown of Tim-1 protein in BMMCs but were unsuccessful in obtaining efficient reduction of Tim-1 expression.","To determine whether Tim-1 plays a positive or negative regulatory role in mast cells, we first attempted siRNA-mediated knockdown of Tim-1 protein in BMMCs but were unsuccessful in obtaining efficient Tim-1 reduction.","Modify,Clarity",Clarity
7817,5-251,5-251_v2_52@1,5-251_v1_52@1,"Furthermore, two separate strains of Tim-1-deficient mice showed relatively unaltered IgE production and AHR development in an OVA-induced mouse model of asthma, although one study did note higher type 2 and Th17 cytokine production in Tim-1 knockout (KO) mice <REF-26> , <REF-29> .","Furthermore, two separate strains of Tim-1-deficient mice showed relatively unaltered IgE production and AHR development in an OVA-induced mouse model of asthma, even though one study did observe higher type 2 and Th17 cytokine production in Tim-1 knockout (KO) mice <REF-26> , <REF-29> .","Modify,Clarity",Clarity
7818,5-251,5-251_v2_52@3,5-251_v1_52@3,"The mucin domain of Tim-1 is also essential for homeostasis and function of regulatory B cells <REF-14> , <REF-15> , <REF-21> .","It is also essential to regulatory B cell maintenance, signaling, transplant tolerance and induction of systemic autoimmunity <REF-14> , <REF-15> , <REF-21> .","Modify,Fact/Evidence",Fact/Evidence
7819,5-251,5-251_v2_52@5,5-251_v1_52@5,"Contrary to the effects seen in B and T cells, the mucin domain was dispensable for the effects of Tim-1 in mast cells, as degranulation and cytokine release were intact in the absence of the mucin domain.","Contrary to the effects seen in B and T cells, the Tim-1 mucin domain is dispensable for mast cell activity, as mast cell degranulation and cytokine release remain intact in the absence of the mucin domain.","Modify,Clarity",Clarity
7820,5-251,5-251_v2_52@8,5-251_v1_52@8,"While our study focused on bone marrow-derived mast cells, absence of the Tim-1 mucin domain may nonetheless affect the differentiation and/or function of other mast cell types in their respective tissue microenvironments in vivo .","While our study focused on bone marrow-derived mast cells, absence of the Tim-1 mucin domain may nonetheless affect trafficking and/or differentiation of other mast cell types in their respective tissue microenvironments in vivo .","Modify,Claim",Claim
7821,5-251,5-251_v2_52@9,5-251_v1_52@9,"Tim1-Tim4 interactions are thought to occur mostly through their respective IgV domains, although there is evidence that Tim-4 may also bind to the Tim-1 mucin domain <REF-10> .","Tim1-Tim4 interaction is thought to occur mostly through the IgV domains of the respective proteins, although there is evidence that Tim-4 may also bind to the Tim-1 mucin domain <REF-10> .","Modify,Clarity",Clarity
7822,5-251,5-251_v2_52@10,5-251_v1_52@10,We showed that Tim-4 mediated co-stimulation of mast cell function occurred independent of the Tim-1 mucin domain.,We showed that Tim-4 mediated co-stimulation of mast cell function occurred independent of the mucin domain.,"Modify,Clarity",Clarity
7823,5-251,5-251_v2_53@0,5-251_v1_53@0,We also examined the signaling pathways upstream of enhanced transcriptional activation and cytokine production by Tim-1 and Ag co-stimulation in mast cells.,We also examined the signaling pathways leading to enhanced transcriptional activation and cytokine production by Tim-1 and Ag co-stimulation in mast cells.,"Modify,Clarity",Clarity
7824,5-251,5-251_v2_53@2,5-251_v1_53@2,"This is consistent with our finding that the Tim1-Tim4 interaction did not alter Ag-stimulated FcεRI signaling intensity, using mast cells from a Nur77 GFP mouse model <REF-18> .","This is consistent with our finding that the Tim1-Tim4 interaction did not promote Ag-stimulated FcεRI signaling intensity, using mast cells from a Nur77 GFP mouse model <REF-18> .","Modify,Clarity",Clarity
7825,5-251,5-251_v2_53@3,5-251_v1_53@3,"Syk is phosphorylated on multiple tyrosines by either auto-phosphorylation or trans-phosphorylation by Lyn, resulting in enhancement or inhibition, respectively, of Ag-mediated FcεRI signaling <REF-31> – <REF-33> .","Syk is phosphorylated on multiple tyrosines by either auto-phosphorylation or trans-phosphorylation by Lyn, resulting in positive or negative regulation, respectively, of Ag-mediated FcεRI signaling <REF-31> – <REF-33> .","Modify,Clarity",Clarity
7826,5-251,5-251_v2_53@4,5-251_v1_53@4,"Since we only examined tyrosines 519 and 520 in the Syk activation loop, which are sites of Syk auto-phosphorylation, it is possible that other tyrosine phosphorylation sites of phosphorylation may be affected by Tim-1.","Since we only examined tyrosines 519 and 520 in the kinase loop, which are sites of Syk auto-phosphorylation, it is possible that other tyrosine phosphorylation sites may be affected by Tim-1.","Modify,Claim",Claim
7827,5-251,5-251_v2_53@7,5-251_v1_53@7,"In particular, Src homology-2-containing signaling protein (SHIP), which has been implicated in regulation of IgE/Ag-induced IL-6 production through inhibition of NF-κB activity, both of which are enhanced by Tim-1 cross-linking in our study <REF-35> .","Thus, a particular FcεRI proximal phosphatase of interest is the Src homology-2-containing signaling protein (SHIP), which has been implicated in regulation of IgE/Ag-induced IL-6 production through inhibition of NF-κB activity, both of which are enhanced by Tim-1 cross-linking in our study <REF-35> .","Modify,Fact/Evidence",Fact/Evidence
7828,5-251,5-251_v2_54@0,5-251_v1_54@0,"In a previous study, Tim-4 was shown to enhance phosphorylation of Erk and Akt in CD4 T cells <REF-9> .","In a previous study, Tim-4/CD3/CD28-coated beads enhanced phosphorylation of Erk and Akt in CD4 T cells <REF-9> .","Modify,Fact/Evidence",Fact/Evidence
7829,5-251,5-251_v2_54@1,5-251_v1_54@1,"These effects were not observed in a previous study on mast cells, with either BMMC’s or peritoneal mast cells (PMCs) <REF-16> .",These results were not observed in previously study using both BMMCs and peritoneal mast cells (PMCs) <REF-16> .,"Modify,Clarity",Clarity
7830,5-251,5-251_v2_54@2,5-251_v1_54@2,"Similarly, we did not observe effects of soluble Tim-4 on these signaling pathways, in conjunction with Ag-mediated FcεRI aggregation.","Similarly, we did not observe similar effect with soluble Tim-4 addition in Ag-mediated FcεRI aggregation at the peak of antigen stimulation or when signals returned to basal.","Modify,Fact/Evidence",Fact/Evidence
7831,5-251,5-251_v2_54@4,5-251_v1_54@4,"While phosphorylation of Akt was not detectably affected, phosphorylation of ribosomal protein S6 was significantly enhanced upon Tim-4 treatment, an effect that correlated with enhanced cytokine production.","While phosphorylation of Akt was not affected, ribosomal protein S6 was significantly enhanced upon Tim-4 treatment.","Merge+Modify,Fact/Evidence",Fact/Evidence
7832,5-251,5-251_v2_54@4,5-251_v1_54@5,"While phosphorylation of Akt was not detectably affected, phosphorylation of ribosomal protein S6 was significantly enhanced upon Tim-4 treatment, an effect that correlated with enhanced cytokine production.","Specifically, Tim-1 cross-linking enhanced and sustained IgE/Ag-induced S6 phosphorylation, which correlates with enhanced cytokine production.","Merge+Modify,Fact/Evidence",Fact/Evidence
7833,5-251,5-251_v2_11@2,5-251_v1_11@2,"Monoclonal antibodies to murine Tim-1 (3B3, RMT1-10, 5G5, 5F12) and purified Tim4-Fc (the latter consists of the IgV and mucin domains of murine Tim-4 fused to the constant region of hIgG1) were obtained from Vijay Kuchroo (Harvard Medical School).","Monoclonal antibodies to murine Tim-1 (3B3, RMT1-10, 5G5, 5F12) and purified Tim4-Fc were obtained from Vijay Kuchroo (Harvard Medical School).","Modify,Fact/Evidence",Fact/Evidence
7834,5-2532,,5-2532_v1_20@4,,"Post-transplant, he developed hypertension and later developed septic shock, which were managed successfully.","Delete,Fact/Evidence",Fact/Evidence
7835,5-2532,5-2532_v2_2@2,,"Mutations of the recombination-activating genes RAG 1 and RAG 2 are associated with a range of clinical presentations including, severe combined immunodeficiency and autoimmunity.",,"Add,Claim",Claim
7836,5-2532,5-2532_v2_2@3,,"Recently, our understanding of the molecular basis of immune dysfunction in RAG deficiency has improved tremendously with newer insights into the ultrastructure of the RAG complex.",,"Add,Claim",Claim
7837,5-2532,,5-2532_v1_4@2,,"The accurate molecular diagnosis would provide a fresh opportunity to enable cost-effective screening of family members and offer appropriate genetic counselling especially for populations where there is a high degree of consanguinity <REF-3> , <REF-4> .","Delete,Fact/Evidence",Fact/Evidence
7838,5-2532,5-2532_v2_4@1,,"The patients with SCID exhibit recurrent infections with bacteria, virus and fungi.",,"Add,Fact/Evidence",Fact/Evidence
7839,5-2532,5-2532_v2_4@2,,The deficiency of recombination activating gene is associated with T - B - NK + SCID.,,"Add,Fact/Evidence",Fact/Evidence
7840,5-2532,5-2532_v2_4@3,,Recombination of activating gene enzymes plays a significant role in recombination of V(D)J segments <REF-2> .,,"Add,Fact/Evidence",Fact/Evidence
7841,5-2532,5-2532_v2_4@4,,"The mutation in recombination activating gene 1 ( RAG1 ) is associated with absence of V(D)J recombination, which in turn produces immature lymphocytes leading to SCID <REF-3> .",,"Add,Fact/Evidence",Fact/Evidence
7842,5-2532,5-2532_v2_11@3,,The child’s mother was HIV ELISA negative and the child had a negative Mantoux test and negative gastric acid AFB stain.,,"Add,Fact/Evidence",Fact/Evidence
7843,5-2532,5-2532_v2_14@2,,"The conditioning regimen used was Fludarbine 40mg/M2 for 4 days, and Treosulphan 12 gm/M2 for 3 days.",,"Add,Fact/Evidence",Fact/Evidence
7844,5-2532,5-2532_v2_14@3,,"GVHD prophylaxis was provided with Methotrexate 10 mg/M2 on days 1, 3 and 6 following transplant, along with Tacrolimus on day 0.",,"Add,Fact/Evidence",Fact/Evidence
7845,5-2532,5-2532_v2_14@4,,Leuconostoc sepsis was treated with intravenous Amoxicillin and Clavulanic acid.,,"Add,Fact/Evidence",Fact/Evidence
7846,5-2532,5-2532_v2_14@5,,Chimerism was assessed using whole blood by fluorescence in situ hybridization (FISH) as the transplant was sex mismatched.,,"Add,Fact/Evidence",Fact/Evidence
7847,5-2532,5-2532_v2_14@6,,"At 6 months post- transplant, chimerism was down to 28%, and hence 2 donor lymphocyte infusions were given.",,"Add,Fact/Evidence",Fact/Evidence
7848,5-2532,5-2532_v2_14@7,,"The last assessment was done at 1 year by T and B cell markers and serum immunoglobulins, and these were found to be within the normal range.",,"Add,Fact/Evidence",Fact/Evidence
7849,5-2532,5-2532_v2_16@0,,Methods,,"Add,Other",Other
7850,5-2532,5-2532_v2_18@0,,Results,,"Add,Other",Other
7851,5-2532,5-2532_v2_23@2,,"Whole exome sequencing identified a mutation c.2308G>A p.E770K in RAG1 , which was previously reported and shown to significantly reduce recombination activity <REF-12> .",,"Add,Fact/Evidence",Fact/Evidence
7852,5-2532,5-2532_v2_23@3,,"We feel that whole exome sequencing can have more extensive application in the management of primary immune deficiency in developing countries like India, and can add to rapidly expanding scientific knowledge in this arena.",,"Add,Claim",Claim
7853,5-2532,,5-2532_v1_11@4,,The baby was negative for HIV infection and there was no evidence of tuberculosis.,"Delete,Fact/Evidence",Fact/Evidence
7854,5-2532,,5-2532_v1_2@2,,The widespread application of whole-exome sequencing based on next-generation sequencing has offered a new opportunity to systematically screen these genes in clinical scales.,"Delete,Claim",Claim
7855,5-2532,5-2532_v2_22@1,5-2532_v1_19@1,X-linked recessive severe combined Immunodeficiency (SCID) is characterized by an elevated percentage of B cells and the absence of B cells in the child ruled this out.,XR SCID is characterized by an elevated percentage of B cells and in the absence of B cells in the child ruled this out.,"Modify,Clarity",Clarity
7856,5-2532,5-2532_v2_22@2,5-2532_v1_19@2,Janus kinase 3 (Jak3) deficiency was also not thought of for the same reason.,Jak3 deficiency was also not thought of for the same reason.,"Modify,Clarity",Clarity
7857,5-2532,5-2532_v2_22@3,5-2532_v1_19@3,"Adenosine deaminase (ADA) deficient SCID is characterized by bony abnormalities including rib cage defects, which were absent.","ADA deficient SCID is characterized by bony abnormalities including rib cage defects, which were absent.","Modify,Clarity",Clarity
7858,5-2532,5-2532_v2_14@8,5-2532_v1_20@5,The chilld is now one year three months post-transplant and off all medications including immunosuppressive therapy.,He is now one year three months post-transplant and off all medications including immunosuppressive therapy.,"Modify,Clarity",Clarity
7859,5-2532,5-2532_v2_4@0,5-2532_v1_4@0,Severe combined immunodeficiency (SCID) encompasses a constellation of clinically and genetically heterogeneous diseases resulting in defects of the humoral and/or cellular immune defense mechanism <REF-1> .,Severe combined immunodeficiency (SCID) encompasses a constellation of clinically and genetically heterogeneous diseases resulting in defects of the humoral and/or cellular immune defence mechanism <REF-1> .,"Modify,Grammar",Grammar
7860,5-2532,5-2532_v2_4@5,5-2532_v1_4@1,The accurate molecular diagnosis in SCID enables genetic counselling for disease <REF-4> .,"Accurate molecular diagnosis of the disease is of prime importance, not only in offering appropriate genetic counselling, but also in understanding the exact molecular defect and would potentially enable prenatal screening <REF-2> .","Modify,Fact/Evidence",Fact/Evidence
7861,5-2532,5-2532_v2_4@6,5-2532_v1_4@3,"So far, arriving at a precise molecular diagnosis has been quite cumbersome, technically challenging and expensive, as over a dozen genes are known to be implicated in the genetic disease, which would require systematic targeted sequencing of each of the gene <REF-5> , <REF-6> .","So far, arriving at a precise molecular diagnosis has been quite cumbersome, technically challenging and expensive as over a dozen genes are known to be implicated in the disease, which would require systematic targeted sequencing of each of the gene <REF-5> , <REF-6> .","Modify,Clarity",Clarity
7862,5-2532,5-2532_v2_4@7,5-2532_v1_4@4,"The advent of next generation sequencing, especially whole exome and sometimes whole genome sequencing has significantly enabled the rapid identification of the causative genetic variations in clinical settings <REF-6> .","The advent of next generation sequencing, especially whole exome and sometime whole genome sequencing has significantly enabled the rapid identification of the causative genetic variations in clinical settings <REF-6> .","Modify,Grammar",Grammar
7863,5-2532,5-2532_v2_5@0,5-2532_v1_5@0,"In this report, we describe the application of whole exome sequencing for the accurate molecular diagnosis of a case of T - B - NK+ SCID.","In the present report, we describe the application of whole exome sequencing for the accurate molecular diagnosis of a case of B- T- NK+ SCID.","Modify,Clarity",Clarity
7864,5-2532,5-2532_v2_5@1,5-2532_v1_5@1,Our report also adds a genetic variation c.2308G>A p.E770K in Recombination activating gene 1 ( RAG1 ) to the compendium of variations associated with the disease.,Our report also adds a genetic variation c.2308G>A p.E770K to the compendium of variations associated with the disease.,"Modify,Fact/Evidence",Fact/Evidence
7865,5-2532,5-2532_v2_7@4,5-2532_v1_7@4,"There was no facial dysmorphism, and skin and hair were normal.",There was no facial dysmorphism and skin and hair were normal.,"Modify,Grammar",Grammar
7866,5-2532,5-2532_v2_7@5,5-2532_v1_7@5,He weighed 5.4 kg; measured 64 cm in length and head circumference was 39.5 cm; all below the 3rd centile as per WHO Child Growth Standards.,He weighed 5.4 kg; measured 64 cm in length and head circumference was 39.5 cm.,"Modify,Fact/Evidence",Fact/Evidence
7867,5-2532,5-2532_v2_8@2,5-2532_v1_8@2,There was a history of admission to pediatric intensive care unit (PICU) and artificial ventilation for severe pneumonia at the age of 2 months.,There was a history of admission to PICU and artificial ventilation for severe pneumonia at the age of 2 months.,"Modify,Clarity",Clarity
7868,5-2532,5-2532_v2_2@1,5-2532_v1_2@1,At least 13 genes are known to be involved in the pathophysiology of the disease and the mutation spectrum in SCID has been well documented.,At least 13 genes are known to be involved in the pathophysiology of the disease and the mutation spectrum in SCID have been well documented.,"Modify,Grammar",Grammar
7869,5-2532,5-2532_v2_11@0,5-2532_v1_11@0,"On investigation, the child was found to have hypochromic microcytic anemia, lymphocytopenia, and a normal eosinophil count and platelet count.","On investigation, the child was found to have hypochromic microcytic anemia, lymphocytopenia with absolute lymphocyte counts less than 1000/cu.mm and a normal platelet count.","Modify,Fact/Evidence",Fact/Evidence
7870,5-2532,5-2532_v2_11@4,5-2532_v1_11@5,His chest X-Ray’s lateral view showed absence of the thymus shadow apart from evidence of bronchopneumonia.,His chest X-Ray showed absence of the thymus shadow apart from evidence of bronchopneumonia.,"Modify,Clarity",Clarity
7871,5-2532,5-2532_v2_13@0,5-2532_v1_13@0,"The child was treated with piperacillin (80mg/kg/dose Q8H), vancomycin (15 mg/kg/dose Q6H), dopamine (10 mic/kg/min), intravenous immunoglobulin (IVIG) and other supportive measures and was put on cotrimoxazole (6 mg/kg/day OD) prophylaxis.","The child was treated with piperacillin (80mg/kg/dose Q8H), vancomycin (15 mg/kg/dose Q6H), dopamine (10 mic/kg/min), IVIG and other supportive measures and was put on cotrimoxazole (6 mg/kg/day OD) prophylaxis.","Modify,Clarity",Clarity
7872,5-2532,5-2532_v2_17@0,5-2532_v1_14@2,"After obtaining informed consent from the parents, blood was drawn by venipuncture under aseptic precautions.","After obtaining informed consent from the parents, blood was drawn after venipuncture under aseptic precautions.","Modify,Grammar",Grammar
7873,5-2532,5-2532_v2_17@5,5-2532_v1_14@7,"For the prioritisation of variants, we filtered all homozygous variants, further filtered by an allele frequency of <1% in the 1000 Genome and ExAC.","For the prioritisation of variants, we filtered all homozygous variants, further filtered by an allele frequency of <1% in the 1000 Genome and Exac.","Modify,Grammar",Grammar
7874,5-2532,5-2532_v2_19@0,5-2532_v1_15@0,Whole exome sequencing analysis revealed a homozygous missense variation (c.2308G>A) in exon number 2 of recombination activating gene 1 ( RAG1 ).,Analysis revealed a homozygous missense variation (c.2308G>A) in exon number 2 of Recombination activating gene 1 (RAG1).,"Modify,Clarity",Clarity
7875,5-2532,5-2532_v2_19@3,5-2532_v1_15@3,"The present variation was not found in the 1000 Genome ( http://browser.1000genomes.org/index.html ), ExAC ( http://exac.broadinstitute.org/ ) or internal control database of over 150 exomes from South East Asian ancestry.","The present variation was not found in the 1000 Genome ( http://browser.1000genomes.org/index.html ), Exac ( http://exac.broadinstitute.org/ ) or internal control database of over 150 exomes from South East Asian ancestry.","Modify,Grammar",Grammar
7876,5-2532,5-2532_v2_21@0,5-2532_v1_18@0,Mutations in recombinase activating gene ( RAG1) cause various degrees of severe combined immunodeficiency syndrome (SCID).,Mutations in RAG1 gene cause various degrees of severe combined immunodeficiency syndrome.,"Modify,Clarity",Clarity
7877,5-2634,5-2634_v2_35@0,,"Because edge densities can be selectively displayed, KK CSNs generated for larger compound data sets can be readily analyzed.",,"Add,Claim",Claim
7878,5-2634,5-2634_v2_35@1,,"In addition, for SAR analysis, one may initially select a high threshold value to primarily focus on intra-cluster relationships and then gradually decrease the threshold to concentrate more on inter-cluster connections, as illustrated in Figure 2 .",,"Add,Fact/Evidence",Fact/Evidence
7879,5-2634,5-2634_v2_34@0,5-2634_v1_34@0,"Figure 2 shows KK CSNs for inhibitors of MAP kinase ERK2 and glutamate [NMDA] receptor subunit ε2 (data sets 11638 and 222, respectively) ( Table 1 ).",Figure 2 shows KK CSNs for data sets 11638 and 222 ( Table 1 ).,"Modify,Fact/Evidence",Fact/Evidence
7880,5-2634,5-2634_v2_34@2,5-2634_v1_34@2,"The KK CSN of the MAP kinase inhibitor set 11638 revealed a clear clustering of similar compounds with comparably high or low potency, corresponding to the presence of locally continuous SARs <REF-1> .","The KK CSN of set 11638 revealed a clear clustering of similar compounds with comparably high or low potency, corresponding to the presence of locally continuous SARs <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
7881,5-2634,5-2634_v2_34@3,5-2634_v1_34@3,"By contrast, the KK CSN of the set of ligands of glutamate [NMDA] receptor subunit ε2 revealed a cluster of highly similar compounds with large potency variations, corresponding to a high degree of local SAR discontinuity <REF-1> .","By contrast, the KK CSN of set 222 revealed a cluster of highly similar compounds with large potency variations, corresponding to a high degree of local SAR discontinuity <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
7882,5-2634,5-2634_v2_34@4,5-2634_v1_34@4,"This cluster was distant from other compounds of this set, consistent with the presence of unique structural features.","This cluster was distant from other compounds of set 222, consistent with the presence of unique structural features.","Modify,Clarity",Clarity
7883,5-2634,5-2634_v2_39@0,5-2634_v1_38@0,"Figure 3 compares the KK and FR CSNs for a set of inhibitors of the apoptosis regulator Bcl-W (data set 100476), revealing the presence of distinct layouts.","Figure 3 compares the KK and FR CSNs for set 100476, revealing the presence of distinct layouts.","Modify,Fact/Evidence",Fact/Evidence
7884,5-2634,5-2634_v2_47@0,5-2634_v1_46@0,"Figure 5 shows a KK CSN representation for three analog series (A, B, and C) that were extracted from compounds active against the serotonin 1a receptor (data set 51).","Figure 5 shows a KK CSN representation for three analog series (A, B, and C) that were extracted from compound set 51.","Modify,Fact/Evidence",Fact/Evidence
7885,5-2807,5-2807_v2_10@0,,"By examining the differences between the populations and computing genetic distances we can make suggestions on approximate time of the population separation ( Nei, 1972 ).",,"Add,Fact/Evidence",Fact/Evidence
7886,5-2807,5-2807_v2_10@1,,The AFLP profiles show patterns of nuclear DNA markers obtained across the whole genome.,,"Add,Fact/Evidence",Fact/Evidence
7887,5-2807,5-2807_v2_10@2,,"This data analysis gives an opportunity to estimate genetic similarity of the samples, and statistically verify significance of the differences.",,"Add,Claim",Claim
7888,5-2807,5-2807_v2_10@4,,"Dominant markers are applicable for polyploid genome studies but less informative than co-dominant markers ( Guillot & Carpentier-Skandalis, 2011 ).",,"Add,Fact/Evidence",Fact/Evidence
7889,5-2807,5-2807_v2_10@5,,"It allows to obtain a large marker set from nuclear DNA but these markers are anonymous ( Vos et al. , 1995 ).",,"Add,Fact/Evidence",Fact/Evidence
7890,5-2807,5-2807_v2_10@6,,We can’t distinguish which of them are selectively neutral and more informative.,,"Add,Claim",Claim
7891,5-2807,5-2807_v2_10@7,,"Therefore, it’s not correct to make the ultimate phylogenetic conclusions based only on this data.",,"Add,Claim",Claim
7892,5-2807,5-2807_v2_10@8,,The AFLP method could be very useful in comparison with the data obtained from other methods of nuclear DNA marker investigations.,,"Add,Claim",Claim
7893,5-2807,5-2807_v2_14@4,,Selective primer combinations produced sets of markers with different levels of polymorphism.,,"Add,Fact/Evidence",Fact/Evidence
7894,5-2807,5-2807_v2_14@5,,The eight combinations demonstrated the most significant differentiation between samples and were selected for further analysis ( Table 1 ):,,"Add,Fact/Evidence",Fact/Evidence
7895,5-2807,5-2807_v2_22@1,,In this study only nuclear DNA markers were investigated.,,"Add,Fact/Evidence",Fact/Evidence
7896,5-2807,5-2807_v2_22@2,,"Primary restriction site analysis confirmed that no mitochondrial DNA markers were amplified with used enzymes EcoRI, MspI and the applied primer combinations.",,"Add,Fact/Evidence",Fact/Evidence
7897,5-2807,5-2807_v2_2@6,5-2807_v1_2@6,"In the present study, four samples were compared: Persian sturgeons from the South Caspian Sea, Russian sturgeons from the Caspian Sea and the Sea of Azov, and Siberian sturgeons from the Ob’ River, which are close to the latter two species, but are also clearly morphologically and genetically distinct from them.","In the present study, four samples were compared: Persian sturgeons from the South Caspian Sea, Russian sturgeons from the Caspian Sea and the Sea of Azov, and Siberian sturgeons from the Ob’ River, which are close to these two species, but are also clearly morphologically and genetically distinct from them.","Modify,Clarity",Clarity
7898,5-2807,5-2807_v2_2@7,5-2807_v1_2@7,"For the amplified fragment length polymorphism (AFLP) method, eight pairs of selective primers were used.","For the AFLP method, eight pairs of selective primers were used.","Modify,Clarity",Clarity
7899,5-2807,5-2807_v2_2@2,5-2807_v1_2@2,"According to previous studies, ‘baerii-like’ mitochondrial genotypes were found in the Caspian Sea among 35% of Russian sturgeon specimens, but were not found in Persian sturgeons.","According to previous studies, ‘baerii-like’ mitotypes were found in the Caspian Sea among 35% of Russian sturgeon specimens, but were not found in Persian sturgeons.","Modify,Fact/Evidence",Fact/Evidence
7900,5-2807,5-2807_v2_14@2,5-2807_v1_13@2,"Briefly, genomic DNA was incubated with the MspI and EcoRI enzyme combination (Fermentas).","Briefly, genomic DNA was incubated with the MspI and EcoR enzyme combination (Fermentas).","Modify,Fact/Evidence",Fact/Evidence
7901,5-2807,5-2807_v2_14@3,5-2807_v1_13@3,"Next, DNA fragments were ligated with oligonucleotide adapters and used for pre-selective and selective PCR with combinations of fluorescent primers.","Next, DNA fragments were ligated with oligonucleotide adapters and used for pre-selective and selective PCR with eight combinations of fluorescent primers ( Table 1 ):","Modify,Fact/Evidence",Fact/Evidence
7918,5-683,,5-683_v1_39@2,,We also tested whether a Reviewing Editor serving as a reviewer had an effect on the number of rounds of revision before the final decision and found no significant effect (see Table S3 ).,"Delete,Fact/Evidence",Fact/Evidence
7919,5-683,5-683_v2_5@2,,This subset of 2747 papers was then analysed in detail.,,"Add,Fact/Evidence",Fact/Evidence
7920,5-683,5-683_v2_14@1,,"Once the full submission has been received, it is assigned by staff to the Reviewing Editor who agreed to handle it, both as the handling editor, and as one of the reviewers, unless the Reviewing Editor actively decides against serving as a referee.",,"Add,Fact/Evidence",Fact/Evidence
7921,5-683,5-683_v2_14@2,,"A common reason for not serving as one of the referees is workload: for example, a Reviewing Editor already handling two papers as an editor and a reviewer may be less likely to take on a third, unless they can take the third one without providing a review.",,"Add,Claim",Claim
7922,5-683,5-683_v2_14@3,,"Another common reason for not serving as one of the referees is when the paper is outside of the Reviewing Editor’s immediate area of expertise: however, eLife editors are still encouraged to serve as a reviewer in these circumstances as a review from this perspective can be informative in helping to assess a paper’s broad appeal.",,"Add,Claim",Claim
7923,5-683,5-683_v2_14@4,,"We cannot rule out the possibility that some Reviewing Editors self select the most interesting submissions to provide a review themselves, but the journal takes various steps to encourage the practice of providing a review wherever possible: for example, by tracking the trend on a monthly basis, by explaining this expectation when a Reviewing Editor first joins, and by asking for a justification when Reviewing Editors decides against providing a review of his or her own.",,"Add,Claim",Claim
7924,5-683,5-683_v2_18@3,,"This dataset was obtained in collaboration with the editorial staff at eLife , who contributed to and collaborated on this manuscript.",,"Add,Fact/Evidence",Fact/Evidence
7925,5-683,5-683_v2_34@3,,"Additionally, another possibility is that the papers with more reviewers were more technically challenging, and so required more review time to fully examine all the complexity.",,"Add,Claim",Claim
7926,5-683,5-683_v2_42@1,,"In this model, we test whether the dependent variable (the probability that a paper is published by eLife ) is affected by the number of referees reviewing a paper ( Unique_Reviewers ), whether the Reviewing Editor was also serving as a reviewer ( Editor_as_Reviewer ), and the number of days since eLife began accepting papers ( Publication_Since_Start ).",,"Add,Fact/Evidence",Fact/Evidence
7927,5-683,5-683_v2_43@1,,That is to say that the chances of a paper submitted to eLife being accepted have declined over time.,,"Add,Fact/Evidence",Fact/Evidence
7928,5-683,5-683_v2_43@2,,It’s important however to highlight that we cannot say whether this trend reflects changes in eLife’ s acceptance criteria without assuming that the average quality of papers eLife has remained constant.,,"Add,Claim",Claim
7929,5-683,5-683_v2_43@3,,"As the volume of papers processed by eLife has greatly increased over three years, this is a very difficult factor to independently verify - as such, while we report all the analysis and include the full dataset as well as the scripts to reproduce them, we suggest caution when interpreting the results.",,"Add,Claim",Claim
7930,5-683,5-683_v2_48@0,,We take advantage of the ability to upload new manuscript versions to repeat our analysis using updated citation data.,,"Add,Fact/Evidence",Fact/Evidence
7931,5-683,5-683_v2_48@1,,"We report the coefficients calculated using the original citation dataset, obtained on 29th February 2016, as well as using more recent citation data obtained on 11th July.",,"Add,Fact/Evidence",Fact/Evidence
7932,5-683,5-683_v2_48@2,,"The coefficients estimated in both instances have overlapping confidence intervals, but, if we only look at the latest dataset, then the effect of the number of reviewers on citation is statistically significant (although barely; see Table S4 ) and papers with more reviewers tend to gather slightly more citations over time.",,"Add,Fact/Evidence",Fact/Evidence
7933,5-683,5-683_v2_48@5,,"We counsel caution when interpreting these results: the confidence intervals are quite large, and the effect size is small ( Figure 3 , red dots).",,"Add,Fact/Evidence",Fact/Evidence
7934,5-683,5-683_v2_7@0,5-683_v1_7@0,"The Reviewing Editor serving as one of the peer reviewers results in faster decision times on average, with the time to final decision ten days faster for accepted submissions (n=1,405) and five days faster for papers that were rejected after peer review (n=1,099).","The Reviewing Editor serving as one of the peer reviewers results in faster decision times on average, with the time to final decision ten days faster for accepted submissions (n=1,405) and 5 days faster for papers that were rejected after peer review (n=1,099).","Modify,Grammar",Grammar
7935,5-683,5-683_v2_7@1,5-683_v1_7@1,"Moreover, editors acting as reviewers had no effect on whether submissions were accepted or rejected, and a very small (but significant) effect on citation rates.","There was no effect on whether submissions were accepted or rejected, and a very small (but significant) effect on citation rates for published articles where the Reviewing Editor served as one of the peer reviewers.","Modify,Clarity",Clarity
7936,5-683,5-683_v2_35@1,5-683_v1_32@1,The results are shown in Figure 2 and summarised in Table 2 .,The results are shown in Figure 2 and summarized in Table 2 .,"Modify,Grammar",Grammar
7937,5-683,5-683_v2_42@0,5-683_v1_39@0,"To test whether eLife ’s acceptance rate changed over time, we built a logit model including as a predictive variable the number of days since eLife began accepting papers and whether the Reviewing Editor served as one of the reviewers.","To test whether eLife ’s acceptance criteria changed over time, we built a logit model including as a predictive variable the number of days since eLife began accepting papers and whether the Reviewing Editor served as one of the reviewers.","Modify,Clarity",Clarity
7938,5-683,5-683_v2_43@0,5-683_v1_39@1,"The only significant variable in our analysis was the number of days since publication ( Publication_Since_Start) , which had a very small (-0.003) but significant effect (p < 0.02) (see Table S2 ).",The number of days since publication had a very small (–0.003) but significant effect (p < 0.02) while the effect of the Reviewing Editor serving as a reviewer was not significant (see Table S2 ).,"Modify,Fact/Evidence",Fact/Evidence
7939,5-683,5-683_v2_47@0,5-683_v1_43@0,We examined this effect using a generalised linear model.,We examined this effect using a generalized linear model.,"Modify,Grammar",Grammar
7940,5-683,5-683_v2_47@1,5-683_v1_43@1,"As variables, we considered whether the Reviewing Editor served as a reviewer (Editor_As_Reviewer), the total amount of time taken to review the paper (Total_Decision_Time) as well as the number of reviewers examining the paper (Unique_Reviewers).","As variables, we considered whether the Reviewing Editor served as a reviewer (Editor_As_Reviewer, true or false), as well as the number of days between eLife publishing its first manuscript and the day the Scopus database was queried.","Modify,Fact/Evidence",Fact/Evidence
7941,5-683,5-683_v2_48@3,5-683_v1_43@2,The presence of a Reviewing Editor serving as a reviewer had lead to a small increase in citations using both citation datasets (see Table S4 ).,The presence of a Reviewing Editor serving as a reviewer had no significant effect on the number of citations (see Table S4 ).,"Modify,Fact/Evidence",Fact/Evidence
7942,5-683,5-683_v2_53@0,5-683_v1_48@0,"Due to an increasingly competitive funding environment, scientists are under immense pressure to publish in prestigious scientific journals, yet the peer-review process remains relatively opaque at many journals.","Due to an increasingly competitive funding environment, scientists are under immense pressure to publish in scientific journals, yet the peer-review process remains relatively opaque at many journals.","Modify,Claim",Claim
7943,5-683,5-683_v2_56@0,5-683_v1_51@0,"Insofar as the editor serving as a reviewer is concerned, we did not observe any difference in the chances of a paper being accepted or rejected, but we did notice a modest increase in the number of citations that a paper receives when an editor serves as one of the reviewers, although this effect is very small.","Insofar as the editor serving as a reviewer is concerned, we did not observe any difference in the chances of a paper being accepted or rejected, but we did notice a modest increase in the overall number of citations that a paper receives when an editor serves as one of the reviewers, although this effect is very small.","Modify,Clarity",Clarity
7944,5-683,5-683_v2_56@1,5-683_v1_51@1,"An interesting result from our analysis is that a longer peer-review process or more referees does not lead to an increase in citations (note: using the updated citation data, there is an effect which is barely greater than zero – see Table S4 , part 2), so this is another reason for journals and editors to carefully consider the impact of the number of reviewers involved, and to strive to communicate the results presented in a timely manner for others to build upon.","An interesting result from our analysis is that a longer peer-review process or more referees does not lead to an increase in citations, so this is another reason for journals and editors to carefully consider the impact of the number of reviewers involved, and to strive to communicate the results presented in a timely manner for others to build upon.","Modify,Fact/Evidence",Fact/Evidence
7945,5-683,5-683_v2_18@0,5-683_v1_15@0,"We analysed a dataset containing information about 9,589 papers submitted to eLife since June 2012 in an anonymised format.","We analyzed a dataset containing information about 9,589 papers submitted to eLife since June 2012 in an anonymised format.","Modify,Grammar",Grammar
7946,5-683,5-683_v2_19@1,5-683_v1_16@1,"After clean up, our dataset consisted of a total of 8,905 submissions, of which 2747 were sent for peer review.","After clean up, our dataset consisted of a total of 8,905 submissions, of which 2,750 were sent for peer review.","Modify,Fact/Evidence",Fact/Evidence
7947,5-683,5-683_v2_19@2,5-683_v1_16@2,"For the rest of the paper, we focus our analysis on this subset of 2747 papers, of which 1,405 had been accepted, 1,099 had been rejected, and the rest were still under consideration.","For the rest of the paper, we focus our analysis on this subset of 2,750 papers, of which 1,405 had been accepted, 1,099 had been rejected, and the rest were still under consideration.","Modify,Fact/Evidence",Fact/Evidence
7948,5-683,5-683_v2_20@0,5-683_v1_17@0,"Before discussing the results, we introduce a few definitions: the “ eLife Decision Time” is the amount of time taken by eLife from the version of the submission being received until a decision has been reached for a particular round of review.","Before discussing the results, we introduce a few definitions: the “ eLife Decision Time” is the amount of time taken by eLife from that version of the submission being received until a decision has been reached for a particular round of review.","Modify,Clarity",Clarity
7949,5-683,5-683_v2_20@2,5-683_v1_17@2,"The “Total Time” is the time from first submission to acceptance, or amount of time taken for eLife to accept a paper from the moment it was first received for consideration.","The “Total Time” is the time from first submission to acceptance, or amount of time taken for eLife to publish a paper from the moment it was first received for consideration.","Modify,Clarity",Clarity
7950,5-683,5-683_v2_20@5,5-683_v1_17@5,"We distinguish between Reviewing Editors who served as one of the reviewers during the first round of review and Reviewing Editors who did not serve as one of the reviewers (i.e., did not personally try to critically evaluate the scientific content of the article) with the “Editor_As_Reviewer” variable (True or False).","We distinguish between Reviewing Editors who served as one of the reviewers during the first round of review and Reviewing Editors who did not serve as one of the reviewers (i.e., those who undertook more of a supervisory role during the review process) with the “Editor_As_Reviewer” variable (True or False).","Modify,Fact/Evidence",Fact/Evidence
7951,5-683,5-683_v2_5@1,5-683_v1_5@1,"We analysed a dataset of 8,905 research submissions to eLife since June 2012, of which 2,747 were sent for peer review.","We analysed a dataset of 8,905 research submissions to eLife since June 2012, of which 2,750 were sent for peer review, using R and Python to perform the statistical analysis.","Modify,Fact/Evidence",Fact/Evidence
7952,5-683,5-683_v2_24@0,5-683_v1_21@0,The example submission from Table 1 was received as an “initial submission” (MS TYPE 5) on 20th June 2012.,The example submission from Table 1 was received as an “initial submission” (MS TYPE 5) on 20 June 2012.,"Modify,Grammar",Grammar
7953,5-683,5-683_v2_24@2,5-683_v1_21@2,"The full submission was received on 27th June 2012, when the Reviewing Editor was assigned and reviewers were contacted.","The full submission was received on 27 June 2012, when the Reviewing Editor was assigned and reviewers were contacted.","Modify,Grammar",Grammar
7954,5-683,5-683_v2_25@0,5-683_v1_22@0,"On 25th July (28 days later), the Reviewing Editor sent out a decision asking for revisions to the authors, who submitted their revised manuscript on 5th September.","On 25 July (28 days later), the Reviewing Editor sent out a decision asking for revisions to the authors, who submitted their revised manuscript on 5 September.","Modify,Grammar",Grammar
7955,5-683,5-683_v2_25@3,5-683_v1_22@3,Total Time refers only to the total time across all rounds and revisions for each paper - and therefore does not vary across rounds.,Total Time refers only to the total time across all rounds and revisions for each paper - and does not vary across rounds.,"Modify,Clarity",Clarity
7956,5-758,,5-758_v1_29@1,,All 19 courses prescribed had at least one additional nephrotoxic agent prescribed during CDV therapy ( Table 2 ).,"Delete,Fact/Evidence",Fact/Evidence
7957,5-758,,5-758_v1_29@2,,"Four courses (21%) had only one additional nephrotoxic medication prescribed, five courses (26%) had two such medications prescribed, six courses (32%) had three prescribed, two courses (11%) had four prescribed, and two courses (11%) had five prescribed.","Delete,Fact/Evidence",Fact/Evidence
7958,5-758,,5-758_v1_32@4,,There was no statistically significant difference when assessing for increased risk of renal dysfunction if patients received ≤ 1 additional nephrotoxic agent or ≥ 2 additional nephrotoxic agents.,"Delete,Fact/Evidence",Fact/Evidence
7959,5-758,,5-758_v1_42@3,,We were unable to detect any increased risk of nephrotoxicity associated with concomitant administration of additional nephrotoxic agents but this may reflect our small number of study participants.,"Delete,Fact/Evidence",Fact/Evidence
7960,5-758,5-758_v2_11@1,,"Depending on the clinical context, testing for adenoviruses was typically only performed in symptomatic patients, except in the case of stem cell transplant recipients who had a known history of adenovirus infection prior to transplant in which case adenovirus screening was performed routinely.",,"Add,Fact/Evidence",Fact/Evidence
7961,5-758,5-758_v2_11@6,,"Of note, all patients who received cidofovir also received probenecid for renal protection at a standard dose of 1.25g/m 2 /dose administered 3 hours prior to and 2 hours and 8 hours after completion of each 1-hour CDV infusion.",,"Add,Fact/Evidence",Fact/Evidence
7962,5-758,5-758_v2_11@7,,We performed a search of relevant literature up till December 2010.,,"Add,Fact/Evidence",Fact/Evidence
7963,5-758,5-758_v2_11@8,,"The literature search was conducted using PubMed, PubMed Central and Medline databases.",,"Add,Fact/Evidence",Fact/Evidence
7964,5-758,5-758_v2_11@9,,"Search terms included “treatment of adenoviral infection”, “pediatric”, “adenovirus” “lung transplant”, “liver transplant”, “multi-visceral transplant”, “kidney transplant”, “stem cell transplant”, “immunocompromised”, “nephrotoxic”, “ribavirin”, “ganciclovir” and “vidarabine”.",,"Add,Fact/Evidence",Fact/Evidence
7965,5-758,5-758_v2_11@10,,"As we found larger case series pertaining to use of cidofovir in stem cell transplant recipients, we excluded case reports in this population.",,"Add,Fact/Evidence",Fact/Evidence
7966,5-758,5-758_v2_11@11,,"However, given the paucity of data in solid organ transplant recipients, we included case reports.",,"Add,Fact/Evidence",Fact/Evidence
7967,5-758,5-758_v2_17@1,,Baseline creatinine was defined as the most recent serum creatinine value prior to initiation of CDV therapy.,,"Add,Fact/Evidence",Fact/Evidence
7968,5-758,,5-758_v1_16@5,,The peak SCr during therapy was used to calculate the number of patients that experienced renal dysfunction.,"Delete,Fact/Evidence",Fact/Evidence
7969,5-758,5-758_v2_39@5,,"Interestingly, a prospective study performed in adult liver, kidney and heart transplant recipients noted the transient nature of adenoviremia and self limited infection in this population even in the absence of any treatment or interventions <REF-28> .",,"Add,Fact/Evidence",Fact/Evidence
7970,5-758,5-758_v2_39@6,,"However, the authors also note that the majority of patients in whom adenoviremia was detected in their study were asymptomatic or only mildly symptomatic, and thus differed from patients with severe infections who are more frequently reported in the pediatric transplant population and in lung allograft recipients.",,"Add,Fact/Evidence",Fact/Evidence
7971,5-758,5-758_v2_39@7,,"In contrast, Seidemann and colleagues <REF-29> report mortality in 2 of 5 pediatric solid organ transplant recipients despite the use of cidofovir in their case series.",,"Add,Fact/Evidence",Fact/Evidence
7972,5-758,5-758_v2_39@8,,"Similarly, Leurez-Ville et al. <REF-30> report mortality in 1 of 3 pediatric solid organ transplant recipients with disseminated adenovirus infection.",,"Add,Fact/Evidence",Fact/Evidence
7973,5-758,5-758_v2_39@9,,The patients who expired in both these reports had severe symptoms and ultimately died of septic multiorgan failure.,,"Add,Fact/Evidence",Fact/Evidence
7974,5-758,5-758_v2_39@10,,"With the exception of a lung transplant recipient, all other solid organ transplant recipients with adenovirus infection in our study were more than mildly symptomatic.",,"Add,Fact/Evidence",Fact/Evidence
7975,5-758,5-758_v2_39@11,,"While other reports suggest the possibility of self-resolution of adenoviremia and absence of significant clinical sequelae in asymptomatic or mildly symptomatic solid organ transplant recipients, the propensity for serious infections and mortality has also been highlighted in the pediatric specific solid organ transplant literature <REF-29> , <REF-30> .",,"Add,Fact/Evidence",Fact/Evidence
7976,5-758,5-758_v2_40@5,,It is hence difficult to conclude from these data whether or not cidofovir provided any clinical benefit.,,"Add,Claim",Claim
7977,5-758,5-758_v2_40@6,,It should also be noted that two patients in our series received cidofovir despite being asymptomatic.,,"Add,Fact/Evidence",Fact/Evidence
7978,5-758,5-758_v2_40@7,,"One such patient was a lung transplant recipient in whom adenovirus was detected in both blood and BAL fluid, the other was a stem cell transplant recipient with a prior history of recurrent viremia and pneumonia.",,"Add,Fact/Evidence",Fact/Evidence
7979,5-758,5-758_v2_40@8,,Both these patients were considered to be at high risk for complications from adenovirus infection thus leading to the decision to use cidofovir.,,"Add,Fact/Evidence",Fact/Evidence
7980,5-758,5-758_v2_41@3,,"Finally, brincidofovir (CMX001), an orally administered lipid -conjugate derivative of cidofovir is currently being investigated in clinical trials and is reported to have no nephrotoxicity <REF-31> .",,"Add,Fact/Evidence",Fact/Evidence
7981,5-758,5-758_v2_26@2,5-758_v1_25@2,"Respiratory symptoms were the most common presentation (10 courses, 53%) of which six courses were prescribed for patients with respiratory symptoms and radiological evidence of pneumonia.",Respiratory symptoms were the most common presentation in 10 courses (53%) of which six courses were prescribed for patients with respiratory symptoms and radiological evidence of pneumonia.,"Modify,Grammar",Grammar
7982,5-758,5-758_v2_26@4,5-758_v1_25@4,One course was prescribed in a patient with asymptomatic respiratory tract infection and one course was prescribed in another patient with asymptomatic gastrointestinal infection.,Two courses were prescribed in patients with asymptomatic respiratory tract infection and asymptomatic gastrointestinal infection respectively.,"Modify,Clarity",Clarity
7983,5-758,5-758_v2_27@4,5-758_v1_26@4,"The majority of adenovirus blood-positive CDV courses (10/16, 63%) were associated with clinical improvement with viral clearance; however this was not the case in four courses.","The majority of adenovirus blood-positive CDV courses (10/16, 63%) were associated with clinical improvement with viral clearance, however this was not the case in four courses.","Modify,Grammar",Grammar
7984,5-758,5-758_v2_30@0,5-758_v1_29@0,Each patient’s medication profile was assessed to determine the number of additional nephrotoxic agents concomitantly prescribed during CDV therapy (from Day 1 to 7 days post last CDV dose) ( Table 2 ).,Each patient’s medication profile was assessed to determine the number of additional nephrotoxic agents concomitantly prescribed during CDV therapy (from Day 1 to 7 days post last CDV dose).,"Modify,Fact/Evidence",Fact/Evidence
7985,5-758,5-758_v2_8@4,5-758_v1_8@4,This associated adverse effect has limited the use of CDV for treatment of ADV infections in pediatric patients.,These associated adverse effects have limited the use of CDV for treatment of ADV infections in pediatric patients.,"Modify,Grammar",Grammar
7986,5-758,5-758_v2_39@0,5-758_v1_40@0,"There are very few reports on the use of CDV for adenovirus infection in pediatric SOT recipients, which have largely been restricted to reports of children receiving liver or lung transplants <REF-16> , <REF-20> , <REF-24> , <REF-25> , <REF-29> , <REF-30> .","There are very few reports on the use of CDV for adenovirus infection in pediatric SOT recipients, which have largely been restricted to reports of children receiving liver or lung transplants <REF-16> , <REF-20> , <REF-24> , <REF-25> .","Modify,Fact/Evidence",Fact/Evidence
7987,5-758,5-758_v2_39@1,5-758_v1_40@1,"We identified six publications reporting the use of CDV for adenovirus infection in pediatric SOT recipients limited to one to four per report with the majority of these children having received liver or lung transplants <REF-16> , <REF-20> , <REF-24> , <REF-25> , <REF-29> , <REF-30> .","We identified four publications reporting the use of CDV for adenovirus infection in pediatric SOT recipients limited to one to four per report and all of these children having received liver or lung transplants <REF-16> , <REF-20> , <REF-24> , <REF-25> .","Modify,Fact/Evidence",Fact/Evidence
7988,5-758,5-758_v2_8@5,5-758_v1_8@5,"To minimize potential toxicity of CDV, modified dosing regimens such as the use of 1 mg/kg three times weekly have been utilized <REF-14> .","To minimize potential toxicity of CDV, modified dosing regimens such as the use of 1 mg/kg three times have been utilized <REF-14> .","Modify,Fact/Evidence",Fact/Evidence
7989,5-758,5-758_v2_40@1,5-758_v1_41@1,"However, one-third died all of whom were stem cell transplant recipients.","However, one-third died all of which were stem cell transplant recipients.","Modify,Grammar",Grammar
7990,5-758,5-758_v2_11@2,5-758_v1_11@1,"The following data were collected: (1) demographic information, (2) underlying disease state, (3) type of transplant, (4) duration of cidofovir therapy, (6) serum creatinine (SCr) (baseline, peak during therapy, and level up to 2 weeks post last dose), (7) concomitant nephrotoxins prescribed (acyclovir, amikacin, cyclosporine, foscarnet, gentamicin, liposomal amphotericin B, tacrolimus, tobramycin, vancomycin, and intravenous contrast media), (8) sites of ADV detection by viral direct fluorescent antibody (DFA), nucleic acid test, and/or culture, (9) viral quantitative PCR surveillance in whole blood and other sites of infection (all specimens were tested at least weekly before, during and to two weeks post last dose of CDV to evaluate for changes in viral load with a minimum three serial values being obtained before, during and at end of therapy); (10) symptoms of infection, and clinical course including response to therapy, (11) concomitant reduction of immunosuppression and (12) mortality and cause(s) of mortality.","The following data were collected: (1) demographic information, (2) underlying disease state, (3) type of transplant, (4) duration of cidofovir therapy, (6) serum creatinine (SCr) (baseline, peak during therapy, and level up to 2 weeks post last dose), (7) concomitant nephrotoxins prescribed (acyclovir, amikacin, cyclosporine, foscarnet, gentamicin, liposomal amphotericin B, tacrolimus, tobramycin, vancomycin, and intravenous contrast media), (8) sites of ADV detection by viral direct fluorescent antibody (DFA), nucleic acid test, and/or culture, (9) viral quantitative PCR surveillance in blood and other sites of infection (all specimens were tested at least weekly before, during and to two weeks post last dose of CDV to evaluate for changes in viral load with a minimum three serial values being obtained before, during and at end of therapy); (10) symptoms of infection, and clinical course including response to therapy, (11) concomitant reduction of immunosuppression and (12) mortality and cause(s) of mortality.","Modify,Clarity",Clarity
7991,5-758,5-758_v2_11@3,5-758_v1_11@2,"All blood sample testing for adenovirus quantitative PCR in whole blood was performed at the Boston Children’s Hospital Virology Laboratory using our laboratory developed test, using components of the Argene adenovirus kit (bioMerieux, Cambridge, MA).","All blood sample testing for adenovirus quantitative PCR in blood was performed at the Boston Children’s Hospital Virology Laboratory using our laboratory developed test, the Argene adenovirus assay (bioMerieux, Cambridge, MA).","Modify,Clarity",Clarity
7992,5-758,5-758_v2_11@4,5-758_v1_11@3,The Argene adenovirus kit contains primers and probes selective for a 138 base pair (bp) sequence in the Hexon gene of the adenovirus.,The Argene adenovirus assay contains primers and probes selective for a 138 base pair (bp) sequence in the Hexon gene of the adenovirus.,"Modify,Clarity",Clarity
7993,5-758,5-758_v2_11@5,5-758_v1_11@4,"Using a 5’ nuclease assay, viral DNA is detected using the primers and fluorescent probes from the Argene kit by means of real time PCR in a Cepheid SmartCycler (Cepheid, Sunnyvale, CA).","Using a 5’ nuclease assay, viral DNA is detected using the primers and fluorescent probes from the Argene assay kit by means of real time PCR in a Cepheid SmartCycler (Cepheid, Sunnyvale, CA).","Modify,Clarity",Clarity
7994,5-758,5-758_v2_16@2,5-758_v1_16@2,Viral response was defined as decrease in viremia by at least one log-reduction (i.e 10-fold).,Viral response was defined as decrease in viremia by at least one log-fold.,"Modify,Fact/Evidence",Fact/Evidence
7995,6-125,6-125_v2_10@7,,Three replications were maintained in the field at a dimention of 2.4 × 7.0m plot size in split-split plot experimental design.,,"Add,Fact/Evidence",Fact/Evidence
7996,6-125,6-125_v2_19@3,,A significant increase in the total root length observed in 0.8 m lateral distance (LD) laid at 5–10 cm depth subsurface drip irrigation treatment (66.6m/hill).,,"Add,Fact/Evidence",Fact/Evidence
7997,6-125,6-125_v2_24@2,,The 0.8 m lateral distance in SDI laid out at 5–10 cm soil depth improved the root volume of JKRH 3333 rice with greater significance ( Table 1a ).,,"Add,Fact/Evidence",Fact/Evidence
7998,6-125,6-125_v2_25@4,,"Comparing the treatment interactions, solar operated drip system (0.8 m LD laid out at 5–10 cm SDI) treatment significantly improve the root density in JKRH 3333(RLD: 2.36, RMD: 1.59) over the control ( Table 2a .)( Figure 2 .).",,"Add,Fact/Evidence",Fact/Evidence
7999,6-125,6-125_v2_25@6,,The drip treatment 0.8 m LD + 5–10 cm depth SDI showed significant increment in root dry weight by comparing the genotypes and on par by comparing the irrigation sources ( Table 2a .).,,"Add,Fact/Evidence",Fact/Evidence
8000,6-125,6-125_v2_25@8,,The specific root length was superior in solar operated drip irrigation system (i.e. 0.8 m LD laid out at 5–10 cm depth SDI) than the well-operated drip irrigation system.,,"Add,Fact/Evidence",Fact/Evidence
8001,6-125,6-125_v2_35@2,,Solar operated drip system (0.8 m LD in SDI laid out at 5–10 cm) showed significant enhancement of filled grain percentage in JKRH 3333 rice genotype ( Table 3a .).,,"Add,Fact/Evidence",Fact/Evidence
8002,6-125,6-125_v2_40@3,,"The 0.8 m LD in SDI laid out at 5–10 cm depth with the solar operated irrigation system, raise the rice grain yield in JKRH 3333 genotype (6177 kg/ha) over the control.",,"Add,Fact/Evidence",Fact/Evidence
8003,6-125,6-125_v2_49@2,,"Also, the drip fertigation at 5–10 cm soil depth favourably altered the root density.",,"Add,Fact/Evidence",Fact/Evidence
8004,6-125,6-125_v2_49@3,,A similar increase in density was verified by Sharda et al. (2017) in drip irrigated dry seeded rice with nitrogen fertigation.,,"Add,Fact/Evidence",Fact/Evidence
8005,6-125,6-125_v2_55@2,,"The 0.8 m LD in SDI treatment laid at 5–10 cm depth with solar operated drip system attained 36.7% , 36.0% and 19.0% higher grain yield in JKRH 3333, TNRH 180 and ADT(R)45 respectively over the control.",,"Add,Fact/Evidence",Fact/Evidence
8006,6-125,6-125_v2_57@3,,"Comparing the two irrigation sources, solar-powered drip favors the rice root density.",,"Add,Fact/Evidence",Fact/Evidence
8007,6-125,6-125_v2_57@5,,The drip irrigation treatment 0.8 m lateral distance in subsurface drip irrigation (SDI) laid out at 5–10 cm soil depth with solar irrigation system improved the rice grain yield by 19–37% over the conventional aerobic rice.,,"Add,Fact/Evidence",Fact/Evidence
8008,6-125,6-125_v2_2@6,6-125_v1_2@7,The 0.8m lateral distance laid out at 5-10cm depth SDI with solar system proliferated more roots at subsurface soil layer with significant yield increment in rice.,The 0.8m lateral distance laid out at 5-10cm depth SDI proliferated more roots at subsurface soil layer with significant yield increment in rice.,"Modify,Fact/Evidence",Fact/Evidence
8009,6-125,6-125_v2_34@0,6-125_v1_30@0,The root ATPase activity of JKRH 3333 (33.1µg Pi/g/h) showed was more statistically significant supremacy than TNRH 180 (29.5µg Pi/g/h) and ADT(R)45 (23.8µg Pi/g/h) (Table 2b.).,The root ATPase activity of JKRH 3333 (33.1µg Pi/g/h) showed was more statistically significant supremacy than TNRH 180 (29.5µg Pi/g/h) and ADT(R)45 (23.8µg Pi/g/h).,"Modify,Fact/Evidence",Fact/Evidence
8010,6-125,6-125_v2_40@2,6-125_v1_32@2,"Among the performance of genotypes under drip irrigated aerobic rice, JKRH 3333 was statistical superior in mean grain yield (4831kg/ha) ( Table 3b ) followed by TNRH 180 (4639kg/ha) and ADT(R)45 (4224kg/ha).","Among the performance of genotypes under drip irrigated aerobic rice, JKRH 3333 was statistical superior in mean grain yield (4831kg/ha) followed by TNRH 180 (4639kg/ha) and ADT(R)45 (4224kg/ha).","Modify,Fact/Evidence",Fact/Evidence
8011,6-125,6-125_v2_43@1,6-125_v1_39@1,"Fageria (2007) observed that root length followed a significant quadratic response with the advancement of plant age from 19 to 110 days after sowing, and shows a linear increase in root length during flowering.","Fageria (2007) observed that root length followed a significant quadratic response with the advancement of plant age from 19 to 120 days after sowing, and shows a linear increase in root length during flowering.","Modify,Fact/Evidence",Fact/Evidence
8012,6-125,6-125_v2_48@0,6-125_v1_44@0,"Root volume of plants covers huge soil volumes and water uptake from the soil in water-limited conditions ( Kanbar et al. , 2004 ).","Root volume of plants covers huge soil volumes and water uptake from the soil in water-limited conditions (Kanbar, 2004).","Modify,Fact/Evidence",Fact/Evidence
8013,6-125,6-125_v2_49@1,6-125_v1_45@1,"In the present experiment, the SDI at 5–10cm depth using JKRH 3333 increased the RLD and RMD, due to the root zone of rice exposed to frequent wetting and slight drying and nutrient accessibility ( Figure 1 .).","In the present experiment, the SDI at 5–10cm depth using JKRH 3333 increased the RLD and RMD, due to the root zone of rice exposed to frequent wetting and slight drying and nutrient accessibility.","Modify,Fact/Evidence",Fact/Evidence
8014,6-125,6-125_v2_5@0,6-125_v1_5@0,"A deeper root system of rice eases water stress and improves the uptake of nutrients and water in deep soil layers ( Lilley & Fukai, 1994 ).","A deeper root system of rice eases water stress and improves the uptake of nutrients and water in deep soil layers (Lilley et al. , 1994).","Modify,Fact/Evidence",Fact/Evidence
8015,6-125,6-125_v2_57@1,6-125_v1_53@1,"Based on the data of lateral spacing, lateral depth and the root characters of rice under drip significantly showed that there was characteristic flexibility in the roots of the rice plant.","Based on the data of lateral spacing, discharge variations and the root characters of rice under drip significantly showed that there was characteristic flexibility in the roots of the rice plant.","Modify,Fact/Evidence",Fact/Evidence
8016,6-125,6-125_v2_63@0,6-125_v1_59@0,"Drip treatments: T 1 , 0.8m LD+5–10cm; T 2 , 0.8m LD+5–10cm; T 3 , 1.2m LD+5–10cm; T 4 , 1.2m LD+15–20cm; T 5 , conventional aerobic rice.","Drip treatments: T 1 , 0.8m LD; T 2 , 1.2m LD; T 3 , 5–10cm; T 4 , 15–20cm; T 5 , conventional aerobic rice.","Modify,Fact/Evidence",Fact/Evidence
8017,6-125,6-125_v2_10@0,6-125_v1_10@0,"A root phenotyping experiment was conducted during the summer season of 2013 and 2014 at Tamil Nadu Agricultural University (Coimbatore, Tamil Nadu, India).","A root phenotyping experiment was conducted during the summer season of 2013 and 2014, using JKRH 3333, TNRH 180 and ADT(R)45 as the test rice varieties at Tamil Nadu Agricultural University (Coimbatore, Tamil Nadu, India).","Modify,Fact/Evidence",Fact/Evidence
8018,6-125,6-125_v2_10@3,6-125_v1_10@3,"Solar powered and well-operated drip irrigation sources as main plot treatments (S: Source), test varieties JKRH 3333, TNRH 180 and ADT(R)45 were sown in subplots (V: Variety), drip treatments such as 0.8 and 1.2m lateral distances, 5–10 and 15–20cm depth sub-surface drip (SDI) and conventional aerobic treatments were adopted as sub-sub plots (T: Treatment) at field level.","Solar powered and well-operated drip irrigation sources, 0.8 and 1.2m lateral distances, 5–10 and 15–20cm depth sub-surface drip (SDI) were the treatments adopted at field level.","Modify,Fact/Evidence",Fact/Evidence
8019,6-125,6-125_v2_10@8,6-125_v1_10@7,"Further information on genotypes, experimental set up, fertigation schedule, drip layout and drip components are given in Supplementary File 1 and Supplementary File 2 .","Further information on genotypes, experimental set up and fertigation schedule are given in Supplementary File 1 .","Modify,Fact/Evidence",Fact/Evidence
8020,6-125,6-125_v2_2@2,6-125_v1_2@3,"Two lateral spacing levels (0.8 and 1.2m), laid at two depths of sub surface irrigation (5-10 and 15-20 cm) by solar powered and well operated irrigation were tested using TNRH 180, JKRH 3333 and ADT(R)45 rice genotypes during the summer season (2013 & 2014) in Coimbatore, India.","Two lateral spacing levels (0.8 and 1.2m), two depths of irrigation (5-10 and 15-20 cm) by solar powered and well operated irrigation were tested using TNRH 180, JKRH 3333 and ADT(R)45 rice genotypes during the summer season (2013 & 2014) in Coimbatore, India.","Modify,Fact/Evidence",Fact/Evidence
8021,6-125,6-125_v2_24@1,6-125_v1_20@1,"From the main plot treatment, the solar drip irrigation recorded an increased root volume of 43.4% compared with the well-operated drip irrigation treatment ( Table 1b .).","From the main plot treatment, the solar drip irrigation recorded an increased root volume of 43.4% compared with the well-operated drip irrigation treatment.","Modify,Fact/Evidence",Fact/Evidence
8047,6-1600,6-1600_v2_47@4,,Circulating glucagon levels were also similar between L-DKO mice and controls both at 10 weeks of age and 24 weeks of age ( Figure 4H ).,,"Add,Fact/Evidence",Fact/Evidence
8048,6-1600,6-1600_v2_23@7,6-1600_v1_23@7,Membranes were washed 2×5 min and 1×15 min in PBS with 0.1% Tween and then incubated with the secondary antibody for 1h followed by another washing procedure.,Membranes were washed 2x5 min and 1x15 min in PBS with 0.1% Tween and then incubated with the secondary antibody for 1h followed by another washing procedure.,"Modify,Grammar",Grammar
8049,6-1600,6-1600_v2_25@0,6-1600_v1_25@0,"IRS1 (RRID:AB_2127860, rabbit monoclonal, 1:50, Cell Signaling Technology Inc, cat# 3407 for western blot), IRS1 (RRID:AB_631842, rabbit polyclonal, 10μl per reaction, Santa Cruz Biotechnology Inc, cat# sc-559 for immunoprecipitation), p110α (rabbit monoclonal, 1:1000 for western blot and 1:50 for immunoprecipitation, Cell Signaling Technology Inc, cat# 4249), p110β (RRID:AB_2165246, rabbit monoclonal, 1:500 for western blot and 1:50 for immunoprecipitation, Cell Signaling Technology Inc, cat# 3011), p110γ (RRID:AB_10828316, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 5405), p110δ (mouse monoclonal, 1:500, Becton, Dickinson and Company, cat# 611015), p101 (RRID:AB_10829448, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 5569), Vps34 (RRID:AB_2299765, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4263), p150 (rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 14580), Akt/PKB (RRID:AB_329827, rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 9272), pS-Akt/PKB (RRID:AB_329825, rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 9271), pT-Akt/PKB (RRID:AB_2255933, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 2965), pT-p70S6K (RRID:AB_330944, rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 9205), p70S6K (rabbit polyclonal, 1:500, Cell Signaling Technology Inc, cat# 9202), p85α (RRID:AB_2268174, rabbit monoclonal, 1:1000, Abcam, cat# 22653), p85-pan (RRID:AB_10831521, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4257), pT202/Y204-ERK (RRID:AB_2315112, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4370), ERK (RRID:AB_390779, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4695), p55γ (mouse monoclonal, 1:2000, Abcam, cat# ab186612), PIK3C2α (rabbit polyclonal, 1:1000, MyBiosource, cat# MBS9202698), PIK3C2γ (rabbit polyclonal, 1:1000, MyBiosource, cat# MBS820611).","IRS1 (RRID:AB_2127860, rabbit monoclonal, 1:50, Cell Signaling Technology Inc, cat# 3407 for western blot), IRS1 (RRID:AB_631842, rabbit polyclonal, 10μl per reaction, Santa Cruz Biotechnology Inc, cat# sc-559 for immunoprecipitation), p110α (rabbit monoclonal, 1:1000 for western blot and 1:50 for immunoprecipitation, Cell Signaling Technology Inc, cat# 4249), p110β (RRID:AB_2165246, rabbit monoclonal, 1:500 for western blot and 1:50 for immunoprecipitation, Cell Signaling Technology Inc, cat# 3011), p110γ (RRID:AB_10828316, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 5405), p110δ (mouse monoclonal, 1:500, Becton, Dickinson and Company, cat# 611015), p101 (RRID:AB_10829448, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 5569), Vps34 (RRID:AB_2299765, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4263), p150 (rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 14580), Akt/PKB (RRID:AB_329827, rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 9272), pS-Akt/PKB (RRID:AB_329825, rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 9271), pT-Akt/PKB (RRID:AB_2255933, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 2965), pT-p70S6K (RRID:AB_330944, rabbit polyclonal, 1:1000, Cell Signaling Technology Inc, cat# 9205), p85α (RRID:AB_2268174, rabbit monoclonal, 1:1000, Abcam, cat# 22653), p85-pan (RRID:AB_10831521, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4257), pT202/Y204-ERK (RRID:AB_2315112, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4370), ERK (RRID:AB_390779, rabbit monoclonal, 1:1000, Cell Signaling Technology Inc, cat# 4695), p55γ (mouse monoclonal, 1:2000, Abcam, cat# ab186612), PIK3C2α (rabbit polyclonal, 1:1000, MyBiosource, cat# MBS9202698), PIK3C2γ (rabbit polyclonal, 1:1000, MyBiosource, cat# MBS820611).","Modify,Fact/Evidence",Fact/Evidence
8050,6-1600,6-1600_v2_32@1,6-1600_v1_32@1,"Deletion of Pik3ca and Pik3r1 in the liver resulted in markedly reduced gene and protein expression of p110α and p85α ( Figures 1A, 1C, 1E ), as well as impaired activation of the downstream targets Akt/PKB, with decreased phosphorylation of serine 473 and threonine 308, and p70S6 kinase ( Figure 1F–I ).","Deletion of Pik3ca and Pik3r1 in the liver resulted in markedly reduced gene and protein expression of p110α and p85α ( Figures 1A, 1C, 1E ), as well as impaired activation of the downstream targets Akt/PKB, with decreased phosphorylation of serine 473 and threonine 308, and p70S6 kinase ( Figure 1F ).","Modify,Fact/Evidence",Fact/Evidence
8051,6-1600,6-1600_v2_35@2,6-1600_v1_35@2,"However, only very low levels of p85β protein were detected in the liver of the L-DKO mice, as shown both in assessment of total p85 protein ( Figure 1E ) and in p85 immunoprecipitates with IRS1 ( Figure 1K and 1O ), similar to what we have reported earlier in liver-specific p85α knock-out mice <REF-14> .","However, only very low levels of p85β protein were detected in the liver of the L-DKO mice, as shown both in assessment of total p85 protein ( Figure 1E ) and in p85 immunoprecipitates with IRS1 ( Figure 1G ).","Modify,Fact/Evidence",Fact/Evidence
8052,6-1600,6-1600_v2_67@0,6-1600_v1_67@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2018 Chaudhari A et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2017 Chaudhari A et al.,"Modify,Fact/Evidence",Fact/Evidence
8053,6-1600,6-1600_v2_17@3,6-1600_v1_17@3,"Insulin and glucagon was measured with ELISA (Crystal Chem Inc., Downer Grover, IL).","Insulin was measured with ELISA (Crystal Chem Inc., Downer Grover, IL).","Modify,Fact/Evidence",Fact/Evidence
8054,6-1750,6-1750_v2_7@10,,"Assembly of the high quality reads was performed using PLATANUS v1.2.4 ( Kajitani et al. , 2014 ) and SSPACE v3.0 ( Boetzer et al. , 2011 ) with default parameter.",,"Add,Fact/Evidence",Fact/Evidence
8055,6-1750,6-1750_v2_7@14,,"The protein-coding genes were annotated by using BLAST based approach against a database containing functional plant genes downloaded from NCBI with Blast2GO (version 4.01) ( Conesa & Gotz, 2008 ).",,"Add,Fact/Evidence",Fact/Evidence
8056,6-1750,6-1750_v2_7@15,,Genes with significant hits were assigned with GO (Gene Ontology) terms and EC (Enzyme Commission) numbers.,,"Add,Fact/Evidence",Fact/Evidence
8057,6-1750,6-1750_v2_7@16,,InterProScan search and pathway analyses with KEGG database were also performed by using Blast2GO.,,"Add,Fact/Evidence",Fact/Evidence
8058,6-1750,,6-1750_v1_7@12,,"The InterProScan results were further parsed for additional functional evidence (GO terms and KEGG pathway) using interproscanParser script available at iPlant ( Brozynska et al., 2016 ).","Delete,Fact/Evidence",Fact/Evidence
8059,6-1750,6-1750_v2_4@2,6-1750_v1_4@2,Wild species are a potential source of many useful genes and QTLs that may not be present in the primary gene pool of the domesticated species.,Wild species are a potential source of many useful genes and QTLs that may not be present in the gene pool of the domesticated species.,"Modify,Clarity",Clarity
8060,6-1750,6-1750_v2_5@3,6-1750_v1_5@3,"However, with the exception of one transcriptomic ( Garg et al. , 2014 ) and one miRNA ( Mondal et al. , 2015 ) experiment, no large scale generation of any other genomic resource is available for this important species, although several pinitol biosynthesis pathway genes have been cloned to study the functional genomics ( Sengupta & Majumder, 2009 ).","However, with the exception of one transcriptomic ( Garg et al. , 2014 ) and one miRNA (Mondal et al. , 2014) experiment, no large scale generation of any other genomic resource is available for this important species, although several pinitol biosynthesis pathway genes have been cloned to study the functional genomics ( Sengupta & Majumder, 2009 ).","Modify,Fact/Evidence",Fact/Evidence
8061,6-1750,6-1750_v2_2@0,6-1750_v1_2@0,"Oryza coarctata plant, collected from Sundarban delta of West Bengal, India, has been used in the present study to generate draft genome sequences, employing the hybrid genome assembly with Illumina reads and third generation Oxford Nanopore sequencing technology.","Oryza coarctata plants, collected from Sundarban delta of West Bengal, India, have been used in the present study to generate draft genome sequences, employing the hybrid genome assembly with Illumina reads and third generation Oxford Nanopore sequencing technology.","Modify,Grammar",Grammar
8062,6-1750,6-1750_v2_7@0,6-1750_v1_7@0,"The plant was collected from its native place, Sundarban delta of West Bengal, India (21°.36'N and 88°.15' E) and established at our institute Net house through clonal propagation.","The plants were collected from its native place, Sundarban delta of West Bengal, India (21º.36'N and 88º.15' E) and established to our institute NET house.","Modify,Fact/Evidence",Fact/Evidence
8063,6-1750,6-1750_v2_7@4,6-1750_v1_7@4,"Further, high-quality genomic DNA from 100 mg young leaf of a single plant was extracted using CTAB method ( Ganie et al. , 2016 ) for the preparation of various genomic DNA libraries.","Further, high-quality genomic DNA from 100 mg young leaf was extracted using CTAB method ( Ganie et al. , 2016 ) for the preparation of various genomic DNA libraries.","Modify,Fact/Evidence",Fact/Evidence
8064,6-1750,6-1750_v2_7@5,6-1750_v1_7@5,"We used standard Illumina HiSeq 4000 platform (San Diego, CA, USA) to construct 151-bp paired-end libraries and four mate-pair libraries of four different sizes (average of 2, 4, 6 and 8 kb size).","We used Illumina 4000 GA IIx sequencer (San Diego, CA, USA), with 150-bp paired-end libraries, four mate-pair library (with 150-bp paired-end libraries) of four different sizes (average of 2, 4, 6 and 10 kb size).","Modify,Fact/Evidence",Fact/Evidence
8065,6-1750,6-1750_v2_7@12,6-1750_v1_7@11,"Gene model prediction was done by ab initio gene predictor AUGUSTUS 3.1 ( Stanke & Waak, 2003 ) and sequence evidence based annotation pipeline, MAKER v2.31.8 ( Campbell et al. , 2014 ) with O. sativa ssp.","Gene model prediction was done by AUGUSTUS 3.1 ( Stanke & Waak, 2003 ) and genes were functionally analysed using InterProScan version 5.16.55 (Jones et al. , 2014).","Modify,Fact/Evidence",Fact/Evidence
8066,6-1750,6-1750_v2_7@17,6-1750_v1_7@13,"Non-coding RNAs, such as miRNA, tRNA, rRNA, snoRNA, snRNA, were identified by adopting Infernal v1.1.2 ( Nawrocki & Eddy, 2013 ) using Rfam database (release 9.1) ( Nawrocki et al. , 2015 ) and snoscan distribution.","Noncoding RNAs, such as miRNA, tRNA, rRNA, snoRNA, snRNA, were identified by adopting Infernal v1.1.2 ( Nawrocki & Eddy, 2013 ) using Rfam ( Nawrocki et al. , 2015 ).","Modify,Fact/Evidence",Fact/Evidence
8067,6-1750,6-1750_v2_7@18,6-1750_v1_7@14,"Transfer RNA was predicted using tRNAscan-SE v 1.23 ( Lowe & Eddy, 1997 )","Transfer RNA was predicted using tRNAscane-SE v 1.23 (Schattner et al. , 2005)","Modify,Fact/Evidence",Fact/Evidence
8068,6-1750,6-1750_v2_9@0,6-1750_v1_9@0,"The O. coarctata genome (2n=4X=48; KKLL; Sanchez et al. , 2013 ) is self-pollinated, ( Sarkar et al., 1993 ) tetraploid plant with a genome size estimated by flow cytometry is found to be approximately 665Mb.",The genome (KKLL) of O. coarctata is tetraploid (2n=4X=48) with a genome size estimated by flow cytometer is found to be approximately 665Mb.,"Modify,Fact/Evidence",Fact/Evidence
8069,6-1750,6-1750_v2_9@1,6-1750_v1_9@1,The Illumina 4000 GA IIx sequencer pair-end generated 123.78 Gb data.,The Illumina 4000 GA IIx sequencer pair-end generated 137 Gb data.,"Modify,Fact/Evidence",Fact/Evidence
8070,6-1750,6-1750_v2_9@2,6-1750_v1_9@2,Further four mate-pair libraries together generated 36.54 Gb and Nanopore generated 6.35 Gb sequence data.,Further four mate-pair libraries together generated 104.35 Gb and Nanopore generated 6.35 Gb sequence data.,"Modify,Fact/Evidence",Fact/Evidence
8071,6-1750,6-1750_v2_9@3,6-1750_v1_9@3,"Hence, we achieved 250.66 X depth of the genome of O. coarctata .","Hence, we achieved 372.48 X depth of the genome of O. coarctata .","Modify,Fact/Evidence",Fact/Evidence
8072,6-1750,6-1750_v2_2@1,6-1750_v1_2@1,"We report for the first time the draft genome with the coverage of 85.71 % and deposited the raw data in NCBI SRA, with BioProject ID PRJNA396417 .","We report for the first time that more than 85.71 % of the genome coverage and the data have been deposited in NCBI SRA, with BioProject ID PRJNA396417 .","Modify,Clarity",Clarity
8073,6-1750,6-1750_v2_9@4,6-1750_v1_9@4,"The final assembly generated 58362 numbers of scaffolds with a minimum length of 200 bp to maximum length of 7,855,609 bp and 1,858,627 bp N50 value, making a total scaffold length of 569994164 (around 570 Mb) assembled genome, resulting in 85.71% genome coverage.","The final assembly generated 58362 number of contigs with a minimum length of 200 bp to maximum length of 7,855,609 bp and 1,858,627 bp N50 value, making a total contig length of 569994164 (around 570 Mb) assembled genome, resulting 85.71 % genome coverage.","Modify,Clarity",Clarity
8074,6-1750,6-1750_v2_9@6,6-1750_v1_9@6,"Further, we also found that the 19.89% of the assembled genome is repetitive in nature.","Further, we also found that the repeat contain 19.89% of the genome.","Modify,Clarity",Clarity
8075,6-1750,6-1750_v2_9@7,6-1750_v1_9@7,"We also identified approximately 5512 different non-coding RNAs and around 230,968 SSRs.",We also identified approximately 1605 different non-coding RNAs and around 105673 SSRs.,"Modify,Fact/Evidence",Fact/Evidence
8076,6-1780,,6-1780_v1_7@1,,"In 2012, it was estimated that there were 1.7 million breast cancer cases with more than half million deaths.","Delete,Claim",Claim
8077,6-1780,,6-1780_v1_47@0,,P63 is highly expressed in embryonic ectoderm and in the nuclei of basal regenerative cell of many epithelial tissues <REF-23> .,"Delete,Fact/Evidence",Fact/Evidence
8078,6-1780,,6-1780_v1_47@1,,P63 is expressed selectively in basal mammary epithelial cells and its expression is increased during mammary gland maturation <REF-24> .,"Delete,Fact/Evidence",Fact/Evidence
8079,6-1780,6-1780_v2_7@3,,"Triple-negative breast cancer (TNBC), a group of breast cancers with the absence of oestrogen receptor and progesterone receptor and no overexpression of human epidermal growth factor receptor 2 (HER2), represents 10%–20% of invasive breast cancer.",,"Add,Claim",Claim
8080,6-1780,6-1780_v2_7@4,,"A global data base, National Cancer Data Base (NCDB), reveals that TNBC was present in 13% of breast cancer patients, ranged from 23.7% in African-Americans to 8.9% in Filipino patients <REF-5> .",,"Add,Fact/Evidence",Fact/Evidence
8081,6-1780,6-1780_v2_7@5,,"In Southeast Asia, a study found that TNBC presented in 10.5% among 1227 breast cancer patients <REF-6> .",,"Add,Fact/Evidence",Fact/Evidence
8082,6-1780,6-1780_v2_7@6,,"In Indonesia, a study that was conducted between 2010 and 2011 in Bandung found that 11.9% of breast cancer patients were TNBC <REF-7> .",,"Add,Fact/Evidence",Fact/Evidence
8083,6-1780,6-1780_v2_8@0,,"Immunohistochemically, TNBC could be divided into two subtypes: Basal-like (positive for the expression of high-molecular-weight/basal cytokeratins 5/6 (CK5/6) and epidermal growth factor receptor (EGFR)) and Non basal-like (negative for the expression of CK5/6 and EGFR).",,"Add,Claim",Claim
8084,6-1780,6-1780_v2_8@1,,"Basal-like TNBC usually has p53 mutation, EGFR overexpression, loss of function of BRCA1, c-MYC amplification, and high histological grade indicating more aggressive characteristics and aggressive behavior <REF-8> , <REF-9> .",,"Add,Fact/Evidence",Fact/Evidence
8085,6-1780,6-1780_v2_8@2,,"In addition, majority of Basal-like cancer cannot be managed effectively with trastuzumab and hormonal treatments <REF-10> .",,"Add,Fact/Evidence",Fact/Evidence
8086,6-1780,6-1780_v2_10@3,,"The roles of p63 in tumorigenesis, cancer progression, and metastasis are still being discovered.",,"Add,Claim",Claim
8087,6-1780,6-1780_v2_10@4,,"However, in animal model found that p63 deficiency may be a causative factor for metastatic spread <REF-19> , <REF-20> .",,"Add,Fact/Evidence",Fact/Evidence
8088,6-1780,6-1780_v2_10@5,,"In addition, clinical evidence suggests that a robust correlation between reduced p63 expression and cancer progression <REF-21> .",,"Add,Fact/Evidence",Fact/Evidence
8089,6-1780,6-1780_v2_7@1,6-1780_v1_7@2,"The incidence of breast cancer increased significantly, approximately by 30% in developed countries <REF-3> and currently it has been also rising in many developing countries <REF-2> .","Between 1980s and 1990s, the incidence of breast cancer increased significantly, approximately by 30% in developed countries <REF-3> and currently it has been also rising in many developing countries <REF-2> .","Modify,Fact/Evidence",Fact/Evidence
8090,6-1780,6-1780_v2_55@0,6-1780_v1_53@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2018 Kamarlis RK et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2017 Kamarlis RK et al.,"Modify,Fact/Evidence",Fact/Evidence
8091,6-1780,6-1780_v2_11@0,6-1780_v1_9@3,A study revealed that the total percentage of P63-positive cells was related to marked nuclear pleomorphism and the intensity of P63 staining was associated with syncytial growth pattern in TNBC <REF-22> .,A study revealed that the total percentage of P63-positive cells was related to marked nuclear pleomorphism and the intensity of P63 staining was associated with syncytial growth pattern in triple-negative breast cancer (TNBC) <REF-13> .,"Modify,Clarity",Clarity
8092,6-1863,6-1863_v2_8@1,,Perfect pest surveillance efforts could determine exactly when eradication has been achieved.,,"Add,Claim",Claim
8093,6-1863,6-1863_v2_8@2,,"However, actual surveillance has a density threshold below which it is increasingly probable that a population is undetected.",,"Add,Claim",Claim
8094,6-1863,6-1863_v2_9@3,,"Additionally, the efficacy of pest surveillance efforts should factor into quarantine length, but that is beyond the scope of this paper.",,"Add,Claim",Claim
8095,6-1863,6-1863_v2_20@1,,"Models indicate that these sites are in regions suitable for Medfly <REF-31> , <REF-32> .",,"Add,Fact/Evidence",Fact/Evidence
8096,6-1863,6-1863_v2_20@2,,Many of the sites experienced outbreaks in their vicinity the past and are of current concern.,,"Add,Claim",Claim
8097,6-1863,6-1863_v2_20@3,,"Additionally, they cover a range of conditions latitudinally as well as the California sites varying from coastal to more arid inland locations.",,"Add,Claim",Claim
8098,6-1863,6-1863_v2_27@2,,"For example, each run include simulations with the initial number of adult females in the population ranging from 33 to 100, but the initial population age distribution was the same for all simulations.",,"Add,Fact/Evidence",Fact/Evidence
8099,6-1863,6-1863_v2_27@4,,LHS ranges for the probability of loss of reproduction due innundative SIT releases (0.5 to 1 chance per day) and additional human induced mortality from control efforts (0.05 to 0.15 per day) were chosen based on estimates of a typical California intervention <REF-26> .,,"Add,Fact/Evidence",Fact/Evidence
8100,6-1863,6-1863_v2_27@5,,The full list of parameters used and their values is provided in Supplementary Table S1 .,,"Add,Fact/Evidence",Fact/Evidence
8101,6-1863,6-1863_v2_28@0,,It is important to note that the 95% threshold for ABS PQL does not mean that there is a 95% chance a given outbreak will be eliminated.,,"Add,Fact/Evidence",Fact/Evidence
8102,6-1863,6-1863_v2_28@1,,"Instead, it refers to 95% of the LHC sampled points in parameter space reaching eradication by a given time.",,"Add,Fact/Evidence",Fact/Evidence
8103,6-1863,6-1863_v2_28@2,,"Despite the fact that we only know most of those parameters to within a range, it is almost certainly true that extreme values are less probable than mid-range values, and even more improbable that combinations of extreme values (for example: low mortalities and high fecundity) which lead to long eradication times will be as frequent as the uniform sampling the LHC procedure produces.",,"Add,Claim",Claim
8104,6-1863,6-1863_v2_28@3,,"Therefore, the 95% threshold used here is expected to be quite conservative.",,"Add,Claim",Claim
8105,6-1863,6-1863_v2_21@2,6-1863_v1_21@2,"The 3 other sites contained large ( > 14 days) gaps or other problems in the early years of their data, so data starting on 1970-01-01 for IAH and 1973-01-01 for BUR and MCO was used.","The 3 other sites contained large (>14 days) gaps or other problems in the early years of their data, so data starting on 1970-01-01 for IAH and 1973-01-01 for BUR and MCO was used.","Modify,Grammar",Grammar
8106,6-1863,6-1863_v2_24@0,6-1863_v1_24@0,"Degree-days were computed by the single-sine method <REF-27> , using a base development temperature of 12.39°C (54.3°F) and 345.56 degree-days Celsius (DDc; 622 DDf) per generation following the standard set by California Department of Food and Agriculture regulation 3406(b) <REF-24> , <REF-33> .","Degree-days were computed by the single-sine method <REF-26> , using a base development temperature of 12.39°C (53.3°F) and 345.56 degree-days Celsius (DDc; 622 DDf) per generation following the standard set by California Department of Food and Agriculture regulation 3406(b) <REF-23> , <REF-30> .","Modify,Fact/Evidence",Fact/Evidence
8107,6-1863,6-1863_v2_33@2,6-1863_v1_32@2,"Additionally, by computing the normals of the predicted quarantine durations, we can investigate properties of the distribution of values as shown in Figure 3 and Figure 4 and the “supernorm"" Supplementary Figure S1 , Supplementary Figure S2 , and Supplementary Figure S3 .","Additionally, by computing the normals of the predicted quarantine durations, we can investigate properties of the distribution of values as shown in Figure 3 and Figure 4 and the “supernorm” supplementary figure S1 , supplementary figure S2 , and supplementary figure S3 .","Modify,Grammar",Grammar
8108,6-1863,6-1863_v2_58@0,6-1863_v1_57@0,The standard deviations of the ABS PQL normals shown in Figure 4 are generally about 1/2 as large as for DD PQL.,The standard deviations of the ABS PQL normals shown in Figure 4 are generally about ½ as large as for DD PQL.,"Modify,Grammar",Grammar
8109,6-1863,6-1863_v2_62@1,6-1863_v1_61@1,"For this set of hypothetical quarantines, the ABS produced significantly shorter quarantines (mean=169.7 days, σ =21.8 days) than simple 3 generation degree day accumulation (mean=234.2 days, σ =79.2 days) ( df =33, t =6.01, p <10 − 5 ).","For this set of hypothetical quarantines, the ABS produced significantly shorter quarantines (mean=169.7 days, σ =21.8 days) than simple 3 generation degree day accumulation (mean=234.2 days, σ =79.2 days) ( df =33, t =6.01, p<10 −5 ).","Modify,Grammar",Grammar
8110,6-1863,6-1863_v2_62@2,6-1863_v1_61@2,"Additionally, the variance in the difference between quarantine lengths using a specific date and the mean of the normal PQL for that day of year was smaller for the ABS ( σ =8.2 days) than with degree day ( σ =25.9 days) ( df =33, F =9.92, p <10 − 8 ).","Additionally, the variance in the difference between quarantine lengths using a specific date and the mean of the normal PQL for that day of year was smaller for the ABS ( σ =8.2 days) than with degree day ( σ =25.9 days) ( df =33, F =9.92, p<10 −8 ).","Modify,Grammar",Grammar
8111,6-1863,6-1863_v2_65@0,6-1863_v1_64@0,- 1) Comparison of PQLs as determined by the degree day and ABS methods.,1) Comparison of PQLs as determined by the degree day and ABS methods.,"Modify,Grammar",Grammar
8112,6-1863,6-1863_v2_65@2,6-1863_v1_66@0,- 3) Variation in PQLs within a time of year and location.,3) Variation in PQLs within a time of year and location.,"Modify,Grammar",Grammar
8113,6-1863,6-1863_v2_66@0,6-1863_v1_67@0,"Consideration of all three of these by program managers, planners and other decision makers is likely to improve management of Medfly incursions by informing resource allocation ahead of outbreaks, reducing quarantine costs in some cases, and reducing risk from premature quarantine suspension in others.","Consideration of all three of these by program managers, planners and other decision makers is likely to improve management of Medfly outbreaks by informing resource allocation ahead of outbreaks, reducing quarantine costs in some cases, and reducing risk from premature quarantine suspension in others.","Modify,Clarity",Clarity
8114,6-1863,6-1863_v2_68@2,6-1863_v1_70@2,"On the other hand, in cases where the ABS predicts longer times to elimination the degree day indicated quarantine may be unusually short, so treatments and SIT releases should be conducted more aggressively than normal to ensure eradication is achieved within the perscribed degree day based quarantine.","On the other hand, in cases where the ABS predicts longer times to elimination, it is plausible that the degree day indicated quarantine is optimistically short, and eradication treatments and SIT releases should be conducted even more aggressively than normal to ensure eradication is achieved within the degree day based period.","Modify,Clarity",Clarity
8115,6-1863,6-1863_v2_71@2,6-1863_v1_73@2,The specificity of the ABS is helpful for determining when quarantines might be safely suspended due to such a rare event not be captured by the degree day model.,"The specificity of the ABS is helpful for determining when quarantines might be safely suspended due to a rare event, something that might not be captured by the degree day model.","Modify,Clarity",Clarity
8116,6-1863,6-1863_v2_71@3,6-1863_v1_73@3,"For cold temperatures especially there can be a significant difference in PQLs: The degree day model includes only development, which is halted at low temperatures, extending quarantine lengths.","The degree day model includes only development for generating PQLs, and development is halted at low temperatures, extending quarantine lengths.","Modify,Claim",Claim
8117,6-1863,6-1863_v2_73@1,6-1863_v1_76@1,"If 95% of simulations show elimination, the decision to end quarantine early could be made, or in the case where the ABS has not reached the 95% threshold at the end of the DD PQL additional measures could be considered to reduce the risk of re-detection.","If a threshold of 95% of simulations show elimination, the decision to end quarantine early could be made, or in the case where the ABS has not reached the 95% threshold at the end of the DD PQL additional measures could be considered to reduce the risk of re-detection.","Modify,Clarity",Clarity
8118,6-1863,6-1863_v2_75@0,6-1863_v1_78@0,"All data, non-standard programs, and scripts used area available in the GitHub repository: https://github.com/travc/paper-Predicted-MF-Quarantine-Length-Data-and-Code , archived at https://doi.org/10.5281/zenodo.1006698 .","All data, non-standard programs, and scripts used are available in the GitHub repository: https://github.com/travc/paper-Predicted-MF-Quarantine-Length-Data-and-Code , archived source code as at the time of publication is available at https://doi.org/10.5281/zenodo.1006698 <REF-35> .","Modify,Clarity",Clarity
8119,6-1863,6-1863_v2_9@0,6-1863_v1_9@0,"Currently, most programs extend quarantine periods past when the last fly is found, by calculating the amount of time required for a given number of generations (usually but not always three) to elapse under a thermal unit accumulation (“degree day”) physiological development model.","Currently, most programs extend quarantine periods past when the last fly is found, by calculating the amount of time required for a given number of generations (usually three) to elapse under a thermal unit accumulation (“degree day”) physiological development model.","Modify,Clarity",Clarity
8120,6-2020,6-2020_v2_8@0,,Before continuing it is important to clarify that in this article we use the term ‘genomic’ to refer to a wide range of sequencing and laboratory techniques.,,"Add,Fact/Evidence",Fact/Evidence
8121,6-2020,6-2020_v2_8@1,,There are a range of different technologies that interrogate the ‘whole genome’.,,"Add,Fact/Evidence",Fact/Evidence
8122,6-2020,6-2020_v2_8@2,,Next generation sequencing may be used to create a ‘whole genome sequence’ - a complete catalogue of all (approx) 3 billion base pairs of an individual’s genome.,,"Add,Claim",Claim
8123,6-2020,6-2020_v2_8@3,,"There are also a number of technologies that look across an entire genome but do not create a ‘whole genome sequence’ for example, microarrays, SNP arrays, and exome sequences.",,"Add,Claim",Claim
8124,6-2020,6-2020_v2_8@4,,For our purposes we refer to all technologies that look across the genome as ‘genomic’.,,"Add,Fact/Evidence",Fact/Evidence
8125,6-2020,6-2020_v2_8@5,,Where there are specific technological issues (such as positive and negative predictive values in direct to consumer genetic tests) we refer to these.,,"Add,Fact/Evidence",Fact/Evidence
8126,6-2020,6-2020_v2_8@6,,For the purposes of this article we discuss broadly the implications of ‘genomic’ technology with an understanding that this refers to a range of sequencing and testing techniques.,,"Add,Fact/Evidence",Fact/Evidence
8127,6-2020,6-2020_v2_8@7,,"We also use the term ‘genetics’ broadly with an understanding that this term covers wide disciplinary boundaries, including genomics.",,"Add,Claim",Claim
8128,6-2020,6-2020_v2_11@0,,"A commitment to significant and ongoing investment in genomics on an international scale is demonstrated by the ‘Million European Genomes Project’, where genomic and health data will be linked from 1 million European patients <REF-5> and The Global Alliance for Genomics and Health ( www.ga4gh.org ) that represents more than 500+ organisations globally all with the shared endeavour of implementing and enabling genomic data sharing to be applied in research and clinical practice.",,"Add,Fact/Evidence",Fact/Evidence
8129,6-2020,6-2020_v2_13@0,,"While there are many ways in which genomics is improving healthcare, it is important to note that there is evidence that genomic medicine does not always simplify or improve care.",,"Add,Claim",Claim
8130,6-2020,6-2020_v2_13@1,,"For example Adam Hedgecoe <REF-10> questions the utility of genetic testing, which can increase diagnostic uncertainty and Sophie Day et al. , <REF-11> identify the ways in which genomic medicine further complicates treatment pathways for breast cancer.",,"Add,Fact/Evidence",Fact/Evidence
8131,6-2020,6-2020_v2_13@2,,Arribas-Ayllon <REF-12> reviews the literature to show that applications of genetic testing in healthcare are uneven and partial.,,"Add,Fact/Evidence",Fact/Evidence
8132,6-2020,6-2020_v2_16@0,,"As patients are exposed to increasingly complex and uncertain genetic information, debates have emerged as to the best way to manage this.",,"Add,Claim",Claim
8133,6-2020,6-2020_v2_16@1,,"Middleton et al. , <REF-15> demonstrate that while many people are enthusiastic about receiving genetic information healthcare professions (especially those who work in genetics) are more cautious.",,"Add,Fact/Evidence",Fact/Evidence
8134,6-2020,6-2020_v2_16@2,,"Joon-Ho et al. , <REF-17> suggest that genetic information should be framed as a ‘dynamic resource’ with uncertainty managed by viewing this information as a resource that should be revisited over the lifetime of an individual.",,"Add,Fact/Evidence",Fact/Evidence
8135,6-2020,6-2020_v2_16@3,,There is as yet no consensus regarding the best way to manage the increasing volume of complexity and uncertainty generated by genomic sequencing.,,"Add,Claim",Claim
8136,6-2020,6-2020_v2_16@4,,In the ongoing discussion we argue it is crucial that debates are informed by wide range of voices.,,"Add,Claim",Claim
8137,6-2020,6-2020_v2_18@5,,"It is important when assessing how people respond to genetic information to ensure that ’the public’ is not envisioned as a singular, unified entity.",,"Add,Claim",Claim
8138,6-2020,6-2020_v2_18@6,,"Scholarship, especially from genetic counselling, demonstrates that the different ways people understand and make sense of genetic information is complex, varied and often idiosyncratic.",,"Add,Claim",Claim
8139,6-2020,6-2020_v2_18@8,,"An important ethical issue, especially in the context of continuing enthusiasm for genomics, is how to respect the wishes of those who dissent, turning down personal genomic knowledge <REF-28> .",,"Add,Fact/Evidence",Fact/Evidence
8140,6-2020,6-2020_v2_37@3,,This can happen when technological advances lead to what can be done being conflated with what should be done.,,"Add,Claim",Claim
8141,6-2020,6-2020_v2_37@4,,"For example, with prenatal screening programs there is evidence that as new technologies become routinized they have driven medical practice <REF-53> .",,"Add,Fact/Evidence",Fact/Evidence
8142,6-2020,6-2020_v2_37@5,,This happens when the ‘normal’ thing to do has become conflated with the ‘right’ thing to do.,,"Add,Claim",Claim
8143,6-2020,6-2020_v2_37@6,,"Scholars writing from a disability rights perspective have noted that this may subvert the wishes of patients who may not want screening <REF-54> , <REF-55> .",,"Add,Fact/Evidence",Fact/Evidence
8144,6-2020,6-2020_v2_37@7,,In a medical setting - where there are complex power dynamics in play - patients may not feel empowered to state a preference that goes against what is construed as ‘normal’ and therefore ‘right’.,,"Add,Claim",Claim
8145,6-2020,6-2020_v2_19@0,6-2020_v1_14@0,"The complex ways that genetics – and now genomics – will affect patients, means that the provision of genetic counselling is of increasing significance.","The complex ways that genetics – and now genomics – will affect patients, means that the provision of genetic counselling is of increasing in significance.","Modify,Grammar",Grammar
8146,6-2020,6-2020_v2_12@0,6-2020_v1_9@6,"Genomic technology is now being utilised globally in a wide range of contexts to provide diagnostic, prognostic and treatment information for patients in a way that is predicted to transform healthcare <REF-1> .","Thus we can see that genomic technology is now being utilised globally in a wide range of contexts to provide diagnostic, prognostic and treatment information for patients using healthcare services in a way that is predicted to transform healthcare <REF-1> .","Modify,Clarity",Clarity
8147,6-2020,6-2020_v2_12@1,6-2020_v1_10@0,"Genetic testing is currently used in a range of hospital settings, including the diagnosis of rare disease in paediatrics, prenatal care, ophthalmology, dermatology, ENT, etc.","Genetic testing is currently used in a wide range of healthcare settings, including the diagnosis of rare disease in paediatrics, prenatal care, ophthalmology, dermatology, ENT, etc.","Modify,Clarity",Clarity
8148,6-2020,6-2020_v2_2@2,6-2020_v1_2@2,"Since then, our ability to sequence genomes has been finessed so much that by 2018 it is possible to explore the 20,000 or so human genes for under £1000, in a matter of days.","Since then, our ability to sequence genomes has been finessed so much that by 2017 it is possible to explore the 20,000 or so human genes for under £1000, in a matter of days.","Modify,Fact/Evidence",Fact/Evidence
8149,6-2020,6-2020_v2_12@5,6-2020_v1_10@4,"Alterations in these genes are known to lead an increased risk for certain types of cancer, most notably breast and ovarian cancer.","Mutations in these genes are known to lead an increased risk for certain types of cancer, most notably breast and ovarian cancer.","Modify,Clarity",Clarity
8150,6-2020,6-2020_v2_12@13,6-2020_v1_10@12,"As genomic medicine is increasingly available across healthcare systems, we are moving closer to genetics becoming ‘mainstreamed’ <REF-7> , <REF-9> .","Genomic medicine is now available across whole healthcare systems, it has been truly ‘mainstreamed’ <REF-6> , <REF-8> .","Modify,Clarity",Clarity
8151,6-2020,6-2020_v2_2@3,6-2020_v1_2@3,"Such testing offers clues to our past, present and future health, as well as information about how we respond to medications so that truly ‘personalised medicine’ is now moving closer to a reality.","Such testing offers clues to our past, present and future health, as well as information about how we respond to medications so that truly ‘personalised medicine’ is now a reality.","Modify,Other",Other
8152,6-2020,6-2020_v2_14@1,6-2020_v1_11@1,Such ’Variants of Uncertain Significance’ are results where the meaning is unclear and are more likely to be discovered when multiple genes are tested for at once <REF-14> .,Such ’Variants of Unknown Significance’ are results where the meaning is unclear and are more likely to be discovered when multiple genes are tested for at once <REF-10> .,"Modify,Clarity",Clarity
8153,6-2020,6-2020_v2_17@2,6-2020_v1_12@2,"Furthermore, this may be linked to pharmacogenomics – genetic testing used to guide drug use in medicine.","Furthermore, this is linked to pharmacogenomics – genetic testing used to guide drug use in medicine.","Modify,Other",Other
8154,6-2020,6-2020_v2_3@0,6-2020_v1_3@0,"The impact of such a ‘genomic era’ is likely to have some level of impact on an increasingly large number of us, even if we are not directly using healthcare services ourselves.","The impact of such a ‘genomic era’ is likely to have some level of impact on all of us, even if we are not directly using healthcare services ourselves.","Modify,Claim",Claim
8155,6-2020,6-2020_v2_17@4,6-2020_v1_12@4,"This is also being used in oncology, where chemotherapies are targeted towards people with certain genetic profiles <REF-20> .","This is also being used in oncology, where chemotherapies are targeted towards a people with certain genetic profiles <REF-15> .","Modify,Grammar",Grammar
8156,6-2034,6-2034_v2_23@0,6-2034_v1_23@0,More or less soluble colourants detected by LDI-TOF-MS were occasionally confirmed by high performance liquid chromatography (HPLC).,More or less soluble colourants detected by MALDI were occasionally confirmed by high performance liquid chromatography (HPLC).,"Modify,Fact/Evidence",Fact/Evidence
8157,6-2034,6-2034_v2_23@2,6-2034_v1_23@2,"Coloured extracts were centrifuged at 12’000 g, filtered with 0.45 µm PTFE syringe filters and analysed with Ion Pair Reversed Phase HPLC with Ultraviolet Diode Array (UV/DAD) detection under the following conditions: Kromasil-column C18, 5 µm, 150 × 2 mm (30°C); eluent A: aqueous solution of dodecyltrimethylammonium bromide (3 g/L) and ammonium bromide (1 g/L), eluent B: ethanolic solution of dodecyltrimethylammonium bromide (3 g/L) and ammonium bromide (1 g/L); run time = 30 minutes; flow rate = 0.35 mL/min; gradient conditions: 0 min 45% eluent B, 2 min 55% eluent B, 10 min 65% eluent B, 20 min 100% eluent B, 24 min 100% eluent B, 24.1 min 45% eluent B.","Coloured extracts were centrifuged at 12’000 g, filtered with 0.45 µm PTFE syringe filters and analysed with Ion Pair Reversed Phase HPLC with Ultraviolet Diode Array (UV/DAD) detection under the following conditions: Kromasil-column C18, 5 µm, 150 x 2 mm (30°C); eluent A: aqueous solution of dodecyltrimethylammonium bromide (3 g/L) and ammonium bromide (1 g/L), eluent B: ethanolic solution of dodecyltrimethylammonium bromide (3 g/L) and ammonium bromide (1 g/L); run time = 30 minutes; flow rate = 0.35 mL/min; gradient conditions: 0 min 45% eluent B, 2 min 55% eluent B, 10 min 65% eluent B, 20 min 100% eluent B, 24 min 100% eluent B, 24.1 min 45% eluent B.","Modify,Grammar",Grammar
8158,6-2034,6-2034_v2_25@2,6-2034_v1_25@2,"From these former investigations we derived the following conclusions: LDI- or MALDI-TOF-MS is an excellent and rapid method for the detection and identification of organic colour pigments, but not for inorganic ones.","From these former investigations we derived the following conclusions: MALDI-TOF MS is an excellent and rapid method for the detection and identification of organic colour pigments, but not for inorganic ones.","Modify,Claim",Claim
8159,6-2034,6-2034_v2_25@3,6-2034_v1_25@3,"For the most part of the analysed pigments, the ionisation can be performed without added matrix (LDI-TOF-MS), because the pigments themselves function as chromophores absorbing the laser beam <REF-14> .","For the most part of the analysed pigments, the ionisation can be performed without added matrix (LDI-TOF), because the pigments themselves function as chromophores absorbing the laser beam <REF-14> .","Modify,Fact/Evidence",Fact/Evidence
8160,6-2034,6-2034_v2_2@9,6-2034_v1_2@9,"Pigment screening of 396 tattoo inks and 55 PMU taken from the Swiss market between 2009 and 2017 lead to the following conclusions: Pigment variety is much greater in tattoo inks (18) than in PMU (10); four prohibited pigments (Pigment Green 7, Pigment Red 122, Pigment Violet 19 and 23) were found in both ink types; for PMU, these four pigments made up 12% of the pigment findings, compared to 32% for tattoo inks.","Pigment screening of 396 tattoo inks and 55 PMUs taken from the Swiss market between 2009 and 2017 lead to the following conclusions: Pigment variety is much greater in tattoo inks (18) than in PMUs (10); four prohibited pigments (Pigment Green 7, Pigment Red 122, Pigment Violet 19 and 23) were found in both ink types; for PMUs, these four pigments made up 12% of the pigment findings, compared to 32% for tattoo inks.","Modify,Grammar",Grammar
8161,6-2034,6-2034_v2_29@4,6-2034_v1_29@4,"This problem was met by washing samples with EtOH before LDI-TOF-MS, which proved to be effective in most cases <REF-16> .","This problem was met by washing samples with EtOH before LDI/MALDI, which proved to be effective in most cases <REF-16> .","Modify,Fact/Evidence",Fact/Evidence
8162,6-2034,6-2034_v2_2@10,6-2034_v1_2@10,"Therefore, legal compliance of PMU was at a higher level.","Therefore, legal compliance of PMUs was at a higher level.","Modify,Grammar",Grammar
8163,6-2034,6-2034_v2_37@5,6-2034_v1_37@5,LDI spectra did not reveal their characteristic ions [M+Na] + (m/z 463) and [M+Na] + (m/z 477) for the red pigment (a mixture of C.I. 12474 and 12475) and the ion cluster [M+H] + (m/z 575) of the blue one ( Figure 3C ).,MALDI spectra did not reveal their characteristic ions [M+Na] + (m/z 463) and [M+Na] + (m/z 477) for the red pigment (a mixture of C.I. 12474 and 12475) and the ion cluster [M+H] + (m/z 575) of the blue one ( Figure 3C ).,"Modify,Fact/Evidence",Fact/Evidence
8164,6-2034,6-2034_v2_2@11,6-2034_v1_2@11,"A comparison of pigments found with those declared on tattoo ink labels clearly showed that banned pigments are rarely declared, but rather masked by listing non present legal pigments and label forging; therefore, highlighting the urgency of widespread market controls.","A comparison of pigments found with those declared on tattoo ink labels clearly showed that banned pigments are rarely declared, but rather masked by listing not present legal pigments and label forging; therefore, highlighting the urgency of widespread market controls.","Modify,Grammar",Grammar
8165,6-2034,6-2034_v2_41@4,6-2034_v1_41@4,"With DHB the signal intensity of the molecular ion [M] + (m/z 628) was twice that of the sodium adduct [M+Na] + (m/z 651), even twelve times as high as without matrix supplement.","With DHB the signal intensity of the molecular ion [M] + (m/z 628) was twice that of the sodium adduct [M+Na] + (m/z 651), even twelve times as high than without matrix supplement.","Modify,Grammar",Grammar
8166,6-2034,6-2034_v2_45@0,6-2034_v1_45@0,"Because the identification of pigments by LDI-TOF-MS is a qualitative method, validation was only performed for mass resolution, accuracy of pigment identification, a rough estimation of limits of detection and the precision of characteristic mass intensity.","Because the identification of pigments by LDI/MALDI-TOF MS is a qualitative method, validation was only performed for mass resolution, accuracy of pigment identification, a rough estimation of limits of detection and the precision of characteristic mass intensity.","Modify,Claim",Claim
8167,6-2034,6-2034_v2_47@7,6-2034_v1_47@7,"For the two other samples, results of LDI-TOF-MS were not consistent with those of HPLC-analysis: in the first case, C.I. 21110 was identified with LDI-TOF-MS, whereas HPLC-analysis gave C.I. 21115.","For the two other samples, results of LDI-TOF MS were not consistent with those of HPLC-analysis: in the first case, C.I. 21110 was identified with LDI-TOF MS, whereas HPLC-analysis gave C.I. 21115.","Modify,Grammar",Grammar
8168,6-2034,6-2034_v2_4@1,6-2034_v1_4@1,"These figures, the widespread on-line sales of tattoo related products, and the invasive techniques used during tattooing - where inks are injected into the skin’s dermis - have led to serious concerns on the safety of tattoo inks and permanent make-up (PMU).","These figures, the widespread on-line sales of tattoo related products, and the invasive techniques used during tattooing - where inks are injected into the skin’s dermis - have led to serious concerns on the safety of tattoo inks and permanent make-ups (PMUs).","Modify,Grammar",Grammar
8169,6-2034,6-2034_v2_0@0,6-2034_v1_0@0,Identification of organic pigments in tattoo inks and permanent make-up using laser desorption ionisation mass spectrometry,Identification of organic pigments in tattoo inks and permanent make-ups using MALDI-TOF mass spectrometry,"Modify,Other",Other
8170,6-2034,6-2034_v2_52@0,6-2034_v1_52@0,Over the last eight years we used LDI- or MALDI-TOF-MS for market survey purposes in Switzerland.,Over the last eight years we used LDI/MALDI-TOF MS for market survey purposes in Switzerland.,"Modify,Clarity",Clarity
8171,6-2034,6-2034_v2_52@3,6-2034_v1_52@3,Data obtained show that Pigment Blue 15 (C.I. 74160) was the most often found colourant followed by the prohibited Pigment Green 7 (C.I. 74260).,Data obtained show that pigment Blue 15 was the most often found colourant followed by the prohibited Pigment Green 7.,"Modify,Fact/Evidence",Fact/Evidence
8172,6-2034,6-2034_v2_52@4,6-2034_v1_52@4,"All prohibited pigments, especially Pigment Green 7, were more frequently found in inks (3 – 13%) than in PMU (2 – 4%).","All prohibited pigments, especially PG7, were more frequently found in inks (3 – 13%) than in PMUs (2 – 4%).","Modify,Clarity",Clarity
8173,6-2034,6-2034_v2_52@7,6-2034_v1_52@7,"This fraud considers pigments that are banned due to toxicological concerns, showcasing the urgency for widespread market controls.","This fraud considers pigments that are banned due to toxicological concerns and implications for consumer health may be serious, showcasing the urgency for widespread market controls.","Modify,Claim",Claim
8174,6-2034,6-2034_v2_4@3,6-2034_v1_4@3,"For colourants, namely pigments, being the ingredients, which give tattoo inks and PMU the desired effect, regulations are summarised as follows: a ban on colourants that can form aromatic amines under reductive cleavage, a negative list for specific colourants and a ban for colourants with restricted use in cosmetics.","For colourants, namely pigments, being the ingredients, which give tattoo inks and PMUs the desired effect, regulations are summarised as follows: a ban on colourants that can form aromatic amines under reductive cleavage, a negative list for specific colourants and a ban for colourants with restricted use in cosmetics.","Modify,Grammar",Grammar
8175,6-2034,6-2034_v2_2@1,6-2034_v1_2@1,"Rising concerns regarding consumer safety, led to legal restrictions on tattoo and permanent make-up (PMU) inks.","Rising concerns regarding consumer safety, led to legal restrictions on tattoo inks and permanent make-up (PMU) inks.","Modify,Clarity",Clarity
8176,6-2034,6-2034_v2_61@0,6-2034_v1_61@0,"To our knowledge, no study reported a LDI-TOF-MS method for the identification of colour pigments in tattoo inks, PMU or cosmetic products.","To our knowledge, no study reported a LDI/MALDI-TOF MS method for the identification of colour pigments in tattoo inks, PMUs or cosmetic products.","Modify,Claim",Claim
8177,6-2034,6-2034_v2_61@1,6-2034_v1_61@1,Method validation and using the LDI-TOF-MS method for market surveys demonstrated that the method described is fit for purpose.,Method validation and using the MALDI method for market surveys demonstrated that the method described is fit for purpose.,"Modify,Claim",Claim
8178,6-2034,6-2034_v2_61@2,6-2034_v1_61@2,"Therefore, LDI-TOF-MS is a further powerful tool particularly in combination with py-GC/MS <REF-10> , HPLC or ultraviolet–visible spectroscopy <REF-18> for enforcing legal restrictions on pigments in tattoo inks and PMU.","Therefore, LDI/MALDI-TOF MS is a further powerful tool particularly in combination with py-GC/MS <REF-10> , HPLC or ultraviolet–visible spectroscopy <REF-18> for enforcing legal restrictions on pigments in tattoo inks and PMUs.","Modify,Claim",Claim
8179,6-2034,6-2034_v2_63@0,6-2034_v1_63@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2018 Niederer M et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2017 Niederer M et al.,"Modify,Fact/Evidence",Fact/Evidence
8180,6-2034,6-2034_v2_65@3,6-2034_v1_65@3,"Further, we created an Excel sheet ( Dataset 4 ) with intermediary data of the market surveys.","Further, we created an Excel sheet (Dataset 4) with intermediary data of the market surveys.","Modify,Grammar",Grammar
8181,6-2034,6-2034_v2_4@8,6-2034_v1_4@8,"Pigment fading and transport of organic pigments from the skin to regional lymph nodes have been well documented for tattoos <REF-4> , <REF-5> .","Pigment fading and transport of organic pigments from the skin to regional lymph nodes has been well documented for tattoos <REF-4> , <REF-5> .","Modify,Grammar",Grammar
8182,6-2034,6-2034_v2_2@2,6-2034_v1_2@2,Restrictions also include bans on certain colourants.,Restrictions also include bans on certain hazardous colourants.,"Modify,Clarity",Clarity
8183,6-2034,6-2034_v2_5@4,6-2034_v1_5@4,"While FT-IR and Raman Spectroscopy are very suitable for the identification of single pigments, their successful use for pigment mixtures, often present in tattoo inks, has yet to be proven.","While FT-IR and Raman Spectroscopy are very suitable for the identification of single pigments, their successful use for pigment mixtures, often present in tattoo inks, has yet to be proved.","Modify,Grammar",Grammar
8184,6-2034,6-2034_v2_5@5,6-2034_v1_5@5,Direct laser desorption or matrix assisted laser desorption ionisation time-of-flight mass spectrometry (LDI-TOF-MS or MALDI-TOF–MS) has been reported for identifying pigments in automotive coatings <REF-11> or art work <REF-12> – <REF-14> .,"Matrix assisted laser desorption ionisation time-of-flight mass spectrometry (MALDI-TOF–MS) has been reported for identifying pigments in automotive coatings <REF-11> or art work <REF-8> , <REF-12> – <REF-14> .","Modify,Fact/Evidence",Fact/Evidence
8185,6-2034,6-2034_v2_5@6,6-2034_v1_5@6,"In this article, we present a validated LDI-TOF-MS approach for the identification of pigments in tattoo inks and PMU.","In this article, we present a validated MALDI-TOF-MS approach for the identification of pigments in tattoo inks and PMUs.","Modify,Fact/Evidence",Fact/Evidence
8186,6-2034,6-2034_v2_12@0,6-2034_v1_12@0,Tattoo inks and PMU were taken from the Swiss market over the last eight years.,Tattoo inks and PMUs were taken from the Swiss market over the last eight years.,"Modify,Grammar",Grammar
8187,6-2034,6-2034_v2_13@1,6-2034_v1_13@1,"Then, about 25 µL (20–30 mg) of the suspension or 20 mg of PMU were weighed into a tared 2 mL-tube, mixed with 1 mL of EtOH, sonicated (5 min, 25°C) and centrifuged (5 min, 15000 rpm).","Then, about 25 µL (20–30 mg) of the suspension or 20 mg of PMUs were weighed into a tared 2 mL-tube, mixed with 1 mL of EtOH, sonicated (5 min, 25°C) and centrifuged (5 min, 15000 rpm).","Modify,Grammar",Grammar
8188,6-2034,6-2034_v2_2@5,6-2034_v1_2@5,Their detection and identification therefore pose a major challenge for laboratories involved in monitoring the legal compliance of tattoo inks and PMU.,Their detection and identification therefore pose a major challenge for laboratories involved in monitoring the legal compliance of tattoo inks and PMUs.,"Modify,Grammar",Grammar
8189,6-2034,6-2034_v2_2@6,6-2034_v1_2@6,"We overcame this challenge by developing a direct laser desorption ionisation time-of-flight mass spectrometry method, which included an easy sample clean up.","We overcame this challenge by developing a matrix-assisted laser desorption ionisation time-of-flight mass spectrometry method, which included an easy sample clean up.","Modify,Fact/Evidence",Fact/Evidence
8190,6-2034,6-2034_v2_19@2,6-2034_v1_19@2,"The target plate was scanned by the laser (diameter of 30 μm) in the regular rectangular mode and serpentine style (1000 × 1000 μm, spacing 166.666 μm and 49 points).","The target plate was scanned by the laser (diameter of 30 μm) in the regular rectangular mode and serpentine style (1000 x 1000 μm, spacing 166.666 μm and 49 points).","Modify,Grammar",Grammar
8191,6-2097,6-2097_v2_7@2,,Effects of Toxoplasma gondii infection on fear are not absolute.,,"Add,Claim",Claim
8192,6-2097,6-2097_v2_7@3,,Rather effects of the infection on aversion follow a non-monotonous function roughly resembling an inverted-U <REF-12> .,,"Add,Fact/Evidence",Fact/Evidence
8193,6-2097,6-2097_v2_7@4,,"Similarly, effects of stress on anxiety are also open to environmental modifications.",,"Add,Claim",Claim
8194,6-2097,6-2097_v2_7@5,,"Anxiety induced by stress can be reliably prevented if housing conditions of animals are changed <REF-1> , <REF-13> or if animals have opportunity of voluntary exercise <REF-14> – <REF-16> .",,"Add,Fact/Evidence",Fact/Evidence
8195,6-2097,6-2097_v2_7@6,,These observations suggest that effects of both the infection and stress on animal behavior are responsive to environmental modifications.,,"Add,Claim",Claim
8196,6-2097,6-2097_v2_14@3,,"Toxoplasma gondii infection did not cause significant change in body weight of animals (179.1 ± 4.708, n = 8 for uninfected; 183.1 ± 2.706, n = 7 for infected; p = 0.5, independent sample t-test).",,"Add,Fact/Evidence",Fact/Evidence
8197,6-2097,6-2097_v2_35@6,,"Furthermore, stressed animals spent more time in open arms during the test duration compared to unstressed counterparts ( Figure 2B ; t 14 = 6.69, p < 0.001).",,"Add,Fact/Evidence",Fact/Evidence
8198,6-2097,6-2097_v2_44@0,,"Proximate mechanisms of atypical observations in the current study remain unknown, although several possibilities can be posited based on the previous literature.",,"Add,Claim",Claim
8199,6-2097,6-2097_v2_44@1,,Long-term effects of environment on the behavior often take form of epigenetic modifications in the brain.,,"Add,Claim",Claim
8200,6-2097,6-2097_v2_44@2,,"Toxoplasma gondii infection, for example, causes DNA hypomethylation in arginine vasopressin promoter within medial amygdala <REF-5> .",,"Add,Fact/Evidence",Fact/Evidence
8201,6-2097,6-2097_v2_44@3,,"Similarly, maternal separation results in robust hypomethylation in insulin signaling pathway within rat hippocampus <REF-28> .",,"Add,Fact/Evidence",Fact/Evidence
8202,6-2097,6-2097_v2_44@4,,It is thus plausible that environmental disturbance influenced behavior through epigenetic modifications within the brain.,,"Add,Claim",Claim
8203,6-2097,6-2097_v2_44@5,,Alternatively alterations in central monoamine levels could also cause the behavioral change.,,"Add,Claim",Claim
8204,6-2097,6-2097_v2_44@6,,Maternal separation increases monoamine levels within hippocampus and amygdala <REF-29> while Toxoplasma gondii infection reduced dopamine concentration within nucleus accumbens <REF-30> .,,"Add,Fact/Evidence",Fact/Evidence
8205,6-2097,6-2097_v2_44@7,,It is plausible that environmental modification changed the nature of monoamine response consequent to the stress or the infection.,,"Add,Claim",Claim
8206,6-2097,6-2097_v2_4@2,6-2097_v1_4@2,"We also found that Toxoplasma gondii infection caused an increase, rather than historically observed decrease, in innate aversion to predator odors in rats.","We also found that Toxoplasma infection caused an increase, rather than historically observed decrease, in innate aversion to predator odors in rats.","Modify,Clarity",Clarity
8207,6-2097,6-2097_v2_28@4,6-2097_v1_28@4,The maximum of animals from the infected group was below the median of the uninfected animals.,The maximum of animals from the infected group was below the median of the control animals.,"Modify,Clarity",Clarity
8208,6-2097,6-2097_v2_28@5,6-2097_v1_28@5,"The robust effect size and the observation that infected mean was lower than uninfected animals in contrast to the multitude of published studies, led us to plan a further experiment to increase the statistical power.","The robust effect size and the observation that infected mean was lower than controls in contrast to the multitude of published studies, led us to plan a further experiment to increase the statistical power.","Modify,Clarity",Clarity
8209,6-2097,6-2097_v2_5@0,6-2097_v1_5@0,Conclusion: These observations suggest that effects of stress and Toxoplasma gondii are dependent on variables in the environment that often go unreported in the published literature.,Conclusion: These observations suggest that effects of stress and Toxoplasma are dependent on variables in the environment that often go unreported in the published literature.,"Modify,Clarity",Clarity
8210,6-2097,6-2097_v2_31@6,6-2097_v1_31@6,The maximum of animals from the infected group was again observed to be below the median of the uninfected animals.,The maximum of animals from the infected group was again observed to be below the median of the control animals.,"Modify,Clarity",Clarity
8211,6-2097,6-2097_v2_7@7,6-2097_v1_7@2,"In this backdrop, this report describes our serendipitous observations that the direction for both behavioral changes is intricately dependent on the broader environment where animal facilities are situated.",This report describes our serendipitous observations that the direction for both behavioral changes is intricately dependent on the broader environment where animal facilities are situated.,"Modify,Clarity",Clarity
8212,6-2097,6-2097_v2_42@10,6-2097_v1_42@10,"In fact, we observed reversal to Toxoplasma -induced loss of fear in female rats in experiments conducted in the animal facility after the cessation of building construction <REF-7> .","In fact, we observed reversal to Toxoplasma -induced loss of fear in female rats in experiments conducted in the animal facility after the cessation of building construction.","Modify,Fact/Evidence",Fact/Evidence
8213,6-2097,6-2097_v2_48@0,6-2097_v1_46@0,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2018 Abdulai-Saiku S et al.,The data referenced by this article are under copyright with the following copyright statement: Copyright: ï¿½ 2017 Abdulai-Saiku S et al.,"Modify,Fact/Evidence",Fact/Evidence
8214,6-2097,6-2097_v2_50@1,6-2097_v1_48@1,Percentage time spent exploring the cat odour stimulus by uninfected and Toxoplasma -infected rats in both experiment 1 and 2.,Percentage time spent exploring the cat odour stimulus by control and Toxoplasma -infected rats in both experiment 1 and 2.,"Modify,Clarity",Clarity
8215,6-2097,6-2097_v2_11@4,6-2097_v1_11@4,Analysis was conducted by AV who was also blind to group allocations.,Analysis was done by AV who was also blind to group allocations.,"Modify,Clarity",Clarity
8216,6-2097,6-2097_v2_11@8,6-2097_v1_11@8,Animals were daily observed to confirm lack of sickness related behaviors and weighed weekly.,Animals were observed daily to confirm lack of sickness related behaviors and weighed weekly.,"Modify,Clarity",Clarity
8217,6-2097,6-2097_v2_14@0,6-2097_v1_14@0,"Female rats were either injected with tachyzoites of type 2 Prugniaud strain of Toxoplasma gondii (5x10 6 tachyzoites in 500 µl phosphate buffered saline, i.p. ;) or mock injected with the buffer alone between 2pm and 4pm.","Female rats were either injected with tachyzoites of type 2 Prugniaud strain of Toxoplasma gondii (5×10 6 tachyzoites in 500 µl phosphate buffered saline, i.p. ;) or mock injected with the buffer alone between 2pm and 4pm.","Modify,Grammar",Grammar
8218,6-2097,6-2097_v2_3@0,6-2097_v1_3@0,"Methods: This study pertains to two such well-studied and well-replicated perturbations, i.e., stress-induced anxiogenesis and Toxoplasma gondii -induced loss of innate fear.","Methods: This study pertains to two such well-studied and well-replicated perturbations, i.e., stress-induced anxiogenesis and Toxoplasma-induced loss of innate fear.","Modify,Clarity",Clarity
8219,6-2097,6-2097_v2_15@1,6-2097_v1_15@1,"For each run of the experiment, there was one uninfected group and one Toxoplasma -infected group.","For each run of the experiment, there was one control group and one Toxoplasma -infected group.","Modify,Clarity",Clarity
8220,6-2097,6-2097_v2_15@2,6-2097_v1_15@2,"Fifteen animals were used in total for experiment 1 (8 uninfected, 7 infected) and nineteen animals were used in total for experiment 2 (10 uninfected, 9 infected).","Fifteen (15) animals were used in total for experiment 1 (8 control, 7 infected) and 19 animals were used in total for experiment 2 (10 control, 9 infected).","Modify,Clarity",Clarity
8221,6-2097,6-2097_v2_16@0,6-2097_v1_16@0,"Aversion was first quantified in a rectangular arena with two opposite and identical arms ( Figure 1A ; 76 x 9 cm each), separated by a central part (9 x 9 cm in size; white Perspex).","Aversion was first quantified in a rectangular arena with two opposite and identical arms (76 × 9 cm each), separated by a central part (9 × 9 cm in size; white Perspex).","Modify,Fact/Evidence",Fact/Evidence
8222,6-2097,6-2097_v2_17@0,6-2097_v1_17@0,Aversion to cat odor was also quantified in a circular arena ( Figure 1A ; diameter = 1 m) that was arbitrally divided into four quadrants.,Aversion to cat odor was also quantified in a circular arena that was arbitrally divided into four quadrants.,"Modify,Fact/Evidence",Fact/Evidence
8223,6-2178,6-2178_v2_31@4,,"Venous thromboembolism, which comprised events of pulmonary embolism and deep venous thrombosis, were also counted from the included studies ( Supplementary Table 6 ).",,"Add,Fact/Evidence",Fact/Evidence
8224,6-2178,6-2178_v2_31@5,,"Two trials, RESPECT and REDUCE trials, reported venous thromboembolism, which occurred in 20 and 6 patients in the PFO closure and medical therapy groups.",,"Add,Fact/Evidence",Fact/Evidence
8225,6-2178,6-2178_v2_38@4,,"A recent meta-analysis also reported that in comparison with medical treatment, PFO prevents recurrent stroke and TIA <REF-27> .",,"Add,Fact/Evidence",Fact/Evidence
8226,6-2178,6-2178_v2_38@5,,"Further, another recent meta-analysis reported that in patients with PFO and cryptogenic stroke, transcatheter device closure decreases risk of recurrent stroke compared with medical therapy alone <REF-28> .",,"Add,Fact/Evidence",Fact/Evidence
8227,6-2178,6-2178_v2_38@6,,"By contrast, anther meta-analysis reported that PFO reduced the risk of stroke, but not TIA, mortality, major bleeding and increased the risk of AF <REF-29> .",,"Add,Fact/Evidence",Fact/Evidence
8228,6-2178,6-2178_v2_38@14,,"As such, based on the results of our meta-analysis, it supports the need to primarily prevent high-risk PFO with PFO closure procedures instead of providing medical therapy.",,"Add,Claim",Claim
8229,6-2178,6-2178_v2_38@15,,This approach is further by the increasing simplicity and success rates of the PFO closure procedure <REF-32> .,,"Add,Fact/Evidence",Fact/Evidence
8230,6-2178,6-2178_v2_38@18,,"While the mechanism leading to the increased risk remains unclear, it may be possibly attributable to inappropriate application of groin compression subsequent to PFO intervention.",,"Add,Claim",Claim
8231,6-2178,6-2178_v2_25@1,6-2178_v1_25@1,"The different trials used slightly different primary endpoints, as follows: 1) CLOSURE I trial: acute focal neurological event that is magnet resonance imaging (MRI) positive, regardless of duration of clinical symptoms, or if imaging cannot be performed for confirmation, it was defined as a persistent focal neurological deficit lasting longer than 24 hours; 2) PC trial: any neurologic deficit lasting for >24 hours typically with documentation in MRI or computer tomography (CT); 3) CLOSE trial: sudden onset of focal neurological symptoms with the presence of cerebral infarction in the appropriate territory on brain imaging (CT or MRI), regardless of the duration of the symptoms (less than or greater than 24 hours); 4) RESPECT trial: ischemic stroke was defined as an acute focal neurologic deficit, which was presumed to be due to focal ischemia, and either symptoms that persisted for 24 hours or longer or symptoms that persisted for less than 24 hours but were associated with findings of a new, neuroanatomically relevant, cerebral infarct on MRI or CT; and 5) REDUCE trial: an acute focal neurologic deficit, presumably due to ischemia, that either resulted in clinical symptoms lasting 24 hours or more or was associated with evidence of relevant infarction on MRI or, if MRI could not be performed, CT of the brain.","The different trials used slightly different primary endpoints, as follows: 1) CLOSURE I trial: acute focal neurological event that is MR imaging positive, regardless of duration of clinical symptoms, or if imaging cannot be performed for confirmation, it was defined as a persistent focal neurological deficit lasting longer than 24 hours; 2) PC trial: any neurologic deficit lasting for >24 hours typically with documentation in magnet resonance imaging (MRI) or computer tomography (CT); 3) CLOSE trial: sudden onset of focal neurological symptoms with the presence of cerebral infarction in the appropriate territory on brain imaging (CT or MRI), regardless of the duration of the symptoms (less than or greater than 24 hours); 4) RESPECT trial: ischemic stroke was defined as an acute focal neurologic deficit, which was presumed to be due to focal ischemia, and either symptoms that persisted for 24 hours or longer or symptoms that persisted for less than 24 hours but were associated with findings of a new, neuroanatomically relevant, cerebral infarct on MRI or CT; and 5) REDUCE trial: an acute focal neurologic deficit, presumably due to ischemia, that either resulted in clinical symptoms lasting 24 hours or more or was associated with evidence of relevant infarction on MRI or, if MRI could not be performed, CT of the brain.","Modify,Clarity",Clarity
8232,6-2178,6-2178_v2_28@0,6-2178_v1_28@0,AF or AFL was detected in 76 patients in the PFO closure group (4.2%) and 37 patients (1.9%) in the medical therapy group ( Supplementary Table 4 ).,Atrial fibrillation or flutter was detected in 76 patients in the PFO closure group (4.2%) and 37 patients (1.9%) in the medical therapy group ( Supplementary Table 4 ).,"Modify,Clarity",Clarity
8233,6-2178,6-2178_v2_28@2,6-2178_v1_28@2,"Subgroup analysis was performed for the type of AF or AFL by dividing the episodes into i) paroxysmal or minor, and ii) permanent or major [as defined by the individual trials].","Subgroup analysis was performed for the type of atrial fibrillation or flutter by dividing the episodes into i) paroxysmal or minor, and ii) permanent or major [as defined by the individual trials].","Modify,Clarity",Clarity
8234,6-2178,6-2178_v2_28@4,6-2178_v1_28@4,"Permanent or serious AF or AFL occurred in 1.3% in the PFO closure group compared to 0.4% in the medical therapy group without significance between these groups (RR: 2.19, 95% CI: 0.94-5.01; P = 0.07; I 2 : 0%) ( Figure 3 , bottom panel).","Permanent or serious atrial fibrillation or flutter occurred in 1.3% in the PFO closure group compared to 0.4% in the medical therapy group without significance between these groups (RR: 2.19, 95% CI: 0.94-5.01; P = 0.07; I 2 : 0%) ( Figure 3 , bottom panel).","Modify,Clarity",Clarity
8235,6-2178,6-2178_v2_35@1,6-2178_v1_35@1,"Nevertheless, these benefits were observed despite a two-fold increase in the risk of AF or AFL in the PFO closure group.","Nevertheless, these benefits were observed despite a two-fold increase in the risk of atrial fibrillation or flutter in the PFO closure group.","Modify,Clarity",Clarity
8236,6-2178,6-2178_v2_36@7,6-2178_v1_36@7,"A recent meta-analysis reported that anticoagulant therapy was more effective than antiplatelet therapy in preventing recurrent stroke and/or TIA, but with a 6-fold greater risk of major bleeding <REF-15> .","A recent meta-analysis reported that anticoagulant therapy was more effective than antiplatelet therapy in preventing recurrent stroke and/or transient ischemic attack, but with a 6-fold greater risk of major bleeding <REF-14> .","Modify,Clarity",Clarity
8237,6-2178,6-2178_v2_37@2,6-2178_v1_37@2,"In addition, in another small cohort including 164 patients with PFO and cryptogenic stroke the two groups (PFO closure vs. medical treatment) did not differ in regard to the composite end-point of death, stroke, TIA or peripheral embolism <REF-17> .","In addition, in another small cohort including 164 patients with PFO and cryptogenic stroke the two groups (PFO closure vs. medical treatment) did not differ in regard to the composite end-point of death, stroke, transient ischemic attack or peripheral embolism <REF-16> .","Modify,Clarity",Clarity
8238,6-2178,6-2178_v2_37@3,6-2178_v1_37@3,"Similarly, data of the IPSYS registry, which included 521 patients aged 18–45 years old with cryptogenic stroke and PFO, showed no significant difference neither in composite end-point [ischemic stroke, TIA or peripheral embolism (P=0.285)] nor in brain ischemia (p=0.168) between PFO closure and medical treatment groups <REF-18> .","Similarly, data of the IPSYS registry, which included 521 patients aged 18–45 years old with cryptogenic stroke and PFO, showed no significant difference neither in composite end-point [ischemic stroke, transient ischemic attack, or peripheral embolism (P=0.285)] nor in brain ischemia (p=0.168) between PFO closure and medical treatment groups <REF-17> .","Modify,Clarity",Clarity
8239,6-2178,6-2178_v2_38@0,6-2178_v1_38@0,"Previous meta-analyses of randomized trials have found no statistically significant differences between PFO closure and medical therapy in the prevention of recurrent ischemic stroke <REF-21> – <REF-24> , whilst PFO closure was associated with an increased risk of AF <REF-21> , <REF-24> .","Previous meta-analyses of randomized trials have found no statistically significant differences between PFO closure and medical therapy in the prevention of recurrent ischemic stroke <REF-20> – <REF-23> , whilst PFO closure was associated with an increased risk of atrial fibrillation <REF-20> , <REF-23> .","Modify,Clarity",Clarity
8240,6-2178,6-2178_v2_38@17,6-2178_v1_38@12,"For example, in the RESPECT trial, a significant increase in pulmonary emboli were observed (12 in the PFO closure group, of which 2 are listed as a complication of the procedure, vs. 3 in the control group) and deep venous thromboses (5 and 1, respectively).","For example, in the RESPECT trial, a significant increase in pulmonary emboli were observed (12 in the PFO closure group vs. 3 in the control group) and deep venous thromboses (5 and 1, respectively).","Modify,Fact/Evidence",Fact/Evidence
8241,6-2178,6-2178_v2_7@0,6-2178_v1_7@0,The association between the presence of a patent foramen ovale (PFO) and cryptogenic stroke has been established by previous case-control studies <REF-1> .,The association between the presence of a patent foramen ovale (PFO) and cryptogenic stroke has been established by previous case-control studies.,"Modify,Fact/Evidence",Fact/Evidence
8242,6-2178,6-2178_v2_42@4,6-2178_v1_42@4,"Low levels of heterogeneity were observed for most of our analyses, including primary endpoints, strokes, TIAs and gastrointestinal complications.","Low levels of heterogeneity were observed for most of our analyses, including primary endpoints, stroke, transient ischemic attacks and gastrointestinal complications.","Modify,Clarity",Clarity
8243,6-2178,6-2178_v2_7@2,6-2178_v1_7@2,"Three randomized trials, the STARFlex Septal Closure in Patients with a Stroke and/or Transient Ischemic Attack due to Presumed Paradoxical Embolism through a PFO (CLOSURE I) <REF-2> , the Clinical Trial Comparing Percutaneous Closure of PFO Using the Amplatzer PFO Occluder with Medical Treatment in Patients with Cryptogenic Embolism (PC) <REF-3> and the Randomized Evaluation of Recurrent Stroke Comparing PFO Closure to Established Current Standard of Care Treatment (RESPECT) <REF-4> , were conducted.","Three randomized trials, CLOSURE I <REF-1> , PC <REF-2> and RESPECT <REF-3> , were conducted.","Modify,Fact/Evidence",Fact/Evidence
8244,6-2178,6-2178_v2_44@0,6-2178_v1_44@0,"PFO closure significantly reduces the risk of primary endpoints, strokes, but not TIAs, when compared to medical treatment, despite higher rates of AF or AFL being observed.","PFO closure significantly reduces the risk of primary endpoints, strokes, but not TIAs, when compared to medical treatment, despite higher rates of atrial fibrillation or flutter being observed.","Modify,Clarity",Clarity
8245,6-2178,6-2178_v2_7@5,6-2178_v1_7@5,"Firstly, the PFO Closure or Anticoagulants versus Antiplatelet Therapy to Prevent Stroke Recurrent (CLOSE) trial evaluated PFO closure or anticoagulation against antiplatelet therapy, with a primary endpoint of fatal or non-fatal stroke <REF-5> .","Firstly, the CLOSE trial evaluated PFO closure or anticoagulation against antiplatelet therapy, with a primary endpoint of fatal or non-fatal stroke <REF-4> .","Modify,Clarity",Clarity
8246,6-2178,6-2178_v2_7@6,6-2178_v1_7@6,"Secondly, the Gore Helex septal occlude and antiplatelet medical management of reduction of recurrent stroke or imaging-confirmed transient ischemic attack in patients with PFO (REDUCE) trial compared PFO closure to antiplatelet therapy only, with a primary endpoint of ischemic stroke, new ischemic stroke or silent brain infarction, demonstrating significant reductions in these events compared to antiplatelet therapy <REF-6> .","Secondly, the REDUCE trial compared PFO closure to antiplatelet therapy only, with a primary endpoint of ischemic stroke, new ischemic stroke or silent brain infarction, demonstrating significant reductions in these events compared to antiplatelet therapy <REF-5> .","Modify,Fact/Evidence",Fact/Evidence
8247,6-2178,6-2178_v2_10@1,6-2178_v1_10@1,PubMed and Cochrane Library were searched for randomized trials that compared the efficacy in stroke prevention of PFO closure with that of medical therapy.,PubMed and Cochrane Library were searched for randomized trials that compared the efficacy in stroke prevention of patent foramen ovale (PFO) closure with that of medical therapy.,"Modify,Clarity",Clarity
8248,6-2178,6-2178_v2_14@0,6-2178_v1_14@0,"The number of events for: i) primary endpoint, ii) stroke, iii) transient ischemic attack (TIA), iv) all-cause bleeding complications, v) gastrointestinal complications [bleeding, ulceration, ulcer perforation], vi) short-term AF or AFL, vii) long-term AF or AFL, viii) venous thromboembolism, were identified and extracted independently by each reviewer from each trial.","The number of events for: i) primary endpoint, ii) stroke, iii) transient ischemic attack, iv) all-cause bleeding complications, v) gastrointestinal complications [bleeding, ulceration, ulcer perforation], vi) short-term atrial fibrillation or flutter, viii) long-term atrial fibrillation or flutter, were identified and extracted independently by each reviewer from each trial.","Modify,Fact/Evidence",Fact/Evidence
8249,6-2178,6-2178_v2_20@0,6-2178_v1_20@0,"PFO closure and primary endpoint(s), stroke and TIA events","PFO closure and primary endpoint(s), stroke and transient ischemic attack events","Modify,Clarity",Clarity
8250,6-2178,6-2178_v2_21@1,6-2178_v1_21@1,"The different trials used slightly different primary endpoints ( Supplementary Table 2 ), as follows: 1) CLOSURE I trial: stroke, TIA, 30-day mortality, neurology-related death, 2) PC trial: stroke, TIA, death, peripheral embolism, 3) CLOSE trial: fatal or non-fatal stroke, 4) RESPECT trial: nonfatal ischemic stroke, fatal ischemic stroke, or early death after randomization and 5) REDUCE trial: co-primary endpoints of i) ischemic stroke, and ii) new ischemic stroke or silent brain infarction.","The different trials used slightly different primary endpoints ( Supplementary Table 2 ), as follows: 1) CLOSURE I trial: stroke, transient ischemic accident (TIA), 30-day mortality, neurology-related death, 2) PC trial: stroke, TIA, death, peripheral embolism, 3) CLOSE trial: fatal or non-fatal stroke, 4) RESPECT trial: nonfatal ischemic stroke, fatal ischemic stroke, or early death after randomization and 5) REDUCE trial: co-primary endpoints of i) ischemic stroke, and ii) new ischemic stroke or silent brain infarction.","Modify,Clarity",Clarity
8251,6-36,6-36_v2_39@5,,"However, the converse may be the case for the free-living non-parasitic photosynthetic algae, Chromera velia and Vitrella brassicaformis , protists related to apicomplexans <REF-88> , <REF-89> .",,"Add,Fact/Evidence",Fact/Evidence
8252,6-36,6-36_v2_39@6,,"These groups of algae live freely in their environment, which unlike apicomplexans that depend on a host animal to survive <REF-88> .",,"Add,Fact/Evidence",Fact/Evidence
8253,6-36,6-36_v2_39@7,,"This adaptation may explain the difference in the clustering of their transporters after phylogenetic analysis, which separated on the minor clade from other apicomplexans that separated on the major clade.",,"Add,Claim",Claim
8254,6-36,6-36_v2_39@8,,This suggests a high level of evolutionary divergence between folate transporters in both the apicomplexans and these algae based on life-style adaptations.,,"Add,Claim",Claim
8255,6-36,6-36_v2_41@1,,"The folate transporter proteins were categorized into potential drug targeting features including mitochondrial localization, number of transmembrane helix, and protein sequence relatedness.",,"Add,Fact/Evidence",Fact/Evidence
8256,6-36,6-36_v2_45@1,,These data are available in a .xlsx file.,,"Add,Fact/Evidence",Fact/Evidence
8257,6-36,6-36_v2_46@0,,Dataset 2: Eukaryotic microbes from which folate transporters were identified.,,"Add,Fact/Evidence",Fact/Evidence
8258,6-36,,6-36_v1_3@1,,We also performed phylogenetic comparisons of identified proteins. .,"Delete,Fact/Evidence",Fact/Evidence
8259,6-36,,6-36_v1_4@2,,"The mitochondrion is the predicted location of the majority of the proteins, with 15% possessing signal peptides.","Delete,Fact/Evidence",Fact/Evidence
8260,6-36,,6-36_v1_44@1,,Our results show that these proteins that mediate the transportation folate are widely distributed in different pathogen species examined in various phyla.,"Delete,Fact/Evidence",Fact/Evidence
8261,6-36,,6-36_v1_2@3,,The folate synthesis and salvage pathway are important for eukaryote pathogen survival and organismal biology and may present new targets for drug discovery.,"Delete,Claim",Claim
8262,6-36,6-36_v2_3@0,,Methods : We developed automated search strategies in the Eukaryotic Pathogen Database Resources (EuPathDB) to construct a protein list and retrieve protein sequences of folate transporters encoded in the genomes of 200 eukaryotic microbes.,,"Add,Fact/Evidence",Fact/Evidence
8263,6-36,6-36_v2_3@1,,"The folate transporters were categorized according to features including mitochondrial localization, number of transmembrane helix, and protein sequence relatedness.",,"Add,Fact/Evidence",Fact/Evidence
8264,6-36,6-36_v2_4@1,,Phylogenetic analysis placed 219 proteins into a major clade and 15 proteins into a minor clade.,,"Add,Fact/Evidence",Fact/Evidence
8265,6-36,6-36_v2_4@2,,"All the folate transporter sequences from the malaria parasite, Plasmodium, belonged to the major clade.",,"Add,Fact/Evidence",Fact/Evidence
8266,6-36,6-36_v2_4@4,,About 60% of the identified proteins are reported for the first time.,,"Add,Fact/Evidence",Fact/Evidence
8267,6-36,,6-36_v1_13@0,,Our experiment workflow is depicted in Figure 1 .,"Delete,Fact/Evidence",Fact/Evidence
8268,6-36,,6-36_v1_3@0,,Methods: We applied a combination of bioinformatics methods to examine the genomes of pathogens in the EupathDB for genes encoding homologues of proteins that mediate folate salvage in a bid to identify and assign putative functions.,"Delete,Fact/Evidence",Fact/Evidence
8269,6-36,6-36_v2_16@2,,"The protein information are included in Dataset 1 <REF-43> and summarised in Dataset 2 <REF-44> , which are marked as either identified in other literature or in this research work.",,"Add,Fact/Evidence",Fact/Evidence
8270,6-36,6-36_v2_24@13,,The newick formats of the phylogenetic trees in Figure 2 – Figure 5 are presented as Supplementary Dataset 1 – Supplementary Dataset 4 .,,"Add,Fact/Evidence",Fact/Evidence
8271,6-36,6-36_v2_4@0,6-36_v1_4@0,"Results : We identified 234 folate transporter proteins associated with 63 eukaryotic microbes including 48 protozoa, 13 fungi the others being algae and bacteria.","Results: We identified 234 proteins to be involve in folate transport in 63 strains, 28 pathogen species and 12 phyla, 60% of which were identified for the first time.","Modify,Fact/Evidence",Fact/Evidence
8272,6-36,6-36_v2_4@3,6-36_v1_4@1,"The identified folate transporters include folate-binding protein YgfZ, folate/pteridine transporter, folate/biopterin transporter, reduced folate carrier family protein and folate/methotrexate transporter FT1.","Many of the genomes examined contained genes encoding transporters such as folate-binding protein YgfZ, folate/pteridine transporter, folate/biopterin transporter, reduced folate carrier family protein, folate/methotrexate transporter FT1.","Modify,Clarity",Clarity
8273,6-36,6-36_v2_0@0,6-36_v1_0@0,Characterization of potential drug targeting folate transporter proteins from Eukaryotic Pathogens,Genome-wide characterization of folate transporter proteins of eukaryotic pathogens,"Modify,Clarity",Clarity
8274,6-36,6-36_v2_18@0,6-36_v1_20@0,"A methodological search for folate transporters in all eukaryotic microbe genomes examined under EuPathDB with validation via GenBank, GeneDB and UniProt contained a total of 234 proteins (detail features of proteins are presented in Dataset 1 <REF-43> ).","A methodological search for folate transporters in all eukaryotic pathogen genomes we examined under EupathDB with validation via GenBank, GeneDB and Uniprot contained a total of 234 proteins (detail features of proteins are presented in Dataset 1 <REF-43> ).","Modify,Clarity",Clarity
8275,6-36,6-36_v2_18@1,6-36_v1_20@1,We identified these transporters in 28 pathogen species (containing 63 strains) cutting across 12 phyla ( Dataset 2 <REF-44> ).,We identified these transporters in 28 pathogen species (containing 63 strains) cutting across 12 phyla ( Table 1 ).,"Modify,Fact/Evidence",Fact/Evidence
8276,6-36,6-36_v2_18@3,6-36_v1_20@3,"While Aspergillus clavatus NRRL 1, A. flavus NRRL3357, A. macrogynus ATCC 38327, Crithidia fasciculata strain Cf-Cl and others have one folate transporter protein each ( Dataset 2 <REF-44> ).","While Aspergillus clavatus NRRL 1, A. flavus NRRL3357, A. macrogynus ATCC 38327, Crithidia fasciculata strain Cf-Cl and others have one folate transporter protein each ( Table 1 ).","Modify,Fact/Evidence",Fact/Evidence
8277,6-36,6-36_v2_21@0,6-36_v1_23@0,"Our literature search for parasite folate transporters on PubMed and Google Scholar indicated 60% (38 out 63) of the proteins were identified for the first time as presented in Dataset 2 <REF-44> , while 40% have been previously investigated.","Our literature search for parasite folate transporters on PubMed and Google Scholar indicated 60% (38 out 63) of the proteins were identified for the first time as presented in Table 1 and Figure 2C , while 40% have been previously investigated.","Modify,Fact/Evidence",Fact/Evidence
8278,6-36,6-36_v2_2@2,6-36_v1_2@2,The availability of genome sequences of many eukaryotic microbes is providing critical biological information for understanding parasite biology and identifying new drug and vaccine targets.,The availability of genome sequences of many eukaryotic protozoa is providing important data for understanding parasite biology and identifying new drug and vaccine targets.,"Modify,Claim",Claim
8279,6-36,6-36_v2_22@5,6-36_v1_24@5,Parasites such as Microsporidium daphniae UGP3 and the amoeba Naegleria fowleri ATCC 30863 possess the reduced folate carrier family protein.,Parasites such as Microsporidium daphniae UGP3 and the amoeba Naegleria fowleri ATCC 30863 possess the reduced folate carrier family protein ( Figure 2D ).,"Modify,Fact/Evidence",Fact/Evidence
8280,6-36,6-36_v2_22@8,6-36_v1_24@8,The remaining proteins are localized on the plasma membrane ( Dataset 1 <REF-43> ).,The remaining proteins are localized on the plasma membrane ( Dataset 1 <REF-43> and Figure 2D ).,"Modify,Fact/Evidence",Fact/Evidence
8281,6-36,6-36_v2_23@0,6-36_v1_25@0,Approximately 15% (34/234) of the folate transporters identified possess signal peptides with the trypanosomes with the most signal peptides.,Approximately 15% (34/234) of the folate transporters identified possess signal peptides ( Figure 2E ) with the trypanosomes with the most signal peptides.,"Modify,Fact/Evidence",Fact/Evidence
8282,6-36,6-36_v2_34@1,6-36_v1_37@1,We identified proteins that could mediate the salvage of folates into cells and/or mitochondria from eukaryotic microbe genomes in EuPathDB.,We identified proteins that could mediate the salvage of folates into cells and/or mitochondria from eukaryotic pathogen genomes in EupathDB.,"Modify,Clarity",Clarity
8283,6-36,6-36_v2_34@2,6-36_v1_37@2,Many of these proteins are involved in folate biosynthesis or transport and are present in most of the eukaryotic microbe genomes we queried.,Many of these proteins are involved in folate biosynthesis or transport and are present in many of the eukaryotic pathogens we queried.,"Modify,Clarity",Clarity
8284,6-36,6-36_v2_34@3,6-36_v1_37@3,"In this study, 234 genes encoding homologues of folate salvaging proteins were identified in the genome of 64 strains, representing 28 species of eukaryotic microbes.","In this study, 234 genes encoding homologues of folate salvaging proteins were identified in the genome of 64 strains, representing 28 species of eukaryotic pathogens.","Modify,Clarity",Clarity
8285,6-36,6-36_v2_34@4,6-36_v1_37@4,"Some of the pathogens among the microbes queried include P. falciparum 3D7 and IT, P. knowlesi H, P. berghei ANKA, P. chabaudi chabaudi, T. brucei Lister 427, T. brucei TREU927, T. brucei gambiense DAL972, Encephalitozoon cuniculi GB-M1.","Some of the pathogens include P. falciparum 3D7 and IT, P. knowlesi H, P. berghei ANKA, P. chabaudi chabaudi, T. brucei Lister 427, T. brucei TREU927, T. brucei gambiense DAL972, Encephalitozoon cuniculi GB-M1.","Modify,Clarity",Clarity
8286,6-36,6-36_v2_35@0,6-36_v1_38@0,"About 40% of the proteins we identified have been previously identified and characterized in parasites such as Plasmodium falciparum <REF-22> , <REF-30> , Trypanosome species <REF-26> , Leishmania species and Toxoplasma gondii <REF-50> .","A few of the proteins we identified have been previously identified and characterized in parasites such as Plasmodium falciparum <REF-22> , <REF-30> , Trypanosome species <REF-26> , Leishmania species and Toxoplasma gondii <REF-49> .","Modify,Fact/Evidence",Fact/Evidence
8287,6-36,6-36_v2_35@1,6-36_v1_38@1,"It has been estimated that over half of the drugs currently on the market target integral membrane proteins ion channel blockers like verapamil, and serotonin transporter inhibitors feature prominently in the WHO model list of essential medicines <REF-51> , <REF-52> .","It has been estimated that over half of the drugs currently on the market target integral membrane proteins of which membrane transporters are a part, but unfortunately, these transporters have not been adequately explored as drug targets <REF-50> .","Split+Modify,Fact/Evidence",Fact/Evidence
8288,6-36,6-36_v2_35@2,6-36_v1_38@1,"Unfortunately, a great number of these transporters have not been adequately explored as drug targets <REF-53> .","It has been estimated that over half of the drugs currently on the market target integral membrane proteins of which membrane transporters are a part, but unfortunately, these transporters have not been adequately explored as drug targets <REF-50> .","Split+Modify,Clarity",Clarity
8289,6-36,6-36_v2_36@7,6-36_v1_39@7,"Results from our study describing the presence of these transporters across several phyla corroborate results from other works establishing the conservation of folate transport function among FBT family proteins from plants and protists <REF-22> , <REF-56> .","Results from our study describing the presence of these transporters across several phyla corroborate results other researches, establishing the conservation of folate transport function among FBT family proteins from species from plants and protists <REF-22> , <REF-53> .","Modify,Clarity",Clarity
8290,6-36,6-36_v2_39@2,6-36_v1_42@2,The relatedness of these proteins across the different pathogens show that there are two major phylogenetically distinct clades in the eukaryotic pathogens examined.,The relatedness of these proteins across the different pathogens shows that there are two major phylogenetically distinct clades in the eukaryotic pathogens examined.,"Modify,Grammar",Grammar
8291,6-36,6-36_v2_41@0,6-36_v1_44@0,"In summary, we have retrieved information on 234 folate transporter proteins from Eukaryotic Pathogen Database (EuPathDB) resources.","In summary, we have identified and classified 234 proteins after an extensive search of pathogens genome in eukaryotic pathogen resource databases, though experimental studies will be required to confirm the expression and function of these proteins in parasites.","Modify,Fact/Evidence",Fact/Evidence
8292,6-36,6-36_v2_10@3,6-36_v1_10@3,"This is despite the sequencing of the genomes of most eukaryotic microbes, which has produced a vast wealth of data that could aid in identification of druggable pathogen-specific proteins <REF-33> – <REF-39> .","This is despite the sequencing of the genomes of most eukaryotic pathogens, which has produced a vast wealth of data that could aid in identification of druggable pathogen-specific proteins <REF-33> – <REF-39> .","Modify,Clarity",Clarity
8293,6-36,6-36_v2_13@6,6-36_v1_13@7,The complete list of proteins extracted from EuPathdb is presented in Dataset 1 <REF-43> .,The complete list of proteins extracted from Eupthadb is presented in Dataset 1 <REF-43> .,"Modify,Grammar",Grammar
8294,6-36,6-36_v2_13@8,6-36_v1_13@9,Gene sequences were obtained in FASTA format for transporter proteins using the sequence download tool on EuPathDB ( http://eupathdb.org/eupathdb/ ).,Gene sequences were obtained in FASTA format for transporter proteins using the sequence download tool on EupathDB ( http://eupathdb.org/eupathdb/ ).,"Modify,Grammar",Grammar
8295,6-36,6-36_v2_16@1,6-36_v1_16@1,"The protein sequence information ( Dataset 1 <REF-43> ) obtained from literature search was used for a BLAST search on EupathDB ( http://eupathdb.org/eupathdb/ ), UniprotDB ( http://www.uniprot.org ) and GeneDB ( http://www.genedb.org/Homepage ).","The protein sequence information ( Dataset 1 <REF-43> and Table 1 ) obtained from literature search was used for a BLAST search on EupathDB ( http://eupathdb.org/eupathdb/ ), UniprotDB ( http://www.uniprot.org ) and GeneDB ( http://www.genedb.org/Homepage ).","Modify,Fact/Evidence",Fact/Evidence
8296,6-445,6-445_v2_15@4,,"The diagnosis of diabetes mellitus, hypertension and chronic kidney disease were made based on the previous medical records of study population and controls.",,"Add,Fact/Evidence",Fact/Evidence
8297,6-445,6-445_v2_32@0,,"As seen in Figure 4 , maximum percentage of both the study population and controls have normal hearing.",,"Add,Fact/Evidence",Fact/Evidence
8298,6-445,6-445_v2_32@1,,Around 24% of both study population and controls have moderate hearing loss as per WHO criteria.,,"Add,Fact/Evidence",Fact/Evidence
8299,6-445,6-445_v2_50@5,,The lowest age group patient in this study was 34 years and patients below 50 years of age were very few in number so the first age group made was from 15–50 years.,,"Add,Fact/Evidence",Fact/Evidence
8301,6-445,6-445_v2_7@2,6-445_v1_7@1,"Because of improved nutrition and public health measures in the developed countries, the greatest cause of morbidity has been cardiovascular disease (CVD) and cancer.","Infections and malnutrition were the most common cause of death before 1900; nowadays in developed countries, because of improved nutrition and public health measures, the greatest cause of morbidity has been cardiovascular disease (CVD) and cancer.","Split+Modify,Clarity",Clarity
8302,6-445,6-445_v2_9@1,6-445_v1_9@1,The present study was done to explore the differences in hearing status between patients with cardiovascular disease on aspirin therapy and age matched controls.,The present study was done to explore the differences in hearing status between patients with cardiovascular disease on aspirin therapy and age matched healthy controls.,"Modify,Clarity",Clarity
8303,6-445,6-445_v2_2@1,6-445_v1_2@1,"This cross sectional, comparative study study aims to explore differences in hearing status between the cardiovascular disease patients on aspirin therapy and age matched controls.","This cross sectional, comparative study study aims to explore differences in hearing status between the cardiovascular disease patients on aspirin therapy and age matched healthy controls.","Modify,Clarity",Clarity
8304,6-445,6-445_v2_11@2,6-445_v1_11@2,This was a cross sectional comparative study.,"The objective of this cross sectional comparative study was to evaluate hearing level in patients on long term aspirin therapy (75mg, once a day) and to assess whether there was correlation between the severity of hearing loss and duration of aspirin therapy.","Modify,Fact/Evidence",Fact/Evidence
8305,6-445,6-445_v2_12@1,6-445_v1_12@1,"They were informed about the design and purpose of the study and requested to visit the ear, nose and throat outpatient department (ENT OPD) voluntarily to take part in the study.","They were informed about the design and purpose of the study and requested to visit the ear, nose and throat outpatient department (ENT OPD) to take part in the study voluntarily.","Modify,Clarity",Clarity
8306,6-445,6-445_v2_12@2,6-445_v1_12@2,The control population consisted of age matched controls who were not taking aspirin.,The control population consisted of age matched healthy controls who were not taking aspirin.,"Modify,Clarity",Clarity
8307,6-445,6-445_v2_15@3,6-445_v1_15@3,"Systemic causes of hearing loss e.g. Diabetes mellitus, hypertension, and chronic kidney disease, should also be noted.","Systemic causes of hearing loss e.g. Diabetes mellitus, hypertension, and chronic kidney disease, also had to be ruled out.","Modify,Claim",Claim
8308,6-445,6-445_v2_3@1,6-445_v1_3@1,The control population consisted of 221 age matched controls who were not taking aspirin.,The control population consisted of 221 age matched healthy controls who were not taking aspirin.,"Modify,Clarity",Clarity
8309,6-445,6-445_v2_4@0,6-445_v1_4@0,"Results : It was found that age of patient, not aspirin intake, was more important risk factor contributing to hearing loss.","Results: Not aspirin, but the age of the patient was found to be the important risk factor for hearing loss.","Modify,Clarity",Clarity
8310,6-445,6-445_v2_18@3,6-445_v1_18@3,"Among controls, 48.1% of the cases were male and 51.9% of the cases were female ( Table 1 ).","Among controls, 48.1% of the cases were male and 51.9% of the cases were female.","Modify,Fact/Evidence",Fact/Evidence
8311,6-445,6-445_v2_21@3,6-445_v1_19@3,"47.6% of the study population was in the 60–75 year age group; in the control group the number of participants in the 60–75 age group which was higher, with 48.4% ( Table 1 ).","47.6% of the study population was in the 60–75 year age group; in the control group the number of participants in the 60–75 age group which was higher, with 48.4%.","Modify,Fact/Evidence",Fact/Evidence
8312,6-445,6-445_v2_22@1,6-445_v1_20@1,"Among the controls, 60.1% were of Indo-Aryan origin and 39.9% were of East Asian origin ( Table 1 ).","Among the controls, 60.1% were of Indo-Aryan origin and 39.9% were of East Asian origin.","Modify,Fact/Evidence",Fact/Evidence
8313,6-456,6-456_v2_21@12,,"Furthermore, as stated before, PDC have been shown to infiltrate tumors <REF-33> – <REF-40> and the presence of infiltrating PDC have been associated with a poor prognosis in some tumors <REF-35> , <REF-36> , <REF-39> , <REF-40> .",,"Add,Fact/Evidence",Fact/Evidence
8314,6-456,6-456_v2_21@13,,"Defective type I IFN production by tumor-infiltrating PDC has been identified as one potential mechanism explaining tumor progression <REF-34> , <REF-35> , <REF-38> , <REF-91> , <REF-92> .",,"Add,Fact/Evidence",Fact/Evidence
8315,6-456,6-456_v2_21@15,,The pathological microenvironment in which PDC are present may impact on PDC metabolism and subsequently on their functions.,,"Add,Claim",Claim
8316,6-456,6-456_v2_21@16,,"This is particularly true for tumor-infiltrating PDC, since metabolic dysregulation is a common and well-recognized feature of cancer <REF-93> – <REF-95> .",,"Add,Fact/Evidence",Fact/Evidence
8317,6-456,6-456_v2_21@17,,"Today, this has been mainly studied in infiltrating T cells and macrophages.",,"Add,Claim",Claim
8318,6-456,6-456_v2_30@5,,Regions of hypoxia are also present in solid tumors <REF-95> infiltrated by PDC.,,"Add,Fact/Evidence",Fact/Evidence
8319,6-456,,6-456_v1_2@5,,Some differences may be related to the origin of PDC (human versus mouse PDC or blood-sorted versus FLT3 ligand stimulated-bone marrow-sorted PDC).,"Delete,Claim",Claim
8320,6-456,6-456_v2_57@6,,This may concern tumor-infiltrating PDC or PDC present in inflamed tissues.,,"Add,Claim",Claim
8321,6-456,,6-456_v1_10@1,,"As mentioned above, PDC-defining transcription factors have been identified, such as E2-2 (TCF4) or SPIB <REF-7> .","Delete,Fact/Evidence",Fact/Evidence
8322,6-456,6-456_v2_10@8,,"Moreover, PDC infiltrate several tumors including: melanoma <REF-33> , head and neck <REF-34> , breast <REF-35> – <REF-37> and ovarian <REF-38> – <REF-40> tumors.",,"Add,Fact/Evidence",Fact/Evidence
8323,6-456,6-456_v2_18@3,,PDC have been shown to prevent allo-immune responses in the setting of solid organ transplantation <REF-67> or after hematopoietic cell transplantation <REF-68> .,,"Add,Fact/Evidence",Fact/Evidence
8324,6-456,6-456_v2_18@4,,PDC participate also in oral tolerance <REF-69> .,,"Add,Fact/Evidence",Fact/Evidence
8325,6-456,6-456_v2_2@5,6-456_v1_2@6,The kinetics of glycolysis after TLR7/9 triggering may differ between human and murine PDC.,The kinetics of glycolysis may differ between human and murine PDC.,"Modify,Claim",Claim
8327,6-456,6-456_v2_2@7,6-456_v1_2@7,This could explain a delayed glycolysis in mouse PDC.,"In mouse PDC, metabolism changes promoted by TLR7/9 activation may depend on an autocrine/paracrine loop, implicating type I IFN and its receptor IFNAR, explaining a delayed glycolysis.","Split+Modify,Clarity",Clarity
8328,6-456,6-456_v2_2@9,6-456_v1_2@9,"This may occur via the production of lipid ligands that activate nuclear receptors (e.g., liver X receptor [LXR]) in PDC or through limiting intracellular cholesterol pool size (by statin or LXR agonist treatment) in these cells.","This may occur via the production of lipid ligands that activate nuclear receptors (e.g., liver X receptor [LXR]) in PDC or through limiting intracellular cholesterol pool size (by statins or LXR agonists) in these cells.","Modify,Clarity",Clarity
8329,6-456,6-456_v2_2@10,6-456_v1_2@10,"Finally, lipid-activated nuclear receptors (i.e., LXR or peroxisome proliferator activated receptor) may also directly interact with pro-inflammatory transcription factors, such as NF-κB.","Finally, lipid-activated nuclear receptors ( i.e ., LXR or peroxisome proliferator activated receptor) may also directly interact with pro-inflammatory transcription factors, such as NF-κB.","Modify,Grammar",Grammar
8330,6-456,6-456_v2_32@5,6-456_v1_32@5,"Thus, whether the origin of PDC (human <REF-4> versus mouse <REF-5> ) or their source (sorted from peripheral blood mononuclear cells <REF-4> versus sorted from FLT3 ligand-stimulated bone marrow cultures <REF-5> ) may explain this discrepancy remains to be determined.","Thus, whether the origin of PDC (human <REF-4> versus mouse <REF-5> ) or their source (sorted from peripheral blood mononuclear cells <REF-4> versus sorted from FLT3-stimulated ligand-bone marrow cultures <REF-5> ) may explain this discrepancy remains to be determined.","Modify,Clarity",Clarity
8331,6-456,6-456_v2_32@11,6-456_v1_32@11,The modulation of this metabolic pathway may limit uncontrolled pro-inflammatory cytokines by PDC in pathological situations or may restore type I IFN production in chronic infectious diseases or in solid tumors.,The modulation of this metabolic pathway may limit uncontrolled pro-inflammatory cytokines by PDC in pathological situations or may restore type I IFN production in chronic infectious diseases.,"Modify,Claim",Claim
8332,6-456,6-456_v2_34@5,6-456_v1_34@5,"These LXR or PPAR target genes code not only for enzymes involved in lipid metabolism, but also for transcription factors and transporters, and regulate also glucose or amino acid metabolism.","These LXR or PPAR target genes code not only for enzymes involved in lipid metabolism, but also for transcription factors and transporters, and regulate also to glucose or amino acid metabolism.","Modify,Grammar",Grammar
8333,6-456,6-456_v2_4@14,6-456_v1_4@14,"Furthermore, mTOR, through its association with regulatory-associated protein of mTOR (RAPTOR), constitutes the mTOR complex 1 (mTORC1), which is connected with other metabolic pathways (see a recent review <REF-8> and section 3.1).","Furthermore, mTOR, through its association with regulatory-associated protein of mTOR (RAPTOR), constitutes the mTOR complex 1 (mTORC1), which is connected with other metabolic pathways (see section 3.1).","Modify,Fact/Evidence",Fact/Evidence
8334,6-456,6-456_v2_49@4,6-456_v1_49@4,"Thus, LXR agonists could inhibit TLR7/9-mediated type I IFN by interfering with the mevalonate pathway ( i.e ., de novo cholesterol synthesis), as statins did.","Thus, LXR agonists could inhibit TLR7/9-mediated type I IFN by interfering with this signaling pathway together with massively decreasing the intracellular cholesterol pool size.","Split+Modify,Claim",Claim
8335,6-456,6-456_v2_49@5,6-456_v1_49@4,"Simultaneously, LXR agonists could stimulate type I IFN production as a result of a massive decrease in the intracellular cholesterol pool size.","Thus, LXR agonists could inhibit TLR7/9-mediated type I IFN by interfering with this signaling pathway together with massively decreasing the intracellular cholesterol pool size.","Split+Modify,Claim",Claim
8336,6-456,6-456_v2_49@6,6-456_v1_49@5,This compensatory mechanism could explain why IFN-α production is unaffected after LXR agonist treatment of PDC.,This could explain why IFN-α production is unaffected after LXR agonist treatment of PDC.,"Modify,Clarity",Clarity
8337,6-456,6-456_v2_51@1,6-456_v1_51@1,"These pathways comprise: the mTOR signaling pathway, glycolysis, FAO coupled to OXPHOS, fatty acid synthesis and cholesterol metabolism ( Table 1 ).","These pathways comprise: the mTOR signaling pathway, glycolysis, FAO coupled to OXPHOS, fatty acid synthesis and cholesterol metabolism.","Modify,Fact/Evidence",Fact/Evidence
8338,6-456,6-456_v2_51@3,6-456_v1_51@3,"Few data are available, but it seems that induction of pro-inflammatory cytokines (e.g., TNF, IL-6 and IL-8) and costimulatory molecules ( i.e ., CD80 or CD86) also need most of these metabolic pathways ( Table 1 ).","Few data are available, but it seems that induction of pro-inflammatory cytokines (e.g., TNF, IL-6 and IL-8) and costimulatory molecules ( i.e ., CD80 or CD86) also need most of these metabolic pathways.","Modify,Fact/Evidence",Fact/Evidence
8339,6-456,6-456_v2_51@4,6-456_v1_51@4,"On the contrary, alteration of cholesterol metabolism associated with decreased intracellular cholesterol content either after inhibition of de novo cholesterol synthesis or LXR activation inhibits the pro-inflammatory functions of PDC ( Table 1 ).","On the contrary, alteration of cholesterol metabolism associated with decreased intracellular cholesterol content either after inhibition of de novo cholesterol synthesis or LXR activation inhibits the pro-inflammatory functions of PDC.","Modify,Fact/Evidence",Fact/Evidence
8340,6-456,6-456_v2_57@8,6-456_v1_55@7,"This factor can be targeted with bortezomib, which disturbs ER homeostasis <REF-124> .","This factor can be targeted with bortezomib, which maintains ER homeostasis <REF-105> .","Modify,Fact/Evidence",Fact/Evidence
8341,6-456,6-456_v2_7@1,6-456_v1_7@1,"These features include: the capacity to rapidly and massively produce type I IFN ( i.e ., IFN-α/β), the expression of a particular set of pattern-recognition receptors (PRR), leading to the recognition of specific pathogen-associated molecular pattern (PAMP) and damage-associated molecular pattern (DAMP) molecules, as well as a preferential localization in lymphoid organs <REF-7> .","These features include: the capacity to rapidly and massively produce type I IFN ( i.e ., IFN-α/β), the expression of a particular set of pathogen-recognition receptors (PRR), leading to the recognition of specific pathogen-associated molecular pattern (PAMP) and damage-associated molecular pattern (DAMP) molecules, as well as a preferential localization in lymphoid organs <REF-7> .","Modify,Fact/Evidence",Fact/Evidence
8342,6-456,6-456_v2_2@3,6-456_v1_2@3,"Through these functions, PDC participate in antimicrobial responses or maintenance of immune tolerance, and have been implicated in the pathophysiology of several autoimmune diseases, as well as in tumor immune escape mechanisms.","Through these functions, PDC participate in antimicrobial responses or maintenance of immune tolerance, and have been implicated in the pathophysiology of several autoimmune diseases.","Modify,Fact/Evidence",Fact/Evidence
8343,6-456,6-456_v2_8@2,6-456_v1_8@2,"Human PDC are usually identified as CD4 + , CD303 + (previously known as BDCA-2), CD123 high , and CD11c - , whereas mouse PDC are CD11c int , B220 + , SIGLEC-H + , and CD317 + (also known as BST2 or PDCA1) <REF-7> .","Human PDC are usually identified as CD4 + , CD303 + (previously known as BDCA-2), and CD123 high , whereas mouse PDC are CD11c int , B220 + , SIGLEC-H + , and CD317 + <REF-7> .","Modify,Fact/Evidence",Fact/Evidence
8344,6-456,6-456_v2_8@3,6-456_v1_8@3,"Despite the difference in phenotypes of human and mouse PDC, PDC from both species exhibit a conserved genetic signature with some common genes (e.g., tlr7 or ifr7 ) <REF-21> .","Despite the difference in phenotypes of human and mouse PDC, PDC from both species exhibit a conserved genetic signature with some common genes (e.g., tlr7 ) <REF-20> .","Modify,Fact/Evidence",Fact/Evidence
8345,6-456,6-456_v2_10@1,6-456_v1_10@2,"After this differentiation step, PDC are released from the bone marrow to the blood for homing to different lymphoid tissues <REF-22> .","After differentiation in the bone marrow, PDC are released into the bloodstream for homing to different lymphoid tissues <REF-21> .","Modify,Clarity",Clarity
8380,7-103,7-103_v2_19@4,,"Dedoose is a powerful, feature-rich, collaborative web-based application for managing, analyzing and presenting qualitative and mixed methods research.",,"Add,Claim",Claim
8381,7-103,7-103_v2_19@5,,The software is applicable for Persian language and illustrates hierarchical linkage of codes for clear visualization of data structure.,,"Add,Claim",Claim
8382,7-103,7-103_v2_58@1,,"There is lack of appropriate studies, especially qualitative studies regarding defining social determinants of PMH in Iranian culture which can be considered as one of the most important strengths of this study.",,"Add,Claim",Claim
8383,7-103,7-103_v2_58@2,,Using the qualitative approach provides an in-depth understanding of the concept of PMH from the society perspective.,,"Add,Claim",Claim
8384,7-103,7-103_v2_58@3,,"Besides, maximum variation has been observed in the selection of study samples (marital status, occupation, gender and education).",,"Add,Fact/Evidence",Fact/Evidence
8385,7-103,7-103_v2_63@0,,"Data associated with the article are available under the terms of the Creative Commons Zero ""No rights reserved"" data waiver (CC0 1.0 Public domain dedication).",,"Add,Fact/Evidence",Fact/Evidence
8386,7-103,7-103_v2_43@1,7-103_v1_43@1,"In people’s view, spirituality is another of PMH’s personal dimension and emerged as a component of it.","In people's view, spirituality is another of PMH’s personal dimension and emerged as a component of it.","Modify,Grammar",Grammar
8387,7-103,7-103_v2_46@2,7-103_v1_46@2,"- - Acceptance of social norms “ In my view, a mentally healthy person respects law and lives according to the society’s established norms and customs… ” (Women`s group).","- - Acceptance of social norms "" In my view, a mentally healthy person respects law and lives according to the society's established norms and customs… "" (Women`s group).","Modify,Grammar",Grammar
8388,7-103,7-103_v2_46@3,7-103_v1_46@3,"- - Abiding and respecting law was another issue proposed in the social dimension, which was cited in the definition of PMH from participants’ perspective.","- - Abiding and respecting law was another issue proposed in the social dimension, which was cited in the definition of PMH from participants' perspective.","Modify,Grammar",Grammar
8389,7-103,7-103_v2_54@4,7-103_v1_54@4,"According to a study conducted in Singapore, positive thinking is able to affect promotion of PMH through interaction with people’s personality attributes <REF-25> .","According to a study conducted in Singapore, positive thinking is able to affect promotion of PMH through interaction with people's personality attributes <REF-25> .","Modify,Grammar",Grammar
8390,7-103,7-103_v2_58@0,7-103_v1_58@0,The present study has certain strengths and limitations.,The present study has certain limitations.,"Modify,Claim",Claim
8391,7-103,7-103_v2_59@0,7-103_v1_58@1,"Considering the study limitation, there is lack of generalizability and representativeness since the study was conducted using a qualitative method, and only its process and methodology can be generalized.","There is lack of generalizability and representativeness since the study was conducted using a qualitative method, and only its process and methodology can be generalized.","Modify,Clarity",Clarity
8392,7-103,7-103_v2_9@2,7-103_v1_9@2,"Using the slogan “mental health for all”, many countries have implemented extensive policies to promote mental health with an emphasis on its positive aspects <REF-8> .","Using the slogan ""mental health for all"", many countries have implemented extensive policies to promote mental health with an emphasis on its positive aspects <REF-8> .","Modify,Grammar",Grammar
8393,7-1030,7-1030_v2_8@4,,"A related alternative funding system is to fund all applications where reviewers agree on a high score, and then allocate the remaining budget at random where the reviewers disagreed but some reviewers gave the application a high score <REF-6> .",,"Add,Fact/Evidence",Fact/Evidence
8394,7-1030,7-1030_v2_22@0,,To graphically examine associations we used scatterplots of the total relative citations against the application score statistics.,,"Add,Fact/Evidence",Fact/Evidence
8395,7-1030,7-1030_v2_22@1,,"If a disagreement in scores indicates a high-risk high-return project, then there may be a greater variation in citations, with more unusually low and high citations for larger disagreements in scores.",,"Add,Claim",Claim
8396,7-1030,7-1030_v2_22@2,,To examine this we plotted the estimated inter-quartile range in total relative citations by grouping applications using a scatterplot smoothing span <REF-23> .,,"Add,Fact/Evidence",Fact/Evidence
8397,7-1030,7-1030_v2_22@3,,"We used a span of 20 applications which was based on trial and error, and weighted the estimated inter-quartile ranges using a Gaussian kernel <REF-23> .",,"Add,Fact/Evidence",Fact/Evidence
8398,7-1030,7-1030_v2_22@4,,"We used the inter-quartile range instead of the standard deviation because of the strong skew in citations, and the standard deviation was strongly influenced by the application with the highest citations.",,"Add,Fact/Evidence",Fact/Evidence
8399,7-1030,7-1030_v2_23@0,,Regression model,,"Add,Other",Other
8400,7-1030,7-1030_v2_50@0,,The inter-quartile ranges in total relative citations by the application scores’ mean and standard deviation are in Figure 4 .,,"Add,Fact/Evidence",Fact/Evidence
8401,7-1030,7-1030_v2_50@1,,There was a general reduction in the inter-quartile range as the application score mean increased.,,"Add,Fact/Evidence",Fact/Evidence
8402,7-1030,7-1030_v2_50@2,,"The interquartile range also reduced somewhat as the application score standard deviation increased, although the reduction was not as clear as that for the mean.",,"Add,Fact/Evidence",Fact/Evidence
8403,7-1030,7-1030_v2_62@5,,"It may be possible to measure disagreement using an observer who watches the panel dynamics <REF-30> , <REF-31> .",,"Add,Fact/Evidence",Fact/Evidence
8404,7-1030,7-1030_v2_69@0,,"We only had summary statistics on the application scores and hence we could not examine the distribution of scores to look for interesting patterns such as bimodality in scores, indicating a strong split in the peer review panel.",,"Add,Claim",Claim
8405,7-1030,7-1030_v2_44@2,7-1030_v1_37@2,This indicates the largest disagreement is where at least one panel member has given a poor score (remembering that the best possible score is 1.0 and the worst 5.0).,This indicates the largest disagreement is where at least one panel member has given a poor score (remembering lower scores are better).,"Modify,Fact/Evidence",Fact/Evidence
8406,7-1030,7-1030_v2_56@1,7-1030_v1_46@1,There was a reduction in citations for applications with a worse mean score.,There was a reduction in citations for applications with a higher (worse) mean score.,"Modify,Clarity",Clarity
8407,7-1030,7-1030_v2_60@0,7-1030_v1_50@0,"We found a statistically significant association between an application’s mean score and subsequent citations, with the result in the expected direction because applications with better scores had more citations (on average).","We found a statistically significant association between an application’s mean score and subsequent citation counts, with the result in the expected direction because applications with better scores had more citations (on average).","Modify,Clarity",Clarity
8408,7-1030,7-1030_v2_7@3,7-1030_v1_7@3,"A recent literature review found there are many unanswered questions in funding peer review, and concluded, “there is a need for open, transparent experimentation and evaluation of different ways to fund research” <REF-2> .","A recent systematic review found there are many unanswered questions in funding peer review, and concluded, “there is a need for open, transparent experimentation and evaluation of different ways to fund research” <REF-2> .","Modify,Clarity",Clarity
8409,7-1030,7-1030_v2_63@1,7-1030_v1_52@7,"Indeed, some recent research has indicated that there is more variability in scores across reviewers than across proposals <REF-34> and previous studies indicate inter-rater reliability as very low <REF-35> .","Indeed, some recent research has recently indicated that there is more variability in score across reviewers than across proposals <REF-31> and previous results indicate inter-rater reliability as very low <REF-32> .","Modify,Clarity",Clarity
8410,7-1030,7-1030_v2_64@3,7-1030_v1_52@13,"However, the scatter-plots in Figure 3 show no sign of an increasing variance in citations for higher standard deviations or ranges, and the inter-quartile ranges in citations in Figure 4 show a slight decrease for greater disagreements.","However, the scatter-plots in Figure 3 show no sign of an increasing variance in citations for higher standard deviations or ranges.","Modify,Fact/Evidence",Fact/Evidence
8411,7-1030,7-1030_v2_66@1,7-1030_v1_54@1,"Studies that follow funded and unfunded fellowship applicants are possible, e.g., Bornmann et al (2008) <REF-39> , but this is very difficult when examining projects that need specific funding <REF-40> .","Studies that follow funded and unfunded fellowship applicants are possible, e.g., <REF-36> , but this is very difficult when examining projects that need specific funding <REF-37> .","Modify,Fact/Evidence",Fact/Evidence
8412,7-1030,7-1030_v2_7@4,7-1030_v1_7@4,An earlier systematic review similarly concluded that studies to examine the accuracy and soundness of funding peer review are “urgently needed” <REF-3> .,A prior systematic review similarly concluded that studies to examine the accuracy and soundness of funding peer review are “urgently needed” <REF-3> .,"Modify,Clarity",Clarity
8414,7-1030,7-1030_v2_68@2,7-1030_v1_55@3,"It would also be useful to repeat the study in larger sample sizes, particularly because any conclusions could be influenced by a small proportion of applications that have a very high pay-off.",It would be useful to examine whether reviewer disagreement is associated with research impact in other funding schemes and in larger sample sizes.,"Split+Modify,Claim",Claim
8415,7-1030,7-1030_v2_7@5,7-1030_v1_7@5,Whilst a systematic review of innovations focused specifically on studies aiming to improve the effectiveness and efficiency in peer review funding found only eight studies and called for more studies of peer review <REF-4> .,Whilst a systematic review of innovations for effectiveness and efficiency in peer review funding found only eight studies and called for more studies <REF-4> .,"Modify,Clarity",Clarity
8416,7-1030,7-1030_v2_10@0,7-1030_v1_10@0,"A recent literature review found “suggestive” evidence that funding peer review can have an anti-innovation bias <REF-2> , whilst a survey of applicants and reviewers found that innovation and risk may not often be sufficiently addressed in review feedback <REF-8> .",A recent systematic review found “suggestive” evidence that funding peer review can have an anti-innovation bias <REF-2> and that innovation and risk may not often be sufficiently addressed in review feedback <REF-7> .,"Modify,Fact/Evidence",Fact/Evidence
8417,7-1030,7-1030_v2_10@2,7-1030_v1_10@2,Some researchers feel they need to write conservative applications that please all members of the panel to achieve a good mean score <REF-10> .,Some researchers feel they need to write conservative applications that please all members of the panel to achieve a good average score <REF-9> .,"Modify,Clarity",Clarity
8418,7-1030,7-1030_v2_11@1,7-1030_v1_11@1,Many studies using large sample sizes found either no association or only a weak association between the mean score and the number of citations of subsequent publications <REF-13> – <REF-17> .,Many studies using large sample sizes found either no association or only a weak association between the mean score and the citations of subsequent publications <REF-12> – <REF-16> .,"Modify,Clarity",Clarity
8419,7-1030,7-1030_v2_11@2,7-1030_v1_11@2,"Other studies have shown a positive association between better mean peer review scores and increased citations <REF-18> , <REF-19> , including a study that used the same data analyzed here <REF-20> .","Other studies have shown a positive association between higher mean peer review scores and increased citations <REF-17> , <REF-18> , including a study that used the same data analyzed here <REF-19> .","Modify,Clarity",Clarity
8420,7-1030,7-1030_v2_15@3,7-1030_v1_15@3,In this study we also consider statistics that measure within-panel disagreement which are the standard deviation and the range (largest minus smallest score).,"In this study we also consider statistics that measure within-panel disagreement, which are the standard deviation and the range (largest minus smallest score).","Modify,Grammar",Grammar
8421,7-1030,7-1030_v2_18@3,7-1030_v1_18@3,"These published average rates were determined for 2000 to 2010 by scientific field, assessed in 2011 and displayed a linear relationship with time (e.g., R 2 = 0.99 for the field of molecular biology).","These published average rates were determined for 2000–2010 by scientific field, assessed in 2011 and displayed a linear relationship with time (e.g., R 2 = 0.99 for the field of molecular biology).","Modify,Grammar",Grammar
8422,7-1133,7-1133_v2_28@3,,The staining and mounting method described are suitable for both upright and inverted microscopy.,,"Add,Claim",Claim
8423,7-1133,7-1133_v2_29@0,,"Following capture, images can be analysed for relevant parameters using FIJI (ImageJ) software.",,"Add,Claim",Claim
8424,7-1133,7-1133_v2_29@1,,To measure the length of cilia use the segmented line tool on a maximum intensity projection of a z-stack.,,"Add,Claim",Claim
8425,7-1133,7-1133_v2_29@2,,"KV volume can be calculated using the area delineated by aPCK; to obtain a good approximation of the average radius, use the oval tool to outline the KV and measure the area.",,"Add,Claim",Claim
8426,7-1133,7-1133_v2_29@3,,"Note that although the KV may appear as an ellipse in the section, it should be modelled in 3D as a sphere.",,"Add,Claim",Claim
8427,7-1133,7-1133_v2_29@4,,"Using the area of the KV in 2D, calculate the average radius ( r = A / π ) and subsequently the volume ( V = 4 3 π r 3 ).",,"Add,Claim",Claim
8428,7-1133,7-1133_v2_42@3,,Typical volumes are 2 ml for washes and 200 μl of antibody solution.,,"Add,Fact/Evidence",Fact/Evidence
8429,7-1133,7-1133_v2_32@0,7-1133_v1_31@0,"Fluorescent microscopy images were captured using an Axio Imager Z1 fluorescent microscope (Zeiss), using an apotome for optical sectioning and a Colibri light source and filter sets for DAPI (blue), Alexa Fluor488 (green) and Alexa Fluor 594 (Red) with a 20X air objective.","Fluorescent microscopy images were captured using an Axio Imager Z1 fluorescent microscope (Zeiss), using a Colibri light source and filter sets for DAPI (blue), Alexa Fluor488 (green) and Alexa Fluor 594 (Red) with a 20X lens.","Modify,Fact/Evidence",Fact/Evidence
8430,7-1133,7-1133_v2_42@2,7-1133_v1_41@2,Using 2-ml glass vials allows for staining in a small volume of liquid (≤200 µl) which helps to reduce reagent costs and reduces the storage space required.,Using 2-ml glass vials allows for staining in a small volume of liquid (<200 µl) which helps to reduce reagent costs and reduces the storage space required.,"Modify,Fact/Evidence",Fact/Evidence
8431,7-1133,7-1133_v2_57@7,7-1133_v1_56@7,"Nearly all new ciliopathy syndromes described in man use zebrafish, and their KV in particular, to gain insights into disease pathogenesis (use of zebrafish as a model for human ciliopathies is reviewed in Song et al ., 2016 <REF-2> ).","Nearly all new ciliopathy syndromes described in man use zebrafish, and their KV in particular, to gain insights into disease pathogenesis.","Modify,Fact/Evidence",Fact/Evidence
8432,7-1133,7-1133_v2_57@8,7-1133_v1_56@8,"Genetic knockdowns can cause defects in KV that may affect the size and structure of the organ as well as the cilia, and RNA rescue can determine the specificity of this effect.","Genetic knockdowns can cause defects in KV that may affect the size and structure of the organ as well as the cilia, and RNA rescue can determine the specificity of this affect.","Modify,Grammar",Grammar
8433,7-1133,7-1133_v2_57@9,7-1133_v1_56@9,"The study of KV therefore provides an accessible tool for the modelling of ciliopathies and interventions, such as genetic therapies and pharmacological agents <REF-20> , which may be used to rescue underlying cilia defects.","The study of KV therefore provides an accessible tool for the modelling of ciliopathies and interventions, such as genetic therapies and pharmacological agents, which may be used to rescue underlying cilia defects.","Modify,Fact/Evidence",Fact/Evidence
8456,7-1297,7-1297_v2_77@5,,These results closely mimic benchmarking results observed by Duò et al. <REF-33> on independent silver standard and simulated datasets across multiple single cell technologies.,,"Add,Claim",Claim
8457,7-1297,7-1297_v2_80@0,,We also investigated whether properties of the clustering method correlated with their performance.,,"Add,Fact/Evidence",Fact/Evidence
8458,7-1297,7-1297_v2_80@1,,We found that neither the type of clustering method used nor the similarity metric used seemed to correlate with the performance.,,"Add,Fact/Evidence",Fact/Evidence
8459,7-1297,7-1297_v2_80@2,,"However, our ability to identify patterns might have been impacted by the small sample size.",,"Add,Claim",Claim
8460,7-1297,7-1297_v2_80@3,,"A recent paper by Kim et al. <REF-34> , which systematically studied the effect of different similarity metrics on performance of scRNA-seq clustering methods, found that correlation-based similarity metrics outperformed distance-based metrics.",,"Add,Fact/Evidence",Fact/Evidence
8461,7-1297,7-1297_v2_81@0,,Conclusion,,"Add,Other",Other
8462,7-1297,7-1297_v2_85@2,,"Methods requiring no parameter choices, like Cell Ranger , may offer a better choice for non-experts.",,"Add,Claim",Claim
8463,7-1297,,7-1297_v1_20@1,,Note that we aligned reads with Cell Ranger to the GRCh38 (version 90) genome annotation.,"Delete,Fact/Evidence",Fact/Evidence
8464,7-1297,,7-1297_v1_28@4,,"Finally, we also use a homogeneity score <REF-27> .","Delete,Fact/Evidence",Fact/Evidence
8465,7-1297,,7-1297_v1_28@7,,"Unlike NMI and ARI, this score requires knowledge of an underlying truth.","Delete,Claim",Claim
8466,7-1297,,7-1297_v1_42@2,,"Similarly, we used Dataset 1 for the robustness evaluation with regards to genes, since it had the most number of non-zero genes after filtering.","Delete,Fact/Evidence",Fact/Evidence
8467,7-1297,,7-1297_v1_44@1,,"We randomly filtered half of all genes in Dataset 1 (out of the total of 58,302 genes), generating 10 datasets.","Delete,Fact/Evidence",Fact/Evidence
8468,7-1297,,7-1297_v1_44@2,,For every combination of two datasets (45 combinations in total) we then investigated for each clustering method separately how often cells were assigned to the same cluster using the ARI_comp.,"Delete,Fact/Evidence",Fact/Evidence
8469,7-1297,,7-1297_v1_58@2,,"For all three datasets, a group of five methods ( RCA , scran , Seurat , SIMLR and TSCAN ) produced similar results, while the other seven methods appeared dissimilar between each other and to the set of five methods.","Delete,Fact/Evidence",Fact/Evidence
8470,7-1297,,7-1297_v1_61@3,,"The robustness of ascend , countClust and RaceID was variable.","Delete,Fact/Evidence",Fact/Evidence
8471,7-1297,,7-1297_v1_61@5,,"Seurat , SIMLR and Cell Ranger demonstrated robustness with regards to input, but also exhibited robustness when changing gene filtering procedures (compare Figure 4b ).","Delete,Fact/Evidence",Fact/Evidence
8472,7-1297,,7-1297_v1_61@6,,"CIDR appeared to be very sensitive to changes in gene filtering, which may be due to its imputation feature.","Delete,Claim",Claim
8473,7-1297,,7-1297_v1_67@4,,Their fast running time is due to both of these methods offering little flexibility or intermediate results during their analysis (compare Table 1 ).,"Delete,Fact/Evidence",Fact/Evidence
8474,7-1297,,7-1297_v1_67@5,,By contrast Seurat ’s relatively long running time is partially due to extensive quality control during the analysis.,"Delete,Claim",Claim
8475,7-1297,,7-1297_v1_79@0,,Our evaluations suggest that Seurat and Cell Ranger provide the most stable and accurate clustering solutions for 10x Genomics scRNA-seq data.,"Delete,Claim",Claim
8476,7-1297,,7-1297_v1_79@2,,More generally we find that different clustering methods resulted in very different solutions.,"Delete,Fact/Evidence",Fact/Evidence
8477,7-1297,,7-1297_v1_79@3,,The good performance of Seurat as well as the vast difference between clustering methods have also been observed by Duò et al. <REF-32> in a benchmarking study including multiple scRNA-seq protocols.,"Delete,Fact/Evidence",Fact/Evidence
8478,7-1297,,7-1297_v1_79@4,,"Our investigations suggest that biological differences between cells, such as cell type or state, and technical variation between cells (as well as combinations of biological differences and technical variation) all drive clustering.","Delete,Claim",Claim
8479,7-1297,,7-1297_v1_79@5,,"However, which aspects are captured by which clustering method remain to be confirmed.","Delete,Claim",Claim
8480,7-1297,,7-1297_v1_79@6,,"Our study merely pinpoints some of the drivers of performance, but not their origin, and thus cannot anoint an overall best method.","Delete,Claim",Claim
8481,7-1297,7-1297_v2_10@3,,"Since many methods are still being actively developed, we include assessment of program versions available in October 2017 and April 2018.",,"Add,Fact/Evidence",Fact/Evidence
8482,7-1297,7-1297_v2_20@1,,"Note that, Cell Ranger filters any barcode that contains less than 10% of the 99 th percentile of total UMI counts per barcode, as these are considered to be barcodes associated with empty droplets.",,"Add,Fact/Evidence",Fact/Evidence
8483,7-1297,7-1297_v2_20@2,,"The barcode by design can take one of 737,000 different sequences that comprise a whitelist.",,"Add,Fact/Evidence",Fact/Evidence
8484,7-1297,7-1297_v2_20@3,,This feature allows the performance of error correction when the observed barcode does not match any barcode on the whitelist due to sequencing error.,,"Add,Fact/Evidence",Fact/Evidence
8485,7-1297,7-1297_v2_21@0,,Preprocessed versions of Datasets 2-5 were available in the R package TENxPBMCData .,,"Add,Fact/Evidence",Fact/Evidence
8486,7-1297,7-1297_v2_21@1,,"However, preprocessing was conducted with a CellRanger modified version of GRCh38 (version90) genome annotation resulting in slightly different versions for Dataset 2 and 3, referred to as Dataset 2a and Dataset 3a.",,"Add,Fact/Evidence",Fact/Evidence
8487,7-1297,7-1297_v2_23@6,,During the second evaluation of the methods (R version 3.5.0) only 11 methods were still functional.,,"Add,Fact/Evidence",Fact/Evidence
8488,7-1297,7-1297_v2_23@7,,SIMLR resulted in R aborting and had to be excluded.,,"Add,Fact/Evidence",Fact/Evidence
8489,7-1297,7-1297_v2_27@0,,"To evaluate the performance of the different clustering methods with regards to an underlying truth, we use the ARI as well as a homogeneity score <REF-24> .",,"Add,Fact/Evidence",Fact/Evidence
8490,7-1297,7-1297_v2_27@3,,"Unlike ARI, this score does not penalize members of a single group being split into several clusters and thus serves as a complimentary score to the ARI.",,"Add,Fact/Evidence",Fact/Evidence
8491,7-1297,7-1297_v2_27@4,,"Furthermore, bounded ranges and no assumptions regarding cluster structures are properties of both the ARI with regards to ground truth and the homogeneity score.",,"Add,Claim",Claim
8492,7-1297,7-1297_v2_35@0,,"We evaluated accuracy, robustness and running time for all methods (for detailed benchmarking plan see Supplementary Table 2 ).",,"Add,Fact/Evidence",Fact/Evidence
8493,7-1297,7-1297_v2_35@1,,"For some assessments we tested methods both in R version 3.4.3 and R version 3.5.0, other assessments were only performed for one R version.",,"Add,Fact/Evidence",Fact/Evidence
8494,7-1297,7-1297_v2_36@1,,The gold standard dataset consists of a mixture of three human lung adenocarcinoma cell lines in equal proportions.,,"Add,Fact/Evidence",Fact/Evidence
8495,7-1297,7-1297_v2_36@2,,"As the library preparation requires mixing these cells, the origin of each sequenced cell is technically unknown.",,"Add,Claim",Claim
8496,7-1297,7-1297_v2_36@7,,Note that the gold standard dataset was only used during the first evaluation (R version 3.4.3).,,"Add,Fact/Evidence",Fact/Evidence
8497,7-1297,7-1297_v2_38@0,,Note that the first evaluation (R version 3.4.3) was performed with Datasets 1-3.,,"Add,Fact/Evidence",Fact/Evidence
8498,7-1297,7-1297_v2_38@1,,"The second evaluation (R version 3.5.0) was performed on Datasets 2-5, as these were available in the R package TENxPBMCData .",,"Add,Fact/Evidence",Fact/Evidence
8499,7-1297,7-1297_v2_40@1,,We also investigated the robustness of different methods with regards to different stringency of gene filtering.,,"Add,Fact/Evidence",Fact/Evidence
8500,7-1297,7-1297_v2_41@4,,In the second evaluation (R version 3.5.0) we used Dataset 5.,,"Add,Fact/Evidence",Fact/Evidence
8501,7-1297,7-1297_v2_41@5,,"Here, we randomly sampled 4,000 cells (out of the total of 8,381 that were available after filtering), generating five (non-independent) datasets.",,"Add,Fact/Evidence",Fact/Evidence
8502,7-1297,7-1297_v2_41@6,,We then repeated the evaluation procedure described above.,,"Add,Fact/Evidence",Fact/Evidence
8503,7-1297,7-1297_v2_41@7,,We also investigated the variability of ARI_truth for all methods in both evaluations.,,"Add,Fact/Evidence",Fact/Evidence
8504,7-1297,7-1297_v2_42@1,,Impact of gene filtering was only investigated for methods available in R version 3.5.0 during the second evaluation.,,"Add,Fact/Evidence",Fact/Evidence
8505,7-1297,7-1297_v2_42@2,,"We analyzed Dataset 4, as it had the most detected genes, with 10%, 20%, 30%, 40% and 50% of the most expressed genes (total counts).",,"Add,Fact/Evidence",Fact/Evidence
8506,7-1297,7-1297_v2_42@3,,"We investigated both the ARI_comp with regards to the clustering solution produced on a version of the dataset with no gene filtering, as well as the ARI_truth.",,"Add,Fact/Evidence",Fact/Evidence
8507,7-1297,7-1297_v2_43@6,,Note that this was only done for the evaluation with methods available in R version 3.4.3.,,"Add,Fact/Evidence",Fact/Evidence
8508,7-1297,7-1297_v2_58@2,,This is probably due to the vast differences in filtering and data normalization between the methods.,,"Add,Claim",Claim
8509,7-1297,7-1297_v2_61@0,,Most methods had comparable performance on Datasets 2/2a and 3/3a in the first and second evaluation.,,"Add,Fact/Evidence",Fact/Evidence
8510,7-1297,7-1297_v2_61@1,,Consistent performance increases were only noted for countClust and Seurat (compare Supplementary Figure 3 ).,,"Add,Fact/Evidence",Fact/Evidence
8511,7-1297,7-1297_v2_62@4,,"In contrast, changes to gene filtering seemed to result in method specific effects, probably owing to individual filtering and normalization procedures.",,"Add,Claim",Claim
8512,7-1297,7-1297_v2_62@5,,"The performance of Seurat improved dramatically with the inclusion of more genes, whereas it deteriorated for RaceID .",,"Add,Fact/Evidence",Fact/Evidence
8513,7-1297,7-1297_v2_62@6,,"In contrast, both Cell Ranger and SC3 exhibited stable performance when the percentage of highly expressed genes was varied.",,"Add,Fact/Evidence",Fact/Evidence
8514,7-1297,7-1297_v2_68@4,,Considerable faster running times in evaluation 2 (R version 3.5.0) than in evaluation 1 (R version 3.4.3) were reported for Seurat and SC3 (compare Supplementary Figure 9 ).,,"Add,Fact/Evidence",Fact/Evidence
8515,7-1297,7-1297_v2_68@5,,"They were the second and third fastest methods in evaluation 2 respectively, despite offering more intermediate steps than most methods.",,"Add,Fact/Evidence",Fact/Evidence
8516,7-1297,7-1297_v2_77@0,,We also summarized the performance of each method across all evaluations (see Figure 9 ).,,"Add,Fact/Evidence",Fact/Evidence
8517,7-1297,7-1297_v2_77@1,,"This summary suggests that Seurat provides the best clustering solutions for 10x Genomics scRNA-seq data in terms of running time, robustness and accuracy.",,"Add,Fact/Evidence",Fact/Evidence
8518,7-1297,7-1297_v2_77@2,,"The next best performing methods were RCA , SC3 , Cell Ranger and CIDR .",,"Add,Fact/Evidence",Fact/Evidence
8519,7-1297,7-1297_v2_77@3,,"However, it should be noted that RCA performed particularly poorly on the gold standard dataset.",,"Add,Fact/Evidence",Fact/Evidence
8520,7-1297,7-1297_v2_77@4,,This highlights that RCA ’s performance hinges on the studied cell types being represented in the reference used during the supervised clustering approach.,,"Add,Claim",Claim
8521,7-1297,7-1297_v2_14@1,7-1297_v1_14@1,"Three human lung adenocarcinoma cell lines, HCC827, H1975 and H2228, were cultured separately <REF-6> .","Three human lung adenocarcinoma cell lines, HCC827, H1975 and H2228, were cultured separately.","Modify,Fact/Evidence",Fact/Evidence
8522,7-1297,7-1297_v2_14@4,7-1297_v1_14@4,"Before mixing cell lines, cells were dissociated into single-cell suspensions in FACS buffer (phosphate-buffered saline (PBS), catalog number: 14190-144; Thermo Fisher Gibco) with 5% FBS (catalog number: 35-076-CV; Corning), stained with propidium iodide (catalog number: P21493; Thermo Fisher FluoroPure) and 120,000 live cells were sorted for each cell line by FACS (BD FACSAria III flow cytometer, BD FACSDiva software version 7.0; BD Biology) to acquire an accurate equal mixture of live cells from the three cell lines.","Before mixing cell lines, cells were dissociated into single-cell suspensions in FACS buffer (phosphate-buffered saline (PBS); catalog number: 14190-144; Thermo Fisher Gibco) with 5% FBS, Corning, catalog number: 35-076-CV), stained with propidium iodide (catalog number: P21493; Thermo Fisher FluoroPure) and 120,000 live cells were sorted for each cell line by FACS (BD FACSAria III flow cytometer, BD FACSDiva software version 7.0; BD Biology) to acquire an accurate equal mixture of live cells from the three cell lines.","Modify,Grammar",Grammar
8523,7-1297,7-1297_v2_14@6,7-1297_v1_14@6,"Afterwards the library was sequenced using Illumina NextSeq500 and V4 chemistry (NextSeq 500/550 High Output Kit v2.5, 150 Cycles, catalog number: 20024907; Iluumina) with 100bp paired end reads.","Afterwards the library was sequenced using Illumina NextSeq500 and V4 chemistry (NextSeq 500/550 High Output Kit v2.5, 150 Cycles, catalog number; 20024907; Illumina) with 100bp paired end reads.","Modify,Grammar",Grammar
8524,7-1297,7-1297_v2_17@1,7-1297_v1_17@1,We consider five fresh human peripheral blood mononuclear cells (PBMCs) scRNA-seq datasets to be the silver standard ( Table 2 ).,We consider three human peripheral blood mononuclear cells (PBMCs) scRNA-seq datasets to be the silver standard ( Table 2 ).,"Modify,Fact/Evidence",Fact/Evidence
8525,7-1297,7-1297_v2_17@2,7-1297_v1_17@2,All datasets were generated using the 10x Genomics droplet system combined with Illumina sequencing.,All datasets were generated using the 10X Genomics droplet system combined with Illumina sequencing.,"Modify,Grammar",Grammar
8526,7-1297,7-1297_v2_17@4,7-1297_v1_17@4,Four datasets were generated by 10x Genomics and are publicly available (Datasets 2-5).,Two datasets were generated by 10x Genomics and are publicly available (Datasets 2 and 3).,"Modify,Fact/Evidence",Fact/Evidence
8527,7-1297,7-1297_v2_17@5,7-1297_v1_17@5,"Of these, Datasets 2 and 4 were generated with an earlier version of the microfluidics instrument, the 10x Genomics GemCode Controller ( Dataset 2 , Dataset 4 ).","Of these, one dataset was generated with an earlier version of the microfluidics instrument, the 10x Genomics GemCode Controller ( Dataset 2 ).","Modify,Fact/Evidence",Fact/Evidence
8528,7-1297,7-1297_v2_17@6,7-1297_v1_17@6,"Datasets 3 and 5 were generated with the latest instrument, the 10x Genomics Chromium Controller ( Dataset 3 , Dataset 5 ).","The second dataset was generated with the latest instrument, the 10x Genomics Chromium Controller ( Dataset 3 ).","Modify,Fact/Evidence",Fact/Evidence
8529,7-1297,7-1297_v2_18@0,7-1297_v1_18@0,"For Dataset 1, PBMCs were isolated from whole blood obtained through the Australian Red Cross Blood Service in the following manner.","For the first dataset, PBMCs were isolated from whole blood obtained through the Australian Red Cross Blood Service in the following manner.","Modify,Clarity",Clarity
8530,7-1297,7-1297_v2_18@3,7-1297_v1_18@3,"We then centrifuged at room temperature for 20 minutes at 400 g and carefully removed the interface layer containing PBMCs, located between the top plasma layer and middle layer (Heraeus Multifuge 3 S-R Centrifuge, Thermo Fisher Scientific).","We then centrifuged at room temperature for 20 minutes at 400 g and carefully removed the interface layer containing PBMCs, located between the top plasma layer and middle layer (Heraeus Multifuge 3 S-R Centrifuge; Thermo Fisher Scientific).","Modify,Grammar",Grammar
8531,7-1297,7-1297_v2_18@6,7-1297_v1_18@6,"Finally, cells were resuspended in 20ml of cell culture media with 5% FBS (RPMI-1640 Medium, catalog number: R0884-500ml, Sigma-Aldrich) and counted (Nikon Eclipse TS100 Microscope, Nikon).","Finally, cells were resuspended in 20ml of cell culture media with 5% FBS (RPMI-1640 Medium, catalog number: R0884-500ml, Sigma-Aldrich) and counted (Nikon Eclipse TS100 Microscope; Nikon).","Modify,Grammar",Grammar
8532,7-1297,7-1297_v2_18@9,7-1297_v1_18@9,"RTA (version 1.18.66.3, Illumina) was used for base calling.",RTA (version 1.18.66.3; Illumina) was used for base calling.,"Modify,Grammar",Grammar
8533,7-1297,7-1297_v2_20@0,7-1297_v1_20@0,"For Datasets 1-3, we used the 10x Genomics software version 2.0.0, Cell Ranger to align to the GRCh38 (version 90) genome annotation, de-duplicate, filter barcodes and quantify genes.","We used the 10x Genomics software, Cell Ranger (version 2.0.0) to align, de-duplicate, filter barcodes and quantify genes for all datasets.","Modify,Fact/Evidence",Fact/Evidence
8534,7-1297,7-1297_v2_34@0,7-1297_v1_21@0,Performance assessment,Establishing truth,"Modify,Other",Other
8535,7-1297,7-1297_v2_36@3,7-1297_v1_22@1,By exploiting the genetic differences between the three different cell lines we were able to establish the cell line of origin for each cell in the gold standard dataset.,By exploiting the genetic differences between the three different cell lines we were able to establish near absolute truth in the gold standard dataset.,"Modify,Fact/Evidence",Fact/Evidence
8536,7-1297,7-1297_v2_23@0,7-1297_v1_25@0,We based our selection of method on the online list within www.scRNA-tools.org <REF-2> in October 2017.,We based our selection of method on the online list within www.scrna-tools.org <REF-2> in October 2017.,"Modify,Grammar",Grammar
8537,7-1297,7-1297_v2_23@4,7-1297_v1_25@3,We also excluded any methods that continually failed to run (e.g. Linnorm <REF-19> because computation would time out and Monocle <REF-20> because calculation of dispersion resulted in errors).,We also excluded any methods that continually failed to run (e.g. Linnorm <REF-22> and Monocle <REF-23> ).,"Modify,Fact/Evidence",Fact/Evidence
8538,7-1297,7-1297_v2_23@5,7-1297_v1_25@4,This resulted in the evaluation of 12 methods (see Table 1 and for further details see Supplementary Table 1 ) in the first evaluation (R version 3.4.3).,This resulted in the evaluation of 12 methods (see Table 1 ).,"Modify,Fact/Evidence",Fact/Evidence
8539,7-1297,7-1297_v2_24@1,7-1297_v1_26@1,"Hence, we used all clustering methods with their default parameters as this represents the most common use case.","Hence, we use all clustering methods with their default parameters as this represents the most common use case.","Modify,Grammar",Grammar
8540,7-1297,7-1297_v2_24@2,7-1297_v1_26@2,"In the case of countClust and SIMLR parameters included the number of clusters, which we set to 3, 8 and 20 for the gold standard, silver standard datasets in evaluation 1 (R version 3.4.3) and silver standard datasets in evaluation 2 (R version 3.5.0), respectively.","In the case of countClust and SIMLR parameters included the number of clusters, which we set to 3 and 8 for the gold standard and silver standard datasets, respectively.","Modify,Fact/Evidence",Fact/Evidence
8541,7-1297,7-1297_v2_26@0,7-1297_v1_28@0,"To evaluate the similarity of different clustering solutions, we rely on two different metrics.","To evaluate the performance and similarity of different clustering solutions, we rely on three different metrics.","Modify,Fact/Evidence",Fact/Evidence
8542,7-1297,7-1297_v2_27@1,7-1297_v1_28@5,The homogeneity score takes the value 1 when all of its clusters contain only data points that are members of a single known group.,This score takes the value 1 when all of its clusters contain only data points that are members of a single known group.,"Modify,Clarity",Clarity
8543,7-1297,7-1297_v2_8@0,7-1297_v1_8@0,"Research into clustering has produced many algorithms for the task, including over 90 tools specifically designed for scRNA-seq <REF-2> .","Research into clustering has produced many algorithms for the task, including over 60 tools specifically designed for scRNA-seq <REF-2> .","Modify,Fact/Evidence",Fact/Evidence
8544,7-1297,7-1297_v2_41@1,7-1297_v1_42@1,In the first evaluation (R version 3.4.3) we used Dataset 3 for the robustness evaluation with regards to cells.,"We used Dataset 3 for the cell robustness evaluation with regards to cells, since it had the most number of cells.","Modify,Fact/Evidence",Fact/Evidence
8545,7-1297,7-1297_v2_40@2,7-1297_v1_42@3,"Finally, the impact of different aligners and preprocessing was assessed using all possible combinations of programs (i.e. some clustering methods did not run with scPipe output).",The impact of different aligners and preprocessing was assessed using all appropriate combinations of programs.,"Modify,Fact/Evidence",Fact/Evidence
8546,7-1297,7-1297_v2_43@1,7-1297_v1_45@1,"In order to assess the effect of using different preprocessing pipelines on the data, we applied the Bioconductor package scPipe <REF-29> (version 1.0.6) to the raw data.","In order to assess the affect of using different preprocessing pipelines on the data, we applied the Bioconductor package scPipe <REF-28> (version 1.0.6) to the raw data.","Modify,Grammar",Grammar
8547,7-1297,7-1297_v2_44@0,7-1297_v1_46@0,Run time assessment,Run time,"Modify,Clarity",Clarity
8548,7-1297,7-1297_v2_45@1,7-1297_v1_47@1,"Each task was allocated as many CPU cores of a 24 core Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz as specified by the default parameters, but less than 10 cores.",Each task was allocated as many CPU cores of a 24 core Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz as specified by the default parameters.,"Modify,Fact/Evidence",Fact/Evidence
8549,7-1297,7-1297_v2_45@2,7-1297_v1_47@2,The base::set.seed was set for all steps involving stochasticity (i.e. dimension reduction and clustering).,The base::set.seed was overridden in order to prevent stochasticity and thus give reduced unwanted variation in the results.,"Modify,Fact/Evidence",Fact/Evidence
8550,7-1297,7-1297_v2_47@1,7-1297_v1_49@1,"Properties of a cell’s data refer to features such as the number of total reads that included the cell’s barcode, the total number of detected genes found for this cell, etc.","Properties of a cell’s data refer to features such as the number of total reads that included the cell’s barcode, the total number of gene transcripts found for this cell, etc.","Modify,Clarity",Clarity
8551,7-1297,7-1297_v2_50@0,7-1297_v1_52@0,Gold standard dataset.,Gold standard data.,"Modify,Clarity",Clarity
8552,7-1297,7-1297_v2_50@3,7-1297_v1_52@3,"The clustering solutions produced by these methods, with the exception of countClust , largely reflected cell types.","The clustering solutions produced by these methods, with the exception of countClust , largely reflect the cell types.","Modify,Grammar",Grammar
8553,7-1297,7-1297_v2_53@0,7-1297_v1_55@0,Silver standard datasets.,Silver standard data.,"Modify,Clarity",Clarity
8554,7-1297,7-1297_v2_53@1,7-1297_v1_55@1,We labeled the cells in each of the silver standard datasets as one of 11 different PBMC cell populations.,We labeled the cells in each of the three silver standard datasets as one of 11 different PBMC cell populations.,"Modify,Clarity",Clarity
8555,7-1297,7-1297_v2_53@2,7-1297_v1_55@2,"When using the ARI_truth to compare the likeness of the clustering solutions and the labels, no method produced solutions that were uniformly the most similar to the inferred labels ( Figure 2 ) in either the first or second evaluation.","When using the ARI_truth to compare the likeness of the clustering solutions and the labels, no method produced solutions that were uniformly the most similar to the inferred labels ( Figure 2 ).","Modify,Fact/Evidence",Fact/Evidence
8556,7-1297,7-1297_v2_53@3,7-1297_v1_55@3,"In both evaluations, ascend tended to estimate smaller number of clusters and consequently did not agree with the labeling.","Two methods, ascend and countClust , tended to estimate smaller number of clusters and consequently did not agree with the labeling.","Modify,Clarity",Clarity
8557,7-1297,7-1297_v2_53@4,7-1297_v1_55@4,"Only Seurat , SC3 and Cell Ranger achieved an ARI_truth above 0.4 for at least two datasets in each of the evaluations.","Only Seurat , SC3 and Cell Ranger achieved an ARI_truth above 0.4 for at least two out of the three silver standard datasets.","Modify,Clarity",Clarity
8558,7-1297,7-1297_v2_53@6,7-1297_v1_55@6,"RCA and SC3 were particularly affected, showing much greater similarity for more confidently labeled cells.","RCA was particularly affected, showing much greater similarity for more confidently labeled cells.","Modify,Fact/Evidence",Fact/Evidence
8559,7-1297,7-1297_v2_53@7,7-1297_v1_55@7,We also calculated the homogeneity of each method in each dataset with respect to the inferred labeling (compare Figure 3 ).,We also calculated the homogeneity of each method in each dataset with respect to the inferred labeling.,"Modify,Fact/Evidence",Fact/Evidence
8560,7-1297,7-1297_v2_53@8,7-1297_v1_55@8,"Generally, most methods exhibited significantly lower performance on datasets generated with the older version of the 10x Genomics technology.","Generally, most methods exhibited significantly lower performance on Dataset 2, which was generated with an older version of the 10x Genomics technology than that used to generate Datasets 1 and 3.","Modify,Fact/Evidence",Fact/Evidence
8561,7-1297,7-1297_v2_53@9,7-1297_v1_55@9,"Most methods had much lower accuracy than for the gold standard data, indicating that most clusters represent mixtures of different inferred cell types.","Apart from RCA all methods had much lower accuracy than for the gold standard data, indicating that most clusters represent mixtures of different inferred cell types.","Modify,Clarity",Clarity
8562,7-1297,7-1297_v2_53@10,7-1297_v1_55@10,"The exceptions are SC3 ’s clustering solution of Dataset 3 in the first evaluation and Seurat ’s clustering solution on Datasets 3a and 5 in the second evaluation, which all achieved an homogeneity score above 0.7.","The exception is SC3 ’s clustering solution of Dataset 3, which achieved an homogeneity score above 0.7.","Modify,Fact/Evidence",Fact/Evidence
8563,7-1297,7-1297_v2_58@1,7-1297_v1_58@1,"Furthermore, similar algorithms did not result in more similar solutions.","In fact, only a few methods resulted in clustering solutions that were similar.","Modify,Clarity",Clarity
8564,7-1297,7-1297_v2_62@2,7-1297_v1_61@2,"When assessing the stability with regards to input in both evaluations 1 and 2, RaceID and RaceID2 did not appear very robust.","When assessing the stability with regards to input, countClust , RaceID and RaceID2 did not appear very robust.","Modify,Fact/Evidence",Fact/Evidence
8565,7-1297,7-1297_v2_62@3,7-1297_v1_61@4,"Due to its reliance on reference profiles RCA is extremely robust, achieving ARI_comp above 0.9 consistently in both evaluations.","Due to its reliance on reference profiles RCA is extremely robust, achieving ARI_comp above 0.9 consistently.","Modify,Fact/Evidence",Fact/Evidence
8566,7-1297,7-1297_v2_67@0,7-1297_v1_62@0,We also investigated how the stability of the clustering method was affected by the use of different aligners ( Supplementary Figure 5 ) in evaluation 1 (R version 3.4.3).,We also investigated how the stability of the clustering method was affected by the use of different aligners ( Figure 5 ).,"Modify,Fact/Evidence",Fact/Evidence
8567,7-1297,7-1297_v2_68@1,7-1297_v1_67@1,Running time varied substantially between different methods.,Running time varies substantially between different methods.,"Modify,Grammar",Grammar
8568,7-1297,7-1297_v2_68@2,7-1297_v1_67@2,RaceID2 took prohibitively long and thus does not lend itself to interactive analysis when applied to 10x Genomics data ( Figure 7 ).,Methods like RaceID and RaceID2 take prohibitively long and thus do not lend themselves to interactive analysis when applied to 10x Genomics data ( Figure 6 ).,"Modify,Fact/Evidence",Fact/Evidence
8569,7-1297,7-1297_v2_68@3,7-1297_v1_67@3,"The fastest methods was RCA , with both taking less than 25 seconds on average for the entire dataset analysis.","The fastest methods were RCA and TSCAN , with both taking less than 25 seconds on average for the entire dataset analysis.","Modify,Fact/Evidence",Fact/Evidence
8570,7-1297,7-1297_v2_68@7,7-1297_v1_67@7,"For example, tools like Cell Ranger and Seurat offer detailed documentation, with many different use cases as well as tutorials (compare Supplementary Table 1 ).","For example, tools like Cell Ranger and Seurat offer detailed documentation, with many different use cases as well as tutorials.","Modify,Fact/Evidence",Fact/Evidence
8571,7-1297,7-1297_v2_68@8,7-1297_v1_67@8,"Tools, which are not found on Bioconductor, such as RaceID2 , ascend and RCA have more limited documentation.","Tools, which are not found on Bioconductor, such as RaceID , RaceID2 , ascend and RCA have more limited documentation.","Modify,Fact/Evidence",Fact/Evidence
8572,7-1297,7-1297_v2_72@0,7-1297_v1_71@0,"The variation in the percentage of reads aligning to ribosomal protein genes strongly predicted all clustering solutions as well as the inferred cell labels (see Figure 8 , Supplementary Figure 10 , Supplementary Figure 11 ).",The variation in the percentage of reads aligning to ribosomal protein genes strongly predicted all clustering solutions as well as the inferred cell labels (see Figure 7 ).,"Modify,Fact/Evidence",Fact/Evidence
8573,7-1297,7-1297_v2_72@3,7-1297_v1_71@3,"Furthermore, differences in abundance of ribosomal protein genes are likely to drive variation in PBMC scRNA-seq datasets, as they typically account for a large proportion of reads (around 40% in all three datasets).","Furthermore, differences in abundance of ribosomal protein genes are likely to drive variation in PBMCs scRNA-seq datasets, as they typically account for a large proportion of reads (around 40% in all three datasets).","Modify,Grammar",Grammar
8574,7-1297,7-1297_v2_75@0,7-1297_v1_72@0,Most methods’ solutions were much more driven by the total number of detected genes and total number of counts than the inferred solution.,Most methods’ solutions were much more driven by the total number of features and total number of counts than the inferred solution.,"Modify,Clarity",Clarity
8575,7-1297,7-1297_v2_75@1,7-1297_v1_72@1,"TSCAN was particularly affected ( R 2 = 0.52 in evaluation 1 and R 2 = 0.68 in evaluation 2), but for RaceID2 similar effects were observed.","TSCAN was particularly affected ( R 2 = 0.52), but for both ascend and RaceID2 similar effects were observed.","Modify,Fact/Evidence",Fact/Evidence
8576,7-1297,7-1297_v2_75@2,7-1297_v1_72@2,It can be speculated that this strong influence of total number of features and total number of counts on their clustering solutions points to a failure to appropriately normalize the data.,It can be speculated that this strong influence of total number of features and total number of count on their clustering solutions points to a failure to appropriately normalize the data.,"Modify,Grammar",Grammar
8577,7-1297,7-1297_v2_83@1,7-1297_v1_77@1,"The results of our investigations will be useful for method users, as we provide practical guidelines.","The results of our investigations will be useful for method users, as we provide clear and practical guidelines.","Modify,Clarity",Clarity
8578,7-1297,7-1297_v2_85@0,7-1297_v1_79@1,"While Seurat performed slightly better than the next best methods, in our opinion, the choice of clustering method should be informed by the user’s familiarity with statistical concepts and R programming.","While Seurat performed slightly better, the choice between Seurat and Cell Ranger , in our opinion, should be informed by the user’s familiarity with statistical concepts, which enable them to make the informed parameter choices required in Seurat .","Split+Modify,Claim",Claim
8579,7-1297,7-1297_v2_85@1,7-1297_v1_79@1,"Many methods, including Seurat , require the user to make informed parameter choices and occasionally troubleshoot code.","While Seurat performed slightly better, the choice between Seurat and Cell Ranger , in our opinion, should be informed by the user’s familiarity with statistical concepts, which enable them to make the informed parameter choices required in Seurat .","Split+Modify,Claim",Claim
8580,7-1297,7-1297_v2_86@0,7-1297_v1_80@0,"In general, we recommend that practitioners and consumers of results generated from 10x Genomics scRNA-seq data alike remain vigilant about the outcome of their analysis, and acknowledge the variability and likelihood of undesired influences.","We recommend that practitioners and consumers of results generated from 10x Genomics scRNA-seq data alike remain vigilant about the outcome of their analysis, and acknowledge the variability and likelihood of undesired influences.","Modify,Claim",Claim
8581,7-1297,7-1297_v2_86@2,7-1297_v1_80@2,"Hence, we suggest using several clustering methods ideally with multiple parameter choices on 10x Genomics scRNA-seq data in order to ensure that biological results are not artifacts of method or parameter choice.","Hence, at least two clustering tools should be routinely applied to 10x Genomics scRNA-seq data in order to offer more than one subjective interpretation and hence increase robustness and confidence in any results.","Split+Modify,Claim",Claim
8582,7-1297,7-1297_v2_86@3,7-1297_v1_80@2,This should help guard against subjective interpretation of the data and thus increase robustness of and confidence in results.,"Hence, at least two clustering tools should be routinely applied to 10x Genomics scRNA-seq data in order to offer more than one subjective interpretation and hence increase robustness and confidence in any results.","Split+Modify,Clarity",Clarity
8687,7-1359,7-1359_v2_42@3,,"In comparison, recent trials evaluating InSTI-based triple maintenance combinations showed a similar virological failure rates <REF-36> , <REF-37> .",,"Add,Fact/Evidence",Fact/Evidence
8688,7-1359,7-1359_v2_45@8,,"In the MONODO study, all patients had an undetectable plasma HIV viral load at week 24 on DTG maintenance monotherapy, whereas only one had a detectable viral load in the cerebrospinal fluid <REF-21> .",,"Add,Fact/Evidence",Fact/Evidence
8689,7-1359,7-1359_v2_45@9,,"Moreover, levels of HIV-RNA in the genital tract on DTG monotherapy <REF-41> and on DTG-3TC <REF-42> were comparable to those on standard cART.",,"Add,Fact/Evidence",Fact/Evidence
8690,7-1359,7-1359_v2_19@4,,"Of note, we separated data from Blanco et al. <REF-18> according to the strategy used (DTG-monotherapy and DTG-based dual therapy).",,"Add,Fact/Evidence",Fact/Evidence
8691,7-1359,7-1359_v2_37@2,7-1359_v1_37@2,Two of these three patients were previously exposed to InSTI and none had a history of previous VF.,These three patients did not have a history of previous VF and had a suppressed HIV viral load for several years before switching to DTG-monotherapy.,"Split+Modify,Fact/Evidence",Fact/Evidence
8692,7-1359,7-1359_v2_37@3,7-1359_v1_37@2,They all had a suppressed HIV viral load for several years before switching to DTG-monotherapy.,These three patients did not have a history of previous VF and had a suppressed HIV viral load for several years before switching to DTG-monotherapy.,"Split+Modify,Clarity",Clarity
8693,7-1359,7-1359_v2_43@0,7-1359_v1_43@0,"DTG-based dual therapy is a promising simplification strategy, especially when combined with 3TC, as the likelihood of developing toxicity events and DDI on such regimens is very low.","DTG-based dual therapy is a promising simplification strategy, especially when combined with 3TC or emtricitabine (FTC, both compounds referred to as XTC), as the likelihood of developing toxicity events and DDI on such regimens is very low.","Modify,Claim",Claim
8694,7-1359,7-1359_v2_43@4,7-1359_v1_43@4,"The impact of the latter mutation on viral fitness has been extensively described both in vitro <REF-38> and in vivo <REF-39> , and could also potentially explain the improved treatment outcomes in these patients compared to those switched to DTG-monotherapy without any previous failures.",The impact of the latter mutation on viral fitness has been extensively described and could also potentially explain the improved treatment outcomes in these patients compared to those switched to DTG-monotherapy without any previous failures.,"Modify,Fact/Evidence",Fact/Evidence
8695,7-1359,7-1359_v2_46@6,7-1359_v1_46@6,"As a consequence, the comparison of DTG-monotherapy vs. DTG/3TC, which would have been the most interesting one, was not possible.","As a consequence, the comparison of DTG-monotherapy vs. DTG/XTC, which would have been the most interesting one, was not possible.","Modify,Fact/Evidence",Fact/Evidence
8696,7-1359,7-1359_v2_47@4,7-1359_v1_47@4,"In addition to the studies using DTG-emtricitabine(FTC <REF-44> ) and DTG-3TC <REF-45> maintenance therapy, clinical trials are also assessing the efficacy of DTG/3TC in treatment-naïve patients <REF-46> .","In addition to the studies on maintenance therapy <REF-39> , <REF-40> , clinical trials are also assessing the efficacy of DTG/XTC in treatment-naïve patients <REF-41> .","Modify,Fact/Evidence",Fact/Evidence
8697,7-1359,7-1359_v2_47@5,7-1359_v1_47@5,"Furthermore, it will be critical to evaluate the efficacy of DTG-3TC or FTC dual therapy in specific sub-groups such as pregnant and breast-feeding women, adolescents, patients with previous failure to standard triple regimens and harboring the M184V resistance mutation, as well as in patients with HIV associated neurocognitive disorder and tuberculosis coinfection.","Furthermore, it will be critical to evaluate the efficacy of DTG-XTC dual therapy in specific sub-groups such as pregnant and breast-feeding women, adolescents, patients with previous failure to standard triple regimens and harboring the M184V resistance mutation, as well as in patients with HIV associated neurocognitive disorder and tuberculosis coinfection.","Modify,Claim",Claim
8698,7-1641,7-1641_v2_16@3,,"The detailed search workflow, a spreadsheet recording the results, and a bibliography of all papers deemed in scope are published <REF-1> , <REF-2> .",,"Add,Fact/Evidence",Fact/Evidence
8699,7-1641,7-1641_v2_16@4,,The year 2003 was chosen as the start date for the review as this was the year of the last major SARS (Severe Acute Respiratory Syndrome) outbreak.,,"Add,Fact/Evidence",Fact/Evidence
8700,7-1641,7-1641_v2_28@2,,There are very few evidence-based case studies that describe clearly the public health benefit that was achieved following the sharing of research data.,,"Add,Claim",Claim
8701,7-1641,7-1641_v2_28@3,,Funders should ensure better monitoring of the implementation of their policies and where such evidence exists that shared data added value this should be documented and disseminated.,,"Add,Claim",Claim
8702,7-1641,7-1641_v2_29@3,,Support for new mechanisms to publish data and papers rapidly during an emergency with peer review happening post-publication should serve both the need to share data and credit researchers.,,"Add,Claim",Claim
8703,7-1641,7-1641_v2_31@3,,"Alongside support for technical standards there needs to be sustainable support for the infrastructure necessary to host those data with the appropriate governance mechanisms to ensure the efficient, ethical and equitable access outlined in the joint statement by funders of health research (2010) referenced above.",,"Add,Claim",Claim
8704,7-1641,7-1641_v2_25@0,7-1641_v1_25@0,Conclusion: what are the next steps for the role for funders in support of data sharing,What are the next steps: the role for funders in support of data sharing,"Modify,Other",Other
8705,7-1641,7-1641_v2_26@2,7-1641_v1_26@2,In part this might reflect the limited guidance and additional resources offered by the same funders in supporting their researchers to understand and undertake data sharing to implement and monitor these policies in practice.,In part this might reflect the limited guidance offered by the same funders in supporting their researchers to understand and undertake data sharing to implement and monitor these policies in practice.,"Modify,Claim",Claim
8706,7-1641,7-1641_v2_32@0,7-1641_v1_31@0,One contributory role for funders would be to systematically collect the data management plans that they have requested as part of funding grants and make them publicly accessible.,For example one contributory role for funders would be to collect more systematically the data management plans that they have requested as part of funding grants and make them publicly accessible.,"Modify,Clarity",Clarity
8707,7-1641,7-1641_v2_32@2,7-1641_v1_31@2,"An online resource that brings together the reference material and policies that are exemplars of good practice in each of the categories that cover governance, data curation, security and longevity would provide the basis for a framework to guide the future development of new sharing resources.","An online resource that brings together the reference material and policies that are exemplars in each of the categories that cover governance, data curation, security and longevity would provide the basis for a framework to guide the future development of new sharing resources.","Modify,Clarity",Clarity
8708,7-1641,7-1641_v2_33@1,7-1641_v1_32@1,"In addition to defining the purpose of data sharing this would highlight the the political, technical, cultural, legal and ethical issues that need to be considered and point to examples of emerging good practice that can be used to address them.","In addition to defining the purpose of data sharing this would highlight the technical, cultural and ethical issues that need to be considered and point to examples of emerging good practice that can be used to address them.","Modify,Claim",Claim
8709,7-1641,7-1641_v2_35@0,7-1641_v1_34@0,All data associated with this article are referenced and available as open access under a Creative Commons licence (CC BY).,No data are associated with this article.,"Modify,Fact/Evidence",Fact/Evidence
8710,7-1641,7-1641_v2_6@0,7-1641_v1_6@0,Policies that require the sharing of health research data to improve public health have been promoted by international research funders for over a decade.,"The benefits of sharing health research data to improve public health have been promoted by international research funders for over a decade but the reality is that the quality and volume of health research data shared, even in emergency situations, remains low <REF-1> , <REF-2> .","Split+Modify,Clarity",Clarity
8711,7-1641,7-1641_v2_6@1,7-1641_v1_6@0,"However, when measured the quality and volume of health research data that has been shared, even when related to public health emergencies, remains low <REF-1> , <REF-2> .","The benefits of sharing health research data to improve public health have been promoted by international research funders for over a decade but the reality is that the quality and volume of health research data shared, even in emergency situations, remains low <REF-1> , <REF-2> .","Modify,Claim",Claim
8712,7-1641,7-1641_v2_6@2,7-1641_v1_6@1,"There are a number of ethical, legal and technical issues that act as impediments to sharing data but it seems this lack of progress is more a consequence of a cultural reluctance among researchers to ‘give up their data’ unless there are clear benefits returning to them.",This lack of progress seems to reflect a cultural reluctance among researchers to ‘give up their data’ without any clear benefits returning to them.,"Modify,Claim",Claim
8713,7-1641,7-1641_v2_6@3,7-1641_v1_6@2,"This reluctance is heightened among researchers in low resource settings who feel that the requirements to share data, from funders and journals, risk turning them into data exporters unless greater efforts are made to ensure a fairer distribution of benefits.","This concern is heightened among researchers in low resource settings who feel that the requirements to share data, from funders and journals, risk turning them into data exporters unless greater efforts are made to ensure a fairer distribution of benefits.","Modify,Clarity",Clarity
8714,7-1641,7-1641_v2_6@4,7-1641_v1_6@3,In this paper the authors draw on their experience working for Wellcome Trust and TDR - the Special Programme for Research and Training in Tropical Diseases - of supporting data sharing initiatives and combine that with commissioned research to highlight the barriers to sharing research data and the role research funders might play to improve this situation.,In this paper we draw on our experience of supporting data sharing initiatives and some commissioned research to highlight the barriers to sharing research data and the role research funders might play to improve this situation.,"Modify,Fact/Evidence",Fact/Evidence
8715,7-1641,7-1641_v2_7@0,7-1641_v1_7@0,A decade of data sharing policies but little progress?,A decade of progress?,"Modify,Other",Other
8716,7-1641,7-1641_v2_8@0,7-1641_v1_8@0,"In January 2011, a group of research funding organizations published a joint statement on sharing health research data with the aim to harmonize their existing policies and promote the efficient use of those data to accelerate improvements in public health.","In January 2011, a group of research funding organizations published a joint statement on sharing health research data with the aim to promote the efficient use of those data to accelerate improvements in public health.","Modify,Fact/Evidence",Fact/Evidence
8717,7-1641,7-1641_v2_14@0,7-1641_v1_14@0,"To explore this further, Wellcome and TDR commissioned two surveys to review the governance arrangements and standards within existing data sharing resources.","To explore this further, we commissioned two surveys to review the governance arrangements and standards within existing data sharing resources.","Modify,Clarity",Clarity
8718,7-1641,7-1641_v2_14@1,7-1641_v1_14@1,The findings of those studies informed a workshop held in October 2017 with a set of stakeholders representing researchers and funding organizations with experience of sharing and using shared data.,The findings of those studies informed a workshop held in October 2017 with a set of stakeholders representing researchers and funding organizations.,"Modify,Fact/Evidence",Fact/Evidence
8719,7-1641,7-1641_v2_15@0,7-1641_v1_14@2,"All the reports, methods and supporting data files from these commissioned studies are published as open access under a Creative Commons licence and in free-to-access repositories.",All the reports and supporting files are published as open access under a Creative Commons licence and in free-to-access repositories.,"Modify,Clarity",Clarity
8720,7-1641,7-1641_v2_16@1,7-1641_v1_15@1,A review of all academic papers published since 2003 referencing these diseases was undertaken and attempts were then made to access the data underlying those publications via the web and through a direct survey of the corresponding authors.,A review of academic papers published since 2003 relating to these diseases was undertaken and attempts were then made to access the data underlying those publications via the web and through a direct survey of the corresponding authors.,"Modify,Clarity",Clarity
8721,7-1641,7-1641_v2_16@2,7-1641_v1_15@2,"Interviews were undertaken with a range of people either conducting or supporting research in these areas and this was supplemented with a review of institutional policies, discussion documents and academic commentaries about standards and norms in data sharing.","Interviews were undertaken with a range of people either conducting or supporting research in these areas and this was supplemented with a review of institutional policies, discussion documents and academic commentaries about standards and norms in data sharing <REF-1> , <REF-2> .","Modify,Fact/Evidence",Fact/Evidence
8722,7-1641,7-1641_v2_17@0,7-1641_v1_16@0,The second survey - Development of International Standards for Online Repositories - was designed to identify which technical ‘standards’ were being used in data sharing infrastructure relating to the neglected diseases.,The second survey - Development of International Standards for Online Repositories - was designed to identify which ‘standards’ were being used in data sharing relating to the neglected diseases.,"Modify,Fact/Evidence",Fact/Evidence
8723,7-1641,7-1641_v2_18@0,7-1641_v1_17@0,"A third report combined the findings of these two surveys referenced above and was used to shape thinking at a workshop held in Antwerp, Belgium in October 2017.","A third report combined the findings of these two surveys and was used to shape thinking at a workshop held in Antwerp, Belgium in October 2017 <REF-10> .","Modify,Fact/Evidence",Fact/Evidence
8724,7-1641,7-1641_v2_19@0,7-1641_v1_19@0,Summary of the findings,What does this tell us?,"Modify,Other",Other
8725,7-1641,7-1641_v2_20@2,7-1641_v1_20@2,"While a few authors will provide the data on request, 65% of the papers (207 of 319) give no information on how to find or access the data.","While a few authors will provide the data on request, 65% of these papers give no information on how to find or access the data.","Modify,Fact/Evidence",Fact/Evidence
8726,7-1725,7-1725_v2_74@0,,Our study has several strengths.,,"Add,Claim",Claim
8727,7-1725,7-1725_v2_34@3,7-1725_v1_34@3,"The studies included 71,330 women.",The studies included 71 330 women.,"Modify,Grammar",Grammar
8728,7-1725,7-1725_v2_34@4,7-1725_v1_34@4,"The case-control studies included 28,761 mothers, 594 of whom were exposed to HPTs; the cohort studies included 42,569 mothers and 3,615 exposures to HPTs.","The case-control studies included 28 761 mothers, 594 of whom were exposed to HPTs; the cohort studies included 42 569 mothers and 3615 exposures to HPTs.","Modify,Grammar",Grammar
8729,7-1725,7-1725_v2_7@0,7-1725_v1_7@0,"Oral hormone pregnancy tests (HPTs), such as Primodos (known as Duogynon in Germany), were available as injections from 1950 and in tablet form in the UK from 1956 onwards, before the modern forms of urine pregnancy tests became available <REF-1> .","Oral hormone pregnancy tests (HPTs), such as Primodos (known as Duogynon in Germany), were used from 1958 to 1978, before urine pregnancy tests were available <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
8730,7-1725,7-1725_v2_7@2,7-1725_v1_7@2,The test principle was that they would induce bleeding similar to menstruation in those who were not pregnant.,The test principle was that menstruation would be induced in those who were not pregnant.,"Modify,Clarity",Clarity
8731,7-1725,7-1725_v2_43@0,7-1725_v1_43@0,"Nine studies, including 61,642 mothers of infants and 3,274 exposed to HPTs, examined the association in pregnancy with all congenital malformations.","Nine studies, including 61 642 mothers of infants and 3274 exposed to HPTs, examined the association in pregnancy with all congenital malformations.","Modify,Grammar",Grammar
8732,7-1725,7-1725_v2_46@0,7-1725_v1_46@0,"Seven studies, including 19,267 mothers of infants and 218 exposed to oral HPTs, analysed congenital heart malformations.","Seven studies, including 19 267 mothers of infants and 218 exposed to oral HPTs, analysed congenital heart malformations.","Modify,Grammar",Grammar
8733,7-1725,7-1725_v2_11@0,7-1725_v1_11@0,"Since Primodos was withdrawn, the discovery of previously confidential documents has led to renewed concerns about its potential to cause harm <REF-5> .","Since Primodos was withdrawn, the discovery of previously confidential documents has led to renewed concerns about its potential to cause harm.","Modify,Fact/Evidence",Fact/Evidence
8734,7-1725,7-1725_v2_73@4,7-1725_v1_73@4,"The analyses of gastrointestinal, urogenital, musculoskeletal, and VACTERL malformations were limited by their small sample sizes and low number of events: the interpretation of these effects should, therefore, be treated more cautiously.","The analyses of gastrointestinal, urogenital, musculoskeletal, and VACTERL malformations were limited by their small sample sizes and low number of events: the interpretation of these effects should therefore be treated more cautiously.","Modify,Grammar",Grammar
8735,7-1725,7-1725_v2_74@1,7-1725_v1_74@0,"We used standard systematic review methods, and by asking a focused question solely on exposure to HPTs, and excluding exposure to other hormones, we have been able to assess the heterogeneity of the effect estimates.",A significant strength of this current study is its use of standard systematic review methods.,"Merge+Modify,Clarity",Clarity
8736,7-1725,7-1725_v2_74@1,7-1725_v1_74@1,"We used standard systematic review methods, and by asking a focused question solely on exposure to HPTs, and excluding exposure to other hormones, we have been able to assess the heterogeneity of the effect estimates.","By asking a focused question solely on exposure to HPTs, and excluding exposure to other hormones, we have been able to assess the heterogeneity of the effect estimates.","Merge+Modify,Clarity",Clarity
8737,7-1818,7-1818_v2_8@2,,"The impact of outliers is well-known in research, be they of clinical or laboratory origin <REF-11> , <REF-12> ; they must be detected through appropriate methods, possibly with adjustment for skewness <REF-13> , and their presence requires investigation, especially for small groups.",,"Add,Fact/Evidence",Fact/Evidence
8738,7-1818,7-1818_v2_11@0,,The strong association between the severity of OSA and a higher prevalence and incidence of cardiovascular events has been evidenced for a long time <REF-21> .,,"Add,Fact/Evidence",Fact/Evidence
8739,7-1818,7-1818_v2_11@1,,"However, where cardiac biomarkers are useful for the diagnosis of many cardiovascular diseases, the interest of natriuretic peptides in the evaluation of OSA-associated cardiac dysfunction and CPAP effects remain controversial, especially because of uncontrolled co-morbidities, as summarized by Maeder et al. <REF-22> , <REF-23> .",,"Add,Fact/Evidence",Fact/Evidence
8740,7-1818,7-1818_v2_11@2,,"To date, no study has specifically evaluated whether NT-proBNP reflects cardiac dysfunction in OSA or whether NT-proBNP is under the influence of obesity in this context.",,"Add,Claim",Claim
8741,7-1818,7-1818_v2_8@3,7-1818_v1_8@2,"In the study from Recoquillon et al. , a median (IQR) expression would therefore have been more appropriate than mean (SD), and a graph detailing the scatter dot plots for both groups, with connecting lines before and after treatment, would have been required.","Median (IQR) expression would therefore have been more appropriate, and a graph detailing the scatter dot plots for both groups, with connecting lines before and after treatment, would have been required.","Modify,Fact/Evidence",Fact/Evidence
8742,7-1818,7-1818_v2_10@6,7-1818_v1_10@6,"Given the long and tedious assay protocol impractical in hospital laboratory routine, and given the absence of hindsight about its analytical performance, the authors should rather have used a most widespread, reliable, and rapid automated method, like the electrochemiluminescent immunoassay method on Roche analyzers (Roche Diagnostics, Mannheim, Germany) <REF-18> , which was, moreover, available in the laboratory from one of the five hospital centers participating to the trial (Poitiers Hospital Center <REF-19> , NCT01426607 <REF-20> ).","Given the long and tedious assay protocol, which is impractical in hospital laboratory routine, and given the absence of hindsight about its analytical performance, the authors should rather have used a most widespread, reliable, and rapid automated method, like the electrochemiluminescent immunoassay method on Roche analyzers (Roche Diagnostics, Mannheim, Germany) <REF-15> .","Modify,Fact/Evidence",Fact/Evidence
8743,7-1818,7-1818_v2_12@0,7-1818_v1_10@7,"An interesting perspective is the ongoing MOSAIC study, whose main objective is to assess the impact of three months of MAD therapy on AHI in Asian patients with heart failure and OSA <REF-24> .","In this way, an interesting perspective is the ongoing MOSAIC study, whose main objective is to assess the impact of three months of MAD therapy on AHI in Asian patients with heart failure and OSA <REF-16> .","Modify,Clarity",Clarity
8765,7-1925,,7-1925_v1_63@7,,Research project costs often are smaller in the field of law compared to other disciplines.,"Delete,Claim",Claim
8766,7-1925,,7-1925_v1_63@8,,"As legal scholars are not dependent on third party funding, so that funder OA requirements have only limited potential to incentivize OA publishing.","Delete,Claim",Claim
8767,7-1925,,7-1925_v1_66@0,,"Over the course of the last three decades, OA to the scholarly literature has emerged as a new norm of scholarly publishing.","Delete,Claim",Claim
8768,7-1925,,7-1925_v1_66@1,,"As a response to perceived limitations of the subscription-based model of scholarly publishing and propelled by technical possibilities offered by the Internet, OA promises the removal of major barriers in assessing, distributing and re-using research findings <REF-6> .","Delete,Fact/Evidence",Fact/Evidence
8769,7-1925,,7-1925_v1_66@2,,"OA publishing has grown substantially across different types of publication outlets, academic disciplines and research contexts, resulting in growing shares of scholarly publications being made openly accessible.","Delete,Claim",Claim
8770,7-1925,,7-1925_v1_67@2,,"Doing so, we explained the publishing patterns and trends observed in the first part of this review.","Delete,Fact/Evidence",Fact/Evidence
8771,7-1925,,7-1925_v1_67@14,,"Factors facilitating OA and shaping OA publishing practices in these disciplines are strong OA mandates combined with both funder-operated repositories and available funding for APCs, a richness in highquality OA journals and the perception of authors that OA journals allow for a wider circulation of publications than subscription journals do.","Delete,Claim",Claim
8772,7-1925,,7-1925_v1_67@18,,"OA in physics, mathematics, information technology, astronomy and biology has been facilitated by an existing culture of preprint distribution and by high levels of familiarity with OA publishing in general and Green OA in particular.","Delete,Claim",Claim
8773,7-1925,,7-1925_v1_67@19,,"Barriers to OA in chemistry and engineering can be identified as concerns about the quality of OA journals, which are shared by scholars, publishers and learned societies alike, as well as high degrees of industrial integration within these fields.","Delete,Claim",Claim
8774,7-1925,,7-1925_v1_67@21,,"For scholars within the social sciences, open repositories appear to be of central importance for making research outputs openly accessible, closely followed by publication in Gold OA journals, and, with some distance, Hybrid and Bronze OA.","Delete,Claim",Claim
8775,7-1925,,7-1925_v1_67@22,,We identified several factors that shape OA publishing practices within the social sciences.,"Delete,Fact/Evidence",Fact/Evidence
8776,7-1925,,7-1925_v1_67@23,,"Most importantly, this includes authors’ concerns about the quality and prestige of OA journals, the central role of monographs in terms of academic career advancement and difficulties in assessing funding for APCs and BPCs.","Delete,Claim",Claim
8777,7-1925,,7-1925_v1_67@24,,These factors also explain why most OA within the social sciences is published via the Green route.,"Delete,Claim",Claim
8778,7-1925,,7-1925_v1_67@25,,"We observed signs of cultural change particularly in young scholars, who embrace the idea of conducting science more openly.","Delete,Claim",Claim
8779,7-1925,,7-1925_v1_16@2,,"Thereby, we aim to identify discipline-specific barriers and potentials for OA.","Delete,Fact/Evidence",Fact/Evidence
8780,7-1925,,7-1925_v1_67@26,,Humanities features OA uptake levels well below the social sciences.,"Delete,Claim",Claim
8781,7-1925,,7-1925_v1_67@28,,"The most important factors shaping these publishing practices are comparable to those identified in the social sciences, including a dry climate for APC and BPC funding, the central role of monographs, which are less likely to become OA, and authors, publishers and scholarly societies being opposed to OA.","Delete,Claim",Claim
8782,7-1925,,7-1925_v1_67@29,,"Just like in the social sciences, there is, however, some movement with new economic models that do not rely on author payments appearing to have some traction with humanities scholars.","Delete,Claim",Claim
8783,7-1925,,7-1925_v1_67@30,,OA in law is still in its infancy with legal scholars making only small proportions of their research outputs OA.,"Delete,Claim",Claim
8784,7-1925,,7-1925_v1_67@31,,"In large part, this is due to low levels of awareness and little demand for OA within the academic community.","Delete,Claim",Claim
8785,7-1925,,7-1925_v1_67@32,,Of relevance is also that OA mandates and policies only have limited impact on publishing behaviour as legal studies in large part do not depend on third party funding.,"Delete,Claim",Claim
8786,7-1925,,7-1925_v1_67@33,,"The financing of publication fees for publishing in OA journals appears to constitute a major barrier to OA within the humanities, social sciences and law.","Delete,Claim",Claim
8787,7-1925,,7-1925_v1_67@34,,We believe that new OA models that do not rely on author payments represent a viable alternative to financing OA within these disciplines.,"Delete,Claim",Claim
8788,7-1925,,7-1925_v1_67@35,,"This includes models such as the OLH or other crowd funding initiatives, such as KU.","Delete,Claim",Claim
8789,7-1925,,7-1925_v1_68@0,,"These findings indicate that, as OA is implemented and used across different academic disciplines, it is shaped by the scholars that use respective communication technologies.","Delete,Claim",Claim
8790,7-1925,,7-1925_v1_68@1,,"In turn, OA technologies shape the ways in which scholars communicate and disseminate their research findings.","Delete,Claim",Claim
8791,7-1925,,7-1925_v1_68@2,,"Our findings also suggest that, in spite of the transformational potential of OA, the shift towards OA is uneven across disciplines and even sub-disciplines.","Delete,Claim",Claim
8792,7-1925,,7-1925_v1_68@3,,We found that academic disciplines feature distinctive research cultures that have grown historically and manifest themselves in discipline-specific publishing practices.,"Delete,Claim",Claim
8793,7-1925,,7-1925_v1_68@4,,"These publishing practices vary fundamentally in terms of their compatibility with OA publishing formats, which is the reason why the implementation of OA can be assumed to be a natural continuation of publishing cultures in some disciplines, while in other disciplines, the implementation of OA faces major obstacles and requires a change of research culture.","Delete,Claim",Claim
8794,7-1925,,7-1925_v1_16@4,,Each co-author of our team examined evidence on factors that shape OA publishing practices within their own areas of research training.,"Delete,Fact/Evidence",Fact/Evidence
8795,7-1925,,7-1925_v1_69@4,,"For example, the few bibliometric studies that have assessed OA publishing practices for the natural sciences and related sub-disciplines revealed that there are substantial differences in the OA uptake between physics and chemistry.","Delete,Claim",Claim
8796,7-1925,,7-1925_v1_69@6,,"Second, only two bibliometric studies in our review have included Bronze OA and Hybrid OA in their analyses, resulting in highly limited data on the relative uptake on these OA routes.","Delete,Claim",Claim
8797,7-1925,,7-1925_v1_69@7,,This likely limits the robustness of our conclusions.,"Delete,Claim",Claim
8798,7-1925,,7-1925_v1_69@8,,We encourage further research to include Bronze and Hybrid OA in their bibliometric analyses.,"Delete,Claim",Claim
8799,7-1925,,7-1925_v1_69@9,,"Third, in explaining OA publishing patterns, we conducted a narrative review by the means of which each co-author identified relevant socio-technical forces that affect OA within their area of research training.","Delete,Fact/Evidence",Fact/Evidence
8800,7-1925,,7-1925_v1_70@2,,"Doing so, we contributed to understanding how different disciplines adopt and shape OA.","Delete,Claim",Claim
8801,7-1925,,7-1925_v1_70@3,,We encourage further research to investigate the underlying mechanisms and factors that shape scholarly communication in general and OA publishing practices in particular.,"Delete,Claim",Claim
8802,7-1925,,7-1925_v1_70@4,,A profound understanding should inform both OA policies and community-driven efforts in promoting OA.,"Delete,Claim",Claim
8803,7-1925,,7-1925_v1_16@10,,"Having identified key experts within the field, their GS profiles were also searched for material.","Delete,Fact/Evidence",Fact/Evidence
8804,7-1925,,7-1925_v1_16@11,,Each co-author contributed original content on OA in their discipline and participated in the reviewing and editing process.,"Delete,Fact/Evidence",Fact/Evidence
8805,7-1925,,7-1925_v1_19@2,,"Earlier studies analysed random samples of academic publications from bibliometric databases, such as Scopus or WoS, whereas more recent studies examined these databases in full.","Delete,Claim",Claim
8806,7-1925,,7-1925_v1_19@4,,"On this basis, studies determined OA levels and the relative uptake on different OA routes across disciplines.","Delete,Claim",Claim
8807,7-1925,,7-1925_v1_19@5,,"Earlier studies distinguished between Green OA, which refers to articles published in subscription-based journals, but for which either the accepted or the published version can be retrieved from an open repository, and Gold OA, which describes articles published in OA journals, that is, journals in which all articles are openly accessible.","Delete,Claim",Claim
8808,7-1925,7-1925_v2_4@1,,Estimated OA levels for publication years after 2010 varied between 29.4% and 66%.,,"Add,Fact/Evidence",Fact/Evidence
8809,7-1925,,7-1925_v1_19@6,,"More recent studies also include Hybrid OA, which refers to articles free under an open license in a subscription journal, and Bronze OA, which describes articles free to read on the publisher page without an open license <REF-12> 1 .","Delete,Fact/Evidence",Fact/Evidence
8810,7-1925,7-1925_v2_11@0,,Definition of open access and open access routes,,"Add,Other",Other
8811,7-1925,7-1925_v2_12@0,,Fifteen years of research into the prevalence of OA have produced a number of different concepts of OA and its sub-types 1 .,,"Add,Claim",Claim
8812,7-1925,7-1925_v2_12@1,,"One influential definition of OA is that offered by the 2002 Budapest Open Access Initiative, which understands scholarly outputs as OA if they are both free to read and free to reuse, without any financial, legal, or technical barriers other than gaining access to the internet <REF-11> , <REF-12> .",,"Add,Fact/Evidence",Fact/Evidence
8813,7-1925,7-1925_v2_12@2,,"However, a number of bibliometric studies have adopted a more lax definition of OA.",,"Add,Claim",Claim
8814,7-1925,7-1925_v2_12@3,,"Some require only that OA contents are freely available to read online, while disregarding reuse rights <REF-13> – <REF-16> .",,"Add,Fact/Evidence",Fact/Evidence
8815,7-1925,7-1925_v2_12@4,,"Others apply the minimum requirement that scholarly articles should be freely available to read online, and assess factors that determine their openness, for example what rights are provided by different types of licences or how articles are stored <REF-11> , <REF-17> , <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
8816,7-1925,7-1925_v2_12@5,,"Following the latter studies, this study understands OA as scholarly outputs that are free to read online, either on a journal website or through an open repository, and that might or might not be free to reuse.",,"Add,Fact/Evidence",Fact/Evidence
8817,7-1925,7-1925_v2_12@6,,"This definition assumes that OA is a spectrum that encompasses a range of components, which determine the degree of openness of a certain publication outlet <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
8818,7-1925,7-1925_v2_12@7,,"Different sub-types, so-called ""routes"" of OA, can be identified, depending on when and where scholarly articles are made available, who makes them available and what rights are provided by different types of licences <REF-17> .",,"Add,Fact/Evidence",Fact/Evidence
8819,7-1925,7-1925_v2_12@9,,"These routes differ in their openness and sustainability across fundamental aspects of OA – reader rights, reuse rights, copyrights, author posting rights and machine readability <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
8820,7-1925,7-1925_v2_12@10,,Some of these routes enjoy general support as sub-types of OA while others remain controversial <REF-20> .,,"Add,Fact/Evidence",Fact/Evidence
8821,7-1925,7-1925_v2_12@11,,Their definitions are given in Table 1 .,,"Add,Fact/Evidence",Fact/Evidence
8822,7-1925,7-1925_v2_12@12,,These routes are understood as exclusive categories and publisher-hosted content trumps self-archived content <REF-11> .,,"Add,Fact/Evidence",Fact/Evidence
8823,7-1925,7-1925_v2_12@13,,"This study does not include ""Black OA"", which refers to articles shared on illegal pirate sites, for example Sci-Hub, and ""Academic Social Networks"" (ASNs) or ""Free availability"" (FA), which describes authors sharing their papers on commercial online social networks like ResearchGate or other websites 2 <REF-11> .",,"Add,Fact/Evidence",Fact/Evidence
8824,7-1925,7-1925_v2_12@14,,"Where bibliometric studies differ from our definition of OA, this will be highlighted.",,"Add,Fact/Evidence",Fact/Evidence
8825,7-1925,7-1925_v2_25@3,,"Within this broad approach, important methodological differences can be identified.",,"Add,Claim",Claim
8826,7-1925,7-1925_v2_25@4,,"This relates to, first, definitions of OA and different OA routes.",,"Add,Claim",Claim
8827,7-1925,7-1925_v2_25@5,,"Some studies only estimated overall OA prevalence levels, but did not assess the relative uptake of different OA routes <REF-13> – <REF-15> , <REF-24> , <REF-25> .",,"Add,Fact/Evidence",Fact/Evidence
8828,7-1925,7-1925_v2_25@6,,"Others did assess the relative importance of Gold and Green OA, but not the uptake levels of other OA sub-types <REF-1> , <REF-9> , <REF-17> .",,"Add,Fact/Evidence",Fact/Evidence
8829,7-1925,7-1925_v2_25@7,,"One study assessed relative uptake levels for Gold, Green, Hybrid and Bronze OA, but excluded Delayed OA from its analyses <REF-11> .",,"Add,Fact/Evidence",Fact/Evidence
8830,7-1925,7-1925_v2_25@8,,"Two further studies estimated uptake levels for Delayed OA, but only as part of ""Other OA"", together with Hybrid OA, ASNs and other websites <REF-10> .",,"Add,Fact/Evidence",Fact/Evidence
8831,7-1925,7-1925_v2_25@9,,"A small number of studies included ASNs and FA in their definitions of OA, either as a part of Green OA together with other websites <REF-16> , <REF-17> , as the sub-type ""Other OA"" merged with Delayed OA, Hybrid OA and other websites <REF-10> , or as the sub-type ""FA"" together with other websites and harvesters <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
8832,7-1925,7-1925_v2_25@10,,"Second, bibliometric studies covered different publication years for which they determined OA prevalence levels, spanning 1992 <REF-24> to 2017 <REF-13> .",,"Add,Fact/Evidence",Fact/Evidence
8833,7-1925,7-1925_v2_25@11,,"Third, in determining OA prevalence levels, studies used different databases and search strategies.",,"Add,Claim",Claim
8834,7-1925,7-1925_v2_25@12,,"Some studies examined the WoS database or its predecessor Thomson Reuters ISI Web of Knowledge in full <REF-13> , <REF-24> , <REF-25> , while others assessed random samples of papers indexed in these databases <REF-9> , <REF-11> , or combined them with Scopus <REF-17> or the Social Sciences Citation Index and Humanities Citation Index <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
8835,7-1925,7-1925_v2_25@13,,"Another subset of studies examined Scopus either in full or as random samples of articles indexed therein <REF-1> , <REF-10> , <REF-14> , and one study used GS <REF-15> .",,"Add,Fact/Evidence",Fact/Evidence
8836,7-1925,7-1925_v2_25@14,,"In assessing whether openly accessible versions of scholarly publications indexed in these databases can be found, some studies searched for their corresponding freely available full text versions via Unpaywall <REF-13> , in the oaDOI database <REF-11> , <REF-25> or in the 1science database of OA articles <REF-17> .",,"Add,Fact/Evidence",Fact/Evidence
8837,7-1925,7-1925_v2_25@15,,"Other studies searched for OA versions in GS <REF-14> , <REF-15> or via Google, either manually <REF-1> or by means of automated robot crawling <REF-9> , <REF-24> .",,"Add,Fact/Evidence",Fact/Evidence
8838,7-1925,7-1925_v2_26@0,,Overall uptake on OA.,,"Add,Other",Other
8839,7-1925,7-1925_v2_26@17,,"Chemistry and engineering feature the lowest OA uptake levels, varying across studies between 15.5% and 35% for chemistry and between 17.4% and 29% for engineering <REF-11> , <REF-13> .",,"Add,Fact/Evidence",Fact/Evidence
8840,7-1925,7-1925_v2_27@0,,Relative uptake of open access routes.,,"Add,Other",Other
8841,7-1925,7-1925_v2_27@4,,"ASNs and FA appear to play a highly relevant role for making research outputs openly accessible, featuring levels of 20.7% in 2009 and 2014 <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
8842,7-1925,7-1925_v2_43@7,,"The Wellcome Trust has launched its own OA journal, Wellcome Open Research, enabling its grant recipients to publish OA for free <REF-41> .",,"Add,Fact/Evidence",Fact/Evidence
8843,7-1925,7-1925_v2_45@3,,"In biology, OA uptake increased in the early 2000s.",,"Add,Claim",Claim
8844,7-1925,7-1925_v2_46@1,,"In biology, scholars initially were slower in embracing the idea of sharing preprints, but with the launch of platforms like PeerJ Preprints and bioRxiv in 2013, preprints took off <REF-49> .",,"Add,Fact/Evidence",Fact/Evidence
8845,7-1925,7-1925_v2_48@2,,"Its concept has resulted in a number of discipline-specific repositories in other sub-fields, for example bioRXiv for biology <REF-49> .",,"Add,Fact/Evidence",Fact/Evidence
8846,7-1925,7-1925_v2_48@6,,"In biology, preprints finally took off after 2013 with the launch of platforms such as launch of PeerJ Preprints and bioRxiv <REF-49> .",,"Add,Fact/Evidence",Fact/Evidence
8847,7-1925,7-1925_v2_55@2,,"Social scientists have however been slow to adopt Green OA, which might be because readers consider the article version of a manuscript as important and are likely to distrust versions of articles held in a repository <REF-76> .",,"Add,Fact/Evidence",Fact/Evidence
8848,7-1925,7-1925_v2_59@1,,"For scholars, open repositories appear to be of greater importance than Gold OA journals <REF-9> – <REF-11> , <REF-17> .",,"Add,Fact/Evidence",Fact/Evidence
8849,7-1925,7-1925_v2_59@2,,Not much information is available on the importance of Hybrid and Bronze OA.,,"Add,Claim",Claim
8850,7-1925,7-1925_v2_60@6,,"A recent report however demonstrates that research and communication in the humanities are largely taking place in an electronic environment, which includes blogs or wikis, and that the distribution of scientific information occurs simultaneously through print and digital media, with the latter gaining importance <REF-85> .",,"Add,Fact/Evidence",Fact/Evidence
8851,7-1925,7-1925_v2_61@6,,Some publishers now offer Hybrid OA for their existing subscription journals <REF-81> .,,"Add,Fact/Evidence",Fact/Evidence
8852,7-1925,7-1925_v2_61@7,,This allows authors to conform with most OA mandates while publishing their work in familiar journals by traditional publishers.,,"Add,Claim",Claim
8853,7-1925,7-1925_v2_61@8,,This might explain why Hybrid OA is popular in these disciplines.,,"Add,Claim",Claim
8854,7-1925,,7-1925_v1_22@8,,"As such, medicine and health-related fields implemented OA to an even smaller degree than the humanities have in the early years of OA (19% OA reported for humanities in 2010 <REF-9> ).","Delete,Fact/Evidence",Fact/Evidence
8855,7-1925,7-1925_v2_74@1,,"While there is little doubt over the notion that the proportion of scholarly literature that is openly accessible has increased continuously across all disciplines, the studies included in our review show great variation in terms of how much of the literature is OA.",,"Add,Claim",Claim
8856,7-1925,7-1925_v2_74@3,,"In part, this variation could be explained by the fact that studies, which reported high OA levels, included ASNs and FA in their estimations.",,"Add,Claim",Claim
8857,7-1925,7-1925_v2_74@4,,"This caused OA shares to be overreported <REF-10> , <REF-17> , <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
8858,7-1925,7-1925_v2_74@5,,"Because most of these studies included ASNs and FA not as separate OA sub-type but as parts of ""Green OA"" or ""Other free availability"" together with other Hybrid and Bronze OA, it was not possible to quantify the size of overreporting.",,"Add,Claim",Claim
8859,7-1925,7-1925_v2_74@6,,"At the same time, Piwowar et al. (2018) and Bosman and Kramer (2018), who reported particularly low OA levels, used the oaDOI service to search for freely available full-text papers, which has been shown to be more conservative than methods used by other studies in our review, e.g. Archambault (2014).",,"Add,Fact/Evidence",Fact/Evidence
8860,7-1925,7-1925_v2_74@7,,"Their results should therefore be interpreted as minimum proportions of papers that are OA <REF-11> , <REF-25> .",,"Add,Fact/Evidence",Fact/Evidence
8861,7-1925,7-1925_v2_75@2,,"Third, at least for the medical, life and natural sciences, OA mandates are usually combined with convenient open repositories for depositing articles and with sufficient funds for covering fees for publication in OA journals.",,"Add,Claim",Claim
8862,7-1925,7-1925_v2_75@3,,"This finding is in line with other reviews that have identified the interplay between bottom-up and topdown factors as the driving force for OA <REF-6> , <REF-103> .",,"Add,Fact/Evidence",Fact/Evidence
8863,7-1925,7-1925_v2_75@4,,"Some reviews report the interplay between ’soft factors’, such as different degrees of awareness and cultures, and ’hard factors’, such as institutional barriers, as the main determinant of disciplinary OA publishing patterns <REF-104> .",,"Add,Fact/Evidence",Fact/Evidence
8864,7-1925,7-1925_v2_76@2,,"Evidence on the importance of the remaining OA routes is sparse as only three studies have determined respective uptake levels <REF-10> , <REF-11> , <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
8865,7-1925,7-1925_v2_76@5,,ASNs and FA also are of importance for making research outputs openly accessible <REF-18> .,,"Add,Fact/Evidence",Fact/Evidence
8866,7-1925,7-1925_v2_76@6,,Some of these routes are more open and sustainable than others.,,"Add,Claim",Claim
8867,7-1925,7-1925_v2_76@7,,"In general, the more a publication outlet allows for immediate readability and reuse and the more it guarantees long-term access to its contents, the more open and sustainable it is <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
8868,7-1925,7-1925_v2_76@9,,"Also, publishers may decide to change contents or to remove them entirely <REF-20> .",,"Add,Fact/Evidence",Fact/Evidence
8869,7-1925,7-1925_v2_76@10,,Contents hosted on ASNs and personal websites are vulnerable to take-down notices by publishers due to potential copyright infringements.,,"Add,Claim",Claim
8870,7-1925,7-1925_v2_76@11,,This is of concern as these sub-types feature high uptake levels.,,"Add,Claim",Claim
8871,7-1925,7-1925_v2_77@0,,The studies included in our review suffer from limitations in determining uptake levels for OA routes.,,"Add,Claim",Claim
8872,7-1925,7-1925_v2_77@1,,"First, some studies merged different OA sub-types, for example ASNs with Green OA <REF-1> , Gold with Hybrid and Bronze OA <REF-17> or ASNs with Hybrid and Delayed OA <REF-10> .",,"Add,Fact/Evidence",Fact/Evidence
8873,7-1925,7-1925_v2_77@2,,"Also, studies did not assess Platinum OA as a separate OA route, but likely as part of Gold OA.",,"Add,Claim",Claim
8874,7-1925,7-1925_v2_77@3,,"As a result, estimates for some OA sub-types are overreported, which limits the comparability of studies.",,"Add,Claim",Claim
8875,7-1925,7-1925_v2_77@4,,"Second, for most studies, Green OA uptake levels are underreported <REF-1> , <REF-9> , <REF-11> , <REF-13> , <REF-14> , <REF-17> , <REF-18> , <REF-24> , <REF-25> .",,"Add,Fact/Evidence",Fact/Evidence
8876,7-1925,7-1925_v2_77@5,,This is because databases like Scopus and WoS employ strict demarcations for Green OA as OA in the form of author submitted versions are not included.,,"Add,Claim",Claim
8877,7-1925,,7-1925_v1_22@12,,"Because of higher OA growth rates in medicine and health towards the end of this phase, these fields soon overtook the natural and technical sciences in embracing the idea of OA.","Delete,Claim",Claim
8878,7-1925,7-1925_v2_77@6,,"Also, not all repositories are harvested by these databases, so that Green OA contents are incomplete <REF-25> .",,"Add,Fact/Evidence",Fact/Evidence
8879,7-1925,7-1925_v2_78@5,,Chemistry and engineering feature OA levels comparable the humanities and law.,,"Add,Claim",Claim
8880,7-1925,7-1925_v2_78@9,,"For social scientists, open repositories are of central importance, closely followed by publication in Gold OA journals, and, with some distance, Hybrid and Bronze OA.",,"Add,Claim",Claim
8881,7-1925,7-1925_v2_78@12,,"Similarly, Liu and Li (2018) found that both the social and natural sciences experienced OA growth, but note that the social sciences now feature a lower absolute quantity and relative share of OA publications <REF-104> .",,"Add,Fact/Evidence",Fact/Evidence
8882,7-1925,7-1925_v2_79@1,,"In our systematic review, the strictness of inclusion criteria caused studies to be left out that also analysed disciplinary OA publishing practices, albeit focusing on only one type of OA mechanism or one discipline.",,"Add,Fact/Evidence",Fact/Evidence
8883,7-1925,7-1925_v2_79@5,,"Further, the included bibliometric studies differed substantially in terms of their definitions of OA, included OA subtypes, covered publication years, employed search strategies for OA full texts and time-lags between when levels of OA was measured and when studied materials were published.",,"Add,Claim",Claim
8884,7-1925,7-1925_v2_79@6,,We tried to account for this heterogeneity in our review.,,"Add,Fact/Evidence",Fact/Evidence
8885,7-1925,7-1925_v2_79@9,,"Furthermore, we included author surveys to explain publishing behaviour.",,"Add,Fact/Evidence",Fact/Evidence
8886,7-1925,7-1925_v2_79@10,,There might be discrepancies between what scholars self-report about their publishing preferences and what really drives their behaviour.,,"Add,Claim",Claim
8887,7-1925,7-1925_v2_82@0,,Notes,,"Add,Other",Other
8888,7-1925,7-1925_v2_83@0,,"1 For an in-depth review of the literature on OA, see for example Tennant et al. (2017) <REF-6> .",,"Add,Fact/Evidence",Fact/Evidence
8889,7-1925,7-1925_v2_84@0,,"2 Of note, for analytical purposes of this article, ASNs and FA will be included in the results section.",,"Add,Claim",Claim
8890,7-1925,7-1925_v2_88@0,,6 For a comprehensive discussion of the merits of these perspectives in explaining publishing practices see Kling & Kim (2000) and Oostveen (2004).,,"Add,Fact/Evidence",Fact/Evidence
8891,7-1925,7-1925_v2_89@0,,7 See for example swissuniversity guidelines addressed at Swiss higher education institutions for drafting own OA policies <REF-101> .,,"Add,Fact/Evidence",Fact/Evidence
8892,7-1925,,7-1925_v1_8@3,,"From an information-processing perspective, scholars across all fields should see these benefits and use OA communication channels uniformly <REF-5> .","Delete,Fact/Evidence",Fact/Evidence
8893,7-1925,,7-1925_v1_25@4,,"Relative uptake on Bronze OA was determined to be an average 13.2% for publication years 2009 and 2014 and 12.9% for publication years from 2009 to 2015 <REF-12> , <REF-17> .","Delete,Fact/Evidence",Fact/Evidence
8894,7-1925,,7-1925_v1_25@7,,"Two more recent studies have revealed that the publication of articles free to read on the publisher page without open license (Bronze OA) also is of substantial relevance for OA in the medical sciences, featuring similar prevalence levels as Gold OA.","Delete,Claim",Claim
8895,7-1925,,7-1925_v1_9@2,,"In the absence of a valid theory of how academic disciplines adopt OA, resources may be dedicated to ventures that are not sustainable.","Delete,Claim",Claim
8896,7-1925,,7-1925_v1_27@3,,These perspectives emphasize particular sets of criteria as relevant for analysing publishing practices while other sets of criteria are considered irrelevant or ignored <REF-5> .,"Delete,Fact/Evidence",Fact/Evidence
8897,7-1925,,7-1925_v1_27@4,,Technological determinism suggests that technology is the driving force behind social and cultural change <REF-24> .,"Delete,Fact/Evidence",Fact/Evidence
8898,7-1925,,7-1925_v1_27@5,,Studies adopting this perspective accordingly focus on the infrastructures and technical aspects of scholarly communication channels in explaining how OA is implemented across disciplines.,"Delete,Claim",Claim
8899,7-1925,,7-1925_v1_27@6,,Social and cultural factors are believed to be of less or no relevance in explaining the emergence of OA <REF-5> .,"Delete,Fact/Evidence",Fact/Evidence
8900,7-1925,,7-1925_v1_27@7,,SCOT perspectives view technology as a social phenomenon constructed by the society producing and using it.,"Delete,Claim",Claim
8901,7-1925,,7-1925_v1_27@8,,"In order to analyse OA publishing patterns, one would have to first understand the social relations within which respective technologies are used <REF-25> .","Delete,Fact/Evidence",Fact/Evidence
8902,7-1925,,7-1925_v1_27@14,,This process involves a set of conscious and unconscious choices between different technical options <REF-28> .,"Delete,Fact/Evidence",Fact/Evidence
8903,7-1925,,7-1925_v1_27@23,,The analytical dimensions entailed in this framework are illustrated in Table 4 .,"Delete,Fact/Evidence",Fact/Evidence
8904,7-1925,,7-1925_v1_31@3,,"Factors facilitating OA can be identified as strong OA mandates combined with either funder-operated repositories or available funding for article processing charges (APCs), the richness in high-quality and prestigious OA journals and the wide circulation of publications in these outlets.","Delete,Claim",Claim
8905,7-1925,,7-1925_v1_31@4,,"A major barrier to OA in the medical sciences are authors’ concerns over the quality of peer review in OA journals, which is related to the emergence of fraudulent journals and publishers.","Delete,Claim",Claim
8906,7-1925,,7-1925_v1_32@1,,"For example, in 2004, Sara Schroter and colleagues interviewed authors who submitted articles to the BMJ.","Delete,Fact/Evidence",Fact/Evidence
8907,7-1925,,7-1925_v1_32@2,,"Almost all authors supported the concept of OA, but many were concerned about poor quality research being published for a fee, and OA was not a factor of importance when selecting a journal <REF-30> .","Delete,Fact/Evidence",Fact/Evidence
8908,7-1925,,7-1925_v1_32@3,,"More recently, the 2014 international author survey conducted by publisher Taylor & Francis showed that investigators working in Science, Technology and Medicine (SEM) mentioned wider circulation than publication in a subscription journal as an advantage of OA, but were strongly against to the use of their work for commercial gain without their explicit permission <REF-32> .","Delete,Fact/Evidence",Fact/Evidence
8909,7-1925,,7-1925_v1_32@4,,"Authors expected rigorous peer review and rapid publication in return for paying for OA publication <REF-32> , <REF-33> .","Delete,Fact/Evidence",Fact/Evidence
8910,7-1925,,7-1925_v1_32@6,,"A study from India found that the most important factors influencing the selection of medical or dental journals were that the journal is indexed in widely used bibliographic databases, has an online submission system, a satisfactory impact factor and peer review, and that APCs are affordable <REF-36> .","Delete,Fact/Evidence",Fact/Evidence
8911,7-1925,,7-1925_v1_32@7,,The importance of affordable APCs may explain why authors from resource-limited settings are over-represented among publications in fraudulent journals that charge small fees but do not provide proper peer review or add value through editing <REF-37> .,"Delete,Fact/Evidence",Fact/Evidence
8912,7-1925,,7-1925_v1_33@3,,Policies on prior publication remain tight for most of these journals.,"Delete,Claim",Claim
8913,7-1925,,7-1925_v1_34@8,,"Submissions into the PMC undergo indexing and formatting procedures, which produces advanced metadata and unique identifiers <REF-45> .","Delete,Fact/Evidence",Fact/Evidence
8914,7-1925,,7-1925_v1_34@9,,"Of interest, even though not of the same relevance as PMC, is also the PeerJ Preprint section, which allows authors to submit preprints and postprints from the biological and medical sciences.","Delete,Claim",Claim
8915,7-1925,,7-1925_v1_2@3,,This study investigates the underlying mechanisms that cause disciplines to vary in their OA publishing practices.,"Delete,Fact/Evidence",Fact/Evidence
8916,7-1925,,7-1925_v1_35@2,,"Further, medical research is in large part funded by third-party funding, for example by the World Health Organization (WHO) and the Wellcome Trust.","Delete,Claim",Claim
8917,7-1925,,7-1925_v1_35@3,,"These organizations have strong OA mandates while, at the same time, providing both convenient open repositories for depositing articles and sufficient funds for covering processing charges for publication in OA journals <REF-46> .","Delete,Fact/Evidence",Fact/Evidence
8918,7-1925,,7-1925_v1_36@4,,"Besides the NIH, this includes the WHO and the Wellcome Trust.","Delete,Claim",Claim
8919,7-1925,,7-1925_v1_36@7,,Both funders state that they will withhold or suspend payments if articles are not made OA.,"Delete,Claim",Claim
8920,7-1925,,7-1925_v1_38@4,,"While Green OA seems to be of central relevance for OA publishing within physics, astronomy, biology, information technology and mathematics (followed by Bronze, Gold and, by some distance, Hybrid OA), scholars in chemistry and biology make larger shares of their research OA through publication in Gold OA journals than in open repositories.","Delete,Claim",Claim
8921,7-1925,,7-1925_v1_38@5,,"Factors facilitating OA in the natural and technical sciences can be identified as the long-existing culture of preprint distribution, availability in funding for APCs and high levels of awareness of and familiarity with OA publishing.","Delete,Claim",Claim
8922,7-1925,,7-1925_v1_38@6,,Barriers to OA are concerns about the quality of OA journals and high degrees of industrial integration in some fields.,"Delete,Claim",Claim
8923,7-1925,,7-1925_v1_39@1,,"Before it was possible to make documents available electronically, a paper-based culture of preprint distribution developed in the 1960s, especially in high-energy physics <REF-49> .","Delete,Fact/Evidence",Fact/Evidence
8924,7-1925,,7-1925_v1_39@2,,"With the emergence of the Internet, scholars began sharing electronic versions of their preprints informally via electronic mail and when Paul Ginsparg established the open repository arXiv in 1991, scholars started making their preprints openly accessible through centrally self-archiving them in arXiv <REF-4> .","Delete,Fact/Evidence",Fact/Evidence
8925,7-1925,,7-1925_v1_39@5,,"As a consequence, Green OA has become the most popular way of making research outputs OA in physics, mathematics, astronomy, information technology and biology.","Delete,Claim",Claim
8926,7-1925,,7-1925_v1_39@6,,"Publishing in journals (closed-access and Gold, Hybrid or Bronze OA) is less prominent for scholars within these fields.","Delete,Claim",Claim
8927,7-1925,,7-1925_v1_12@2,,"This relates to definitions of OA, included OA routes, covered publication years and employed search strategies for OA full texts.","Delete,Fact/Evidence",Fact/Evidence
8928,7-1925,,7-1925_v1_39@8,,"Despite the preprint culture in some of the natural sciences, 40% to 50% of all research outputs overall remain closed-access today.","Delete,Claim",Claim
8929,7-1925,,7-1925_v1_39@11,,"Consequently, OA journals within the natural sciences have not yet been able to match the reputation of subscription journals <REF-52> .","Delete,Fact/Evidence",Fact/Evidence
8930,7-1925,,7-1925_v1_41@2,,"Even though repositories do not employ formal mechanisms of quality control, scholars within the natural sciences use them to first, disseminate their research outputs without publication delays, and second, stay informed about ongoing research within their fields <REF-4> .","Delete,Fact/Evidence",Fact/Evidence
8931,7-1925,,7-1925_v1_41@6,,"Exemplary journals in engineering are the International Journal of Antennas and Propagation, the Journal of Engineered Fibers and Fabrics, Journal of Scientific and Industrial Research and Thermal Science <REF-55> .","Delete,Fact/Evidence",Fact/Evidence
8932,7-1925,,7-1925_v1_41@7,,"Chemistry journals that enjoy popularity are the Archive for Organic Chemistry, Beilstein Journal of Organic Chemistry, Chemistry Central, Catalysts and ChemistryOpen <REF-52> .","Delete,Fact/Evidence",Fact/Evidence
8933,7-1925,,7-1925_v1_43@10,,"When circumstances require publication in journals that are not covered by SCOAP, the APCs must be covered by funds from outside the CERN Budget, for example through EU projects or by other institutions.","Delete,Claim",Claim
8934,7-1925,,7-1925_v1_45@3,,"The low uptake on OA is due to a variety of reasons, including low levels of awareness, concerns about quality and prestige of OA journals, the central role of monographs for career advancement and difficulties in accessing funding for APCs and Book Processing Charges (BPCs).","Delete,Claim",Claim
8935,7-1925,,7-1925_v1_45@4,,"Having said that, the social sciences are currently experiencing a cultural shift towards conducting science more openly, which manifests itself in an increasing embracement of OA.","Delete,Claim",Claim
8936,7-1925,,7-1925_v1_46@3,,"As a consequence, OA publishing activity remains low for the social sciences.","Delete,Claim",Claim
8937,7-1925,,7-1925_v1_46@5,,Relevant to the appreciation of OA in the social sciences is also the importance attached to monographs.,"Delete,Claim",Claim
8938,7-1925,,7-1925_v1_47@6,,OLH is based on a business model that is called “Library Partnership Subsidy” and which asks libraries to pay a relatively small annual subscription fee to enable OA to scientific publications.,"Delete,Claim",Claim
8939,7-1925,,7-1925_v1_47@7,,"The model originally was aimed at journals in the humanities and social sciences, but has been expanded to monographs <REF-63> .","Delete,Fact/Evidence",Fact/Evidence
8940,7-1925,,7-1925_v1_47@8,,The goal of KU is to create a financially sustainable route to OA for monographs through a global co-operated model where libraries use their existing acquisition budgets to enable OA to monographs <REF-63> .,"Delete,Fact/Evidence",Fact/Evidence
8941,7-1925,,7-1925_v1_47@11,,One well-known example of this is OpenEdition.,"Delete,Claim",Claim
8942,7-1925,,7-1925_v1_47@12,,"While long-term access to research outputs is questionable within these models, OpenEdition and others managed to convince otherwise conservative publishers to create open versions of their journal volumes and monographs <REF-66> .","Delete,Claim",Claim
8943,7-1925,,7-1925_v1_48@2,,"Because OA preprint repositories do not employ peer review, however, social scientists have been slow to adopt Green OA.","Delete,Claim",Claim
8944,7-1925,,7-1925_v1_48@4,,Key academic journals in most countries remain closed access <REF-68> .,"Delete,Fact/Evidence",Fact/Evidence
8945,7-1925,,7-1925_v1_52@1,,This is partly due to the fact that these disciplines exist in a “dry climate” of funding for gold OA models that rely on APCs <REF-73> .,"Delete,Fact/Evidence",Fact/Evidence
8946,7-1925,,7-1925_v1_52@2,,"Low uptake is also due, though, to the fact that the monograph plays such a central role in many humanities disciplines, but the funding challenges for open access to such outputs remains an unresolved problem at scale <REF-74> , <REF-75> .","Delete,Fact/Evidence",Fact/Evidence
8947,7-1925,,7-1925_v1_12@17,,This procedure resulted in a total of 11 studies.,"Delete,Fact/Evidence",Fact/Evidence
8948,7-1925,,7-1925_v1_52@4,,"Given that the humanities focus on the study of human cultures and artforms, it is, though, nonetheless surprising that more humanists do not seek to reach general public audiences through broader availability of their research work.","Delete,Claim",Claim
8949,7-1925,,7-1925_v1_53@2,,"Although institutional signups to the San Francisco Declaration on Research Assessment may help to change this through a shift to evaluation at the article level, the focus on the Impact Factor in that declaration may make it harder to alter evaluative cultures in these disciplines.","Delete,Claim",Claim
8950,7-1925,,7-1925_v1_55@2,,"Postpublication peer-review remains rare and usually elicits scant participation without active intervention, with a few notable exceptions and experiments <REF-82> , <REF-83> .","Delete,Fact/Evidence",Fact/Evidence
8951,7-1925,,7-1925_v1_56@5,,Museum policies on licensing have not kept pace with digital publication practices and still often rely on “number of copies” as a metric determining pricing for re-use.,"Delete,Claim",Claim
8952,7-1925,,7-1925_v1_56@6,,"Under such a paradigm, it can be difficult (or very expensive) to negotiate re-use rights for unlimited online dissemination.","Delete,Claim",Claim
8953,7-1925,,7-1925_v1_56@8,,"Creative writing scholars are often assessed on whether they can produce a “bestselling novel”, which works poorly under an OA model.","Delete,Claim",Claim
8954,7-1925,,7-1925_v1_59@2,,"In part, this is because of low levels of awareness and little demand for OA publishing outlets amongst legal scholars and practicing lawyers.","Delete,Claim",Claim
8955,7-1925,,7-1925_v1_59@3,,Those who would most benefit from the OA movement (e.g. law schools unable to subscribe to a wide range of law journals and practitioners in smaller law firms) have little influence over publication behavior.,"Delete,Claim",Claim
8956,7-1925,,7-1925_v1_59@4,,"Further, despite the rising importance of international law, the relevance of national legal systems remains high, causing most law journals and law books to focus on the legal situation in a specific country and to be managed by publishing houses in that same country.","Delete,Claim",Claim
8957,7-1925,,7-1925_v1_59@5,,"Often, legal scholars know their publisher(s) personally and tend to publish in a relatively small number of journals -– most of which are closed access.","Delete,Claim",Claim
8958,7-1925,,7-1925_v1_60@7,,"According to Hunter (2005), scholarship in law “is arguably the most useful to the public and that has the greatest effect on public policy”.","Delete,Fact/Evidence",Fact/Evidence
8959,7-1925,,7-1925_v1_61@2,,"Hence, a large and growing number of US law journals are OA.","Delete,Claim",Claim
8960,7-1925,7-1925_v2_71@0,7-1925_v1_64@0,E) Open access mandates and policies – OA mandates by public funding agencies and research foundations only have limited impact since legal research is relatively inexpensive and does not depend on third party funding in large parts <REF-96> .,"E) OA mandates and policies – OA mandates by public funding agencies, research foundations and private companies only have limited impact in the field of law since legal research is relatively inexpensive and therefore does not depend on third party funding in large parts <REF-90> .","Modify,Fact/Evidence",Fact/Evidence
8961,7-1925,7-1925_v2_71@3,7-1925_v1_64@4,"In 2009, the directors of the law libraries of 12 US Universities signed the Durham Statement on OA to Legal Scholarship, which urges law schools to make their scholarship immediately available upon publication in stable, open and digital formats <REF-102> .","In 2009, the directors of the law libraries of 12 US Universities signed the Durham Statement on Open Access to Legal Scholarship.","Merge+Modify,Clarity",Clarity
8962,7-1925,7-1925_v2_71@3,7-1925_v1_64@5,"In 2009, the directors of the law libraries of 12 US Universities signed the Durham Statement on OA to Legal Scholarship, which urges law schools to make their scholarship immediately available upon publication in stable, open and digital formats <REF-102> .","This statements urges law schools to make the definitive versions of journals and other scholarship produced at the school immediately available upon publication in stable, open, digital formats, rather than in print <REF-94> .","Merge+Modify,Fact/Evidence",Fact/Evidence
8963,7-1925,7-1925_v2_72@0,7-1925_v1_65@0,Discussion,Discussion and conclusion,"Modify,Other",Other
8964,7-1925,7-1925_v2_73@0,7-1925_v1_66@3,Many of the discussions surrounding OA revolve around how it affects publishing practices across academic disciplines.,"While there is little doubt about the notion that OA is of global relevance with the potential to revolutionize the ways in which scholarly publications are shared, many of the discussions surrounding OA still revolve around the question of how it affects publishing practices across different academic disciplines.","Modify,Claim",Claim
8965,7-1925,7-1925_v2_75@1,7-1925_v1_66@4,"Second, funding organisations, governments and universities implement strong OA mandates that require scholars across disciplines to make their research outputs OA.","This question has become increasingly relevant against the background of first, funding organisations, governments and universities implementing OA mandates and policies that require scholars across all disciplines to make their research outputs OA and, second, vast amounts of resources being dedicated to the development, maintenance and advancement of respective publishing infrastructures.","Modify,Claim",Claim
8966,7-1925,7-1925_v2_73@1,7-1925_v1_67@0,"In the first part of this study, we reviewed eleven bibliometric studies that assessed OA publishing across broad academic disciplines and thereby identified discipline-specific OA publishing patterns.","Reviewing bibliometric studies that assessed OA prevalence and publishing patterns across broad academic disciplines in the first part of this review, we examined how different disciplines have adopted OA publishing over time and identified discipline-specific patterns of OA publishing.","Modify,Fact/Evidence",Fact/Evidence
8967,7-1925,7-1925_v2_73@2,7-1925_v1_67@1,"In the second part of this study, we explained these findings by examining a variety of data sources.","In the second part of this review, and based on a social shaping of technology perspective, we examined a variety of data sources and identified discipline-specific barriers and potentials for OA.","Modify,Fact/Evidence",Fact/Evidence
8968,7-1925,7-1925_v2_74@0,7-1925_v1_67@3,"Over the last three decades, scholarly publishing has experienced a fundamental shift from closed access to OA.","We found that, over the last three decades, scholarly publishing has experienced a shift from closed access to OA.","Modify,Claim",Claim
8969,7-1925,7-1925_v2_74@2,7-1925_v1_67@4,"Estimated OA levels for publication years after 2010 varied between 29.4% and 66% <REF-13> , <REF-25> , with most studies reporting OA levels to lie somewhere between 50% and 60% <REF-10> , <REF-14> , <REF-17> , <REF-18> .","The proportion of scholarly literature that is openly accessible has increased continuously across all disciplines, resulting in overall OA levels well above 50% for publication years after 2010.","Modify,Fact/Evidence",Fact/Evidence
8970,7-1925,7-1925_v2_76@0,7-1925_v1_67@5,"Globally, most OA is published as journal articles in subscription journals for which the accepted or the published version can be retrieved from an open repository (Green OA).",Most OA appears to be published as journal articles in subscription journals for which the accepted of the published version can be retrieved from an open repository (Green OA).,"Modify,Clarity",Clarity
8971,7-1925,7-1925_v2_76@1,7-1925_v1_67@6,"Publication of articles in pure OA journals (Gold OA) is also of importance, even though the relative uptake remains well below Green OA for most publication years <REF-1> , <REF-10> , <REF-11> .","Publication of articles in pure OA journals (Gold OA) is also of importance for scholarly publishing, even though the relative uptake on Gold OA remains well below Green OA for most publication years and academic disciplines.","Modify,Fact/Evidence",Fact/Evidence
8972,7-1925,7-1925_v2_76@4,7-1925_v1_67@7,"Publication of articles free to read in subscription based journals either under open licenses (Hybrid OA) or after embargo periods (Delayed OA) are of less relevance for OA publishing than Green, Gold and Bronze OA.","Hybrid OA generally is of little variance for OA publishing, with 1% or less of all scholarly outputs being published as articles free under open licenses in subscription journals.","Modify,Claim",Claim
8973,7-1925,7-1925_v2_76@3,7-1925_v1_67@8,Publication of articles on the journal or publisher website that are free to read without a clearly identifiable license (Bronze OA) is of similar importance as Gold OA.,"The importance of Bronze OA is comparable to Gold OA, featuring similar levels of uptake.","Modify,Claim",Claim
8974,7-1925,7-1925_v2_78@0,7-1925_v1_67@9,The shift of scholarly publishing towards OA occurs uneven across disciplines in two respects.,"Having compared OA publishing patterns for the broad academic disciplines natural and technical sciences, medical sciences, social sciences, law and humanities, we found that the shift of scholarly publishing towards OA occurs uneven across disciplines in two respects.","Modify,Claim",Claim
8975,7-1925,7-1925_v2_78@1,7-1925_v1_67@10,"First, scholars in different disciplines differ in how much they embrace OA.","First, the growth of OA has not been uniform across disciplines; scholars in different disciplines differ substantially in how much they embrace the idea of OA, which manifests itself in varying proportions of openly accessible research outputs across disciplines and sub-disciplines.","Split+Modify,Claim",Claim
8976,7-1925,7-1925_v2_78@2,7-1925_v1_67@10,This manifests itself in varying proportions of openly accessible research outputs across disciplines.,"First, the growth of OA has not been uniform across disciplines; scholars in different disciplines differ substantially in how much they embrace the idea of OA, which manifests itself in varying proportions of openly accessible research outputs across disciplines and sub-disciplines.","Split+Modify,Clarity",Clarity
8977,7-1925,7-1925_v2_78@6,7-1925_v1_67@11,"Second, academic disciplines differ regarding the relative importance of publication channels used by scholars to publish OA.","Second, academic disciplines have not converged on a set of homogeneous OA publishing practices, but differ substantially regarding the OA publishing channels scholars use to publish their research outputs OA.","Modify,Claim",Claim
8978,7-1925,7-1925_v2_78@8,7-1925_v1_67@17,"Green OA plays an important role for scholars in physics, mathematics, information technology and astronomy, while scholars in engineering and chemistry publish most OA through the Gold OA route.","Further, while Green OA plays an important role for scholars in physics, mathematics, information technology, astronomy and biology (followed by Bronze, Gold, and with some distance, Hybrid OA), scholars in engineering and chemistry publish most OA through the Gold OA route.","Modify,Claim",Claim
8979,7-1925,7-1925_v2_22@1,7-1925_v1_16@1,"To do this, we performed a narrative review of the mechanisms and factors that shape OA publishing practices.","To do this, we performed a narrative review of the mechanisms and factors that shape OA publishing practices in different academic disciplines.","Modify,Clarity",Clarity
8980,7-1925,7-1925_v2_78@4,7-1925_v1_67@20,"OA uptake in the social sciences is below the medical and natural sciences, but remains above OA prevalence that we observed for the humanities and law.","The OA uptake in the social sciences is well below the medical and natural and technical sciences, but remains above OA prevalence rates that we observed for the humanities and law.","Modify,Clarity",Clarity
8981,7-1925,7-1925_v2_22@2,7-1925_v1_16@3,"We recruited an interdisciplinary team of researchers covering the natural and technical sciences, medicine, social sciences, law and the humanities.","We recruited an interdisciplinary team of researchers covering the broad academic disciplines natural and technical sciences, medicine and health-related sciences, social sciences and law, arts and the humanities.","Modify,Fact/Evidence",Fact/Evidence
8982,7-1925,7-1925_v2_79@0,7-1925_v1_69@0,Our study has several limitations.,Our review has several limitations and these should be taken into account when interpreting our results.,"Modify,Claim",Claim
8983,7-1925,7-1925_v2_79@2,7-1925_v1_69@1,"Further, most bibliometric studies included in our review assessed publishing practices across broad academic disciplines, which produced coarse-grained data.","First, most of the bibliometric studies included in our review assessed OA publishing practices across broad academic disciplines, that is, the natural and technical sciences, medical sciences, social sciences, humanities and law.","Merge+Modify,Clarity",Clarity
8984,7-1925,7-1925_v2_79@2,7-1925_v1_69@2,"Further, most bibliometric studies included in our review assessed publishing practices across broad academic disciplines, which produced coarse-grained data.",Choosing broad academic disciplines as units of analysis produces data that is fairly coarse-grained.,"Merge+Modify,Clarity",Clarity
8985,7-1925,7-1925_v2_79@3,7-1925_v1_69@3,Differences in the OA uptake between sub-disciplines remain undetected.,"Consequently, there is a chance that relevant differences in publishing practices between sub-disciplines remain undetected.","Modify,Clarity",Clarity
8986,7-1925,7-1925_v2_79@4,7-1925_v1_69@5,We encourage future research to take into account sub-disciplines.,"Therefore, we encourage future bibliometric research to assess OA publishing practices not only across broad disciplines, but to also take into account related sub-disciplines and research fields.","Modify,Clarity",Clarity
8987,7-1925,7-1925_v2_79@7,7-1925_v1_69@10,"As for our narrative review, there is a chance that evidence has been selectively chosen.",A major limitation of narrative reviews is that there is a chance that evidence has been selectively chosen.,"Modify,Clarity",Clarity
8988,7-1925,7-1925_v2_79@8,7-1925_v1_69@11,We tried to keep this to a minimum by using an analytical framework.,We tried to keep limitations in objectiveness to a minimum by basing the narrative review on an analytical framework.,"Modify,Clarity",Clarity
8989,7-1925,7-1925_v2_22@3,7-1925_v1_16@5,"We did not perform a systematic review of the literature, but developed an analytical framework of socio-cultural and technical factors that shape publishing practices.","In doing so, we did not perform a systematic review of the literature.","Merge+Modify,Clarity",Clarity
8990,7-1925,7-1925_v2_79@11,7-1925_v1_70@0,"Despite these limitations, our review is the first to comprehensively explain OA publishing patterns across academic disciplines.","Overall, our review is the first to comprehensively explain OA publishing patterns across academic disciplines.","Modify,Clarity",Clarity
8991,7-1925,7-1925_v2_22@3,7-1925_v1_16@6,"We did not perform a systematic review of the literature, but developed an analytical framework of socio-cultural and technical factors that shape publishing practices.","Instead, we developed an analytical framework of socio-cultural and technical factors that generally shape publishing practices.","Merge+Modify,Clarity",Clarity
8992,7-1925,7-1925_v2_25@1,7-1925_v1_19@1,"In general, studies were concerned with the questions of (1) how much literature is OA across all disciplines and for individual disciplines, and (2) how much literature is published via different OA routes across all disciplines and for individual disciplines.","In general, studies were concerned with the questions of (1) how much of the scholarly literature in a academic discipline is openly accessible, and (2) via which OA route scholarly outputs are made openly accessible.","Modify,Fact/Evidence",Fact/Evidence
8993,7-1925,7-1925_v2_25@2,7-1925_v1_19@3,"Making use of automated web search strategies, studies assessed whether openly accessible versions of scholarly publications could be found on the web.","Making use of automated web search strategies, studies assessed whether openly accessible versions of sampled scholarly publications could be found on the web, for example through GS.","Modify,Clarity",Clarity
8994,7-1925,7-1925_v2_4@2,7-1925_v1_4@1,"The shift towards OA is uneven across disciplines in two respects: first, the growth of OA has been uneven across disciplines, which manifests itself in varying OA prevalence levels.","The shift towards OA is however uneven across disciplines in two respects: first, the growth of OA has been uneven across disciplines, which manifests itself in varying OA prevalence levels.","Modify,Clarity",Clarity
8995,7-1925,7-1925_v2_26@2,7-1925_v1_22@3,We can distinguish between three phases.,"Looking at how different disciplines implemented OA over time, we can distinguish between three phases.","Modify,Claim",Claim
8996,7-1925,7-1925_v2_26@4,7-1925_v1_22@5,"An exception to this are the fields engineering and chemistry, which feature consistently lower OA levels.","An exception to this are the fields engineering and chemistry, which feature OA prevalence rates that consistently are lower than all natural and technical sciences and lower than most other disciplines, including the social sciences and the humanities <REF-1> , <REF-9> .","Modify,Fact/Evidence",Fact/Evidence
8997,7-1925,7-1925_v2_26@5,7-1925_v1_22@6,"The social sciences were also fast in embracing OA, featuring OA prevalence levels only slightly below those reported for the natural sciences <REF-1> , <REF-9> , <REF-24> .","The social sciences were also fast in embracing OA, featuring OA prevalence levels only slightly below those reported for the natural and technical sciences (16% OA in sociology in the time from 1992 to 2003, followed by economics with 13.5% OA and business with 9% OA <REF-21> ; 23.5% OA and 37% OA observed in the social sciences for publication years 2008 and 2010, respectively <REF-1> , <REF-9> ).","Modify,Fact/Evidence",Fact/Evidence
8998,7-1925,7-1925_v2_26@6,7-1925_v1_22@7,"Medical fields were substantially slower in implementing OA than natural and social sciences <REF-1> , <REF-9> , <REF-24> .","Medicine and health-related research fields were substantially slower in implementing OA than most natural and social sciences (OA levels of 6.2% in medicine between 1992 and 2003 <REF-21> ; 21.7% for medicine and 15.2% for other areas related to medicine in 2008 <REF-1> ; 17%, 14% and 12% OA reported for health, clinical medicine and biomedical research in 2010, respectively <REF-9> ).","Modify,Fact/Evidence",Fact/Evidence
8999,7-1925,7-1925_v2_26@7,7-1925_v1_22@9,The second phase of OA is dated between the late 2000s and the mid 2010s and can be characterized as a period of transformation.,The second phase of OA is dated between the mid 2000s and the mid 2010s and can be characterized as a period of transformation.,"Modify,Claim",Claim
9000,7-1925,7-1925_v2_26@9,7-1925_v1_22@10,"In medicine, OA uptake soon increased substantially, causing OA levels in these fields to equal or surpass OA prevalence in other fields <REF-14> .","In medicine and health-related research fields, OA uptake increased substantially, causing OA levels in these fields to equal or surpass OA prevalence in the social sciences and humanities (26% OA determined for medicine for publication years until 2013, while 24% OA showed for arts and humanities <REF-22> ; 59.7% OA in health sciences between 2004 and 2014, while 60.8% of publications in social sciences were OA <REF-16> ).","Modify,Fact/Evidence",Fact/Evidence
9001,7-1925,7-1925_v2_26@8,7-1925_v1_22@11,"For the early period of this phase, OA levels in the natural and technical sciences remained above those observed in other disciplines with reported OA levels between 27% for mathematics and 50% for computer sciences <REF-15> .","For the early period of this phase, OA levels in the natural and technical sciences remained well above those observed in other disciplines (Observed OA levels were 50% in computer sciences, 35% in both geo-sciences and physics, 29% in environmental sciences and 27% in mathematics in publication years until 2013 <REF-22> ; 60% OA in physical sciences in the time from 2004 to 2014 <REF-16> ).","Modify,Fact/Evidence",Fact/Evidence
9002,7-1925,7-1925_v2_26@10,7-1925_v1_22@13,"Particularly biomedical research took on a leading role, featuring reported OA levels of 70.6% (including ASNs and FA) <REF-10> .","Particularly biomedical research took on a leading role in embracing OA (70.6% OA in biomedical research, 67.6% OA in mathematics & statistics, 66.2% for biology, 59.4% for physics & astronomy and 58.8% for earth and environmental sciences, closely followed by public health & health services and clinical medicine with OA levels of 57.2% and 56,3%, respectively, in the period from 2011 to 2013 <REF-10> ).","Modify,Fact/Evidence",Fact/Evidence
9003,7-1925,7-1925_v2_26@12,7-1925_v1_22@15,"The humanities and arts published research outputs to lesser degrees OA, featuring OA levels that vary across studies between 23.3% for visual and performing arts and 35.9% for general arts, humanities and social sciences (both including ASNs and FA) <REF-10> .","The humanities in particular published research outputs to lesser degrees OA than other disciplines (35.0% OA in arts, humanities & social sciences, 34.7% in philosophy & theology, 34.4% in historical studies for publication years 2011 to 2013) <REF-10> .","Modify,Fact/Evidence",Fact/Evidence
9004,7-1925,7-1925_v2_26@14,7-1925_v1_22@17,"Studies consistently show that medical and health-related research fields are taking the leading roles in embracing OA, featuring reported OA uptake levels between 47.8% for clinical medicine and 85% for biomedical research <REF-11> , <REF-13> , <REF-17> , <REF-18> , <REF-25> .","Studies consistently show that medical and health-related research fields are taking the leading roles in embracing OA, featuring OA uptake levels that are well above those reported for other disciplines (Reported OA levels are 60% in medical and life sciences on average for 2009 and 2014 <REF-17> ; 59% for health sciences in 2014 <REF-19> ; 58.5%, 47.8% and 41.8% for biomedical research, clinical medicine and health in publication years from 2009 to 2015, respectively <REF-12> ; 41.7% for life sciences and biomedicine in 2016 <REF-20> and 85%, 79% and 73% for biomedical research, clinical health and health in publication years from 2009 to 2017, respectively <REF-18> ).","Modify,Fact/Evidence",Fact/Evidence
9005,7-1925,7-1925_v2_7@0,7-1925_v1_7@0,"As a response to perceived limitations of the subscription-based model of scholarly publishing and propelled by technical possibilities provided by the internet and the world wide web, Open Access (OA) presents a new model of academic publishing <REF-1> .","As a response to perceived limitations of the subscription-based model of scholarly publishing and propelled by technical possibilities provided by the internet, Open Access (OA) presents a new model of academic publishing <REF-1> .","Modify,Clarity",Clarity
9006,7-1925,7-1925_v2_26@15,7-1925_v1_22@18,"This is closely followed by physics, mathematics and earth and space sciences <REF-11> , <REF-13> , <REF-17> , <REF-18> , <REF-25> .","The medical sciences are closely followed by disciplines from the natural and technical sciences (50% OA for natural sciences on average in 2009 and 2014 <REF-17> ; 55% OA for natural sciences in 2014 <REF-19> ; 52.7% OA for mathematics, 40.4% OA in earth and space, 32.7% OA in biology and 31.6% OA in physics between 2009 and 2015 <REF-12> ; 14.8% for physical sciences / technology in 2016; <REF-20> ; 57% OA for mathematics, 56% OA for earth and space, % 56% OA for physics and 51% OA for biology in publication years from 2009 to 2017 <REF-18> ).","Modify,Fact/Evidence",Fact/Evidence
9007,7-1925,7-1925_v2_26@16,7-1925_v1_22@19,"OA uptake in the social sciences is close behind the natural sciences, followed by law, arts and humanities with some distance <REF-11> , <REF-13> , <REF-17> , <REF-18> , <REF-25> .",OA uptake in the social sciences is close behind the natural sciences (Reported OA levels are 49.9% for social and behavioural sciences in 2009 to 2014 <REF-17> ; 55% for economic and social sciences in 2014 <REF-19> ; 25.1% in social sciences between 2009 and 2015 <REF-12> ; 17.3% in social sciences for 2016 <REF-20> ; 39% for social sciences between 2009 and 2017 <REF-18> ).,"Merge+Modify,Fact/Evidence",Fact/Evidence
9008,7-1925,7-1925_v2_26@16,7-1925_v1_22@20,"OA uptake in the social sciences is close behind the natural sciences, followed by law, arts and humanities with some distance <REF-11> , <REF-13> , <REF-17> , <REF-18> , <REF-25> .","Law, arts and humanities show the lowest OA uptake across all disciplines (OA prevalence rates determined to be 32.3% for law, arts and humanities between 2009 and 2014 <REF-17> ; 24% for arts and humanities in 2014 <REF-19> ; 13.9% for arts and humanities in 2016 <REF-20> ).","Merge+Modify,Fact/Evidence",Fact/Evidence
9009,7-1925,7-1925_v2_7@1,7-1925_v1_7@1,"OA takes different forms but generally offers free and unrestricted access to the outputs of academic research with relaxed constraints on reuse, as opposed to publications being behind subscription paywalls and under copyright <REF-2> .","OA takes different forms but generally offers free and unrestricted access to the outputs of academic research with relaxed constraints on reuse, as opposed to publications being “locked away” behind subscription paywalls <REF-2> .","Modify,Clarity",Clarity
9010,7-1925,7-1925_v2_7@2,7-1925_v1_7@2,"Having gained global recognition, the potential implications of OA for academic publishing continue to generate debate in the academic community.","Having gained global relevance, the potential implications of OA for academic publishing continue to generate debate in the academic community.","Modify,Clarity",Clarity
9011,7-1925,7-1925_v2_7@3,7-1925_v1_7@3,Many of these discussions revolve around how OA affects publishing practices in different academic disciplines <REF-3> .,Many of these discussions revolve around the question of how OA affects publishing practices in different academic disciplines <REF-3> .,"Modify,Clarity",Clarity
9012,7-1925,7-1925_v2_8@1,7-1925_v1_8@1,"OA soon appeared to constitute an “inescapable imperative” <REF-5> for several reasons: first, OA gained early momentum based on a combination of grassroots advocacy initiatives promoting unrestricted access to publications and funders, universities and national governments implementing OA mandates and policies that require scholars to make their outputs publicly accessible <REF-6> .","OA soon appeared to constitute an “inescapable imperative” <REF-5> for several reasons: first, OA gained early momentum based on a combination of grass-root advocacy initiatives promoting the unrestricted access to publications on the one hand and funding organisations, universities and national governments implementing OA mandates and policies that require scholars to make their outputs publicly accessible on the other hand <REF-6> .","Modify,Clarity",Clarity
9013,7-1925,7-1925_v2_2@1,7-1925_v1_2@1,It was a long-held view that it would be only a matter of time before all disciplines fully and relatively homogeneously implemented OA.,It was a long-held view that it would be only a matter of time for all disciplines to fully and relatively homogeneously implement OA.,"Modify,Clarity",Clarity
9014,7-1925,7-1925_v2_8@2,7-1925_v1_8@2,"Second, OA has the potential to enhance scholarly communication by speeding up the dissemination of research outputs, by expanding readership and by increasing the impact of research outputs <REF-5> , <REF-7> .","Second, OA has the potential to enhance scholarly communication by speeding up the dissemination of research outputs, by expanding readership and by increasing the impact of research outputs <REF-7> .","Modify,Fact/Evidence",Fact/Evidence
9015,7-1925,7-1925_v2_8@3,7-1925_v1_8@4,These trends suggested that it would only be a matter of time for all academic disciplines fully to adopt OA and to converge on a stable set of homogeneous OA publishing practices <REF-8> .,These trends suggested that it would only be a matter of time for all academic disciplines and fields to fully adopt OA and to converge on a stable set of relatively homogeneous OA publishing practices <REF-8> .,"Modify,Clarity",Clarity
9016,7-1925,7-1925_v2_8@4,7-1925_v1_8@5,"In contrast to these expectations, recent bibliometric studies show that academic disciplines vary considerably in their OA publishing practices <REF-9> , <REF-10> .","In contrast to these expectations, recent bibliometric studies show that academic disciplines vary considerably in terms of their OA publishing practices <REF-9> , <REF-10> .","Modify,Clarity",Clarity
9017,7-1925,7-1925_v2_27@1,7-1925_v1_25@0,"Most OA is published via the Green route, featuring reported uptake levels that vary across studies between 5.9% (publication years 2011–2013), 21% (publication years 2005–2010) and 31% (publication year 2014, including ASN and FA) <REF-10> , <REF-17> , <REF-17> .","Looking at the relative uptake of OA routes for all disciplines, we observe that most OA is published via the Green route, that is, published as journal articles for which the accepted or the published version can be retrieved from an open repository.","Modify,Fact/Evidence",Fact/Evidence
9018,7-1925,7-1925_v2_27@2,7-1925_v1_25@1,"Gold OA journals are also of importance for scholarly publishing, even though the relative uptake on Gold OA remains below Green OA for most publication years, with reported prevalence levels between 2% (publication years 2005–2010) and 12.1% (publication years 2011–2013) <REF-1> , <REF-10> , <REF-11> , <REF-14> , <REF-18> .","Gold OA journals are also of importance for scholarly publishing, even though the relative uptake on Gold OA remains well below Green OA for most publication years (Relative uptake levels were 11.9% Green OA and 8.5% Gold OA in 2008, respectively, <REF-1> , 21% Green OA and 2% Gold OA in publication years from 2005 to 2010 <REF-9> , 5.9% Green OA and 12.1% Gold OA between 2011 and 2013 <REF-10> , 10.8% Green OA and 7.3% Gold OA on average in publication years 2009 and 2014 <REF-17> , 8.8% Green OA and 49.4% Gold OA in publication years between 2004 and 2014 <REF-16> , 31% Green OA and 23% Gold OA in 2014 <REF-19> and 11.5% Green OA and 7.4% Gold OA in publication years between 2009 and 2015 <REF-12> ).","Modify,Fact/Evidence",Fact/Evidence
9019,7-1925,7-1925_v2_9@0,7-1925_v1_9@0,"Such bibliometric studies are in large part descriptive and, as such, do not analyse the mechanisms that shape discipline-specific OA publishing practices.","Bibliometric studies investigating disciplinary OA publishing practices are in large part descriptive and, as such, do not analyse the mechanisms that shape discipline-specific OA publishing practices.","Modify,Clarity",Clarity
9020,7-1925,7-1925_v2_27@3,7-1925_v1_25@2,"Studies that also assessed the relative uptake on Bronze, Hybrid and Delayed OA have revealed that the importance of Bronze OA is comparable to that of Gold OA and that Hybrid and Delayed OA generally are of little importance for scholarly publishing, with less than 5% of all scholarly outputs being published Hybrid or Delayed OA <REF-11> , <REF-18> .","Studies that also assessed the relative uptake on Hybrid OA and Bronze OA have revealed, that, first, Hybrid OA generally is of little importance for scholarly publishing, with 1% or less of all scholarly outputs being published as articles free under an open license in subscription journals.","Merge+Modify,Fact/Evidence",Fact/Evidence
9021,7-1925,7-1925_v2_27@3,7-1925_v1_25@3,"Studies that also assessed the relative uptake on Bronze, Hybrid and Delayed OA have revealed that the importance of Bronze OA is comparable to that of Gold OA and that Hybrid and Delayed OA generally are of little importance for scholarly publishing, with less than 5% of all scholarly outputs being published Hybrid or Delayed OA <REF-11> , <REF-18> .","Second, the importance of Bronze OA is comparable to that of Gold OA.","Merge+Modify,Clarity",Clarity
9022,7-1925,7-1925_v2_28@2,7-1925_v1_25@9,"For scholars in chemistry and biology, Gold OA journals are of greater importance than any other OA route, followed by Green, Bronze and Hybrid OA.","In contrast, for scholars in chemistry and biology, Gold OA journals are of greater importance than any other OA route.","Modify,Claim",Claim
9023,7-1925,7-1925_v2_28@4,7-1925_v1_25@11,"In the humanities and law, scholars make research outputs openly accessible predominantly through publication of articles in Hybrid OA journals, followed by Green OA, Bronze OA and Gold OA <REF-1> , <REF-10> , <REF-11> , <REF-14> , <REF-17> , <REF-18> .","In the humanities and law, scholars make research outputs openly accessible predominantly through publication of articles in Hybrid OA journals, followed by Green OA, Bronze OA and Gold OA.","Modify,Fact/Evidence",Fact/Evidence
9024,7-1925,7-1925_v2_2@2,7-1925_v1_2@2,"Recent large-scale bibliometric studies show, however, that the uptake of OA differs substantially across disciplines.",Recent large-scale bibliometric studies show however that the uptake of OA differs substantially across disciplines.,"Modify,Grammar",Grammar
9025,7-1925,7-1925_v2_34@4,7-1925_v1_27@10,The so-called “social shaping of technology” (SST) perspective that takes an intermediate standing between these extremes proves to be more useful for analysing publishing practices.,The so-called “social shaping of technology” (SST) perspective that takes an intermediate standing between these extremes proves to be more useful for analysing OA publishing practices.,"Modify,Clarity",Clarity
9026,7-1925,7-1925_v2_34@6,7-1925_v1_27@12,Technology is believed to be a social product patterned by the conditions of its creation and use <REF-28> .,"Instead of evolving according to an inner technical logic or a single social determinant, technology is believed to be a social product patterned by the conditions of its creation and use <REF-27> .","Modify,Fact/Evidence",Fact/Evidence
9027,7-1925,7-1925_v2_34@7,7-1925_v1_27@13,Central to technical change are choices made by social actors during the generation and implementation of new technologies <REF-29> .,Central to technical change are choices made by social actors and groups during the generation and implementation of new technologies.,"Modify,Fact/Evidence",Fact/Evidence
9028,7-1925,7-1925_v2_34@12,7-1925_v1_27@19,These choices are influenced by both technical considerations and socio-cultural aspects.,These operational choices are influenced by both technical considerations and socio-cultural aspects.,"Modify,Clarity",Clarity
9029,7-1925,7-1925_v2_34@14,7-1925_v1_27@21,"In order to explain discipline-specific OA publishing practices, it is necessary to examine the socio-cultural and technical factors that affect publishing choices.","It follows that, in order to explain discipline-specific OA publishing practices, it is necessary to examine the socio-cultural and technical factors that affect publishing choices within particular disciplines.","Modify,Clarity",Clarity
9030,7-1925,7-1925_v2_34@15,7-1925_v1_27@22,"Based on these assumptions, we have developed an analytical framework that places focus upon technical factors and socio-cultural factors alike when analysing patterns of OA publishing practices ( Table 5 ).","Based on these assumptions, we have developed an analytical framework that places focus upon technical factors and socio-cultural factors alike when analysing patterns of OA publishing practices.","Modify,Fact/Evidence",Fact/Evidence
9031,7-1925,7-1925_v2_9@3,7-1925_v1_9@4,"In order to answer these questions, we first synthesise relevant bibliometric studies that were aimed at assessing the prevalence and patterns of OA publishing practices across disciplines.","In order to answer these questions, we first synthesise relevant bibliometric studies that were aimed at assessing the prevalence and patterns of OA publishing practices across academic disciplines.","Modify,Clarity",Clarity
9032,7-1925,7-1925_v2_38@0,7-1925_v1_31@0,"Initially, medicine and health-related disciplines were reluctant to adopt OA publishing.","Initially, medicine and health-related disciplines were reluctant to adopt OA publishing, resulting in OA levels to be well below those observed in the natural and social sciences.","Modify,Claim",Claim
9033,7-1925,7-1925_v2_38@1,7-1925_v1_31@1,"From the mid-2000s onwards, the uptake on OA increased substantially and particularly biomedicine took on a leading role in embracing OA.","From the mid-2000s onwards, however, the uptake on OA increased substantially and particularly biomedicine and clinical medicine took on leading roles in embracing OA.","Modify,Clarity",Clarity
9035,7-1925,7-1925_v2_38@3,7-1925_v1_31@2,"Hybrid OA, Bronze OA and Green OA are of less importance.","Research outputs are predominantly made OA by publication in Gold OA journals, whereas Hybrid OA, Bronze OA and Green OA are of little importance for these disciplines.","Split+Modify,Clarity",Clarity
9036,7-1925,7-1925_v2_39@0,7-1925_v1_32@0,"A) Author behaviour and attitudes – Several surveys and interview studies have shown that a large majority of authors support OA publishing, but the reputation of journals, impact factors, and quality and speed of peer review are more important factors determining the choice of publication outlets <REF-30> – <REF-33> .","A) Author behaviour and attitudes – Several surveys and interview studies have shown that in biomedicine and the life sciences, a large majority of authors support OA publishing, but the reputation of journals, their impact factor, and the quality and speed of peer review are more important factors determining the choice of publication outlets than the OA status <REF-29> – <REF-31> .","Modify,Fact/Evidence",Fact/Evidence
9037,7-1925,7-1925_v2_9@5,7-1925_v1_9@6,We apply this analytical framework to the case of OA publishing and examine evidence on the forces that represent barriers to and potentials for OA.,"We apply this analytical framework to the case of OA publishing and examine evidence on the forces that represent barriers to and potentials for OA, causing OA publishing practices to differ across disciplines.","Modify,Claim",Claim
9038,7-1925,7-1925_v2_39@1,7-1925_v1_32@5,"Surveys among academics from lower income countries indicate that the funding of APCs is an important concern, which might explain why authors from resource-limited settings are over-represented among publications in fraudulent journals that charge small fees but do not provide proper editorial and peer review services <REF-34> – <REF-36> .","Surveys among academics from lower income countries indicate that the funding of APCs is an important concern <REF-34> , <REF-35> .","Modify,Fact/Evidence",Fact/Evidence
9039,7-1925,7-1925_v2_40@0,7-1925_v1_33@0,"B) Publisher behaviour and policies – As the OA model is unlikely to generate the same level of income and profit that can be achieved with the subscription model, commercial medical publishers have been reluctant to convert their subscription journals to OA <REF-3> , <REF-37> .","B) Publisher behaviour and policies – As private profit-oriented companies, most traditional publishers are driven by maximizing income to satisfy their shareholders <REF-3> .","Merge+Modify,Fact/Evidence",Fact/Evidence
9040,7-1925,7-1925_v2_40@0,7-1925_v1_33@1,"B) Publisher behaviour and policies – As the OA model is unlikely to generate the same level of income and profit that can be achieved with the subscription model, commercial medical publishers have been reluctant to convert their subscription journals to OA <REF-3> , <REF-37> .","Consequently, as the OA model is unlikely to generate the level of income and profit that can be achieved with the subscription model, few commercial medical publishers have converted their subscription journals to OA.","Merge+Modify,Fact/Evidence",Fact/Evidence
9041,7-1925,7-1925_v2_40@1,7-1925_v1_33@2,The same applies to academic and professional societies <REF-38> .,This also applies to academic or professional societies <REF-29> .,"Modify,Clarity",Clarity
9042,7-1925,7-1925_v2_40@2,7-1925_v1_33@4,"Some journals have now moved to allowing the self-archiving of submitted manuscripts without embargo periods, while for others self-archiving of accepted versions remains subject to embargo periods of 12 months.","Some journals have now moved to allowing their authors to self-archive submitted manuscripts without an embargo period, while self-archiving of accepted versions of a publication remains subject to a standard embargo period of 12 months.","Modify,Clarity",Clarity
9043,7-1925,7-1925_v2_40@3,7-1925_v1_33@5,"Pioneers among OA medical journals include the Journal of Clinical Investigation, which in 1996 became the first major journal to be freely available.","Pioneers among OA medical journals include the Journal of Clinical Investigation, which in 1996 became the first major journal to be freely available on the web.","Modify,Clarity",Clarity
9044,7-1925,7-1925_v2_9@6,7-1925_v1_9@7,"Doing so, we examine and aggregate evidence from a variety of primary data sources.","Doing so, we examine and aggregate evidence from a variety of primary data sources including, but not limited to, OA mandates and policies, infrastructures of scholarly communication technologies and author surveys.","Modify,Claim",Claim
9045,7-1925,7-1925_v2_40@4,7-1925_v1_33@6,"Publication in the journal was free initially, but APCs were introduced after the journal lost 40% of its institutional subscribers <REF-39> .","Of note, publication in the journal was free to authors initially, but APCs were introduced after the journal lost 40% of its institutional subscribers <REF-38> .","Modify,Fact/Evidence",Fact/Evidence
9046,7-1925,7-1925_v2_40@5,7-1925_v1_33@7,"The BMJ followed in 1998, but moved some contents behind a paywall in 2005 <REF-40> .","The BMJ followed suit in 1998, but moved some content (including editorials and education and debate articles) behind a pay wall in 2005 <REF-39> .","Modify,Fact/Evidence",Fact/Evidence
9047,7-1925,7-1925_v2_40@6,7-1925_v1_33@8,"The number of OA journals increased considerably from 2000 onwards, with the rapid growth of OA publishers such as the not-for-profit publisher Public Library of Science (PLOS) or the commercial publisher BioMedCentral (BMC).","The number of OA journals increased considerably from 2000 onwards, with the arrival and rapid growth of OA publishers such as the not-for-profit publisher Public Library of Science (PLoS) or the commercial publisher BioMedCentral (BMC).","Modify,Clarity",Clarity
9048,7-1925,7-1925_v2_40@7,7-1925_v1_33@9,The launch of OA journals by major biomedical research funders <REF-41> – <REF-43> and the emergence of mega-journals are other factors that facilitate OA <REF-44> .,The launch of OA journals by major biomedical research funders <REF-40> – <REF-42> and the emergence of mega-journals are other factors that have influenced uptake of OA publishing in medical research fields <REF-43> .,"Modify,Fact/Evidence",Fact/Evidence
9049,7-1925,7-1925_v2_41@0,7-1925_v1_34@0,C) Infrastructure of scholarly communication – OA publishing focuses on Gold OA journals and only a small number of OA institutional and subject repositories has emerged.,C) Infrastructure of scholarly communication – OA publishing in the medical sciences focuses on Gold OA journals and only a small number of OA institutional and subject repositories has emerged.,"Modify,Clarity",Clarity
9050,7-1925,7-1925_v2_41@1,7-1925_v1_34@1,"This is because, first, sufficient funding is available for publication in Gold OA journals.",This can be explained as follows.,"Merge+Modify,Clarity",Clarity
9052,7-1925,7-1925_v2_41@2,7-1925_v1_34@3,"Second, journal publications are of central importance in academic hiring and promotion decisions.","Second, journal publications are of central importance in academic hiring and promotion decisions within the medical sciences.","Modify,Clarity",Clarity
9053,7-1925,7-1925_v2_41@4,7-1925_v1_34@5,"An exception to this is the PubMed Central (PMC), which archives full-text scholarly articles and has experienced rapid growth in the late 2000s to early 2010s as the National Institutes of Health (NIH) introduced an OA policy in 2008 that mandates its grantees to deposit the final peer-reviewed version of an article based on NIH-funded research in PMC.","The uptake on open repositories in general is low, but an exception to this is the PubMed Central (PMC), which archives full-text scholarly articles and plays a central role in the medical and life sciences.","Merge+Modify,Claim",Claim
9054,7-1925,7-1925_v2_41@4,7-1925_v1_34@6,"An exception to this is the PubMed Central (PMC), which archives full-text scholarly articles and has experienced rapid growth in the late 2000s to early 2010s as the National Institutes of Health (NIH) introduced an OA policy in 2008 that mandates its grantees to deposit the final peer-reviewed version of an article based on NIH-funded research in PMC.",PMC has experienced rapid growth in the late 2000s as the National Institutes of Health (NIH) introduced an OA policy that mandates its grantees to deposit the final peer-reviewed version of an article based on NIH-funded research in PMC.,"Merge+Modify,Claim",Claim
9055,7-1925,7-1925_v2_41@5,7-1925_v1_34@7,"The embargo was initially 12 months after publication, but was later shortened to 6 months.","The embargo was initially 12 months after publication, but was later shortened to 6 months <REF-44> and journals have since moved to be compliant with this Green OA mandate.","Split+Modify,Fact/Evidence",Fact/Evidence
9056,7-1925,7-1925_v2_41@6,7-1925_v1_34@7,Journals have since moved to be compliant with this Green OA mandate <REF-45> .,"The embargo was initially 12 months after publication, but was later shortened to 6 months <REF-44> and journals have since moved to be compliant with this Green OA mandate.","Split+Modify,Fact/Evidence",Fact/Evidence
9057,7-1925,7-1925_v2_42@0,7-1925_v1_35@0,D) Structural and institutional factors – The main type of work products are journal articles.,D) Structural and institutional factors – The main type of work products in the medical sciences are journal articles.,"Modify,Clarity",Clarity
9058,7-1925,7-1925_v2_42@1,7-1925_v1_35@1,"As research in the medical sciences and related fields mostly is funded by project-specific grants, it is fairly easy to integrate APCs into existing funding structures.","Like the natural sciences, research in the medical sciences and related fields in most parts is funded by project-specific grants, which makes it fairly easy to integrate processing charges for publication in OA journals into existing funding structures.","Modify,Claim",Claim
9059,7-1925,7-1925_v2_43@0,7-1925_v1_36@0,E) Open access mandates and policies – Evolving national and institutional OA policies and mandates have accelerated OA publishing.,"E) OA mandates and policies – Evolving national and institutional OA policies, OA mandates by major funders of (bio-)medical research and the availability of funding for APCs have accelerated the uptake of OA publishing in the medical and life sciences.","Modify,Claim",Claim
9060,7-1925,7-1925_v2_43@1,7-1925_v1_36@1,A substantial number of national governments have moved to require scholars to make their articles OA if based on publicly-funded research.,A substantial number of national governments have moved to require scholars in the medical and life sciences to make their articles OA if based on publicly-funded research by either publishing in OA journals or by making publications OA by depositing the accepted or the published version of an article in a repository.,"Modify,Claim",Claim
9061,7-1925,7-1925_v2_43@2,7-1925_v1_36@2,Scholars can either follow the Gold or the Green route and are granted embargo periods of 6 or 12 months to comply with the latter <REF-13> .,"Usually, scholars are granted embargo periods of 6 or 12 months to comply with the latter <REF-18> .","Modify,Fact/Evidence",Fact/Evidence
9062,7-1925,7-1925_v2_43@3,7-1925_v1_36@3,Major funders of (bio)medical research also play an active role in promoting OA.,"Besides national governments and research institutions, major funders of medical research play an active role in promoting OA.","Modify,Clarity",Clarity
9063,7-1925,7-1925_v2_43@4,7-1925_v1_36@5,"Since 2014, journal articles and book chapters based on research funded by the World Health Organization (WHO) have to be published in either an Gold or Hybrid OA journal or in a subscription journal that allows the depositing of accepted versions in PMC no later than 12 months after publication <REF-46> .","Since 2014, journal articles and book chapters based on WHO-funded research have to be published in either an Gold or Hybrid OA journal or in a subscription journal that allows the author to deposit the accepted version in PMC no later than 12 months after publication <REF-47> .","Modify,Clarity",Clarity
9064,7-1925,7-1925_v2_16@0,7-1925_v1_12@0,The objective of our review is to identify and to synthesize bibliometric studies on the prevalence and patterns of OA publishing across academic disciplines.,The objective of our review is to identify and synthesize large-scale bibliometric studies on the prevalence and patterns of OA publishing across academic disciplines.,"Modify,Clarity",Clarity
9065,7-1925,7-1925_v2_43@5,7-1925_v1_36@6,The Wellcome Trust requires articles to be published in OA journals where a journal makes this option available and to be deposited as the accepted version in an open repositories no later than 6 months.,"Similarly to the NIH, the Wellcome Trust requires articles to be published in OA journals where a journal makes this option available and to be deposited as the accepted version in an open repositories no later than 6 months after publication.","Modify,Clarity",Clarity
9066,7-1925,7-1925_v2_43@6,7-1925_v1_36@8,Both funders provide repository infrastructures (PMC for NIH and PMC or PMC Europe for Wellcome Trust) and APC funds <REF-47> .,Both funders provide repository infrastructures (PMC for NIH and PMC or PMC Europe for Wellcome Trust) and funds for covering APCs <REF-46> .,"Modify,Clarity",Clarity
9067,7-1925,7-1925_v2_43@8,7-1925_v1_36@9,"In contrast to the USA, the policy environment in the UK favoured Gold and Hybrid OA, with particularly high uptake in the life sciences and increasing costs <REF-48> .","In contrast to the USA, the policy environment in the UK favoured gold and hybrid OA, with particularly high uptake in the life sciences and rapidly increasing costs <REF-48> .","Modify,Grammar",Grammar
9068,7-1925,7-1925_v2_45@1,7-1925_v1_38@1,There are differences in the publishing patterns between the sub-disciplines.,"There are, however, substantial differences in the OA publishing patterns between different subdisciplines of the natural and technical sciences.","Modify,Clarity",Clarity
9069,7-1925,7-1925_v2_45@2,7-1925_v1_38@2,"Scholars in physics, mathematics, astronomy and information technology were early pioneers of OA.","Journals in the fields of physics, mathematics, astronomy, information technology and biology were the early pioneers of OA and continue to make large shares of their research outputs OA.","Modify,Claim",Claim
9070,7-1925,7-1925_v2_45@4,7-1925_v1_38@3,Engineering and chemistry feature OA prevalence rates that are consistently lower.,"In contrast, engineering and chemistry feature OA prevalence rates that are consistently much lower than in other fields of the natural and technical sciences and even slightly lower than OA levels observed in the social sciences and humanities.","Modify,Claim",Claim
9071,7-1925,7-1925_v2_16@1,7-1925_v1_12@1,"Such studies explore OA availability ""bottom-up"" through webbased queries of bibliometric databases such as Web of Science (WoS), Google Scholar (GS) or Scopus, and give uptake metrics for various OA routes.","Such studies usually analyse similar samples of academic publications, including data from Web of Science (WoS), Google Scholar (GS) and Scopus, but employ different methods for identifying disciplinary publishing practices within these databases.","Modify,Claim",Claim
9072,7-1925,7-1925_v2_46@0,7-1925_v1_39@0,"A) Author behaviour and attitudes – The distribution of preprints has a long tradition in physics, mathematics, astronomy, and information technology.","A) Author behaviour and attitudes – The distribution of preprints has a long tradition in many fields related to the natural sciences, particularly in physics, mathematics, astronomy, information technology and biology, where scholars commonly share their manuscripts before submitting these for publication to journals.","Modify,Claim",Claim
9073,7-1925,7-1925_v2_46@2,7-1925_v1_39@3,"Surveys have revealed that, to scholars within these fields, rapid publication, high visibility and large readership appear to be the most important factors for choosing a publication outlet, and that scholars associate these features with repositories <REF-50> , <REF-51> .","Surveys have revealed that, to scholars within these fields, rapid publication, high visibility and large readership appear to be the most important factors when it comes to choosing a publication outlet, and that scholars associate these features with depositing preprints in open repositories <REF-33> , <REF-50> .","Modify,Clarity",Clarity
9074,7-1925,7-1925_v2_46@3,7-1925_v1_39@4,"Adding to this, scholars generally show high levels of familiarity with OA <REF-16> , <REF-52> .","Adding to this, scholars in the natural sciences generally show high levels of familiarity with the concepts of OA in general and Green OA in particular <REF-15> , <REF-51> .","Modify,Fact/Evidence",Fact/Evidence
9075,7-1925,7-1925_v2_46@4,7-1925_v1_39@7,"In contrast, scholars in chemistry and engineering value publication in journals over self-archiving, causing Gold OA to play a bigger role than Green OA <REF-51> .","In contrast, scholars in chemistry and engineering value publication in journals over self-archiving in repositories, which is the reason why Gold OA plays a bigger role than Green OA in these fields <REF-50> .","Modify,Clarity",Clarity
9076,7-1925,7-1925_v2_46@5,7-1925_v1_39@9,Chemistry and engineering further show a particularly low uptake on OA.,Chemistry and engineering show particularly low uptake levels on OA.,"Modify,Clarity",Clarity
9077,7-1925,7-1925_v2_46@6,7-1925_v1_39@10,"This might be because scholars have doubts about the quality of peer review in OA journals and are concerned that this might translate into low-quality publications <REF-53> , <REF-54> .",This might be due to the fact that scholars within these fields still have concerns about the quality of peer review in OA journals and are concerned that this might translate into low-quality publications in these outlets.,"Modify,Fact/Evidence",Fact/Evidence
9078,7-1925,7-1925_v2_47@0,7-1925_v1_40@0,B) Publisher behaviour and policies – Commercial publishers and learned societies have been slow in embracing the idea of OA.,B) Publisher behaviour and policies – Commercial publishers as well as learned societies in the natural and technical sciences have been slow in embracing the idea of OA.,"Modify,Clarity",Clarity
9079,7-1925,7-1925_v2_47@2,7-1925_v1_40@3,"As a result, most of the major commercial publishers as well as learned societies have been reluctant to convert their existing journals to OA or to set up new OA journals.","As a result, most of the major commercial publishers, as well as learned societies in the natural sciences, have been reluctant to either convert their existing subscription journals to OA and to set up new OA journals.","Modify,Clarity",Clarity
9080,7-1925,7-1925_v2_16@2,7-1925_v1_12@3,"Because significant methodological differences can be identified within this approach, we conducted a meta-synthesis.","For this reason, we conducted a meta-synthesis.","Modify,Claim",Claim
9081,7-1925,7-1925_v2_47@3,7-1925_v1_40@4,"An exception to this are few large publishing houses that set up new OA journals in disciplines that do not have a culture of preprint distribution, such as chemistry.","An exception to this are few large publishing houses that have started setting up new OA journals in disciplines that do not have a culture of preprint distribution, such as chemistry or engineering.","Modify,Claim",Claim
9082,7-1925,7-1925_v2_47@4,7-1925_v1_40@5,"In disciplines where there is a preprint culture, publishers are relaxing policies on prior publication and enable manuscripts deposited in repositories to be directly submitted to their journals <REF-53> .","In disciplines where there is a culture of preprint distribution, publishers have started relaxing policies on prior publication and enable manuscripts deposited in repositories to be directly submitted to their journals <REF-52> .","Modify,Clarity",Clarity
9083,7-1925,7-1925_v2_48@0,7-1925_v1_41@0,"C) Infrastructure of scholarly communication – In physics, mathematics, astronomy, information technology and, with some delay, in biology, scholars became used to sharing their research outputs openly making use of open repositories <REF-4> .","C) Infrastructure of scholarly communication – In physics, mathematics, astronomy, information technology and biology, scholars are used to sharing their research outputs openly making use of open repositories, particularly arXiv .","Modify,Fact/Evidence",Fact/Evidence
9084,7-1925,7-1925_v2_16@3,7-1925_v1_12@4,"The aim of a meta-synthesis is to integrate qualitatively, to compare, and to analyse methodologically heterogeneous studies, thereby allowing the emergence of interpretive themes <REF-23> .","The aim of a meta-synthesis is to qualitatively integrate, compare and analyse methodologically heterogeneous studies, thereby allowing the emergence of interpretive themes <REF-11> .","Modify,Grammar",Grammar
9085,7-1925,7-1925_v2_48@1,7-1925_v1_41@1,"Originally established within high energy physics, arXiv is the most popular repository and is now used by scholars in most fields of the natural sciences.","Originally established within high energy physics, arXiv now is used by scholars in most fields of the natural sciences and its concept has eventuated in a number of discipline-specific repositories in other fields, including the social sciences.","Modify,Claim",Claim
9086,7-1925,7-1925_v2_48@4,7-1925_v1_41@4,"In fields where there is a smaller culture of self-archiving in repositories, most particularly in chemistry and engineering, and initially in biology, the number of OA journals has grown slowly but steadily.","In fields where there is a smaller culture of self-archiving in repositories, most particularly in chemistry and engineering, the number of OA journals has grown slowly but steadily in recent years.","Modify,Claim",Claim
9087,7-1925,7-1925_v2_48@5,7-1925_v1_41@5,"These journals cover a variety of specific subject areas, are peer-reviewed, and, for the most part, published in English <REF-53> , <REF-57> .","These journals cover a variety of specific subject areas, are peer-reviewed, and, for the most part, are published in English.","Modify,Fact/Evidence",Fact/Evidence
9088,7-1925,7-1925_v2_49@0,7-1925_v1_42@0,"D) Structural and institutional factors – The main types of work products are journal articles, preprints and conference proceedings.","D) Structural and institutional factors – The main types of work products in the natural and technical sciences are journal articles, electronic preprints and conference proceedings, which are published records of conferences, congresses or other meetings.","Modify,Claim",Claim
9089,7-1925,7-1925_v2_49@1,7-1925_v1_42@1,Researchers have reported that the process of self-archiving in repositories is easy and little time-consuming <REF-51> .,Researchers from the natural sciences have reported that the process of self-archiving electronic preprints and conference proceedings is little time-consuming and that they generally experience little difficulties in making research outputs OA using open repositories <REF-50> .,"Modify,Fact/Evidence",Fact/Evidence
9090,7-1925,7-1925_v2_16@4,7-1925_v1_12@5,"Here, we synthesised the results from bibliometric studies to identify patterns of OA publishing practices.","In this study, we synthesised the results from bibliometric studies to identify patterns of OA publishing practices across academic disciplines.","Modify,Clarity",Clarity
9091,7-1925,7-1925_v2_49@2,7-1925_v1_42@2,"Research is in large parts funded by project-specific grants, which would make it fairly easy for scholars to integrate APCs for Gold or Hybrid OA journals into existing funding structures.","In addition, and similar to the medical sciences, research in the natural sciences is in large parts funded by project-specific grants, which would make it fairly easy for scholars to integrate fees for publication in Gold or Hybrid OA journals into existing funding structures.","Modify,Clarity",Clarity
9092,7-1925,7-1925_v2_49@3,7-1925_v1_42@3,"A structural factor that limits OA uptake particularly in chemistry and engineering, is that these fields are industry-oriented, which is incompatible with wide and open knowledge dissemination <REF-58> .","A structural factor that limits the uptake on OA within the natural and technical sciences is that some of these fields, particularly chemistry and engineering, are industry-oriented.","Modify,Fact/Evidence",Fact/Evidence
9093,7-1925,7-1925_v2_49@4,7-1925_v1_42@4,"This adds to the fact that, particularly within engineering, the focus is rather national than international as products are mostly produced for domestic markets <REF-58> , <REF-59> .","This adds to the fact that, particularly within engineering, the focus is rather national than international as products developed by engineers are, for the large part, produced for domestic markets.","Modify,Fact/Evidence",Fact/Evidence
9094,7-1925,7-1925_v2_49@5,7-1925_v1_42@5,"Consequently, large numbers of publications are more practice-oriented and published in closed-access journals that are partly financed by advertising <REF-57> .","As a consequence of these factors, large numbers of publications within these fields are more practice- than science-oriented and are published in closed-access journals that are partly financed by advertising <REF-55> .","Modify,Fact/Evidence",Fact/Evidence
9095,7-1925,7-1925_v2_50@0,7-1925_v1_43@0,"E) Open access mandates and policies – There are strong OA mandates, requiring scholars to make their outputs OA if based on publicly-funded research by following either the Gold or the Green OA route.","E) OA mandates and policies – Reflecting the ambition to make research outputs OA, there are strong OA mandates for the natural and technical sciences.","Modify,Claim",Claim
9096,7-1925,7-1925_v2_16@5,7-1925_v1_12@6,"The search was pre-planned and comprehensive, as it aimed to seek all available studies.","The search was pre-planned and comprehensively, as it aimed to seek all available studies.","Modify,Grammar",Grammar
9097,7-1925,7-1925_v2_50@1,7-1925_v1_43@2,Scholars are granted embargo periods of 6 or 12 months to comply with the latter <REF-13> .,"By default, scholars are granted embargo periods of 6 or 12 months to comply with the latter <REF-18> .","Modify,Clarity",Clarity
9098,7-1925,7-1925_v2_50@2,7-1925_v1_43@3,"Besides public funders, CERN and the Sponsoring Consortium for OA Publishing in Particle Physics (SCOAP) play leading roles in promoting OA.","Besides national and international funding agencies, CERN and the Sponsoring Consortium for Open Access Publishing in Particle Physics (SCOAP) play leading roles in promoting OA.","Modify,Clarity",Clarity
9099,7-1925,7-1925_v2_50@3,7-1925_v1_43@4,SCOAP is an international partnership that aims to provide funding for the conversion of high-energy physics journals to OA.,"SCOAP is an international partnership of funding agencies, research centers and libraries that was launched with the aim of providing funding for the conversion of high-energy physics journals from a subscription model of publishing to OA.","Modify,Claim",Claim
9100,7-1925,7-1925_v2_50@5,7-1925_v1_43@6,Saved monies are used to pay publishers up front to publish OA articles <REF-60> .,"Saved monies feed into a central fund, which is used to pay publishers up front to publish OA articles <REF-56> .","Modify,Fact/Evidence",Fact/Evidence
9101,7-1925,7-1925_v2_50@6,7-1925_v1_43@7,This enables scholars to publish OA without straining own research funds <REF-61> .,"Doing so, the initiative enables scholars to make their research outputs OA without straining their own research funds.","Modify,Fact/Evidence",Fact/Evidence
9102,7-1925,7-1925_v2_50@7,7-1925_v1_43@9,CERN requires its scholars to publish their articles in journals covered by SCOAP.,"The OA policy of CERN requires its scholars to publish their articles, wherever possible, in journals covered by SCOAP.","Modify,Clarity",Clarity
9104,7-1925,7-1925_v2_52@0,7-1925_v1_45@0,"The OA uptake in the social sciences is higher than in most disciplines of the humanities, but remains below the medical and natural sciences.","Overall, the OA uptake in the social sciences is higher than in most disciplines of the humanities, but remains below the medical and natural sciences.","Modify,Clarity",Clarity
9105,7-1925,7-1925_v2_52@2,7-1925_v1_45@1,"Gold OA, Hybrid OA and Bronze OA play a less important role <REF-1> , <REF-9> , <REF-11> , <REF-17> , <REF-18> .",Publishing in Gold OA journals plays a less important role than the archiving of publications in institutional and subject repositories following publication in a subscription journal.,"Modify,Fact/Evidence",Fact/Evidence
9106,7-1925,7-1925_v2_16@7,7-1925_v1_12@9,The searches were conducted in August to October 2018 in a systematic way ( Figure 1 ).,Bibliometric studies were searched in a systematic way.,"Merge+Modify,Fact/Evidence",Fact/Evidence
9107,7-1925,7-1925_v2_52@1,7-1925_v1_45@2,"For social scientists, open repositories appear to be of central importance for making research outputs OA.","For scholars within the social sciences, open repositories appear to be of central importance for making research outputs openly accessible, closely followed by publication in Gold OA journals, and, with some distance, Hybrid and Bronze OA.","Modify,Claim",Claim
9108,7-1925,7-1925_v2_53@0,7-1925_v1_46@0,"A) Author behaviour and attitudes – Author surveys reveal that the awareness of OA publishing is low, and that OA publication outlets have not yet fully become part of the workflow for social scientists <REF-52> , <REF-63> .","A) Author behaviour and attitudes – Author surveys consistently have revealed that the awareness of OA publishing is lower for the social sciences than for the medical and natural sciences, and that OA publication outlets have not yet fully become part of the workflow for social scientists <REF-51> .","Modify,Fact/Evidence",Fact/Evidence
9110,7-1925,7-1925_v2_53@2,7-1925_v1_46@1,Particularly young researchers report high levels of OA engagement <REF-63> .,The knowledge of OA journals and repositories however appears to grow amongst social scientists with particularly young researchers reporting high levels of OA awareness and engagement <REF-58> .,"Split+Modify,Fact/Evidence",Fact/Evidence
9111,7-1925,7-1925_v2_53@3,7-1925_v1_46@2,"Most social scientists support the idea of OA in principle, but stringent quality control, improvement of the manuscript before publication and journal prestige appear to outweigh OA as journal selection criteria <REF-64> , <REF-65> .","Most social scientists support the idea of OA in principle, but stringent quality control, further improvement of the manuscript before publication and journal prestige still appear to outweigh OA in authors’ journal selection criteria <REF-59> , <REF-60> .","Modify,Clarity",Clarity
9112,7-1925,7-1925_v2_53@4,7-1925_v1_46@4,This adds to the fact that scholars and learned societies are concerned about the quality of peer review and editorial services in OA outlets <REF-66> .,"This is also due to the fact that some social scientists and their learned societies are still opposed to OA, which relates mainly to concerns about quality of peer review and editorial services in OA journals <REF-61> .","Modify,Clarity",Clarity
9113,7-1925,7-1925_v2_53@5,7-1925_v1_46@6,"Of relevance is also that the monograph has a central place in the culture of publishing and is relevant to career advancement <REF-65> , <REF-67> .","While in the natural and medical sciences, the large part of research findings is disseminated via journal articles, the monograph has a central place in the culture and ecology of publishing in most of the social sciences and is highly relevant to career advancement <REF-60> , <REF-62> .","Modify,Fact/Evidence",Fact/Evidence
9114,7-1925,7-1925_v2_53@6,7-1925_v1_46@7,"Monographs are less likely to be published OA because of authors’ concerns over restricted editorial services, difficulties in financing Book Processing Charges (BPCs) and doubts if unestablished OA publishers are able to translate authors’ efforts into reputational gain <REF-68> .",Monographs have been shown to be less likely to be published OA.,"Merge+Modify,Clarity",Clarity
9115,7-1925,7-1925_v2_53@6,7-1925_v1_46@8,"Monographs are less likely to be published OA because of authors’ concerns over restricted editorial services, difficulties in financing Book Processing Charges (BPCs) and doubts if unestablished OA publishers are able to translate authors’ efforts into reputational gain <REF-68> .","Amongst other factors, this relates to authors’ concerns over restricted editorial services and doubts whether unestablished OA publishers and formats are able to translate their effort in writing a monograph into reputational gain within the scientific community <REF-63> .","Merge+Modify,Fact/Evidence",Fact/Evidence
9116,7-1925,7-1925_v2_54@0,7-1925_v1_47@0,B) Publisher behaviour and policies – Few publishers have converted existing subscription journals to OA or set up new OA journals.,B) Publisher behaviour and policies – Few publishers in the social sciences have decided to convert their existing subscription-based journals to OA or to set up new OA journals.,"Modify,Clarity",Clarity
9117,7-1925,7-1925_v2_54@1,7-1925_v1_47@1,Key journals remain closed.,Key academic journals in the social sciences remain closed access.,"Modify,Clarity",Clarity
9118,7-1925,7-1925_v2_54@2,7-1925_v1_47@2,"Amongst other factors, this relates to publishers fearing that authors will not be able fund APCs or that switching to OA will result in a loss of prestige <REF-65> .","Amongst other factors, this relates to publishers fearing that their academic authors will not be able to access funding for APCs or that switching to an APC model will result in a loss of prestige – both of which are main factors affecting authors’ choice of publication venue <REF-60> .","Modify,Fact/Evidence",Fact/Evidence
9119,7-1925,7-1925_v2_16@10,7-1925_v1_12@12,The selection of the search terms was based on the topic literature.,The selection of the search terms was based on the topic literature on scholarly communication.,"Modify,Clarity",Clarity
9120,7-1925,7-1925_v2_54@5,7-1925_v1_47@3,"For some journals, such as the Historical Social Research, it has become common practice to make contents automatically OA after two years <REF-70> .","For some journals, such as the Historical Social Research or the Zeitschrift für Soziologie, it has become common practice to make their contents automatically OA after an embargo period of two years either by enabling access to their articles on their own website or by depositing them in an OA repository <REF-64> .","Modify,Fact/Evidence",Fact/Evidence
9121,7-1925,7-1925_v2_54@6,7-1925_v1_47@4,"In addition, a large variety of new economic models of OA publishing has emerged that offers viable alternatives to author-payment model.","In addition to this, a large variety of new economic models of OA publishing has emerged that offers viable alternatives to author-payment model in the social sciences and humanities.","Modify,Claim",Claim
9122,7-1925,7-1925_v2_54@7,7-1925_v1_47@5,"To name only two, this includes Knowledge Unlatched (KU) and the Open Library of Humanities (OLH) <REF-71> .","To name only two, this includes Knowledge Unlatched (KU) and the Open library of Humanities (OLH).","Modify,Fact/Evidence",Fact/Evidence
9123,7-1925,7-1925_v2_16@11,7-1925_v1_12@13,"Second, reference lists and bibliographies of all included studies were evaluated for additional publications.","Second, reference lists and bibliographies of all included studies were evaluated manually for additional publications.","Modify,Clarity",Clarity
9124,7-1925,7-1925_v2_54@8,7-1925_v1_47@9,"Another innovative business model of OA publishing that has gained some popularity is the so-called “freemium” model, which makes HTML versions of articles and books openly available, while PDF and ePub formats are accessible only to subscribers <REF-72> , <REF-73> .",Another innovative business model of OA publishing that has gained some popularity in the social sciences and humanities is the so-called “freemium” model.,"Merge+Modify,Claim",Claim
9125,7-1925,7-1925_v2_54@8,7-1925_v1_47@10,"Another innovative business model of OA publishing that has gained some popularity is the so-called “freemium” model, which makes HTML versions of articles and books openly available, while PDF and ePub formats are accessible only to subscribers <REF-72> , <REF-73> .","This model makes HTML versions of articles and books openly available to everyone, while PDF and ePub formats are accessible only to subscribing libraries and research institutes <REF-65> .","Merge+Modify,Fact/Evidence",Fact/Evidence
9126,7-1925,7-1925_v2_55@0,7-1925_v1_48@0,C) Infrastructures of scholarly communication – Some attempts have been made to promote repositories.,"C) Infrastructures of scholarly communication – The social sciences are currently experiencing a considerable growth of open repositories, resulting in authors being able to choose from more than 200 different OA repositories, the most of which are institutional or subject repositories <REF-67> .","Split+Modify,Clarity",Clarity
9127,7-1925,7-1925_v2_55@1,7-1925_v1_48@0,"Authors are now able to choose from more than 200 different OA repositories, the most of which are institutional or subject repositories <REF-74> , <REF-75> .","C) Infrastructures of scholarly communication – The social sciences are currently experiencing a considerable growth of open repositories, resulting in authors being able to choose from more than 200 different OA repositories, the most of which are institutional or subject repositories <REF-67> .","Split+Modify,Fact/Evidence",Fact/Evidence
9128,7-1925,7-1925_v2_16@12,7-1925_v1_12@14,"Having identified key experts, their GS profiles were also searched for material.","Having identified key experts within the field, their GS profiles were also searched for material.","Modify,Clarity",Clarity
9129,7-1925,7-1925_v2_55@5,7-1925_v1_48@3,Gold OA is also of little importance to social scientists.,Gold OA journals are of even less importance for the social sciences.,"Modify,Clarity",Clarity
9130,7-1925,7-1925_v2_55@6,7-1925_v1_48@5,The few existing OA journals are restricted to highly specified sub-disciplines with limited impact and small readership <REF-77> .,The few existing OA journals in large part are restricted to highly specified sub-disciplines with limited impact and small readership.,"Modify,Fact/Evidence",Fact/Evidence
9131,7-1925,7-1925_v2_54@3,7-1925_v1_48@6,One notable exception is SAGE Open in 2011 – the OA mega journal model already popular in the natural and medical sciences <REF-69> .,"One notable exception to this was the launch of SAGE Open in 2011, which has brought to the social sciences the OA mega journal model already popular in the natural and medical sciences <REF-69> .","Modify,Clarity",Clarity
9132,7-1925,7-1925_v2_16@13,7-1925_v1_12@15,"In an initial screening stage, two independent reviewers screened titles and abstracts of studies and decided on whether to include respective studies.","In an initial screening stage, two independent reviewers screened titles and abstracts of studies and decided on whether to include respective studies in the review.","Modify,Clarity",Clarity
9133,7-1925,7-1925_v2_54@4,7-1925_v1_48@7,"In addition, a few OA journals were launched by academic or professional societies <REF-51> .","In addition to this, a number of OA journals were launched by academic or professional societies, such as Socius: Sociological Research for a Dynamic World launched by the American Sociological Association in 2016 <REF-50> .","Modify,Fact/Evidence",Fact/Evidence
9134,7-1925,7-1925_v2_56@0,7-1925_v1_49@0,D) Structural and institutional factors – Monographs are one of the main work products in the social sciences and highly relevant for academic career advancement.,"D) Structural and institutional factors – Similar to most disciplines of the humanities, monographs are one of the main work products in the social sciences and highly relevant for academic promotion and career advancement.","Modify,Clarity",Clarity
9135,7-1925,7-1925_v2_56@1,7-1925_v1_49@1,"Besides author concerns over prestige and standards of editorial services of OA monograph publishers, the high costs and procedural complexities associated with producing monographs are important factors restricting the uptake on OA of monographs <REF-78> .","Besides author concerns over prestige and standards of editorial services of OA monograph publishers, the high costs and procedural complexities associated with producing monographs are important factors restricting the uptake on OA of monographs in the social sciences <REF-70> .","Modify,Fact/Evidence",Fact/Evidence
9136,7-1925,7-1925_v2_56@2,7-1925_v1_49@2,"In addition to this, social scientists have reported to face significant difficulties in access to grant funding for both APCs and BPCs, as most research in the social sciences is not done by means of project-specific funding <REF-32> .","In addition to this, social scientists have reported to face significant difficulties in access to grant funding for both APCs and BPCs, as most research in the social sciences is not done by means of project-specific funding that is commonly used to compensate APCs in the natural and medical sciences <REF-31> .","Modify,Fact/Evidence",Fact/Evidence
9137,7-1925,7-1925_v2_57@0,7-1925_v1_50@0,"E) Open access mandates and policies – Scholars in the social sciences face similar OA requirements as the natural and medical sciences, albeit with some special regulations.",E) OA mandates and policies – Scholars in the social sciences face similar OA requirements as scholars within the natural and medical sciences do.,"Merge+Modify,Clarity",Clarity
9138,7-1925,7-1925_v2_57@0,7-1925_v1_50@1,"E) Open access mandates and policies – Scholars in the social sciences face similar OA requirements as the natural and medical sciences, albeit with some special regulations.","Some special regulations can be identified, however.","Merge+Modify,Clarity",Clarity
9139,7-1925,7-1925_v2_57@2,7-1925_v1_50@3,Most public funders only recommend OA for monographs.,Most public funders limit themselves to recommending OA for monographs.,"Modify,Clarity",Clarity
9140,7-1925,7-1925_v2_57@3,7-1925_v1_50@4,"One of the few exceptions is the Swiss National Science Foundation (SNSF), which demands the OA publication of monographs and provides respective funding for BPCs <REF-68> , <REF-79> .","One of the few exceptions to this is the SNSF, which demands the OA publication of monographs and provides respective funding for BPCs <REF-63> , <REF-71> .","Modify,Clarity",Clarity
9141,7-1925,7-1925_v2_57@4,7-1925_v1_50@5,The social sciences commonly also are granted longer embargo periods for archiving articles after publication in a subscription journal.,"Second, the social sciences commonly are granted longer embargo periods for the archiving of a journal article after publication in a subscription journal.","Modify,Clarity",Clarity
9142,7-1925,7-1925_v2_16@14,7-1925_v1_12@16,Studies were excluded that did not meet our selection criteria ( Table 2 ).,"Studies were excluded that did not meet our selection criteria, as outlined in Table 1 .","Modify,Clarity",Clarity
9143,7-1925,7-1925_v2_57@5,7-1925_v1_50@6,"While embargo periods of 6 or 12 months are the default for the natural and medical sciences, social scientists usually are granted 12 or 24 months <REF-13> , <REF-80> .","While embargo periods of 6 or 12 months are the default for the natural and medical sciences, social scientists usually have to deposit journal articles in institutional or subject repositories after up to 12 or 24 months following publication <REF-18> , <REF-72> .","Modify,Fact/Evidence",Fact/Evidence
9144,7-1925,7-1925_v2_59@0,7-1925_v1_52@0,The OA uptake in the humanities is lower than in most other fields.,"Generally speaking, OA uptake in the humanities is lower than in most areas of the natural, medical and social sciences.","Modify,Clarity",Clarity
9145,7-1925,7-1925_v2_59@3,7-1925_v1_52@3,One recent study has indicated that Hybrid OA is of central importance for the humanities and that Bronze OA plays a similar role as Gold OA <REF-11> .,"Hybrid OA is of central importance for the humanities, followed by Green OA, Bronze OA and Gold OA.","Modify,Fact/Evidence",Fact/Evidence
9146,7-1925,7-1925_v2_60@0,7-1925_v1_53@0,A) Author behaviour and attitudes – Authors operate within a symbolic economy of prestige that is usually among the prime motivations in choice of publication venue <REF-81> .,"A) Author behaviour and attitudes – As in many academic fields, authors operate within a symbolic economy of prestige that is usually among the prime motivations in choice of publication venue <REF-76> .","Modify,Clarity",Clarity
9147,7-1925,7-1925_v2_60@1,7-1925_v1_53@1,"The relative prestige of publications is determined by a scarcity correlation with a shortage of labour on hiring, tenure, and grant panels, although most humanities fields use an informal hierarchy of publications rather than quantitative measures such as the Impact Factor <REF-82> .","The relative prestige of publications is determined by a scarcity correlation (usually achieved through peer review) with the shortage of evaluative labour on hiring, tenure, and grant panels, although most humanities fields use an informal hierarchy of publications rather than quantitative measures such as the Impact Factor <REF-75> .","Modify,Clarity",Clarity
9148,7-1925,7-1925_v2_16@15,7-1925_v1_12@18,"In a second screening stage, we assessed the full texts and extracted data on reported proportions of publications that were OA from the ""Results"" sections of included studies.","In a second screening stage, we assessed the full text of the included studies.","Merge+Modify,Clarity",Clarity
9149,7-1925,7-1925_v2_60@2,7-1925_v1_53@3,"Further, academics and learned societies have often been opposed to OA, for a variety of reasons that range from concerns to misunderstandings, worries about licensing and plagiarism, or fears for the standing of their members <REF-54> , <REF-83> .","Further, academics and learned societies in the humanities disciplines have often been opposed to open access, for a variety of reasons that range from concerns over misunderstanding, worries about open licensing and plagiarism, or fears for the standing of their members <REF-77> , <REF-78> .","Modify,Clarity",Clarity
9150,7-1925,7-1925_v2_16@14,7-1925_v1_12@19,Studies were excluded that did not meet our selection criteria ( Table 2 ).,"In order to gain the data of interest to our review, we analysed the “Results” sections of primary studies and extracted data on reported proportions of publications that were OA, including both the overall OA proportions and the relative uptake on OA routes.","Merge+Modify,Fact/Evidence",Fact/Evidence
9151,7-1925,7-1925_v2_60@3,7-1925_v1_53@4,"In addition to this, humanities scholars show fairly low levels of awareness of OA and OA publication outlets in their fields <REF-84> .","In addition to this, humanities scholars show fairly low levels of awareness of OA and potential OA publication outlets in their fields <REF-79> .","Modify,Clarity",Clarity
9152,7-1925,7-1925_v2_60@4,7-1925_v1_53@5,"That said, there are signs of a cultural shift with new economic models that do not rely on author payments, such as KU, OLH, Open Humanities Press, Open Book Publishers, Punctum Books, which appear to have some traction with some humanities scholars.","That said, there are signs of a cultural shift with new economic models that do not rely on author payments, such as KU, the OLH, Open Humanities Press, Open Book Publishers, Punctum Books, and others appearing to have some traction with at least some humanities scholars.","Modify,Clarity",Clarity
9153,7-1925,7-1925_v2_60@5,7-1925_v1_53@6,"It is tempting to posit that humanities scholars are less driven by technological change than counterparts in science disciplines, and thereby less inclined towards digital and open publishing solutions.","Although it is tempting to posit that humanities scholars are simply less driven by technological change than their counterparts in scientific disciplines, and thereby less inclined towards digital (and, therefore, open) publishing solutions, this is a generalized assertion that is hard to substantiate.","Modify,Claim",Claim
9154,7-1925,7-1925_v2_61@1,7-1925_v1_54@1,"In switching to an APC or BPC model, publishers fear that their academic authors will not be able to pay.","In switching to an APC or BPC model, often undifferentiated from scientific publications, publishers fear that their academic authors will not be able to pay.","Modify,Clarity",Clarity
9155,7-1925,7-1925_v2_61@3,7-1925_v1_54@3,"Hence there is little movement towards a fully Gold OA ecosystem, although it is unclear what impact the recently announced pan-European initiative, Plan S, may have upon this.","Hence there is little movement towards a fully gold OA ecosystem, although it is unclear what impact the recently announced pan-European initiative, Plan S, may have upon this.","Modify,Grammar",Grammar
9156,7-1925,7-1925_v2_61@4,7-1925_v1_54@4,"That said, most humanities publishers are compliant with green OA mandates <REF-86> .","That said, most humanities publishers are compliant with green OA mandates, such as the UK’s REF policy <REF-80> .","Modify,Fact/Evidence",Fact/Evidence
9157,7-1925,7-1925_v2_61@5,7-1925_v1_54@5,"On the other hand, some humanities scholars have argued that a longer citation half-life (particularly for monographs) should translate to longer embargo periods, although this does not necessarily match up to sales half-lives <REF-87> .","On the other hand, it is also the case that some humanities scholars have argued that a longer citation half-life (particularly for monographs) should translate to longer embargo periods within these disciplines, although this does not necessarily match up to sales half-lives <REF-81> .","Modify,Clarity",Clarity
9158,7-1925,7-1925_v2_61@10,7-1925_v1_54@6,"Policies on prior publication remain tight, especially in prestigious venues.","Despite some disciplines having healthy cultures of offline working paper circulation (philosophy, for instance), preprints have not taken off in the humanities and policies on prior publication remain tight, especially in the most prestigious venues.","Split+Modify,Clarity",Clarity
9159,7-1925,7-1925_v2_61@9,7-1925_v1_54@6,"Despite some disciplines having healthy cultures of offline working paper circulation (philosophy, for instance), preprints have not taken off.","Despite some disciplines having healthy cultures of offline working paper circulation (philosophy, for instance), preprints have not taken off in the humanities and policies on prior publication remain tight, especially in the most prestigious venues.","Split+Modify,Clarity",Clarity
9160,7-1925,7-1925_v2_62@0,7-1925_v1_55@0,"C) Infrastructure of scholarly communication – In addition to institutional repositories, there has been a growth of subject repositories, such as CORE, the Open Access Repository for the Humanities, which is operated by Modern Language Association of America.","C) Infrastructure of scholarly communication – In addition to institutional repositories, there has been a growth in recent years of OA subject repositories, such as the MLA Commons, which is operated by one of the largest subject associations in the humanities.","Modify,Claim",Claim
9161,7-1925,7-1925_v2_62@1,7-1925_v1_55@1,"There has also been a prominent culture, for many years, of scholarled OA journal and book publications <REF-81> .","There has also been a prominent culture, for many years, of scholar-led OA journal and book publications <REF-76> .","Modify,Grammar",Grammar
9162,7-1925,7-1925_v2_62@2,7-1925_v1_55@3,There is no preprint infrastructure at a comparative scale to arXiv.,There is no infrastructure at a comparative scale to arXiv in the humanities disciplines.,"Modify,Claim",Claim
9163,7-1925,7-1925_v2_62@3,7-1925_v1_55@4,"Further, for long-form reading, print remains a crucial resource and scholars often report that they do not wish to read such works in a digital format.","Furthermore, for long-form reading, print remains a crucial resource and scholars often report that they do not wish to read works of 80,000-words length in a purely digital format.","Modify,Claim",Claim
9164,7-1925,7-1925_v2_63@0,7-1925_v1_56@0,"D) Structural and institutional factors – The high costs of producing monographs are a key structural factor that limits OA <REF-67> , <REF-78> .","D) Structural and institutional factors – The high costs of producing monographs are a key structural factor that currently limits OA in the humanities <REF-62> , <REF-70> .","Modify,Clarity",Clarity
9165,7-1925,7-1925_v2_63@1,7-1925_v1_56@1,"Further, most research work in the humanities does not receive project-specific funding, making it difficult to integrate APCs into grants.","Further, most research work in the humanities does not receive project-specific funding, making it difficult to integrate processing charges into a grant.","Modify,Clarity",Clarity
9166,7-1925,7-1925_v2_63@2,7-1925_v1_56@2,That the humanities are often of lesser importance in institutional hierarchies also means that it can be difficult to secure funding.,That the humanities disciplines are often of lesser importance in institutional hierarchies also means that it can be difficult to secure funding for articles.,"Modify,Clarity",Clarity
9167,7-1925,7-1925_v2_63@3,7-1925_v1_56@3,"The slow cycle of producing long-form outputs is also problematic for OA, as the time investment (and hoped-for credit) is greater than those of a journal article, leading scholars into conservative behaviours.","The slow cycle of producing long-form outputs is also problematic for OA, as the time investment (and hoped-for credit on publication) is greater than those of a journal article, leading scholars into more conservative prestige-seeking behaviours.","Modify,Clarity",Clarity
9168,7-1925,7-1925_v2_63@4,7-1925_v1_56@4,"There are also substantial challenges around third-party rights and reuse of images, particularly within disciplines such as Art History, where it can be difficult to negotiate re-use rights for dissemination.","There are also substantial challenges around third-party rights and re-use of images, particularly within disciplines such as Art History.","Modify,Claim",Claim
9169,7-1925,7-1925_v2_63@5,7-1925_v1_56@7,"Some disciplines, such as creative writing, have outward facing cultures that rely on sales, which works poorly under OA.","Finally, some disciplinary spaces, such as creative writing, have developed outward facing cultures that rely on sales.","Modify,Claim",Claim
9170,7-1925,7-1925_v2_63@6,7-1925_v1_56@9,The production of such outputs may have a research process behind them and various institutional policies will regard those as scholarly undertakings.,"The production of such artifacts may, however, have a research process behind them and various institutional policies will regard such objects as scholarly undertakings.","Modify,Clarity",Clarity
9171,7-1925,7-1925_v2_63@7,7-1925_v1_56@10,The extent to which such work should be exempted from OA mandates remains an ongoing debate.,"The extent to which such work should be exempted from OA mandates remains, therefore, an ongoing debate.","Modify,Clarity",Clarity
9172,7-1925,7-1925_v2_64@0,7-1925_v1_57@0,"E) Open access mandates and policies – In national cultures, such as in the UK, the humanities face similar OA requirements as the social sciences, involving monographs being excluded from OA mandates and embargo periods of 12 or 24 months for the archiving of journal articles after publication in a subscription-journal.","E) OA mandates and policies – In national cultures, such as that in the UK, the humanities are subject to similar OA requirements as the social sciences, involving monographs being excluded from OA mandates and embargo periods of 12 or 24 months for the archiving of journal articles after publication in a subscription-journal.","Modify,Clarity",Clarity
9173,7-1925,7-1925_v2_64@2,7-1925_v1_57@2,"It appears likely, given recent moves among European funders, that policies around lengthened embargo periods for the humanities will be harmonized with other disciplines, e.g. Plan S, which does not allow any embargoes <REF-88> .","It appears likely, given recent moves among European funders, that policies around lengthened embargo periods for the humanities will be harmonized with other disciplines down to zero in coming years.","Modify,Fact/Evidence",Fact/Evidence
9174,7-1925,7-1925_v2_66@0,7-1925_v1_59@0,The transition to OA of legal literature is in its infancy.,The transition to OA of legal literature can be said to be still in its infancy.,"Modify,Clarity",Clarity
9175,7-1925,7-1925_v2_66@1,7-1925_v1_59@1,Legal studies feature some of the lowest OA rates <REF-24> .,Legal studies feature some of the lowest OA prevalence levels.,"Modify,Fact/Evidence",Fact/Evidence
9176,7-1925,7-1925_v2_67@0,7-1925_v1_60@0,A) Author behaviour and attitudes – Scholars have been reluctant to adopt OA despite agreeing that the field would benefit from journals that publish OA <REF-89> – <REF-91> .,"A) Author behaviour and attitudes – Generally speaking, legal scholars have been reluctant to adopt OA despite agreeing that the research field would benefit from journals that publish OA articles <REF-84> – <REF-86> .","Modify,Clarity",Clarity
9177,7-1925,7-1925_v2_67@1,7-1925_v1_60@1,"Many authors either are not aware of OA or have little incentive to publish OA <REF-92> , but the field is slowly moving with networks for OA being established, such as the German-speaking network jurOA (established in 2018).","Even though the field is slowly moving towards OA, many authors of legal publications either are not aware of OA or have little to no incentive to publish their research in OA journals or public repositories <REF-87> .","Modify,Fact/Evidence",Fact/Evidence
9178,7-1925,7-1925_v2_67@2,7-1925_v1_60@2,It is common practice that academics and practicing lawyers publish in the same legal journals or commentaries.,"In legal studies, it is common practice that academics and practicing lawyers publish in the same legal journals or legal commentaries.","Modify,Clarity",Clarity
9179,7-1925,7-1925_v2_67@3,7-1925_v1_60@3,"Some practicing lawyers might even prefer to publish in law journals behind paywalls, thereby guaranteeing exclusive access to their knowledge <REF-93> .","Some practicing lawyers might even prefer to publish in law journals behind paywalls, thereby guaranteeing an exclusive access to their knowledge and ensuring that potential clients are not able to find the relevant information themselves <REF-88> .","Modify,Fact/Evidence",Fact/Evidence
9180,7-1925,7-1925_v2_67@4,7-1925_v1_60@4,"Because of the high relevance of national legal systems, large parts of the literature are written in the languages of these countries and published in journals or books operated in the same countries.","Because of the high relevance of national legal systems, large parts of the legal literature is written in the languages of these countries and published in law journals or books operated in the same countries.","Modify,Clarity",Clarity
9181,7-1925,7-1925_v2_67@5,7-1925_v1_60@5,The argument that OA enables worldwide readership is of limited relevance.,"Accordingly, the argument that OA enables a worldwide readership is of limited relevance in the field of law.","Modify,Clarity",Clarity
9182,7-1925,7-1925_v2_67@6,7-1925_v1_60@6,"On the other hand, many legal issues are of interest not only to legal scholars but also to the media and politics <REF-94> .","On the other hand, many legal issues are of interest not only to academics and practicing lawyers, but also to the media and politics.","Modify,Fact/Evidence",Fact/Evidence
9183,7-1925,7-1925_v2_67@7,7-1925_v1_60@8,The role of electronic media in supporting scholarly communication and dissemination of research findings is growing but important databases (e.g. HeinOnline in the United States or BeckOnline in Germany) are paywalled <REF-95> .,The role of electronic media in supporting scholarly communication and dissemination of research findings is growing but the most important databases (e.g. HeinOnline and LexisNexis in the United States or BeckOnline in Germany) are paywalled <REF-89> .,"Modify,Fact/Evidence",Fact/Evidence
9184,7-1925,7-1925_v2_68@0,7-1925_v1_61@0,"B) Publisher behaviour and policies – In the U.S., many law reviews are published by law schools, not by for-profit publishers <REF-95> – <REF-97> .","B) Publisher behaviour and policies – In the U.S., many or most law reviews are published by law schools, not by for-profit publishers <REF-89> – <REF-91> .","Modify,Clarity",Clarity
9185,7-1925,7-1925_v2_68@1,7-1925_v1_61@1,"In contrast to commercial publishers, law schools do not have the usual incentives to oppose OA and a growing number of their journals are converted to OA.","In contrast to commercial publishers, law schools do not have the usual incentives to oppose OA.","Modify,Claim",Claim
9186,7-1925,7-1925_v2_68@2,7-1925_v1_61@3,"This is different in jurisdictions outside the US where legal scholarship is generally published by commercial publishers <REF-89> , <REF-97> .","The situation is very different in jurisdictions outside the US where legal scholarship is generally published by commercial publishers <REF-84> , <REF-91> .","Modify,Clarity",Clarity
9187,7-1925,7-1925_v2_68@3,7-1925_v1_61@4,"Due to the small demand for OA by legal scholars, there are little to no incentives for for-profit publishers to set up new OA journals or book series or to convert existing subscription journals to OA.","Due to the small demand for OA publishing on part of legal scholars, there are little to no incentives for for-profit publishers to set up new OA journals or book series or to convert existing subscription-based journals to OA.","Modify,Clarity",Clarity
9188,7-1925,7-1925_v2_68@4,7-1925_v1_61@5,There are some notable exceptions.,"There are some notable exceptions, however.","Modify,Clarity",Clarity
9189,7-1925,7-1925_v2_68@5,7-1925_v1_61@6,"In recent years, some OA law journals have been set up that are predominantly community-driven (e.g. Journal of Intellectual Property, Information Technology and Electronic Commerce Law and Forum Historiae Iuris in Germany or sui generis in Switzerland).","In recent years, some OA law journals have been set up that are predominantly community-driven and operated independently from commercial publishers (e.g. JIPITEC in the EU, Forum Historiae Iuris in Germany or sui generis in Switzerland).","Modify,Claim",Claim
9190,7-1925,7-1925_v2_68@6,7-1925_v1_61@7,"According to the DOAJ, there are about 260 OA law journals.","According to the DOAJ, there are about 200 OA law journals.","Modify,Fact/Evidence",Fact/Evidence
9191,7-1925,7-1925_v2_68@8,7-1925_v1_61@9,"The Creative Commons List of OA Law Adopting Journals lists 37 OA law journals but most of the 17 Harvard Law School OA journals are missing <REF-98> , <REF-99> .",The Creative Commons list of OA Law Adopting Journals lists 37 OA law journals but most of the 18 Harvard Law School Journals (all but one of them are OA) are missing <REF-92> .,"Modify,Fact/Evidence",Fact/Evidence
9192,7-1925,7-1925_v2_69@4,7-1925_v1_62@4,There is only a limited number of disciplinary repositories and the uptake is slow.,There is only a limited number of disciplinary repositories and the uptake of repositories such as LawArXiv appears to be slow.,"Modify,Claim",Claim
9193,7-1925,7-1925_v2_69@5,7-1925_v1_62@5,"In the U.S. and in international law, the most popular disciplinary repository is SSRN, which is now owned by Elsevier.","In the US and in international law, the most popular disciplinary repository for law professors is SSRN, which is now owned by Elsevier.","Modify,Clarity",Clarity
9194,7-1925,7-1925_v2_69@6,7-1925_v1_62@6,"In English-speaking legal scholarship, scholars find it difficult to build reputation without being represented in SSRN <REF-100> .","In English-speaking legal scholarship, scholars find it even difficult to build reputation without being represented in SSRN <REF-93> .","Modify,Clarity",Clarity
9195,7-1925,7-1925_v2_69@7,7-1925_v1_62@7,"A growing number of universities is further providing support for setting up OA journals or transforming closed to OA journals (for example, by providing an Open Journal Systems infrastructure).","A growing number of universities is further providing support for setting up OA journals or transforming closed to OA journals (for example, by providing an OJS infrastructure).","Modify,Clarity",Clarity
9196,7-1925,7-1925_v2_69@8,7-1925_v1_62@8,"Since practicing lawyers and scholars work almost exclusively with texts, OA infrastructures do not have to meet demanding technical requirements.","Since practicing lawyers and legal scholars work almost exclusively with texts, OA infrastructures do not have to fulfill demanding technical requirements.","Modify,Clarity",Clarity
9197,7-1925,7-1925_v2_70@1,7-1925_v1_63@1,PhD theses are predominantly published as monographs and many universities routinely make PhD theses OA.,PhD theses in the field of law are predominantly published as monographs.,"Merge+Modify,Clarity",Clarity
9198,7-1925,7-1925_v2_70@1,7-1925_v1_63@2,PhD theses are predominantly published as monographs and many universities routinely make PhD theses OA.,Many universities routinely make PhD theses OA (for example Harvard University in the U.S. University of St.Gallen in Switzerland).,"Merge+Modify,Claim",Claim
9199,7-1925,7-1925_v2_70@2,7-1925_v1_63@3,"While the authors of legal books are mostly academics, this is different for journal articles and legal commentaries where both academics and practitioners contribute.","While the authors of legal books are mostly academics, this remains different for journal articles and legal commentaries where both academics and practitioners contribute.","Modify,Clarity",Clarity
9200,7-1925,7-1925_v2_70@3,7-1925_v1_63@4,"As a result, not only scholars and universities, but also practicing lawyers need to be convinced to move to OA.","As a result, not only scholars and universities, but also practicing lawyers need to be convinced to move towards OA.","Modify,Clarity",Clarity
9201,7-1925,7-1925_v2_70@4,7-1925_v1_63@5,One possible way to foster OA might be to encourage academics and practitioners to publish in different journals and commentaries.,One possible way to foster OA amongst legal scholars might be to encourage academics and practitioners to publish in different journals and commentaries.,"Modify,Clarity",Clarity
9202,7-1925,7-1925_v2_70@5,7-1925_v1_63@6,"Here, academics could publish in scientific OA journals and practitioners could keep using closed access journals and commentaries, which would be more practice-oriented.","In this scenario, academics could publish their works in scientific OA journals and practitioners could keep on using closed access journals and commentaries, which, however, would be more practice-oriented.","Modify,Clarity",Clarity
9203,7-222,,7-222_v1_4@2,,A phylogenetic tree of Maximum Likelihood was built.,"Delete,Fact/Evidence",Fact/Evidence
9204,7-222,7-222_v2_2@4,,"This data contributes with base information on the biodiversity of the Parks, necessary to design and implement measures for the conservation of fungi in Ecuador.",,"Add,Claim",Claim
9205,7-222,7-222_v2_7@8,,Alignments that presented 100% coverage and at least 99% identity with a sequence previously reported in GenBank were considered.,,"Add,Fact/Evidence",Fact/Evidence
9206,7-222,7-222_v2_7@9,,"The results were compared with the previously made morphological identification at the QCAM Fungarium, to check the taxonomic designation.",,"Add,Fact/Evidence",Fact/Evidence
9207,7-222,7-222_v2_13@17,,The number of nucleotide differences (SNPs) between the sample and the closest hit on the BLASTn search suggests that these specimens may belong to new species ( Table 1 ).,,"Add,Claim",Claim
9208,7-222,7-222_v2_13@18,,Additional loci and more detailed morphological analyses are needed to determine this.,,"Add,Claim",Claim
9209,7-222,7-222_v2_13@20,,"Studies related to the biological diversity of this order in the National Parks of Ecuador are scarce, more systematic field studies would surely reveal a greater diversity of families, genera and species within the Xylariales in SP and LP, as well as other regions and protected areas of Ecuador, especially if we take into account the cosmopolitan distribution of Xylaria <REF-13> .",,"Add,Claim",Claim
9210,7-222,,7-222_v1_3@0,,"The taxonomic identification of fungi of the order Xylariales was achieved with the bioinformatic tools, to further study the phylogenetic relationships among the collected individuals and thus contribute with base information on their biological diversity, necessary to design and implement measures for the conservation of fungi.","Delete,Claim",Claim
9211,7-222,7-222_v2_16@0,7-222_v1_18@0,These entire unidentified specimens might represent new species.,These unidentified specimens might represent new species.,"Modify,Clarity",Clarity
9212,7-222,7-222_v2_18@5,7-222_v1_20@5,To advance our understanding of the Kingdom Fungi we must start by deciphering the diversity of species present in these sites.,To advance our understanding of this Kingdom we must start by deciphering the diversity of fungi present in these sites.,"Modify,Clarity",Clarity
9213,7-222,7-222_v2_4@3,7-222_v1_6@3,"ITS is the accepted as primary fungal barcode marker for fungi <REF-3> , <REF-4> .",ITS is the accepted ’barcode’ for fungi <REF-3> .,"Modify,Clarity",Clarity
9214,7-222,7-222_v2_4@5,7-222_v1_6@5,"Here we present results exclusively for the Xylariales order, other fungal orders were also collected but are not shown here.",Here we present results exclusively for the Xylariales order.,"Modify,Fact/Evidence",Fact/Evidence
9215,7-222,7-222_v2_6@0,7-222_v1_8@0,Sequencing and molecular identification,Obtaining the sequences and molecular identification,"Modify,Clarity",Clarity
9216,7-222,7-222_v2_7@3,7-222_v1_9@3,The ITS1-5.8SITS2 region was amplified by PCR with primers ITS1F (5’-CTTGGTCATTTAGAGGAAGTAA-3’) <REF-5> and ITS4 (5’-TCCTCCGCTTATTGATATGC-3’) <REF-6> .,"The ITS1-5.8S-ITS2 region was amplified by PCR with primers (provided by Invitrogen Co., Carlsbad, CA, USA) ITS1F (5’-CTTGGTCATTTAGAGGAAGTAA-3’) <REF-4> and ITS4 (5’-TCCTCCGCTTATTGATATGC-3’) <REF-5> .","Modify,Fact/Evidence",Fact/Evidence
9217,7-222,7-222_v2_0@0,7-222_v1_0@0,"Xylariales: First results of mycological exploration in the Sangay and Llanganates National Parks, Ecuador","Xylariales: First results of mycological exploration in the Sangay and Llanganates National Park, Ecuador","Modify,Grammar",Grammar
9218,7-222,7-222_v2_7@5,7-222_v1_9@5,"The forward and reverse sequences obtained for each isolate were assembled in Geneious R8 (Biomatter Ltd. 2005–2012), and submitted to GenBank.",The obtained sequences were edited in Geneious R8 (Biomatter Ltd. 2005–2012) by selecting the “ de novo assemble” tool and then trimming the ends.,"Merge+Modify,Clarity",Clarity
9219,7-222,7-222_v2_7@5,7-222_v1_9@6,"The forward and reverse sequences obtained for each isolate were assembled in Geneious R8 (Biomatter Ltd. 2005–2012), and submitted to GenBank.","The consensus sequence was manually edited, and submitted to GenBank .","Merge+Modify,Fact/Evidence",Fact/Evidence
9220,7-222,7-222_v2_11@1,7-222_v1_13@1,Public sequences available in GenBank that corresponded to specimens that gave the greatest homology in BLASTn with the sequences of the collected specimens were included.,Public sequences are available in GenBank that corresponded to specimens that gave the greatest homology in BLASTn with the sequences of the collected specimens were included in the analyses.,"Modify,Grammar",Grammar
9221,7-222,7-222_v2_11@2,7-222_v1_13@2,"Phylogenetic trees were constructed in Geneious R8 using the PhyML <REF-8> plugin for Maximum Likelihood (ML) with a custom substitution model (010230), determined by jModelTest 2.1.4.",Phylogenetic trees were constructed in Geneious R8 using the PhyML <REF-7> plugin for Maximum Likelihood (ML) with a Custom (010230) substitution model determined by jModelTest 2.1.4.,"Modify,Clarity",Clarity
9222,7-222,7-222_v2_13@0,7-222_v1_15@0,All the specimens analyzed were of the genus Xylaria.,All the specimens collected were of the genus Xylaria .,"Modify,Clarity",Clarity
9223,7-222,7-222_v2_13@3,7-222_v1_15@3,"Differences in the number of samples found at each park could be due to the sampling effort, and not necessarily to the richness of the Xylareales in the Parks.","Differences in the number of samples found at each park could be due to the sampling effort that was different in each park, however, this is a sample of the high biodiversity in LP and SP.","Modify,Claim",Claim
9224,7-222,7-222_v2_13@5,7-222_v1_15@5,"The analysis shows that there are no shared species of Xylaria at the two sampled sites ( Table 1 ), this is important for conservation decision making.","The analysis shows that there are no shared species of Xylaria at the two parks ( Table 1 ), this is important for conservation decisions.","Modify,Clarity",Clarity
9225,7-222,7-222_v2_2@2,7-222_v1_4@0,"All analyzed collections presented here belong to the genus Xylaria, of these eight belong to PL and two to SP.","All records belong to the genus Xylaria, of these eight belong to PL and two to SP.","Modify,Clarity",Clarity
9226,7-222,7-222_v2_13@7,7-222_v1_15@7,"The first major group, composed by clades A and B, is well supported, it includes specimens from LP and PS.","The first major group, composed by clades A and B, is well supported (bootstrap > 95) includes specimens from LP and PS.","Modify,Grammar",Grammar
9227,7-222,7-222_v2_13@8,7-222_v1_15@8,"Clade A includes all X. entogena specimens and Clade B includes all X. telfairii specimens, and Xylarya sp.1 specimens.",Clade A includes all X. entogena specimens and is well supported (bootstrap > 95).,"Link+Modify,Fact/Evidence",Fact/Evidence
9228,7-222,7-222_v2_13@8,7-222_v1_15@9,"Clade A includes all X. entogena specimens and Clade B includes all X. telfairii specimens, and Xylarya sp.1 specimens.","Clade B includes all X. telfairii specimens and Xylarya sp.1 specimens (bootstrap < 50), it could be supposed that Xylarya sp.1 belongs to the X. telfairii species, but because the high difference among the sequences it is considered a different species.","Link+Modify,Fact/Evidence",Fact/Evidence
9229,7-222,7-222_v2_13@9,7-222_v1_15@9,"It is possible that Xylarya sp.1 might belong to the X. telfairii group, but due to the differences among the sequences it is likely a different species.","Clade B includes all X. telfairii specimens and Xylarya sp.1 specimens (bootstrap < 50), it could be supposed that Xylarya sp.1 belongs to the X. telfairii species, but because the high difference among the sequences it is considered a different species.","Link+Modify,Clarity",Clarity
9230,7-222,7-222_v2_13@11,7-222_v1_15@11,Clade C includes all X. schweinitzii specimens.,Clade C includes all X. schweinitzii specimens (bootstrap > 95).,"Modify,Fact/Evidence",Fact/Evidence
9231,7-222,7-222_v2_2@3,7-222_v1_4@1,"Four samples were not identified at the species level, suggesting it could be a new species.","A record was not identified at the species level, suggesting that it could be a new species.","Modify,Fact/Evidence",Fact/Evidence
9232,7-222,7-222_v2_13@12,7-222_v1_15@12,Clade D includes Xylaria sp. 2.,"Clade D (bootstrap > 80) includes Xylaria sp. 2, the closest sequence to Xylaria sp. 2 from SP was a previously reported collection also from Ecuador <REF-12> in a cloud forest in the province of Imbabura, that was also identified only at the genus level.","Split+Modify,Fact/Evidence",Fact/Evidence
9234,7-222,7-222_v2_13@14,7-222_v1_15@13,"Clade E shows Xylaria sp. 3, the closest sequence to this individual belongs to the same previously reported study <REF-13> , identified only at the genus level.","Clades E (bootstrap > 95) shows Xylaria sp. 3, the closest sequence to this individuals belongs to the same previously reported collection <REF-12> , identified only at the genus level.","Modify,Fact/Evidence",Fact/Evidence
9235,7-222,7-222_v2_13@15,7-222_v1_15@14,Clade F includes Xylaria fissilis sequences from LP and one from <REF-13> .,Clade F (bootstrap = 100) includes Xylaria fissilis sequences from LP and one from <REF-12> ; clade F also includes Xylaria sp. 4 an unidentified specimen.,"Split+Modify,Fact/Evidence",Fact/Evidence
9236,7-222,7-222_v2_13@16,7-222_v1_15@14,"Clade F also includes Xylaria sp. 4, an unidentified specimen.",Clade F (bootstrap = 100) includes Xylaria fissilis sequences from LP and one from <REF-12> ; clade F also includes Xylaria sp. 4 an unidentified specimen.,"Split+Modify,Grammar",Grammar
9237,7-229,7-229_v2_16@1,,"The secondary forest plots were last subject to selective logging until 2008 for BS1, 1999 for BS2, 2003 for BS3, and 2010 for BS4.",,"Add,Fact/Evidence",Fact/Evidence
9238,7-229,7-229_v2_16@2,,"The shrub swamp plots burned in 1997, and BB2 burned yearly since.",,"Add,Claim",Claim
9239,7-229,7-229_v2_17@4,,"It was not possible to conduct the survey each month, or to repeat the same plot sampling sequence for the second set of recordings because of access and transportation restrictions.",,"Add,Fact/Evidence",Fact/Evidence
9240,7-229,7-229_v2_21@1,,We checked that the models were not over-dispersed and that the standardised residuals did not indicate heteroscedasticity.,,"Add,Fact/Evidence",Fact/Evidence
9241,7-229,7-229_v2_28@1,,"Error bars show the 83% confidence intervals for the mean alpha and beta richness values, which do not differ significantly at P=0.05 when they overlap (Krzywinski, 2013).",,"Add,Fact/Evidence",Fact/Evidence
9242,7-229,7-229_v2_33@1,,Mean values are represented with red dots and their 83% confidence intervals are indicated with error bars.,,"Add,Fact/Evidence",Fact/Evidence
9243,7-229,7-229_v2_33@2,,"Means are significantly different at P=0.05 when their confidence intervals do not overlap (Krzywinski, 2013), and significant differences are indicated with asterisks.",,"Add,Fact/Evidence",Fact/Evidence
9244,7-229,7-229_v2_37@0,,Abundances are split by habitat and shown for different IUCN Red List statuses.,,"Add,Fact/Evidence",Fact/Evidence
9245,7-229,7-229_v2_40@4,,This change in the community also became apparent in a shift to bigger and more mobile species with greater distribution ranges in shrub swamp.,,"Add,Claim",Claim
9246,7-229,7-229_v2_41@3,,"Wild bird trapping threatens bird populations directly (Harris et al . 2016), and is especially worrisome as birds from the Berbak region are increasingly traded in the caged bird market of Jambi city (pers. obs. KD).",,"Add,Claim",Claim
9247,7-229,7-229_v2_22@0,7-229_v1_23@0,"We pooled the data from both acoustic counts and visualized the composition of the bird communities in non-metric multidimensional scaling graphs generated with the package vegan <REF-39> , and tested the significance of the habitat in structuring these communities with an ADONIS test <REF-40> .","We visualized the composition of the bird communities in non-metric multidimensional scaling graphs generated with the package vegan <REF-39> , and tested the significance of the habitat in structuring these communities with an ADONIS test <REF-40> .","Modify,Fact/Evidence",Fact/Evidence
9248,7-229,7-229_v2_22@2,7-229_v1_23@2,"To investigate whether the combined, different habitats lead to higher species richness than one primary forest area of similar size, we calculated the rarefied richness based on the entire bird community, rarefied to 4 sampling plots, to compare it to the number of species found in the 4 forest plots.","To investigate whether the combined, different habitats lead to higher species richness than one primary forest area of similar size, we calculated the rarefied richness based on the entire bird community, rarefied to 4 sampling sites, to compare it to the number of species found in the 4 forest sites.","Modify,Clarity",Clarity
9249,7-229,7-229_v2_24@0,7-229_v1_25@0,We detected 426 birds overall.,"We detected 379 birds overall, belonging to 90 species ( Table S1 ).","Modify,Fact/Evidence",Fact/Evidence
9250,7-229,7-229_v2_24@1,7-229_v1_25@1,"Among those, 30 individuals were not identified to species level and 2 were detected above 50 m, resulting in a working dataset of 394 individuals, belonging to 88 species ( Table S1 ).","Among those, 26 individuals were not identified to species and 2 were detected above 50 m, resulting in a working dataset of 351 detections.","Modify,Fact/Evidence",Fact/Evidence
9251,7-229,7-229_v2_24@2,7-229_v1_25@2,"The three habitats differed considerably based on their vegetation structure ( Figure S1 ) and the distribution of their DBH values, with primary forest having the highest basal area, secondary forest intermediate values, and shrub swamp having the smallest basal area ( Figure S2 ).",The three habitats differed considerably based on their vegetation structure and the distribution of their DBH values ( Figure S1 and Figure S2 ).,"Modify,Fact/Evidence",Fact/Evidence
9252,7-229,7-229_v2_25@0,7-229_v1_26@0,"Species richness and abundance at the count level, and mean alpha and beta species richness at the plot level were similar between the habitats ( Figure 2 and Figure 3 ).","Species richness and abundance at the count level, and mean alpha and beta species richness at the site level were similar between the habitats ( Figure 2 and Figure 3 ).","Modify,Clarity",Clarity
9253,7-229,7-229_v2_34@1,7-229_v1_33@1,The ADONIS test revealed that habitat structured bird community composition with marginal significance (P=0.068).,The ADONIS test revealed that habitat structured bird community composition with marginal significance (P=0.053).,"Modify,Fact/Evidence",Fact/Evidence
9254,7-229,7-229_v2_41@4,7-229_v1_39@3,"All these human activities increase the risk of fires, especially during dry spells caused by the warm phases of the El Niño Southern Oscillation, which led to the especially severe fires of 1994, 1997, and 2015 (after our survey).","These human activities increase the risk of fires, especially during dry spells caused by the warm phases of the El Niño Southern Oscillation, which led to the especially severe fires of 1994, 1997, and 2015 (after our survey).","Modify,Clarity",Clarity
9255,7-229,7-229_v2_42@0,7-229_v1_40@0,"Primary forest had high conservation value because we found 16 species of conservation concern (""near threatened"" status according to IUCN Red List status), twice as many as in shrub swamp.","Primary forest sites had high conservation value because we found 16 species of conservation concern (""near threatened"" status according to IUCN Red List status), twice as much as in shrub swamp.","Modify,Grammar",Grammar
9256,7-229,7-229_v2_42@2,7-229_v1_40@2,"Secondary forest was exactly intermediary with 12 species of conservation concern, although one bird, the Javan Myna ( Acridotheres javanicus ), has recently been classified as vulnerable.","Secondary forest sites were exactly intermediary with 12 species of conservation concern, although one bird, the Javan Myna ( Acridotheres javanicus ), has recently been classified as vulnerable.","Modify,Grammar",Grammar
9257,7-229,7-229_v2_42@3,7-229_v1_40@3,Javan Mynas are commonly sold on the market in Jambi city and might establish feral populations when occasionally breaking free.,Javan Mynas are commonly sold on the market in Jambi city.,"Modify,Claim",Claim
9258,7-229,7-229_v2_42@5,7-229_v1_40@5,Compared to the secondary forest plots surveyed by Prabowo et al .,Compared to the secondary forest sites surveyed by Prabowo et al .,"Modify,Clarity",Clarity
9259,7-229,7-229_v2_42@7,7-229_v1_40@7,"Our secondary forest plots seemed relatively well-preserved, as we could not detect any typical loss of understory and terrestrial insectivores due to changes in understory vegetation <REF-43> .","Our secondary forest sites seemed relatively well-preserved, as we could not detect any typical loss of understory and terrestrial insectivores due to changes in understory vegetation <REF-43> .","Modify,Clarity",Clarity
9260,7-229,7-229_v2_42@10,7-229_v1_40@8,"Considering that the detected abundance of birds in the other habitats was similarly high, this indicates that the National Park of Berbak still provides relatively good living conditions for birds, and especially conservation-worthy species thrive in the primary forest tracts.","Considering that the detected abundance of birds in the other habitats was similarly high, this indicates that the National Park of Berbak provides relatively good living conditions for birds, and especially conservation-worthy species thrive in the primary forest tracts.","Modify,Clarity",Clarity
9261,7-229,7-229_v2_8@1,7-229_v1_8@1,"In Southeast Asia, most primary forest bird species still occur in previously logged forests <REF-12> – <REF-14> (Azhar et al . 2011).","In Southeast Asia, most primary forest bird species still occur in previously logged forests <REF-12> – <REF-14> .","Modify,Fact/Evidence",Fact/Evidence
9262,7-229,7-229_v2_9@1,7-229_v1_9@1,"Theoretical and modelling approaches are usually used to analyse the potential benefit of disturbances for overall landscape biodiversity <REF-20> , <REF-21> .","Few studies have focused on the potential benefit of disturbances for overall landscape biodiversity apart from theoretical and modelling approaches <REF-20> , <REF-21> .","Modify,Claim",Claim
9263,7-229,7-229_v2_17@1,7-229_v1_18@0,We recorded audible sound in all 12 plots two times.,We recorded audible sound in all 12 sites.,"Modify,Fact/Evidence",Fact/Evidence
9264,7-229,7-229_v2_17@3,7-229_v1_18@2,"From February to November 2013, we sampled all three plots of one site each month for 48 hours, starting at midnight.","From February to November 2013, we sampled all three habitats at one site each month for 48 hours, starting at midnight.","Modify,Clarity",Clarity
9265,7-229,7-229_v2_17@6,7-229_v1_18@4,We also recorded whether the plot was flooded or not at the time of the sound recorder installation.,We also recorded whether the site was flooded or not at the time of the sound recorder installation.,"Modify,Clarity",Clarity
9266,7-229,7-229_v2_19@0,7-229_v1_20@0,"We uploaded 20 minutes recordings starting at sunrise from each plot from each month (24 recordings in total, 2 per plot) to our online platform ( http://soundefforts.uni-goettingen.de/ ).",We uploaded 20 minutes recordings after sunrise for each plot in each month (24 recordings in total) to our online platform ( http://soundefforts.uni-goettingen.de/ ).,"Modify,Fact/Evidence",Fact/Evidence
9267,7-229,7-229_v2_19@2,7-229_v1_20@2,"The distance of bird vocalisations was estimated by ear to the meter; even though the accuracy is lower, estimation error was assumed to be random.","The distance of bird vocalisations was estimated by ear to the meter, based on their loudness in the sound recording compared to the ambient sound level and knowledge of the source sound level of each species.","Split+Modify,Claim",Claim
9268,7-229,7-229_v2_19@3,7-229_v1_20@2,Distance estimates were made based on the call loudness in the sound recording compared to the ambient sound level and knowledge of the source sound level of each species.,"The distance of bird vocalisations was estimated by ear to the meter, based on their loudness in the sound recording compared to the ambient sound level and knowledge of the source sound level of each species.","Split+Modify,Clarity",Clarity
9269,7-229,7-229_v2_20@1,7-229_v1_21@1,"We excluded detections that were not identified to species, as well as detections above 50 m to compare plots at a common detection radius <REF-35> .","We excluded detections that were not identified to species, as well as detections above 50 m to compare sites at a common detection radius <REF-35> .","Modify,Clarity",Clarity
9270,7-229,7-229_v2_3@1,7-229_v1_3@1,"We analysed the species richness, abundance, vocalisation activity, and community composition across acoustic counts, plots, feeding guilds and IUCN Red List categories.","We analysed the species richness, abundance, vocalisation activity, and community composition across acoustic counts, sites, feeding guilds and IUCN Red List categories.","Modify,Clarity",Clarity
9271,7-229,7-229_v2_20@3,7-229_v1_21@3,Bird species richness was further computed at the plot (alpha richness) and habitat (gamma richness) levels.,Bird species richness was further computed at the site and habitat level.,"Modify,Fact/Evidence",Fact/Evidence
9272,7-229,7-229_v2_20@4,7-229_v1_21@4,"For counting bird abundance, we first derived the maximum number of simultaneously vocalising individuals in each species, and then summed these maxima over all species, leading to a conservative estimate of the number of individuals per count.",Bird abundance was counted as the sum of the maximum number of individuals vocalising simultaneously in each species.,"Modify,Fact/Evidence",Fact/Evidence
9273,7-229,7-229_v2_20@5,7-229_v1_21@5,"We calculated community-weighted means (hereafter CWM, also called community functional parameter <REF-36> ) for body mass, wing length, and distribution area for each count.","We calculated community-weighted means (or community functional parameter <REF-36> , hereafter CWM) for body mass, wing length, and distribution area for each count.","Modify,Clarity",Clarity
9274,7-407,,7-407_v1_36@0,,"Even if with our search activity we are quite sure to have reduced to a minimum the problem of publication bias, we performed a statistical estimation by using the Copas selection model which is recommended by Jin et al . (2015) .","Delete,Fact/Evidence",Fact/Evidence
9275,7-407,,7-407_v1_55@0,,"The search method used and the small number of people interested in this research field, guarantee that from an empirical point of view, any publication bias is almost absent.","Delete,Claim",Claim
9276,7-407,,7-407_v1_66@0,,"We found very interesting evidence of presentiment distilled from the conventional post-stimulus psychological research of Jolij and Bierman, who have performed a long series of experiments using a face detection paradigm.","Delete,Claim",Claim
9277,7-407,,7-407_v1_66@1,,"Additionally, the work of Kittenis found prestimulus effects from a conventional research program and pre-registered single-trial work of Mossbridge represent an important conceptual replication in countering both the use of questionable research practices and expectancy effects arguments.","Delete,Claim",Claim
9278,7-407,,7-407_v1_67@0,,"A promising development of this line of research is the development of paradigms that use software in real-time to predict meaningful future outcomes before they occur, e.g. ( Franklin et al ., 2014 )","Delete,Claim",Claim
9279,7-407,7-407_v2_56@0,,Preregistered vs No-preregistered studies,,"Add,Other",Other
9280,7-407,7-407_v2_57@0,,"This distinction is relevant for assessing the impact of the so-called Questionable Research Practices and in particular p-hacking ( Head et al ., 2015 ; John et al ., 2012 ).",,"Add,Fact/Evidence",Fact/Evidence
9281,7-407,7-407_v2_57@1,,"Preregistered studies must describe all details on how the data will be analyzed before their collection, thus reducing the degree of freedom available during and after data collection.",,"Add,Claim",Claim
9282,7-407,7-407_v2_58@0,,From our database it was possible to compare the estimate of the effect size obtained from the pre-registered studies with that obtained from the no-preregistered ones.,,"Add,Fact/Evidence",Fact/Evidence
9283,7-407,7-407_v2_58@1,,The results are presented in the following Table 4 .,,"Add,Fact/Evidence",Fact/Evidence
9284,7-407,7-407_v2_61@0,,"The effect size point estimates clearly show that the effect size of the preregistered studies is larger than that of the no-preregistered studies, however their precision estimates (see the 95% CI) reveal a considerable overlap and consequently they cannot be considered statistically different.",,"Add,Fact/Evidence",Fact/Evidence
9285,7-407,7-407_v2_63@0,,Our very comprehensive literature search is likely to have reduced the probability of a publication bias.,,"Add,Claim",Claim
9286,7-407,7-407_v2_63@1,,Nevertheless we added a statistical estimation of the publication bias.,,"Add,Fact/Evidence",Fact/Evidence
9287,7-407,7-407_v2_65@1,,"Similarly, more recent publication bias tests like the three-parameters selection model, the p-uniform* and the Vevea and Hedges’ weight-function model ( Vevea & Woods (2005) , seem not recommended for multilevel random meta-analyses with high heterogeneity like the present one.",,"Add,Claim",Claim
9288,7-407,7-407_v2_74@1,,"This phenomenon may hence be considered among the more reliable within those covered under the umbrella term “psi” (see Cardeña, 2018 for an exhaustive review of the evidence and the theoretical hypotheses of all these phenomena).",,"Add,Fact/Evidence",Fact/Evidence
9289,7-407,7-407_v2_77@0,,"In order to arrive at such an ambitious goal, it is necessary to achieve a high degree of correct classifications based on prestimulus activity at the level of each trial so that the number of false positives and false negatives is reduced to a bare minimum.",,"Add,Claim",Claim
9290,7-407,7-407_v2_77@1,,The experiments of Mossbridge (2017) ; Baumgart et al . (2017) and Jolij & Bierman (2017) are promising examples in this regard.,,"Add,Claim",Claim
9291,7-407,7-407_v2_80@0,,"Data associated with the article are available under the terms of the Creative Commons Zero ""No rights reserved"" data waiver (CC0 1.0 Public domain dedication).",,"Add,Fact/Evidence",Fact/Evidence
9292,7-407,,7-407_v1_9@8,,"Additionally, we also found increasing evidence of presentiment research piggybacking onto mainstream psychology programs, even informing aspects of the conventional research.","Delete,Fact/Evidence",Fact/Evidence
9293,7-407,7-407_v2_24@0,7-407_v1_21@0,"Excluded records were studies where the psychophysiological variables were analysed only after and not before the stimuli presentations ( Jin et al. , 2013 ) and with an unusual procedure ( Tressoldi et al. , 2015 ), i.e. using heart rate feedback to inform a voluntary decision to predict random positive or negative events.","Excluded records were studies were the psychophysiological variables were analysed only after and not before the stimuli presentations ( Jin et al. , 2013 ) and with an unusual procedure ( Tressoldi et al. , 2015 ), i.e. using heart rate feedback to inform a voluntary decision to predict random positive or negative events.","Modify,Grammar",Grammar
9294,7-407,7-407_v2_7@0,7-407_v1_4@2,The statistical estimation of the publication bias by using the Copas selection model suggest that the main findings are not contaminated by publication bias.,The statistical estimation of the publication bias by using the Copas model suggest that the main findings are not contaminated by publication bias.,"Modify,Clarity",Clarity
9295,7-407,7-407_v2_29@1,7-407_v1_26@1,The database along with all 19 papers are available from Tressoldi (2017) .,The database along with all 18 papers are available from Tressoldi (2017) .,"Modify,Fact/Evidence",Fact/Evidence
9296,7-407,7-407_v2_36@0,7-407_v1_33@0,"In order to control the reliability of the results, a second analysis was carried out by using a multilevel approach as suggested by Assink & Wibbelink (2016) implemented with the metafor package ( Viechtbauer, 2010 ) and reported in the Table S2 in the Supplementary File 3 .","In order to control the reliability of the results, a second analysis was carried out by using a multilevel approach as suggested by ( Assink & Wibbelink, 2016 ) implemented with the metafor package ( Viechtbauer, 2010 ) and reported in the Table S2 in the Supplementary File 3 .","Modify,Clarity",Clarity
9297,7-407,7-407_v2_37@0,7-407_v1_34@0,"A Bayesian meta-analysis was implemented with the brms package ( Bürkner, 2017 ).","The Bayesian meta-analysis was implemented with the brms package ( Bürkner, 2017 ).","Modify,Grammar",Grammar
9298,7-407,7-407_v2_52@0,7-407_v1_50@0,Another “sensitivity analysis” was carried out excluding the new Mossbridge and Tressoldi studies in order to control whether different authors could obtain similar results.,Another “sensitivity analysis” was carried out excluding the Mossbridge and the Tressoldi studies in order to control whether different authors could obtain similar results.,"Modify,Clarity",Clarity
9299,7-407,7-407_v2_55@0,7-407_v1_53@0,"Both the frequentist and the Bayesian analyses support the evidence of an overall main effect of approximately .28, and a small difference between the peer and non-peer reviewed studies.","Both the frequentist and the Bayesian analyses support the evidence of an overall main effect of approximately .29, and a small difference between the peer and non-peer reviewed studies.","Modify,Fact/Evidence",Fact/Evidence
9300,7-407,7-407_v2_65@2,7-407_v1_57@1,"Anyway, we applied the Copas selection model which is recommended by Jin et al . (2015) .",We hence applied the Copas selection model which is recommended by Jin et al . (2015) .,"Modify,Clarity",Clarity
9301,7-407,7-407_v2_10@3,7-407_v1_7@3,"Now imagine if such prognosticating ability was possible without any sensory or other inferential cues (see Mossbridge & Radin, 2018 for a review).",Now imagine if such prognosticating ability was possible without any sensory or other inferential cues.,"Modify,Fact/Evidence",Fact/Evidence
9302,7-407,7-407_v2_69@0,7-407_v1_62@0,"This update of the Mossbridge et al. (2012) meta-analysis related to the so called predictive anticipatory activity (PAA) responses to future random stimuli, covers the period January 2008- July 2018.","This update of the Mossbridge et al. (2012) meta-analysis related to the so called predictive anticipatory activity (PAA) responses to future random stimuli, covers the years 2008- October 2017.","Modify,Fact/Evidence",Fact/Evidence
9303,7-407,7-407_v2_69@1,7-407_v1_62@1,"Overall, we found 19 new studies describing a total of 36 effect sizes.","Overall, we found 18 new studies describing a total of 34 effect sizes.","Modify,Fact/Evidence",Fact/Evidence
9304,7-407,7-407_v2_0@0,7-407_v1_0@0,Predictive physiological anticipatory activity preceding seemingly unpredictable stimuli: An update of Mossbridge et al ’s meta-analysis,Predictive physiological anticipation preceding seemingly unpredictable stimuli: An update of Mossbridge et al ’s meta-analysis,"Modify,Clarity",Clarity
9305,7-407,7-407_v2_72@0,7-407_v1_65@0,"Furthermore, we did not find substantial differences between peer and non-peer reviewed papers as in the original paper, as the confidence intervals of their mean effect size, overlap considerably.","Furthermore, we did not find substantial differences between peer and not-peer reviewed papers as in the original paper.","Modify,Fact/Evidence",Fact/Evidence
9306,7-407,7-407_v2_74@0,7-407_v1_69@0,This update confirms the main results reported in Mossbridge et al . (2012) original meta-analysis and gives further support to the hypothesis of predictive physiological anticipatory activity of future random events.,This update confirms the main results reported in Mossbridge et al . (2012) original meta-analysis and gives further support to the hypothesis of predictive physiological anticipation of future random events.,"Modify,Clarity",Clarity
9307,7-407,7-407_v2_75@0,7-407_v1_70@0,The limitations of the present meta-analysis are similar to most meta-analyses which include non-preregistered studies.,"The limitations of the present meta-analysis are similar to most meta-analyses which include non pre-registered studies that cannot be controlled for the degree of freedoms in the methodology and data analysis in the course of their implementations, making them prone, for example, to the so-called “questionable research practices” ( John et al ., 2012 ).","Modify,Claim",Claim
9308,7-407,7-407_v2_75@1,7-407_v1_71@0,"The solution is that of prospective meta-analyses ( Watt & Kennedy, 2017 ), based on all preregistered studies where the methods and data analyses have been declared and made public beforehand.","The solution is that of prospective meta-analyses ( Watt & Kennedy, 2017 ), based on preregistered studies where the methods and data analyses have been declared and made public beforehand.","Modify,Clarity",Clarity
9309,7-407,7-407_v2_10@7,7-407_v1_7@7,"Disturbingly, moments before the stimulus is presented there are physiological changes ahead of time.","Disturbingly, moments before the stimulus is presented there are murmurings of activity, as if the body is predicting moments ahead of time.","Modify,Claim",Claim
9310,7-407,7-407_v2_11@1,7-407_v1_8@1,"In both of these approaches it is difficult to envision mundane strategies that might explain the anomalous pre-stimulus effects observed, and indeed, Mossbridge et al ., went to significant lengths in refuting the leading candidate – expectancy effects, both in the 2012 meta-analysis and in post-review exchanges with sceptical psychologists and physiologists.","In both of these approaches it is difficult to envision mundane strategies that might explain the anomalous pre-stimulus effects observed, and indeed, Mossbridge et al , went to significant lengths in refuting the leading candidate – expectancy effects, both in the 2012 meta-analysis and in post-review exchanges with sceptical psychologists and physiologists.","Modify,Grammar",Grammar
9311,7-407,7-407_v2_11@4,7-407_v1_8@4,The presentiment hypothesis calls for a difference between the pre-stimulus responses of the two stimulus categories and this is calculated across sessions.,The presentiment hypothesis calls for a difference between arousing and neutral pre-stimulus responses and this is calculated across sessions.,"Modify,Clarity",Clarity
9312,7-407,7-407_v2_12@0,7-407_v1_9@0,"Because of the high profile nature of Mossbridge et al ., (over 93,000 views as of January 2018) there has been a good number of replications in the few years since publication.","Because of the high profile nature of Mossbridge et al , (over 93,000 views as of January 2018) there has been a good number of replications in the few years since publication.","Modify,Grammar",Grammar
9313,7-407,7-407_v2_12@3,7-407_v1_9@3,"Because expectancy effects have been proposed as a potential mechanism to explain at least some of the presentiment effect, it is noteworthy that several experiments in this fresh cohort of studies tackle this head on by only analysing the first trial of a run.","Because expectancy effects have been forwarded to explain at least some of the presentiment effect, it is noteworthy that several experiments in this fresh cohort of studies tackle this head on by only analysing the first trial of a run.","Modify,Claim",Claim
9314,7-407,7-407_v2_12@6,7-407_v1_9@6,This provides another objective measure of the validity of the presentiment effect.,This provides a second objective measure of the validity of the presentiment effect.,"Modify,Clarity",Clarity
9315,7-407,7-407_v2_14@0,7-407_v1_11@0,"The whole procedure followed both the APA Meta-Analysis Reporting Standards ( APA Publications and Communications Board Working Group on Journal Article Reporting Standards, 2008 ), the Preferred Reporting Items for Systematic reviews and Meta-Analyses for Protocols (PRISMA) 2015 ( Moher et al ., 2015 ) and the reporting standards for literature searches and report inclusion ( Atkinson et al ., 2015 ).","The whole procedure followed both the APA Meta-Analysis Reporting Standards ( APA Publications and Communications Board Working Group on Journal Article Reporting Standards, 2008 ), the Preferred Reporting Items for Systematic reviews and Meta-Analyses for Protocols 2015 ( Moher et al ., 2015 ) and the reporting standards for literature searches and report inclusion ( Atkinson et al ., 2015 ).","Modify,Clarity",Clarity
9316,7-407,7-407_v2_17@0,7-407_v1_14@0,It is important to point out that these eligibility criteria are different from those used by Mossbridge et al. Those authors selected only studies where the anticipatory signals mirrored the post-stimulus ones.,It is important to point out that these eligibility criteria are different from those used by Mossbridge et al. Those authors selected only studies were the anticipatory signals mirrored the post-stimulus ones.,"Modify,Grammar",Grammar
9317,7-407,7-407_v2_17@1,7-407_v1_14@1,In addition we included all studies that used anticipatory signals to predict future events independently of the presence of post-stimulus physiological signals.,Differently we included all studies that used anticipatory signals to predict future events independently of the presence of post-stimulus physiological signals.,"Modify,Clarity",Clarity
9318,7-407,7-407_v2_17@2,7-407_v1_14@2,"For example, some authors, e.g. Mossbridge (2015) used heart rate variability to predict winning i.e. $4, versus losing outcomes without recording the post-stimulus physiological activity associated with hits and misses.","For example, some authors, e.g. Mossbridge (2015) used heart rate variability to predict winning i.e. $4, versus losing outcomes.","Modify,Fact/Evidence",Fact/Evidence
9319,7-407,7-407_v2_19@1,7-407_v1_16@1,"Furthermore, we emailed a request of the data of completed studies to all authors we knew were involved in this type of research.","Furthermore, we emailed a request of the data of completed studies to all authors we knew were involved in this type of investigations.","Modify,Clarity",Clarity
9320,7-407,7-407_v2_19@3,7-407_v1_16@3,"We searched all completed studies, both peer reviewed and non-peer reviewed, e.g. Ph.D dissertations, from January 2008 to June 2018.","We searched all completed studies, both peer reviewed and non-peer reviewed, e.g. Ph.D dissertations, from January 2008 to October 2017.","Modify,Fact/Evidence",Fact/Evidence
9321,7-430,7-430_v2_4@2,7-430_v1_4@2,Pituitary adenoma constituted the bulk of pituitary disorders in this registry (67.2%).,Pituitary adenoma constituted the bulk of pituitary disease in this setting (67.2%).,"Modify,Clarity",Clarity
9322,7-430,7-430_v2_4@3,7-430_v1_4@3,Growth hormone secreting adenoma were the commonest adenoma seen in 41.0% followed by clinically non-functioning pituitary adenoma(NFPA)in 31.4% and prolactinoma in 26.9%.,"Growth hormone secreting adenoma were the most common adenoma seen in 41.0%, followed by clinically non-functioning pituitary adenoma (NFPA) in 31.4% and prolactinoma in 26.9%.","Modify,Grammar",Grammar
9323,7-430,7-430_v2_4@5,7-430_v1_4@5,"Macroadenoma was seen in 73.4 % of growth hormone secreting adenoma, 61.2% in NFPA and 62.0% of prolactinoma (of them six were giant prolactinoma)","Macroadenoma was seen in 73.4% of growth hormone secreting adenoma (acromegaly), 61.2% in NFPA and 62.0% of prolactinom a(of them six were giant prolactinoma).","Modify,Grammar",Grammar
9324,7-430,7-430_v2_43@0,7-430_v1_43@0,All pituitary disorders and adenoma were more common among women in this study.,All pituitary disease and adenoma were more common among women in this study.,"Modify,Clarity",Clarity
9325,7-430,7-430_v2_5@1,7-430_v1_5@1,A change in practice of pituitary adenoma treatment is needed.,A change in practice of adenoma treatment is needed.,"Modify,Clarity",Clarity
9326,7-430,7-430_v2_49@3,7-430_v1_49@3,"In Saudi Arabia, microadenomas were more prevalent <REF-17> .","In Saudi Arabia, microadenomas were more prevelant <REF-17> .","Modify,Grammar",Grammar
9327,7-430,7-430_v2_59@0,7-430_v1_59@0,Pituitary adenomas constituted the bulk of pituitary disorders in Basrah.,"Pituitary adenomas constituted the bulk of pituitary disease in patients treated at the FDEMC, Basrah.","Modify,Clarity",Clarity
9328,7-430,7-430_v2_59@2,7-430_v1_59@2,A change in the practice of pituitary adenoma treatment is needed.,A change in the practice of adenoma treatment is needed.,"Modify,Clarity",Clarity
9329,7-430,7-430_v2_0@0,7-430_v1_0@0,"Spectrum of Pituitary disorders: A retrospective study from Basrah, Iraq","Spectrum of Sellar and Parasellar Region Lesions: A retrospective study from Basrah, Iraq","Modify,Other",Other
9330,7-430,7-430_v2_11@0,7-430_v1_11@0,This study aimed at a comprehensive description of pituitary disorders for patients from FDEMC in Basrah (Southern Iraq).,This study aimed at providing a comprehensive overview of sellar and parasellar region lesions for patients from FDEMC in Basrah (Southern Iraq).,"Modify,Clarity",Clarity
9331,7-430,7-430_v2_14@0,7-430_v1_14@0,Retrospective data analysis of FDEMC database for the period from January 2012 through June 2017.,Retrospective data analysis of the FDEMC database for the period January 2012 through June 2017.,"Modify,Grammar",Grammar
9332,7-430,7-430_v2_19@0,7-430_v1_19@0,"Pituitary adenoma (NFPA, prolactinoma, growth hormone secreting adenoma [acromegaly], and adrenocorticotropic hormone (ACTH)-secreting adenoma) were defined according to the usual criteria <REF-2> , <REF-8> , <REF-12> .","Pituitary adenoma, NFPA, prolactinoma, growth hormone secreting adenoma (acromegaly), and ACTH-secreting adenoma were defined according to the usual criteria <REF-2> , <REF-8> , <REF-12> .","Modify,Clarity",Clarity
9333,7-430,7-430_v2_25@0,7-430_v1_25@0,Continuous variables were summarized as number and percentage and dichotomous variables as mean ±SD.,Continuous variables were summeried as number and percentage and dichotomous varibales as mean ±SD.,"Modify,Grammar",Grammar
9334,7-430,7-430_v2_29@1,7-430_v1_29@1,Pituitary disorders were more common among women ( Table 1 ).,Pituitary disease and adenoma were more common among women ( Table 1 ).,"Modify,Clarity",Clarity
9335,7-430,7-430_v2_32@0,7-430_v1_32@0,Table 2 shows that pituitary adenoma constituted the bulk of pituitary disorders in this registry (67.2%).,Table 2 shows that pituitary adenoma constituted the bulk of pituitary disease in this registry (67.2%).,"Modify,Clarity",Clarity
9336,7-430,7-430_v2_4@1,7-430_v1_4@1,Those with macroadenoma were older than those with microadenoma with nearly equal gender prevalence of macroadenoma.,"Those with macroadenoma were older than those with microadenoma, with nearly equal gender prevalence of macroadenoma.","Modify,Grammar",Grammar
9337,7-521,7-521_v2_24@0,,"While we believe that ANI and other similar measures recently categorized as overall genome related index (OGRI) <REF-35> should be used for species/subspecies determination, phenotypic differences due to gene content may play a role particularly for delineation of subspecies.",,"Add,Claim",Claim
9338,7-521,7-521_v2_24@10,,Gene content analysis can also be confounded by misassembly or misannotation of draft genomes which is why we use RefSeq genomes which have passed a quality screen and are consistently annotated.,,"Add,Claim",Claim
9339,7-521,7-521_v2_25@11,,For xiangfangensis most (222 out of 255) of the genomes have the aga operon but 33 have the gat operon instead.,,"Add,Fact/Evidence",Fact/Evidence
9340,7-521,7-521_v2_25@15,,"The gat, aga, and rbt/dal operons are not limited to the E. hormaechei clades but appear in some other E. cloacae complex species as shown in Supplemental Table 6 .",,"Add,Fact/Evidence",Fact/Evidence
9341,7-521,7-521_v2_32@4,,This analysis supported our decision on what genomes are outliers.,,"Add,Fact/Evidence",Fact/Evidence
9342,7-521,7-521_v2_32@6,,The type strain 16S sequence (Z96077) for Lelliottia nimipressuralis doesn’t match this purported type strain genome sequence and this genome is an exact duplicate to the previously submitted Enterobacter sp. FB ( ASM80579v1 ).,,"Add,Fact/Evidence",Fact/Evidence
9343,7-521,7-521_v2_32@7,,The duplicate genomes are from the same submitter and the only reasonable conclusion is that this was a submission error for Lelliottia nimipressuralis .,,"Add,Claim",Claim
9344,7-521,7-521_v2_32@8,,This has been reported to NCBI GenBank for resolution ( Supplemental File 2 ).,,"Add,Fact/Evidence",Fact/Evidence
9345,7-521,7-521_v2_35@0,,The reason we use MASH to estimate ANI is that few other tools such as Genome-to-Genome Distance Calculator (GGDC) <REF-18> are efficient enough to compute 1249×1249 pairwise comparisons.,,"Add,Fact/Evidence",Fact/Evidence
9346,7-521,7-521_v2_35@1,,To our knowledge GGDC is only available as a web based application with a limit of submitting 75 comparisons at one time.,,"Add,Claim",Claim
9347,7-521,7-521_v2_35@2,,MASH is only an approximation of ANI based on sampling but as we showed for species level comparisons (> 94% ANI) provides a quite accurate estimate.,,"Add,Fact/Evidence",Fact/Evidence
9348,7-521,7-521_v2_35@3,,For final determination of novel species boundaries MASH should be supported by an exact ANI calculation as we did using PanOCT which determines ANI based on orthologous matches similar to OrthoANI <REF-44> .,,"Add,Fact/Evidence",Fact/Evidence
9349,7-521,7-521_v2_35@4,,Comparison of MASH and PanOCT ANI to GGDC which has been carefully validated with respect to actual laboratory DDH results increases confidence in our methods.,,"Add,Fact/Evidence",Fact/Evidence
9350,7-521,7-521_v2_35@6,,In order to easily compare GGDC to PanOCT ANI we converted PanOCT ANI into a distance measure d PANI = 1 – (PanOCT ANI/100).,,"Add,Fact/Evidence",Fact/Evidence
9351,7-521,7-521_v2_35@8,,Total genome length is the sum of the two genomes being compared.,,"Add,Fact/Evidence",Fact/Evidence
9352,7-521,7-521_v2_35@9,,Formula 1 is a measure of what percentage of the two genomes are shared in common.,,"Add,Fact/Evidence",Fact/Evidence
9353,7-521,7-521_v2_35@10,,Formula 2 is basically one variation of how to calculate ANI.,,"Add,Fact/Evidence",Fact/Evidence
9354,7-521,7-521_v2_35@11,,Formula 3 is a combination of formulas 1 and 2.,,"Add,Fact/Evidence",Fact/Evidence
9355,7-521,7-521_v2_35@12,,The GGDC recommends Formula 2 for draft genomes since it is affected least by genome completeness.,,"Add,Fact/Evidence",Fact/Evidence
9356,7-521,7-521_v2_35@13,,The GGDC then uses some statistical modeling to approximate a predicted laboratory DDH value.,,"Add,Fact/Evidence",Fact/Evidence
9357,7-521,7-521_v2_35@14,,Supplemental Figure 3 and Supplemental Table 8 shows that for the combined four datasets d PANI is practically indistinguishable from GGDC Formula 2.,,"Add,Fact/Evidence",Fact/Evidence
9358,7-521,7-521_v2_43@1,,IJSEM currently recognizes provisional species names under the Candidatus designation <REF-46> .,,"Add,Fact/Evidence",Fact/Evidence
9359,7-521,7-521_v2_43@2,,Candidatus was designed for unculturable organisms where a type strain could not be maintained but phenotypic data is still required to be submitted.,,"Add,Claim",Claim
9360,7-521,7-521_v2_43@3,,This is not a good fit for the case where genome sequences exist and species/subspecies are determined computationally because it was designed for environmental or unculturable samples with limited sequence data but at least some phenotypic or morphological data.,,"Add,Claim",Claim
9361,7-521,7-521_v2_43@4,,We suggest that some similar designation be used for our proposed “placeholder” names.,,"Add,Claim",Claim
9362,7-521,7-521_v2_43@5,,"We do not want to computationally assign permanent names with a provisional status, but would rather have the name itself indicate it is provisional and to be replaced when someone does the hard work of depositing a type strain and any required minimal phenotypic information.",,"Add,Claim",Claim
9363,7-521,7-521_v2_44@0,,In the Results section we noted that the type strains for E. asburiae and E. muelleri fall within the same clade which could be separated into subspecies by ANI but we declined to do so.,,"Add,Fact/Evidence",Fact/Evidence
9364,7-521,7-521_v2_44@1,,For E. hormaechei we did propose new subspecies but this was because subspecies for E. hormaechei had already been defined.,,"Add,Fact/Evidence",Fact/Evidence
9365,7-521,7-521_v2_44@2,,We believe that there must be a cogent reason for delineating beyond the species level.,,"Add,Claim",Claim
9366,7-521,7-521_v2_44@6,,An overall genome related index (OGRI) is a computational measure of genome similarity or distance of which ANI is one such.,,"Add,Claim",Claim
9367,7-521,7-521_v2_44@7,,Our ANI analysis possibly fullfill criteria i-iii although given how few strains are in most of the putative subspecies this does not seem robust and criteria iv-v are clearly not met.,,"Add,Claim",Claim
9368,7-521,7-521_v2_44@8,,We only raised the subspecies issue for E. asburiae and E. muelleri because often in the past when two competing names exist for a species if the type strains can be separated into clear clades they become subspecies.,,"Add,Claim",Claim
9369,7-521,7-521_v2_44@9,,Since the type strains fall into neither of the major clades for this species and certainly do not cleanly divide the species we did not feel this was appropriate.,,"Add,Claim",Claim
9370,7-521,7-521_v2_66@0,,"Data associated with the article are available under the terms of the Creative Commons Zero ""No rights reserved"" data waiver (CC0 1.0 Public domain dedication).",,"Add,Fact/Evidence",Fact/Evidence
9371,7-521,,7-521_v1_12@0,,Background,"Delete,Other",Other
9372,7-521,,7-521_v1_25@5,,"While ANI is the primary determinant of drawing distinctions between species and subspecies, gene content plays a role in generating phenotypic differences which might rationalize segregating a clade from species into subspecies.","Delete,Claim",Claim
9373,7-521,,7-521_v1_43@0,,Conclusion,"Delete,Other",Other
9374,7-521,7-521_v2_7@1,7-521_v1_7@1,O’Hara et al. <REF-1> defined the type strain to be ATCC 49162 T from the 23 strains they studied.,O’Hara et al <REF-1> . defined the type strain to be ATCC 49162 T from the 23 strains they studied.,"Modify,Grammar",Grammar
9375,7-521,7-521_v2_18@7,7-521_v1_19@7,Whether the 8 subclades of E. asburiae should be treated as subspecies is beyond the scope of this paper but is revisited in the Discussion section.,Whether the 8 subclades of E. asburiae should be treated as subspecies is beyond the scope of this paper.,"Modify,Fact/Evidence",Fact/Evidence
9376,7-521,7-521_v2_9@0,7-521_v1_9@0,"Hoffmann et al. <REF-3> followed up with a characterization of clusters VI, VII, and VIII asserting based on DDH that these clusters were subspecies of the same species.","Hoffmann et al <REF-3> . followed up with a characterization of clusters VI, VII, and VIII asserting based on DDH that these clusters were subspecies of the same species.","Modify,Grammar",Grammar
9377,7-521,7-521_v2_24@1,7-521_v1_25@0,"To explore the gene content differences of the E. cloacae complex and the E. hormaechei subspecies in particular, the pan-genome of the 1,216 E. cloacae complex genomes was determined using PanOCT <REF-36> .","To explore the gene content differences of the E. cloacae complex and the E. hormaechei subspecies in particular, the pan-genome of the 1216 E. cloacae complex genomes was determined using PanOCT <REF-35> .","Modify,Grammar",Grammar
9378,7-521,7-521_v2_24@3,7-521_v1_25@2,"There were 2,966 genes in “common to all” of the clades (present in 90% of the genomes of each clade).",There were 2966 genes in “common to all” of the clades (present in 90% of the genomes of each clade).,"Modify,Grammar",Grammar
9379,7-521,7-521_v2_24@11,7-521_v1_25@10,Again we emphasize that ANI as our primary criterium appears to have less of these subjective issues to deal with.,ANI appears to have less of these subjective issues to deal with.,"Modify,Claim",Claim
9380,7-521,7-521_v2_27@1,7-521_v1_28@1,"A PERL script was used to invoke the following command to generate a set of MASH (version 2.0) sketches of k-mer size 16 for the 1,249 downloaded Enterobacter genomes:",A PERL script was used to invoke the following command to generate a set of MASH (version 2.0) sketches of k-mer size 16 for the 1249 downloaded Enterobacter genomes:,"Modify,Grammar",Grammar
9381,7-521,7-521_v2_31@1,7-521_v1_32@1,We used the GGRaSP <REF-40> R package (version 1.0) which generated an ultramateric tree by using the R hclust function with average linkage from the distance matrix calculated by subtracting 100 from the MASH ANI results.,We used the GGRaSP R package (version 1.0) which generated an ultramateric tree by using the R hclust function with average linkage from the distance matrix calculated by subtracting 100 from the MASH ANI results.,"Modify,Fact/Evidence",Fact/Evidence
9382,7-521,7-521_v2_12@8,7-521_v1_13@8,"With the advent of inexpensive genome sequencing, computing ANI, which correlates very closely with DDH, has largely supplanted other methods.","With the advent of inexpensive genome sequencing, computing average nucleotide identity (ANI), which correlates very closely with DDH, has largely supplanted other methods.","Modify,Clarity",Clarity
9383,7-521,7-521_v2_33@4,7-521_v1_34@4,"These 23 representative genomes were used to “type” all 1,216 Enterobacter cloacae complex genomes ( Supplemental Table 1 ).",These 23 representative genomes were used to “type” all 1216 Enterobacter cloacae complex genomes ( Supplemental Table 1 ).,"Modify,Grammar",Grammar
9384,7-521,7-521_v2_34@0,7-521_v1_35@0,"GGRaSP was similarly used to select the 250 most diverse genomes including the outliers from the 1,249 downloaded genomes while eliminating very closely related genomes.",GGRaSP was similarly used to select the 250 most diverse genomes including the outliers from the 1249 downloaded genomes while eliminating very closely related genomes.,"Modify,Grammar",Grammar
9385,7-521,7-521_v2_42@0,7-521_v1_42@0,The Introduction section reviews how the tools for defining a species have evolved.,The Background section reviews how the tools for defining a species have evolved.,"Modify,Fact/Evidence",Fact/Evidence
9386,7-521,7-521_v2_42@6,7-521_v1_42@6,"Unfortunately, the current established journal for validly publishing bacterial species’ names, IJSEM, insists on phenotypic characterization and deposition of the type strain before naming is valid.","Unfortunately, the current established journal for validly publishing bacterial species’ names insists on phenotypic characterization and deposition of the type strain before naming is valid.","Modify,Clarity",Clarity
9387,7-521,7-521_v2_43@0,7-521_v1_42@14,We propose allowing “placeholder” species or subspecies names such as “ E. cloacae complex clade S” in order to enable the most robust use of computational and genomic resources for clinical diagnosis.,We propose allowing “placeholder” species or subspecies names such as “ E. cloacae complex clade S” in order to enable the most robust use of computational and genomic resources for clinical diagnosis while awaiting the designation and deposition of a type strain with a valid name possibly with some minimal phenotypic characterization.,"Modify,Claim",Claim
9388,7-521,7-521_v2_45@4,7-521_v1_44@4,We propose to name clade M/Hoffmann cluster IV Enterobacter roggenkampii after Andreas Roggenkamp for his work on elucidating the phylogenetic structure of the E. cloacae complex <REF-2> .,We propose to name clade M / Hoffmann cluster IV Enterobacter roggenkampii after Andreas Roggenkamp for his work on elucidating the phylogenetic structure of the E. cloacae complex <REF-2> .,"Modify,Grammar",Grammar
9389,7-697,7-697_v2_17@5,7-697_v1_17@5,RH is the distance from CO to the Go’ (the reflection of subdivision tangen from ramus and corpus mandibular to the ramus borderline).,RH is the distance from CO to the gonion.,"Modify,Fact/Evidence",Fact/Evidence
9390,7-697,7-697_v2_23@0,7-697_v1_23@0,"To determine the random error, inter-rater (T.B. and E.S.) and intra-rater (E.S. under supervised of T.B.) measurements of variables in this study were randomly done from 20 panoramic radiographs.","To determine the random error, inter-rater (T.B. and E.S.) and intra-rater (E.S.) measurements of variables in this study were randomly selected from 20 panoramic radiographs.","Modify,Clarity",Clarity
9391,7-697,7-697_v2_23@1,7-697_v1_23@1,"The validity and reliability, measured using Cohen’s κ, showed moderate agreement for inter-rater measure-ments between T.B and E.S (κ=0.538) whilst intra-rater measurements from E.S that repeated the measurements 1 week after the first examination and blinded to the initial values (κ=0.674).","Finally, this study used intra-rater measurement as reference data for assessing vertical mandibular symmetry, which repeated the measurements 1 week after the first examination, while blinded to the initial values.","Link+Modify,Clarity",Clarity
9393,7-697,7-697_v2_23@1,7-697_v1_23@2,"The validity and reliability, measured using Cohen’s κ, showed moderate agreement for inter-rater measure-ments between T.B and E.S (κ=0.538) whilst intra-rater measurements from E.S that repeated the measurements 1 week after the first examination and blinded to the initial values (κ=0.674).","The validity and reliability, measured using Cohen’s κ, showed moderate agreement for inter-rater measurements (κ=0.538) whilst intra-rater measurements (κ=0.674).","Link+Modify,Clarity",Clarity
9394,7-697,7-697_v2_31@8,7-697_v1_31@8,This study used Kjellberg’s technique because it is easier to identify the condylar height using this technique than Habets’ method in vertical mandibular symmetry assessment.,This study used Kjellberg’s technique because it is easier to identify the condylar height using this technique than Habet’s method.,"Modify,Claim",Claim
9395,7-697,7-697_v2_31@9,7-697_v1_31@9,"Habets’ method is more complicated when making reference points of the most lateral point of the condyle due to variation in the condylar anatomy <REF-16> , <REF-17> , <REF-29> .","Habet’s method is more complicated when making reference points of the most lateral point of the condyle due to variation in the condylar anatomy <REF-16> , <REF-17> , <REF-31> .","Modify,Grammar",Grammar
9396,7-697,7-697_v2_35@1,7-697_v1_35@1,"In the future, although the result in Table 3 showed a non-significant correlation, the TMD-DI as early screening for TMD might require panoramic radiography with postero-anterior radiography or 3D-cone beam computerized tomography to analyze the complexity of TMD development and mandibular asymmetry.","In the future, although the result in Table 3 showed a non-significant correlation, the TMD-DI as early screening for TMD might require panoramic radiography with postero-anterior radiography or 3D-cone beam computerized tomography to analyze the complexity of development of TMD and mandibular asymmetry.","Modify,Clarity",Clarity
9397,7-697,7-697_v2_35@3,7-697_v1_35@3,"This condition could affect the development of TMD symptoms and vertical mandibular asymmetry; this matches the study by Halicioglu et al. , which reported a slight difference in the vertical mandibular symmetry index was found in patients with early unilateral mandibular first molar extractions <REF-37> .","This condition could affect the development of TMD symptoms and vertical mandibular asymmetry; this matches the study by Halicioglu et al. , which that reported a slight difference in the vertical mandibular symmetry index was found in patients with early unilateral mandibular first molar extractions <REF-39> .","Modify,Grammar",Grammar
9398,7-697,7-697_v2_36@3,7-697_v1_36@3,"However, a combination of questionnaires (as diagnostic indexes) and radiography analysis of predominantly vertical or horizontal mandibular asymmetries indicates that susceptibility to fluctuating asymmetry is increasing <REF-32> .","However, a combination of questionnaires (as diagnostic indexes) and radiography analysis indicates that susceptibility to fluctuating asymmetry is increasing.","Modify,Fact/Evidence",Fact/Evidence
9399,7-697,7-697_v2_38@1,7-697_v1_38@1,"Further studies on the development of TMD, mandibular asymmetry and treatment planning for growing patients are suggested, using longitudinal and transitional approaches.","Further study on the development of TMD, mandibular asymmetry and treatment planning for young patients is suggested, using longitudinal and transitional approaches.","Modify,Grammar",Grammar
9400,7-697,7-697_v2_10@1,7-697_v1_10@1,"The asymmetry indices of mandibular height based on the ratio of condylar height (CH) and ramus height (RH) asymmetry, according to Habets’ method and Kjellberg’s technique, correlated significantly between TMD and non-TMD patients <REF-14> , <REF-15> .","The asymmetry indices of mandibular height based on the ratio of condylar height (CH) and ramus height (RH) asymmetry, according to Habet’s method and Kjellberg’s technique, correlated significantly between TMD and non-TMD patients <REF-14> , <REF-15> .","Modify,Grammar",Grammar
9401,7-704,,7-704_v1_34@3,,"Although the current version of SimNIBS does not allow exporting the resulting E-field maps into FreeSurfer, this option will be available in an upcoming version.","Delete,Claim",Claim
9402,7-704,7-704_v2_12@6,,"Additionally, the segmentation of the brainstem is not accurate because it arbitrarily assigned brain tissue to white and grey matter.",,"Add,Claim",Claim
9403,7-704,7-704_v2_12@10,,"Secondly, an extended head model with field of view covering the entire head would further increase the predictive accuracy of the head models <REF-35> .",,"Add,Fact/Evidence",Fact/Evidence
9404,7-704,7-704_v2_13@3,,"In addition, air cavities were modeled by not adding tetrahedra to these locations, similar to the air surrounding the head.",,"Add,Fact/Evidence",Fact/Evidence
9405,7-704,7-704_v2_20@2,,It was a custom pipeline developed before the official release of SimNIBS 2.1 .,,"Add,Fact/Evidence",Fact/Evidence
9406,7-704,7-704_v2_20@3,,"However, using headreco combined with the CAT12 toolbox (included with SimNIBS 2.1.1 ) for cortical reconstruction, the same accuracy can be achieved.",,"Add,Claim",Claim
9407,7-704,7-704_v2_25@5,,"Accessing group differences between MDD and healthy subjects was not the primary aim of the current data note, however, analysis of the spatial distribution of tDCS-induced E-fields in the bilateral DLPFC and medial prefrontal cortex showed subtle group differences between the healthy and MDD groups.",,"Add,Fact/Evidence",Fact/Evidence
9408,7-704,7-704_v2_13@5,7-704_v1_13@3,The total volume of the brain was 1.22 dm 3 ± 0.11 dm 3 (range: 1.02 dm 3 - 1.49 dm 3 ).,The total volume of the brain was 1.22 dm 3 ± 0.11 dm 3 (range: 1.02 dm 3 – 1.49 dm 3 ).,"Modify,Grammar",Grammar
9409,7-704,7-704_v2_20@0,7-704_v1_20@0,"Except for two manual steps (removal of MRI markers from the forehead, manual correction of tissue segmentations), the process of head model creation was automated using a custom version of SimNIBS 2.1 that employed FreeSurfer 5.3.0 for brain segmentation (as described in <REF-38> and implemented in mri2mesh) and SPM12 for segmentation of the remaining tissues (similarly to <REF-39> and implemented in headreco).","Except for two manual steps (removal of MRI markers from the forehead, manual correction of tissue segmentations), the process of head model creation was automated using a pre-release version of SimNIBS 2.1 that employed FreeSurfer 5.3.0 for brain segmentation (as described in <REF-29> ) and SPM12 for segmentation of the remaining tissues (similarly to <REF-30> ).","Modify,Fact/Evidence",Fact/Evidence
9410,7-704,7-704_v2_20@1,7-704_v1_20@1,This pipeline provides more accurate tissue segmentation relative to other protocols.,This new SimNIBS pipeline provides more accurate tissue segmentation relative to other protocols.,"Modify,Clarity",Clarity
9411,7-704,7-704_v2_20@4,7-704_v1_20@2,We provide scripts compatible with SimNIBS 2.1.1 for automated simulation of tDCS-induced electric fields for all head models available for download at our data repository <REF-36> .,The scripts used for automated simulation of tDCS effects for all head models (as shown in Figure 3 ) are available for download at our data repository <REF-27> .,"Modify,Fact/Evidence",Fact/Evidence
9412,7-704,7-704_v2_4@0,7-704_v1_4@0,"Non-invasive brain stimulation (NIBS) techniques such as transcranial direct current stimulation (tDCS) and transcranial magnetic stimulation (TMS) have been used to investigate the relationship between activity in different cortical regions and cognitive processes <REF-1> , <REF-2> .",Non-invasive brain stimulation (NIBS) techniques such as transcranial direct current stimulation (tDCS) and transcranial magnetic stimulation (TMS) have been used to investigate the relationship between activity in different cortical regions and cognitive processes.,"Modify,Fact/Evidence",Fact/Evidence
9413,7-704,7-704_v2_25@3,7-704_v1_24@3,"Mean and peak E-field values corresponding to both tDCS montages were extracted by reconstructing the two-dimensional cortical surface (more precisely, the middle of the cortical sheet) of each individual along with the corresponding E-field cortical map in FreeSurfer, and an automated atlas-based parcellation of the frontal lobe <REF-41> was applied to each individual brain to delineate the lDLPFC.","Mean and peak E-field values corresponding to both tDCS montages were extracted by reconstructing the two-dimensional cortical surface (more precisely, the middle of the cortical sheet) of each individual along with the corresponding E-field cortical map in FreeSurfer, and applying automated atlas-based parcellation of the frontal lobe to delineate the lDLPFC region in each brain <REF-32> .","Modify,Clarity",Clarity
9414,7-704,7-704_v2_4@1,7-704_v1_4@1,A key advantage of NIBS is that it allows direct manipulation of neural excitability <REF-3> .,A key advantage of NIBS is that it allows direct manipulation of neural excitability.,"Modify,Fact/Evidence",Fact/Evidence
9415,7-704,7-704_v2_25@4,7-704_v1_25@0,"As a result, we show that (1) both protocols induce strong E-fields in the DLPFC (with symmetrical effects for the bipolar montage and unilateral E-field distribution for the 4x1 protocol), (2) E-field magnitudes and distributions are similar for our head models and for the NY Head, (3) all E-field measures (peak and mean strength, FI) show great degree of variability, and (4) montage-specific effects are consistent with previous results reported in the literature regarding both the spatial distribution and the magnitude of E-fields <REF-35> , <REF-42> – <REF-45> ( Figure 3 , Figure 4 ).","As a result, we show that (1) both protocols induce strong E-fields in the DLPFC (with symmetrical effects for the bipolar montage and unilateral E-field distribution for the 4×1 protocol), (2) effects are similar for our head models and for the NY Head, (3) all E-field measures (peak and mean strength, FI) show great degree of variability, and (4) montage-specific effects are consistent with previous results reported in the literature regarding both the spatial distribution and the magnitude of E-fields <REF-33> – <REF-37> ( Figure 3 , Figure 4 ).","Modify,Fact/Evidence",Fact/Evidence
9416,7-704,7-704_v2_4@2,7-704_v1_4@2,"Therefore when used carefully, it allows causal interpretation of how specific brain regions might be involved in mental phenomena such as perception <REF-4> , working memory <REF-5> , attention <REF-6> , decision-making <REF-7> or emotional regulation <REF-8> .","Therefore when used carefully, it allows causal interpretation of how specific brain regions might be involved in mental phenomena such as perception, working memory, attention, decision-making or emotional regulation.","Modify,Fact/Evidence",Fact/Evidence
9417,7-704,7-704_v2_25@6,7-704_v1_28@0,For detailed discussion of these results and that of Figure 4 we refer the reader to our accompanying paper <REF-14> .,For detailed discussion of the results presented in Figure 4 we refer the reader to our accompanying paper <REF-6> .,"Modify,Clarity",Clarity
9418,7-704,7-704_v2_33@0,7-704_v1_34@0,Our head models are compatible with SimNIBS 2.1.1 ( http://simnibs.de/ ) for simulating the effects of tDCS and TMS protocols.,Our head models are compatible with SimNIBS 2.0 ( http://simnibs.de/ ) for simulating the effects of tDCS and TMS protocols.,"Modify,Fact/Evidence",Fact/Evidence
9419,7-704,7-704_v2_2@0,7-704_v1_2@0,"During the past decade, it became clear that the electric field elicited by non-invasive brain stimulation (NIBS) techniques such as transcranial direct current stimulation (tDCS) and transcranial magnetic stimulation (TMS) are substantially influenced by variations in individual head and brain anatomy.","During the past decade, it became clear that the effects of non-invasive brain stimulation (NIBS) techniques such as transcranial direct current stimulation (tDCS) and transcranial magnetic stimulation (TMS) are substantially influenced by variations in individual head and brain anatomy.","Modify,Clarity",Clarity
9420,7-704,7-704_v2_33@3,7-704_v1_34@4,"The script will also output data registered to an average surface (’fsaverage’) which allows creating group averaged data, as we have shown previously <REF-14> .","This will enable registering data to an average surface (’fsaverage’) and creating group averaged data, as we have shown previously <REF-6> .","Modify,Clarity",Clarity
9421,7-704,7-704_v2_33@4,7-704_v1_34@5,"In addition, researchers have the opportunity to extract E-field components that are either radial (normal) or tangential relative to the cortical surface, and have been associated with different cellular effects <REF-46> .","In addition, using the upcoming new version of SimNIBS, researchers will have the opportunity to extract E-field components that are either radial (normal) or tangential relative to the cortical surface, and have been associated with different cellular effects <REF-38> .","Modify,Clarity",Clarity
9422,7-704,7-704_v2_0@0,7-704_v1_0@0,Head models of healthy and depressed adults for simulating the electric fields of non-invasive electric brain stimulation,Head models of healthy and depressed adults for simulating the effects of non-invasive brain stimulation,"Modify,Other",Other
9423,7-704,7-704_v2_5@0,7-704_v1_5@0,"Given the heterogeneity in the efficacy of NIBS protocols in modulating behavior and clinical symptoms, there has been a move towards computational modelling of the spatial distribution of E-fields in the brain to understand how stimulation parameters such as electrode placement, electrode rotation or electrode type affects current flow in the neural tissue.","Given the heterogeneity in the efficacy of NIBS protocols in modulating behavior and clinical symptoms, there has been a move towards computational modelling of the spatial distribution of E-fields in the brain to understand how stimulation parameters such as electrode placement, rotation or type affects current flow in the neural tissue.","Modify,Clarity",Clarity
9424,7-704,7-704_v2_8@0,7-704_v1_8@0,Methods and results,Methods,"Modify,Other",Other
9425,7-704,7-704_v2_12@1,7-704_v1_12@1,"Automated tissue segmentation was performed in SPM12 <REF-34> for skin, skull, eyeballs, CSF and major air cavities, and in FreeSurfer for gray and white matter.","Automated tissue segmentation was performed in SPM12 <REF-26> for skin, skull, eyeballs and CSF, and in FreeSurfer for gray and white matter.","Modify,Fact/Evidence",Fact/Evidence
9426,7-704,7-704_v2_12@5,7-704_v1_12@5,"Moreover, the resulting masks were not corrected for inconsistencies relating to subcortical nuclei and thus, these head models are not suitable for estimating stimulation-related E-fields in structures such as the thalamus, basal ganglia, amygdala or the cerebellum.","Moreover, the resulting masks were not corrected for inconsistencies relating to subcortical nuclei and thus, these head models are not suitable for estimating stimulation-related E-fields in structures such as the thalamus, basal ganglia, amygdala, or brainstem nuclei.","Modify,Claim",Claim
9427,7-704,7-704_v2_2@3,7-704_v1_2@3,"By using a freely available software package for modelling the electric fields induced by different NIBS protocols, we show that our head models are well-suited for assessing inter-individual and between-group variability in the magnitude and focality of tDCS-induced electric fields for two protocols targeting the left dorsolateral prefrontal cortex.","By using a freely available software package for modelling the effects of different NIBS protocols, we show that our head models are well-suited for assessing inter-individual and between-group variability in the magnitude and focality of tDCS-induced electric fields for two protocols targeting the left dorsolateral prefrontal cortex.","Modify,Fact/Evidence",Fact/Evidence
9428,7-704,7-704_v2_12@7,7-704_v1_12@6,"Furthermore, because the original dataset was de-faced and did not include the neck/shoulder region, our head models do not include these regions.","Additionally, because the original dataset was de-faced and did not include the neck/shoulder region, our head models do not include these regions.","Modify,Clarity",Clarity
9429,7-704,7-704_v2_13@0,7-704_v1_13@0,"Head models were created with a custom version of SimNIBS 2.1 <REF-23> , a freely available software package for simulating the effects of NIBS techniques.","Head models were created with an extended, pre-release version of SimNIBS 2.1 <REF-15> , a freely available software package for simulating the effects of NIBS techniques.","Modify,Clarity",Clarity
9430,7-738,7-738_v2_4@2,,"In their study to assess PE and deep vein thrombosis (DVT) inpatient costs in the United States, Lamori et al . found that the mean cost of initial hospitalization for acute PE was approximately $37,006 per patient <REF-3> .",,"Add,Fact/Evidence",Fact/Evidence
9431,7-738,7-738_v2_4@3,,"This figure was higher for older patients, women and readmissions.",,"Add,Fact/Evidence",Fact/Evidence
9432,7-738,7-738_v2_8@5,,"There was no chest pain, tachypnea or tachycardia at this time.",,"Add,Fact/Evidence",Fact/Evidence
9433,7-738,7-738_v2_4@1,7-738_v1_4@1,It exacts a huge economic burden both on the sufferer and the health system.,"It exacts a huge economic burden both on the sufferer and the health system with some estimates placing the annual cost of care between $7,594 to $16,644 per patient <REF-3> .","Modify,Fact/Evidence",Fact/Evidence
9434,7-738,7-738_v2_4@4,7-738_v1_4@2,"Prompt diagnosis is, therefore, essential to reduce disease burden.",Prompt diagnosis is essential to reduce disease burden.,"Modify,Clarity",Clarity
9435,7-738,7-738_v2_6@1,7-738_v1_6@1,"Chest pain was described as left-sided, non-pleuritic, non-radiating, retrosternal, squeezing in character and persistent.","Chest pain was described as left-sided non-pleuritic, non-radiating retrosternal, squeezing in character and persistent.","Modify,Grammar",Grammar
9436,7-738,7-738_v2_7@0,7-738_v1_7@0,"On this visit, his pulse rate was 84 beats per minute; BP 119/66 mm/Hg; respiration rate 16 breaths per minute and his oxygen saturation was 98% on room air.","In this visit, his pulse rate was 84 beats per minute; BP 119/66 mm/Hg; respiration rate 16 breaths per minute and his oxygen saturation was 98% on room air.","Modify,Grammar",Grammar
9437,7-738,7-738_v2_8@0,7-738_v1_8@0,EKG showed deep T wave inversions in leads V1–V6 and the inferior limb leads ( Figure 1 ).,EKG showed deep T wave inversions in leads V1-V6 and the inferior limb leads ( Figure 1 ).,"Modify,Grammar",Grammar
9438,7-738,7-738_v2_8@3,7-738_v1_8@3,Cardiac catheterization revealed normal coronaries ( Supplementary file 1 ).,Left heart catheterization revealed normal coronaries.,"Modify,Fact/Evidence",Fact/Evidence
9439,7-738,7-738_v2_8@4,7-738_v1_8@4,"While the patient was still lying on the cardiac cath table, his oxygen saturation dropped to 91%.",Oxygen saturation dropped to 91% in room air while the patient laid on catheterization table but improved with supplemental oxygen via nasal cannula.,"Split+Modify,Clarity",Clarity
9440,7-738,7-738_v2_8@6,7-738_v1_8@4,Supplemental oxygen at 2l/min via nasal cannula improved saturation to 97%.,Oxygen saturation dropped to 91% in room air while the patient laid on catheterization table but improved with supplemental oxygen via nasal cannula.,"Split+Modify,Fact/Evidence",Fact/Evidence
9441,7-738,7-738_v2_8@7,7-738_v1_8@5,A repeat EKG showed a Q 3 T 3 pattern in lead III ( Figure 2 ).,A repeat EKG at this time showed a Q 3 T 3 pattern in lead III ( Figure 2 ).,"Modify,Clarity",Clarity
9442,7-738,7-738_v2_8@8,7-738_v1_8@6,"In view of these new findings (low oxygen saturation and a change in the EKG pattern), a computerized tomography of the chest with angiogram (chest CTA) was ordered.","This was followed by a computerized tomography of the chest with angiogram (chest CTA), which revealed a saddle pulmonary embolus which extended into the right and left pulmonary arteries and involved all lobar branches of the pulmonary arteries.","Split+Modify,Clarity",Clarity
9443,7-738,7-738_v2_8@9,7-738_v1_8@6,This revealed a saddle pulmonary embolus which extended into the right and left pulmonary arteries and involved all lobar branches of the pulmonary arteries ( Figure 3 ).,"This was followed by a computerized tomography of the chest with angiogram (chest CTA), which revealed a saddle pulmonary embolus which extended into the right and left pulmonary arteries and involved all lobar branches of the pulmonary arteries.","Split+Modify,Fact/Evidence",Fact/Evidence
9444,7-738,7-738_v2_17@9,7-738_v1_15@9,The clues to possible acute PE in our case was the transient desaturation that occurred during cardiac catheterization and the observed change on repeat EKG.,The only clue to possible acute PE in our case was the transient desaturation that occurred during cardiac catheterization.,"Modify,Fact/Evidence",Fact/Evidence
9445,7-738,7-738_v2_17@10,7-738_v1_15@10,These dictated the urgency of getting a chest CTA.,This dictated the urgency of getting a chest CTA.,"Modify,Grammar",Grammar
9446,7-75,7-75_v2_8@1,,The native format for WikiPathways is Graphical Pathway Markup Language (GPML) based on the eXtensible Markup Language (XML) standard.,,"Add,Fact/Evidence",Fact/Evidence
9447,7-75,7-75_v2_8@2,,The RDF export is transformed from the original GPML.,,"Add,Fact/Evidence",Fact/Evidence
9448,7-75,7-75_v2_8@3,,"In the RDF representation we use two distinct controlled vocabularies, to distinguish between the graphical notation of a pathway and the biological meanings expressed in the pathway.",,"Add,Fact/Evidence",Fact/Evidence
9449,7-75,7-75_v2_8@4,,This is done to allow integration with other pathway repositories which use other graphical notations or none.,,"Add,Fact/Evidence",Fact/Evidence
9450,7-75,7-75_v2_11@3,,"If a direction is not specified in the call, all the adjacent interactions will be retrieved regardless of their direction.",,"Add,Fact/Evidence",Fact/Evidence
9451,7-75,7-75_v2_11@5,,Vocabularies.wikipathways.org also identifies catalysis and binding events as well as a more generic directedInteraction in the case where the type of the interaction is not identified.,,"Add,Fact/Evidence",Fact/Evidence
9452,7-75,7-75_v2_14@0,,"To ensure multiple URI schemes can be used to identify genes, proteins, and metabolites, the Open PHACTS platform uses an Identifier Mapping Service (IMS) <REF-6> .",,"Add,Fact/Evidence",Fact/Evidence
9453,7-75,7-75_v2_14@1,,"This ensures that people can use Ensembl, NCBI Gene, and others for genes, UniProt, Ensembl, etc. for proteins, and HMDB, ChEBI, CAS registry number, and PubChem for metabolites.",,"Add,Claim",Claim
9454,7-75,7-75_v2_14@2,,"Furthermore, it supports identifiers.org formatted URIs, further simplifying entering identifiers <REF-13> .",,"Add,Fact/Evidence",Fact/Evidence
9455,7-75,7-75_v2_17@6,,An example result for this query can be found in Supplementary Figure 1 .,,"Add,Fact/Evidence",Fact/Evidence
9456,7-75,7-75_v2_24@3,,An example result for this query can be seen in Supplementary Figure 2 .,,"Add,Fact/Evidence",Fact/Evidence
9457,7-75,7-75_v2_27@0,,Example workflows,,"Add,Other",Other
9458,7-75,7-75_v2_28@0,,"In order to demonstrate the basic use of the introduced API methods, we developed two workflows, available in the Supplementary Material .",,"Add,Fact/Evidence",Fact/Evidence
9459,7-75,7-75_v2_28@1,,One uses Python to return a file with the results in a table and the other uses a HTML webpage using the ops.js JavaScript client library <REF-17> .,,"Add,Fact/Evidence",Fact/Evidence
9460,7-75,7-75_v2_28@2,,"More involved workflows have been developed for KNIME and Pipeline Pilot <REF-18> , <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
9461,7-75,7-75_v2_29@0,,"The Python script example uses the Open PHACTS /pathway/getInteraction API call and prompts the user to enter a WikiPathways pathway number that they wish to query, such as 1544 for WikiPathways pathway WP1544.",,"Add,Fact/Evidence",Fact/Evidence
9462,7-75,7-75_v2_29@1,,Invocation of the API call with the pathway identifier returns information about the directed interactions that are involved with the pathway.,,"Add,Fact/Evidence",Fact/Evidence
9463,7-75,7-75_v2_29@2,,"The information that is returned is the interaction ID used by WikiPathways, the interaction type, and URIs for the source and target of the interaction.",,"Add,Fact/Evidence",Fact/Evidence
9464,7-75,7-75_v2_29@3,,"In order to convert the URIs into something more readable, a SPARQL query is then executed to get labels, from the WikiPathways SPARQL endpoint, for the source and target of the interaction.",,"Add,Fact/Evidence",Fact/Evidence
9465,7-75,7-75_v2_29@4,,"The results are written to a file with the interaction ID, interaction type, URIs for the source and target, as well as alias IDs, the curl for the API call, the pathway ID used, and a number of interactions returned.",,"Add,Fact/Evidence",Fact/Evidence
9466,7-75,7-75_v2_30@0,,"The second example uses a HTML5 webpage and the ops.js JavaScript client library to retrieve interactions for a particular gene, using the URI for the gene’s Ensembl identifier and the /pathways/interactions/byEntity API method.",,"Add,Fact/Evidence",Fact/Evidence
9467,7-75,7-75_v2_30@1,,"The ops.js library passes the returned JSON with interaction information to a callback function, where the interacting source and target are extracted and the interacting entity determined.",,"Add,Fact/Evidence",Fact/Evidence
9468,7-75,7-75_v2_30@2,,"For each interacting entity, which may be a protein, RNA, or small compound, a call to the /pathways/interactions/byEntity/count method is made to return the number of interaction that entity has.",,"Add,Fact/Evidence",Fact/Evidence
9469,7-75,7-75_v2_32@0,,"While the calls identified here are simple calls, workflow tools make it possible to take advantage of the integrative nature of the OPDP to make API calls in succession.",,"Add,Claim",Claim
9470,7-75,7-75_v2_32@1,,Two such workflow tools that work with the OPDP are KNIME and Pipeline Pilot.,,"Add,Claim",Claim
9471,7-75,7-75_v2_32@2,,"With these tools, it is possible to perform a directional query of a target and identify alternative targets that can then be queried against the chemistry calls to identify active compounds for these alternative targets.",,"Add,Claim",Claim
9472,7-75,7-75_v2_32@3,,"The client libraries ops.js, ops4j, and ropenphacts also support Open PHACTS and the interaction calls for pathways.",,"Add,Claim",Claim
9473,7-75,7-75_v2_32@4,,"This allows users to perform API calls to the OPDP using their preferred language or platform, such as JavaScript, Java, or R.",,"Add,Claim",Claim
9474,7-75,7-75_v2_5@4,7-75_v1_5@4,"Up- or downstream targets may be interesting alternatives with similar therapeutic effect to targets, for which it is particularly hard to develop a drug agent.","Up- or downstream targets may be interesting alternatives with similar therapeutic effect to targets, for which it is particularly hard to develop an drug agent.","Modify,Grammar",Grammar
9475,7-75,7-75_v2_8@5,7-75_v1_8@1,The WikiPathways RDF also includes details about directed and undirected interactions.,It includes details about directed and undirected interactions.,"Modify,Clarity",Clarity
9476,7-75,7-75_v2_9@0,7-75_v1_9@0,The WikiPathways basic drawing tools also contain generic arrows and T-bar annotations that give the user the ability to create basic diagrams without the semantic meaning of MIM or SBGN notations.,The WikiPathways basic drawing tools also contain generic arrows and t-bar annotations that give the user the ability to create basic diagrams without the semantic meaning of MIM or SBGN notations.,"Modify,Grammar",Grammar
9477,7-75,7-75_v2_13@2,7-75_v1_13@2,"As in previous versions, the API uses HTTP GET to call methods and needs a (free) application ID and key (see https://dev.openphacts.org/signup ) <REF-3> .","As in previous versions, the API uses HTTP GET to call methods and needs a (free) application ID and key <REF-3> .","Modify,Fact/Evidence",Fact/Evidence
9478,7-75,7-75_v2_16@4,7-75_v1_15@4,The AKT protein has a central role and usefully shows the API call’s ability to return connected elements with the /pathways/interactions/byEntity and the /pathway/getInteractions calls.,The AKT protein has a central role and usefully shows the API call’s ability to return connected elements with the first and third calls.,"Modify,Clarity",Clarity
9479,7-75,7-75_v2_16@5,7-75_v1_15@5,"The API calls can help aid drug discovery by taking a target, in this case AKT, and easily identify other connected proteins that could potentially be used as drug targets with a common downstream effect.","The API call can help aid drug discovery by taking a target, in this case AKT, and easily identify other connected proteins that could potentially be used as drug targets with a common downstream effect.","Modify,Grammar",Grammar
9480,7-906,7-906_v2_52@0,,"In Berg-Nielsen ’ s review, mothers with depression andanxiety, as well as parents with certain personality disorders, have a parental style often characterized by some aspect of negativity <REF-20> .",,"Add,Fact/Evidence",Fact/Evidence
9481,7-906,7-906_v2_52@1,,"In a systematic review by Christian, 2017, depression and anxiety were noted as a direct link to difficulties in the parent-child relationship and poor parent-child interactions <REF-18> .",,"Add,Fact/Evidence",Fact/Evidence
9482,7-906,7-906_v2_52@2,,"In a meta analytic review by van der Bruggen et al ., 2008, direction association between child anxiety, and parental control was unknown <REF-22> .",,"Add,Fact/Evidence",Fact/Evidence
9483,7-906,7-906_v2_53@1,,When clients through the therapeutic process build skills that lead to successes in their parenting relationships they gain the confidence needed to keep improving the parent-child relationship <REF-18> .,,"Add,Fact/Evidence",Fact/Evidence
9484,7-906,7-906_v2_54@2,,"In line with our study, in the Erel and Burman, 1995 meta-analytic review, there was a positive relationship between the quality of the marital relationship and the quality of the parent-child relationship <REF-68> .",,"Add,Fact/Evidence",Fact/Evidence
9485,7-906,7-906_v2_54@3,,Parents with a satisfying marital relationship may receive more support from their spouse; the positive feeling from a satisfying marital relationship may spill over to a parent-child relationship <REF-25> .,,"Add,Fact/Evidence",Fact/Evidence
9486,7-906,7-906_v2_55@0,,"In line with Berg-Nielsen’s review <REF-20> , our study association between maternal drug use and dysfunctional parenting was reported.",,"Add,Fact/Evidence",Fact/Evidence
9487,7-906,7-906_v2_56@0,,"In Berg- Nielsen’s review, anxiety in children has been correlated with parental negative control, rejection, and inconsistency.",,"Add,Fact/Evidence",Fact/Evidence
9488,7-906,7-906_v2_56@1,,"And parents of depressed children may be less warm and supportive, less communicative, and more critical <REF-20> .",,"Add,Fact/Evidence",Fact/Evidence
9489,7-906,7-906_v2_57@0,,"In conclusion, the review showed that some child or parental psychopathologic factors contribute to dysfunctional parenting.",,"Add,Fact/Evidence",Fact/Evidence
9490,7-906,7-906_v2_60@0,,Implication of findings,,"Add,Other",Other
9491,7-906,7-906_v2_61@0,,"Consultants, psychologists, and therapists can use the findings of this study to provide services to families.",,"Add,Claim",Claim
9492,7-906,,7-906_v1_7@0,,Parenting styles refer to the set of strategies adopted by parents to control the behaviors of their children <REF-1> .,"Delete,Fact/Evidence",Fact/Evidence
9493,7-906,,7-906_v1_51@1,,These characteristics are created in the process of parents’ growth and development <REF-8> .,"Delete,Fact/Evidence",Fact/Evidence
9494,7-906,,7-906_v1_55@0,,"In conclusion, considering these multiple psychological factors influencing parenting styles, we recommended including parent-child psychological status assessment in family health programs in order to identify the needs for health-oriented care and take steps towards the development of parenting skills among parents.","Delete,Claim",Claim
9495,7-906,7-906_v2_7@0,,"Parenting styles consist of a constellation of parental behaviors, beliefs, and attitudes displayed across a variety of parent-child interactions and so specific parenting behaviors that parents use to socialize their child <REF-1> .",,"Add,Fact/Evidence",Fact/Evidence
9496,7-906,7-906_v2_7@1,,Baumrind (1971) develop a popular theory of parenting styles in which she identified three different parenting styles are mostly used in literature.,,"Add,Fact/Evidence",Fact/Evidence
9497,7-906,7-906_v2_7@2,,"Later, (in the 1980s) a fourth was added to her theory <REF-2> – <REF-5> .",,"Add,Fact/Evidence",Fact/Evidence
9498,7-906,7-906_v2_7@4,,"Authoritative parents are warm and communicative, but they also exert appropriate control.",,"Add,Fact/Evidence",Fact/Evidence
9499,7-906,7-906_v2_7@5,,"Authoritarian parents exert control while lacking warmth, while permissive parents show warmth but do not exert control).",,"Add,Fact/Evidence",Fact/Evidence
9500,7-906,7-906_v2_7@6,,"Finally, parents with lacking warmth and control have neglectful parenting.",,"Add,Fact/Evidence",Fact/Evidence
9501,7-906,7-906_v2_7@7,,Some researchers define parenting styles as specific interpersonal parental behaviors or characteristics that influence child development.,,"Add,Fact/Evidence",Fact/Evidence
9502,7-906,7-906_v2_7@8,,"For example, sensitivity, responsiveness, affect, reciprocity, negativity, involvement, harsh discipline <REF-6> , <REF-7> .",,"Add,Fact/Evidence",Fact/Evidence
9503,7-906,7-906_v2_7@9,,"In the present study, parental behaviors or characteristics were used as models of parenting styles <REF-8> .",,"Add,Fact/Evidence",Fact/Evidence
9504,7-906,7-906_v2_7@13,,Clarifying these factors is important for family therapeutic intervention.,,"Add,Claim",Claim
9505,7-906,7-906_v2_26@2,7-906_v1_26@2,This checklist includes 8 questions for case-control studies and cohort studies with a maximum 9 score.,This checklist includes 8 questions for case control studies and cohort studies with maximum 9 score.,"Modify,Grammar",Grammar
9506,7-906,7-906_v2_26@7,7-906_v1_26@7,"In this review, studies that received ≥ 5 scores from the Newcastle–Ottawa scale and The HE QAT were included <REF-30> , <REF-33> .","In this review, studies that received ≥ 5 score from Newcastle–Ottawa scale and The HE QAT were included <REF-20> , <REF-23> .","Modify,Grammar",Grammar
9507,7-906,7-906_v2_31@0,7-906_v1_31@0,A summary of the included studies is presented in Table 1 .,A summary of included studies are presented in Table 1 .,"Modify,Grammar",Grammar
9508,7-906,7-906_v2_33@6,7-906_v1_33@6,"These parents may have low self-esteem, reduced self-efficacy, negative emotions, more anger, and distress, as well as negative worthlessness to themselves or negative attitudes towards their parenting abilities <REF-17> , <REF-35> , <REF-36> , which have an impact on the trust between parents and children <REF-18> , <REF-37> , <REF-38> .","These parents may have low self-esteem, reduced self-efficacy, negative emotions, more anger and distress, as well as negative worthlessness to themselves or negative attitudes towards their parenting abilities <REF-11> , <REF-26> , <REF-27> , which have an impact on the trust between parents and children <REF-12> , <REF-28> , <REF-29> .","Modify,Grammar",Grammar
9509,7-906,7-906_v2_33@9,7-906_v1_33@9,"Such parents may use harassment of their children as the first choice of parenting <REF-18> , or parents’ interactions with children and their parenting may be accompanied by excessive control and rejection <REF-39> , <REF-40> .","Such parents may use harassment of their children as a first choice of parenting <REF-12> , or parents’ interactions with children and their parenting may be accompanied by excessive control and rejection <REF-30> , <REF-31> .","Modify,Grammar",Grammar
9510,7-906,7-906_v2_42@5,7-906_v1_37@5,"Moreover, these parents may show their love for their children when children act in accordance with parents expectations.","Moreover, these parents may show their love to their children when children act in accordance with parents expectations.","Modify,Grammar",Grammar
9511,7-906,7-906_v2_2@2,7-906_v1_2@2,The purpose of this systematic review was to examine psychological factors affecting parenting style.,"Thus, the purpose of this systematic review was to examine psychological factors affecting parenting style.","Modify,Clarity",Clarity
9512,7-906,7-906_v2_43@2,7-906_v1_43@2,"As a result of emotional security, behavioral independence and social competence created in them can lead to the formation of a healthy personality and personal maturity and these people can rely more on others.","As the result of emotional security, behavioral independence and social competence created in them can lead to the formation of a healthy personality and personal maturity and these people can rely more on others.","Modify,Grammar",Grammar
9513,7-906,7-906_v2_44@3,7-906_v1_44@3,"Marital problems, as well as psychological disorders of substance-abusing individuals, are related to poor parenting <REF-20> .",Marital problems as well as psychological disorders of substance-abusing individuals are related to poor parenting <REF-14> .,"Modify,Grammar",Grammar
9514,7-906,7-906_v2_50@2,7-906_v1_50@2,"Consequently, increased self-efficacy and reduced parenting stress, as well as lower depression and anxiety in parents, could lead to the adoption of more appropriate strategies <REF-18> , <REF-23> , <REF-25> , <REF-35> .","Consequently, increased self-efficacy and reduced parenting stress as well as lower depression and anxiety in parents could lead to the adoption of more appropriate strategies <REF-12> , <REF-24> , <REF-26> , <REF-34> .","Modify,Grammar",Grammar
9515,7-906,7-906_v2_50@3,7-906_v1_50@3,"Moreover, dimensions of perfectionism in parents and parental personality traits could affect parenting styles <REF-7> , <REF-45> , <REF-47> .","Moreover, dimensions of perfectionism in parents and parental personality traits could effect parenting styles <REF-37> , <REF-39> , <REF-40> .","Modify,Grammar",Grammar
9516,7-906,7-906_v2_50@4,7-906_v1_50@4,"The range of parents’ psychological disturbances such as depression and anxiety could also affect parental dysfunction, leading to child maltreatment; and consequently, parents’ psychopathology could increase the likelihood of inappropriate and ineffective parenting <REF-20> , <REF-23> .","The range of parents’ psychological disturbances such as depression and anxiety could also affect parental dysfunction, leading to child maltreatment; and consequently parents’ psychopathology could increase the likelihood of inappropriate and ineffective parenting <REF-14> , <REF-24> .","Modify,Grammar",Grammar
9517,7-906,7-906_v2_59@2,7-906_v1_57@2,"Despite these limitations, it seems the result of this study can be used in the development and implementation of family health intervention programs.",Despite these limitations it seems the result of this study can be used in the development and implementation of family health intervention programs.,"Modify,Grammar",Grammar
9518,7-906,7-906_v2_59@3,7-906_v1_57@3,"Also, clinicians, psychologists, psychiatrists, and counselors may consider the psychological factors affecting parenting styles reported in this review for further interventions; the assessment of parent-child mental health status, as well as positive parenting education and in this way help with positive parent-child interactions.","Also clinicians, psychologists, psychiatrists, and counselors may consider the psychological factors affecting parenting styles reported in this review for further interventions; the assessment of parent-child mental health status, as well as positive parenting education and in this way help with positive parent-child interactions.","Modify,Grammar",Grammar
9519,7-906,7-906_v2_22@1,7-906_v1_22@1,A third author (FE) reviewed the evidence tables for accuracy and completeness.,Third author (FE) reviewed the evidence tables for accuracy and completeness.,"Modify,Grammar",Grammar
9520,7-906,7-906_v2_22@4,7-906_v1_22@4,The results of the literature review led to the categorization of the contents on psychological factors contributing to parenting styles into several categories as presented in the Results section.,The results of the literature review led to categorization of the contents on psychological factors contributing to parenting styles into several categories as presented in the Results section.,"Modify,Grammar",Grammar
9521,7-993,7-993_v2_5@3,,"An additional future direction of this work is to use the list of 3,228 polyphenolic compounds identified in this work to enhance the on-going polyphenol-protein interactome studies.",,"Add,Claim",Claim
9522,7-993,7-993_v2_11@2,,"The GRAS and DrugBank sets used in this work also have been used as reference in other comparative studies ( Medina-Franco et al ., 2012 ).",,"Add,Fact/Evidence",Fact/Evidence
9523,7-993,7-993_v2_11@3,,The random set from ZINC was employed just as reference and other random sets from ZINC could be used.,,"Add,Fact/Evidence",Fact/Evidence
9524,7-993,7-993_v2_30@4,,The comparable physicochemical properties between compounds from FooDB and DrugBank encourages additional systematic investigations for bioactivity of food components.,,"Add,Claim",Claim
9525,7-993,7-993_v2_30@5,,"Of course, during this search one needs to consider that compounds with similar properties may have different activity profile.",,"Add,Claim",Claim
9526,7-993,7-993_v2_36@4,,"In a follow-up work, it will be interesting to explore the type of functional groups commonly present in the acyclic structures of FooDB.",,"Add,Claim",Claim
9527,7-993,7-993_v2_42@6,,"The large list of polyphenols identified from FooDB is larger than the list of 1,395 polyphenols identified and used in the recent work of Lacroix et al . ( Lacroix et al ., 2018 ) that was retrieved from Phenol-Explorer and the Dictionary of Natural Products.",,"Add,Fact/Evidence",Fact/Evidence
9528,7-993,7-993_v2_42@7,,"Indeed, the list of 3,228 polyphenolic compound made available in this work can be used to augment the already extensive polyphenol-protein interactome work of Lacroix et al . ( Lacroix et al ., 2018 ).",,"Add,Claim",Claim
9529,7-993,7-993_v2_50@15,,"Virtual screening can be done using multiple methods, for instance, using similarity searching.",,"Add,Claim",Claim
9530,7-993,7-993_v2_50@16,,"In this case one needs to consider, however, the potential presence of activity cliffs i.e., compounds with similar structure but different activity ( Stumpfe et al ., 2014 ).",,"Add,Fact/Evidence",Fact/Evidence
9531,7-993,7-993_v2_26@2,7-993_v1_26@2,"As shown in Figure 1a , the coverage of chemical space of FooDB is quite large as compared to other datasets.","As shown in Figure 1a , the coverage of chemical space of FoodDB is quite large as compared to other datasets.","Modify,Clarity",Clarity
9532,7-993,7-993_v2_42@1,7-993_v1_42@1,"In this work it was found that 3,228 (13.5%) compounds in FooDB are polyphenolic.","In this work it was found that 3,228 (13.5%) compounds in FoodDB are polyphenolic.","Modify,Clarity",Clarity
9533,7-993,7-993_v2_50@4,7-993_v1_50@4,Compounds in FooDB have a large diversity of physicochemical properties.,Compounds in FoodDB have a large diversity of physicochemical properties.,"Modify,Clarity",Clarity
9534,7-993,7-993_v2_50@5,7-993_v1_50@5,The distributions of most physicochemical properties of FooDB compounds overlap with those of approved drugs and natural products in ZINC.,The distributions of most physicochemical properties of FoodDB compounds overlap with those of approved drugs and natural products in ZINC.,"Modify,Clarity",Clarity
9535,7-993,7-993_v2_50@8,7-993_v1_50@8,One third of the compounds in FooDB are acyclic.,One third of the compounds in FoodDB are acyclic.,"Modify,Clarity",Clarity
9536,7-993,7-993_v2_50@10,7-993_v1_50@10,"Of note, polyphenols represent a large fraction of FooDB.","Of note, polyphenols represent a large fraction of FoodDB.","Modify,Clarity",Clarity
9537,7-993,7-993_v2_15@3,7-993_v1_15@3,"This approach exploits the ‘chemical satellites’ concept ( Oprea & Gottfries, 2001 ), i.e., molecules whose similarity to the rest of the molecules in the database yield sufficient information for generating a visualization of the chemical space.","This approach exploits the 'chemical satellites' concept ( Oprea & Gottfries, 2001 ), i.e., molecules whose similarity to the rest of the molecules in the database yield sufficient information for generating a visualization of the chemical space.","Modify,Grammar",Grammar
9538,7-993,7-993_v2_3@2,7-993_v1_3@2,The global diversity of FooDB was characterized using Consensus Diversity Plots.,The global diversity of FoodDB was characterized using Consensus Diversity Plots.,"Modify,Clarity",Clarity
9539,8-1027,8-1027_v2_57@0,,"Yet, there are notable strengths to using a semi-structured interview like the CAPE 1.1 for CU traits.",,"Add,Claim",Claim
9540,8-1027,8-1027_v2_57@1,,"For one, it is commonly observed in parent training programs that over the course of managing child behaviour problems, parents tend to become frustrated and may make global, dispositional, and sweeping attributions of their child’s challenging behaviour <REF-55> .",,"Add,Fact/Evidence",Fact/Evidence
9541,8-1027,8-1027_v2_57@3,,"Since parental ratings are often used in clinical interviews and assessments, it may be that their ratings of callous-unemotional traits are contaminated by dispositional attributions that arise out of their need to explain their child’s externalizing behaviour.",,"Add,Claim",Claim
9542,8-1027,8-1027_v2_57@4,,"However <REF-55> , Sawrikar et al. showed that dispositional ratings relate uniquely to parental feelings in comparison to CU traits, so these are separable.",,"Add,Fact/Evidence",Fact/Evidence
9543,8-1027,8-1027_v2_57@5,,"When conducting the assessment with the CAPE, parents are asked to describe the different contexts in which children may have shown cruelty or callousness.",,"Add,Claim",Claim
9544,8-1027,8-1027_v2_57@6,,"These types of follow-up questions test the when, where, and with whom, hopefully eliminating the ‘halo effect’ or the ‘horn effect’ where negative behaviour stains a child as ‘naughty’.",,"Add,Claim",Claim
9545,8-1027,8-1027_v2_57@7,,"They also divulge the contextual nature of behaving callously sometimes, which is patently different from a stable and consistent presentation of limited prosocial emotion.",,"Add,Claim",Claim
9546,8-1027,8-1027_v2_57@8,,"Additionally, clinicians are able to use their knowledge of typical development to query if the behaviour is part of maturational processes.",,"Add,Claim",Claim
9547,8-1027,,8-1027_v1_17@1,,Children’s ages ranged between 3 and 19 years of age (M=12.2; SD=4.3).,"Delete,Fact/Evidence",Fact/Evidence
9548,8-1027,,8-1027_v1_24@6,,"The first author is trained in psychometric assessments within clinical settings and has completed a PhD that involved carrying out psychoeducational and mental health assessments within a community clinic, special education provision, and juvenile justice services under the supervision of a licensed clinical psychologist in the USA.","Delete,Fact/Evidence",Fact/Evidence
9549,8-1027,,8-1027_v1_24@7,,"The fourth author is a trained psychotherapeutic counsellor accredited and registered with UK Council for Psychotherapists as a therapist and counsellor, with a clinical psychology master’s degree and experience working as a psychotherapist in a prison in the USA as well as subsequent independent clinic work in the northeast of England.","Delete,Fact/Evidence",Fact/Evidence
9550,8-1027,,8-1027_v1_30@1,,The package ggcorrplot 0.1.2 <REF-45> in R 1.1.453 <REF-46> software was used for correlation analyses.,"Delete,Fact/Evidence",Fact/Evidence
9551,8-1027,,8-1027_v1_32@0,,Do target children differ in symptoms from their non-target counterparts?,"Delete,Other",Other
9552,8-1027,,8-1027_v1_33@0,,"We first tested whether target children for the intervention scored higher on emotional and behaviour problems, as well as CU and psychopathic traits.","Delete,Fact/Evidence",Fact/Evidence
9553,8-1027,,8-1027_v1_33@1,,The mean scores and standard deviations are shown in Figure 1 (see underlying data <REF-47> ).,"Delete,Fact/Evidence",Fact/Evidence
9554,8-1027,,8-1027_v1_33@2,,Welch t-tests are reported because of violations of normality assumptions.,"Delete,Fact/Evidence",Fact/Evidence
9555,8-1027,,8-1027_v1_33@4,,"Target children were higher than non-target children in UNSW CU traits according to both parents and children themselves ( t (65.50)= -2.38, p = 0.020 , d = -0.54; t (38.83)= -2.61, p = 0.013 , d = -0.80) as well as parent-reported externalizing behaviour ( t (68.30)= -2.33, p = 0.023 , d = -0.53) and they showed more of an adverse impact on their daily living activities from their symptoms based on the SDQ ( t (53.19)= -4.11, p = < 0.001 , d = -0.96).","Delete,Fact/Evidence",Fact/Evidence
9556,8-1027,,8-1027_v1_33@5,,"Thus, target children were similar to their non-target siblings in symptoms of internalizing behaviour problems, regardless of reporter, but were higher on psychopathic traits, CU traits and the impact of their problems on their activities of daily living.","Delete,Claim",Claim
9557,8-1027,,8-1027_v1_44@1,,An ‘x’ placed across the correlation in the figure denotes that the result is non-significant.,"Delete,Fact/Evidence",Fact/Evidence
9558,8-1027,8-1027_v2_12@5,,"Also, at least one child of the targeted families had been identified by teachers as exhibiting symptoms linked to conduct problems.",,"Add,Fact/Evidence",Fact/Evidence
9559,8-1027,8-1027_v2_19@1,,"Therefore, the total sample of children (N=84), consisted of 34 target children and 50 non-target children.",,"Add,Fact/Evidence",Fact/Evidence
9560,8-1027,8-1027_v2_19@2,,See Figure 1 for a flow chart of the selected families and siblings.,,"Add,Fact/Evidence",Fact/Evidence
9561,8-1027,8-1027_v2_19@3,,"Only data from the target child will be presented, since they are the only ones who had a completed CAPE.",,"Add,Fact/Evidence",Fact/Evidence
9562,8-1027,8-1027_v2_23@5,,These were unsuitable because either the caseworkers were themselves afraid of violence or the families were already non-compliant with the caseworkers efforts at intervention.,,"Add,Claim",Claim
9563,8-1027,8-1027_v2_26@3,,The other child with ASD was capable of being interviewed.,,"Add,Fact/Evidence",Fact/Evidence
9564,8-1027,8-1027_v2_26@4,,"We decided to do assessments using the CAPE regardless of ASD, because research shows that some children have a ‘double hit’ of ASD and callous-unemotional traits <REF-34> and the modest phenotypic overlap observed in social-emotional deficits is largely explained by shared genetic variance <REF-35> .",,"Add,Fact/Evidence",Fact/Evidence
9565,8-1027,8-1027_v2_26@8,,The manual specifies that raters use their developmental psychology training to ensure that symptoms are rated with regard to what is typical behaviour for a child based on their age.,,"Add,Fact/Evidence",Fact/Evidence
9566,8-1027,8-1027_v2_26@9,,Both raters had sufficient training in developmental psychology and in the assessment of callous-unemotional traits in children as young as 2–3 years of age <REF-36> .,,"Add,Fact/Evidence",Fact/Evidence
9567,8-1027,8-1027_v2_46@5,,The relatively small confidence intervals show the reliability of the estimation procedure used here have value.,,"Add,Fact/Evidence",Fact/Evidence
9568,8-1027,8-1027_v2_46@7,,The externalizing results are notable because the confidence intervals were large.,,"Add,Fact/Evidence",Fact/Evidence
9569,8-1027,8-1027_v2_46@8,,"Thus, power may be too low in the present study to yield reliable estimates of the true parameters.",,"Add,Claim",Claim
9570,8-1027,8-1027_v2_46@11,,The large confidence intervals are a sign that repeated samples are needed in future investigations.,,"Add,Claim",Claim
9571,8-1027,8-1027_v2_52@6,,"Thus, while the CAPE 1.1 may show prospective effects on delinquent behaviour or risky decision making within highly antisocial samples, this may not be apparent in cross-section research when the sample was selected for problem behaviour <REF-52> , <REF-53> .",,"Add,Claim",Claim
9572,8-1027,8-1027_v2_12@4,8-1027_v1_12@4,"The schemes target families in which parents experience unemployment, their children fail to attend school, and where family members are involved (or at risk of being involved) in drug use and/or other criminal activity.","The scheme targets families in which parents experience unemployment, their children fail to attend school, and where family members are involved (or at risk of being involved) in drug use and/or other criminal activity.","Modify,Grammar",Grammar
9573,8-1027,8-1027_v2_12@7,8-1027_v1_12@6,We examined the relations among the CAPE 1.1 item scores and criterion-related measures with well-validated questionnaires of CU traits and psychopathic traits in a sample of families in the Troubled Families Scheme.,"In the current study, we examined the relations among the CAPE 1.1 item scores and criterion-related measures with well-validated questionnaires of CU traits and psychopathic traits in a sample of families in the Troubled Families Scheme.","Modify,Clarity",Clarity
9574,8-1027,8-1027_v2_15@4,8-1027_v1_15@4,No exclusion criteria were employed.,No other exclusion criteria were necessary.,"Modify,Clarity",Clarity
9575,8-1027,8-1027_v2_17@0,8-1027_v1_17@0,Participants were families who were registered as one of two government schemes in the North East of England.,Participants were families who were registered as part of the Troubled Families government scheme from the North East of England.,"Modify,Fact/Evidence",Fact/Evidence
9577,8-1027,8-1027_v2_17@2,8-1027_v1_17@2,"As result, no a priori power analysis was conducted to inform sample size.","A total of 34 families took part, which were based on availability and no sample size calculation was performed.","Split+Modify,Fact/Evidence",Fact/Evidence
9578,8-1027,8-1027_v2_17@7,8-1027_v1_17@7,"In one case the mother and father of the child completed the questionnaires and interview together and, in another case, these were completed by an older sister who was the legal guardian.",In one case the mother and father of the child completed the questionnaires and interview together and in another case these were completed by an older sister who was the legal guardian.,"Modify,Grammar",Grammar
9579,8-1027,8-1027_v2_18@1,8-1027_v1_18@1,"With regard to gender, 24 (69%) of the 35 target children (one family had two target children) were male, while 25 out of 50 (50%) of the non-targets were male.","With regards to gender, 24 (69%) of the 35 target children (one family had two target children) were male, while 25 out of 50 (50%) of the non-targets were male.","Modify,Grammar",Grammar
9580,8-1027,8-1027_v2_19@0,8-1027_v1_19@0,One of the target children was selected at random from the family that had two target children (and who were twins).,One of the target children was selected at random from the family that had two target children.,"Modify,Fact/Evidence",Fact/Evidence
9581,8-1027,8-1027_v2_23@0,8-1027_v1_21@0,Families already targeted by the Troubled Families scheme or Family Intervention Programme were contacted by the Stockton Community Safety Team to be invited to take part in this study.,Families already targeted by the Troubled Families scheme were contacted by the Stockton Community Safety Team to be invited to take part in this study.,"Modify,Fact/Evidence",Fact/Evidence
9582,8-1027,8-1027_v2_23@1,8-1027_v1_21@1,They were told that participation was voluntary and that their decision would not affect involvement in the respective scheme.,They were told that participation was voluntary and that their decision would not affect involvement in the ‘Troubled Families’ scheme.,"Modify,Clarity",Clarity
9583,8-1027,8-1027_v2_26@2,8-1027_v1_24@2,"For two children below the age of 7 years and for a child with a diagnosis of Autism Spectrum Disorder (ASD; and who had severe symptoms), only the parent interview was conducted.","For two children below the age of 7 and for a child with a diagnosis of Autism Spectrum Disorder, only the parent interview was conducted.","Modify,Fact/Evidence",Fact/Evidence
9584,8-1027,8-1027_v2_30@1,8-1027_v1_28@1,"A dichotomous measure (1=present, 0=not present) was created from the risk assessment for violence that caseworkers assessed as part of their work with the families; a risk assessment of ‘present,’ meant that violence was of concern to caseworkers and they had actions in place to minimize harm to themselves or others.","A dichotomous measure (1=present, 0=not present) was created from the risk assessment for violence that caseworkers assessed as part of their work with the families.","Modify,Fact/Evidence",Fact/Evidence
9585,8-1027,8-1027_v2_32@0,8-1027_v1_30@0,"JASP 0.9.1.0 <REF-47> was used for t-tests, correlations, descriptive statistics, and chi-square analyses.","JASP 0.9.1.0 <REF-44> was used for t-tests, descriptive statistics, and chi-square analyses.","Modify,Fact/Evidence",Fact/Evidence
9586,8-1027,8-1027_v2_42@0,8-1027_v1_44@0,Table 1 notes the results of Spearman’s correlations examining the associations of the validation measures (questionnaires and case file records) with CAPE 1.1 ratings (number of symptoms rated 2).,Figure 4 notes the results of Spearman’s correlations examining the associations of the validation measures (questionnaires and case file records) with CAPE 1.1 ratings (number of symptoms rated 2).,"Modify,Fact/Evidence",Fact/Evidence
9587,8-1027,8-1027_v2_42@1,8-1027_v1_44@2,Spearman’s rho was used because of the non-parametric nature of many of the measures used.,Spearman’s rho was used because of the non-parametric nature of many of the measures utilized.,"Modify,Clarity",Clarity
9588,8-1027,8-1027_v2_42@3,8-1027_v1_44@4,There were no associations found between the CAPE 1.1 and externalizing/internalizing behaviour regardless of reporter.,"There were no associations found between the CAPE 1.1 and externalizing/internalizing behaviour regardless of reporter, although the relation with externalizing behaviour (as reported by the parent) was moderate.","Modify,Fact/Evidence",Fact/Evidence
9589,8-1027,8-1027_v2_46@3,8-1027_v1_48@2,"Levene’s test of equality of variance was nonsignificant except for child reported internalizing behaviour, so we used Student’s t-tests except in that case.","Levene’s test of equality of variance was nonsignificant except for child reported internalizing behaviour, so we used Student t-tests except in that case.","Modify,Grammar",Grammar
9590,8-1027,8-1027_v2_51@0,8-1027_v1_53@0,"Since the CAPE 1.1 and UNSW CU traits measure are both derived from the ASPD and are therefore based on the same historical items, it is possible that they may use similarly worded items.","As the CAPE 1.1 and UNSW CU traits measure are both derived from the ASPD and are therefore based on the same historical items, it is possible that they may use similarly worded items.","Modify,Clarity",Clarity
9591,8-1027,8-1027_v2_52@2,8-1027_v1_54@2,"However, this group did not differ on the other measures of externalizing behaviour or risk for violence, which is similar to recent research that found the CAPE did not necessarily distinguish different offenders <REF-52> .","However, this group did not differ on the other measures of externalizing behaviour or risk for violence.","Modify,Fact/Evidence",Fact/Evidence
9592,8-1027,8-1027_v2_52@4,8-1027_v1_54@4,"First, in the present study, the cut-off led to only 7 children in the sample meeting the diagnostic criteria, leading to very low power for detecting group differences, as evidenced by the large confidence intervals with some of the measures.","First, the cut-off led to only 7 children in the sample meeting the diagnostic criteria, leading to very low power for detecting group differences.","Modify,Claim",Claim
9593,8-1027,8-1027_v2_54@2,8-1027_v1_56@2,"Further, as interventions are developed and tested to specifically target the needs of children and adolescents with elevated CU traits <REF-54> , their success will rely on adequate assessment, especially in samples who experience social disadvantage, behaviour problems, poor school attendance, and who show behaviours that are generally difficult to assess.","Further, as interventions are developed and tested to specifically target the needs of children and adolescents with elevated CU traits <REF-52> , their success will rely on adequate assessment, especially in samples who experience social disadvantage, behaviour problems, poor school attendance, and who show behaviours that are generally difficult to access.","Modify,Grammar",Grammar
9594,8-1027,8-1027_v2_55@0,8-1027_v1_57@0,"Given that the CAPE 1.1 only leads to the rating of four items, it was somewhat surprising that they still formed a relatively internally consistent scale, which is similar to other more recent research <REF-52> .","Given that the CAPE 1.1 only leads to the rating of four items, it was somewhat surprising that they still formed a relatively internally consistent scale.","Modify,Fact/Evidence",Fact/Evidence
9595,8-1027,8-1027_v2_55@5,8-1027_v1_57@5,"However, it does point to the need to evaluate the relative utility of the symptoms, both in their sensitivity and in their specificity, used to define the LPE specifier <REF-50> .","However, it does point to the need to evaluate the relative utility of the symptoms used to define the LPE specifier <REF-50> .","Modify,Fact/Evidence",Fact/Evidence
9596,8-1027,8-1027_v2_10@6,8-1027_v1_10@6,"However, negatively worded items can be difficult to understand and put strain on a child’s verbal abilities, which have been found to be deficient in children with conduct problems <REF-31> .","However, negatively worded items can sometimes be difficult to understand and put a strain on a child’s verbal abilities, which are often found to be deficient in children with conduct problems, anyway <REF-31> .","Modify,Clarity",Clarity
9597,8-1027,8-1027_v2_12@2,8-1027_v1_12@2,"Thus, we investigated the validity of the CAPE 1.1 in a group of socially disadvantaged families that are part of the ‘Troubled Families Scheme’ and the ‘Family Intervention Programme’ - implemented by the UK government.","Thus, we investigated the validity of the CAPE 1.1 in a group of socially disadvantaged families that are part of the ‘Troubled Families Scheme’ - implemented by the UK government in 2010.","Modify,Fact/Evidence",Fact/Evidence
9598,8-1027,8-1027_v2_12@3,8-1027_v1_12@3,"Children who show serious conduct problems tend to come from high-risk backgrounds involving disorganized, highly stressed, or economically disadvantaged families <REF-33> , and the schemes provide early intervention for these behaviour problems facilitated by local county councils.","Children who show serious conduct problems tend to come from high-risk backgrounds involving disorganized, unmotivated or disadvantaged families <REF-33> , and the scheme provides early intervention for these behaviour problems facilitated by local county councils.","Modify,Fact/Evidence",Fact/Evidence
9599,8-1066,8-1066_v2_75@3,,"At EVI, decision regarding which vaccine candidates to include into the organisation’s portfolio, and which ones to move forward, are based on a rigorous selection of candidates made by the EVI Board, based on input from an independent scientific advisory committee.",,"Add,Fact/Evidence",Fact/Evidence
9600,8-1066,8-1066_v2_75@4,,"For selecting vaccine candidates and advancing their development, EVI employs a portfolio management approach that has defined gating criteria (Go/No-Go criteria), ensuring that only the best leads are fed in and candidates that do not meet the criteria set are weeded out early on, thereby balancing the number of projects supported with available resources <REF-4> .",,"Add,Fact/Evidence",Fact/Evidence
9601,8-1066,8-1066_v2_75@5,,"Results delivered by the portfolio analysis using the P2I tool, in particular the total estimated costs and expected success rates, therefore provide valuable information that informs this selection and decision-making process.",,"Add,Claim",Claim
9602,8-1066,8-1066_v2_81@2,,"Similarly, as a static model, it does not take into account the possibility that candidates may sometimes have to go “backwards” to an earlier phase.",,"Add,Fact/Evidence",Fact/Evidence
9603,8-1066,8-1066_v2_81@3,,"For example, once a candidate enters into phase I there may be bottlenecks that require that the candidate return to a preclinical evaluation stage (e.g., if different formulations need to be re-evaluated or alternate adjuvants need to be tested).",,"Add,Claim",Claim
9604,8-1066,8-1066_v2_82@1,,"Although the assumptions were based on a very large number of data points (from 25,000 development candidates) and validated with experts, it is unclear how many of these data points came from vaccine development for neglected and emerging infectious diseases.",,"Add,Claim",Claim
9605,8-1066,8-1066_v2_82@2,,"Thus there is some uncertainty as to how accurate the assumptions are for the costs, attrition rates, and cycle times per phase for the three vaccine archetypes used in our study.",,"Add,Claim",Claim
9606,8-1066,8-1066_v2_83@1,,"The exclusion of phase IV studies, also known as post-marketing surveillance, is a major limitation—determining long-term safety and effectiveness is critical, yet it can be a lengthy, expensive process.",,"Add,Claim",Claim
9607,8-1066,8-1066_v2_83@2,,"We acknowledge that using the P2I tool, which only includes advanced pre-clinical to phase III, will always lead to an under-estimate of the total costs, since the costs of early pre-clinical research and post-phase III research can both be substantial.",,"Add,Claim",Claim
9608,8-1066,8-1066_v2_83@3,,"For example, based on data from a sample of 106 NCEs, DiMasi et al. <REF-5> estimate that developing an NCE to the point of marketing approval costs $2.6 billion; this includes $1.2 billion in “time costs” (the expected returns that private investors forgo while a drug is in development) <REF-5> .",,"Add,Fact/Evidence",Fact/Evidence
9609,8-1066,8-1066_v2_83@4,,"Of this $2.6 billion, $1.1 billion is in pre-clinical development costs and $1.5 billion in clinical development costs.",,"Add,Fact/Evidence",Fact/Evidence
9610,8-1066,8-1066_v2_83@5,,Previous research has suggested that the cost of regulatory approval stage may represent up to 5.7% of the total R&D cost <REF-6> .,,"Add,Fact/Evidence",Fact/Evidence
9611,8-1066,8-1066_v2_84@0,,"By only including advanced pre-clinical to phase III, the model also provides no insight into the costs and complexity of the array of activities that need to happen after phase III for a new product to have a public health impact.",,"Add,Claim",Claim
9612,8-1066,8-1066_v2_84@1,,"The phase after phase III is often considered as a “valley of death” for product development—a product may pass successfully through phase III but then there may be no concerted, strategic plan for large-scale manufacturing or scale-up.",,"Add,Claim",Claim
9613,8-1066,8-1066_v2_84@2,,"Demand forecasting, developing a long-term business case, understanding the public health value of new products, and analysing the delivery system and scale-up approach are all critical components in determining the ultimate public health utility of a new health technology.",,"Add,Claim",Claim
9614,8-1066,8-1066_v2_84@3,,We have previously noted that the P2I model “is “agnostic” when it comes to the public health value of the estimated launches—it cannot judge their clinical utility” <REF-2> .,,"Add,Fact/Evidence",Fact/Evidence
9615,8-1066,8-1066_v2_85@0,,"Fourth, accurate classification of candidates into their archetypes can be challenging.",,"Add,Claim",Claim
9616,8-1066,8-1066_v2_85@1,,"As we previously noted, “the P2I v.2 model requires users to classify every candidate into an archetype, but categorizing candidates based on the archetype definitions was challenging—especially determining a candidate’s complexity. It will be helpful for future iterations of the model to include more fine-grained, detailed descriptions” <REF-2> .",,"Add,Fact/Evidence",Fact/Evidence
9617,8-1066,8-1066_v2_86@0,,"Fifth, the model assumes that the costs, attrition rates, and cycle times per phase for vaccine development would be the same regardless of the setting where the study is done.",,"Add,Claim",Claim
9618,8-1066,8-1066_v2_86@1,,"Yet in reality, it is likely that these parameters would be different if a study were conducted in a high-, middle-, or low-income country.",,"Add,Claim",Claim
9619,8-1066,8-1066_v2_86@2,,It would be helpful for future iterations of the P2I tool to incorporate these differences across study settings.,,"Add,Claim",Claim
9620,8-1066,8-1066_v2_87@0,,"Sixth, the model also assumes that the costs of vaccine development per phase do not vary and are predictable.",,"Add,Claim",Claim
9621,8-1066,8-1066_v2_87@1,,"Yet there can be substantial variation and unpredictability in items such as the cost of manufacturing the product candidates and adjuvants, or the maintenance and quality control of clinical trial sites.",,"Add,Claim",Claim
9622,8-1066,8-1066_v2_91@2,,"Findings from the analysis of the overall EVI vaccine portfolio using the P2I tool will be taken into consideration in the next revision of the EVI Strategic Plan, and estimations for individual vaccine candidates will inform decisions regarding whether or not to continue with the development of individual vaccine candidates once they reach major milestone or stage gating criteria.",,"Add,Claim",Claim
9623,8-1066,8-1066_v2_8@0,,"As a financial forecasting tool that estimates the funding needs for pharmaceutical product development, the tool and its outputs are of value to funders of product development, product development partnerships, and other stakeholders involved in research and development (R&D) policy.",,"Add,Claim",Claim
9624,8-1066,8-1066_v2_8@1,,"Terry and colleagues, who developed the P2I model, note that “its real utility lies in its predictive value for modelling the impact of different funding strategies at the portfolio level” <REF-1> .",,"Add,Fact/Evidence",Fact/Evidence
9625,8-1066,8-1066_v2_13@0,,"We used the P2I tool because, to the best of our knowledge, it is the first publicly available comprehensive portfolio model that includes data on cost, success rate, and cycle time per phase for various product types based on data from a very large number of previous product development candidates (over 25,000) <REF-1> .",,"Add,Claim",Claim
9626,8-1066,8-1066_v2_13@1,,"The P2I tool is thus complementary to other available tools that can help guide prioritization in vaccine development, such as the multi-stakeholder Vaccine Innovation Prioritization Strategy <REF-1> and Total Systems Effectiveness Framework 2 .",,"Add,Fact/Evidence",Fact/Evidence
9627,8-1066,8-1066_v2_15@0,,"In this section, we begin by summarizing how the Microsoft Excel-based P2I tool was developed, which phases of product development are included in the tool, and which costs are excluded.",,"Add,Fact/Evidence",Fact/Evidence
9628,8-1066,8-1066_v2_18@0,,"A summary of how the P2I tool was developed, and which phases and costs are included",,"Add,Other",Other
9629,8-1066,8-1066_v2_22@1,,Descriptions and examples of each are described elsewhere <REF-1> .,,"Add,Fact/Evidence",Fact/Evidence
9630,8-1066,8-1066_v2_22@2,,"For each of these 11 different archetypes, the model has in-built assumptions on costs, attrition rates, and cycle time per phase.",,"Add,Fact/Evidence",Fact/Evidence
9631,8-1066,,8-1066_v1_13@4,,The P2I tool is a Microsoft Excel based tool and P2I v.2 uses Microsoft Excel 2016.,"Delete,Fact/Evidence",Fact/Evidence
9632,8-1066,8-1066_v2_23@0,,"One valuable feature of the model is that it is highly adaptable, users can input additional archetypes into the Excel tool.",,"Add,Claim",Claim
9633,8-1066,8-1066_v2_23@1,,"In the P2I v.2 model, additional archetypes include “unprecedented vaccines” (for candidate vaccines for HIV, TB, and malaria to, which are “considered as unprecedented as current platforms have not led to suitable vaccines” <REF-2> ) and vector control products.",,"Add,Fact/Evidence",Fact/Evidence
9634,8-1066,8-1066_v2_24@0,,"As described elsewhere <REF-1> , assumptions on development costs at each phase of product development for the 11 archetypes included in the P2I.v1 model were initially based on an analysis of clinical trial costs from Parexel’s R&D cost sourcebook.",,"Add,Fact/Evidence",Fact/Evidence
9635,8-1066,8-1066_v2_24@1,,"The assumptions on attrition rates and cycle times at each phase were initially based on the historical attrition rates and cycle times of more than 25,000 development candidates.",,"Add,Fact/Evidence",Fact/Evidence
9636,8-1066,8-1066_v2_25@0,,"As described below, the three archetypes of relevance for our analysis of the EVI portfolio were simple, complex, and unprecedented vaccines (reference <REF-2> describes these three different archetypes in more detail).",,"Add,Fact/Evidence",Fact/Evidence
9637,8-1066,8-1066_v2_25@1,,"After classifying each EVI candidate into its archetype and phase, we then ran the model.",,"Add,Fact/Evidence",Fact/Evidence
9638,8-1066,8-1066_v2_25@2,,There are two main model outputs.,,"Add,Fact/Evidence",Fact/Evidence
9639,8-1066,8-1066_v2_25@3,,"The first is “launches”; in this paper, the term launch refers to a candidate making it through phase III and thus being ready for the next steps, e.g. the regulatory and manufacturing steps.",,"Add,Fact/Evidence",Fact/Evidence
9640,8-1066,8-1066_v2_25@4,,"The second is the total costs to move all candidates through the pipeline from their current phase from now to 2031 (the model also gives a breakdown of these total costs into annual costs by year, from 2019 to 2031).",,"Add,Fact/Evidence",Fact/Evidence
9641,8-1066,8-1066_v2_26@0,,"The model includes only advanced preclinical to phase III, and thus the cost estimates are an under-estimate of the full costs of product development.",,"Add,Fact/Evidence",Fact/Evidence
9642,8-1066,8-1066_v2_26@1,,"In particular, the model excludes all costs related to basic research through lead optimization; chemistry, manufacturing, and controls; good manufacturing practice; manufacturing build up and scale-up costs; regulatory or registration fees (post-phase III); and all post-market commitments (e.g., phase IV pharmacovigilance studies).",,"Add,Fact/Evidence",Fact/Evidence
9643,8-1066,8-1066_v2_33@0,8-1066_v1_22@0,"Step 2: modelling of costs to move candidates through pipeline and likely launches, using P2I v.2 model with its existing assumptions","Step 2: modeling of costs to move candidates through pipeline and likely launches, using P2I v.2 model with its existing assumptions","Modify,Grammar",Grammar
9644,8-1066,8-1066_v2_38@0,8-1066_v1_27@0,"Step 3: modelling of costs to move candidates through pipeline and likely launches, using the P2I v.2 model with modified assumptions","Step 3: modeling of costs to move candidates through pipeline and likely launches, using the P2I v.2 model with modified assumptions","Modify,Grammar",Grammar
9645,8-1066,8-1066_v2_52@0,8-1066_v1_41@0,"(ii) First run of the P2I financing modelling tool, using assumptions from P2I v.2","(ii) First run of the P2I financing modeling tool, using assumptions from P2I v.2","Modify,Grammar",Grammar
9646,8-1066,8-1066_v2_53@1,8-1066_v1_42@1,The total estimated cost to move the 18 candidates for six diseases along the pipeline to launch would be about US $470 million ( Table 5 ).,"The total estimated cost to move the 18 candidates along the pipeline to launch would be about US $470 million ( Table 5 , Figure 2 ).","Modify,Fact/Evidence",Fact/Evidence
9647,8-1066,8-1066_v2_56@0,8-1066_v1_47@0,Expected launches (expressed as launch probabilities).,Expected launches.,"Modify,Other",Other
9648,8-1066,8-1066_v2_56@1,8-1066_v1_47@1,"Overall, for all 18 candidates under development, the P2I model estimates that there would be 0.69 expected launches across all six diseases combined, as shown in Table 5 (we have left all results unrounded).","Overall, for all 18 candidates under development, the P2I model estimates that there would be 0.69 cumulative expected launches (we have left all results unrounded).","Modify,Fact/Evidence",Fact/Evidence
9649,8-1066,8-1066_v2_56@2,8-1066_v1_47@2,"Table 5 summarizes the expected launches by disease based on the current candidates for six diseases in EVI’s portfolio (the “expected launches” throughout this paper are expressed as launch probabilities, where 1.0 is 100% probability of a launch).",Figure 3 summarizes the expected launches by disease.,"Modify,Fact/Evidence",Fact/Evidence
9650,8-1066,8-1066_v2_59@0,8-1066_v1_54@0,"(iii) Second run of the P2I financing modelling tool, with modifications of selected assumptions","(iii) Second run of the P2I financing modeling tool, with modifications of selected assumptions","Modify,Grammar",Grammar
9651,8-1066,8-1066_v2_71@1,8-1066_v1_63@1,"In the second sensitivity analysis for the second run of the model (which used modified assumptions), we found that the total estimated cost to move all candidates in EVI’s portfolio for all six diseases through the pipeline from their current phase ranged from US$ 482.48 million to US$ 581.9 million ( Table 9 ).","In the sensitivity analysis for the first run of the model (which used assumptions from P2I v.2), we found that the total estimated costs ranged from US$ 482.48 million to US$ 581.9 million ( Table 8 ).","Modify,Fact/Evidence",Fact/Evidence
9652,8-1066,8-1066_v2_71@2,8-1066_v1_63@2,The combined launch probability for launching candidates across all six disease types ranged from 0.53 to 0.96.,The launch probability ranged from 0.53 to 0.96.,"Modify,Fact/Evidence",Fact/Evidence
9653,8-1066,8-1066_v2_68@1,8-1066_v1_66@1,"In the sensitivity analysis for the first run of the model (which used assumptions from P2I v.2), we found that the total estimated costs to move all candidates in EVI’s portfolio for all six diseases through the pipeline from their current phase ranged from US$ 417.08 million to US$ 528.11 million ( Table 8 ).","In the second sensitivity analysis for the second run of the model (which used modified assumptions), we found that the total estimated cost ranged from US $417.08 million to US $528.11 million ( Table 9 ).","Modify,Fact/Evidence",Fact/Evidence
9654,8-1066,8-1066_v2_68@2,8-1066_v1_66@2,The combined launch probability for launching candidates across all six disease types ranged from 0.51 to 0.91.,The launch probability ranged from 0.51 to 0.91.,"Modify,Fact/Evidence",Fact/Evidence
9655,8-1066,8-1066_v2_75@2,8-1066_v1_70@2,"An analysis of EVI´s current vaccine portfolio, providing estimations for future vaccine development costs and expected product launches, was considered important to inform future decision-making and priority setting at EVI, as well as to provide valuable information to global health funders and policy makers.","An analysis of EVI´s current vaccine portfolio—providing estimations for future vaccine development costs and expected product launches—was considered important to inform EVI´s decision-making and priority setting, as well as to provide valuable information to global health funders and policy makers.","Modify,Clarity",Clarity
9656,8-1066,8-1066_v2_79@0,8-1066_v1_74@0,"With regards to the estimated future launches, for all 18 candidates under development, the P2I model estimates that there would be 0.69 expected launches across all six diseases combined.","With regards to the estimated future launches, for all 18 candidates under development, the P2I model estimates that there would be 0.69 cumulative expected launches.","Modify,Fact/Evidence",Fact/Evidence
9657,8-1066,8-1066_v2_80@0,8-1066_v1_75@0,"However, rather than looking at the isolated results on likely launches from the analysis of a single organization’s portfolio, as has been done in this particular study, more meaningful results will be obtained from such simulations using the P2I tool by conducting a much wider portfolio analysis in which the launch estimation results of the entire global vaccine candidate portfolio are estimated in an integrated, combined manner.","However, rather than looking at the isolated results on likely launches from the analysis of a single organization´s portfolio, a more meaningful estimation will be obtained by conducting a much wider portfolio analysis in which the launch estimation results of the entire global vaccine candidate portfolio are estimated in an integrated, combined manner.","Modify,Claim",Claim
9658,8-1066,8-1066_v2_80@1,8-1066_v1_75@1,Only this kind of “full global portfolio” study can provide a reliable prediction of the product success rates on a global level for the next few decades.,Only this kind of “full portfolio” study can provide a reliable prediction of the product success rates on a global level for the next few decades.,"Modify,Clarity",Clarity
9659,8-1066,8-1066_v2_15@1,8-1066_v1_13@0,"After this summary, we then describe the four key steps in our analysis of EVI’s vaccine portfolio, which are summarized in Figure 1 .","In this section, we describe the four key steps in this analysis, which are summarized in Figure 1 .","Modify,Fact/Evidence",Fact/Evidence
9660,8-1066,8-1066_v2_19@0,8-1066_v1_13@1,"A detailed research paper describing the development of the first version of the P2I tool itself (P2I version 1, or P2I v1) has been previously published <REF-1> .","We do not describe the development of the first version of the P2I tool itself (P2I version 1, or P2I v.1), because this has been previously published <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
9661,8-1066,8-1066_v2_19@2,8-1066_v1_13@3,"As summarized below, the model is based on assumptions for costs per phase, attrition rates (probability of success) per phase, and cycle times per phase for four development phases (preclinical to phase III, see Figure 2 ) for a number of different kinds of medical products, called archetypes.","In brief, the model is based on assumptions for costs per phase, attrition rates (probability of success) per phase, and cycle times per phase for four development phases (preclinical to phase III) for 11 different kinds of medical products, called archetypes.","Modify,Fact/Evidence",Fact/Evidence
9662,8-1126,8-1126_v2_9@1,,"- b. Probiotic bacteria: Bifidobacterium bifidum (NCDC 255), Enterococcus faecium (NCIM 5366), and Lactobacillus plantarum (MTCC 2621)",,"Add,Fact/Evidence",Fact/Evidence
9663,8-1126,8-1126_v2_13@1,,"- b. TF as a post-infection therapy ( Patel et al ., 2019b ): Worms already infected with pathogenic bacteria not previously exposed to the test formulation were treated with TF to see whether the test formulation can exert any therapeutic effect on already infected worms. Assay methods remained the same as described in previous section, except that TF was added into assay wells after allowing bacteria either for 6 h or 24 h to establish infection.",,"Add,Fact/Evidence",Fact/Evidence
9664,8-1126,8-1126_v2_41@3,,"Since antibiotic-resistant strains of P. aeruginosa and Entrerobacteriaceae (to which S. marcences belongs) are recognized as serious threats ( https://www.cdc.gov/drugresistance/biggest-threats.html ; https://www.who.int/medicines/publications/WHO-PPL-Short_Summary_25Feb-ET_NM_WHO.pdf ), these two bacteria were used in this assay.",,"Add,Fact/Evidence",Fact/Evidence
9665,8-1126,8-1126_v2_41@4,,"Since higher concentration of antimicrobial formulations can be expected to exert higher selection pressure on the susceptible bacterial population, we chose the highest TF concentration (50 µg/ml) beyond which TF does not exert any statistically superior anti-infective effect.",,"Add,Fact/Evidence",Fact/Evidence
9666,8-1126,8-1126_v2_42@2,,"These results indicate that it may be difficult for the pathogenic bacteria to develop complete resistance against polyherbal formulations like Triphala, but not impossible.",,"Add,Claim",Claim
9667,8-1126,,8-1126_v1_15@1,,"Assay methods remained the same as described in previous section, except that TF was added into assay wells after allowing bacteria either for 6 h or 24 h to establish infection.","Delete,Fact/Evidence",Fact/Evidence
9668,8-1126,8-1126_v2_18@0,8-1126_v1_20@0,"- a. Broth dilution assay ( Joshi et al ., 2016 ) to investigate effect of TF on bacterial growth and quorum sensing (QS)-regulated pigment production: C. violaceum , and S. marcescens were inoculated in nutrient broth (HiMedia MV002-500G) supplemented with TF. Media used for P. aeruginosa and S. aureus were Pseudomonas broth [10 g/l potassium sulfate (SRL 44277), 1.4 g/l magnesium chloride (Merck 1.9366.30521), 16 g/l peptone (HiMedia RM001-500G)], and Staphylococcus broth (HiMedia M578-500G) respectively. S. pyogenes was grown in BHI (brain heart infusion; HiMedia MV210-500G) broth. Following incubation, cell density was measured at 750 nm in a microplate reader (Biorad 680). Pigment from these culture broths were extracted as previously described by us in Joshi et al. (2016) . Cell pellets of C. violaceum , S. marcescens , or S. aureus were dissolved in appropriate solvent i.e. C. violaceum pellet in DMSO [(Merck 1.07046.2521); S. marcescens pellet in acidified methanol [4 ml HCl (HiMedia AS003-500ML) into 96 ml of methanol]; and S. aureus pellet in methanol (Merck 1.94516.2521). This allowed their pigments to be extracted in the solvent applied. In case of P. aeruginosa , pigment extraction was achieved by mixing chloroform (Merck 1.67024.0521) with culture broth (2:1 ratio). Quantification of each pigment was done at the wavelength nearest to its λ max, available in the microplate reader (Biorad 680) used by us.","- a. Broth dilution assay ( Joshi et al ., 2016 ) to investigate effect of Triphala on bacterial growth and quorum sensing (QS)-regulated pigment production: C. violaceum , and S. marcescens were inoculated in nutrient broth (HiMedia MV002-500G) supplemented with TF. Media used for S. aureus and P. aeruginosa were Staphylococcus broth (HiMedia M578-500G) and Pseudomonas broth [10 g/l potassium sulfate (SRL 44277), 1.4 g/l magnesium chloride (Merck 1.9366.30521), 16 g/l peptone (HiMedia RM001-500G)] respectively. S. pyogenes was grown in BHI (brain heart infusion; HiMedia MV210-500G) broth. Following incubation, cell density was measured at 750 nm (Biorad 680). Pigment from these culture broths were extracted as previously described by us in Joshi et al. (2016) . Cell pellets of C. violaceum , S. marcescens , and S. aureus were dissolved in DMSO [(Merck 1.07046.2521), acidified methanol [4 ml HCl (HiMedia AS003-500ML) into 96 ml of methanol], and methanol (Merck 1.94516.2521) respectively. This allowed their pigments to be extracted in the solvent applied. In case of P. aeruginosa , pigment extraction was achieved by mixing chloroform (Merck 1.67024.0521) with culture broth (2:1 ratio). Quantification of each pigment was done at the wavelength nearest to its λ max, available in the microplate reader (Biorad 680) used by us.","Modify,Clarity",Clarity
9669,8-1126,8-1126_v2_18@1,8-1126_v1_20@1,"- b. Effect of TF on biofilm formation and its possible potential to eradicate pre-formed biofilm was assessed through crystal violet assay ( Patel et al ., 2013 ); and its effect on biofilm viability was assessed through MTT assay ( Trafny et al ., 2013 ). For the crystal violet assay, the biofilm-containing tubes after discarding the inside liquid were washed with PBS in order to remove all nonadherent bacteria and air-dried for 15 min. Then, each of the washed tubes was stained with 1.5 mL of 0.4% aqueous crystal violet solution (SRL 54862-9) for 30 min. Afterwards, each tube was washed twice with 2 ml of sterile distilled water and immediately destained with 1500 μL of 95% ethanol. After 45 min of destaining, 1 mL of destaining solution was transferred into separate tubes and read at 570 nm in a microplate reader (Biorad 680). For the MTT assay, the biofilm-containing tubes (after discarding the inside liquid) were washed with PBS in order to remove all nonadherent bacteria and air-dried for 15 min. Then, 900 µL of minimal media was added into each tube, followed by addition of 100 μL of 0.3% MTT (3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide; HiMedia MB186-100MG). After 2 h incubation at 37°C, resulting purple formazan derivatives were dissolved in DMSO and measured at 570 nm in a microplate reader (Biorad 680).","- b. Effect of Triphala on biofilm formation and its possible potential to eradicate pre-formed biofilm was assessed through crystal violet assay ( Patel et al ., 2013 ); and its effect on biofilm viability was assessed through MTT assay ( Trafny et al ., 2013 ). For the crystal violet assay, the biofilm-containing tubes (after discarding the inside liquid) were washed with PBS in order to remove all nonadherent bacteria and air-dried for 15 min. Then, each of the washed tubes was stained with 1.5 mL of aqueous crystal violet solution (0.4%; SRL 54862-9) for 30 min. Afterwards, each tube was washed twice with 2 ml of sterile distilled water and immediately destained with 1500 μL of ethanol (95%). After 45 min of destaining, 1 mL of destaining solution was transferred into separate tubes and read at 570 nm (Biorad 680). For the MTT assay, the biofilm-containing tubes (after discarding the inside liquid) were washed with PBS in order to remove all nonadherent bacteria and air-dried for 15 min. Then, 900 µL of minimal media was added into each tube, followed by addition of 100 μL of 0.3% MTT (3-(4,5-dimethylthiazol-2-yl)-2,5-diphenyltetrazolium bromide; HiMedia MB186-100MG). After 2 h incubation at 37°C, resulting purple formazan derivatives were dissolved in DMSO and measured at 570 nm (Biorad 680).","Modify,Clarity",Clarity
9670,8-1126,8-1126_v2_2@8,8-1126_v1_2@8,P. aeruginosa's lysozyme-susceptibility was found to increase by ~25-43% upon TF-pretreatment.,P. aeruginosa's lysozyme-susceptibility was found to increase by ~25-43% upon Triphala -pretreatment.,"Modify,Clarity",Clarity
9671,8-1126,8-1126_v2_18@2,8-1126_v1_20@2,"- c. Effect of TF on haemolytic potential of the test pathogens ( Neun et al ., 2015 ): Small volume of human blood required for this assay was obtained from the authors, who each gave their written informed consent. The use of this blood was approved by the Institutional Ethics Committee of the Institute of Science, Nirma University (approval no: EC/NU/18/IS/4). Blood collection was executed by one of the authors (AA) on three different times in heparinized vials. OD 750 of the overnight culture grown in presence or absence of TF was standardized to 1.00. Cell-free supernatant was prepared by centrifugation at 15,300 g for 10 min. 10 μl of human blood was incubated with this cell-free supernatant for 2 h at 37°C, followed by centrifugation at 800 g for 15 min. OD of the supernatant was read at 490 nm in a microplate reader (Biorad 680), to quantify the amount of hemoglobin released. 1% Triton X-100 (CDH, New Delhi; CDH030632) was used as a positive control. Phosphate buffer saline was used as a negative control.","- c. Effect of Triphala on haemolytic potential of the test pathogens ( Neun et al ., 2015 ): Small volume of human blood required for this assay was obtained from the authors, who each gave their written informed consent. The use of this blood was approved by the Institutional Ethics Committee of the Institute of Science, Nirma University (approval no: EC/NU/18/IS/4). Blood collection was executed by one of the authors (AA) on three different times in heparinized vials. OD 750 of the overnight grown (in presence or absence of TF) culture was standardized to 1.00. Cell-free supernatant was prepared by centrifugation at 15,300 g for 10 min. 10 μl of human blood was incubated with this cell-free supernatant for 2 h at 37°C, followed by centrifugation at 800 g for 15 min. OD of the supernatant was read at 490 nm, to quantify the amount of hemoglobin released. 1% Triton X-100 (CDH, New Delhi; CDH030632) was used as a positive control. Phosphate buffer saline was used as a negative control.","Modify,Clarity",Clarity
9672,8-1126,8-1126_v2_18@3,8-1126_v1_20@3,"- d. Effect of TF on lysozyme-susceptibility of test pathogens: Bacterial cells were first inoculated in a TF-containing media for 24 h, and then the cell pellet was separated by centrifugation [at 15,000 rpm for 15 min] to be resuspended into phosphate buffer saline (PBS) of pH 7.4, so as to attain OD 750 =1 (Biorad 680). 200 µl of this bacterial suspension was mixed with 750 µg/ml lysozyme (Sigma Aldrich L6876-1G) prepared in PBS, and then incubated for 24 h at appropriate temp for each organism. At the end of incubation OD 750 was measured.","- d. Effect of Triphala on lysozyme-susceptibility of test pathogens: Bacterial cells were first inoculated in a TF-containing media for 24 h, and then the cell pellet was separated by centrifugation [15,000 rpm (21130 g) for 15 min] to be resuspended into phosphate buffer saline (PBS; pH 7.4), so as to attain OD 750 =1 (Biorad 680). 200 µl of this bacterial suspension was mixed with lysozyme (750 µg/ml; Sigma Aldrich L6876-1G) prepared in PBS, and then incubated for 24 h at appropriate temp for each organism. At the end of incubation OD 750 was measured.","Modify,Clarity",Clarity
9673,8-1126,8-1126_v2_25@1,8-1126_v1_27@1,"When all the five pathogens were pre-treated with 0.5-100 µg/ml of TF before being allowed to attack C. elegans, Triphala formulation (TF) was able to attenuate virulence of all test pathogens except S. pyogenes at ≤20 µg/ml [ Figure 1 ; underlying data ( Patel et al ., 2019c )].","When all the five pathogens were pre-treated with Triphala (0.5-100 µg/ml) before being allowed to attack C.elegans, Triphala formulation (TF) was able to attenuate virulence of all test pathogens except S. pyogenes at ≤20 µg/ml [ Figure 1 ; underlying data ( Patel et al ., 2019c )].","Modify,Clarity",Clarity
9674,8-1126,8-1126_v2_25@3,8-1126_v1_27@3,"Effect of catechin and standard antibiotics used as positive controls on bacterial virulence is shown in Figure 2 [underlying data ( Patel et al ., 2019c )].","Effect of catechin and standard antibiotics (both used as positive controls) on bacterial virulence is shown in Figure 2 [underlying data ( Patel et al ., 2019c )].","Modify,Clarity",Clarity
9675,8-1126,8-1126_v2_30@1,8-1126_v1_32@1,"When the TF-treated bacteria were subsequently subcultured on TF-free media, their daughter populations were unable to exert virulence at par with that of control (DMSO-treated parent culture having no TF-exposure).","When the TF-treated bacteria were subsequently subcultured on TF-free media, their daughter populations were unable to exert virulence at par with that of control (DMSO-treated parent culture).","Modify,Clarity",Clarity
9676,8-1126,8-1126_v2_4@4,8-1126_v1_4@4,"Triphala is a polyherbal formulation containing three myrobalans fruits i.e. Phyllanthus emblica , Terminalia bellerica and Terminalia chebula ( Patwardhan et al ., 2015 ).","Triphala is a polyherbal formulation containing three myrobalans fruits i.e. Phyllanthus emblica, Terminalia chebula, and Terminalia bellerica ( Patwardhan et al ., 2015 ).","Modify,Clarity",Clarity
9677,8-1126,8-1126_v2_33@1,8-1126_v1_35@1,"To test the therapeutic efficacy of TF in already-infected worm population, we first allowed different pathogenic bacteria, not previously exposed to TF, to infect C. elegans either for 6 h or 24 h, and then exposed the infected worms to two different concentrations of TF.","To test the therapeutic efficacy of TF in already-infected worm population, we first allowed different pathogenic bacteria (not previously exposed to TF) to infect C. elegans either for 6 h or 24 h, and then exposed the infected worms to two different concentrations of TF.","Modify,Clarity",Clarity
9678,8-1126,8-1126_v2_4@5,8-1126_v1_4@5,"TF is prescribed as a general health promoter, for management of metabolic disorders, dental and skin problems, and for wound management.","Triphala is prescribed as a general health promoter, for management of metabolic disorders, dental and skin problems, and for wound management.","Modify,Clarity",Clarity
9679,8-1126,8-1126_v2_0@0,8-1126_v1_0@0,Anti-pathogenic potential of a classical ayurvedic Triphala formulation,Anti-pathogenic potential of a classical ayurvedic formulation- Triphala,"Modify,Clarity",Clarity
9680,8-1126,8-1126_v2_36@1,8-1126_v1_38@1,"To investigate whether previous feeding with TF can make the worm population tolerate subsequent challenge with pathogenic bacteria, not treated with TF, better; worms were first maintained in a TF-containing M9 buffer for 96 h, and then challenged with different bacterial pathogens.","To investigate whether previous feeding with TF can make the worm population tolerate subsequent challenge with pathogenic bacteria (not treated with TF) better; worms were first maintained in a TF-containing M9 buffer for 96 h, and then challenged with different bacterial pathogens.","Modify,Clarity",Clarity
9681,8-1126,8-1126_v2_36@5,8-1126_v1_38@5,Worms fed with TF (10–20 µg/ml) registered marginally better survival up to 11 days ( Figure 6 ).,Worms fed with TF (10-20 µg/ml) registered marginally better survival up to 11 days ( Figure 6 ).,"Modify,Grammar",Grammar
9682,8-1126,8-1126_v2_4@8,8-1126_v1_4@8,This study aimed to investigate the anti-pathogenic efficacy of TF against five different pathogenic bacteria.,This study aimed to investigate the anti-pathogenic efficacy of Triphala against five different pathogenic bacteria.,"Modify,Clarity",Clarity
9683,8-1126,8-1126_v2_7@0,8-1126_v1_7@0,"Triphala formulation (TF) (Emami Ltd; batch no. EM0029; Proportion of 3 constituent plant species: 1:1:1 i.e. P. emblica , T. bellerica , and T. chebula ) was purchased from a local market in Ahmedabad, India).",Triphala formulation (TF) (Emami Ltd; batch no. EM0029; Proportion of 3 constituent plant species: 1:1:1) was purchased from a local market.,"Modify,Fact/Evidence",Fact/Evidence
9684,8-1126,8-1126_v2_2@1,8-1126_v1_2@1,Virulence of four of them towards the model host Caenorhabditis elegans was attenuated (by 18-45%) owing to pre-treatment with Triphala Formulation (TF) (≤20 µg/ml).,Virulence of four of them towards the model host Caenorhabditis elegans was attenuated (by 18-45%) owing to pre-treatment with Triphala (≤20 µg/ml).,"Modify,Clarity",Clarity
9685,8-1126,8-1126_v2_7@2,8-1126_v1_7@2,"Then it was centrifuged at 8,000 rpm for 30 min at ambient temperature, and resulting supernatant was collected in a sterile 15 ml glass vial (Borosil) and stored under refrigeration till further use.","Then it was centrifuged at 8,000 rpm for 30 min at ambient temperature, and resulting supernatant was collected in a sterile glass vial (15 ml; Borosil) and stored under refrigeration till further use.","Modify,Clarity",Clarity
9688,8-1126,8-1126_v2_59@0,8-1126_v1_60@0,This study has found the classical TF to possess significant anti-infective potential against gram-positive and gram-negative pathogenic bacteria.,This study has found the classical Triphala formulation to possess significant anti-infective potential against various gram-positive and gram-negative pathogenic bacteria.,"Modify,Clarity",Clarity
9689,8-1126,8-1126_v2_59@2,8-1126_v1_60@2,"TF can be said to possess a broad-spectrum of anti-pathogenic activity, which seems to partly arise from its ability to interfere with bacterial quorum-sensing.","Triphala can be said to possess a broad-spectrum of anti-pathogenic activity, which seems to partly arise from its ability to interfere with bacterial quorum-sensing.","Modify,Clarity",Clarity
9691,8-1126,8-1126_v2_59@5,8-1126_v1_60@5,"Further investigation for elucidating the molecular mechanisms associated with the biological effects of TF are warranted, with special emphasis on its role in combating AMR.","Further investigation for elucidating the molecular mechanisms associated with the biological effects of Triphala are warranted, with special emphasis on its role in combating AMR.","Modify,Clarity",Clarity
9693,8-1126,8-1126_v2_2@2,8-1126_v1_2@2,"TF could also exert significant therapeutic effect on worms already infected with Chromobacterium violaceum (MTCC 2656), Serratia marcescens (MTCC 97) or Staphylococcus aureus (MTCC 737).","Triphala could also exert significant therapeutic effect on worms already infected with Chromobacterium violaceum , Serratia marcescens or Staphylococcus aureus .","Modify,Fact/Evidence",Fact/Evidence
9694,8-1126,8-1126_v2_11@0,8-1126_v1_11@0,"In vivo efficacy of TF against bacterial infections was tested in the nematode host Caenorhabditis elegans N2-Bristol (maintained at the Institute of Science, Nirma University).","In vivo efficacy of Triphala against bacterial infections was tested in the nematode host Caenorhabditis elegans (N2-Bristol strain; maintained at the Institute of Science, Nirma University).","Modify,Clarity",Clarity
9695,8-1126,8-1126_v2_11@3,8-1126_v1_11@3,"For synchronization of the worm population, adult worms from a 4–5 days old NGM plate were first washed with distilled water, and then treated with 1 mL of bleaching solution [1N NaOH (HiMedia MB095-100G) + 4% NaOCl (Merck 61842010001730) + water in 1:1:3 proportion], followed by centrifugation (at 1500 rpm at 22°C) for 1 min.","For synchronization of the worm population, adult worms from a 4–5 days old NGM plate were first washed with distilled water, and then treated with 1 mL of bleaching solution [1N NaOH (HiMedia MB095-100G) + 4% NaOCl (Merck 61842010001730) + water in 1:1:3 proportion], followed by centrifugation (22°C; 1,500 rpm) for 1 min.","Modify,Clarity",Clarity
9696,8-1126,8-1126_v2_13@0,8-1126_v1_13@0,"- a. Anti-infective assay ( Patel et al ., 2018a ): TF exposed-pathogenic bacteria were allowed to infect C. elegans (L3-L4 stage), and their capacity to kill the worm population was compared with their TF-unexposed counterparts, over a period of 5 days.","Anti-infective assay ( Patel et al ., 2018a ): Triphala exposed-pathogenic bacteria were allowed to infect C. elegans (L3-L4 stage), and their capacity to kill the worm population was compared with their Triphala -unexposed counterparts, over a period of 5 days.","Modify,Clarity",Clarity
9697,8-1126,8-1126_v2_2@3,8-1126_v1_2@3,Prophylactic use of TF allowed worms to score 14-41% better survival in face of subsequent pathogen challenge.,Prophylactic use of Triphala allowed worms to score 14-41% better survival in face of subsequent pathogen challenge.,"Modify,Clarity",Clarity
9698,8-1126,8-1126_v2_13@2,8-1126_v1_14@0,"- c. Prophylactic assay ( Patel et al ., 2018b ): TF-fed worms were challenged with pathogenic bacteria previously not exposed to the test formulation, and their ability to survive in face of pathogen challenge was compared with their TF-unfed counterparts. C. elegans worms maintained on NGM were kept unfed for 24 h prior to being used for experiments. These worms were then fed with TF by mixing required concentration of this formulation (100 µL of DMSO-dissolved Triphala ) with 800 µL of M9 medium and placed in a sterile non-treated polystyrene 24-well plate (HiMediaTPG24-1X50NO) containing 10 worms per well. Duration of exposure of worms to TF was kept to 96 h, followed by addition of 100 µL of pathogenic bacterial suspension of OD 764 = 1.50 measured with Agilent Cary 60 UV-Vis spectrophotometer). Appropriate controls i.e. worms previously not exposed to TF , but exposed to pathogenic bacteria; worms exposed neither to TF nor bacteria; and worms exposed to TF, but not to bacterial pathogens, were also included in the experiment. Incubation was carried out at 22°C. Number of dead vs. live worms were counted every day for 5 days by putting the plate with lid under a light microscope 4X objective (Catalyst Biotech CatScope CS-U207T). Straight worms were considered to be dead. Plates were gently tapped to confirm lack of movement in the apparently-dead worms. On the last day of the experiment, when plates could be opened, their death was also confirmed by touching them with a straight wire, wherein no movement was taken as confirmation of death.","Prophylactic assay ( Patel et al ., 2018b ): Triphala -fed worms were challenged with pathogenic bacteria (previously not exposed to the test formulation), and their ability to survive in face of pathogen challenge was compared with their Triphala -unfed counterparts.","Merge+Modify,Clarity",Clarity
9700,8-1126,8-1126_v2_13@2,8-1126_v1_14@2,"- c. Prophylactic assay ( Patel et al ., 2018b ): TF-fed worms were challenged with pathogenic bacteria previously not exposed to the test formulation, and their ability to survive in face of pathogen challenge was compared with their TF-unfed counterparts. C. elegans worms maintained on NGM were kept unfed for 24 h prior to being used for experiments. These worms were then fed with TF by mixing required concentration of this formulation (100 µL of DMSO-dissolved Triphala ) with 800 µL of M9 medium and placed in a sterile non-treated polystyrene 24-well plate (HiMediaTPG24-1X50NO) containing 10 worms per well. Duration of exposure of worms to TF was kept to 96 h, followed by addition of 100 µL of pathogenic bacterial suspension of OD 764 = 1.50 measured with Agilent Cary 60 UV-Vis spectrophotometer). Appropriate controls i.e. worms previously not exposed to TF , but exposed to pathogenic bacteria; worms exposed neither to TF nor bacteria; and worms exposed to TF, but not to bacterial pathogens, were also included in the experiment. Incubation was carried out at 22°C. Number of dead vs. live worms were counted every day for 5 days by putting the plate with lid under a light microscope 4X objective (Catalyst Biotech CatScope CS-U207T). Straight worms were considered to be dead. Plates were gently tapped to confirm lack of movement in the apparently-dead worms. On the last day of the experiment, when plates could be opened, their death was also confirmed by touching them with a straight wire, wherein no movement was taken as confirmation of death.","These worms were then fed with TF by mixing required concentration of this formulation (100 µL) with M9 medium (800 µL) and placed in a 24-well plate (non-treated polystyrene plates, sterile; HiMediaTPG24-1X50NO) containing 10 worms per well.","Merge+Modify,Clarity",Clarity
9701,8-1126,8-1126_v2_13@2,8-1126_v1_14@3,"- c. Prophylactic assay ( Patel et al ., 2018b ): TF-fed worms were challenged with pathogenic bacteria previously not exposed to the test formulation, and their ability to survive in face of pathogen challenge was compared with their TF-unfed counterparts. C. elegans worms maintained on NGM were kept unfed for 24 h prior to being used for experiments. These worms were then fed with TF by mixing required concentration of this formulation (100 µL of DMSO-dissolved Triphala ) with 800 µL of M9 medium and placed in a sterile non-treated polystyrene 24-well plate (HiMediaTPG24-1X50NO) containing 10 worms per well. Duration of exposure of worms to TF was kept to 96 h, followed by addition of 100 µL of pathogenic bacterial suspension of OD 764 = 1.50 measured with Agilent Cary 60 UV-Vis spectrophotometer). Appropriate controls i.e. worms previously not exposed to TF , but exposed to pathogenic bacteria; worms exposed neither to TF nor bacteria; and worms exposed to TF, but not to bacterial pathogens, were also included in the experiment. Incubation was carried out at 22°C. Number of dead vs. live worms were counted every day for 5 days by putting the plate with lid under a light microscope 4X objective (Catalyst Biotech CatScope CS-U207T). Straight worms were considered to be dead. Plates were gently tapped to confirm lack of movement in the apparently-dead worms. On the last day of the experiment, when plates could be opened, their death was also confirmed by touching them with a straight wire, wherein no movement was taken as confirmation of death.","Duration of exposure of worms to TF was kept to 96 h, followed by addition of pathogenic bacteria (100 µL of bacterial suspension with OD 764 = 1.50 measured with Agilent Cary 60 UV-Vis spectrophotometer).","Merge+Modify,Clarity",Clarity
9704,8-1126,8-1126_v2_13@2,8-1126_v1_14@6,"- c. Prophylactic assay ( Patel et al ., 2018b ): TF-fed worms were challenged with pathogenic bacteria previously not exposed to the test formulation, and their ability to survive in face of pathogen challenge was compared with their TF-unfed counterparts. C. elegans worms maintained on NGM were kept unfed for 24 h prior to being used for experiments. These worms were then fed with TF by mixing required concentration of this formulation (100 µL of DMSO-dissolved Triphala ) with 800 µL of M9 medium and placed in a sterile non-treated polystyrene 24-well plate (HiMediaTPG24-1X50NO) containing 10 worms per well. Duration of exposure of worms to TF was kept to 96 h, followed by addition of 100 µL of pathogenic bacterial suspension of OD 764 = 1.50 measured with Agilent Cary 60 UV-Vis spectrophotometer). Appropriate controls i.e. worms previously not exposed to TF , but exposed to pathogenic bacteria; worms exposed neither to TF nor bacteria; and worms exposed to TF, but not to bacterial pathogens, were also included in the experiment. Incubation was carried out at 22°C. Number of dead vs. live worms were counted every day for 5 days by putting the plate with lid under a light microscope 4X objective (Catalyst Biotech CatScope CS-U207T). Straight worms were considered to be dead. Plates were gently tapped to confirm lack of movement in the apparently-dead worms. On the last day of the experiment, when plates could be opened, their death was also confirmed by touching them with a straight wire, wherein no movement was taken as confirmation of death.",Number of dead vs. live worms were counted every day for 5 days by putting the plate (with lid) under a light microscope (4X; Catalyst Biotech CatScope CS-U207T).,"Merge+Modify,Clarity",Clarity
9708,8-1126,8-1126_v2_17@0,8-1126_v1_19@0,"After confirming the in vivo anti-pathogenic efficacy of the TF, we performed following in vitro assays to gain insight into interaction of this formulation with the pathogenic bacteria, as per the methodology described in respective references mentioned in the parenthesis:","After confirming the in vivo anti-pathogenic efficacy of the Triphala formulation, we performed following in vitro assays to gain insight into interaction of this formulation with the pathogenic bacteria, as per the methodology described in respective references mentioned in the parenthesis:","Modify,Clarity",Clarity
9709,8-1126,8-1126_v2_2@6,8-1126_v1_2@6,TF was able to modulate production of quorum sensing (QS)-regulated pigments in three of the multidrug-resistant gram-negative test bacteria.,Triphala was able to modulate production of quorum sensing (QS)-regulated pigments in three of the multidrug-resistant gram-negative test bacteria.,"Modify,Clarity",Clarity
9743,8-1439,8-1439_v2_7@0,,The physical setting can influence our mood and how we perceive the social situation.,,"Add,Claim",Claim
9744,8-1439,8-1439_v2_7@1,,"It can also determine our likelihood of interacting with others, and also influences the form that interaction will take and how long it is likely to last <REF-1> .",,"Add,Fact/Evidence",Fact/Evidence
9745,8-1439,8-1439_v2_4@2,8-1439_v1_4@2,The layout where the physician and the patient had a 90º angle facing each other was the most commonly used layout in Asia-Pacific and Africa.,The layout where the physician and the patient had a 90º angle facing each other was the most commonly used layout in Asia-Australia and Africa.,"Modify,Fact/Evidence",Fact/Evidence
9746,8-1439,8-1439_v2_39@0,8-1439_v1_39@0,"The position of the chairs, computer and desk can directly affect the doctor-patient relationship <REF-3> , <REF-6> .",The position of the chairs and desk can directly affect the doctor-patient relationship.,"Modify,Fact/Evidence",Fact/Evidence
9747,8-1439,8-1439_v2_47@1,8-1439_v1_47@1,"Modifying current consulting room designs according to patient’s and doctor’s preferences could open up new opportunities for interaction between GPs and their patients, while continuing to remain conscious of both community and cultural differences during planning.","Modifying current consulting room designs opens up new opportunities for interaction between GPs and their patients, while continuing to remain conscious of both community and cultural differences during planning.","Modify,Fact/Evidence",Fact/Evidence
9748,8-1439,8-1439_v2_8@6,8-1439_v1_8@6,"Furthermore, the power dynamics relationship (how power affects a relationship between two or more people) can be directly affected by the GP’s desk position, including the computer <REF-6> , <REF-7> and furniture arrangement that can negatively influence the physician-patient relationship.","Furthermore, the power relationship can be directly affected by the GP’s desk position, including the computer <REF-5> , <REF-6> and furniture arrangement that can negatively influence the physician-patient relationship.","Modify,Claim",Claim
9749,8-1439,8-1439_v2_9@2,8-1439_v1_9@2,The aim of this study was to explore and investigate the layout of GP’s consulting rooms around the world and to describe differences encountered.,The aim of this study was to explore and investigate the layout of GP’s consulting rooms around the world and to describe any significant differences.,"Modify,Clarity",Clarity
9750,8-1439,8-1439_v2_11@0,8-1439_v1_11@0,"After a literature review, a specific questionnaire exploring this topic was not found and the authors decided to develop one.",A specific questionnaire exploring this topic was not found and the authors decided to develop one.,"Modify,Fact/Evidence",Fact/Evidence
9751,8-1439,8-1439_v2_12@0,8-1439_v1_12@0,"Between July 3rd and August 2nd 2018, an internet-based questionnaire on Google Docs ( Extended data ) was distributed by email and WhatsApp to several worldwide rural medicine social media and WhatsApp groups as this allowed reaching a varied number of countries.","Between July 3rd and August 2nd 2018, an internet-based questionnaire on Google Docs ( Extended data ) was distributed by email to several worldwide rural medicine social media and WhatsApp groups.","Modify,Fact/Evidence",Fact/Evidence
9752,8-1439,8-1439_v2_13@5,8-1439_v1_13@5,"Finally, there was a section for questionnaire feedback.","Finally, there was a section for questionnaire feedback in order to allow for future improvements.","Modify,Fact/Evidence",Fact/Evidence
9753,8-1439,8-1439_v2_23@2,8-1439_v1_23@2,Scenario 4 was also the most common layout in Asia-Pacific (80%) and Africa (56%).,Scenario 4 was also the most common layout in Asia-Australia (80%) and Africa (56%).,"Modify,Fact/Evidence",Fact/Evidence
9754,8-1439,8-1439_v2_24@1,8-1439_v1_24@1,We did not analyze differences in the layouts between Asia-Pacific and Africa as we had so few responses.,We did not analyze differences in the layouts between Asia-Australia and Africa as we had so few responses.,"Modify,Fact/Evidence",Fact/Evidence
9755,8-155,8-155_v2_10@16,8-155_v1_11@16,"In our case, the diagnosis was limited as these confirmatory tests just mentioned i.e. echocardiography, biopsy, and MRI, could not be performed due to the early death of the patient.","In our case our diagnosis was limited as these confirmatory tests just mentioned i.e. echocardiography, biopsy and MRI, could not be performed due to the early death of the patient.","Modify,Grammar",Grammar
9756,8-155,8-155_v2_4@0,8-155_v1_5@0,Hepatitis E virus (HEV) is an important cause of morbidity and mortality and constitutes a significant public health problem <REF-1> .,Hepatitis E (HEV) virus is an important cause of morbidity and mortality and constitutes a significant public health problem <REF-1> .,"Modify,Clarity",Clarity
9757,8-155,8-155_v2_4@3,8-155_v1_5@3,"Other extra-hepatic manifestations seen in HEV infection include Guillian Barre syndrome, neuralgic amyotrophy, glomerulonephritis, cryoglobulinemia, pancreatitis, leukemia, thrombocytopenia, meningitis, thyroiditis, neuro-myopathy, vestibular neuritis and arrhythmias <REF-3> , <REF-4> .","Other extra-hepatic manifestations seen in HEV infection includes Guillian Barre syndrome, neuralgic amyotrophy, glomerulonephritis, cryoglobulinemia, pancreatitis, leukemia, thrombocytopenia, meningitis, thyroiditis, neuro-myopathy, vestibular neuritis and arrhythmias <REF-3> , <REF-4> .","Modify,Grammar",Grammar
9758,8-155,8-155_v2_6@0,8-155_v1_7@0,"A 22-year-old male student, from the Sindh province of Pakistan, unmarried, presented to the emergency department of Jinnah Postgraduate Medical Centre, Pakistan, in April 2018 with loss of consciousness, convulsions, and generalized rigidity.","A 22 year old male student, from the Sindh province of Pakistan, unmarried, presented to the emergency department of Jinnah Postgraduate Medical Centre, Pakistan, in April 2018 with loss of consciousness, convulsions, and generalized rigidity.","Modify,Grammar",Grammar
9759,8-155,8-155_v2_6@3,8-155_v1_7@3,"The patient was unresponsive to pain with bilateral reactive pupil, and there was a slightly yellow skin pigmentation of palms and soles with yellow sclera.","The patient was unresponsive to pain with bilateral reactive pupil, and there was a slight yellow skin pigmentation of palms and sole with yellow sclera.","Modify,Grammar",Grammar
9760,8-155,8-155_v2_6@4,8-155_v1_7@4,The patient was not maintaining oxygen saturation hence intubation and ventilatory support were required and so the patient was shifted to the intensive care unit.,The patient was not maintaining oxygen saturation hence intubation and ventilatory support was required and so patient was shifted to the intensive care unit.,"Modify,Grammar",Grammar
9761,8-155,8-155_v2_6@5,8-155_v1_7@5,"The abdominal exam was normal without hepatosplenomegaly or ascites, respiratory and heart sounds were audible and normal.","Abdominal exam was normal without hepatosplenomegaly or ascites, respiratory and heart sounds were audible and normal.","Modify,Grammar",Grammar
9762,8-155,8-155_v2_6@7,8-155_v1_7@7,"Laboratory parameters at that time revealed, altered liver function tests (LFTs) with Alanine Aminotransferase (ALT) 1160 u/L (reference range, 7–56 u/L); aspartate aminotransferase (AST) 225 u/L (reference range, 10–40 u/L); gamma-glutamyltransferase (GGT) 51 u/L (reference range, 9–50 u/L); alkaline phosphatase (ALP) 372 u/L (reference range, 150–480 u/L); serum albumin 4.2 g/dL (reference range, 3.5–5.5 g/dL); total bilirubin 4 mg/dL (reference range, 0.1–1.2 mg/dL); Prothrombin time (PT) 13 seconds (reference range, 11–14 seconds); and international normalized ratio (INR) 1.13 (reference range, 0.9–1.2).","Laboratory parameters at that time revealed, altered liver function tests (LFTs) with serum glutamic pyruvic transaminase (SGPT) 1160 u/L (reference range, 7–56 u/L); aspartate aminotransferase (AST) 225 u/L (reference range, 10–40 u/L); gamma-glutamyltransferase (GGT) 51 u/L (reference range, 9–50 u/L); alkaline phosphatase (ALP) 372 u/L (reference range, 150–480 u/L); serum albumin 4.2 g/dL (reference range, 3.5–5.5 g/dL); total bilirubin 4 mg/dL (reference range, 0.1–1.2 mg/dL); platelet time (PT) 13 seconds (reference range, 11–14 seconds); and international normalized ratio (INR) 13 seconds (reference range, 0.9–1.2 seconds).","Modify,Fact/Evidence",Fact/Evidence
9763,8-155,8-155_v2_2@1,8-155_v1_2@1,"In this case, we report a patient aged 22 years who was admitted with presenting complains of loss of consciousness, generalized muscle rigidity and yellowish discoloration of the skin.","In this case we report a patient aged 22 years who was admitted with presenting complains of loss of consciousness, generalized muscle rigidity and yellowish discoloration of skin.","Modify,Grammar",Grammar
9764,8-155,8-155_v2_6@8,8-155_v1_7@8,"His blood urea was 61 mg/dL (reference range, 7–20 mg/dL), serum creatinine of 1.64 (reference range, 0.6–1.2 mg/dL), with a normal serum electrolyte panel.","His blood urea was 61 mg/dl (Reference range, 7–20 mg/dL), serum creatinine of 1.64 (reference range, 0.6–1.2 mg/dL), with a normal serum electrolyte panel.","Modify,Grammar",Grammar
9765,8-155,8-155_v2_6@9,8-155_v1_7@9,"A viral screen of the patient's blood was ordered and HEV IgM and IgG was positive, with negative serology for Hepatitis A, Hepatitis B, Hepatitis C, Hepatitis D, Dengue, Typhoid, Cox-B, Epstein-Barr virus (EBV), Leptospira, Herpes simplex virus, Adenovirus, and HIV.","A viral screen of the patients blood was ordered and HEV IgM and IgG was positive, with negative serology for Hepatitis B, Hepatitis C, Hepatitis D, Dengue, Typhoid, Cox-B, Epstein-Barr virus (EBV), Leptospira, Herpes simplex virus, Adenovirus and HIV.","Modify,Fact/Evidence",Fact/Evidence
9766,8-155,8-155_v2_6@10,8-155_v1_7@10,"Blood cultures were negative, rapid malaria test was negative, labs for antinuclear antibody, anti-mitochondrial antibody, and anti-smooth muscle antibody was also negative.","Blood cultures were negative, rapid malaria test was negative, labs for antinuclear antibody, anti-mitochondrial antibody and anti-smooth muscle antibody was also negative.","Modify,Grammar",Grammar
9767,8-155,8-155_v2_6@12,8-155_v1_7@12,Patient’s blood urea and creatinine returned to normal on the second day of admission and LFTs started recovering by the fourth day.,Patient’s blood urea and creatinine returned to normal on the second day of admission and LFT’s started recovering by the fourth day.,"Modify,Grammar",Grammar
9768,8-155,8-155_v2_6@13,8-155_v1_7@13,"On the seventh day of hospitalization, the patient had normal total bilirubin with slightly raised LFTs of ALP 120 u/l, ALT 115 u/L, AST 62 u/L, GGT 68 u/L and platelet of 201×10 9 /L, leukocytes 27×10 9 /L with high-grade fever.","On the seventh day of hospitalization, the patient had normal total bilirubin with slightly raised LFT’s of ALP 120 u/l, SGPT 115 u/l, AST 62 u/l, GGT 68 u/l and platelet of 201×10 9 , leukocytes 27×10 9 with high-grade fever.","Modify,Grammar",Grammar
9769,8-155,8-155_v2_6@14,8-155_v1_7@14,"On the seventh day of admission, the patient became hypotensive with BP of 92/68 mm/Hg and a pulse of 148.",On the seventh day of admission the patient became hypotensive with BP of 92/68 mm/Hg and a pulse of 148.,"Modify,Grammar",Grammar
9770,8-155,8-155_v2_6@17,8-155_v1_7@17,"On further investigations and workups, a chest X-Ray showed bilateral pulmonary congestion at the base of the lung with cephalization of vessels.",On further investigations and workups a chest X-Ray showed bilateral pulmonary congestion at the base of the lung with cephalization of vessels.,"Modify,Grammar",Grammar
9771,8-155,8-155_v2_6@18,8-155_v1_7@18,Electrocardiography (ECG) showed nonspecific ST-segment and T-wave abnormalities with supraventricular tachycardia ( Figure 1 ).,An electrocardiography (ECG) showed nonspecific ST segment and T-wave abnormalities with supraventricular tachycardia ( Figure 1 ).,"Modify,Grammar",Grammar
9772,8-155,8-155_v2_6@21,8-155_v1_7@21,Echocardiography was performed which demonstrated impaired left ventricular function with diffuse hypokinesia without any pericardial effusion and an ejection fraction of 30 %.,Echocardiography was performed which demonstrated impaired left ventricular function with diffuse hypokinesia without any pericardial effusion and ejection fraction of 30 %.,"Modify,Grammar",Grammar
9773,8-155,8-155_v2_6@23,8-155_v1_7@23,"The patient was treated accordingly an injection of Omeprazole (40 mg once daily), 25% dextrose (as per needed), Colistimethate sodium (2 million IU thrice daily) and moxifloxacin (400 mg once daily), acyclovir (500 mg thrice daily); syrup lactulose (30 ml 6 hourly) was given nasogastrically; and patient was kept sedated with propofol.","The patient was treated accordingly an injection of Risek (40 mg once daily), 25% dextrose (as per needed), colomycin (2 million IU thrice daily) and moxifloxacin (400 mg once daily), acyclovir (500 mg thrice daily); syp duphalac (30 ml 6 hourly) was given nasogastrically; and patient was kept sedated with propofol.","Modify,Fact/Evidence",Fact/Evidence
9774,8-155,8-155_v2_10@2,8-155_v1_11@2,"Our patient contracted an acute HEV infection causing acute fulminant hepatitis leading to hepatic encephalopathy, coma, and loss of consciousness.","Our patient contracted an acute HEV infection causing acute fulminant hepatitis leading to hepatic encephalopathy, coma and loss of consciousness.","Modify,Grammar",Grammar
9775,8-155,8-155_v2_2@4,8-155_v1_3@2,"HEV infection can range from asymptomatic disease course to fulminant hepatitis but in rare cases, it has been found to be a cause of myocarditis.",HEV infection can range from asymptomatic disease course to fulminant hepatitis but in rare cases it has been found to be a cause of myocarditis.,"Modify,Grammar",Grammar
9776,8-155,8-155_v2_10@4,8-155_v1_11@4,"Myocarditis is the inflammation of the myocardium with inflammatory infiltrate, necrosis, and degeneration of myocytes in the myocardium <REF-8> .","Myocarditis is the inflammation of the myocardium with inflammatory infiltrate, necrosis and degeneration of myocytes in the myocardium <REF-8> .","Modify,Grammar",Grammar
9777,8-155,8-155_v2_10@5,8-155_v1_11@5,"Among all other causes of myocarditis, viral etiology appears to be the most common in developed countries, whereas, in developing countries, rheumatic carditis, Chagas disease, and HIV associated diseases are more common <REF-9> , <REF-10> .","Among all other causes of myocarditis, viral etiology appears to be the most common in developed countries, whereas in developing countries its rheumatic carditis, Chagas disease and HIV associated diseases are more common <REF-9> , <REF-10> .","Modify,Grammar",Grammar
9778,8-155,8-155_v2_10@7,8-155_v1_11@7,Diagnostic guidelines such as those of the American college of cardiology/American heart association and Dallas criteria provide help with early diagnosis <REF-4> .,Diagnostic guidelines such as those of American college of cardiology/American heart association and Dallas criteria provide help with early diagnosis <REF-4> .,"Modify,Grammar",Grammar
9779,8-155,8-155_v2_10@8,8-155_v1_11@8,"On eighth hospitalization day, our patient developed hypotension and distended jugular venous distension, pedal edema, bilateral pulmonary edema, and muffled heart sounds.","On eighth hospitalization day, our patient developed hypotension and distended jugular venous distension, pedal edema, bilateral pulmonary edema and muffled heart sounds.","Modify,Grammar",Grammar
9780,8-155,8-155_v2_10@12,8-155_v1_11@12,"Due to myocardial inflammation, T1 and T2 relaxation times and spin densities give accurate tissue characterization <REF-12> .",Due to myocardial inflammation T1 and T2 relaxation times and spin densities gives accurate tissue characterization <REF-12> .,"Modify,Grammar",Grammar
9781,8-160,8-160_v2_33@0,,"The prevalence of Ng and Ct has been increasing in MSM populations in a number of countries <REF-16> , <REF-17> .",,"Add,Fact/Evidence",Fact/Evidence
9782,8-160,8-160_v2_29@0,8-160_v1_29@0,No associations were found between anal or genital screening intensity and Ng or Ct prevalence in clinic populations ( Table 2 ).,No associations were found between anal or genital screening intensity and Ng prevalence in clinic populations ( Table 2 ).,"Modify,Fact/Evidence",Fact/Evidence
9783,8-160,8-160_v2_33@1,8-160_v1_33@0,Intensified screening in MSM would be one way to reduce the incidence and prevalence of these infections.,A key reason for screening for Ng and Ct in MSM is to reduce the incidence and prevalence of these infections.,"Modify,Claim",Claim
9784,8-160,8-160_v2_34@0,8-160_v1_34@0,"To deal with this bias and the fact that the ECDC Ng/Ct incidence estimates do not provide incidence estimates for MSM, we also evaluated the association between screening intensity and Ng/Ct prevalence in MSM attending STI clinics.","To deal with this bias and the fact that the ECDC Ng/Ct incidence estimates do not provide incidence estimates for MSM, we also evaluated the association in MSM attending STI clinics.","Modify,Fact/Evidence",Fact/Evidence
9785,8-160,8-160_v2_35@4,8-160_v1_35@4,"As noted above, the STI incidence estimates were for all men and were likely strongly influenced by practices such as screening intensity, access to health care and accuracy of national case reporting.","As noted above, the STI incidence estimates were for all men and were likely strongly influenced by practices such as screening intensity.","Modify,Claim",Claim
9786,8-160,8-160_v2_35@6,8-160_v1_35@6,The study design of each of the 6 studies contributing Ng and CT prevalence estimates differed somewhat further limiting the extent to which correlations could be assessed between screening intensity and prevalence across these studies.,The study design of each of the 6 studies contributing Ng and CT prevalence estimates differed somewhat further limiting the extent to which comparisons can be made between prevalence estimates derived from these studies.,"Modify,Clarity",Clarity
9787,8-160,8-160_v2_37@3,8-160_v1_37@3,"These omissions may explain the discrepancy between its prediction, and our and the earlier systematic review of observational studies <REF-11> .",These omissions may explain the discrepancy between its finding and that of the systematic review of observational studies which found that even 3-monthly screening was not associated with a decline in Ng or Ct prevalence <REF-11> .,"Modify,Claim",Claim
9788,8-160,8-160_v2_38@0,8-160_v1_38@0,"Based on the findings of this study and those reviewed here we conclude that we can still not exclude the possibility that intense screening (at least 3-site, 3-monthly) may have a small to moderate influence on Ng/Ct prevalence in MSM.","Based on the findings of this study and those reviewed here we conclude that we cannot exclude the possibility that intense screening (at least 3-site, 3-monthly) may have a small to moderate influence on Ng/Ct prevalence in MSM.","Modify,Clarity",Clarity
9789,8-160,8-160_v2_13@1,8-160_v1_13@1,- 2. Systematic review of Ng/Ct prevalence in MSM Ng/Ct prevalence estimates for MSM were taken from a published literature review of pharyngeal and anorectal Ng and Ct prevalence estimates in MSM (and other populations) <REF-15> . All studies listed in PubMed reporting prevalence of extragenital Ng and Ct in MSM up to 1 December 2015 were included. A total of 53 studies were included from countries around the world. Of these 18 were from 6 European countries ( Table 1 ). For the four European countries with more than one study we selected the study reporting prevalence estimates from 2010 or as soon after this year as possible. All selected studies were prevalence estimates established by Nucleic Acid Amplification Testing of MSM clients attending STI clinics.,- 2. Systematic review of Ng/Ct prevalence in MSM Ng/Ct prevalence estimates for MSM were taken from a published literature review of pharyngeal and anorectal Ng and Ct prevalence estimates in MSM (and other populations) <REF-15> . All studies listed in PubMed reporting prevalence of extragenital Ng and Ct in MSM up to 1 December 2015 were included. A total of 53 studies were included of which 18 were from 6 European countries ( Table 1 ). For the four European countries with more than one study we selected the study reporting prevalence estimates from 2010 or as soon after this year as possible. All selected studies were prevalence estimates established by Nucleic Acid Amplification Testing of MSM clients attending STI clinics.,"Modify,Clarity",Clarity
9823,8-1770,,8-1770_v1_21@7,,Histology slides were observed under Leica Scanscope AT2 at 0.5 µm/pixel resolution with 50 fields of view.,"Delete,Fact/Evidence",Fact/Evidence
9824,8-1770,8-1770_v2_8@7,,The mechanism needs to be investigated.,,"Add,Claim",Claim
9825,8-1770,8-1770_v2_9@3,,"However, under TNF-α stimulation at in vitro model, the MSCs can also release IL-10 as anti-inflammatory cytokine that may be a beneficial for cancer growth inhibition <REF-16> .",,"Add,Fact/Evidence",Fact/Evidence
9826,8-1770,8-1770_v2_50@4,,The changing of cell composition on tumor nodule is not clearly defined.,,"Add,Claim",Claim
9827,8-1770,8-1770_v2_16@0,8-1770_v1_16@0,"The experimental design of ECCT exposure treatments used four rat groups, six biological replicates, which consisted of:","The experimental design of ECCT exposure treatments used four rat gr6oups, six biological replicates, which consisted of:","Modify,Grammar",Grammar
9828,8-1770,8-1770_v2_18@1,8-1770_v1_18@1,The DMBA (Sigma Aldrich; cat. no. D3254-1G) administrations were done around 04 p.m. in the animal room by the technician of LPPT Research Center following the Standard Operational Procedure (SOP) for DMBA treatment animal.,The DMBA (Sigma Aldrich; cat. no. D3254-1G) administrations were done around 04 pm in the animal room by the technician of LPPT Research Center following the Standard Operational Procedure (SOP) for DMBA treatment animal.,"Modify,Grammar",Grammar
9829,8-1770,8-1770_v2_3@3,8-1770_v1_3@3,Two groups were non DMBA-induced rats without ECCT exposure (NINT) and with (NIT).,Two groups were none DMBA-induced rats without ECCT exposure (NINT) and with (NIT).,"Modify,Grammar",Grammar
9830,8-1770,8-1770_v2_18@4,8-1770_v1_18@4,Tumor nodule diameters were measured every 2 days using a digital caliper (Fisher Scientific) and all data measurements were tabulated.,Tumor nodule diameters were measured every 2 days using digital caliper (Fisher Scientific) and all data measurements were tabulated.,"Modify,Grammar",Grammar
9831,8-1770,8-1770_v2_19@1,8-1770_v1_19@1,"EF therapy was performed for 21 days, with a total exposure of 10 hours per day with 2 hours rest after first 5 hours exposure.","Therapy was performed for 21 days, with a total exposure of 10 hours per day with 2 hours rest.","Modify,Fact/Evidence",Fact/Evidence
9832,8-1770,8-1770_v2_19@2,8-1770_v1_19@2,"The starting time of ECCT treatments were at 06 to 11 a.m., then at 01 to 06 p.m.","The starting time of ECCT treatments were at 06 to 11 am, then at 01 to 06 pm.","Modify,Grammar",Grammar
9833,8-1770,8-1770_v2_19@3,8-1770_v1_19@3,"During ECCT-exposing in the individual ECCT cage (designed by Ctech Labs Edwar Teknologi, IDN Patent REG. P00201200011), rats were fed with a standard diet and cucumber ad libitum , however during rest hours, rats were fed with a standard diet and water ad libitum in a communal cage with standard bedding and feeding for 5 rats.","During ECCT-exposing in the individual ECCT cage (designed by Ctech Labs Edwar Teknologi, IDN Patent REG. P00201200011), rats were fed with cucumber ad libitum , however during rest hours, rats were fed with a standard diet and water ad libitum in a communal cage with standard bedding and feeding for 5 rats.","Modify,Fact/Evidence",Fact/Evidence
9834,8-1770,8-1770_v2_19@6,8-1770_v1_19@6,Rats were sacrificed starting at around 08 a.m. with the standard ethics procedure for rat euthanasia and surgery.,Rats were sacrificed starting at around 08 am with the standard ethics procedure for rat euthanasia and surgery.,"Modify,Grammar",Grammar
9835,8-1770,8-1770_v2_21@4,8-1770_v1_21@4,"The sample paraffin blocks were sectioned with a microtome (Microm HM 315) providing a 4–6 um thick slice, which were then placed on a slide.","The sample paraffin blocks were sectioned with microtome (Microm HM 315) providing a 4–6 um thick slice, which were then placed on a slide.","Modify,Grammar",Grammar
9836,8-1770,8-1770_v2_21@6,8-1770_v1_21@6,"The stained samples were subsequently dehydrated using an upgraded level of alcohol, cleared in xylene, and lastly, mounted with Entellan (Merck; cat. no. 1079600500) and coverslip.","The stained samples were subsequently dehydrated using upgraded level of alcohol, cleared in xylene and, lastly, mounted with Entellan (Merck; cat. no. 1079600500) and coverslip.","Modify,Grammar",Grammar
9837,8-1770,8-1770_v2_23@1,8-1770_v1_23@1,"The INT and IT tumor tissue samples were then processed using the Starr Trek Universal-HRP Detection Kit (Biocare Medical; cat.no BRR 700 AH, AL10) using the manufacturer’s protocols.","The INT and IT tumor tissues samples were then processed using the Starr Trek Universal-HRP Detection Kit (Biocare Medical; cat.no BRR 700 AH, AL10) using the manufacturer’s protocols.","Modify,Grammar",Grammar
9838,8-1770,8-1770_v2_25@0,8-1770_v1_25@0,"Quantitative-RT-PCR (qRT-PCR) was applied for measuring the transcriptomic expression (mRNA) of IL18, CCL2, TNF-α, and IL23α (due to the use of sub unit p19 fragment for primer construction) genes.","Quantitative-RT-PCR (qRT-PCR) was applied for measuring the transcriptomic expression (mRNA) of IL18, CCL2, TNF-α, and IL23α genes.","Modify,Fact/Evidence",Fact/Evidence
9839,8-1770,8-1770_v2_45@1,8-1770_v1_44@1,"The appearance of CCL2(15.29 fold change), was significantly lower (p<0.01) on solid tumor tissues of the IT group than the INT group (97.72 fold change).",The appearance of CCL2 was significantly lower on solid tumor tissues of the IT group than the INT group (p<0.01).,"Modify,Fact/Evidence",Fact/Evidence
9840,8-1770,8-1770_v2_45@2,8-1770_v1_44@2,This result was consistent with decreasing IL18 expression on tumor tissues of IT group (1.34 fold change) compared to the INT group (2.08 fold change).,This result was consistent with decreasing IL18 expression on tumor tissues of IT group compared to the INT group.,"Modify,Fact/Evidence",Fact/Evidence
9841,8-1770,8-1770_v2_7@3,8-1770_v1_7@3,"Moreover, Mujib et al . <REF-2> suggested that ECCT exposure (100–200 kHz) might induce p53 expression in cancer cells, such as oral squamous cell carcinoma, HeLa, and bone marrow mesenchymal cells.","Moreover, Mujib et al . <REF-2> suggested that ECCT exposure (100–200 kHz) might induce p53 expression in cancer cells, such as oral squamous cell carcinoma, HeLa, and bone marrow mesenchyme cells.","Modify,Grammar",Grammar
9842,8-1770,8-1770_v2_50@6,8-1770_v1_49@5,Tumors treated with ECCT had a lower number (unseen data) of mitotic figures than the sham tumor treatment.,Tumors treated with ECCT had a lower number of mitotic figures than the sham tumor treatment.,"Modify,Fact/Evidence",Fact/Evidence
9843,8-1770,8-1770_v2_50@7,8-1770_v1_49@6,"Indeed, the apoptotic figures on tumor tissues with therapy were higher (unseen data) than non-therapy tissues ( Figure 2E and F ).","Indeed, the apoptotic figures on tumor tissues with therapy were higher than non-therapy tissues ( Figure 2E and F ).","Modify,Fact/Evidence",Fact/Evidence
9844,8-1770,8-1770_v2_53@2,8-1770_v1_52@2,"The present study shows that the percentage of breast tumor cells expressing caspase 3 (effector caspase) in the IT group is higher than in the INT group ( Figure 3E, F and K ).","The present study shows that the percentage of breast tumor cells expressing Caspase 3 (effector caspase) in the IT group is higher than in the INT group ( Figure 3E, F and K ).","Modify,Grammar",Grammar
9845,8-1770,8-1770_v2_54@2,8-1770_v1_53@2,"The current study ( Figure 3 G, H, and L ) showed increasing expression of CD68 (a marker for macrophage and monocyte) on breast tumors exposed to ECCT (IT group), which was significantly higher than non-EF therapy (INT).","The current study ( Figure 3 G, H, and L ) showed increasing expression of CD68 (a classical macrophage marker) on breast tumors exposed to ECCT (IT group), which was significantly higher than non-therapy (INT).","Modify,Fact/Evidence",Fact/Evidence
9846,8-1770,8-1770_v2_55@7,8-1770_v1_54@7,"Additionally, IL18 and IL10 act synergistically on angiogenesis progression <REF-8> .","Additionally, IL18 and IL10 act synergistically on t angiogenesis progression <REF-8> .","Modify,Grammar",Grammar
9847,8-1770,8-1770_v2_58@0,8-1770_v1_57@0,"In conclusion, we propose that noncontact ECCT treatment could have an anti-proliferative effect on solid breast tumor via the down-regulated expression of CCL2 and IL18.","In conclusion, we purpose that noncontact ECCT treatment could have an anti-proliferative effect on solid breast tumor via the down-regulated expression of CCL2 and IL18.","Modify,Grammar",Grammar
9848,8-1770,8-1770_v2_8@1,8-1770_v1_8@1,"Stromal components, such as endothelial cells, myeloid derivate suppressor cells, and macrophages, reside in the solid tumor microenvironment <REF-6> .","Stromal components, such as endothelial cells, myeloid derivate suppressor cells and macrophages, reside in the solid tumor microenvironment <REF-6> .","Modify,Grammar",Grammar
9849,8-1770,8-1770_v2_8@2,8-1770_v1_8@2,"Macrophages act as inflammatory cells that can be affected by chemical signals, i.e. cytokines and chemokines <REF-7> , <REF-8> , and electric fields <REF-9> .","Macrophages and tumor cells act as inflammatory cells that can be affected by chemical signals, i.e. cytokines and chemokines <REF-7> , <REF-8> , and electric fields <REF-9> .","Modify,Fact/Evidence",Fact/Evidence
9850,8-1770,8-1770_v2_9@2,8-1770_v1_9@2,"However, in the following years, recent studies reported that TNF-α significantly induces breast cancer metastasis via TNFα-activated mesenchymal stem cells (MSCs) in a lung metastasis model of murine breast cancer <REF-13> – <REF-15> .","However, in the following years, recent studies reported that TNF-α significantly induces breast cancer metastasis via TNFα-activated mesenchyme stem cells (MSCs) in a lung metastasis model of murine breast cancer <REF-13> – <REF-15> .","Modify,Grammar",Grammar
9851,8-1770,8-1770_v2_9@6,8-1770_v1_9@5,"Tumor-associated macrophages (TAMs) help tumor cell growth by releasing several pro-inflammatory cytokines, such as TNFα and IL23 <REF-17> .","Tumor-associated macrophages (TAMs) help tumor cell growth by releasing several pro-inflammatory cytokines, such as TNFα and IL23, which are expressed by the classically activated M1 macrophage <REF-16> .","Modify,Fact/Evidence",Fact/Evidence
9852,8-1770,8-1770_v2_9@9,8-1770_v1_9@8,"On the other hand, Zimolag et al. <REF-21> reported that direct current (DC)-EF in the physiological condition might reposition MCSs into a wound site and allow macrophages to be at a short distance to the wound.","On the other hand, Zimolag et al. <REF-19> reported that direct current (DC)-EF in the physiological condition might reposition MCSs into a wound site and allow macrophages to be at short distance to the wound.","Modify,Grammar",Grammar
9853,8-1770,8-1770_v2_9@10,8-1770_v1_9@9,"Therefore, the expression of either TNFα or IL-23 cytokines-produced inflammatory cells in the microenvironment of solid breast tumor during the physiological DC-EF or AC-EF need to be further examined.","Therefore, the expression of either TNFα or IL-23α cytokines-produced inflammatory cells in the microenvironment of solid breast tumor during the physiological DC-EF or AC-EF need to be further examined.","Modify,Fact/Evidence",Fact/Evidence
9854,8-1770,8-1770_v2_10@3,8-1770_v1_10@3,"A recent study demonstrated that TTFields therapy activates macrophage specific immune responses through the activation of several cytokines, such as TNF-α, and IL1-β in vitro <REF-10> .","A recent study demonstrated that TTFields therapy activates macrophage specific immune responses through the activation of several cytokines, such as NF-kB (nuclear factor-kB), TNF-α, and IL1-β in vitro <REF-10> .","Modify,Fact/Evidence",Fact/Evidence
9855,8-1770,8-1770_v2_13@3,8-1770_v1_13@3,"The rat number for this experimental design was calculated for the minimal biological replication of rats (n=6), with four treatment groups according to the Federer Formula <REF-23> .","The rat number for experimental design was calculated for the minimal biological replication of rats, with four treatment groups according to the Federer Formula <REF-21> .","Modify,Fact/Evidence",Fact/Evidence
9856,8-1770,8-1770_v2_15@1,8-1770_v1_15@1,"Therefore, we only observed the minimal number of tissue samples required for replication; three tissues samples (n=3) per treatment group (4 groups) was used for biological replication.","Therefore, we only observed the minimal number of tissue samples required for replication; three tissues samples per treatment group (4 groups) was used for biological replication.","Modify,Fact/Evidence",Fact/Evidence
9857,8-1775,8-1775_v2_4@8,,"However, this information can be crucial when the goal is to study the molecular composition of individual cells in the context of spatial location, for example, in the context of primary cancer cells research <REF-3> .",,"Add,Fact/Evidence",Fact/Evidence
9858,8-1775,8-1775_v2_5@6,,In this paper we present a procedure for solving the cell-position problem posed in the DREAM SCTC.,,"Add,Fact/Evidence",Fact/Evidence
9859,8-1775,8-1775_v2_5@7,,"This challenge consists of predicting the positions of individual cells, based on an expression reference atlas and a small set of genes reported in single-cell studies.",,"Add,Fact/Evidence",Fact/Evidence
9860,8-1775,8-1775_v2_15@2,8-1775_v1_15@2,"The 20, 40 and 60 selected genes used for each cell location prediction task are listed in Table S1 (see Extended data ); we also include the outgroup set of genes.","The 20, 40 and 60 selected genes used for each cell location prediction task were listed in Table S1 (see Extended data ); we also include the out group set.","Modify,Grammar",Grammar
9861,8-1775,8-1775_v2_17@1,8-1775_v1_17@1,"One of these measures is the MCC computed between the binarized expression profiles, as proposed in <REF-7> .","One of these measures is the Matthews correlation coefficient (MCC) computed between the binarized expression profiles, as proposed in <REF-7> .","Modify,Clarity",Clarity
9862,8-1775,8-1775_v2_17@2,8-1775_v1_17@2,"The MCC will be used in the initial step to assign putative bin positions for each single cell, and then to predict the spatial expression profile of the outgroup set of genes.",The MCC will be used in the initial step to assign putative bin positions for each single cell and then to predict the spatial expression profile of the outgroup genes.,"Modify,Clarity",Clarity
9863,8-1775,8-1775_v2_17@3,8-1775_v1_17@3,"The other measure is the overlap between the normalized expression vector of the single cells, and the projected vector corresponding to the predicted spatial expression profile.","The other measure is the overlap between the normalized expression vector of single cells, and the projected vector corresponding to the predicted spatial expression profile.","Modify,Grammar",Grammar
9864,8-1775,8-1775_v2_17@4,8-1775_v1_17@4,This vectorial space corresponds to the one spanned by the outgroup set of genes only.,This vectorial space corresponds to the one spanned by the outgroup genes only.,"Modify,Clarity",Clarity
9865,8-1775,8-1775_v2_21@1,8-1775_v1_21@1,"In the first step we select the set of N genes from the 84 driver genes to be used in the prediction, using the method described in Selection of the gene sets section.",In the first step we select the set of N genes from the 84 driver genes to be used in the prediction using the method described in Selection of the gene sets section.,"Modify,Grammar",Grammar
9866,8-1775,8-1775_v2_21@2,8-1775_v1_21@2,"We also select an additional 100 genes (outgroup set of genes) from all genes measured in the sc-RNAseq experiment, but excluding the driver genes.","We also select an additional 100 genes (outgroup genes) from all genes measured in the sc-RNAseq experiment, but excluding the driver genes.","Modify,Clarity",Clarity
9867,8-1775,8-1775_v2_21@4,8-1775_v1_21@4,"Then, using the binarized expression data of the selected genes, we compute the MCC (measure 1) for each binarized single-cell vector against the 3039 binarized vectors associated with each positional bin of the reference atlas (BDTNP).","Then, using the binarized expression data of the selected genes we compute the MCC (measure 1) for each binarized single-cells vector against the 3039 binarized vectors associated with each positional bin of the reference atlas (BDTNP).","Modify,Grammar",Grammar
9868,8-1775,8-1775_v2_21@5,8-1775_v1_21@5,"By means of the MCC-based score, we predict the single-cell positions and build the putative expression patterns of the outgroup set of genes.",By means of the MCC-based score we predict the single cell positions and build the putative expression patterns of the outgroup set of genes.,"Modify,Grammar",Grammar
9869,8-1775,8-1775_v2_21@6,8-1775_v1_21@6,"In this sense, the expression level of gen g at the bin position i is given by the weighted average of the normalized gene expression across 10 putative positions corresponding to that bin, being the weight proportional to the associated MCC.","In this sense, the expression level of gen g at the bin position i is given by the weighted average of the normalized gene expression across N putative positions corresponding to that bin, being the weight proportional to the associated MCC.","Modify,Fact/Evidence",Fact/Evidence
9870,8-1775,8-1775_v2_21@7,8-1775_v1_21@7,"Mathematically, e i g = ∑ j * c i j e j g , where c ij are the MCC-based scores of the single cell j against position i , and e i g are the expression levels of gene g recorded in the individual cells j .","Mathematically, e i g = ∑ j * c i j e j g , where c i j are the MCC-based scores of the single cell j against position i and e g j are the expression levels of gene g recorded in the individual cells j .","Modify,Grammar",Grammar
9871,8-1775,8-1775_v2_21@8,8-1775_v1_21@8,The asterisk in the summation indicates that the 10 first better scored cells positions are included.,The asterisk in the summation indicates that the first better scored N cells are included.,"Modify,Fact/Evidence",Fact/Evidence
9872,8-1775,8-1775_v2_21@9,8-1775_v1_21@9,The predicted expression patterns of the outgroup set of genes computed in this manner are used to compute the overlap (measure 2) with the corresponding expression level of each one of the 1297 single cells.,The predicted expression patterns computed in this manner are used to compute the overlap (measure 2) with the corresponding expression level of each one of the 1297 single cells.,"Modify,Clarity",Clarity
9873,8-1775,8-1775_v2_21@10,8-1775_v1_21@10,"Finally, using the measure 1 and the measure 2 we compute a composed score S , defined as S = w 1 ∗ c + w 2 ∗ o , where c is MCC-based score, o is the overlap-based score, and w 1 and w 2 are the respective weights.","Finally, using the measure 1 and measure 2 we compute a composed score S , defined as S = w 1 * c + w 2 * o , where c is MCC-based score, o is overlap-based score and w 1 and w 2 are the respective weights.","Modify,Grammar",Grammar
9874,8-1775,8-1775_v2_21@12,8-1775_v1_21@12,"The last two steps are repeated (2 or 3 times), as indicated in Figure 3 with dashed arrows.","The last two steps are repeated (2 or 3 times), as indicated in Figure 3 by dashed arrows.","Modify,Grammar",Grammar
9875,8-1775,8-1775_v2_4@2,8-1775_v1_4@2,"These approaches allow quantification of gene expression in many cells but, unfortunately, these techniques can currently be assayed only over a small number of genes.","These approaches allow quantification of gene expression in many cells but, unfortunately, these techniques can currently only be assayed to a small number of genes.","Modify,Clarity",Clarity
9876,8-1775,8-1775_v2_24@0,8-1775_v1_24@0,"The above scheme is applied to the subchallenges with 20, 40 and 60 genes using different weight values.","The above scheme was applied to the Sub-challenges with 20, 40 and 60 genes using different values of the weights.","Modify,Grammar",Grammar
9877,8-1775,8-1775_v2_24@1,8-1775_v1_24@1,"First of all, we apply the procedure to the subchallenge 3.",In the first example we apply the procedure to the Sub-challenge 3 and using the 20 genes we compute the MCC for every cell-bin combination.,"Split+Modify,Clarity",Clarity
9879,8-1775,8-1775_v2_24@6,8-1775_v1_24@5,"The score combining both measures is then used to predict the positions of each single cell, which leads to a performance of 36% in the second iteration, and 38% in the third iteration.","The score combining both measures is then used to predict the positions of each single cell, which leads to a performance of 36% in the second iteration and 38% in the third iteration.","Modify,Grammar",Grammar
9880,8-1775,8-1775_v2_24@7,8-1775_v1_24@6,Further iteration steps do not produce any additional improvement.,Further iteration steps does not produce any additional improvement.,"Modify,Grammar",Grammar
9881,8-1775,8-1775_v2_4@3,8-1775_v1_4@3,The selection of these genes introduces a bias that limits the power of these studies.,The selection of these genes introduce a bias that limits the power of these studies.,"Modify,Grammar",Grammar
9882,8-1775,8-1775_v2_27@0,8-1775_v1_25@0,"In order to select the set of 60 genes to be used in subchallenge 1, from the 84 genes available in the reference atlas, we perform the above-mentioned agglomerative clustering procedure.","To select the set of 60 genes to be used in subchallenge 1, from the 84 genes available in the reference atlas, we perform the above mentioned agglomerative clustering procedure.","Modify,Clarity",Clarity
9883,8-1775,8-1775_v2_27@5,8-1775_v1_25@5,"In this case, the used scoring measure was composed by MCC with a weight of 0.90; and the overlap of the single-cell expression profiles and the 3039 positions of the predicted expression patterns obtained in the previous step, with a weight of 0.10.","In this case the used scoring measure was composed by MCC with a weight of 0.90, and the overlap, with a weight of 0.10, of the single-cell expression profiles and the 3039 positions of the predicted expression patterns obtained in the previous step.","Modify,Clarity",Clarity
9884,8-1775,8-1775_v2_27@6,8-1775_v1_25@6,After two iterations the performance obtained is 95.4%.,"After two iterations the performance obtained was 95.4%, Figure 4B shows the predicted expression pattern of the ftz gene obtained using the set of 60 genes.","Split+Modify,Grammar",Grammar
9886,8-1775,8-1775_v2_27@8,8-1775_v1_25@7,The same procedure is used to predict the positions of single cells by considering a set of 40 genes.,The same procedure was used to predict the positions of single cells by considering a set of 40 genes.,"Modify,Grammar",Grammar
9887,8-1775,8-1775_v2_27@9,8-1775_v1_25@8,"Again, these genes are selected as described in Methods.","Again, these genes were selected as described in Methods.","Modify,Grammar",Grammar
9888,8-1775,8-1775_v2_27@11,8-1775_v1_25@10,"In this case, the performance obtained reaches 71.4%.",In this case the performance obtained reaches 71.4%.,"Modify,Grammar",Grammar
9889,8-1775,8-1775_v2_29@3,8-1775_v1_29@3,"For example, the Jaccard distance <REF-10> could be used in the clustering procedure instead of the Euclidean distance.","For example, the Jaccard distance could be used in the clustering procedure instead of the Euclidean distance.","Modify,Fact/Evidence",Fact/Evidence
9890,8-1775,8-1775_v2_29@7,8-1775_v1_29@7,"Last but not least, the third innovation is the iterative procedure, which improves the performance of any of the alternative strategies presented here.","Last but not least, the third innovation is the iterative procedure which improves the performance of any of the alternative strategies presented here.","Modify,Grammar",Grammar
9891,8-1775,8-1775_v2_4@7,8-1775_v1_4@7,Removing cells from their native context results in the loss of spatial information.,Separating cells from their native context results in the loss of spatial information.,"Modify,Clarity",Clarity
9892,8-1775,8-1775_v2_4@9,8-1775_v1_4@9,"Fortunately, some progress has been made to overcome limitations of spatial information loss associated to this technique.","However, some progress has been made to overcome limitations of spatial information loss associated to this technique.","Modify,Clarity",Clarity
9893,8-1775,8-1775_v2_4@11,8-1775_v1_4@11,"More recently, several computational techniques coupled to in situ RNA patterns facilitate this reconstruction with better resolution <REF-5> – <REF-7> .","More recently several computational techniques, coupled to in situ RNA patterns facilitate this reconstruction with better resolution <REF-5> – <REF-7> .","Modify,Grammar",Grammar
9894,8-1775,8-1775_v2_5@4,8-1775_v1_5@4,"In subchallenge 1 the prediction must be performed using 60 driver genes out of 84 genes, in subchallenge 2 using a subset of any expression patterns from 40 genes out of the 84, and in subchallenge 3 using a subset of any expression patterns from only 20 driver genes.","In subchallenge 1, the prediction must be performed using 60 driver genes out of 84 genes; subchallenge 2, using a subset of any expression patterns from 40 genes out of the 84; subchallenge 3, using a subset of any expression patterns from only 20 driver genes.","Modify,Clarity",Clarity
9895,8-1775,8-1775_v2_8@4,8-1775_v1_8@4,"These data were next binarized <REF-7> , sorted in the same order of cell location, and listed in an additional file (binarized_bdtnp.csv at DVEX server).","These data were binarized following <REF-7> , sorted in the same order of cell location, and listed in an additional file (binarized_bdtnp.csv at DVEX server).","Modify,Clarity",Clarity
9896,8-1775,8-1775_v2_8@5,8-1775_v1_8@5,"The single-cell RNA sequencing data is provided as a matrix with 8924 genes as rows, and 1297 cells as columns.",The single-cell RNA sequencing data is provided as a matrix with 8924 genes as rows and 1297 cells as columns.,"Modify,Grammar",Grammar
9897,8-1775,8-1775_v2_8@8,8-1775_v1_8@8,"The normalized values are also binarized, i.e. a given gene is ON (OFF) if the normalized values are above (below) of a quantile value.","The normalized values are also binarized, i.e., a given gene is ON (OFF) if the normalized values are above (below) of a quantile value.","Modify,Grammar",Grammar
9898,8-1775,8-1775_v2_2@2,8-1775_v1_2@2,"With the purpose of developing new algorithms, the Dialogue for Reverse Engineering Assessments and Methods (DREAM) consortium organized a crowd-sourced competition known as DREAM Single Cell Transcriptomics Challenge (SCTC).","To develop new algorithms for this purpose, the Dialogue for Reverse Engineering Assessments and Methods (DREAM) consortium organized a crowd-sourced competition known as DREAM Single Cell Transcriptomics Challenge (SCTC).","Modify,Clarity",Clarity
9899,8-1775,8-1775_v2_8@11,8-1775_v1_8@11,Both normalized as well as binarized data were provided by the DREAM Challenge.,"Both normalized, as well as binarized, data were provided by the DREAM Challenge.","Modify,Grammar",Grammar
9900,8-1775,8-1775_v2_11@0,8-1775_v1_11@0,"- (i) Genes that have complementary expression patterns across the single-cell population. It is well known that many genes are co-expressed, that is, their expression profiles are highly correlated. This correlation introduces a degree of redundancy in the expression matrix, which frequently is reduced by clustering those genes with similar expression profiles. This step allows us to identify genes with complementary expression patterns.",- (i) Genes that have complementary expression patterns across the single-cell population.,"Modify,Claim",Claim
9901,8-1775,8-1775_v2_11@1,8-1775_v1_11@1,"- (ii) Genes with expression levels broadly distributed across the single-cell population. This step is performed in order to select one gene per cluster. Those genes with many null expression values over a large part of the population are discarded, because they are associated with distributions with a large peak at zero.",- (ii) Genes with expression levels broadly distributed across the single-cell population.,"Modify,Fact/Evidence",Fact/Evidence
9902,8-1775,8-1775_v2_12@3,8-1775_v1_12@3,"Next, we need to select only one gene per cluster.","This step allows us to identify genes, or cluster of genes, with complementary expression patterns; however, we need to select only one gene per cluster.","Modify,Claim",Claim
9903,8-1775,8-1775_v2_12@7,8-1775_v1_12@7,"After that, we compute the associated entropy H = –   ∑ i p i 1 n p i .","After that, we compute the associated entropy S = ∑ i N p i In p i .","Modify,Fact/Evidence",Fact/Evidence
9904,8-1775,8-1775_v2_12@8,8-1775_v1_12@8,"Then, we select the gene with the greatest entropy in each cluster, i.e. the gene within the cluster with the broadest expression distribution across the single-cell population.","Then we select the gene with the greatest entropy in each cluster, i.e., the gene within the cluster with the broadest expression distribution across the single-cell population.","Modify,Grammar",Grammar
9905,8-1775,8-1775_v2_2@3,8-1775_v1_2@3,"Within this context, we describe here our proposed procedures for adequate reference genes selection, and an iterative procedure to predict spatial expression profile of other genes.","In the spirit of this framework, we describe here the proposed procedures for adequate reference genes selection, and an iterative procedure to predict spatial expression profile of other genes.","Modify,Clarity",Clarity
9906,8-1775,8-1775_v2_12@11,8-1775_v1_12@11,"For comparison, we consider the Mathews correlation coefficient (MCC) <REF-10> between the 1297 cells and the 3039 bins.","For comparison we consider the Mathews correlation coefficient (MCC) between the 1297 cells and the 3039 bins, the ten better scored bins are selected as putative position for each cell.","Split+Modify,Fact/Evidence",Fact/Evidence
9907,8-1775,8-1775_v2_12@12,8-1775_v1_12@11,"Then, the ten better scored bins are selected as putative position for each cell.","For comparison we consider the Mathews correlation coefficient (MCC) between the 1297 cells and the 3039 bins, the ten better scored bins are selected as putative position for each cell.","Split+Modify,Clarity",Clarity
9908,8-1775,8-1775_v2_12@13,8-1775_v1_12@12,"As the true positions of the cells are not available, we take the bin with the highest MCC, obtained with the set that include all 84 genes, as the bin associated with the true position.","As the true positions of the cells is not available, we take the bin with the highest MCC, obtained with the set that include all 84 genes, as the bin associated with the true position.","Modify,Grammar",Grammar
9909,8-1775,8-1775_v2_12@14,8-1775_v1_12@13,"Thus, we count cells with the ten best scores containing the true position as cells whose positions are well predicted.","Thus, we count cells with ten best scores containing the true position as cells whose positions are well predicted.","Modify,Grammar",Grammar
9910,8-1775,8-1775_v2_12@17,8-1775_v1_12@16,"In all cases, this percentage is quite lower than that obtained with 20 genes selected as indicated above, which is 33.46%.","In all cases this percentage is quite lower than that obtained with 20 genes selected as indicated above, which is 33.46%.","Modify,Grammar",Grammar
9911,8-1775,8-1775_v2_15@0,8-1775_v1_15@0,"We use this procedure to select an additional set of 100 genes from the 8924 genes measured by the single-cell technique, but excluding the genes from the 84 reference gene set.","We use this procedure to select an additional set of 100 genes from the 8924 genes measured by single-cell technique, but excluding the genes from the 84 reference gene set.","Modify,Grammar",Grammar
9912,8-182,8-182_v2_2@3,,"The heart rate was 114 beats/min, and blood pressure was 106/90 mmHg.",,"Add,Fact/Evidence",Fact/Evidence
9913,8-182,8-182_v2_11@5,,"Also, the detailed examination (including Homan’s and Moses sign) was performed and was deemed unremarkable.",,"Add,Fact/Evidence",Fact/Evidence
9914,8-182,8-182_v2_17@4,,"Trop I levels testing was not available at our centre and hence, was not done.",,"Add,Fact/Evidence",Fact/Evidence
9915,8-182,8-182_v2_19@10,,"The patient was most satisfied with the treatment and the recovery he’d made, but this was not recorded in a form of any official questionnaire (but he had mentioned this verbally).",,"Add,Fact/Evidence",Fact/Evidence
9916,8-182,8-182_v2_20@0,,"The patient had followed up in our center for the first three months, following which relocated to Uttar Pradesh, India (his hometown).",,"Add,Fact/Evidence",Fact/Evidence
9917,8-182,8-182_v2_20@1,,He experienced no side effects of Rivaroxaban.,,"Add,Fact/Evidence",Fact/Evidence
9918,8-182,8-182_v2_20@2,,"At three months of post discharge, a lower limb doppler was repeated which showed more than 50% reduction in size of the obstructing thrombus as compared to the previous one done at admission.",,"Add,Fact/Evidence",Fact/Evidence
9919,8-182,8-182_v2_20@3,,"Post three months of discharge, the patient has not returned back yet and has been lost to follow up.",,"Add,Fact/Evidence",Fact/Evidence
9920,8-182,8-182_v2_26@1,8-182_v1_25@1,"Apart from history, family members needs to be screened for coagulopathy or asymptomatic VTE, which was not done in this case.","Apart from history, family members need to be screened for coagulopathy or asymptomatic VTE, which was not done in this case.","Modify,Grammar",Grammar
9921,8-182,8-182_v2_26@6,8-182_v1_25@6,"Our patient refused to give consent for doing a thrombophilia profile, hence the procedure was not done.","Our patient gave a negative consent for doing a thrombophilia profile, hence the procedure was not done.","Modify,Clarity",Clarity
9922,8-182,8-182_v2_29@0,8-182_v1_28@0,Silent VTE can develop into PE which may remain unrecognised for a long time before the clinical features develop.,Silent VTE can develop into PE which may be unrecognized for a long time before the clinical features develop.,"Modify,Grammar",Grammar
9923,8-182,8-182_v2_6@1,8-182_v1_6@1,It leads to 100 000 deaths annually globally.,It leads to 100 000 deaths annually.,"Modify,Clarity",Clarity
9924,8-182,8-182_v2_0@0,8-182_v1_0@0,Case Report: Unprovoked venous thromboembolism in a young adult male,Case Report: Unprovoked venous thromboembolism in a young adult,"Modify,Other",Other
9925,8-182,8-182_v2_10@1,8-182_v1_10@1,The patient also denied having any addiction history.,The patient also denied any addiction history.,"Modify,Grammar",Grammar
9926,8-182,8-182_v2_2@4,8-182_v1_2@3,Electrocardiogram showed tachycardia with S 1 Q 3 T 3 pattern.,The Electrocardiogram showed tachycardia with S 1 Q 3 T 3 pattern.,"Modify,Grammar",Grammar
9927,8-182,8-182_v2_17@2,8-182_v1_17@2,The patient had mild hyperuricemia with serum uric acid level being 7.4 mg/dL (Normal: 3.5 – 7.2 mg/dL).,The patient had mild hyperuricemia with serum uric acid level being 7.4 mg/dL (Normal – 3.5 – 7.2 mg/dL).,"Modify,Grammar",Grammar
9928,8-182,8-182_v2_24@1,8-182_v1_23@1,"A young man with sudden chest pain and dyspnea without any leg pain and who is otherwise healthy, is likely to be mismanaged, as suspicion of developing pulmonary or venous thrombo-embolism is quite low.","A young man with sudden chest pain and dyspnea without any leg pain and who is otherwise healthy, is likely to be mismanaged, as suspicion of pulmonary or venous thrombo-embolism is quite low.","Modify,Clarity",Clarity
9929,8-1874,,8-1874_v1_6@1,,"FastQC has been cited over 3,000 times, with citations increasing steadily since its introduction.","Delete,Claim",Claim
9930,8-1874,,8-1874_v1_45@0,,Falco scales for longer Nanopore reads,"Delete,Other",Other
9931,8-1874,,8-1874_v1_46@0,,Nanopore sequencing is gaining popularity in genome assembly applications and as a low-cost protocol to quantify short reads <REF-26> .,"Delete,Fact/Evidence",Fact/Evidence
9932,8-1874,,8-1874_v1_46@1,,"Nanopore sequencers can generate reads of up to millions of bases, and assessing quality metrics for these datasets is fundamental to test for potential problems in quality or bias in specific regions of such long reads.","Delete,Claim",Claim
9933,8-1874,,8-1874_v1_46@2,,"While FastQC is capable of making summaries for protocols such as 454 <REF-27> PacBio <REF-28> , which generate sequences with around 10,000 bases per read, we have observed that it does not run to completion when given files with larger reads of over 100,000 bases.","Delete,Fact/Evidence",Fact/Evidence
9934,8-1874,,8-1874_v1_46@3,,Files for which FastQC ’s analysis does not finish are marked with an asterisk in Table 3 and Table 4 .,"Delete,Fact/Evidence",Fact/Evidence
9935,8-1874,,8-1874_v1_46@4,,"Falco successfully completes its analysis on these datasets, demonstrating that it can equally be used as a QC tool for longer reads.","Delete,Claim",Claim
9936,8-1874,8-1874_v2_5@1,,The QC step measures a set of statistics in a file of sequenced reads to assess if its content matches the experiment expectations and if the data is suitable for downstream analysis.,,"Add,Claim",Claim
9937,8-1874,8-1874_v2_5@2,,"Common QC tests include counting relative frequency of nucleotides in each position of a set of reads to detect potential deviations from expected frequencies, summarizing the distribution of Phred <REF-10> quality scores to identify base positions with globally low quality (suggesting degeneration in the sequencing process), and measuring the frequency of sequencing adapters and contaminants that are not expected to be biological DNA from the sample.",,"Add,Claim",Claim
9938,8-1874,8-1874_v2_7@2,,FastQC reports ten analysis modules that summarize the content of a sequencing file ( Table 1 ).,,"Add,Fact/Evidence",Fact/Evidence
9939,8-1874,8-1874_v2_7@3,,"An input file may pass or fail the tests run in each module, and high-quality sequencing data from most protocols is expected to pass all tests.",,"Add,Claim",Claim
9940,8-1874,8-1874_v2_13@2,,"While the text outputs are comparable to FastQC , Falco also provides more flexible interaction with graphical plots in its HTML report using the same visualization standards set by FastQC .",,"Add,Claim",Claim
9941,8-1874,8-1874_v2_16@0,,Falco <REF-14> is an Open Source C++ implementation of the FastQC software tool built for UNIX-based operating systems.,,"Add,Fact/Evidence",Fact/Evidence
9942,8-1874,8-1874_v2_16@5,,Falco is intended to be used in a command-line environment.,,"Add,Fact/Evidence",Fact/Evidence
9943,8-1874,8-1874_v2_16@6,,"Unlike FastQC , Falco cannot be run through a graphical user interface.",,"Add,Fact/Evidence",Fact/Evidence
9944,8-1874,8-1874_v2_27@0,,System requirements,,"Add,Other",Other
9945,8-1874,8-1874_v2_28@0,,"Falco requires little memory and disk space to run, and there are no constraints on the minimum or maximum FASTQ input size or number of reads.",,"Add,Fact/Evidence",Fact/Evidence
9946,8-1874,8-1874_v2_28@1,,"Reads are analyzed sequentially, with one read stored in memory at a time, so the amount of memory necessary to run depends on the largest read length in a dataset, but not on the size of the input file.",,"Add,Fact/Evidence",Fact/Evidence
9947,8-1874,8-1874_v2_28@2,,"For instance, processing a short-read sample, with reads of length at most 1000 bases, requires 100 MB of available RAM, whereas processing a long-read sample containing at least one read with 1 million bases require 500 MB of RAM.",,"Add,Fact/Evidence",Fact/Evidence
9948,8-1874,8-1874_v2_28@3,,The total disk space necessary to store the three output files generated by Falco is no more than 1 MB.,,"Add,Fact/Evidence",Fact/Evidence
9949,8-1874,,8-1874_v1_12@2,,"We also present example datasets from the public domain where FastQC fails to generate reports even when run on high-performance computing hardware, demonstrating that falco expands the range of possible cases in which these quality control metrics can be applied.","Delete,Fact/Evidence",Fact/Evidence
9950,8-1874,8-1874_v2_46@0,,The memory required to run Falco differs between short-read samples (tests 1-8; Table 2 ) and long-read samples (tests 9-11).,,"Add,Fact/Evidence",Fact/Evidence
9951,8-1874,8-1874_v2_46@1,,"All programs demonstrated similar behavior in memory usage, with all short-read samples having similar memory requirements, and test 10 requiring the most memory (as it contains the longest read).",,"Add,Fact/Evidence",Fact/Evidence
9952,8-1874,8-1874_v2_46@2,,The total memory usage was also measured by GNU time command.,,"Add,Fact/Evidence",Fact/Evidence
9953,8-1874,8-1874_v2_46@3,,"For Falco , short-read samples required 92 MB of RAM, whereas long-read samples used at most 342 MB of RAM.",,"Add,Fact/Evidence",Fact/Evidence
9954,8-1874,8-1874_v2_46@4,,"In short-read samples, FastQC and fastp used 319 MB and 568 MB of RAM, respectively.",,"Add,Fact/Evidence",Fact/Evidence
9955,8-1874,8-1874_v2_46@5,,"In long-read samples, FastQC and fastp used at most 4.88 GB and 1.28 GB of RAM, respectively.",,"Add,Fact/Evidence",Fact/Evidence
9956,8-1874,8-1874_v2_46@6,,This comparison suggests that Falco ’s memory requirement is also the lowest across all tests.,,"Add,Claim",Claim
9957,8-1874,8-1874_v2_57@0,,"Users may report errors, bugs, installation problems, and improvement suggestions in the same page provided to download the source code under the “issues” section.",,"Add,Claim",Claim
9958,8-1874,8-1874_v2_26@0,8-1874_v1_26@0,"Default configuration files are contained in a Configuration directory that is included with the program, but Falco also allows users to manually define the thresholds to pass or fail each module, the list of adapters to search for in reads, and the list of contaminants to compare with overrepresented sequences by using configuration files in the same format used by FastQC .","Default configuration files are contained in a Configuration directory that is included with the program, but falco also allows users to manually define the thresholds for statistics to be considered a pass, warning or fail, the list of adapters to search for in reads and the list of contaminants to check overrepresented sequences by using configuration files in the same format used by FastQC .","Modify,Fact/Evidence",Fact/Evidence
9959,8-1874,8-1874_v2_31@0,8-1874_v1_29@0,We compared the output of Falco <REF-14> to its FastQC counterpart using 11 datasets ( Table 2 ).,We compared the output of falco <REF-13> to its FastQC counterpart using 11 datasets ( Table 2 ).,"Modify,Grammar",Grammar
9960,8-1874,8-1874_v2_31@1,8-1874_v1_29@1,"The tests consist of Illumina files originating from a range of different library preparation protocols for DNA, RNA, and epigenetic experiments, as well as reads from the nanopore <REF-17> technology.","The tests consist of Illumina files originating from a range of different library preparation protocols for DNA, RNA and epigenetic experiments, as well as reads from the nanopore <REF-16> technology.","Modify,Grammar",Grammar
9961,8-1874,8-1874_v2_31@2,8-1874_v1_29@2,"For simplicity, Illumina paired-end datasets were only tested on the first read end.","For simplicity, Illumina paired-end datasets were only tested on their first read.","Modify,Clarity",Clarity
9962,8-1874,8-1874_v2_4@1,8-1874_v1_4@1,"New sequencing protocols are constantly being introduced <REF-7> , <REF-8> , and as the cost of sequencing per base decreases, sequencing data is growing in abundance, dataset size, and read length <REF-9> .","New sequencing protocols are constantly being introduced <REF-7> , <REF-8> , and as the cost of sequencing per base decreases, sequencing data is growing in abundance, dataset size and read length <REF-9> .","Modify,Grammar",Grammar
9963,8-1874,8-1874_v2_5@0,8-1874_v1_5@0,Quality control (QC) is often the first step in high-throughput sequencing data analysis pipelines.,"When high-throughput sequencing data is generated it often undergoes common upstream analysis steps involving quality control (QC), adapter trimming, filtering contaminants and low-quality reads, and mapping reads to a reference genome or transcriptome.","Split+Modify,Claim",Claim
9964,8-1874,8-1874_v2_6@0,8-1874_v1_5@0,"Data that passes specific QC tests then undergoes downstream analysis steps, which may include adapter trimming, filtering contaminants and low-quality reads, and mapping the resulting reads to a reference genome or transcriptome.","When high-throughput sequencing data is generated it often undergoes common upstream analysis steps involving quality control (QC), adapter trimming, filtering contaminants and low-quality reads, and mapping reads to a reference genome or transcriptome.","Split+Modify,Claim",Claim
9965,8-1874,8-1874_v2_34@0,8-1874_v1_32@0,FASTQ files available in the Sequence Read Archive (SRA) <REF-18> were downloaded using the fastq-dump command from the SRA toolkit.,FASTQ files available in the Sequencing Read Archive (SRA) were downloaded using the fastq-dump command from the SRA toolkit.,"Modify,Fact/Evidence",Fact/Evidence
9966,8-1874,8-1874_v2_35@0,8-1874_v1_33@0,"We directly compared the text summary for each output of Falco to FastQC ’s output summary files, obtaining the same outputs (pass, warning, or fail) for all tested criteria in all datasets.","We directly compared the text summary for each output of falco to FastQC ’s output summary files, obtaining the same outputs (pass/warn/fail) for all tested criteria in all datasets.","Modify,Grammar",Grammar
9967,8-1874,8-1874_v2_36@1,8-1874_v1_34@2,"Differences in the fastqc_data.txt files between the two programs result from choices for numerical precision output, or as a result of Falco calculating certain averages based on more of the data within each file.","Differences in the fastq_data.txt files between the two programs result from choices for numerical precision output, or as a result of falco calculating certain averages based on more of the data within each file.","Modify,Fact/Evidence",Fact/Evidence
9968,8-1874,8-1874_v2_38@4,8-1874_v1_36@4,The two programs were used as benchmarks to compare Falco with.,The two programs were used as benchmarks to compare with falco ’s performance.,"Modify,Clarity",Clarity
9969,8-1874,8-1874_v2_6@1,8-1874_v1_5@1,"With the exception of sequence assembly applications, read mapping should be the most computationally expensive step early in analysis pipelines.","Excluding sequence assembly applications, read mapping should be the most computationally expensive step early in analysis pipelines.","Modify,Clarity",Clarity
9970,8-1874,8-1874_v2_39@5,8-1874_v1_37@5,Programs were compared both in compressed (gzip FASTQ) and uncompressed (plain FASTQ) file formats.,Programs were compared both in compressed (gzipped FASTQ) and uncompressed (plain FASTQ) file formats.,"Modify,Grammar",Grammar
9971,8-1874,8-1874_v2_40@0,8-1874_v1_38@0,Files used to assess Falco ’s output comparison to FastQC ( Table 2 ) were also used for speed and memory comparison.,Files used to assess falco ’s output comparison to FastQC ( Table 2 ) were also used for speed benchmarking.,"Modify,Fact/Evidence",Fact/Evidence
9972,8-1874,8-1874_v2_40@3,8-1874_v1_38@3,Both fastp and FastQC were instructed to run using a single thread.,Programs were instructed to run using a single thread.,"Modify,Fact/Evidence",Fact/Evidence
9973,8-1874,8-1874_v2_41@5,8-1874_v1_40@1,"We used the GNU time command to measure the total running times for each program, using the total elapsed wall time as measurement.","We used the time command (using the BASH shell keyword) to measure the total running times for each program, using the real time (total wall clock from program start to finish) as measurement.","Modify,Fact/Evidence",Fact/Evidence
9974,8-1874,8-1874_v2_6@3,8-1874_v1_5@3,"However, the efficiency of mapping algorithms has improved substantially over the past decade, while software for QC has received far less attention.","However, the efficiency of mapping algorithms has improving substantially over the past decade, while software for QC has received far less attention.","Modify,Grammar",Grammar
9975,8-1874,8-1874_v2_41@6,8-1874_v1_40@2,"The benchmarking results ( Table 3 and Table 4 ) show that Falco performs faster than fastp and FastQC in all datasets, with an average 3 times faster runtime than FastQC , both with the overrepresented sequences module on and off.","The benchmarking results ( Table 3 and Table 4 ) show that falco performs faster than fastp and FastQC in all datasets, with an average 3x faster runtime than FastQC , both with the overrepresented sequences module on and off.","Modify,Grammar",Grammar
9976,8-1874,8-1874_v2_41@7,8-1874_v1_40@3,"Despite HTQC failing to process most test datasets due to unaccepted header formats, the two tests that ran to completion demonstrate that Falco ’s analysis times are also significantly smaller in comparison.","Despite HTQC failing to process most test datasets due to unaccepted header formats, the two tests that ran to completion demonstrate that falco ’s analysis times are also significantly smaller in comparison.","Modify,Grammar",Grammar
9977,8-1874,8-1874_v2_7@0,8-1874_v1_6@0,"The most commonly used tool for quality control of sequencing data is FastQC <REF-11> , which, since its release, has incorporated a wide range of QC tests covering multiple use cases.","The most commonly used tool for quality control of sequencing data is FastQC <REF-10> , which, since 2011, has incorporated a wide range of QC checks covering multiple use cases.","Modify,Fact/Evidence",Fact/Evidence
9978,8-1874,8-1874_v2_7@1,8-1874_v1_6@2,"Its analysis reports have become the standard for several QC tools, and automated analysis pipelines often rely on its result as a criterion to proceed with downstream steps or, alternatively, to filter, trim, or ultimately discard the data <REF-12> , <REF-13> .","Its analysis reports have become the standard for several QC tools, and automated analysis pipelines often rely on its evaluation as a safety criteria to proceed with downstream steps or, alternatively, to filter, trim or ultimately discard the data <REF-11> , <REF-12> .","Modify,Clarity",Clarity
9979,8-1874,8-1874_v2_8@0,8-1874_v1_7@0,"In FastQC ’s implementation, each module computation is executed sequentially after an input sequence is read.","FastQC is implemented in a modular design, where multiple independent analysis procedures are run sequentially after an input record is read.","Modify,Fact/Evidence",Fact/Evidence
9980,8-1874,8-1874_v2_8@1,8-1874_v1_7@1,"This design allows new modules to be incorporated easily, but it implies that the time required to process each read is the sum of the processing times for each module.","This design allows new modules to be incorporated easily, but it implies that each analysis module is applied independently to each read, so the time required to process each read is the sum of the processing times for each module.","Modify,Claim",Claim
9981,8-1874,8-1874_v2_48@0,8-1874_v1_48@0,"Despite FastQC ’s clarity in its HTML reports, graphs are displayed as static images and have limited visualization flexibility, such as tile heatmaps not displaying raw deviations from average Phred scores in base positions, or raw values in line plots not being visible.","Despite FastQC ’s clarity in its HTML reports, graphs are displayed as static images and have limited visualization flexibility, such as tile heatmaps not displaying raw deviations from average Phred scores in base positions or raw values in line plots not being visible.","Modify,Grammar",Grammar
9982,8-1874,8-1874_v2_48@1,8-1874_v1_48@1,"We have opted to display Falco ’s analysis results using the Plotly JavaScript library <REF-28> , which allows interactive changes of axis labels, hovering on data points to visualize raw values, and screenshots from specific positions on the plot ( Figure 1 ).","We have opted to display falco ’s analysis results using the Plotly JavaScript library <REF-29> , which allows interactive changes of axis labels, hovering on data points to visualize raw values and screenshots from specific position on the plot ( Figure 1 ).","Modify,Grammar",Grammar
9983,8-1874,8-1874_v2_52@0,8-1874_v1_52@0,Falco <REF-14> is a faster alternative to calculate the wide range of QC metrics reported by FastQC .,Falco <REF-13> is a faster alternative to calculate the wide range of QC metrics generated by FastQC .,"Modify,Clarity",Clarity
9984,8-1874,8-1874_v2_8@2,8-1874_v1_7@2,"If multiple modules compute similar measurements, such as nucleotide content or Phred quality scores, the same calculation will be performed multiple times, causing the total analysis run time to increase.","If multiple modules use similar measurements, such as nucleotide content or average sequence quality, the same measurement will be calculated multiple times, causing the total analysis run time to increase.","Modify,Clarity",Clarity
9985,8-1874,8-1874_v2_54@1,8-1874_v1_54@1,Guidance for how to accept accession wgs-FAB49164 is available from the Benchmark directory of the Falco GitHub page .,Guidance for how to accept accession wgs-FAB49164 is available from the Benchmark directory of the falco GitHub page .,"Modify,Grammar",Grammar
9986,8-1874,8-1874_v2_9@0,8-1874_v1_8@0,"Several QC software tools have been introduced since FastQC , many focusing on speed improvements, more flexible module visualization, incorporation of paired-end reads, and filtering sequences that failed QC tests.","Several QC software tools have been introduced since FastQC , many focusing on speed improvements, more flexible module visualization, incorporation of paired-end reads and filtering sequences that failed QC checks.","Modify,Clarity",Clarity
9987,8-1874,8-1874_v2_2@2,8-1874_v1_2@2,"We present Falco, an emulation of the popular FastQC tool that runs on average three times faster while generating equivalent results.","We present falco, an emulation of the popular FastQC tool that runs on average three times faster while generating equivalent results.","Modify,Grammar",Grammar
9988,8-1874,8-1874_v2_12@1,8-1874_v1_11@1,"If a new QC software tool is incorporated in these pipelines, it is desirable that its results, and its output formats, remain consistent with those of FastQC .","If a new QC software tool were to be incorporated in these pipelines, it is desirable that its results, and its output formats, remain consistent with those of FastQC .","Modify,Grammar",Grammar
9989,8-1874,8-1874_v2_13@0,8-1874_v1_12@0,"To address potential speed limitations in FastQC ’s implementation while retaining its behavior, we developed FastQC Alternative Code ( Falco ) <REF-14> , an emulation of the FastQC software tool.","To improve the speed of quality control while retaining the behaviour of FastQC , we developed FastQC Alternative Code ( falco ) <REF-13> , an emulation of FastQC ’s current analysis modules.","Modify,Claim",Claim
9990,8-1874,8-1874_v2_2@3,8-1874_v1_2@3,"Compared to FastQC, Falco also requires less memory to run and provides more flexible visualization of HTML reports.","Compared to FastQC, falco also provides greater scalability for datasets with longer reads and more flexible visualization of HTML reports.","Modify,Claim",Claim
9991,8-1874,8-1874_v2_16@2,8-1874_v1_15@1,The goal of Falco is to minimize the effort required to replace the command-line behavior of FastQC in the context of larger automated analysis pipelines.,Our goal was to minimize the effort required to replace FastQC with falco in the context of larger automated analysis pipelines.,"Modify,Clarity",Clarity
9992,8-1874,8-1874_v2_16@3,8-1874_v1_15@2,"We use the same set of command-line arguments, configuration file names, and input file formats as FastQC .","We use the same set of command line arguments, configuration file names and formats.","Modify,Clarity",Clarity
9993,8-1874,8-1874_v2_16@4,8-1874_v1_15@3,"We also produce the same plain text format output, and the same report structure, allowing users to take advantage of improved speed without adjusting to different program behaviors.","We also produce the same plain text format output, and the same report structure as FastQC , allowing users to take advantage of improved speed without adjusting to different program behaviors.","Modify,Clarity",Clarity
9994,8-1874,8-1874_v2_17@0,8-1874_v1_16@0,There are major differences between the implementations of Falco and FastQC .,There are major differences between the implementations of falco and FastQC .,"Modify,Grammar",Grammar
9995,8-1874,8-1874_v2_19@0,8-1874_v1_19@0,"Compilation of Falco requires a GNU GCC compiler version 5.0.0 (July 16, 2015; full support for the C++11 standard) or greater.","Compilation of falco requires a GNU GCC compiler version 5.0.0 (July 16, 2015; full support for the C++11 standard) or greater.","Modify,Grammar",Grammar
9996,8-1874,8-1874_v2_19@1,8-1874_v1_19@1,"Once compiled, Falco can be run on uncompressed files (FASTQ and SAM) without any additional dependencies.","Once installed, falco can be run on uncompressed files (FASTQ and SAM) without any additional dependencies.","Modify,Clarity",Clarity
9997,8-1874,8-1874_v2_19@2,8-1874_v1_19@2,"In order to process files in gzip compressed FASTQ and BAM formats, Falco must be compiled with the ZLib <REF-15> and HTSLib <REF-16> libraries, respectively.","In order to process files in gzip compressed FASTQ and BAM formats, falco must be compiled with the ZLib <REF-14> and HTSLib <REF-15> libraries.","Modify,Clarity",Clarity
9998,8-1874,8-1874_v2_19@3,8-1874_v1_19@3,"The full documentation on how to compile, install dependencies, and run the program is available in the README file in the Falco repository.","The full documentation on how to compile, install dependencies and run the program is available in the README file in the falco repository.","Modify,Grammar",Grammar
9999,8-1874,8-1874_v2_4@0,8-1874_v1_4@0,"High-throughput sequencing is routinely used to profile copy number variations in cancers <REF-1> , assemble genomes of microbial organisms <REF-2> , <REF-3> , quantify gene expression <REF-4> , identify cell populations from single-cell transcriptomes in a variety of tissues <REF-5> , and track epigenetic changes in developing organisms and diseases <REF-6> , among numerous other applications.","High-throughput sequencing is routinely used to profile copy number variations in cancers <REF-1> , assemble genomes of microbial organisms <REF-2> , <REF-3> , quantify gene expression <REF-4> , identify cell populations from single-cell transcriptomes in a variety of tissues <REF-5> and track epigenetic changes in developing organisms and diseases <REF-6> , among numerous other applications.","Modify,Grammar",Grammar
10000,8-1874,8-1874_v2_21@0,8-1874_v1_21@0,"Like FastQC , Falco <REF-14> can be applied to any file of sequenced reads in the formats accepted by FastQC.","Like FastQC , falco <REF-13> can be applied to any sequencing data file ( i.e. a file of sequenced reads) in the accepted formats.","Modify,Clarity",Clarity
10001,8-1874,8-1874_v2_21@4,8-1874_v1_21@4,"As mentioned above, this choice is to facilitate integration with larger pipelines that already employ FastQC and depend on its behaviors.","As mentioned above, this choice is to facilitate integration with larger pipelines that already employ FastQC and depend on its behaviours.","Modify,Grammar",Grammar
10002,8-1874,8-1874_v2_22@0,8-1874_v1_22@0,Falco can be run on a FASTQ format file named example.fq with the following simple command:,Falco can be run on a FASTQ format file named example.fastq with the following simple command:,"Modify,Fact/Evidence",Fact/Evidence
10003,8-1911,8-1911_v2_76@6,,- - Figure 7 – data (raw PCR integration gel images in TIF format),,"Add,Fact/Evidence",Fact/Evidence
10004,8-1911,8-1911_v2_80@1,,- - Figure 7. PCR screening of hiPSC clones to check for AAVS1 integration (TIF image file),,"Add,Fact/Evidence",Fact/Evidence
10005,8-1911,8-1911_v2_80@2,,- - Figure 8. sgRNA design (TIF image file),,"Add,Fact/Evidence",Fact/Evidence
10006,8-1911,8-1911_v2_80@3,,- - Table 2.1. Guide 2 off-target locations (XLS file),,"Add,Fact/Evidence",Fact/Evidence
10007,8-1911,8-1911_v2_80@4,,- - Table 2.2 Guide 3 off-target locations (XLS file),,"Add,Fact/Evidence",Fact/Evidence
10008,8-1911,8-1911_v2_80@5,,- - Figure 9. Delta Ct representation of HOXA9 expression in AAVS1-targeted hiPSCs (TIF image file),,"Add,Fact/Evidence",Fact/Evidence
10009,8-1911,8-1911_v2_11@1,,HOXA9 is a transcription factor regulated spatio-temporally during haematopoietic or cardiac development <REF-22> and the aim was to examine if controlled supplemental expression of HOXA9 resulted in more efficient production of mature cells.,,"Add,Fact/Evidence",Fact/Evidence
10010,8-1911,8-1911_v2_27@0,,HOXA9 and mScarlet expression was induced with the addition of 1 µg/ml doxycline every 48 hours.,,"Add,Fact/Evidence",Fact/Evidence
10011,8-1911,8-1911_v2_67@4,,This is in agreement with a recent report which demonstrated differential transgene methylation in AAVS1 -targeted iPSC-derived myeloid cells <REF-13> .,,"Add,Fact/Evidence",Fact/Evidence
10012,8-1911,8-1911_v2_68@3,,"In addition, a recent report elegantly demonstrated that contextual silencing at the AAVS1 locus of iPSC-derived myeloid precursors can occur with varying efficiency depending on the chosen promoter <REF-13> .",,"Add,Fact/Evidence",Fact/Evidence
10013,8-1911,8-1911_v2_31@6,8-1911_v1_31@6,CMs were kept at 37°C and 5% CO 2 and allowed to spontaneously beat throughout data acquisition.,CMs were kept at 37°C and 5% CO 2 throughout data acquisition.,"Modify,Fact/Evidence",Fact/Evidence
10014,8-1911,8-1911_v2_38@1,8-1911_v1_38@1,"One isogenic trio comprised lines that were originally wild-type ( MYH7 WT/WT ), and then CRISPR Cas9 edited to generate heterozygous ( MYH7 WT/MUT ) and homozygous ( MYH7 MUT/MUT ) mutants for the c. MYH7 C9123T mutation <REF-20> .","One isogenic trio comprised lines that were wild-type ( MYH7 WT/WT ), heterozygous ( MYH7 WT/MUT ) and homozygous ( MYH7 MUT/MUT ) for the c. MYH7 C9123T mutation <REF-19> .","Modify,Fact/Evidence",Fact/Evidence
10015,8-1911,8-1911_v2_38@2,8-1911_v1_38@2,The other comprised a pair that were heterozygous originally patient-derived ( ACTC1 WT/MUT ) and corrected ( ACTC1 WT/WT ) for the c. ACTC1 G301A mutation <REF-21> .,The other comprised a pair that were heterozygous ( ACTC1 WT/MUT ) and corrected ( ACTC1 WT/WT ) for the c. ACTC1 G301A mutation <REF-20> .,"Modify,Fact/Evidence",Fact/Evidence
10016,8-1911,8-1911_v2_59@3,8-1911_v1_59@3,"Despite some expected variability in spontaneous beat rate between wild-type hiPSC-CMs ( Figure 5A and 5E ) <REF-29> , for both the c. MYH7 C9123T and c. ACTC1 G301A mutations, increasing mutation load resulted in an increased incidence of abnormal Ca 2+ transient events.","For both the c. MYH7 C9123T and c. ACTC1 G301A mutations, increasing mutation load resulted in an increased incidence of abnormal Ca 2+ transient events.","Modify,Fact/Evidence",Fact/Evidence
10017,8-1911,8-1911_v2_9@5,8-1911_v1_9@5,"However, some reports of DNA methylation dampening transgene expression in both hPSC-derived hepatocytes <REF-12> and iPSC-derived myeloid progenitors <REF-32> raise questions on whether a ‘perfect’ safe harbour locus exists.","However, some reports of DNA methylation dampening transgene expression in hPSC-derived hepatocytes raise questions on whether a ‘perfect’ safe harbour locus exists <REF-12> .","Modify,Fact/Evidence",Fact/Evidence
10069,8-290,8-290_v2_7@1,,"This particular questionnaire is suitable at low knowledge levels and was developed for older teenage and young adult patients, along with parents in a pediatric setting.",,"Add,Claim",Claim
10070,8-290,8-290_v2_7@2,,"This survey was chosen because the targeted population is not involved in the life sciences/biology area, and, thus, are not prominently exposed to this type of information.",,"Add,Fact/Evidence",Fact/Evidence
10071,8-290,8-290_v2_7@3,,"Moreover, it appears useful to use an instrument measuring basic knowledge as a baseline report, especially in a region where no information about the competency of students in genetics is available.",,"Add,Claim",Claim
10072,8-290,8-290_v2_17@12,,"These outcomes might be related to the hitherto reported conceptual variation in biology textbooks, which have been shown to have detrimental repercussions regarding the students understanding of conceptual knowledge, models in particular, within the context of genetics ( Gericke et al ., 2014 ; Gericke et al ., 2013 ).",,"Add,Fact/Evidence",Fact/Evidence
10073,8-290,8-290_v2_18@2,,"Therefore, to have a better understanding on the actual knowledge, we suggest to implement, for each question, a section in which the interviewed is asked to provide a degree of certainty for his or her answer.",,"Add,Claim",Claim
10074,8-290,8-290_v2_18@3,,"Indeed, such an analysis has been applied to measure diabetic patients’ knowledge about the illness, and was shown to be useful in determining more efficaciously their degree of mastery about the subject ( Leclercq, 2010 ).",,"Add,Fact/Evidence",Fact/Evidence
10075,8-290,8-290_v2_18@7,,"Furthermore, this study provides adequate estimates of the knowledge of genetic and its relation to disease in a non-specialized population.",,"Add,Fact/Evidence",Fact/Evidence
10076,8-290,8-290_v2_2@7,8-290_v1_2@7,"The highly educated status of the surveyed population could explain the overall results; nonetheless, the possibility that the correct responses were given by chance cannot be ignored.","The highly educated status of the surveyed population could explain the overall adequate results; nonetheless, the possibility that the correct responses were given by chance cannot be ignored.","Modify,Clarity",Clarity
10077,8-290,8-290_v2_2@8,8-290_v1_2@8,"Therefore, the actual knowledge of genetics among the participants might be different than that revealed by the percentages of correct answers.","Therefore, the actual knowledge of genetics among the participants might be less than that revealed by the percentages of correct answers.","Modify,Clarity",Clarity
10078,8-290,8-290_v2_2@9,8-290_v1_2@9,"Consequently, to achieve the goal of ensuring informed decision-making concerning genetic and genomic tests, it seems evident that the national education programs of Ecuador require improvement in the teaching of genetic concepts.","Consequently, to achieve the goal of ensuring informed decision-making concerning genetic and genomic tests, it seems evident that the national education programs of Ecuador require improvement in teaching of genetic concepts.","Modify,Grammar",Grammar
10079,8-290,8-290_v2_17@0,8-290_v1_17@0,"In this report, we portray the percent of correct answers to an 18-item questionnaire measuring a minimum amount of knowledge about genetics.","In this report, we portray the percent of correct answers to an 18-item questionnaire measuring a minimum, adequate amount of knowledge about genetics.","Modify,Clarity",Clarity
10080,8-290,8-290_v2_17@11,8-290_v1_17@11,The lowest scores obtained were for the two questions involved in how chromosomes are passed down to the next generation.,"To our surprise, the lowest scores obtained were for the two questions involved in how chromosomes are passed down to the next generation.","Modify,Clarity",Clarity
10081,8-290,8-290_v2_18@0,8-290_v1_18@0,"Additionally, the presented results indicate that the probability of participants providing correct responses by chance could not be significantly discarded ( Table 1 ).","Additionally, the presented results indicate that, despite the relatively adequate scores, the probability that participants were providing correct responses by chance could not be significantly discarded for the overall test and for the two subsections ( Table 1 ).","Modify,Clarity",Clarity
10082,8-290,8-290_v2_18@1,8-290_v1_18@1,This fact implies that the actual knowledge might be different from the one asserted by the percentages of correct answers.,This fact implies that the actual knowledge might be truly weaker than the one asserted by the percentages of correct answers.,"Modify,Claim",Claim
10083,8-290,8-290_v2_18@4,8-290_v1_18@2,Individuals affiliated with private and public universities responded with similar accuracy.,"However, individuals affiliated with private and public universities responded with similar accuracy.","Modify,Clarity",Clarity
10084,8-290,8-290_v2_18@6,8-290_v1_18@4,It is worth mentioning that the interviewed people did not follow any biologically/medically related courses.,"It is worth mentioning that the interviewed people did not follow any biologically/medically related courses, which indicates that a non-specialized population may have adequate knowledge about the essential genetic concepts and their involvement in disease.","Modify,Claim",Claim
10085,8-290,8-290_v2_18@8,8-290_v1_18@5,It is important to note that the participants’ knowledge may not be as strong as it appears.,"Nevertheless, the participants’ knowledge may not be as strong as it appears.","Modify,Clarity",Clarity
10086,8-290,8-290_v2_4@9,8-290_v1_4@9,"Evidently, a basic amount of genetic knowledge is essential to understand and interpret the results of genetic and medical analyses.","Evidently, an adequate amount of basic knowledge about genetics is essential to understand and interpret the results of genetic and medical analyses.","Modify,Clarity",Clarity
10087,8-290,8-290_v2_7@0,8-290_v1_7@0,"The main objective of this research was to assess the competence of undergraduate students, who do not follow programs involving biologically related courses (n=350 by convenience sampling method), to respond to a validated survey evaluating a minimum, amount of knowledge about genetics ( Fitzgerald-Butt et al. , 2016 ).","Participants’ knowledge of genetics was measured as a baseline report on the attitude among undergraduate students toward genetic concepts, who were intentionally chosen because they did not follow programs involving biologically related courses (n=350 by convenience sampling method).","Merge+Modify,Clarity",Clarity
10088,8-290,8-290_v2_7@0,8-290_v1_7@1,"The main objective of this research was to assess the competence of undergraduate students, who do not follow programs involving biologically related courses (n=350 by convenience sampling method), to respond to a validated survey evaluating a minimum, amount of knowledge about genetics ( Fitzgerald-Butt et al. , 2016 ).","The main objective of this research was to assess the competence of students to respond to a validated survey evaluating a minimum, adequate amount of knowledge about genetics ( Fitzgerald-Butt et al. , 2016 ).","Merge+Modify,Clarity",Clarity
10089,8-323,8-323_v2_25@2,8-323_v1_25@2,"The median number of 10–18 year olds registered in paediatric services in each region was 31 (IQR 17, 73; range 1, 212) while that for 19–24 year olds in adult care was 101 (IQR 59, 227; range 0, 3632).","The median number of 10–18 year olds registered in paediatric services in each region was 31 (range 1, 212) while that for 19–24 year olds in adult care was 101 (range 0, 3632).","Modify,Fact/Evidence",Fact/Evidence
10090,8-323,8-323_v2_33@0,8-323_v1_33@0,"Most (22/28) centres reported that young people with horizontally-acquired HIV aged <18 years began their HIV care in paediatric services while in five centres they sometimes initiated care in adult services depending on factors such as adequate maturity, pregnancy, wish to attend adult services, or availability of a paediatrician; one centre reported always registering young people with horizontally-acquired HIV in adult HIV services.","Most (22/28) centres reported that BHIV young people aged <18 years began their HIV care in paediatric services while in five centres they sometimes initiated care in adult services depending on factors such as adequate maturity, pregnancy, wish to attend adult services, or availability of a paediatrician; one centre reported always registering BHIV young people in adult HIV services.","Modify,Clarity",Clarity
10091,8-323,8-323_v2_39@2,8-323_v1_39@2,Testing and treatment for sexually transmitted infections was quite widely available.,"Testing and treatment for sexually transmitted infections and psychological support were quite widely available; however, the three centres without psychologist support were in regions with some of the highest numbers of young people in HIV care (collectively 7287 of the 13286 10–24 year olds in HIV care nationally).","Split+Modify,Grammar",Grammar
10092,8-323,8-323_v2_39@3,8-323_v1_39@2,"This was also the case for psychological support; however, the three centres without psychologist support were in regions with some of the highest numbers of young people in HIV care (collectively 7287 of the 13286 10–24 year olds in HIV care nationally).","Testing and treatment for sexually transmitted infections and psychological support were quite widely available; however, the three centres without psychologist support were in regions with some of the highest numbers of young people in HIV care (collectively 7287 of the 13286 10–24 year olds in HIV care nationally).","Split+Modify,Clarity",Clarity
10093,8-323,8-323_v2_39@4,8-323_v1_39@3,"Out of 26 centres answering the question, 17 reported offering a support group, and at six of these 17 centres a group was provided specifically for young people.","Out of 26 centres, 17 reported offering a support group, and at six of these 17 centres a group was provided specifically for young people.","Modify,Clarity",Clarity
10094,8-323,8-323_v2_44@4,8-323_v1_44@4,"However, 26% of diagnosed individuals have never been linked to HIV care <REF-1> .","However, 26% of diagnosed individuals overall are currently unlinked to HIV care <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
10095,8-323,8-323_v2_46@0,8-323_v1_46@0,Most young people with horizontally-acquired HIV <18 years nationwide start their HIV care in paediatric services.,Most BHIV young people <18 years nationwide start their HIV care in paediatric services.,"Modify,Clarity",Clarity
10096,8-323,8-323_v2_46@3,8-323_v1_46@3,"Young people with horizontally-acquired HIV may experience complex barriers to care related, for example, stigma and concerns around confidentiality, which are reflected in longer delays linking to HIV services than is average for older adults <REF-24> .","BHIV young people may experience complex barriers to care related, for example, stigma and concerns around confidentiality, which are reflected in longer delays linking to HIV services than is average for older BHIV adults <REF-24> .","Modify,Clarity",Clarity
10097,8-323,8-323_v2_11@1,8-323_v1_11@1,"Important successes in prevention of mother-to-child transmission and paediatric treatment programmes are reflected, as in other settings, in the demographic characteristics of perinatally HIV-infected (PHIV) patients, who are an ageing cohort.","Important successes in prevention of mother-to-child transmission and paediatric treatment programmes are reflected, as in other settings, in the demographic characteristics of patients with perinatal HIV (PHIV), who are an ageing cohort.","Modify,Clarity",Clarity
10098,8-323,8-323_v2_50@0,8-323_v1_50@0,"Peer support opportunities for PHIV young people will increase in coming years as this group reach adolescence and young adulthood in greater numbers, and youth-oriented initiatives (such as those led by community-based organisation Teenergizer ) are needed to shape support for the needs of this group alongside youth with horizontally-acquired HIV.","Peer support opportunities for PHIV young people will increase in coming years as this group reach adolescence and young adulthood in greater numbers, and youth-oriented initiatives (such as those led by community-based organisation Teenergizer ) are needed to shape support for the needs of this group alongside BHIV youth.","Modify,Clarity",Clarity
10099,8-323,8-323_v2_50@1,8-323_v1_50@1,"The experiences of and barriers to HIV care for all young people need to be explored in the context of Ukraine’s healthcare reforms towards more patient-centred services, and we recently undertook a survey of these groups of young people at two HIV/AIDS centres which investigated these topics, with work ongoing in this area.","PHIV and BHIV young people’s experiences of and barriers to HIV care need to be explored in the context of Ukraine’s healthcare reforms towards more patient-centred services, and we recently undertook a survey of PHIV and BHIV young people at two HIV/AIDS centres which investigated these topics, with work ongoing in this area.","Modify,Clarity",Clarity
10100,8-323,8-323_v2_51@3,8-323_v1_51@3,"We did not disaggregate young people with sexually-acquired HIV infection into men who have sex with men (MSM) and those with heterosexually-acquired infection, due to the particular vulnerability of MSM in Ukraine which is linked with their under-reporting and misclassification in official figures <REF-32> , and mode of HIV acquisition may be misclassified in other ways (for example due to late diagnosis of a PHIV young person).","We did not disaggregate young people with sexually-acquired HIV infection into men who have sex with men (MSM) and those with heterosexually-acquired infection, due to the particular vulnerability of MSM in Ukraine which is linked with their under-reporting and misclassification in official figures <REF-32> .","Modify,Claim",Claim
10101,8-323,8-323_v2_53@2,8-323_v1_53@2,"Uneven availability of integrated services, financial barriers and lack of evening or weekend services may pose structural barriers to HIV care for young people regardless of mode of HIV acquisition and further work is needed to understand these.","Uneven availability of integrated services, financial barriers and lack of evening or weekend services may pose structural barriers to HIV care for both PHIV and BHIV young people and further work is needed to understand these.","Modify,Clarity",Clarity
10102,8-323,8-323_v2_12@0,8-323_v1_12@0,"In terms of horizontally-acquired HIV injecting drug use (IDU) has been a key driver of the epidemic among young people in Ukraine <REF-3> , including among marginalised youth <REF-4> as average age of IDU initiation is in the late teens <REF-5> .","In terms of behaviourally-acquired HIV (BHIV) among young people in Ukraine, injecting drug use (IDU) has been a key driver of the epidemic <REF-3> , including among marginalised youth <REF-4> as average age of IDU initiation is in the late teens <REF-5> .","Modify,Clarity",Clarity
10103,8-323,8-323_v2_12@1,8-323_v1_12@1,"In recent years, young people aged 15–24 years have accounted for a declining number and proportion of newly diagnosed HIV infections (12% in 2009 vs. 5.2% in 2016) <REF-1> .","In recent years, young people aged 15-24 years have accounted for a declining number and proportion of newly diagnosed HIV infections (12% in 2009 vs. 5.2% in 2016) <REF-1> .","Modify,Grammar",Grammar
10104,8-323,8-323_v2_13@3,8-323_v1_13@3,Around two-thirds of diagnosed individuals linked to care were on ART in 2016 <REF-1> .,Around two-thirds of diagnosed individuals linked to care are on ART.,"Modify,Fact/Evidence",Fact/Evidence
10105,8-323,8-323_v2_17@1,8-323_v1_17@1,"These 28 centres were surveyed because they collate data on all people registered for HIV care nationally, within each of the 24 regions (oblasts), including those followed-up at local or satellite clinics.","These centres were surveyed because they collate data on all people registered for HIV care nationally, within each of the 24 regions (oblasts), including those followed-up at local or satellite clinics.","Modify,Fact/Evidence",Fact/Evidence
10106,8-338,8-338_v2_29@2,,"Patients belonging to rural areas had higher prevalence of misclassification when compared to urban areas (12% vs 2%), but this difference was not statistically significant probably due to small sample size.",,"Add,Fact/Evidence",Fact/Evidence
10107,8-338,8-338_v2_39@3,,Inferior regimen might have also contributed to amplification of resistance in those who may have primary or acquired drug resistance (from prior treatment) and MDR-TB.,,"Add,Claim",Claim
10108,8-338,8-338_v2_39@4,,This has been happening for over 10 years so one can see why India now faces the serious problem of drug resistant TB.,,"Add,Claim",Claim
10109,8-338,8-338_v2_43@1,,RNTCP staff needs to be re-sensitized to “ask” for previous history of TB treatment.,,"Add,Claim",Claim
10110,8-338,8-338_v2_44@1,,"In the national case-based TB notification software ( NIKSHAY ), record linkage and deduplication using key attributes may be considered to identify repeat notification of the same person separated by a time period.",,"Add,Claim",Claim
10111,8-338,8-338_v2_41@0,8-338_v1_41@0,Recommendations,Future research,"Modify,Other",Other
10112,8-338,8-338_v2_42@1,8-338_v1_42@1,The programme should consider replicating similar studies among patients from the general population with a possible sub-group to look for rural-urban differences.,The programme should consider replicating similar studies among patients from the general population.,"Modify,Claim",Claim
10113,8-338,8-338_v2_8@5,8-338_v1_8@5,This provided us with a unique opportunity to document the proportion of newly registered smear-positive pulmonary TB patients that had previous history of TB treatment and were therefore misclassified (henceforth called ‘misclassification’).,This provided us with a unique opportunity to document the proportion of newly registered smear-positive pulmonary TB patients that had previous history of TB treatment and were therefore misclassified.,"Modify,Clarity",Clarity
10114,8-338,8-338_v2_11@0,8-338_v1_11@0,This was a cross-sectional study involving new smear-positive pulmonary TB patients (≥ 15 y) from marginalised and vulnerable populations that were registered for treatment under the RNTCP in India between March 2016 and February 2017.,This was a cross-sectional study involving new smear-positive pulmonary TB patients from marginalised and vulnerable populations that were registered for treatment under the RNTCP in India between March 2016 and February 2017.,"Modify,Fact/Evidence",Fact/Evidence
10115,8-338,8-338_v2_2@1,8-338_v1_2@1,"Ten years down the line, it is important to know what proportion of newly registered patients has a past history of TB treatment for at least one month (henceforth called ‘misclassification’).","Ten years down the line, it is important to know what proportion of newly registered patients has a past history of TB treatment.","Modify,Claim",Claim
10116,8-338,8-338_v2_20@0,8-338_v1_20@0,"Under Axshya SAMVAD study, we collected data for each study participant through record review (age, sex, ACF/PCF status, residence (urban/rural), distance of residence from microscopy centre, sputum smear grade, weight, diabetes status and HIV status) and patient interviews at their residence.","Under Axshya SAMVAD study, we collected data for each study participant through record review (age, gender, ACF/PCF status, residence (urban/rural), distance of residence from microscopy centre, sputum smear grade, weight, diabetes status and HIV status) and patient interviews at their residence.","Modify,Clarity",Clarity
10117,8-338,8-338_v2_22@4,8-338_v1_22@4,"Variables collected during record review (age, sex, ACF/PCF status, residence (urban/rural), distance of residence from microscopy centre and sputum smear grade) were included in the adjusted analysis.","Variables collected during record review (age, gender, ACF/PCF status, residence (urban/rural), distance of residence from microscopy centre and sputum smear grade) were included in the adjusted analysis.","Modify,Clarity",Clarity
10118,8-338,8-338_v2_22@5,8-338_v1_22@5,Baseline weight was missing in two-fifths of patients; baseline diabetes status was missing for more than three-fifths and HIV status was missing for two-fifths.,Baseline weight was missing in two-fifths of patients; baseline diabetes status was missing for more than three-fifths and only one patient was living with HIV.,"Modify,Fact/Evidence",Fact/Evidence
10119,8-338,8-338_v2_22@7,8-338_v1_22@7,The association was summarized (inferred) using adjusted prevalence ratios (95% CIs).,The association was summarized (inferred) using adjusted prevalence ratios (0.95 CIs).,"Modify,Clarity",Clarity
10120,8-358,8-358_v2_70@0,,"In the both cases, we can regulate the trait expression by a feedback so that whenever S i attains a critical level, i.e., a trait is well expressed, then γ should be increased.",,"Add,Fact/Evidence",Fact/Evidence
10121,8-358,8-358_v2_70@1,,"In our numerical simulations we use an alternative model, where we change h j .",,"Add,Fact/Evidence",Fact/Evidence
10122,8-358,8-358_v2_70@2,,"The alternative model, which is used in our numerical simulations, can be described as follows.",,"Add,Fact/Evidence",Fact/Evidence
10123,8-358,8-358_v2_72@1,,"Thus, h j can take large negative or positive values, and also a neutral value close to 0.",,"Add,Fact/Evidence",Fact/Evidence
10124,8-358,8-358_v2_74@0,,Such a regulation produces a good adaptation even when the number of genes is essentially less than the number of the traits.,,"Add,Claim",Claim
10125,8-358,8-358_v2_74@1,,The plot in Figure 3 shows a difference between an evolution without any regulation and with the regulation by ( 2.12 ) described above.,,"Add,Fact/Evidence",Fact/Evidence
10126,8-358,8-358_v2_75@1,,"In fact, the traits with large | h i | are non-sensitive with respect to mutations.",,"Add,Claim",Claim
10127,8-358,8-358_v2_75@2,,The effect produced by this robustness is shown on Figure 1 .,,"Add,Fact/Evidence",Fact/Evidence
10128,8-358,8-358_v2_78@0,,"This regulation is even more effective, if we consider the modular evolution, following the recent paper <REF-32> .",,"Add,Fact/Evidence",Fact/Evidence
10129,8-358,8-358_v2_78@1,,"Indeed, biological systems are characterized by a high degree of modularity.",,"Add,Claim",Claim
10130,8-358,8-358_v2_78@2,,This modularity allows biological systems to vary only in a small subset of traits at each evolution round.,,"Add,Claim",Claim
10131,8-358,8-358_v2_78@3,,Figure 2 shows an effect of this modularity.,,"Add,Fact/Evidence",Fact/Evidence
10132,8-358,8-358_v2_78@4,,"We consider a toy example, where a system with only 10 genes should be adapted to 200 constraints.",,"Add,Fact/Evidence",Fact/Evidence
10133,8-358,8-358_v2_78@5,,"Without regulation, we have no chances to make an adaptation (only about 10 traits are correctly adapted, see the green curve).",,"Add,Fact/Evidence",Fact/Evidence
10134,8-358,8-358_v2_78@6,,It is a consequence of a formidable pleiotropy (20 traits on 1 gene).,,"Add,Fact/Evidence",Fact/Evidence
10135,8-358,8-358_v2_78@7,,"However, if at each evolution stage an organism should be adapted to 4 traits whereas the remaining ones are made robust by high | h i | , then already 66 traits are correctly expressed after 20000 evolution steps.",,"Add,Claim",Claim
10136,8-358,8-358_v2_78@8,,Note that the learning plays a key role in the regulation.,,"Add,Claim",Claim
10137,8-358,8-358_v2_78@9,,"In fact, the sign of the regulation threshold h i depends on the sign of the corresponding coefficient b i , and the knowledge of that sign gives us important information on the fitness landscape.",,"Add,Fact/Evidence",Fact/Evidence
10138,8-358,8-358_v2_166@0,,Rare mutants .,,"Add,Other",Other
10139,8-358,8-358_v2_166@1,,In this Theorem we assume that the frequencies p 0 and p 1 of genotypes (wild and mutant) are fixed and our estimate is valid as p mut → 0.,,"Add,Fact/Evidence",Fact/Evidence
10140,8-358,8-358_v2_166@2,,"I.e., we do not consider mutants with a very small frequencies (fractions).",,"Add,Fact/Evidence",Fact/Evidence
10141,8-358,8-358_v2_166@3,,"Of course, a large population always contains a small number of such mutants.",,"Add,Claim",Claim
10142,8-358,8-358_v2_166@4,,"In numerical simulations we assume that evolution is successful and population is perfectly adapted, if, say, 95 or 99 percents of population members have the maximal fitness.",,"Add,Fact/Evidence",Fact/Evidence
10143,8-358,8-358_v2_390@0,,This network modifies the thresholds by a simple feedback mechanism.,,"Add,Fact/Evidence",Fact/Evidence
10144,8-358,8-358_v2_390@1,,"Although we are not aware of clear experimental evidence for the existence of such a mechanism, we nevertheless think that such a mechanism can be connected with regulations via enhancers <REF-47> , <REF-48> , where enhancer action is described by deep network models based on thermodynamics, and chemical kinetics, and those models contain threshold parameters.",,"Add,Claim",Claim
10145,8-358,8-358_v2_390@2,,Alternative variants involve modifications of weights.,,"Add,Claim",Claim
10146,8-358,8-358_v2_390@3,,"To some extent, both mechanisms are mathematically equivalent.",,"Add,Claim",Claim
10147,8-358,8-358_v2_390@5,,"In this second version of the paper we included a subsection about regulation and two pictures, which show results of numerical simulations based on the “strong selection weak mutation” (SSWM) algorithm.",,"Add,Fact/Evidence",Fact/Evidence
10148,8-358,8-358_v2_390@6,,"As is the case for threshold signs, they of course should have different signs.",,"Add,Claim",Claim
10149,8-358,8-358_v2_390@7,,The key question is how an individual obtains information about the fitness landscape.,,"Add,Claim",Claim
10150,8-358,8-358_v2_390@8,,In our model that information is the sign of b j .,,"Add,Fact/Evidence",Fact/Evidence
10151,8-358,8-358_v2_390@9,,"If the b j is positive the corresponding threshold must be negative, otherwise, it should be negative.",,"Add,Fact/Evidence",Fact/Evidence
10152,8-358,8-358_v2_390@11,,The very fact of the existence of the individual carries the most important information.,,"Add,Claim",Claim
10153,8-358,8-358_v2_390@12,,Look at the mutations of its genotype and you will know where evolution should go!,,"Add,Claim",Claim
10154,8-358,8-358_v2_64@0,,2.5 Gene regulation network,,"Add,Other",Other
10155,8-358,8-358_v2_66@0,,"Regulatory genes as well as environmental factors, such as temperature, can influence the trait expression.",,"Add,Claim",Claim
10156,8-358,8-358_v2_66@1,,"This effect can be realized via thresholds h j (we shall describe it below), or via a regulation of coefficients w ij (see <REF-30> ).",,"Add,Fact/Evidence",Fact/Evidence
10157,8-358,8-358_v2_66@2,,"In fact, these approaches are similar for sharp sigmoidal functions σ that are close to step functions, as can be shown by ideas from <REF-31> .",,"Add,Fact/Evidence",Fact/Evidence
10158,8-358,8-358_v2_68@1,,"Suppose following <REF-31> that w ij take the values γ , 0 or − γ , where γ is a parameter, which can be regulated.",,"Add,Fact/Evidence",Fact/Evidence
10159,8-358,8-358_v2_68@2,,Let h j ≪ γ be fixed.,,"Add,Fact/Evidence",Fact/Evidence
10160,8-358,8-358_v2_69@0,,"Assume that at an evolution step we have S i > d S , where d S > 0 is a parameter, which is more than γ .",,"Add,Fact/Evidence",Fact/Evidence
10161,8-358,8-358_v2_37@2,8-358_v1_36@2,"Then the parameter h j defines how many genes involved in the control of the f j expression should be activators and how many should be repressors. Let the numbers of activator and repressor genes be n j ± , respectively.",Then the parameter h j defines how many genes involved in the control of the f j expression should be activators and how many should be repressors. Let the numbers of activator and repressor genes be n j ± respectively.,"Modify,Grammar",Grammar
10162,8-358,8-358_v2_3@0,8-358_v1_3@0,1 Introduction,1. Introduction,"Modify,Grammar",Grammar
10163,8-358,8-358_v2_63@1,8-358_v1_62@1,They only describe changes in the genotype frequencies because of selection at the t -th time step.,They describe only changes in the genotype frequencies because of selection at the t -th time step.,"Modify,Clarity",Clarity
10164,8-358,8-358_v2_164@0,8-358_v1_146@0,It is interesting to compare Theorem 3.1 and Theorem 3.2 .,It is interesting to compare Theorem3.1 and Theorem3.2 .,"Modify,Grammar",Grammar
10165,8-358,8-358_v2_10@6,8-358_v1_10@6,Learning can sharply reduce the number of mutations needed to form a phenotypic trait useful for adaptation that is consistent with experimental data mentioned above (see <REF-3> ).,Learning can sharply reduce the number of mutations needed to form a phenotypic trait useful for adaptation that is consistent with experimental data mentioned above (see <REF-3> .,"Modify,Grammar",Grammar
10166,8-358,8-358_v2_12@0,8-358_v1_12@0,2 Model,2. Model,"Modify,Grammar",Grammar
10167,8-358,8-358_v2_385@3,8-358_v1_363@3,The main idea is that small mutations pave the way for large epigenetic or genetic changes.,The main idea is that small mutation pave the way for large epigenetic or genetic changes.,"Modify,Grammar",Grammar
10183,8-420,,8-420_v1_55@3,,We will use the same sample size.,"Delete,Fact/Evidence",Fact/Evidence
10184,8-420,8-420_v2_11@2,,"Between different researches on informational masking, coordinate response measure (CRM) sentences appear to be a good option to differentiate between energetic and informational masking <REF-24> .",,"Add,Fact/Evidence",Fact/Evidence
10185,8-420,8-420_v2_11@3,,"By using these phrases as the target and competing signals, a high semantic and syntactic similarity occurs, which is an important factor in introducing informational masking <REF-25> .",,"Add,Fact/Evidence",Fact/Evidence
10186,8-420,8-420_v2_11@4,,"Therefore, since the Persian version of these sentences are not available, we will prepare them and after that, we will develop a new informational measurement test.",,"Add,Fact/Evidence",Fact/Evidence
10187,8-420,8-420_v2_27@0,,The intensity setup of the speech signals with two competing talkers used were similar to some previous studies <REF-29> .,,"Add,Fact/Evidence",Fact/Evidence
10188,8-420,8-420_v2_27@1,,The overall level (RMS power) of target CRM was fixed at the 60 dBSPL.,,"Add,Fact/Evidence",Fact/Evidence
10189,8-420,8-420_v2_27@2,,The overall level (RMS power) of each masker was adjusted relative to the target’s level to produce one target-to-masker ratios (TMRs).,,"Add,Fact/Evidence",Fact/Evidence
10190,8-420,8-420_v2_27@3,,Initially the masker level was varied in 4 dB steps and then they varied adaptively in 2 dB steps.,,"Add,Fact/Evidence",Fact/Evidence
10191,8-420,8-420_v2_27@4,,The two CRM masker phrases always had the same RMS power.,,"Add,Fact/Evidence",Fact/Evidence
10192,8-420,8-420_v2_30@0,,Jakien and Gallun provided mathematical equations by which the effects of age can be predicted for 45 degrees of separation <REF-30> .,,"Add,Fact/Evidence",Fact/Evidence
10193,8-420,8-420_v2_30@1,,"We will develop similar equations, compare them with the published equations, and will use these normative functions to assess improvements in performance after training.",,"Add,Fact/Evidence",Fact/Evidence
10194,8-420,8-420_v2_34@8,,"- - The temporary storage and manipulation of information required to perform a wide range of complex cognitive activities such as learning, and reasoning called working memory. Since the working memory have more influences on the informational masking tasks, so we will measure the ‘Persian Reading Span test’ score in our study <REF-33> . Participants will asked to read sets of sentences, report on the semantic acceptability of each sentence, and then recall the final word of each sentence (secondary outcome).",,"Add,Fact/Evidence",Fact/Evidence
10195,8-420,8-420_v2_45@0,,The ‘synthetic sentence identification test’ <REF-32> and the ‘Persian Reading Span test’ score <REF-33> .also will be evaluated immediately after training and 5 weeks after that.,,"Add,Fact/Evidence",Fact/Evidence
10196,8-420,8-420_v2_59@2,,"In her study the mean and standard deviation of the improvement in the main variable were 37.5 and 25.17 in the experimental group and 25.17 and 18.15 in the control group, respectively.",,"Add,Fact/Evidence",Fact/Evidence
10197,8-420,8-420_v2_59@4,,"By assuming 20% drop out, so we will use 18 people in each group.",,"Add,Fact/Evidence",Fact/Evidence
10198,8-420,8-420_v2_67@2,,"Also at the first of each training session the initial level of training will be calculated and if there will be a progress in the initial signal to noise ratio which train will be started from that, the examiner will inform the patient.",,"Add,Fact/Evidence",Fact/Evidence
10199,8-420,8-420_v2_21@2,8-420_v1_22@2,"In these sentences, the same rigid structure with “Ready [call sign] go to [color] [number] now” format is used.","In these sentences, the same rigid structure with ""Ready [call sign] go to [color] [number] now"" format is used.","Modify,Grammar",Grammar
10200,8-420,8-420_v2_21@4,8-420_v1_22@4,"These sentences will be expressed by speakers of different genders <REF-24> , <REF-25> , <REF-27> .",These sentences will be expressed by speakers of different genders <REF-22> – <REF-24> .,"Modify,Fact/Evidence",Fact/Evidence
10201,8-420,8-420_v2_21@6,8-420_v1_22@6,"Sentences will be expressed by eight speakers (four women and four men), providing a total of 2048 sentences.","Sentences will be expressed by four speakers (two women and 2 men), providing a total of 1024 sentences.","Modify,Fact/Evidence",Fact/Evidence
10202,8-420,8-420_v2_22@2,8-420_v1_23@2,"These experts are the academic members of rehabilitation schools of IUMS, Tehran University of Medical Sciences (TUMS) and Shahid Beheshti University of Medical Sciences (SBUMS).","These experts are the academic members of rehabilitation faculties of IUMS, Tehran University of Medical Sciences (TUMS) and Shahid Beheshti University of Medical Sciences (SBUMS).","Modify,Clarity",Clarity
10203,8-420,8-420_v2_23@0,8-420_v1_24@0,"After selecting the best pattern matching Persian language, based on the model presented for recording the sentences, all sentences will be recorded in a studio with the eight speakers.","After selecting the best pattern matching Persian language, based on the model presented for recording the sentences, all sentences will be recorded in a studio with the four speakers.","Modify,Fact/Evidence",Fact/Evidence
10204,8-420,8-420_v2_24@0,8-420_v1_25@0,"To determine the reliability of CRM speech materials, the mean scores of CRM recognition in the silent will be evaluated in a group of young and old people with normal peripheral hearing who do not have speech perception difficulties in noisy environments.","To determine the reliability of CRM speech materials, the mean scores of CRM recognition in the silent will be evaluated in a group of young and old people with normal hearing who do not have speech perception difficulties in noisy environments.","Modify,Fact/Evidence",Fact/Evidence
10205,8-420,8-420_v2_3@4,8-420_v1_3@4,"The informational masking measurement test and Speech, Spatial and Qualities of Hearing Scale will be compared before intervention, immediately after intervention, and five weeks after intervention between the two groups.","The informational masking measurement test and Speech, Spatial and Qualities of Hearing Scale will be compared before intervention, immediately after intervention, and one month after intervention between the two groups.","Modify,Fact/Evidence",Fact/Evidence
10206,8-420,8-420_v2_24@2,8-420_v1_25@2,This evaluation will be implemented at the comfort hearing level of the participants.,This evaluation will be implemented at the comfort hearing level of the participant.,"Modify,Grammar",Grammar
10207,8-420,8-420_v2_25@0,8-420_v1_26@0,The best way to measure informational masking score is determining the score for speech recognition in the presence of meaningful and meaningless competing noise.,The best way to measure informational masking value is determining the score for speech recognition in the presence of meaningful and meaningless competing noise.,"Modify,Clarity",Clarity
10208,8-420,8-420_v2_27@5,8-420_v1_28@0,"The TMRs in sentence recognition test in steps A and B was ±8, ±4, and 0.","The signal to noise ratio in sentence recognition test in steps A and B was ±10, ±5, and 0.","Modify,Fact/Evidence",Fact/Evidence
10209,8-420,8-420_v2_27@6,8-420_v1_28@1,"The target signal is always presented from a loudspeaker in the 0-azimuth degree and two competing signals from the loudspeakers, which are at ±45 and ±90 degree and 0 azimuth degree (once with spatial separation and twice in the direction of target signal), where once the competing signal has the same gender as the target signal and another time has a different gender.","The target signal is always presented from a loudspeaker in the 0-azimuth degree and two competing signals from the loudspeakers, which are at ±90 degree and 0 azimuth degree (once with spatial separation and once in the direction of target signal), where once the competing signal has the same gender as the target signal and another time has a different gender.","Modify,Fact/Evidence",Fact/Evidence
10210,8-420,8-420_v2_27@7,8-420_v1_28@2,"As a result, 30 conditions will be evaluated at each step (5 TMRs and three spatial angles with two different genders).","As a result, 20 conditions will be evaluated at each step (5 signal to noise ratios and two spatial angles with two different genders).","Modify,Fact/Evidence",Fact/Evidence
10211,8-420,8-420_v2_28@0,8-420_v1_29@0,"Finally, the informational masking score in all 30 conditions will be calculated as follows:","Finally, the informational masking score in all 20 conditions will be calculated as follows:","Modify,Fact/Evidence",Fact/Evidence
10212,8-420,8-420_v2_34@7,8-420_v1_34@6,"- - Determine the SSQ score <REF-31> . The SSQ self-assessment questionnaire will be filled out by the researcher during the preliminary interview. As improving informational masking can improve the speech perception quality of people, this questionnaire will be used to measure the speech perception quality of the participants quantitatively (secondary outcome).","- - Determine the SSQ score <REF-26> . The SSQ self-assessment questionnaire will be filled out by the researcher during the preliminary interview. As improving informational masking can improve the quality of life of people, this questionnaire will be used to measure the quality of life of the participants quantitatively (secondary outcome).","Modify,Fact/Evidence",Fact/Evidence
10213,8-420,8-420_v2_36@1,8-420_v1_36@1,As one of the main principles of any auditory training program is progression in difficulty so the training sessions will be divided into three general steps by considering the competing signals.,Training sessions will be divided into three general steps by considering the competing signals.,"Modify,Claim",Claim
10214,8-420,8-420_v2_36@4,8-420_v1_36@4,"Finally, for making more difficulty, sentence materials with male and female genders will be used.","Finally, sentence materials with male and female genders will be used.","Modify,Fact/Evidence",Fact/Evidence
10215,8-420,8-420_v2_7@0,8-420_v1_7@0,Many older adults complain about speech perception in noisy situations.,"Understanding speech in noisy environments is a major challenge of the auditory system, which occurs mostly due to aging.","Modify,Clarity",Clarity
10216,8-420,8-420_v2_37@0,8-420_v1_37@0,"In all steps, the target signal will be presented from the loudspeaker at 0-azimuth degree and competing signals from different azimuth angles such as ±45, ±90 and 0 <REF-38> , <REF-39> .","In all steps, the target signal will be presented from the loudspeaker at 0-azimuth degree and competing signals from different azimuth angles such as ±90 and 0 <REF-31> , <REF-32> .","Modify,Fact/Evidence",Fact/Evidence
10217,8-420,8-420_v2_39@1,8-420_v1_39@1,Three first sentences will be used for familiarization.,Three first sentences are used for familiarization.,"Modify,Grammar",Grammar
10218,8-420,8-420_v2_39@2,8-420_v1_39@2,"If an individual needs more practice, more familiarization sentences will be provided.","If an individual needs more practice, more familiarization sentences are provided.","Modify,Grammar",Grammar
10219,8-420,8-420_v2_40@0,8-420_v1_40@0,An individual will be requested to identify the keywords heard in the target sentences.,An individual is requested to identify the keywords heard in the target sentences.,"Modify,Grammar",Grammar
10220,8-420,8-420_v2_40@1,8-420_v1_40@1,"In the case of true and false identification, required feedback will be provided.","In the case of true and false identification, required feedback is provided.","Modify,Grammar",Grammar
10221,8-420,8-420_v2_40@2,8-420_v1_40@2,"If the individual identifies more than 50% of the keywords, the sentence will be considered true.","If the individual identifies more than 50% of the keywords, the sentence is considered true.","Modify,Grammar",Grammar
10222,8-420,8-420_v2_40@3,8-420_v1_40@3,"In this signal to noise ratio, 5 sentences will be provided where if the individual identifies more than 50% of the presented sentences, the signal to noise ratio decreases in 5dB steps, after which 5 sentences will be provided again for the individual.","In this signal to noise ratio, 5 sentences are provided where if the individual identifies more than 50% of the presented sentences, the signal to noise ratio decreases in 5dB steps, after which 5 sentences will be provided again for the individual.","Modify,Grammar",Grammar
10223,8-420,8-420_v2_41@1,8-420_v1_41@1,"Since long-term training is not a very suitable option in the clinic <REF-2> , trainings will be repeated three times a week completed in 5-week cycles <REF-42> .","Since long-term training is not a very suitable option in the clinic <REF-2> , trainings are repeated twice a week over 8 sessions <REF-35> .","Modify,Fact/Evidence",Fact/Evidence
10224,8-420,8-420_v2_42@0,8-420_v1_42@0,3. Assessments after auditory spatial training (interview immediately after and five weeks after training),3. Assessments after auditory spatial training (interview immediately after and one month after training),"Modify,Fact/Evidence",Fact/Evidence
10225,8-420,8-420_v2_43@0,8-420_v1_43@0,"The informational masking test (as per Part 1) will be done immediately after training and five weeks after that using the Persian list of the coordinate response measure (CRM) corpus, which will be compared with the pre-training results (preliminary interview).","The informational masking test (as per Part 1) will be done immediately after training and one month after using the Persian list of the coordinate response measure (CRM) corpus, which will be compared with the pre-training results (preliminary interview).","Modify,Fact/Evidence",Fact/Evidence
10226,8-420,8-420_v2_43@2,8-420_v1_43@2,The reason for repeating experiments five weeks after the intervention is determining the reliability of the results obtained by intervention for informational masking release.,The reason for repeating experiments one month after the intervention is determining the reliability of the results obtained by intervention for informational masking release.,"Modify,Fact/Evidence",Fact/Evidence
10227,8-420,8-420_v2_44@0,8-420_v1_44@0,"The informational masking release value will be calculated based on the difference between sentence recognition score (in all 30 conditions of signal to noise, different spatial angles, and two genders) in both noise situations (meaningful and non-understandable).","The informational masking release value will be calculated based on the difference between sentence recognition score (in all 20 conditions of signal to noise, different spatial angles, and two genders) in both noise situations (meaningful and non-understandable).","Modify,Fact/Evidence",Fact/Evidence
10228,8-420,8-420_v2_44@1,8-420_v1_44@1,"The changes in informational masking in the assessments will be calculated before and after the intervention across all 30 conditions (see Table S2 , Extended data).","The changes in informational masking in the assessments will be calculated before and after the intervention across all 20 conditions (see Table S2 , Extended data).","Modify,Fact/Evidence",Fact/Evidence
10229,8-420,8-420_v2_46@0,8-420_v1_45@0,"As the ultimate purpose of this research is improving the quality of speech perception of elderly people, the score of SSQ immediately and 5 weeks after intervention will be obtained and the results of both intervention and control groups will be compared separately.","As the ultimate purpose of this research is improving the quality of life of elderly people, the score of SSQ immediately and one month after intervention will be obtained and the results of both intervention and control groups will be compared separately.","Modify,Fact/Evidence",Fact/Evidence
10230,8-420,8-420_v2_46@1,8-420_v1_45@1,This score and the scores of ‘synthetic sentence identification test’ and ‘Persian reading span test’ will be the secondary outcomes of the interventions.,This score will be the secondary outcome of the intervention.,"Modify,Fact/Evidence",Fact/Evidence
10231,8-420,8-420_v2_46@2,8-420_v1_45@2,Figure S2 (Extended data) represents participant’s timeline of the second part of the study.,Figure S2 (Extended data) represents participants timeline of the second part of the study.,"Modify,Grammar",Grammar
10232,8-420,8-420_v2_48@3,8-420_v1_47@3,"In total, 50 young people aged between 20 and 40 years and 50 elderly people aged between 60 and 75 years, with normal peripheral hearing who do not suffer from speech understanding in noisy environments, will be recruited.","In total, 50 young people aged between 20 and 40 years and 50 elderly people aged between 60 and 75 years, with normal hearing who do not suffer from speech understanding in noisy environments, will be recruited.","Modify,Fact/Evidence",Fact/Evidence
10233,8-420,8-420_v2_59@3,8-420_v1_55@2,"According to this, the sample size calculated 14 in each group.",The sample size of this study was 16 patients in each group.,"Modify,Fact/Evidence",Fact/Evidence
10234,8-420,8-420_v2_7@10,8-420_v1_7@4,"So, the type of background noise heavily influences the extent of the damage imposed to speech intelligibility <REF-1> .","In addition, the type of background noise heavily influences the extent of the damage imposed to speech intelligibility <REF-1> .","Modify,Clarity",Clarity
10235,8-420,8-420_v2_65@4,8-420_v1_61@4,Conducting tests has no side-effects for the studied individuals and all tests and training sessions will be without cost to the participants.,Conducting tests has no side-effects for the studied individuals and all tests and training sessions are without cost to the participants.,"Modify,Grammar",Grammar
10236,8-420,8-420_v2_7@12,8-420_v1_7@6,"In this situation, in addition to energetic masking, informational masking also occurs <REF-10> .","In this situation, in addition to energetic masking, there is another type of masking known as informational masking <REF-3> .","Modify,Clarity",Clarity
10237,8-420,8-420_v2_7@6,8-420_v1_8@2,"Recent research has suggested that when competing signals occur randomly or when there is a high similarity between target and competing signals (for example, when both signals are speech), another type of masking occurs.","Recent research has suggested that when competing signals occur randomly or when there is a high similarity between target and competing signals (for example, when both signals are speech), another type of masking occurs both.","Modify,Clarity",Clarity
10238,8-420,8-420_v2_9@1,8-420_v1_10@1,"Based on the results of different studies, it has become clear that the most important sign of informational masking release is spatial separation of target and competing signals <REF-16> – <REF-18> .","Based on the results of different studies, it has become clear that the most important sign of informational masking release is spatial separation of target and competing signals <REF-16> .","Modify,Fact/Evidence",Fact/Evidence
10239,8-420,8-420_v2_9@5,8-420_v1_10@5,"On the other hand, it has been shown that the elderly population need a higher signal to noise ratio for speech recognition in the presence of noise, compared to young people <REF-11> , <REF-21> .","On the other hand, it has been shown that the elderly population need a higher signal to noise ratio for speech recognition in the presence of noise, compared to young people.","Modify,Fact/Evidence",Fact/Evidence
10240,8-420,8-420_v2_9@7,8-420_v1_10@7,"Therefore, in elderly people, without considering the peripheral hearing impairment, the ability to use spatial and non-spatial signs for informational masking release diminishes due to the reduction of cognitive processing abilities <REF-11> , <REF-12> , temporal processing defects <REF-10> , defects in the connection between hemispheres, and diminished ability to separate simultaneous sounds <REF-11> .","Therefore, in elderly people, without considering the hearing impairment, the ability to use spatial and non-spatial signs for informational masking release diminishes due to the reduction of cognitive processing abilities <REF-11> , <REF-12> , temporal processing defects <REF-3> , defects in the connection between hemispheres, and diminished ability to separate simultaneous sounds <REF-11> .","Modify,Fact/Evidence",Fact/Evidence
10241,8-420,8-420_v2_11@0,8-420_v1_12@0,The present study has two parts.,The present study had two parts.,"Modify,Grammar",Grammar
10242,8-420,8-420_v2_11@1,8-420_v1_12@1,The first part of this research will be conducted to develop a test for measuring and evaluating the informational masking.,The first part of this research was developing a test for measuring and evaluating the informational masking.,"Modify,Clarity",Clarity
10243,8-420,8-420_v2_11@5,8-420_v1_12@2,"The second part of this research will be a clinical trial of an auditory spatial training program in elderly people with normal hearing, which would diminish informational masking.","The second part of this research was a clinical trial of an auditory spatial training program in elderly people with normal hearing, which could diminish informational masking.","Modify,Grammar",Grammar
10244,8-420,8-420_v2_13@0,8-420_v1_14@0,This is version 2 of this protocol.,This is version 1 of this protocol.,"Modify,Fact/Evidence",Fact/Evidence
10245,8-420,8-420_v2_15@0,8-420_v1_16@0,This research will be conducted in the Audiology Clinic of Rehabilitation School of Iran University of Medical Sciences.,This research will be conducted in the Audiology Clinic of Rehabilitation Faculty of Iran University of Medical Sciences.,"Modify,Clarity",Clarity
10278,8-530,8-530_v2_4@2,,"When trying to characterize sequences present in a metagenomics sample, searching first for related sequences in a viral database can lead to identify rapidly a known virus (high identity between the query sequence and the one in the database), or identify potential new species (low identity with any known sequence).",,"Add,Claim",Claim
10279,8-530,8-530_v2_4@3,,Such hits must be further characterized on more comprehensive databases to increase the robustness of taxonomic assignations.,,"Add,Claim",Claim
10280,8-530,8-530_v2_5@2,,"Similarly, UniProtKB <REF-1> contains numerous viral sequences (4 497 049 in total, including 17 008 (0.38%) reviewed) that could, as for NCBI/nr, increase computation time when thousands of sequences have to be analyzed concomitantly, which is routinely practiced in metagenomics analyses.",,"Add,Fact/Evidence",Fact/Evidence
10281,8-530,8-530_v2_5@4,,RefSeq contains 13 180 virus sequences.,,"Add,Fact/Evidence",Fact/Evidence
10282,8-530,8-530_v2_12@3,,The process relies on the amino-acid sequences and information provided initially in the nucleic entry annotations.,,"Add,Fact/Evidence",Fact/Evidence
10283,8-530,8-530_v2_24@0,,"A cluster is defined as a set of sequences, among which each sequence is characterized by its taxonomy ( i.e. a virus species) and eis associated with a description of its putative function, when it is known.",,"Add,Fact/Evidence",Fact/Evidence
10284,8-530,8-530_v2_27@2,,We also produce a complementary word frequency count using sequence descriptions.,,"Add,Fact/Evidence",Fact/Evidence
10285,8-530,8-530_v2_27@3,,These keywords are stored separately from the PFAM ones.,,"Add,Fact/Evidence",Fact/Evidence
10286,8-530,8-530_v2_27@4,,"Despite the fact that sequence descriptions can be vague or inaccurate, they are a good fallback in case the cluster had no match with any PFAM one.",,"Add,Claim",Claim
10287,8-530,8-530_v2_28@1,,"Altogether, these keywords allow to describe a cluster composed of RNA-dependent RNA polymerase of picorna-like viruses.",,"Add,Claim",Claim
10288,8-530,8-530_v2_28@2,,The complementarity of these two annotations is well illustrated here since the simple list of keywords would not have allowed to identify the function of this cluster (here the viral polymerase) without PFAM.,,"Add,Claim",Claim
10289,8-530,,8-530_v1_23@0,,"In our pipeline, a cluster consists in a set of sequences, where each sequence belongs to a species, and each sequence is associated with a description.","Delete,Fact/Evidence",Fact/Evidence
10290,8-530,8-530_v2_41@2,8-530_v1_37@2,- U-RVDBv19.0-prot.fasta-prot-hmm.sqlite (SQLite db containing annotations (please find a documentation below)),- U-RVDBv15.1-prot.fasta-prot-hmm.sqlite (SQLite db containing annotations (please find a documentation below)),"Modify,Fact/Evidence",Fact/Evidence
10291,8-530,8-530_v2_41@3,8-530_v1_37@3,- U-RVDBv19.0-prot.fasta-annot.txt (a directory of annotations with plain text files (one per protein family)),- U-RVDBv15.1-prot.fasta-annot.txt (a directory of annotations with plain text files (one per protein family)),"Modify,Fact/Evidence",Fact/Evidence
10292,8-530,8-530_v2_5@3,8-530_v1_4@4,"RefSeq, on the other hand, is generally better curated but contains only full-length genomes, which reduces the diversity of available sequences, and also rarely includes the latest discoveries.","RefSeq on the other hand, is generally better curated, but it contains only full-length genomes and rarely includes the latest discoveries.","Modify,Claim",Claim
10293,8-530,8-530_v2_5@5,8-530_v1_4@5,"Other specialized databases provide only specific groups of taxa for specific purposes, for instance, virus families responsible for infectious diseases like HIV or influenza viruses.","Other specialized databases provide only specific groups of taxa for specific purposes, for instance, virus families responsible for infectious diseases like HIV or influenza.","Modify,Clarity",Clarity
10294,8-530,8-530_v2_6@0,8-530_v1_5@0,"Thus, the need for better, well-annotated and comprehensive public viral database that can be used for the identification of viruses by high-throughput sequencing led Goodacre et al. to propose their Reference Viral DataBase (RVDB) <REF-2> .","Thus, the need for better, well-annotated and comprehensive public viral databases that can be used for the identification of viruses by high-throughput sequencing lead Goodacre et al. to propose their Reference Viral DataBase (RVDB) <REF-1> .","Modify,Grammar",Grammar
10295,8-530,8-530_v2_6@1,8-530_v1_5@1,"This database consists of a collection of all currently known viral genomes and virus-related nucleic sequences retrieved from NCBI/nr or RefSeq and includes a specific, both manual and computational reviewing process, as well as four updates of the contents per year.","This database consists of a collection of all currently known viral genomes and virus-related nucleic sequences retrieved from NCBI nr or RefSeq, which includes a specific, both manual and computational reviewing process, as well as four updates of the contents per year.","Modify,Clarity",Clarity
10296,8-530,8-530_v2_6@3,8-530_v1_5@2,"This high level of curation makes RVDB quite attractive for the virology research community and in fact, in June 2020, version 19.0 was released.","These features make RVDB quite attractive for the virology research community and in fact, in February 2018, version 15.1 was released.","Modify,Fact/Evidence",Fact/Evidence
10297,8-530,8-530_v2_8@1,8-530_v1_7@1,"Additionally, proteins can also be efficiently clustered according to their similarity, and the resulting clusters can then be used to build Hidden Markov Model (HMM) profiles in order to identify more evolutionary distant proteins.","Additionally, proteins can also be efficiently clustered according to their similarity, and the resulting clusters can then be used to build Hidden Markov Model (HMM) Profiles in order to identify more evolutionary distant proteins.","Modify,Grammar",Grammar
10298,8-530,8-530_v2_8@2,8-530_v1_7@2,"In fact, programs like HMMER <REF-3> allow the building of HMM profiles from a multiple sequence alignment of proteins.","In fact, programs like HMMER <REF-2> allow the building of a HMM profile from a multiple protein sequence alignment.","Modify,Clarity",Clarity
10299,8-530,8-530_v2_8@3,8-530_v1_7@3,"This profile can then help recognizing proteins based on complex position-specific models of sequence conservation and evolution, and it does so in a more accurate way than if a classic sequence alignment is used.","This profile can then be able to recognize proteins based on complex positionspecific models of sequence conservation and evolution, and it does so in a more accurate way than if a classic sequence alignment is used.","Modify,Clarity",Clarity
10300,8-530,8-530_v2_9@0,8-530_v1_8@0,"Therefore, we propose a protein sequence version of RVDB whose update will be synchronized with the original nucleotide RVDB release.","Thus, we propose a protein sequence version of RVDB whose update will be synchronized with the original nucleotide RVDB release.","Modify,Clarity",Clarity
10301,8-530,8-530_v2_12@0,8-530_v1_11@0,"The current version of RVDB, v19.0 <REF-4> consists of a collection of 3 084 319 nucleic sequences .","The current version of RVDB, v15.1 <REF-3> consists of a collection of 2 719 839 nucleic sequences <REF-1> .","Modify,Fact/Evidence",Fact/Evidence
10302,8-530,8-530_v2_12@1,8-530_v1_11@1,The accession numbers were extracted in order to gather the corresponding database entries in Genbank format.,The accession numbers were extracted in order to gather the corresponding database entries in genbank format.,"Modify,Grammar",Grammar
10303,8-530,8-530_v2_12@2,8-530_v1_11@2,"From these entries, the corresponding coding domain protein sequences, description, and protein accession numbers were automatically recognized and copied into the protein collection.","From these entries, coding domain sequences and the description of these sequences were located and copied into the protein collection.","Modify,Fact/Evidence",Fact/Evidence
10304,8-530,8-530_v2_20@0,8-530_v1_19@0,This process produces a 4 705 359 protein sequence file.,This process produces a 3 899 699 protein sequence file.,"Modify,Fact/Evidence",Fact/Evidence
10305,8-530,8-530_v2_22@0,8-530_v1_21@0,"The HMM generation rationale was inspired from vFam (the database of HMM profiles built from all the viral proteins present in RefSeq, discontinued from 2014) <REF-5> , but was entirely re-coded as a Snakemake pipeline <REF-6> , using different tools for some key steps (clustering, alignment).","The HMM generation rationale was inspired from VFam (the database of profile HMM built from all the viral proteins present in RefSeq, discontinued from 2014) <REF-4> , but was entirely re-coded as a Snakemake pipeline <REF-5> , using different tools for some key steps (clustering, alignment).","Modify,Grammar",Grammar
10306,8-530,8-530_v2_22@1,8-530_v1_21@1,The proteins sequences were clustered with a 100% identity criterion to remove duplicates using CD-Hit 4.7.0 <REF-7> .,"The proteins sequences were clustered with a 100% identity criteria to duplicates, using CDHit 4.7.0 <REF-6> .","Modify,Fact/Evidence",Fact/Evidence
10307,8-530,8-530_v2_22@3,8-530_v1_21@3,These comparisons allowed Silix 1.2.6 <REF-9> (using default parameters) to define clusters of sequences according to their similarity.,These comparisons allow Silix 1.2.6 <REF-8> to define clusters of sequences according to the sequence similarity.,"Modify,Fact/Evidence",Fact/Evidence
10308,8-530,8-530_v2_22@4,8-530_v1_21@4,This step produced a text file in which each sequence was associated to one cluster.,This step produces a file text in which each sequence is associated to one cluster.,"Modify,Grammar",Grammar
10309,8-530,8-530_v2_22@5,8-530_v1_21@5,The information of each cluster (containing at least four sequences) was transformed into a fasta file containing all the sequences within the cluster.,The information of each cluster containing at least four sequences was transformed into a fasta file containing all of its sequences.,"Modify,Clarity",Clarity
10310,8-530,8-530_v2_22@6,8-530_v1_21@6,"Then, sequences were aligned using Mafft 7.023 <REF-10> in auto mode.","Then, we performed multiple alignment using Mafft 7.023 <REF-9> in auto mode.","Modify,Clarity",Clarity
10311,8-530,8-530_v2_22@7,8-530_v1_21@7,"The multiple sequence alignments were processed by HMMER 3.2.1 <REF-3> (hmmbuild, using default parameters) in order to obtain the HMM profiles.",The multiple sequence alignments were processed by HMMER 3.2.1 <REF-2> in order to obtain the HMM profiles.,"Modify,Fact/Evidence",Fact/Evidence
10312,8-530,8-530_v2_22@8,8-530_v1_21@8,The HMM profiles were finally grouped into a single file.,The HMM profiles were then put together in a single file.,"Modify,Clarity",Clarity
10313,8-530,8-530_v2_24@1,8-530_v1_23@1,"In order to describe the different clusters, these information and other indicators (such as the cluster length and number of sequences) are combined into an annotation database, in SQLite format.","In order to characterize the clusters, these pieces of information and other indicators (such as cluster length and sequence number) are combined into an annotation database, in SQLite format.","Modify,Clarity",Clarity
10314,8-530,8-530_v2_4@0,8-530_v1_4@0,"Sequence assignation often uses similarity criteria to infer homology, and hence taxonomy and / or protein function.","Sequence assignation often uses similarity criteria to infer homology, and hence taxonomy and / or protein type.","Modify,Clarity",Clarity
10315,8-530,8-530_v2_27@0,8-530_v1_26@0,The first type of data associated to a cluster is a set of keywords describing the putative function of the proteins present in a given cluster.,The first type of data associated to a cluster is a set of keywords.,"Modify,Fact/Evidence",Fact/Evidence
10316,8-530,8-530_v2_27@1,8-530_v1_26@1,"These keywords correspond to the union of all names of the significant sequences found in PFAM <REF-11> (with --cut_ga parameter which tells HMMER to trust the cutoff defined by PFAM) using all the sequences of the cluster as queries, weighted according to their frequencies, and excluding trivial words.","These keywords correspond to the union of all the set of sequence names belonging to the cluster, weighted according to their frequencies, and excluding trivial words.","Modify,Fact/Evidence",Fact/Evidence
10317,8-530,8-530_v2_29@0,8-530_v1_26@3,"In addition to the protein description, the database stores the virus taxonomy associated to all the taxa, referring to tNCBI TaxIDs.","The database stores all these taxa, using NCBI TaxIDs.","Modify,Fact/Evidence",Fact/Evidence
10318,8-530,8-530_v2_29@1,8-530_v1_26@4,"For each cluster, the taxonomic information is summarized by a Last Common Ancestor (LCA) that corresponds to the taxon in the tree of life to which all the sequence taxa belong; this LCA can be close to the root of the tree (Viruses), but is usually specific to a family.","For each cluster, the taxonomic information is summarized by a Last Common Ancestor (LCA) that corresponds to the taxon in the tree of life to which all the sequence taxa belong.","Modify,Claim",Claim
10319,8-530,8-530_v2_4@1,8-530_v1_4@1,"In order to search for this, similarity, reliable, accurate and comprehensive databases are required.","In order to search for this similarity, reliable, accurate and comprehensive databases are required.","Modify,Grammar",Grammar
10320,8-530,8-530_v2_31@1,8-530_v1_27@1,"A text file for each cluster, identified with its cluster number, contains all the information related to it.","A text file for each cluster, identified with its cluster number contains all the information related to it.","Modify,Grammar",Grammar
10321,8-530,8-530_v2_5@0,8-530_v1_4@2,"In the specific field of viruses, several solutions are available but their ability to provide valid results is highly dependent on the goal of the study and on the available computer resources.","In the specific field of viruses, several solutions are available yet their ability to provide valid results is highly dependant on the goal of the study and on the available computer resources.","Modify,Grammar",Grammar
10322,8-530,8-530_v2_38@1,8-530_v1_34@1,Release 19.0 described in this manuscript is also available from Zenodo.,Release 15.1 described in this manuscript is also available from Figshare.,"Modify,Fact/Evidence",Fact/Evidence
10323,8-530,8-530_v2_41@0,8-530_v1_37@0,- U-RVDBv19.0-prot.fasta (fasta file containing protein features of the original database: -prot.fasta),- U-RVDBv15.1-prot.fasta (fasta file containing protein features of the original database: -prot.fasta),"Modify,Fact/Evidence",Fact/Evidence
10324,8-530,8-530_v2_41@1,8-530_v1_37@1,"- U-RVDBv19.0-prot.fasta-prot.hmm (the HMM profiles, generated with and for hmmer 3.2.1 (from 2019, 3.1b2 before))","- U-RVDBv15.1-prot.fasta-prot.hmm (the HMM profiles, generated with and for hmmer 3.2.1 (from 2019, 3.1b2 before))","Modify,Fact/Evidence",Fact/Evidence
10325,8-56,8-56_v2_13@0,,In total 108 oyster were used in this study.,,"Add,Fact/Evidence",Fact/Evidence
10326,8-56,8-56_v2_13@2,,"Sub-station 1 located in port, sub-station 2 located in fish market, sub-station 3 located in between mangrove and beach.",,"Add,Fact/Evidence",Fact/Evidence
10327,8-56,8-56_v2_25@0,,The research station was taken from three different locations.,,"Add,Fact/Evidence",Fact/Evidence
10328,8-56,8-56_v2_25@1,,"The first station is Sendang Biru Coastal area, one of the major ports on the southern coast of East Java and tourist area.",,"Add,Fact/Evidence",Fact/Evidence
10329,8-56,8-56_v2_25@2,,The second station is the Popoh Beach area which is a tourist area and settlement.,,"Add,Fact/Evidence",Fact/Evidence
10330,8-56,8-56_v2_25@3,,"The third station is Prigi Beach which is a tourist beach, settlement and fishing port area.",,"Add,Fact/Evidence",Fact/Evidence
10331,8-56,8-56_v2_44@12,,Raw data are available on OSF <REF-41> .,,"Add,Fact/Evidence",Fact/Evidence
10332,8-56,8-56_v2_34@0,8-56_v1_29@0,"Heavy metals (Pb, Cd, and Hg) in Crassostrea cuculata and Crassostrea glomerata gills and stomach tissue is exhibited in Figure 3 .","Heavy metals (Pb, Cd, and Hg) in Crassostrea cuculata and Crassostrea glomerata gills and gastric tissue is exhibited in Figure 2 .","Modify,Clarity",Clarity
10333,8-56,8-56_v2_4@1,8-56_v1_4@1,"In general, the expression of MT was found to be higher in stomach tissue compared to gill tissue.","In general, the expression of MT was found to be higher in gastric tissue compared to gill tissue.","Modify,Clarity",Clarity
10334,8-56,8-56_v2_34@2,8-56_v1_29@2,"Whereas the highest heavy metal level in Crassostrea cuculata stomach tissue Pb, Hg and Cd levels were observed at the Sendang Biru station in sub-station 1, at 0.067, 0.036 and 0.077 mg l -1 respectively ( Figure 3B ).","Whereas the highest heavy metal level in Crassostrea cuculata gastric tissue Pb, Hg and Cd levels were observed at the Sendang Biru station in sub-station 1, at 0.067, 0.036 and 0.077 mg l -1 respectively ( Figure 2B ).","Modify,Clarity",Clarity
10335,8-56,8-56_v2_37@2,8-56_v1_32@2,"The highest value of stomach Pb and Cd content was observed in Prigi stations in substations 1 and 3: 0.145 and 0.047 mg l -1 , respectively ( Figure 3D ).","The highest value of gastric Pb and Cd content was observed in Prigi stations in substations 1 and 3: 0.145 and 0.047 mg l -1 , respectively ( Figure 2D ).","Modify,Clarity",Clarity
10336,8-56,8-56_v2_41@1,8-56_v1_36@1,Research results exhibited that in MT stomach tissue overall expression was higher than gill tissue ( Figure 4A ).,Research results exhibited that in MT gastric tissue overall expression was higher than gill tissue ( Figure 3A ).,"Modify,Clarity",Clarity
10337,8-56,8-56_v2_41@3,8-56_v1_36@3,The lowest expression on the stomach tissue was found at Sendang Biru station ranging from 453.246–511.098 arbitrary units.,The lowest expression on the gastric tissue was found at Sendang Biru station ranging from 453.246–511.098 arbitrary units.,"Modify,Clarity",Clarity
10338,8-56,8-56_v2_41@8,8-56_v1_36@8,"In Figure 4B , Rhodamine-MT as metallothionine marker is expressed brighter in stomach tissue compared to gill tissue.","In Figure 3B , Rhodamine-MT as metallothionine marker is expressed brighter in gastric tissue compared to gill tissue.","Modify,Clarity",Clarity
10339,8-56,8-56_v2_41@9,8-56_v1_36@9,"Figure 4C shows rhodamine-MT absorption, as an MT marker, is recorded to have a higher intensity in stomach tissues compared to gill tissues.","Figure 3C shows rhodamine-MT absorption, as an MT marker, is recorded to have a higher intensity in gastric tissues compared to gill tissues.","Modify,Clarity",Clarity
10340,8-56,8-56_v2_44@0,8-56_v1_39@0,Heavy metal content was inversely proportional to MT expression in the gill and stomach tissues.,Heavy metal content was inversely proportional to MT expression in the gill and gastric tissues.,"Modify,Clarity",Clarity
10341,8-56,8-56_v2_44@3,8-56_v1_39@3,"Conversely, heavy metal in stomach tissue accumulates less compared to gill tissue.","Conversely, heavy metal in gastric tissue accumulates less compared to gill tissue.","Modify,Clarity",Clarity
10342,8-56,8-56_v2_44@8,8-56_v1_39@8,"Previous research has revealed that MT has a crucial role in various processes of biological activity; it binds heavy metals and conduct recovery process from systemic damage caused by heavy metals through homeostasis process (dynamic balancing of the body’s biological processes) to heavy metals <REF-43> , <REF-44> , and heavy metal detoxification <REF-45> , <REF-46> .","Previous research has revealed that MT has a crucial role in various processes of biological activity; it binds heavy metals and conduct recovery process from systemic damage caused by heavy metals through homeostasis process (dynamic balancing of the body's biological processes) to heavy metals <REF-43> , <REF-44> , and heavy metal detoxification <REF-45> , <REF-46> .","Modify,Grammar",Grammar
10343,8-56,8-56_v2_46@2,8-56_v1_41@2,MT expression in the stomach tissue of Crassostrea glomerata is expressed higher than gill tissue ( Figure 5A ).,MT expression in the gastric tissue of Crassostrea glomerata is expressed higher than gill tissue ( Figure 4A ).,"Modify,Clarity",Clarity
10344,8-56,8-56_v2_46@3,8-56_v1_41@3,"The highest MT expression in stomach tissue was obtained at Prigi Station sub-station 1 with a value of 1412,112 arbitrary units.","The highest MT expression in gastric tissue was obtained at Prigi Station sub-station 1 with a value of 1412,112 arbitrary units.","Modify,Clarity",Clarity
10345,8-56,8-56_v2_46@4,8-56_v1_41@4,"The lowest MT expression in stomach tissue was obtained from Sendang Biru sub-station 3 with a value of 576,243 arbitrary units.","The lowest MT expression in gastric tissue was obtained from Sendang Biru sub-station 3 with a value of 576,243 arbitrary units.","Modify,Clarity",Clarity
10346,8-56,8-56_v2_46@7,8-56_v1_41@7,Higher MT expression was observed in stomach tissue compared to gill tissue morphologically ( Figure 5B ).,Higher MT expression was observed in gastric tissue compared to gill tissue morphologically ( Figure 4B ).,"Modify,Clarity",Clarity
10347,8-56,8-56_v2_46@8,8-56_v1_41@8,The morphological results exhibited that MT labeled Rhodamine-B in stomach tissue appears brighter than gill tissue.,The morphological results exhibited that MT labeled Rhodamine-B in gastric tissue appears brighter than gill tissue.,"Modify,Clarity",Clarity
10348,8-56,8-56_v2_46@10,8-56_v1_41@10,Figure 5C exhibited that the Rhodamine-MT absorption as an MT marker possesses a higher intensity in gill tissue compared to stomach tissue.,Figure 4C exhibited that the Rhodamine-MT absorption as an MT marker possesses a higher intensity in gill tissue compared to gastric tissue.,"Modify,Clarity",Clarity
10349,8-56,8-56_v2_49@4,8-56_v1_44@4,MT expression in Crassostrea cuculata highest value was found in stomach tissue and the lowest value in gill tissue.,MT expression in Crassostrea cuculata highest value was found in gastric tissue and the lowest value in gill tissue.,"Modify,Clarity",Clarity
10350,8-56,8-56_v2_49@7,8-56_v1_44@7,"Therefore, MT expression in the gill tissue was detected as lower than that in stomach tissue.","Therefore, MT expression in the gill tissue was detected as lower than that in gastric tissue.","Modify,Clarity",Clarity
10351,8-56,8-56_v2_52@0,8-56_v1_47@0,"Furthermore, a similar result was found in the relationship between the heavy metal level of Pb, Hg, and Cd with the stomach tissue MT expression.","Furthermore, a similar result was found in the relationship between the heavy metal level of Pb, Hg, and Cd with the gastric tissue MT expression.","Modify,Clarity",Clarity
10352,8-56,8-56_v2_52@2,8-56_v1_47@2,"Multiple linear regression equations of heavy metal level in the aquatic body against MT levels Crassostrea cuculata stomach assessment obtained the equation Y = 494.528 + 4,075.811 X 1 + 2,852.821 X 2 + 5,990.359 X 3 .","Multiple linear regression equations of heavy metal level in the aquatic body against MT levels Crassostrea cuculata gastric assessment obtained the equation Y = 494.528 + 4,075.811 X 1 + 2,852.821 X 2 + 5,990.359 X 3 .","Modify,Clarity",Clarity
10353,8-56,8-56_v2_56@0,8-56_v1_51@0,"The relationship between the heavy metal level of Pb, Hg, Cd in the aquatic body and MT expression Crassostrea glomerata stomach tissue exhibited a strong relationship with the value of the coefficient of determination (R 2 ) of 0.918.","The relationship between the heavy metal level of Pb, Hg, Cd in the aquatic body and MT expression Crassostrea glomerata gastric tissue exhibited a strong relationship with the value of the coefficient of determination (R 2 ) of 0.918.","Modify,Clarity",Clarity
10354,8-56,8-56_v2_56@1,8-56_v1_51@1,Multiple linear regression equations of heavy metal level in the aquatic body against MT expression in Crassostrea glomerata stomach tissue was found to be similar.,Multiple linear regression equations of heavy metal level in the aquatic body against MT expression in Crassostrea glomerata gastric tissue was found to be similar.,"Modify,Clarity",Clarity
10355,8-56,8-56_v2_28@1,8-56_v1_57@1,"According to KEPMENLH. 51 of 2004 <REF-26> , it indicates the temperature suitable for oysters growth is 25–34°C.","According to KEPMENLH. 51 of 2004 <REF-26> , it indicates the temperature suitable for oysters growth is 25-34°C.","Modify,Grammar",Grammar
10356,8-56,8-56_v2_13@1,8-56_v1_13@0,"Three samples of oyster ( Crassostrea cuculata and Crassostrea glomerata ) were collected in three of each of the three sub-stations on the Sendang Biru (Malang) coast, Prigi beach (Trenggalek) and Popoh beach (Tulungagung).","In total, three samples of oyster ( Crassostrea cuculata and Crassostrea glomerata ) were collected in three of each of the three sub-stations on the Sendang Biru (Malang) coast, Prigi beach (Trenggalek) and Popoh beach (Tulungagung).","Modify,Clarity",Clarity
10357,8-56,8-56_v2_13@6,8-56_v1_13@4,Oyster samples were taken three times for gills and stomach tissue taken in each sub-station and each was analyzed separately.,Oyster samples were taken three times for gills and gastric tissue taken in each sub-station and each was analysed separately.,"Modify,Clarity",Clarity
10358,8-56,8-56_v2_16@2,8-56_v1_16@2,"In order to obtain a complete oxidation process in the decomposition of organic substances, to each sample of gill and stomach tissue (0.2 grams), 2 ml of HNO 3 were added.","In order to obtain a complete oxidation process in the decomposition of organic substances, to each sample of gill and gastric tissue (0.2 grams), 2 ml of HNO 3 were added.","Modify,Clarity",Clarity
10359,8-56,8-56_v2_16@3,8-56_v1_16@3,The samples were incubated for 30 minutes at low temperatures (5–8°C) to avoid minerals lost during the evaporation process.,The samples were incubated for 30 minutes at low temperatures (5-8°C) to avoid minerals lost during the evaporation process.,"Modify,Grammar",Grammar
10360,8-56,8-56_v2_18@5,8-56_v1_18@5,The sample was cut into 2–3 mm sections using a microtome and dehydrated using the Tissue Tex Processor.,The sample was cut into 2-3 mm sections using a microtome and dehydrated using the Tissue Tex Processor.,"Modify,Grammar",Grammar
10361,8-56,8-56_v2_22@2,8-56_v1_22@2,"Using the method outlined bn Hertika et al. <REF-17> , the relationship between heavy metal levels with MT (MT) expression was obtained from multiple regression results with variable Y exhibiting heavy metals in oyster gills or stomach tissue.","Using the method outlined bn Hertika et al. <REF-17> , the relationship between heavy metal levels with MT (MT) expression was obtained from multiple regression results with variable Y exhibiting heavy metals in oyster gills or gastric tissue.","Modify,Clarity",Clarity
10362,8-583,8-583_v2_105@4,,"Unfortunately we were unaware of the Global Research Identifier Database project https://www.grid.ac/ which helps to standardise institution names, and incorporating this data could improve our table accuracy.",,"Add,Claim",Claim
10363,8-583,8-583_v2_3@3,,We used Scopus to identify the citations.,,"Add,Fact/Evidence",Fact/Evidence
10364,8-583,8-583_v2_23@1,,"The one example is the Scimago Institutions Rankings which includes the percent of Open Access papers, however this is weighted at just 2% and far higher weightings are given to publication numbers and citations.",,"Add,Claim",Claim
10365,8-583,8-583_v2_28@4,,"Our aim is to reward research “soundness” rather than the typical aim of rewarding “excellence”, an approach which has failed to improve research quality and has instead fueled hyper-competition by rewarding the quantity of research <REF-27> .",,"Add,Fact/Evidence",Fact/Evidence
10366,8-583,8-583_v2_40@0,8-583_v1_40@0,"We used Scopus to identify citations because it is a recognised database for citations that is used by four international league tables, and because of the ease of extracting the data using the rscopus package in R <REF-36> (Version 0.6.3).","We used Scopus to identify citations because it is a recognised database for citations that is used by three international league tables, and because of the ease of extracting the data using the rscopus package in R <REF-35> (Version 0.6.3).","Modify,Fact/Evidence",Fact/Evidence
10367,8-583,8-583_v2_7@2,8-583_v1_7@2,"There are also national league tables, such as the Complete University guide in the UK, and there are also national ranking systems such as the UK Research Excellence Framework, but in this study we only consider international league tables.","There are also national league tables, such as the Complete University guide in the UK, but in this study we only consider international league tables.","Modify,Claim",Claim
10368,8-583,8-583_v2_23@0,8-583_v1_23@0,"To our knowledge, only one current international league table includes a measure of best publication practices, by which we mean established methods that increase the robustness, transparency and reproducibility of research.","To our knowledge, no current international league table includes a measure of best publication practices, by which we mean established methods that increase the robustness, transparency and reproducibility of research.","Modify,Claim",Claim
10369,8-646,,8-646_v1_16@0,,The functions of the toolbox can be performed step-by-step given its modular structure.,"Delete,Fact/Evidence",Fact/Evidence
10370,8-646,,8-646_v1_16@1,,Each module has a specific task and one function from each module calls the others.,"Delete,Fact/Evidence",Fact/Evidence
10371,8-646,,8-646_v1_16@2,,A system can be analysed by calling the main functions from the modules.,"Delete,Fact/Evidence",Fact/Evidence
10372,8-646,,8-646_v1_16@3,,The advantage of this structure is its modularity as each module can be expanded easily and further modules also implemented in a simple way.,"Delete,Claim",Claim
10373,8-646,,8-646_v1_16@4,,A list of their functions and dependencies on each other is presented in the manual.,"Delete,Fact/Evidence",Fact/Evidence
10374,8-646,,8-646_v1_26@1,,"Although many biological networks are available from public databases, due to their complex nature, they are unsuitable for such a simple illustration.","Delete,Claim",Claim
10375,8-646,,8-646_v1_26@2,,"Therefore, the services of the NOCAD toolbox are presented on simple artificial networks.","Delete,Fact/Evidence",Fact/Evidence
10376,8-646,,8-646_v1_27@3,,An example of the application of the path finding method for the creation of a state-space model from the adjacency matrix ( A ) is shown in Figure 2 .,"Delete,Fact/Evidence",Fact/Evidence
10377,8-646,,8-646_v1_27@4,,"In this figure, B denotes the resulting input matrix, C the output matrix, while D stands for representing the direct feedthrough.","Delete,Fact/Evidence",Fact/Evidence
10378,8-646,,8-646_v1_30@0,,"As the configuration above is not complex enough to demonstrate the functions of the second module, a more complex configuration of the input and output nodes is used.","Delete,Claim",Claim
10379,8-646,,8-646_v1_30@1,,"The sample input and output configurations can be seen in Figure 3 , where the input and the output nodes are denoted by blue and red, respectively.","Delete,Fact/Evidence",Fact/Evidence
10380,8-646,,8-646_v1_33@0,,The system presented in Figure 3 consists of 9 state variables and 15 directed connections between them.,"Delete,Fact/Evidence",Fact/Evidence
10381,8-646,,8-646_v1_33@1,,"Quality measures calculated by the System characterisation module of the NOCAD toolbox can be seen in Figure 4 , Figure 5 , and Figure 6 .","Delete,Fact/Evidence",Fact/Evidence
10382,8-646,,8-646_v1_40@0,,"In Figure 4 , measures qualifying the whole system with one value are presented.","Delete,Fact/Evidence",Fact/Evidence
10383,8-646,,8-646_v1_41@0,,Node centrality measures assigned to the state variables of the system are also presented in Figure 4 .,"Delete,Fact/Evidence",Fact/Evidence
10384,8-646,,8-646_v1_42@0,,"In Figure 5 , the first vectors (referred to as driver and sensor nodes) show the driver and sensor nodes as logical vectors.","Delete,Fact/Evidence",Fact/Evidence
10385,8-646,,8-646_v1_42@1,,"The following four vectors classify these nodes as source, external, internal and inaccessible driver and sensor nodes.","Delete,Fact/Evidence",Fact/Evidence
10386,8-646,,8-646_v1_42@2,,These types of nodes are introduced in <REF-24> in detail.,"Delete,Fact/Evidence",Fact/Evidence
10387,8-646,,8-646_v1_42@3,,"In the next section of the figure, the controlling and observing matrices are presented.","Delete,Fact/Evidence",Fact/Evidence
10388,8-646,,8-646_v1_42@5,,"In Figure 5 , we converted them into row vectors for their appropriate visualisation.","Delete,Fact/Evidence",Fact/Evidence
10389,8-646,,8-646_v1_42@8,,The similarity of driver nodes x 4 and x 6 is 0.81.,"Delete,Fact/Evidence",Fact/Evidence
10390,8-646,,8-646_v1_42@9,,"In this case, the reason why it is less than 1 is that although they control the same set of nodes, the numbers of derivations that influence them are different.","Delete,Fact/Evidence",Fact/Evidence
10391,8-646,,8-646_v1_42@10,,"In terms of sensor similarity, sensor nodes x 2 and x 3 observe the same set of nodes and they do this almost simultaneously, so their similarity is 0.91.","Delete,Fact/Evidence",Fact/Evidence
10392,8-646,,8-646_v1_43@7,,"In the topology presented, nodes x 1 , x 2 and x 3 , or nodes x 4 , x 5 , x 6 and x 7 also create parts of the network that possess redundancy.","Delete,Fact/Evidence",Fact/Evidence
10393,8-646,,8-646_v1_44@1,,Results provided by this module can be seen in Figure 7 .,"Delete,Fact/Evidence",Fact/Evidence
10394,8-646,,8-646_v1_44@3,,"Results show that all the methods determine the same set of driver nodes for the system, that is, they are sufficient to influence state variables x 4 and x 8 .","Delete,Fact/Evidence",Fact/Evidence
10395,8-646,,8-646_v1_44@4,,"The resultant cost is 1.5556, the relative degree is 2 which satisfies the requirements, and the mean of the relative degrees is 1.1111.","Delete,Fact/Evidence",Fact/Evidence
10396,8-646,,8-646_v1_44@5,,"In this configuration, six different nodes can be identified which can be damaged separately and the system remains controllable.","Delete,Fact/Evidence",Fact/Evidence
10397,8-646,,8-646_v1_44@6,,This is expressed by the value of robustness (66.6%).,"Delete,Fact/Evidence",Fact/Evidence
10398,8-646,,8-646_v1_44@7,,"The most important nodes in terms of controllability are x 2 , x 4 and x 7 .","Delete,Fact/Evidence",Fact/Evidence
10399,8-646,,8-646_v1_44@8,,"In the case of observability, methods yield different solutions with the exception of the centrality measures-based and mCLASA algorithms which provide the best configuration in this case.","Delete,Fact/Evidence",Fact/Evidence
10400,8-646,,8-646_v1_44@9,,"Although the cost as well as the maximum and mean of the relative degree were identical in the case of retrofit set covering-based and GDFCMSA methods as well, the robustness analysis of these configurations exhibits a higher degree of vulnerability.","Delete,Fact/Evidence",Fact/Evidence
10401,8-646,,8-646_v1_56@0,,Author contributions,"Delete,Other",Other
10402,8-646,,8-646_v1_57@0,,"Dániel Leitold reviewed the literature on network science, developed the algorithms, implemented the Octave and MATLAB functions, designed as well as performed the experiments, and wrote the related sections.","Delete,Fact/Evidence",Fact/Evidence
10403,8-646,,8-646_v1_57@1,,Ágnes Vathy-Fogarassy participated in the formalisation of the methodology.,"Delete,Fact/Evidence",Fact/Evidence
10404,8-646,,8-646_v1_57@2,,"János Abonyi developed the algorithms, implemented the Octave and MATLAB functions and proofread the paper.","Delete,Fact/Evidence",Fact/Evidence
10405,8-646,8-646_v2_2@1,,"In this paper, the applicability of the methodology in the field of life sciences is introduced through the analysis of the neural network of Caenorhabditis elegans.",,"Add,Fact/Evidence",Fact/Evidence
10406,8-646,8-646_v2_4@3,,"A review about the utilisation of the network science-based determination of driver nodes has also been published that introduced the results of the analysis of the protein-protein interaction (PPI) networks, Caenorhabditis elegans neuronal network, neurochemical rat brain network, Saccharomyces cerevisiae cell cycle networks, Epithelial Mesenchymal Transition (EMT) network, myeloid differentiation regulatory network and Th differentiation network, moreover, the identification of drug targets was also presented <REF-3> .",,"Add,Fact/Evidence",Fact/Evidence
10407,8-646,8-646_v2_6@0,,"The contribution of this paper is to introduce the novel toolbox, NOCAD <REF-9> , and its applicability in the life sciences through the example of the local network of 131 frontal neurons of Caenorhabditis elegans <REF-10> .",,"Add,Fact/Evidence",Fact/Evidence
10408,8-646,8-646_v2_6@1,,The proposed toolbox is also suitable for the comprehensive analysis of any linear or linearised dynamical systems through their static network representation <REF-11> – <REF-13> .,,"Add,Fact/Evidence",Fact/Evidence
10409,8-646,8-646_v2_6@2,,"Although in the literature the phrase dynamical network is commonly used, it does not mean that the nodes or connections are temporal but refers to the network of dynamical systems.",,"Add,Claim",Claim
10410,8-646,8-646_v2_6@3,,"In the nonlinear case, the methodology needs further clarification because for small nonlinear examples the results can be incorrect <REF-14> and the cardinality of the assigned sensors underestimated <REF-15> .",,"Add,Fact/Evidence",Fact/Evidence
10411,8-646,8-646_v2_6@4,,"As a result, this toolbox deals with only the linear case, nonlinear system-related methods will be implemented later.",,"Add,Claim",Claim
10412,8-646,8-646_v2_6@5,,"In the following sections, the representation of linear systems as well as their structural controllability and observability are introduced.",,"Add,Fact/Evidence",Fact/Evidence
10413,8-646,8-646_v2_6@6,,Then the theoretical background of the methodology is presented and the implemented functions and measurements introduced through the network of rostral ganglia of C.elegans.,,"Add,Fact/Evidence",Fact/Evidence
10414,8-646,8-646_v2_7@0,,Existing software,,"Add,Other",Other
10415,8-646,8-646_v2_14@0,,In the background of the toolbox the linear systems and their structural controllability and observability properties are stood <REF-26> .,,"Add,Fact/Evidence",Fact/Evidence
10416,8-646,8-646_v2_14@1,,A linear time-invariant (LTI) system is commonly described by its state-space representation that consists of the state equation ( Eq. 1 ) and the output equation ( Eq.2 ).,,"Add,Fact/Evidence",Fact/Evidence
10417,8-646,8-646_v2_17@0,,"In the state-space representation, x stands for state variables, u represents the inputs, i.e. the actuators, and y denotes the vector of outputs, i.e. the sensors of the system.",,"Add,Fact/Evidence",Fact/Evidence
10418,8-646,8-646_v2_17@1,,"Matrices A and B define how state variables and inputs influence changes to the state variables, while matrices C and D define how state variables and inputs influence the outputs, respectively.",,"Add,Fact/Evidence",Fact/Evidence
10419,8-646,8-646_v2_17@2,,"The cardinality of state variables, inputs and outputs are noted by N , M and K , respectively.",,"Add,Fact/Evidence",Fact/Evidence
10420,8-646,8-646_v2_18@0,,A dynamical system is said to be controllable if it can be driven from any initial state to any desired final state within a finite time with properly selected inputs.,,"Add,Claim",Claim
10421,8-646,8-646_v2_18@1,,Observability is the mathematical dual of controllability.,,"Add,Claim",Claim
10422,8-646,8-646_v2_18@2,,A system is said to be observable if its state can be determined at a given time by a finite set of measured input and output variables.,,"Add,Claim",Claim
10423,8-646,8-646_v2_19@0,,"To ensure controllability (or observability) using a minimum number of inputs (or outputs), a brute force approach should generate 2 N – 1 configurations of matrix B (or C ).",,"Add,Fact/Evidence",Fact/Evidence
10424,8-646,8-646_v2_19@1,,"To solve this challenging task, the maximum set of disjoint edges is generated by the maximum matching algorithm <REF-1> .",,"Add,Fact/Evidence",Fact/Evidence
10425,8-646,8-646_v2_19@2,,Two edges are disjointed if they do not share a common starting point or endpoint.,,"Add,Fact/Evidence",Fact/Evidence
10426,8-646,8-646_v2_19@3,,"The matched nodes are the endpoints of the edges that are a member of the maximum set of disjoint edges, the others are unmatched.",,"Add,Fact/Evidence",Fact/Evidence
10427,8-646,8-646_v2_19@4,,"Then the unmatched nodes that are generated based on A are the sensor nodes, where outputs should be placed to grant structural observability, while the unmatched nodes generated based on A T are the driver nodes, where inputs should be placed to grant structural controllability.",,"Add,Fact/Evidence",Fact/Evidence
10428,8-646,8-646_v2_19@5,,A T is also the adjacency matrix of the network representation that is the input of the toolbox.,,"Add,Fact/Evidence",Fact/Evidence
10429,8-646,8-646_v2_19@6,,"It is very important to note that the result of maximum matching is not unique, and it is possible that the matching is perfect, i.e. no unmatched nodes have resulted.",,"Add,Claim",Claim
10430,8-646,8-646_v2_19@7,,"In our implementation, the canonical decomposition of Dulmage-Mendelsohn was utilised to calculate maximum matching <REF-28> .",,"Add,Fact/Evidence",Fact/Evidence
10431,8-646,8-646_v2_20@0,,"For a better understanding, we illustrate the aforementioned definitions by a small example in Figure 1 that contains the command interneurons AVAL, AVAR, AVBL, AVBR, AVDL and AVDR from the frontal neural network of neurons and synapses in C. elegans.",,"Add,Fact/Evidence",Fact/Evidence
10432,8-646,,8-646_v1_2@2,,"In this paper, the functionality of the toolbox is presented, and the implemented functions demonstrated.","Delete,Fact/Evidence",Fact/Evidence
10433,8-646,8-646_v2_27@1,,The input of the first module is the adjacency matrix of the network to be analysed.,,"Add,Fact/Evidence",Fact/Evidence
10434,8-646,8-646_v2_27@2,,The second module requires the matrices of the dynamical system generated by the first module.,,"Add,Fact/Evidence",Fact/Evidence
10435,8-646,8-646_v2_27@3,,The result of the second module is a structure that is also the input of the third module.,,"Add,Fact/Evidence",Fact/Evidence
10436,8-646,8-646_v2_31@0,,"Although the last module seems to be out of line at first, its existence is reasonable.",,"Add,Claim",Claim
10437,8-646,8-646_v2_31@1,,The importance of the controllability of a complex system has already been addressed <REF-1> .,,"Add,Fact/Evidence",Fact/Evidence
10438,8-646,8-646_v2_31@2,,"In terms of control theory, the relative degree is an important measure to describe how fast the system can be influenced or how sluggish it is.",,"Add,Claim",Claim
10439,8-646,8-646_v2_31@3,,"In the field of biology, this “speed” is also important, e.g. the time elapsed between taking a painkiller and feeling its effect.",,"Add,Claim",Claim
10440,8-646,8-646_v2_37@0,,"After utilising the second module of the toolbox, the measures that qualify the whole network with one value are introduced, as presented in Table 2 .",,"Add,Fact/Evidence",Fact/Evidence
10441,8-646,8-646_v2_37@1,,The network contains 131 neurons and 764 synapses.,,"Add,Fact/Evidence",Fact/Evidence
10442,8-646,8-646_v2_40@0,,The second module generates node centrality measures that can reveal structurally important nodes.,,"Add,Fact/Evidence",Fact/Evidence
10443,8-646,8-646_v2_40@1,,"Since the generated measures can be presented by large tables, they are attached in Excel format to the toolbox <REF-9> .",,"Add,Fact/Evidence",Fact/Evidence
10444,8-646,8-646_v2_41@0,,The determined driver and sensor nodes can be classified into four groups <REF-33> .,,"Add,Fact/Evidence",Fact/Evidence
10445,8-646,8-646_v2_41@1,,"According to these groups, four phenomena can provide driver or sensor nodes.",,"Add,Fact/Evidence",Fact/Evidence
10446,8-646,8-646_v2_41@2,,"Firstly, source nodes when the node has no incoming edges, thus, a dedicated input is needed.",,"Add,Fact/Evidence",Fact/Evidence
10447,8-646,8-646_v2_41@3,,"Secondly, dilation, when the generated set of child nodes has higher cardinality than the number of parent nodes.",,"Add,Fact/Evidence",Fact/Evidence
10448,8-646,8-646_v2_41@4,,"A distinction is made between internal dilation and external dilation , in the former the child node is not a leaf, i.e. it has children, while in the latter the child is a leaf node, i.e. it has no children.",,"Add,Fact/Evidence",Fact/Evidence
10449,8-646,8-646_v2_41@5,,"The last type is the inaccessible nodes when the node has an incoming edge and no dilation is present, but the node is not reachable by a directed path from any of the inputs.",,"Add,Fact/Evidence",Fact/Evidence
10450,8-646,8-646_v2_41@6,,"These types are important properties, e.g. the existence of dilation or inaccessibility is detrimental to complete structural controllability <REF-3> .",,"Add,Fact/Evidence",Fact/Evidence
10451,8-646,8-646_v2_41@10,,"This similarity is based on how similar the set of nodes is, which can be reached for driving or observing.",,"Add,Fact/Evidence",Fact/Evidence
10452,8-646,8-646_v2_41@11,,"Furthermore, the necessary derivation to influence or observe them is also part of the comparison.",,"Add,Fact/Evidence",Fact/Evidence
10453,8-646,8-646_v2_43@1,,"The set covering-based grassroot method (SetCovGr) optimises the placement of driver nodes and sensor nodes to provide an initially demanded relative degree, but this method does not take into account the original input and output configurations also, thus, structural controllability and observability is not granted also.",,"Add,Claim",Claim
10454,8-646,8-646_v2_43@2,,The other four methods grant controllability and observability by expanding the minimal configurations.,,"Add,Claim",Claim
10455,8-646,8-646_v2_43@3,,"They are the centrality measures-based (CentMeas) retrofit, set covering-based retrofit (SetCovRet), modified Clustering Large Applications based on Simulated Annealing (mCLASA) and Geodesic Distance-based Fuzzy c-Medoid Clustering with Simulated Annealing algorithm (GDFCMSA) methods <REF-13> .",,"Add,Fact/Evidence",Fact/Evidence
10456,8-646,8-646_v2_43@4,,"These methods were utilised with the following parameters: the required relative degree was set at 2, while the alpha parameter of the cost function was set at 0.5 <REF-13> .",,"Add,Fact/Evidence",Fact/Evidence
10457,8-646,8-646_v2_43@5,,The results can be seen in Table 3 .,,"Add,Fact/Evidence",Fact/Evidence
10458,8-646,8-646_v2_43@6,,The number of assigned driver nodes varies significantly when different methods are applied.,,"Add,Fact/Evidence",Fact/Evidence
10459,8-646,8-646_v2_43@7,,The centrality measures-based method assigned the most driver nodes to the system.,,"Add,Fact/Evidence",Fact/Evidence
10460,8-646,8-646_v2_43@8,,"Thus, this method results in the smallest cost, but the difference is irrelevant, most of the methods resulted in a cost of 1.5.",,"Add,Fact/Evidence",Fact/Evidence
10461,8-646,8-646_v2_43@9,,"The increase of the number of the driver nodes decreases the mean relative degree, which is the lowest in the case of the centrality measures-based method.",,"Add,Fact/Evidence",Fact/Evidence
10462,8-646,8-646_v2_46@0,,The robustness of the configuration was also analysed.,,"Add,Fact/Evidence",Fact/Evidence
10463,8-646,8-646_v2_46@1,,"In each scenario, a node was removed from the network.",,"Add,Fact/Evidence",Fact/Evidence
10464,8-646,8-646_v2_46@2,,"Using the leave-one-out strategy, the network with the altered configuration remains controllable in 115 scenarios.",,"Add,Fact/Evidence",Fact/Evidence
10465,8-646,8-646_v2_46@3,,"As for the sensor nodes, the difference is not as significant between the methods as in the case of the driver nodes.",,"Add,Fact/Evidence",Fact/Evidence
10466,8-646,8-646_v2_46@4,,Critical nodes were also generated.,,"Add,Fact/Evidence",Fact/Evidence
10467,8-646,8-646_v2_46@5,,A node is critical if the system becomes uncontrollable or unobservable if the node is removed.,,"Add,Fact/Evidence",Fact/Evidence
10468,8-646,8-646_v2_46@6,,The determined critical nodes and the names of selected driver and sensor nodes can be found in the Excel file attached to the toolbox.,,"Add,Fact/Evidence",Fact/Evidence
10469,8-646,8-646_v2_48@0,,"Although numerous papers have utilised the network-based determination of driver and sensor nodes, a flexible toolbox that may be used to support the analysis has yet to be designed.",,"Add,Claim",Claim
10470,8-646,,8-646_v1_11@0,,"The contribution of this paper is to provide a novel toolbox, NOCAD <REF-18> , for the comprehensive analysis of linear or linearised dynamical systems based on the approach of network science.","Delete,Fact/Evidence",Fact/Evidence
10471,8-646,,8-646_v1_11@1,,"In the following section, the implemented functions and measurements are presented through examples of their application.","Delete,Fact/Evidence",Fact/Evidence
10472,8-646,8-646_v2_5@1,8-646_v1_5@0,"In terms of controlling the human signalling network, the role of different proteins was also systematically analysed with the toolset of network controllability in <REF-4> to highlight the role of cancer-associated genes.","In terms of controlling the human signalling network, the role of different proteins was also systematically analysed with the toolset of network controlability in <REF-3> to highlight the role of cancer-associated genes.","Modify,Grammar",Grammar
10473,8-646,8-646_v2_35@0,8-646_v1_26@0,"In this section, the main functionalities of the NOCAD toolbox <REF-9> are presented through the analysis of the local network of 131 frontal neurons of Caenorhabditis elegans.","In this section, the main functionalities of the NOCAD toolbox <REF-18> presented through examples of use cases.","Modify,Fact/Evidence",Fact/Evidence
10474,8-646,8-646_v2_5@2,8-646_v1_5@1,"Target control with objective-guided optimisation (TCO) was introduced to control a set of variables (or targets) of interest while the number of drivers and constrained nodes were minimised and maximised, respectively.","Target control with objective-guided optimisation (TCO) was introduced to control a set of variables (or targets) of interest while the quantity of drivers and constrained nodes were minimised and maximised, respectively.","Modify,Clarity",Clarity
10475,8-646,8-646_v2_35@1,8-646_v1_27@0,"The first step in the workflow is to create a state-space model based on the adjacency matrix that presents the structural description of the system that, in this case, has the size of 131×131 according to the 131 frontal neurons.",The first step in each workflow is to create a state-space model from the adjacency matrix that presents the structural description of the system.,"Modify,Fact/Evidence",Fact/Evidence
10476,8-646,8-646_v2_36@0,8-646_v1_27@1,"Two methods, path finding and signal sharing are proposed that were implemented to correct the insufficient result of maximum matching.",This can be achieved by the use of path finding and signal sharing methods implemented in the first module.,"Modify,Fact/Evidence",Fact/Evidence
10477,8-646,8-646_v2_37@2,8-646_v1_40@1,"The density shows that the number of edges is less than a twentieth of the possible maximum, and the diameter of the system, namely the longest shortest path in the network that presents its structure, is 9.","The density shows that the number of edges is almost a fifth of the possible maximum, and the diameter of the system (i.e. the longest shortest path in the network that presents its structure) is 4.","Modify,Fact/Evidence",Fact/Evidence
10478,8-646,8-646_v2_37@3,8-646_v1_40@2,"The degree variance is 44.3299 which is relatively high given the size of the network, while the Freeman’s centrality is 0.2057.","The degree variance is 2.67, while the Freeman’s centrality is 0.43.","Modify,Fact/Evidence",Fact/Evidence
10479,8-646,8-646_v2_37@5,8-646_v1_40@4,"The Pearson correlation coefficient shows that the in-in, in-out and out-out correlations are slightly assortative in nature, while the out-in correlation is likely to be disassortative.","The Pearson coefficient shows that the in-in and in-out correlations are assortative in nature, while out-out and out-in correlations are likely to be disassortative.","Modify,Fact/Evidence",Fact/Evidence
10480,8-646,8-646_v2_2@0,8-646_v1_2@0,The network science-based determination of driver nodes and sensor placement has become increasingly popular in the field of dynamical systems over the last decade.,Network science has become increasingly important in life science over the last decade.,"Modify,Claim",Claim
10481,8-646,8-646_v2_37@8,8-646_v1_40@7,"As 77 symmetrical connections are present between 687 connected node pairs, the percentage of the symmetric edge pairs is 11.2082%.","As there are 6 edges that have symmetric edge pairs and the number of connections is 15, the percentage of the symmetric edge pairs relative to the edges is 40%.","Modify,Fact/Evidence",Fact/Evidence
10482,8-646,8-646_v2_40@2,8-646_v1_41@1,"This analysis shows that one of the most important values is the highest degree of the nodes, which belongs to RIAR, an interneuron located in the nerve ring <REF-31> .","One of the most important values is the highest degree of the nodes, which belongs to state variable x 4 .","Modify,Fact/Evidence",Fact/Evidence
10483,8-646,8-646_v2_40@3,8-646_v1_41@2,"As Scott’s centrality is a normalised degree, the most important node is once again RIAR.","As Scott’s centrality is a normalised degree, the most important node is once again x 4 .","Modify,Fact/Evidence",Fact/Evidence
10484,8-646,8-646_v2_40@5,8-646_v1_41@4,"The higher value indicates the more central position of the node, and now RIAL is the most central element.","The higher value indicates the more central position of the node, and, once again, node x 4 is the most central element.","Modify,Fact/Evidence",Fact/Evidence
10485,8-646,8-646_v2_40@8,8-646_v1_41@7,The highest value belongs to neurotransmitter RIH that is a serotonin <REF-32> .,The highest value belongs to nodes x 2 and x 4 .,"Modify,Fact/Evidence",Fact/Evidence
10486,8-646,8-646_v2_40@9,8-646_v1_41@8,"The PageRank assigns a percentage value to each node, based on their centrality roles if Markov-chains are modelled.","The PageRank assigns a percentage value for each node, based on their centrality roles if Markov-chains are modelled.","Modify,Grammar",Grammar
10487,8-646,8-646_v2_41@7,8-646_v1_42@4,The controlling and observing matrices are sparse matrices as only the columns of drivers and sensors contain nonzero values.,"Generally, these matrices are sparse matrices, as only the columns of drivers and sensors contain nonzero values.","Modify,Clarity",Clarity
10488,8-646,8-646_v2_4@1,8-646_v1_5@5,"The importance of determining the proper driver nodes, i.e. the ones that ensure physically feasible controllability with the minimum cardinality and energy requirement, in biological networks, or more generally in any dynamical system, is unequivocal, and the amount of research concerning network science has increased rapidly.","The importance of determining the proper driver nodes in biological networks, or more generally in any dynamical system, is unequivocal, and the amount of research concerning network science has increased rapidly.","Modify,Claim",Claim
10489,8-646,8-646_v2_41@12,8-646_v1_42@11,R c and R o are the simple reachability matrices.,R and R are the simple reachability matrices.,"Modify,Fact/Evidence",Fact/Evidence
10490,8-646,8-646_v2_41@13,8-646_v1_42@12,"They show which nodes can be controlled or observed by a given node in its structural meaning, i.e. the existence of a directed path between the nodes is shown.",They show which nodes can be controlled or observed by a given node.,"Modify,Fact/Evidence",Fact/Evidence
10491,8-646,8-646_v2_41@14,8-646_v1_42@13,"In R c , the i th column shows which nodes can control node i .","In R , the i th column shows which nodes can control node i .","Modify,Fact/Evidence",Fact/Evidence
10492,8-646,8-646_v2_41@16,8-646_v1_42@15,"It is very important that R c is only a reachability matrix, the structural controllability of the reachable nodes is not granted by a node that can reach them, but in some cases the structural controllability problem can be reduced to a reachability problem <REF-34> .","In this example, node x 8 can influence every node, but it does not guarantee structural controllability.","Modify,Fact/Evidence",Fact/Evidence
10493,8-646,8-646_v2_41@17,8-646_v1_42@16,The R o matrix can be interpreted analogously with regard to observability.,The R matrix can be interpreted analogously with regard to observability.,"Modify,Fact/Evidence",Fact/Evidence
10494,8-646,8-646_v2_42@0,8-646_v1_43@0,"Finally, measures of edge centrality are generated by the system characterisation module.","Finally, measures of edge centrality are seen in Figure 6 .","Modify,Fact/Evidence",Fact/Evidence
10495,8-646,8-646_v2_42@2,8-646_v1_43@2,"From this perspective, the most critical synapsis is the one between the command interneuron AVAL and amphid ADLL with a value of 640.5833.","From this perspective, the most critical edge is the edge a 46 with a value of 10.","Modify,Fact/Evidence",Fact/Evidence
10496,8-646,8-646_v2_43@0,8-646_v1_44@0,"For the demonstration of the last module, four plus one methods were applied to the neural network of C. elegans.","For the demonstration of the last module, configurations provided by the first module are used again ( Figure 2 ).","Modify,Fact/Evidence",Fact/Evidence
10497,8-646,8-646_v2_4@2,8-646_v1_5@6,A detailed study of the control principles in biological networks has already been published <REF-2> .,A detailed study about the control principles in biological networks has already been published <REF-7> .,"Modify,Grammar",Grammar
10498,8-646,8-646_v2_48@1,8-646_v1_48@0,"To fill this gap, in this article the Octave- and MATLAB-compatible NOCAD toolbox <REF-9> was proposed to support the network-based controllability and observability analysis of dynamical systems, and through the analysis of the neural network of C.elegans, the applicability of the toolbox in the life sciences was presented.",In this article the Octave- and MATLAB-compatible NOCAD toolbox <REF-18> was proposed to support the network-based controllability and observability analysis of dynamical systems.,"Modify,Fact/Evidence",Fact/Evidence
10499,8-646,8-646_v2_48@2,8-646_v1_48@1,The toolbox offers two methods to design a structurally controllable and observable system based on the adjacency matrix ( A T ).,The toolbox offers two methods to design a structurally controllable and observable system based on the state-transition matrix.,"Modify,Fact/Evidence",Fact/Evidence
10500,8-646,8-646_v2_8@0,8-646_v1_6@0,"Although considerable research has utilised this method <REF-16> , a flexible software tool which may be used to support research in this field has yet to be designed.","Although considerable research has utilised the method <REF-8> , a flexible software tool which may be used to support the research in this field has yet to be designed.","Modify,Clarity",Clarity
10501,8-646,8-646_v2_2@2,8-646_v1_2@1,"Simultaneously, an Octave and MATLAB-compatible NOCAD toolbox is proposed that provides a set of methods to automatically generate the relevant structural controllability and observability associated measures for linear or linearised systems and compare the different sensor placement methods.",The proposed Octave and MATLAB-compatible NOCAD toolbox provides a set of methods which enables the structural controllability and observability analysis of dynamical systems.,"Modify,Fact/Evidence",Fact/Evidence
10502,8-646,8-646_v2_8@1,8-646_v1_6@1,"Parallel studies have resulted in a collection of applications, toolboxes, plug-ins and scripts that analyse and determine several structural properties of genes, protein-protein interactions and even social or urban networks.","Parallel research has resulted in a collection of applications, toolboxes, plug-ins and scripts that analyse and determine several structural properties of genes, protein-protein interaction or even social or urban networks.","Modify,Clarity",Clarity
10503,8-646,8-646_v2_8@3,8-646_v1_6@3,"As our toolbox belongs to the second group, in the following section, the available applications and programs of this group are elaborated on.","As our toolbox belongs to the second group, in the following section, the available applications and programs of this group are elaborated.","Modify,Grammar",Grammar
10504,8-646,8-646_v2_9@3,8-646_v1_7@3,"Although in Python the focus is on developing a broad software package for complex systems analysis, this has yet to be fulfilled and all of the available solutions have limitations.","Although in Python the focus is on developing a broad software package for complex system analysis, this has yet to be fulfilled and all of the available solutions have limitations.","Modify,Grammar",Grammar
10505,8-646,8-646_v2_9@5,8-646_v1_7@5,"Even though WDNfinder only determines the minimum driver node set (MDS) and classifies nodes based on MDS, it is incapable of facilitating extended analysis.","Even though WDNFinder only determines the minimum driver node set (MDS) and classifies nodes based on MDS, it is incapable of facilitating extended analysis.","Modify,Grammar",Grammar
10506,8-646,8-646_v2_12@0,8-646_v1_10@0,"Additionally, the CytoCtrlAnalyser <REF-23> plug-in for Cytoscape <REF-25> has been developed, which was implemented in Java and offers graphical user interfaces as well.","Additionally, the CytoCtrlAnalyser <REF-13> plug-in for Cytoscape <REF-14> has been developed, which was implemented in Java and offers graphical interfaces for users as well.","Modify,Clarity",Clarity
10507,8-646,8-646_v2_23@0,8-646_v1_13@0,"With the help of the presented Octave - and MATLAB -compatible toolbox, experts can create, analyse and improve any type of dynamical systems.","With the help of the presented Ocatave - and MATLAB -compatible toolbox, experts can create, analyse and improve any type of dynamical systems.","Modify,Grammar",Grammar
10508,8-646,8-646_v2_5@4,8-646_v1_4@1,"In large-scale human liver metabolic networks (HLMN), the driver metabolites have essential functions, moreover, the role of transport reactions and extracellular metabolites in terms of controlling HLMN have revealed the importance of the environment of human liver metabolism with regard to the health of the liver <REF-6> .","In large-scale human liver metabolic networks (HLMN), the driver metabolites have essential functions, and the role of transport reactions and extracellular metabolites in terms of controlling HLMN has revealed the importance of the environment of human liver metabolism with regard to the health of the liver <REF-2> .","Modify,Clarity",Clarity
10509,8-666,8-666_v2_10@4,,"Eye movements normalised post magnesium treatment and did not recur, though it remains impossible to be certain of a causal relationship between the hypomagnesaemia and the neurological presentation.",,"Add,Claim",Claim
10510,8-666,8-666_v2_10@10,,Both parents have been shown have normal serum magnesium levels.,,"Add,Fact/Evidence",Fact/Evidence
10511,8-666,8-666_v2_22@5,,"De novo mutational events, in addition to recessive and dominant mutations, are also a possibility, especially for CNNM2 and ATP1A1.",,"Add,Claim",Claim
10512,8-666,8-666_v2_26@0,,"HSH is thought to represent a classic autosomal-recessive disease, with unaffected heterozygous parents and siblings.",,"Add,Claim",Claim
10513,8-666,8-666_v2_26@6,,Such a finding has not been previously reported.,,"Add,Claim",Claim
10514,8-666,8-666_v2_26@7,,"It is possible this represents a mutation specific phenotype, rather than a general finding in patients with heterozygous TRPM6 mutations.",,"Add,Claim",Claim
10515,8-666,8-666_v2_26@10,,"Newborns usually start with their mothers serum magnesium at birth, and if defective TRPM6 present then show a continuous decline over subsequent weeks.",,"Add,Claim",Claim
10516,8-666,8-666_v2_26@11,,"Some advocate that measurement of serum magnesium can exclude a disease state in siblings, but in this case it is possible that this would have suggested a diagnosis of HSH in the heterozygous siblings given their transient phenotype.",,"Add,Claim",Claim
10517,8-666,8-666_v2_26@13,,"The vast majority of previously reported TRPM6 mutations are nonsense, including stop mutation or small deletions or insertions <REF-12> , and only a small number of missense mutations have been reported and even fewer had a functional assessment.",,"Add,Claim",Claim
10518,8-666,8-666_v2_20@2,8-666_v1_20@2,"Serum magnesium levels make up a relatively tiny proportion of whole-body magnesium content, but need to be kept within a narrow range to maintain neuronal, skeletal muscle and cardiac muscle cell stability.","Serum magnesium levels make up a relatively tiny proportion of whole-body magnesium content, but needs to be kept within a narrow range to maintain neuronal, skeletal muscle and cardiac muscle cell stability.","Modify,Grammar",Grammar
10519,8-666,8-666_v2_22@4,8-666_v1_22@4,"These include hypercalciuric hypomagnesaemias (secondary to mutations in CLCNKB (Bartter syndrome type 3), CLDN16 , CLDN19 , CASR ); Gitelman-like hypomagnesaemias (secondary to mutations in SLC12A3 (Gitelman syndrome), BSND (Bartter syndrome type 4), KCNJ10 , FXYD2 , HNF1B , PCBD1 ); mitochondrial hypomagnesaemias; (mutations in SARS2 , MT-TI and Kearns–Sayre syndrome) and other hypomagnesaemias (secondary to mutations in TRPM6 , CNNM2 , EGF , EGFR , KCNA1 , FAM111A , ATP1A1 ) <REF-5> .","These include hypercalciuric hypomagnesaemias (secondary to mutations in CLCNKB (Bartter syndrome type 3), CLDN16 , CLDN19 , CASR ); Gitelman-like hypomagnesaemias (secondary to mutations in SLC12A3 (Gitelman syndrome), BSND (Bartter syndrome type 4), KCNJ10 , FYXD2 , HNF1B , PCBD1 ); mitochondrial hypomagnesaemias; (mutations in SARS2 , MT-TI and Kearns–Sayre syndrome) and other hypomagnesaemias (secondary to mutations in TRPM6 , CNMM2 , EGF , EGFR , KCNA1 , FAM111A ) <REF-5> .","Modify,Fact/Evidence",Fact/Evidence
10520,8-666,8-666_v2_23@0,8-666_v1_23@0,"TRPM6 is expressed in both the colon and the DCT of the kidney, and mutations here can cause the condition known as hypomagnesaemia with secondary hypocalcaemia (HSH, OMIM 602014).","TRPM6 is expressed in both the colon and the DCT of the kidney, and mutations here can cause the condition known as hypomagnesaemia with secondary hypocalcaemia.","Modify,Fact/Evidence",Fact/Evidence
10521,8-666,8-666_v2_23@4,8-666_v1_23@4,"It typically presents in the neonatal or the infancy period (ranging from a couple of days to 8 months, rarely later) with severe symptoms due to hypomagnesaemia and hypocalcaemia such as seizures, which are subsequently responsive to magnesium administration <REF-8> .","It typically presents in the neonatal period with severe symptoms due to hypomagnesaemia and hypocalcaemia such as seizures, which are subsequently responsive to magnesium administration <REF-8> .","Modify,Claim",Claim
10522,8-666,8-666_v2_25@0,8-666_v1_25@0,"Given what is known about HSH, our first patient presented typically, with severe symptoms and the expected biochemical profile, including low PTH.","Given what is known about hypomagnesaemia with secondary hypocalcaemia, our first patient presented typically, with severe symptoms and the expected biochemical profile, including low PTH.","Modify,Clarity",Clarity
10523,8-666,8-666_v2_26@1,8-666_v1_25@3,"Interestingly in this case, the second child also had severe symptoms at presentation despite ultimately proving to be heterozygous for the TRPM6 mutation.","Interestingly, the second child also had severe symptoms at presentation despite ultimately proving to be heterozygous for the TRPM6 mutation.","Modify,Clarity",Clarity
10524,8-666,8-666_v2_0@0,8-666_v1_0@0,Case Report: Investigation and molecular genetic diagnosis of familial hypomagnesaemia,Case Report: Investigation and molecular genetic diagnosis of familial hypomagnesaemia: a case report,"Modify,Clarity",Clarity
10525,8-666,8-666_v2_7@0,8-666_v1_7@0,"We report a child from a consanguineous family (parents were second cousins) from Oman, who presented with seizures and hypomagnesaemia.","We report a child from a consanguineous family (parents were second degree cousins) from Oman, who presented with seizures and hypomagnesaemia.","Modify,Clarity",Clarity
10526,8-666,8-666_v2_10@3,8-666_v1_7@7,She was treated with intravenous magnesium replacement (20% MgCl 2 0.1 mmol/kg every 6 hours p.r.n.).,She was initially treated with intravenous magnesium (20% MgCl 2 0.1 mmol /kg every 6 hours p.r.n.) and calcium replacement (10% Calcium Gluconate 0.11 mmol/kg).,"Modify,Fact/Evidence",Fact/Evidence
10527,8-666,8-666_v2_7@8,8-666_v1_7@8,"At 4 years of age she is now supported with high-dose oral magnesium supplements (magnesium sulphate 500mg qds) alone, and remains well with no further seizures, though she maintains a low serum magnesium level between 0.4–0.6 mmol/L.","At 4 years of age she is now supported with high-dose oral magnesium supplements (magnesium sulphate 500mg qds) alone, and remains well with no further seizures, though she maintains a low serum magnesium level between 0.4-0.6 mmol/L.","Modify,Grammar",Grammar
10528,8-666,8-666_v2_10@0,8-666_v1_10@0,"Of note, a younger sibling of the proband, also female, presented at 18 days old with abnormal eye movements thought to be as part of a complex partial seizure.","Of note, a younger sibling of the proband, also female, presented at 18 days old with abnormal eye movements in association with a complex partial seizure.","Modify,Clarity",Clarity
10529,8-666,8-666_v2_10@1,8-666_v1_10@1,"Her serum magnesium was below normal limits (0.53 mmol/L), with serum calcium and PTH within the normal range ( Table 1 ), and normal blood glucose.","Her serum magnesium was below normal limits (0.53 mmol/L), with serum calcium and PTH within the normal range ( Table 1 ).","Modify,Fact/Evidence",Fact/Evidence
10530,8-666,8-666_v2_10@5,8-666_v1_10@3,She was then treated with a period of maintenance oral magnesium replacement (magnesium sulphate 300 mg b.d.).,"She was treated with intravenous magnesium replacement (20% MgCl 2 0.1 mmol /kg every 6 hours p.r.n.), followed by a period of maintenance oral magnesium replacement (magnesium sulphate 300 mg b.d.).","Modify,Fact/Evidence",Fact/Evidence
10545,8-87,8-87_v2_13@0,,Open lab notebooks have been pioneered and championed by a number of practitioners but remain a niche activity in the scientific community.,,"Add,Claim",Claim
10546,8-87,8-87_v2_13@1,,Jean-Claude Bradley first coined the term “open notebook science” in 2006 and his definition of this method of scholarly communication have laid the foundations for our own efforts <REF-12> .,,"Add,Fact/Evidence",Fact/Evidence
10547,8-87,8-87_v2_13@2,,"In addition to the notebooks of individual researchers following Bradley’s template, open notebook examples now include collective efforts from the Open Lab Notebook Network ( http://onsnetwork.org ) and Open Source Malaria ( http://opensourcemalaria.org ).",,"Add,Claim",Claim
10548,8-87,8-87_v2_13@3,,"However, the open lab notebook community remains small, the practice is not consistently defined or implemented and the impact of these efforts in the field have not been systematically evaluated.",,"Add,Claim",Claim
10549,8-87,8-87_v2_19@1,,"Open laboratory notebooks need to guarantee that the data will remain accessible, in order to avoid the fate suffered by the pioneer open notebook of Jean-Claude Bradley, which is still accessible while its associated raw data wiki is not.",,"Add,Claim",Claim
10550,8-87,8-87_v2_19@2,,Zenodo is strongly committed to preserving the data it archives.,,"Add,Claim",Claim
10551,8-87,8-87_v2_19@3,,CERN has existed since 1954 and has an experimental program defined for the next 20+ years.,,"Add,Claim",Claim
10552,8-87,8-87_v2_19@4,,Each file has two replicas located on different disk servers.,,"Add,Claim",Claim
10553,8-87,8-87_v2_19@5,,"In the highly unlikely event that Zenodo closes operations, they guarantee migration of all content to other suitable repositories, and since all uploads have DOIs, citations and links to Zenodo resources (including data) will not be affected.",,"Add,Claim",Claim
10554,8-87,8-87_v2_27@0,,"Open notebooks being published before peer-review, there is a risk that dubious experiments, erroneous analysis or misinterpretations find their way on open platforms, get amplified over the internet and mislead colleague scientists, patient groups or other communities.",,"Add,Claim",Claim
10555,8-87,8-87_v2_27@1,,"Once they become indexed by popular search engines, open lab notebooks could become a source of pollution of the scientific (and non-scientific) literature.",,"Add,Claim",Claim
10556,8-87,8-87_v2_27@2,,"This risk, which is not limited to open notebooks but extends to the increasing number of Journals that adopt a post-publication peer-review mechanism, is real, serious, and should be monitored.",,"Add,Claim",Claim
10557,8-87,8-87_v2_27@3,,We believe that the best way to mitigate this risk is for open notebooks to provide a platform for open comments.,,"Add,Claim",Claim
10558,8-87,8-87_v2_27@4,,"In principle, this could be an even stronger quality control than the current peer-review system in place in most scientific journals, as the number of “open reviewers” for any given report is limitless.",,"Add,Claim",Claim
10559,8-87,8-87_v2_27@5,,"At the moment, we find that very few comments are posted at openlabnotebooks.org, a platform that is only a year old, but we see that comments are mainstream, and sometimes turn into healthy discussions at Open Source Malaria, a pioneer in the field <REF-23> .",,"Add,Claim",Claim
10560,8-87,8-87_v2_4@5,8-87_v1_4@5,"In the life sciences, this belief can reach near-mystical levels <REF-2> , and can be compounded by constraints associated with patent protection procedures or the absence of clear mechanism to make one’s data publicly available.","In the life sciences, this belief can reach near-mystical levels <REF-2> .","Modify,Claim",Claim
10561,8-87,8-87_v2_8@0,8-87_v1_8@0,Many believe that the chances of getting scooped before one publishes their work in a peer-reviewed journal increase when openly sharing their work online <REF-9> .,Many believe that openly sharing work online will limit career opportunities.,"Modify,Fact/Evidence",Fact/Evidence
10562,8-87,8-87_v2_9@4,8-87_v1_9@4,Our personal observations seem to indicate that grant applications highlighting the use of open lab notebooks are being viewed positively.,Grant applications that highlight the use of open lab notebooks are being viewed positively.,"Modify,Claim",Claim
10563,8-87,8-87_v2_14@0,8-87_v1_13@0,"Following our prediction that open lab notebooks should be good for science and good for scientists, and after a 2-year pilot study where Rachel Harding, a post-doctoral fellow at the Structural Genomics Consortium (SGC) shared her work on Huntington’s disease at labscribbles.com <REF-13> , we launched openlabnotebooks.org in January 2018, where 12 scientists from the SGC started reporting their work live, online <REF-14> , <REF-15> .","Following our prediction that open lab notebooks should be good for science and good for scientists, and after a 2-year pilot study where Rachel Harding, a post-doctoral fellow at the Structural Genomics Consortium (SGC) shared her work on Huntington’s disease at labscribbles.com ( https://www.vox.com/2016/3/3/11148452/science-blog ), we launched openlabnotebooks.org in January 2018, where 12 scientists from the SGC started reporting their work live, online <REF-11> , <REF-12> .","Modify,Fact/Evidence",Fact/Evidence
10564,8-87,8-87_v2_14@3,8-87_v1_13@3,"The blogs, posted at openlabnotebooks.org, are managed by a webserver downloaded from wordpress.org (the open-source online system LabTrove would be a valid alternative <REF-16> ), archived weekly to GitHub (repository https://github.com/thesgc/static-openlabnotebooks ), quarterly to archive.org ( https://wayback.archive-it.org/6473/*/https:/opennotebook.thesgc.org /), and link to the experimental records, which are deposited at Zenodo (zenodo.org), but can also be made available from other public repositories, such as GitHub (github.com) or Figshare (figshare.com).","The blogs, posted at openlabnotebooks.org, are managed by a webserver downloaded from wordpress.org and link to the experimental records, which are deposited at Zenodo (zenodo.org), but can also be made available from other public repositories, such as GitHub (github.com) or Figshare (figshare.com).","Modify,Fact/Evidence",Fact/Evidence
10565,8-87,8-87_v2_19@0,8-87_v1_13@4,"The Zenodo repository enables sharing research outputs from across all fields of research, creation and curation of complete digital repositories, flexible licensing with controlled degree of openness and safe storage of the data for the future in the same cloud infrastructure as CERN’s own LHC research data.","The Zenodo repository enables sharing research outputs from across all fields of research, creation and curation of complete digital repositories, flexible licensing with controlled degree of openness and safe storage of the data for the future in the same cloud infrastructure as CERN's own LHC research data.","Modify,Grammar",Grammar
10566,8-890,,8-890_v1_106@0,,Strengths and limitations,"Delete,Other",Other
10567,8-890,,8-890_v1_107@1,,"For this purpose, we have used systematic and transparent criteria <REF-23> – <REF-25> .","Delete,Fact/Evidence",Fact/Evidence
10568,8-890,,8-890_v1_108@2,,"Nevertheless, the present report provides insight into the certainty of the evidence of effects of treatments and other interventions that have been evaluated.","Delete,Claim",Claim
10569,8-890,,8-890_v1_108@3,,This report also identifies important research gaps for interventions where no studies have been conducted.,"Delete,Claim",Claim
10570,8-890,,8-890_v1_108@4,,Acknowledging that the effects of these interventions in reducing self-harm and suicide are uncertain can prompt new research efforts important for children and adolescents.,"Delete,Claim",Claim
10571,8-890,,8-890_v1_116@1,,The best strategies for addressing this phenomenon and later suicides following suicide clusters are therefore unknown.,"Delete,Claim",Claim
10572,8-890,,8-890_v1_118@0,,Another high-risk group is young people bereaved or affected by a suicide in their family or other network.,"Delete,Claim",Claim
10573,8-890,,8-890_v1_118@1,,Two studies were identified addressing the effects of support-interventions in this population.,"Delete,Fact/Evidence",Fact/Evidence
10574,8-890,,8-890_v1_118@2,,"However, the evidence is of very low certainty.","Delete,Claim",Claim
10575,8-890,,8-890_v1_120@2,,"For most of these interventions no studies were found, or the certainty of the evidence was very low.","Delete,Claim",Claim
10576,8-890,,8-890_v1_128@2,,These includes approaches to risk assessment and how to best organize the care of young people with known self-harm or suicide risk.,"Delete,Claim",Claim
10577,8-890,,8-890_v1_129@0,,Implications,"Delete,Other",Other
10578,8-890,,8-890_v1_130@0,,Our review suggests that preventive strategies can reduce suicide risk.,"Delete,Claim",Claim
10579,8-890,,8-890_v1_131@0,,It is recommended that communities prepare for situations with a risk for social contagion and suicide clusters.,"Delete,Claim",Claim
10580,8-890,,8-890_v1_131@1,,"Research evaluating strategies to prevent clustering of suicides is scarce, and the studies we found used inappropriate designs to capture the potential beneficial or harmful effects of these interventions.","Delete,Claim",Claim
10581,8-890,,8-890_v1_132@0,,There is great uncertainty associated with the effects of treatment strategies for young people with existing self-harm.,"Delete,Claim",Claim
10582,8-890,,8-890_v1_140@0,,This project contains the following extended data:,"Delete,Fact/Evidence",Fact/Evidence
10583,8-890,,8-890_v1_141@0,,- Appendix_1_Search_strategy.pdf (Study search strategy),"Delete,Other",Other
10584,8-890,8-890_v2_10@10,,"Furthermore, there are repercussions to being exposed to family and/or friends’ self-harm and suicide.",,"Add,Claim",Claim
10585,8-890,8-890_v2_10@12,,"Related, the bereavement process of survivors after losing a significant other may last a long time and increase the risk of suicide <REF-14> and suicidal thoughts <REF-15> .",,"Add,Fact/Evidence",Fact/Evidence
10586,8-890,8-890_v2_11@0,,"Evidently, self-harm and suicide in children and adolescents are complex and multifaceted phenomena.",,"Add,Claim",Claim
10587,8-890,8-890_v2_11@1,,"As prevention likely warrants a variation of measures, clinicians and policy makers are in need of knowledge the effects of different types of preventive interventions.",,"Add,Claim",Claim
10588,8-890,8-890_v2_18@1,,This five-year cut-off is pragmatic in considering that older reviews are no longer a reliable basis for updated evidence.,,"Add,Claim",Claim
10589,8-890,8-890_v2_18@2,,A review published earlier than 2012 may not include primary studies published the last >10 years.,,"Add,Claim",Claim
10590,8-890,8-890_v2_22@1,,"- Interventions with the main objective to prevent other mental health problems, such as depression.",,"Add,Claim",Claim
10591,8-890,8-890_v2_24@1,,We reviewed all references indexed in IN SUM.,,"Add,Fact/Evidence",Fact/Evidence
10592,8-890,8-890_v2_24@3,,"Examples of search words were suicid*, selfharm*, selfharm*, intervention*, strategy, therap*, child*, adoles* .",,"Add,Fact/Evidence",Fact/Evidence
10593,8-890,8-890_v2_103@1,,"We found evidence to suggest that school-based interventions probably prevent suicidal ideation and suicide attempts short term, and possibly suicide attempts long term.",,"Add,Claim",Claim
10594,8-890,8-890_v2_103@2,,"The effects of community-based interventions following suicide clusters and local suicide plans are unknown, as are the benefits and harms of screening young people for suicide risk.",,"Add,Claim",Claim
10595,8-890,8-890_v2_103@3,,The effects of most interventions targeting children and adolescents with known self-harm are also unknown.,,"Add,Claim",Claim
10596,8-890,8-890_v2_103@4,,"However, low certainty evidence suggests that dialectical behavioural therapy and developmental group therapy are equally as effective on repetition of self-harm as enhanced treatment as usual.",,"Add,Claim",Claim
10597,8-890,8-890_v2_103@5,,"In general, the populations are adolescents in the age-range of 12 to 18 years.",,"Add,Fact/Evidence",Fact/Evidence
10598,8-890,8-890_v2_111@5,,"Clinicians should be aware of this potential short-term adverse effect, but this should be investigated in future studies.",,"Add,Claim",Claim
10599,8-890,8-890_v2_111@6,,"However, the findings on beneficial effects are overall promising.",,"Add,Claim",Claim
10600,8-890,8-890_v2_111@7,,"It seems that both dialectical behavioural therapy and developmental group therapy, or established treatment approaches, are good treatment alternatives.",,"Add,Claim",Claim
10601,8-890,8-890_v2_112@0,,"For remaining interventions targeting self-harm, effects are unknown.",,"Add,Claim",Claim
10602,8-890,8-890_v2_113@1,,"The finding that biological factors may be associated with, or even predict, a suicide attempt <REF-13> could have implications for research on pharmacological agents.",,"Add,Claim",Claim
10603,8-890,8-890_v2_114@1,,"New research in this area is pertinent, especially for policy makers.",,"Add,Claim",Claim
10604,8-890,8-890_v2_115@0,,Limitations,,"Add,Other",Other
10605,8-890,8-890_v2_116@2,,A primary study investigating e.g. treatment attendance would be relevant to a clinician wanting to meet with a client struggling with suicidality regularily in order to build a working alliance.,,"Add,Claim",Claim
10606,8-890,8-890_v2_116@3,,"However, if the review authors did not find such an outcome from a primary study relevant, we will have missed this information.",,"Add,Claim",Claim
10607,8-890,8-890_v2_116@4,,"Regardless of this limitation, the reader of our overview of reviews could find a particular primary study referenced in the included review, if there is need to check if the primary study investigated other relevant outcomes.",,"Add,Claim",Claim
10608,8-890,8-890_v2_120@2,,"These interventions include mentalization-based psychotherapy, cognitive behavioural therapy and psychodynamic therapy.",,"Add,Claim",Claim
10609,8-890,8-890_v2_121@0,,"Collectively, due to a general lack of research, and in some cases very low certainty evidence, the effects of most interventions are unknown.",,"Add,Claim",Claim
10610,8-890,8-890_v2_121@1,,This has several implications.,,"Add,Claim",Claim
10611,8-890,8-890_v2_121@3,,"Second, when implementing recommended practice with unknown effects, such as approaches to risk assessment, practice should be closely evaluated.",,"Add,Claim",Claim
10612,8-890,8-890_v2_121@4,,"With all types of interventions, there is a possibility for adverse effects.",,"Add,Claim",Claim
10613,8-890,,8-890_v1_11@11,,"As such, that there is clearly a need for effective prevention of self-harm and suicide in children and adolescents.","Delete,Claim",Claim
10614,8-890,,8-890_v1_74@0,,Interventions for children and adolescents with existing self-harm.,"Delete,Other",Other
10615,8-890,8-890_v2_33@2,8-890_v1_35@2,"In considering overlap, the first author (ISM) extracted this information from the reviews, and the second author (AA) double-checked the information.","In considering overlap, the first author (ISM) extracted this information from the reviews and the second author (AA) double-checked this information.","Modify,Clarity",Clarity
10616,8-890,8-890_v2_33@3,8-890_v1_35@3,"Further, we assessed the methodological quality of the included reviews based on a checklist for systematic reviews (AMSTAR: A MeaSurement Tool to Assess systematic Reviews) <REF-27> .","Further, we assessed the quality of the included reviews based on a checklist for systematic reviews (AMSTAR: A MeaSurement Tool to Assess systematic Reviews) <REF-24> .","Modify,Fact/Evidence",Fact/Evidence
10617,8-890,8-890_v2_33@4,8-890_v1_35@4,"Two people (ISM, IB) considered each publication independently and decided on the quality through discussions until consensus.","Two people (ISM, IB) considered each publication independently and decided on the methodological quality through discussions until consensus.","Modify,Clarity",Clarity
10618,8-890,8-890_v2_90@2,8-890_v1_93@2,The intervention was a manualized home-based family therapy intervention.,The intervention was a manualised home-based family therapy intervention.,"Modify,Grammar",Grammar
10619,8-890,8-890_v2_103@0,8-890_v1_107@0,The present paper gives a comprehensive overview of effects of interventions aimed at preventing self-harm and suicide in children and adolescents.,"The major contribution of this review is to provide children, adolescents and their families, clinicians and researchers with an overview of research regarding the effects of interventions for young people to prevent suicide and (re)occurrence of self-harm.","Modify,Claim",Claim
10620,8-890,8-890_v2_122@1,8-890_v1_107@2,"In decision-making, knowledge on effects of interventions should be supplemented with other relevant research, such as therapeutic processes influencing the outcome, as well as integrated with clinical expertise and the child’s or adolescent’s and caregiver’s values and preferences <REF-42> , <REF-43> .","The results of our review should be supplemented with other relevant research and integrated with clinical expertise as well as the child’s or adolescent’s and their caregiver’s values and preferences <REF-34> , <REF-35> .","Modify,Fact/Evidence",Fact/Evidence
10621,8-890,8-890_v2_116@0,8-890_v1_108@0,"A limitation of overviews of reviews, and consequently of the present paper, is that the analyses are based on secondary reporting of what the review authors interpreted and reported based on the primary studies.","A limitation of overviews of reviews, and consequently of this present report, is that the analyses are based on secondary reporting and the interpretation of the review authors.","Modify,Fact/Evidence",Fact/Evidence
10622,8-890,8-890_v2_116@1,8-890_v1_108@1,It follows that the primary studies may have provided more information than what is reported in the reviews we included.,"Thus, the primary studies may have provided more information than what is reported in the reviews we included.","Modify,Clarity",Clarity
10623,8-890,8-890_v2_117@0,8-890_v1_109@0,"It is also worth noting that the present paper only included reviews of studies where the intervention was to prevent or treat self-harm and suicide in children and adolescents, with exception of a few population-based studies.",It is also worth noting that the present report only included reviews of studies where the population was children and young people with existing self-harm or preventive strategies for children and adolescents with or without an identified risk of self-harm and suicide.,"Modify,Fact/Evidence",Fact/Evidence
10624,8-890,8-890_v2_117@1,8-890_v1_109@1,"Self-harm and suicide are associated with other difficulties such as psychosis, depression and anxiety.","As mentioned in the introduction, self-harm and suicide are outcomes associated with other underlying difficulties.","Modify,Claim",Claim
10625,8-890,8-890_v2_117@2,8-890_v1_109@2,"Therefore, evidence from studies on children and adolescents at risk for or diagnosed with such conditions may provide important direction in decision-making when faces with self-harm and suicide.","Therefore, evidence from studies including young people with problem such as other mental health issues typically associated with self-harm may provide important direction in decision-making when faced with self-harm and suicide.","Modify,Clarity",Clarity
10626,8-890,8-890_v2_117@3,8-890_v1_109@3,"However, in studies on these conditions, self-harm and suicide are rarely investigated as outcomes <REF-39> – <REF-41> .","However, in the existing research-base on e.g. psychosis, depression and anxiety, self-harm and suicide are rarely investigated as outcomes <REF-36> – <REF-38> .","Modify,Fact/Evidence",Fact/Evidence
10627,8-890,8-890_v2_117@4,8-890_v1_109@4,"An exception is research on depression, with low certainty evidence indicating that combination treatment for depression (pharmacological treatment plus psychotherapy) may lead to a reduced risk for suicide <REF-40> .","According to the existing low certainty evidence, combination treatment for depression (pharmacological treatment plus psychotherapy) may lead to a reduced risk for suicide <REF-37> .","Modify,Fact/Evidence",Fact/Evidence
10628,8-890,8-890_v2_104@0,8-890_v1_110@0,Effects of preventive interventions: summary of findings and implications,Summary of findings: preventive interventions,"Modify,Other",Other
10629,8-890,8-890_v2_105@0,8-890_v1_111@0,"Based on the available research, school-based interventions can prevent suicidal ideation and suicide attempts short term (moderate certainty evidence), and possibly suicide attempts long term (low certainty evidence), which should have obvious implications for policy makers.","Based on the available research, there is moderate certainty evidence that school-based interventions can prevent suicidal ideation and suicide attempts short term, and low certainty evidence that they can prevent suicide attempts long term.","Modify,Claim",Claim
10630,8-890,8-890_v2_4@1,8-890_v1_4@1,"The effects of community-based interventions following suicide clusters and local suicide plans are unknown, as are the benefits and harms of screening young people for suicide risk.","The effects of community-based interventions following suicide clusters and local suicide plans are uncertain, as are the benefits and harms of screening young people for suicide risk.","Modify,Clarity",Clarity
10631,8-890,8-890_v2_107@0,8-890_v1_114@0,"We identified no reviews evaluating the effects of reducing access to means from children and young people specifically, or on how media reporting of suicides affects suicide rates in children and young people.",We identified no studies evaluating the effects of reducing access to means from children and young people specifically.,"Merge+Modify,Clarity",Clarity
10632,8-890,8-890_v2_107@1,8-890_v1_114@1,"In these instances, studies on interventions targeting the general population could be informative.","However, studies on the general population, including populations with adults, suggests that this may be an effective strategy <REF-26> .","Link+Modify,Claim",Claim
10633,8-890,8-890_v2_107@2,8-890_v1_114@1,"Such studies suggest that reducing access to means may be an effective strategy <REF-29> , and that certain forms of media reporting are associated with an increase in suicides <REF-29> .","However, studies on the general population, including populations with adults, suggests that this may be an effective strategy <REF-26> .","Link+Modify,Clarity",Clarity
10634,8-890,8-890_v2_107@0,8-890_v1_115@0,"We identified no reviews evaluating the effects of reducing access to means from children and young people specifically, or on how media reporting of suicides affects suicide rates in children and young people.","Furthermore, there is a need for more research on how media reporting of suicides affects suicide rates in children and young people.","Merge+Modify,Claim",Claim
10635,8-890,8-890_v2_107@2,8-890_v1_115@1,"Such studies suggest that reducing access to means may be an effective strategy <REF-29> , and that certain forms of media reporting are associated with an increase in suicides <REF-29> .","However, studies at a population level suggests that certain forms of media reporting are associated with an increase in suicides <REF-26> .","Link+Modify,Clarity",Clarity
10636,8-890,8-890_v2_107@3,8-890_v1_115@2,Guidelines on how to report on suicides is one suggested strategy to address the possible harms of such reporting <REF-29> .,Guidelines on how to report on suicides is one suggested strategy to address the harms of such reporting <REF-26> .,"Modify,Clarity",Clarity
10637,8-890,8-890_v2_108@2,8-890_v1_116@0,"However, based on a few studies, the certainty of evidence for community-based interventions following suicide clusters is very low, as is the evidence on effects of support-interventions in young people bereaved or affected by a suicide in their family or other network.",The certainty of evidence for community-based interventions following suicide clusters is very low.,"Modify,Claim",Claim
10638,8-890,8-890_v2_108@3,8-890_v1_116@2,"Even so, some recommendations are agreed upon, e.g. provision of information to relevant agencies in the community and providing support for those directly affected or other vulnerable individuals <REF-38> .","Even though research is scarce, some recommendations are agreed upon, e.g. provision of information to relevant agencies in the community and providing support for those directly affected or other vulnerable individuals <REF-40> .","Modify,Clarity",Clarity
10640,8-890,8-890_v2_109@0,8-890_v1_117@1,"The reviews we identified also searched for studies targeting young people in residential custodial and detention settings, but no studies were identified.",No studies evaluating interventions to prevent suicide in this high-risk population were identified.,"Merge+Modify,Claim",Claim
10641,8-890,8-890_v2_109@1,8-890_v1_117@2,"Therefore, effects of interventions in this high-risk population are uncertain.","Therefore, effects uncertain.","Modify,Clarity",Clarity
10642,8-890,8-890_v2_110@0,8-890_v1_119@0,Effects of interventions for existing self-harm: summary of findings and implications,Summary of findings: interventions for existing self-harm,"Modify,Other",Other
10643,8-890,8-890_v2_112@1,8-890_v1_120@0,It is uncertain which approach to risk assessment of young people after an episode of self-harm is most appropriate given low certainty evidence.,"Based on the available evidence, it is uncertain which approach to risk assessment of young people after an episode of self-harm is most appropriate.","Modify,Clarity",Clarity
10644,8-890,8-890_v2_112@2,8-890_v1_120@1,"Furthermore, the effects of psychoeducation, psychological therapy, psychosocial interventions, digital interventions for self-management and nutrition for treating young people with existing self-harm are unknown, as no studies were identified.","Furthermore, the effects of psychoeducation, psychological therapy, psychosocial interventions, digital interventions for self-management and nutrition for treating young people with existing self-harm are uncertain.","Modify,Clarity",Clarity
10645,8-890,8-890_v2_111@1,8-890_v1_121@0,"However, based on the available evidence, only two treatment comparisons evaluating psychological therapy provided evidence of their effectiveness (low certainty); dialectical behavioural therapy and developmental group therapy.",Two treatment comparisons evaluating psychological therapy provided evidence of their effectiveness (low certainty); dialectical behavioural therapy and developmental group therapy.,"Modify,Clarity",Clarity
10646,8-890,8-890_v2_111@2,8-890_v1_121@1,"Both treatments were compared to enhanced TAU (e.g. individual and family sessions, medication management, and hospital or respite care as required), and there was little or no important difference in effect on repetition of self-harm, nor on symptoms of depression.","Both treatments were compared to alternative psychological therapy, and there was little or no important difference in effect on repetition of self-harm compared to alternative follow up.","Modify,Fact/Evidence",Fact/Evidence
10647,8-890,8-890_v2_111@3,8-890_v1_121@2,"However, of notice, although not statistically significant, there was a substantial higher degree of repetition of self-harm amongst adolescents participating in group developmental therapy compared to those receiving enhanced TAU at six-month follow-up.","However, of notice, there was substantially higher (although not statistically significant) repetition of self-harm amongst adolescents participating in group developmental therapy compared to those receiving individual therapy at six-month follow-up.","Modify,Clarity",Clarity
10648,8-890,8-890_v2_113@0,8-890_v1_122@0,"The reviews we included searched for, but did not identify, studies on direct comparisons between different pharmacological treatment alternatives or on the effects of combination therapy (pharmacological treatment plus psychotherapy).",We found no studies on direct comparisons of pharmacological treatments or on the effects of combination therapy (pharmacological plus psychotherapy).,"Modify,Clarity",Clarity
10649,8-890,8-890_v2_108@0,8-890_v1_124@0,"Suicide clusters, although rare, is a phenomenon of major concern.","Suicide clusters, although rare, is of major concern.","Modify,Clarity",Clarity
10650,8-890,8-890_v2_108@1,8-890_v1_124@1,"When faced with potential social contagion following suicide, communities are expected to act to prevent contaigon and clustering.","When faced with this phenomenon or in fear of potential social contagion following the suicide of an individual, communities are expected to act to prevent further social contagion and clustering.","Modify,Clarity",Clarity
10651,8-890,8-890_v2_119@2,8-890_v1_127@1,"Furthermore, it is not possible to make any conclusions about the benefits or harms of screening in young people with or without known risk of self-harm and suicide.","Furthermore, it is not possible to make any conclusions about the benefits and harms of screening in young people or and without known risk of self-harm and suicide.","Modify,Grammar",Grammar
10652,8-890,8-890_v2_120@1,8-890_v1_128@1,"The effects of other interventions specifically targeting self-harm are unknown, because of lack of research or evidence of very low certainty, and should be evaluated.",The effects of evidence for other interventions preventing self-harm and suicide is of very low certainty or remains to be evaluated.,"Modify,Claim",Claim
10653,8-890,8-890_v2_106@1,8-890_v1_130@2,"Screening for suicide risk as primary prevention may provide the opportunity of early detection, and if precise, offer the opportunity to provide young people at risk with appropriate treatment.","Screening for suicide risk as primary prevention may provide the opportunity of early detection, and if precise, offers the opportunity to provide young people at risk with appropriate treatment.","Modify,Grammar",Grammar
10654,8-890,8-890_v2_106@5,8-890_v1_130@4,"Therefore, when implemented, approaches to risk assessment and screening programs, as well as local suicide plans, should be closely evaluated.","When implemented, local suicide plans, approaches to risk assessment and screening programs should be closely evaluated.","Modify,Clarity",Clarity
10655,8-890,8-890_v2_108@4,8-890_v1_131@2,"However, given that the above-mentioned research is of very low certainty, we suggest that researchers design appropriate observational studies, allowing for enough observations pre- and post-implementation of preventive measures to inform policy.","We suggest that researchers design appropriate observational studies, allowing for enough observations pre- and post-implementation of preventive measures to inform policy.","Modify,Claim",Claim
10656,8-890,8-890_v2_121@2,8-890_v1_132@1,"First and foremost, more research is needed, including studies on children younger than 12 years og age, as well as long-term follow up.","More research is needed, including on younger children and long-term follow up.","Modify,Clarity",Clarity
10657,8-890,8-890_v2_121@6,8-890_v1_133@1,"Third, policy makers and health providers should consider evidence from other relevant populations in decision-making, such as studies on adults, as well as studies on conditions associated with self-harm and/or suicidality, e.g. depression and psychosis.","It follows that psychological or psychosocial approaches showing promise in treatment and prevention of conditions associated with self-harm and/or suicidality, such as depression and psychosis, should be considered in treatment of repeated self-harm.","Merge+Modify,Claim",Claim
10658,8-890,8-890_v2_121@6,8-890_v1_133@2,"Third, policy makers and health providers should consider evidence from other relevant populations in decision-making, such as studies on adults, as well as studies on conditions associated with self-harm and/or suicidality, e.g. depression and psychosis.","In general, when effects of interventions preventing self-harm and suicide in children and adolescents are uncertain due to lack of research or evidence of very low certainty, policy makers and health providers should consider evidence from population-based studies and adults.","Merge+Modify,Claim",Claim
10659,8-890,8-890_v2_121@5,8-890_v1_134@0,"Hence, it is crucial to be mindful that our own preventive actions or treatment efforts could contribute to an increased risk for self-harm and suicide, and both adverse as well as beneficial effects should be evaluated.",It is crucial to be mindful that our own preventive actions or treatment efforts possibly could contribute to an increased risk for self-harm and suicide.,"Merge+Modify,Clarity",Clarity
10660,8-890,8-890_v2_121@5,8-890_v1_134@1,"Hence, it is crucial to be mindful that our own preventive actions or treatment efforts could contribute to an increased risk for self-harm and suicide, and both adverse as well as beneficial effects should be evaluated.","Practice should be evaluated, and researchers should investigate harmful effects as well as beneficial effects of interventions.","Merge+Modify,Clarity",Clarity
10661,8-890,8-890_v2_5@0,8-890_v1_5@0,The effects of most interventions targeting children and adolescents with known self-harm are unknown.,The effects of most interventions targeting children and adolescents with known self-harm are uncertain.,"Modify,Clarity",Clarity
10662,8-890,8-890_v2_6@1,8-890_v1_6@1,"When such interventions are implemented, the effects should be closely evaluated.","When implemented, these interventions should be closely evaluated.","Modify,Clarity",Clarity
10663,8-890,8-890_v2_7@0,8-890_v1_7@0,"In prevention of self-harm and suicide in children and adolescents, policy makers and health providers should consider evidence from population-based studies with mixed-age samples, adult samples, and studies on conditions associated with self-harm and/or suicidality, such as depression and psychosis.",Policy makers and health providers should consider evidence from population-based studies and adults in preventing self-harm and suicide in children and adolescents.,"Merge+Modify,Claim",Claim
10664,8-890,8-890_v2_7@0,8-890_v1_7@1,"In prevention of self-harm and suicide in children and adolescents, policy makers and health providers should consider evidence from population-based studies with mixed-age samples, adult samples, and studies on conditions associated with self-harm and/or suicidality, such as depression and psychosis.","Also, approaches showing promise in treatment of conditions associated with self-harm and/or suicidality, such as depression and psychosis, should be considered.","Merge+Modify,Clarity",Clarity
10665,8-890,8-890_v2_10@1,8-890_v1_10@1,"It is often a coping mechanism used to solve a difficult situation, and can serve functions such as affect regulation, communicating the extent of pain, or self-punishment <REF-3> .",It is often a coping mechanism used to solve a difficult situation and can serve several functions.,"Merge+Modify,Clarity",Clarity
10666,8-890,8-890_v2_10@1,8-890_v1_10@2,"It is often a coping mechanism used to solve a difficult situation, and can serve functions such as affect regulation, communicating the extent of pain, or self-punishment <REF-3> .","Affect regulation, managing painful unpleasant emotional states including making emotional pain physical and blocking bad memories, is commonly reported <REF-3> .","Merge+Modify,Fact/Evidence",Fact/Evidence
10667,8-890,8-890_v2_10@1,8-890_v1_10@3,"It is often a coping mechanism used to solve a difficult situation, and can serve functions such as affect regulation, communicating the extent of pain, or self-punishment <REF-3> .","Self-harm can also serve interpersonal functions, such as seeking help from someone or communicating the extent of pain <REF-3> .","Merge+Modify,Clarity",Clarity
10668,8-890,8-890_v2_10@1,8-890_v1_10@4,"It is often a coping mechanism used to solve a difficult situation, and can serve functions such as affect regulation, communicating the extent of pain, or self-punishment <REF-3> .","In addition, people who self-harm sometimes report self-punishment as a motivation <REF-3> .","Merge+Modify,Fact/Evidence",Fact/Evidence
10669,8-890,8-890_v2_10@6,8-890_v1_10@5,Completed suicide is on the other hand defined as the act of intentionally ending one ’ s own life <REF-11> .,Completed suicide is defined as the act of intentionally ending one ’ s own life <REF-4> .,"Modify,Clarity",Clarity
10670,8-890,8-890_v2_10@9,8-890_v1_10@6,"Self-harm and suicide result from underlying risk- and maitaining factors, spanning from other mental health problems such as depression, biological factors, exposure to traumatic events or other difficult circumstances in the young person’s environment <REF-4> , <REF-13> .","Self-harm and suicide result from underlying factors such as other mental health problems, exposure to traumatic events or other difficult circumstances in the young person’s environment.","Modify,Fact/Evidence",Fact/Evidence
10671,8-890,8-890_v2_39@0,8-890_v1_41@0,"From the systematic reviews, we extracted information about the primary studies’ populations, characteristics of the interventions and comparison groups, duration of the interventions, follow-up periods, outcome measures and pooled effect estimates for each outcome.","From the systematic reviews, we extracted information about the primary studies populations, characteristics of the interventions and comparison groups, duration of the interventions, follow-up periods, outcome measures and pooled effect estimates for each outcome.","Modify,Grammar",Grammar
10672,8-890,8-890_v2_40@1,8-890_v1_42@1,"For reviews including studies on both children/adolescents and adult populations, we only extracted information from studies on children and adolescents.","For reviews also including studies on adult populations, we only extracted information from studies of children and adolescents.","Modify,Fact/Evidence",Fact/Evidence
10673,8-890,8-890_v2_42@0,8-890_v1_44@0,"We assessed our confidence in the evidence of effect for each outcome using the GRADE methodology (the Grading of Recommendations Assessment, Development and Evaluation) <REF-28> .","We assessed our confidence in the evidence of effect for each outcomes using the GRADE methodology (the Grading of Recommendations Assessment, Development and Evaluation) <REF-25> .","Modify,Grammar",Grammar
10674,8-890,8-890_v2_42@1,8-890_v1_44@1,"If the systematic review authors already had completed a GRADE assessment, we reviewed this.","If the systematic review authors had already completed a GRADE assessment, we reviewed this.","Modify,Grammar",Grammar
10675,8-890,8-890_v2_10@11,8-890_v1_10@7,"Such exposure may contribute to self-harm and suicide in adolescents, a phenomenon referred to as “social contagion” <REF-4> .","Exposure to family and/or friends self-harm and suicide may contribute to self-harm and suicide in adolescents, a phenomenon referred to as “social contagion” <REF-5> .","Modify,Fact/Evidence",Fact/Evidence
10676,8-890,8-890_v2_45@1,8-890_v1_47@1,"Additionally, we identified 12 records through hand-searches.","Additionally, we also identified 12 records through hand-searches.","Modify,Clarity",Clarity
10677,8-890,8-890_v2_45@2,8-890_v1_47@2,"Of the all together 1271 references, we excluded 1242 based on title or summary, mainly because they focused on other diagnosis or problem-areas than self-harm and/or suicide.","We excluded 1242 of these based on title or summary, mainly because they focused on other diagnosis or problem-areas than self-harm and/or suicide.","Modify,Fact/Evidence",Fact/Evidence
10678,8-890,8-890_v2_10@3,8-890_v1_11@4,"Prevalence is highest amongst adolescent girls, typically done by cutting, but self-harm is also a problem amongst boys, more often hitting themselves <REF-6> , <REF-7> .","Prevalence is highest amongst adolescent girls, but it is also a problem amongst boys <REF-7> .","Merge+Modify,Clarity",Clarity
10679,8-890,8-890_v2_10@3,8-890_v1_11@5,"Prevalence is highest amongst adolescent girls, typically done by cutting, but self-harm is also a problem amongst boys, more often hitting themselves <REF-6> , <REF-7> .","Some studies indicate that the gender differences are smaller than previously assumed, and that boys often inflict self-injury in other ways than girls; while girls often cut themselves, boys more often hit themselves <REF-8> .","Merge+Modify,Fact/Evidence",Fact/Evidence
10680,8-890,8-890_v2_10@4,8-890_v1_11@6,"It may be temporary or more long-lasting in nature <REF-6> , and one episode of self-harm is a strong predictor of repetition <REF-8> , <REF-9> .","Self-harm may be a temporary or more long-lasting in nature <REF-7> , and one episode of self-harm is a strong predictor of repetition of this behaviour <REF-9> , <REF-10> .","Modify,Clarity",Clarity
10681,8-890,8-890_v2_10@5,8-890_v1_11@7,"When repeated, the person often advances to a combination of different methods, increasing the medical severity <REF-10> .","When self-harm is repeated, the person often advances to a combination of different methods, increasing the medical severity <REF-11> .","Modify,Clarity",Clarity
10682,8-890,8-890_v2_55@2,8-890_v1_57@2,"Preventive interventions were either focused on primary prevention for mixed-age population based samples (suicide awareness campaigns and other school-based prevention programs, screening for suicide risk) or secondary prevention (local approaches following suicide clusters, suicide prevention in residential custodial and detention settings, interventions to support children and adolescents bereaved or affected by a suspected suicide) <REF-17> , <REF-29> , <REF-30> .","Preventive interventions were either primary prevention strategies for mixed population based samples (suicide awareness campaigns and other school-based prevention programs, screening for suicide risk) or secondary preventions strategies (local approaches following suicide clusters, suicide prevention in residential custodial and detention settings, interventions to support children and adolescents bereaved or affected by a suspected suicide) <REF-14> , <REF-26> , <REF-27> .","Modify,Clarity",Clarity
10683,8-890,8-890_v2_10@7,8-890_v1_11@8,"Suicide is rare before the age of 15 but increases in prevalence through adolescence <REF-5> , and is somewhat most prevalent amongst males <REF-12> .",Suicide is on the other hand rare before the age of 15 but increases in prevalence through adolescence <REF-6> .,"Merge+Modify,Clarity",Clarity
10684,8-890,8-890_v2_10@7,8-890_v1_11@9,"Suicide is rare before the age of 15 but increases in prevalence through adolescence <REF-5> , and is somewhat most prevalent amongst males <REF-12> .","In most parts of the world, male adolescents are more likely to commit suicide than female adolescents <REF-12> .","Merge+Modify,Clarity",Clarity
10685,8-890,8-890_v2_57@1,8-890_v1_59@1,Our assessment of certainty of evidence corresponds to GRADE-tables in Table 3 – Table 16 .,Our assessment of certainty on the evidence corresponds to GRADE-tables in Table 3 –Table 18.,"Modify,Grammar",Grammar
10686,8-890,8-890_v2_12@0,8-890_v1_12@0,There are several reviews with summarized evidence on effects of interventions aimed at preventing (re)occurance of self-harm and suicide.,Several reviews of interventions for preventing self-harm and suicide exist.,"Modify,Claim",Claim
10687,8-890,8-890_v2_12@1,8-890_v1_12@1,"However, many reviews are of variable quality, or outdated <REF-16> – <REF-21> .","However, many are of variable quality, or are outdated <REF-13> – <REF-18> .","Modify,Clarity",Clarity
10688,8-890,8-890_v2_60@0,8-890_v1_62@0,"The review authors also searched for research on effects of the following interventions (versus treatment as usual (TAU) or alternative interventions), but studies on children and adolescents under the age of 18 were not identified.","For the following interventions (versus treatment as usual (TAU) or alternative interventions), the review authors also searched for research on effects, but did not identify studies on children and adolescents under the age of 18 were not identified.","Modify,Clarity",Clarity
10689,8-890,8-890_v2_60@1,8-890_v1_62@1,"These were primary and secondary preventive interventions (reducing access to means, local suicide plans, local media reporting of suicides in newspapers, Internet or other digital channels, suicide prevention in residential custodial and detention settings) <REF-29> and interventions targeting existing self-harm (assessment in children and adolescents at the emergency department, psychoeducation, pharmacological treatment or a combination of pharmacological treatment and psychotherapy, nutrition, other psychotherapeutic approaches such as problem-solving therapy, psychodynamic therapy, multi-systemic therapy, supportive therapy, or other psychosocial approaches such as counselling, self-management, respite care, assertive outreach) <REF-1> , <REF-31> – <REF-35> .","These are primary and secondary preventive interventions (reducing access to means, local suicide plans, local media reporting of suicides in newspapers, Internet or other digital channels, suicide prevention in residential custodial and detention settings) <REF-26> and interventions for existing self-harm (assessment in children and adolescents at the emergency department, psychoeducation, pharmacological treatment or a combination of pharmacological treatment and psychotherapy, nutrition, other psychotherapeutic approaches such as problem-solving therapy, psychodynamic therapy, multi-systemic therapy, supportive therapy, or other psychosocial approaches such as counselling, self-management, respite care, assertive outreach) <REF-1> , <REF-28> – <REF-32> .","Modify,Clarity",Clarity
10690,8-890,8-890_v2_12@2,8-890_v1_12@2,"Furthermore, there is a large overlap of interventions covered in the different reviews, making it difficult for professionals to sort out the best available evidence needed to make informed decisions <REF-22> .","As is the case for many health conditions, there is a large overlap in topics covered by the reviews, making it difficult for professionals to sort out the best available evidence in making informed decisions <REF-19> .","Modify,Claim",Claim
10691,8-890,8-890_v2_62@8,8-890_v1_64@8,Effects on help-seeking and unwanted effects are unclear since the evidence for these outcomes is of very low certainty⊕⊖⊖⊖. See Table 3 .,Effects on help-seeking and possible unwanted effects are unclear since the evidence for these outcomes is of very low certainty⊕⊖⊖⊖. See Table 3 .,"Modify,Clarity",Clarity
10692,8-890,8-890_v2_12@3,8-890_v1_12@3,"Consequently, we wanted to provide an up-to-date overview of the best quality summarized evidence on effects of all types of interventions aimed at preventing self-harm and suicide.","Consequently, we wanted to provide an up-to-date overview of the best quality summarized evidence of effects of interventions aimed at preventing self-harm and suicide, supporting informed decision-making.","Modify,Claim",Claim
10693,8-890,8-890_v2_66@2,8-890_v1_68@2,"However, the evidence of effects of interventions to support children and adolescents bereaved or affected by a suspected suicide is of very low certainty⊕⊖⊖⊖. See Table 5 .",The evidence of effects of interventions to support children and adolescents bereaved or affected by a suspected suicide is of very low certainty⊕⊖⊖⊖. See Table 5 .,"Modify,Clarity",Clarity
10694,8-890,8-890_v2_14@0,8-890_v1_14@0,The objective of this review is to summarize the effects of interventions aimed at preventing self-harm and suicide in children and adolescents.,The objective of this review is to summarize the effects of interventions for preventing self-harm and suicide in children and adolescents.,"Modify,Clarity",Clarity
10695,8-890,8-890_v2_16@0,8-890_v1_16@0,This review was registered with the international prospective register of systematic reviews (PROSPERO; CRD42019117942 ) on February 8 2019.,This review was registered with the international prospective register of systematic reviews (PROSPERO; CRD42019117942 ) on 08 February 2019.,"Modify,Clarity",Clarity
10696,8-890,8-890_v2_18@0,8-890_v1_18@0,"We included systematic reviews published in 2012 and later (last date searched August 2018), and fulfilling the DARE-criteria <REF-23> .","We included systematic reviews published in 2012 and later (last date searched August 2018), with publications in English, Norwegian, Danish or Swedish, and fulfilling the DARE-criteria <REF-20> .","Modify,Fact/Evidence",Fact/Evidence
10697,8-890,8-890_v2_69@3,8-890_v1_71@3,They did however identify two studies evaluating adverse effects associated with screening for psychological distress and a history of deliberate self-harm and suicidal ideation in primary care settings.,They did however identify two studies evaluating harms associated with screening for psychological distress and a history of deliberate self-harm and suicidal ideation in primary care settings.,"Modify,Clarity",Clarity
10698,8-890,8-890_v2_18@4,8-890_v1_18@1,The other inclusion criteria (PICO) are presented in Box 1.,The inclusion criteria (PICO) is presented in Box 1 .,"Modify,Clarity",Clarity
10699,8-890,8-890_v2_72@1,8-890_v1_75@1,"The evidence includes one study with 70 adolescents, 12 to 18-year olds referred for a psychosocial assessment following an episode of self-injury or self-poisoning, irrespective of intent <REF-31> .","The evidence includes one study with 70 adolescents, 12 to 18-year olds, referred for a psychosocial assessment following an episode of self-injury or self-poisoning, irrespective of intent <REF-28> .","Modify,Grammar",Grammar
10700,8-890,8-890_v2_22@0,8-890_v1_22@0,"- Children and adolescents with other main-diagnosis, e.g. children admitted to hospitals because of somatic illness at the same time as experiencing depressive symptoms.","• Children and adolescents with other main-diagnosis, e.g. children admitted to hospitals because of somatic illness at the same time as experiencing depressive symptoms.","Modify,Grammar",Grammar
10701,8-890,8-890_v2_22@2,8-890_v1_23@0,"- Interventions preventing other behaviours with no direct association with mental health, e.g. interventions targeting smoking cessation.","• Interventions preventing other behaviours with no direct association with mental health, e.g. interventions targeting smoking cessation.","Modify,Grammar",Grammar
10702,8-890,8-890_v2_75@1,8-890_v1_78@1,"The evidence includes one study with 80 adolescents, 12 to 17-year olds, diagnosed with depression and presenting to emergency departments or community psychiatric services following an episode of self-injury or self-poisoning, irrespective of whether suicidal intent was present <REF-31> .","The evidence includes one study with 80 adolescents, 12 to 17-year olds, diagnosed with depression presenting to emergency departments or community psychiatric services following an episode of self-injury or self-poisoning, irrespective of whether suicidal intent was present <REF-28> .","Modify,Grammar",Grammar
10703,8-890,8-890_v2_3@2,8-890_v1_3@2,"The methodological quality of the included reviews was assessed independently, and data was extracted by two reviewers.","The quality of the included reviews was assessed independently, and data was extracted by two reviewers.","Modify,Clarity",Clarity
10704,8-890,8-890_v2_78@4,8-890_v1_81@4,"Based on the available evidence, DBT-A has little or no additional effect on repetition or frequency of self-harm (OR 0.72, 95% KI 0.12 to 4.40, low certainty⊕⊕⊖⊖) compared to (enhanced) treatment as usual.","Based on the available evidence DBT-A has little or no effect on repetition or frequency of self-harm (OR 0.72, 95% KI 0.12 to 4.40, low certainty⊕⊕⊖⊖).","Modify,Clarity",Clarity
10705,8-890,8-890_v2_78@5,8-890_v1_81@5,"However, DBT-A may have a moderate effect on reduction of suicidal ideation (SMD -0.62, 95% KI -1.07 to -0.16, low certainty⊕⊕⊖⊖).","DBT-A may have a moderate effect on reduction of suicidal ideation (SMD -0.62, 95% KI -1.07 to -0.16, low certainty⊕⊕⊖⊖).","Modify,Clarity",Clarity
10706,8-890,8-890_v2_78@6,8-890_v1_81@6,The certainty of evidence for other outcomes is very low⊕⊖⊖⊖. See Table 9 .,The certainty of the evidence for other outcomes is very low⊕⊖⊖⊖. See Table 9 .,"Modify,Grammar",Grammar
10707,8-890,8-890_v2_25@0,8-890_v1_27@0,The present overview of systematic reviews was developed following the principles of the Cochrane handbook <REF-26> .,The present review of systematic reviews was developed following the principles of the Cochrane handbook <REF-23> .,"Modify,Clarity",Clarity
10708,8-890,8-890_v2_25@1,8-890_v1_27@1,"Two researchers independently reviewed all publications indexed in IN SUM (two of the authors: AD or ISM, and/or a research colleague KTH).","Two researchers independently reviewed all publications indexed in IN SUM (two of the athors: AD or ISM, and/or a research colleague KTH).","Modify,Grammar",Grammar
10709,8-890,8-890_v2_25@2,8-890_v1_27@2,"Supplementing the references found in IN SUM, we also hand-searched for relevant systematic reviews, in the following databases and organizations:","We also hand-searched for relevant systematic reviews, in the following databases and organisations:","Modify,Claim",Claim
10710,8-890,8-890_v2_81@4,8-890_v1_84@4,The certainty of evidence for effects of CBT compared to non-directive psychotherapy is very low⊕⊖⊖⊖. See Table 10 .,The certainty of the evidence for CBT versus non-directive psychotherapy is very low⊕⊖⊖⊖. See Table 10 .,"Modify,Clarity",Clarity
10711,8-890,8-890_v2_31@1,8-890_v1_33@1,"Two researchers (ISM, AA) independently screened and assessed all full text reviews for potential inclusion.","Two researchers (ISM, AA) independently screened and assessed all full text publications for potential inclusion.","Modify,Clarity",Clarity
10712,8-890,8-890_v2_3@4,8-890_v1_3@4,"The certainty of evidence was assessed using Grading of Recommendations Assessment, Development and Evaluation (GRADE).","The certainty of the evidence was assessed using Grading of Recommendations Assessment, Development and Evaluation (GRADE).","Modify,Grammar",Grammar
10713,8-890,8-890_v2_33@0,8-890_v1_35@0,We sorted all included reviews by population and intervention comparisons (the PICOs).,We sorted all included reviews by population and which interventions were compared (the PICOs).,"Modify,Clarity",Clarity
10714,8-890,8-890_v2_33@1,8-890_v1_35@1,"In cases were more than one review addressed the same comparison for the same population, we included the review with the newest search date (and completeness of this search by considering the included primary studies) and the best quality.","In cases were more than one review addressed the same treatment comparison for the same population, we included the review with the newest search (and completeness of this search by considering the included studies) and the best quality.","Modify,Clarity",Clarity
10715,8-890,8-890_v2_84@1,8-890_v1_87@1,"The evidence contains three studies with 487 adolescents, 12 to 17-year olds, referred to child and adolescent services following an episode of intentional self-injury or self-poisoning, irrespective of intent <REF-31> .","The evidence contains three studies of 487 adolescents, 12 to 17-year olds, referred to child and adolescent services following an episode of intentional self-injury or self-poisoning, irrespective of intent <REF-28> .","Modify,Grammar",Grammar
10716,8-890,8-890_v2_84@2,8-890_v1_87@2,"The acute treatment phase was six weekly sessions, followed by weekly or biweekly booster sessions for as long as required.","Acute treatment phase was six weekly sessions, followed by weekly or biweekly booster sessions for as long as required.","Modify,Grammar",Grammar
10717,8-90,8-90_v2_30@0,,"An additional 19 patient samples (8 SRS, 11 FGR) were deep-sequenced using a custom Nonacus Cell3 TM Target enrichment panel for NGS (Nonacus, Birmingham, UK), using the Manufacturer’s instructions and a protocol described previously ( Buonocore et al. , 2019 ).",,"Add,Fact/Evidence",Fact/Evidence
10718,8-90,8-90_v2_30@1,,"The panel design captured the coding regions of growth related genes CDKN1C and SAMD9 (Tier 1 design, 1Kb – 1.2Mb, Total target size 7386bp).",,"Add,Fact/Evidence",Fact/Evidence
10719,8-90,8-90_v2_30@2,,"In brief, genomic DNA samples (100ng) underwent enzymatic shearing followed by end repair and dA tailing to ligate molecular identifier adapters.",,"Add,Fact/Evidence",Fact/Evidence
10720,8-90,8-90_v2_30@3,,"DNA was purified using Agencourt AMPure beads (Beckman Coulter Inc., USA) to remove nonligated adapters, and amplified using adapter primers.",,"Add,Fact/Evidence",Fact/Evidence
10721,8-90,8-90_v2_30@4,,"Libraries were hybridised with the customised probes, washed, and then targeted library DNA sequences were amplified.",,"Add,Fact/Evidence",Fact/Evidence
10722,8-90,8-90_v2_30@5,,"After washing and quantification, the libraries were sequenced on a MiSeq platform (Illumina Inc.).",,"Add,Fact/Evidence",Fact/Evidence
10723,8-90,8-90_v2_30@6,,Fastq files were analysed on a bioinformatics pipeline provided by Nonacus and variant calling undertaken in Platypus (v 0.8.1).,,"Add,Fact/Evidence",Fact/Evidence
10724,8-90,8-90_v2_30@7,,Inspection of BAM files was done in the Integrative Genomics Viewer.,,"Add,Fact/Evidence",Fact/Evidence
10725,8-90,8-90_v2_50@0,,Analysis of CDKN1C variants outside of the PCNA Binding Domain,,"Add,Other",Other
10726,8-90,8-90_v2_51@0,,"Extended analysis of other regions of CDKN1C did not reveal any nonsense, frameshift and canonical splice site variants, which is not surprising as these variants would be loss of function and would be predicted to be associated with overgrowth.",,"Add,Claim",Claim
10727,8-90,8-90_v2_52@0,,"We did identify two heterozygous, non-synonymous missense variants in the cohort of 78 women with recurrent miscarriages.",,"Add,Fact/Evidence",Fact/Evidence
10728,8-90,8-90_v2_52@1,,One of these is a 9:g.2906703A>G variant (rs201715947) predicted to result in a p.Leu6Pro change that is present in gnomAD with allelic frequency of 0.0001102 (8/72604).,,"Add,Fact/Evidence",Fact/Evidence
10729,8-90,8-90_v2_52@2,,The other variant is a 9:g.2906589C>T change predicted to result in p.Arg44His.,,"Add,Fact/Evidence",Fact/Evidence
10730,8-90,8-90_v2_52@3,,This variant is not present in gnomAD but a p.Arg44Leu is present in one individual.,,"Add,Fact/Evidence",Fact/Evidence
10731,8-90,8-90_v2_52@4,,"We cannot definitively say whether these variants are clinically relevant and pathogenic, but feel it is unlikely.",,"Add,Claim",Claim
10732,8-90,8-90_v2_25@0,8-90_v1_25@0,"Direct Sanger Sequencing was undertaken for 58 SRS patients to analyse the PCNA-binding region (codons 213–316) and hotspot (codons 272–281) using primers reported previously (CCDS7738, ENST00000414822.8) ( Arboleda et al. , 2012 ).","Direct Sanger Sequencing was undertaken for SRS patients to analyse the PCNA-binding region (codons 213–316) and hotspot (codons 272–281) using primers reported previously (CCDS7738, ENST00000414822.8) ( Arboleda et al. , 2012 ).","Modify,Fact/Evidence",Fact/Evidence
10733,8-90,8-90_v2_28@0,8-90_v1_28@0,"A targeted enrichment custom HaloPlex HS panel (501kb–2.5Mb) (Agilent Technologies Inc.) was designed using Agilent SureDesign to capture known and candidate genes for fetal growth disruption, including CDKN1C .","A targeted enrichment custom HaloPlex 501kb–2.5Mb HS panel (Agilent Technologies Inc.) was designed using Agilent SureDesign to capture known and candidate genes for fetal growth disruption, including CDKN1C .","Modify,Clarity",Clarity
10734,8-90,8-90_v2_33@0,8-90_v1_32@0,"Review of available data revealed seven publications describing isolated individuals (7) or families (5) with IMAGe syndrome and adrenal insufficiency, who had pathogenic variants in a key region of the PCNA-binding domain of CDKN1C affecting codons 272, 274, 276, 278 and 279 ( Figure 1 , Table 2 ) ( Arboleda et al. , 2012 ; Bodian et al. , 2014 ; Brioude et al. , 2013 ; Hamajima et al. , 2013 ; Kato et al. , 2014 ; Kerns et al. , 2014 ; Sabir et al. , 2019 ).","Review of available data revealed six publications describing isolated individuals (7) or families (4) with IMAGe syndrome and adrenal insufficiency, who had pathogenic variants in a key region of the PCNA-binding domain of CDKN1C affecting codons 272, 274, 276, 278 and 279 ( Figure 1 , Table 2 ) ( Arboleda et al. , 2012 ; Bodian et al. , 2014 ; Brioude et al. , 2013 ; Hamajima et al. , 2013 ; Kato et al. , 2014 ; Kerns et al. , 2014 ).","Modify,Fact/Evidence",Fact/Evidence
10735,8-90,8-90_v2_3@2,8-90_v1_3@2,"Targeted sequencing was used to investigate the critical region of CDKN1C for potential pathogenic variants in SRS (n=66), FGR (n=37), DNA from spontaneous loss of pregnancy (n= 22) and women with recurrent miscarriages (n=78) (total n=203).","Targeted sequencing was used to investigate the critical region of CDKN1C for potential pathogenic variants in SRS (n=58), FGR (n=26), DNA from spontaneous loss of pregnancy (n= 21) and women with recurrent miscarriages (n=71) (total n=176).","Modify,Fact/Evidence",Fact/Evidence
10736,8-90,8-90_v2_33@2,8-90_v1_32@2,"Multiple individuals from different ancestral backgrounds were found to have p.Asp274Asn, p.Lys278Glu or p.Arg279Leu changes.",Multiple individuals from different ancestral backgrounds were found to have p.Asp274Asn or p.Lys278Glu changes.,"Modify,Fact/Evidence",Fact/Evidence
10737,8-90,8-90_v2_41@1,8-90_v1_40@1,Very rare heterozygous SNVs were found that are predicted to cause p.Ala277Val (11:2905355G>A;1 in 10512 alleles) and p.Ala283Val (11:2905337G>A; rs776541692; 1 in 1158 alleles) changes.,Very rare heterozygous SNVs were found that are predicted to cause p.Ala277Val (11:2905355G>A;1 in 107288 alleles) and p.Ala283Val (11:2905337G>A; rs776541692; 1 in 30726 alleles) changes.,"Modify,Fact/Evidence",Fact/Evidence
10738,8-90,8-90_v2_48@0,8-90_v1_47@0,"A next-generation sequencing (NGS) approach of CDKN1C in children with SRS (n=8), IUGR/FGR (n=37), products of conception (n=22), and mothers with a history of recurrent miscarriage (n=78) also did not reveal pathogenic variants in this PCNA-binding domain region ( Table 1 ).","A next-generation sequencing approach of CDKN1C in children with IUGR/FGR (n=26), products of conception (n=21), and mothers with a history of recurrent miscarriage (n=71) also did not reveal pathogenic variants in this region ( Table 1 ).","Modify,Fact/Evidence",Fact/Evidence
10739,8-90,8-90_v2_54@1,8-90_v1_49@1,"Although loss-of-function of CDKN1C is known to cause macrosomia as part of Beckwith-Wiedemann Syndrome, it is only in the past eight years that “gain-of-function” variants in CDKN1C have been shown to cause growth restriction and IMAGe syndrome.","Although loss-of-function of CDKN1C is known to cause macrosomia as part of Beckwith-Wiedemann Syndrome, it is only in the past six years that “gain-of-function” variants in CDKN1C have been shown to cause growth restriction and IMAGe syndrome.","Modify,Fact/Evidence",Fact/Evidence
10740,8-90,8-90_v2_57@0,8-90_v1_52@0,"Further evidence for a potential role for CDKN1C in fetal growth restriction phenotypes has emerged with reports of CDKN1C variants in familial growth restriction and familial SRS ( Brioude et al. , 2013 ; Kerns et al. , 2014 ; Sabir et al. , 2019 ).","Further evidence for a potential role for CDKN1C in fetal growth restriction phenotypes has emerged with reports of CDKN1C variants in familial growth restriction and familial SRS ( Brioude et al. , 2013 ; Kerns et al. , 2014 ).","Modify,Fact/Evidence",Fact/Evidence
10741,8-90,8-90_v2_57@5,8-90_v1_52@5,"In two families a charged arginine at codon 279 is replaced by a non-polar leucine, whereas a proline at this position is found in classic IMAGe syndrome.","In one family a charged arginine at codon 279 is replaced by a non-polar leucine, whereas a proline at this position is found in classic IMAGe syndrome.","Modify,Fact/Evidence",Fact/Evidence
10742,8-90,8-90_v2_61@1,8-90_v1_56@1,"Although 203 total individuals were studied, each sub group is still relatively small and rare CDKN1C variants might be discovered if the sample size is increased.","Although 176 total individuals were studied, each sub group is still relatively small and rare CDKN1C variants might be discovered if the sample size is increased.","Modify,Fact/Evidence",Fact/Evidence
10743,8-90,8-90_v2_11@0,8-90_v1_11@0,"More recently, SNVs in the PCNA-binding domain of CDKN1C have been reported in families with maternally-inherited fetal growth restriction (FGR) without adrenal insufficiency and in familial Silver-Russell syndrome (SRS) (OMIM 180860 ) ( Brioude et al. , 2013 ; Kerns et al. , 2014 ; Sabir et al. , 2019 ).","More recently, SNVs in the PCNA-binding domain of CDKN1C have been reported in families with maternally-inherited fetal growth restriction (FGR) without adrenal insufficiency and in familial Silver-Russell syndrome (SRS) (OMIM 180860 ) ( Brioude et al. , 2013 ; Kerns et al. , 2014 ).","Modify,Fact/Evidence",Fact/Evidence
10744,8-90,8-90_v2_15@0,8-90_v1_15@0,"A PubMed search was undertaken (March 2020) using the search terms “CDKN1C” with “human” and “growth”, or “IMAGe syndrome”, “IUGR”, “SGA” and “FGR”.","A PubMed search was undertaken (March 2018) using the search terms “CDKN1C”, “human” and “growth”, or “IMAGe syndrome”.","Modify,Fact/Evidence",Fact/Evidence
10745,8-90,8-90_v2_15@2,8-90_v1_15@2,"Population variation in CDKN1C was assessed using the gnomAD browser ( http://gnomad.broadinstitute.org ; accessed April 2020) ( Lek et al. , 2016 ).","Population variation in CDKN1C was assessed using the gnomAD browser ( http://gnomad.broadinstitute.org ; accessed April 2018) ( Lek et al. , 2016 ).","Modify,Fact/Evidence",Fact/Evidence
10746,8-90,8-90_v2_2@2,8-90_v1_2@2,"As three families have been reported with CDKN1C mutations who have fetal growth restriction (FGR)/Silver-Russell syndrome (SRS) without adrenal insufficiency, we investigated whether pathogenic variants in CDKN1C could be associated with isolated growth restriction or recurrent loss of pregnancy.","As two families have been reported with CDKN1C mutations who have fetal growth restriction (FGR)/Silver-Russell syndrome (SRS) without adrenal insufficiency, we investigated whether pathogenic variants in CDKN1C could be associated with isolated growth restriction or recurrent loss of pregnancy.","Modify,Fact/Evidence",Fact/Evidence
10747,8-90,8-90_v2_19@1,8-90_v1_19@1,Additional analysis was undertaken in DNA from 3) products of conception (POC) (n=22) where there had been a spontaneous loss of pregnancy and 4) women who had a history of recurrent miscarriages (n=78) (at least three miscarriages) where an underlying cause was not known (Baby Bio Bank).,Additional analysis was undertaken in DNA from 3) products of conception (POC) (n=21) where there had been a spontaneous loss of pregnancy and 4) mothers who had a history of recurrent miscarriages (n=71) (at least three miscarriages) where an underlying cause was not known (Baby Bio Bank).,"Modify,Fact/Evidence",Fact/Evidence
10748,8-91,8-91_v2_27@3,,In this case despite ultrasound and CT scan the operative approach was as for an inguinal hernia without incarcerated bowel.,,"Add,Fact/Evidence",Fact/Evidence
10749,8-91,8-91_v2_27@4,,We anticipated using mesh in this case but elected not to in the presence of an infarcted inflamed appendix.,,"Add,Fact/Evidence",Fact/Evidence
10750,8-91,8-91_v2_10@1,8-91_v1_10@1,He discussed the case with the surgical registrar at the treating regional hospital and arranged for interhospital transfer.,He discussed the case with the surgical registrar at Toowoomba hospital and arranged for interhospital transfer.,"Modify,Clarity",Clarity
10751,8-91,8-91_v2_10@2,8-91_v1_10@2,On transfer that evening to this regional facility the swelling was red and inflamed.,"On transfer that evening to Toowoomba Hospital (Toowoomba, Queensland, Australia), a regional facility with 240 beds, the swelling was red and inflamed.","Modify,Fact/Evidence",Fact/Evidence
10752,8-91,8-91_v2_12@3,8-91_v1_12@3,Meanwhile the ultrasound was unable to exclude incarcerated bowel and femoral from inguinal hernia ( Figure 1 ).,Meanwhile the ultrasound was reported as an inguinal hernia with suspicion of incarcerated small bowel.,"Modify,Fact/Evidence",Fact/Evidence
10753,8-91,8-91_v2_12@4,8-91_v1_12@4,"The discrepancy of this radiological finding with the clinical findings caused further discussion between the radiology sonographer, consultant and the surgical team; the diagnosis of the type of hernia and its contents mandated the urgency of theatre, approaches and timing.","The discrepancy of this radiological finding with the clinical findings caused further discusion between the radiology sonographer, consultant and the surgical team; the diagnosis of the type of hernia and its contents mandated the urgency of theatre, approaches and timing.","Modify,Grammar",Grammar
10754,8-91,8-91_v2_12@5,8-91_v1_12@5,"As a result, a CT was ordered to further investigate the anatomy in this case in order to plan operative approach.","As a result, a CT was ordered to further investigate the anatomy in this case.","Modify,Clarity",Clarity
10755,8-91,8-91_v2_15@0,8-91_v1_13@0,The initial findings of the CT scan were suggestive of an inflamed inguinal hernia with predominant fat contents and probable bowel involvement ( Figure 2 and Figure 3 ).,The initial findings of the CT scan were suggestive of an inflamed inguinal hernia with predominant fat contents and probable bowel involvement.,"Modify,Fact/Evidence",Fact/Evidence
10756,8-91,8-91_v2_20@5,8-91_v1_14@5,"On opening, a necrotic appendix was found to be incarcerated in the femoral hernia ( Figure 4 ).","On opening, a necrotic appendix was found to be incarcerated in the femoral hernia.","Modify,Fact/Evidence",Fact/Evidence
10757,8-91,8-91_v2_23@1,8-91_v1_15@1,The femoral hernia was repaired primarily with nylon sutures from to the conjoin tendon to the shelf of the inguinal ligament after excision of the sac.,The femoral hernia was repaired primarily with nylon to the conjoin tendon after excision of the sac.,"Modify,Fact/Evidence",Fact/Evidence
10758,8-91,8-91_v2_32@0,8-91_v1_24@0,Written consent for publication of their clinical details and clinical images was obtained from the patient.,Written consent for publication of their clinical details was obtained from the patient.,"Modify,Clarity",Clarity
10759,9-1032,9-1032_v2_56@5,,Recent studies have also shown promising odour-blends of volatile organic compounds identified from domesticated grasses such as rice and pollens of maize and sugarcane.,,"Add,Fact/Evidence",Fact/Evidence
10760,9-1032,9-1032_v2_57@5,,"Potentially a more rigorous evaluation of the plant coverage using standard methods such as a quadrant frame which might have provided more detailed information on plant numbers, could have revealed more associations.",,"Add,Claim",Claim
10761,9-1032,9-1032_v2_57@6,,"However, given the high colonisation during the rainy season such method would be better applied during drier seasons.",,"Add,Claim",Claim
10762,9-1032,9-1032_v2_20@9,9-1032_v1_20@9,Culex larvae possess a siphon on the posterior part of their abdomen for breathing whereas Anopheles larvae have no siphon and rest horizontal to the water body <REF-29> .,Culex larvae possess siphon on the posterior part of their abdomen for breathing through at the interface of the water surface during resting whereas Anopheles larvae have no siphon and rest horizontal to the water body <REF-28> .,"Modify,Fact/Evidence",Fact/Evidence
10763,9-1032,9-1032_v2_20@13,9-1032_v1_20@13,Rearing of the field collected larvae was done in 1 L plastic containers.,"Rearing of the field collected larvae was done in 1 L plastic rectangle food mate (H67 × W126 × L184 mm, Kenpoly manufacturer, Nairobi, Kenya).","Modify,Fact/Evidence",Fact/Evidence
10764,9-1032,9-1032_v2_20@20,9-1032_v1_20@20,"Extraction of DNA was done for each mosquito separately using Tissue Kit (Quagen, GmbH Hilden, Germany).","Extraction of genomic DNA was done for each mosquito separately using Tissue Kit (Quagen, GmbH Hilden, Germany).","Modify,Clarity",Clarity
10765,9-1032,9-1032_v2_20@21,9-1032_v1_20@21,"The PCR was prepared by mixing PCR mix of 2 µl of 5XHot Firepol Blended Master Mix (Ready to Load), primers (0.5 µM each), DNA template (2 µl) and nuclease-free water (5 µl).","The PCR in a 10 µl (per sample) was prepared by mixing PCR mix of 2 µl of 5XHot Firepol Blended Master Mix (Ready to Load), primers (0.5 µM each), DNA template (2 µl) and nuclease-free water (5 µl).","Modify,Fact/Evidence",Fact/Evidence
10766,9-1032,9-1032_v2_20@23,9-1032_v1_20@23,"We used a Kyratec Thermal Cycler (SC300T-R2, Australia) for the thermal reactions.","We used Kyratec Thermal Cycler (SC300T-R2, Australia) for the thermal reactions.","Modify,Grammar",Grammar
10767,9-1032,9-1032_v2_21@2,9-1032_v1_21@2,"Vegetation coverage was estimated visually, always by the same field worker, as the proportion of the habitats covered with vegetations and categorized as (1) 1–25% (2) 25–50% (3) 50–75% (4) 75–100%.",Vegetation coverage was estimated visually as the proportion of the habitats covered with vegetations and categorized as (1) 1–25% (2) 25–50% (3) 50–75% (4) 75–100%.,"Modify,Fact/Evidence",Fact/Evidence
10768,9-1032,9-1032_v2_21@4,9-1032_v1_21@4,"The graminoid plants were identified to family using the morphology of their leaves (two or three-ranked; open or closed sheaths), and their stem type (three-sided or round; hollow or solid) using Revuelta <REF-33> .","The graminoid plants were identified to family using morphology of their leaves (two or three-ranked; open or closed sheaths), and their stem type (three-sided or round; hollow or solid) using Revuelta <REF-32> .","Modify,Grammar",Grammar
10769,9-1032,9-1032_v2_34@0,9-1032_v1_34@0,All the swamp habitats were bordered by graminoid plants along the water edges and had a high surface coverage.,All the swamp habitats were boarded by graminoid plants along the water edges and had a high surface coverage.,"Modify,Grammar",Grammar
10770,9-1032,9-1032_v2_4@8,9-1032_v1_4@8,"The presence of early instar larvae was significantly and positively associated with swamp habitat types (OR=22, 95% CI=6-86, P<0.001) and abundance of late Anopheles larvae (OR=359, CI=33-3941, P<0.001), and negatively associated with the presence of tadpoles (OR=0.1, CI=0.0.01-0.5, P=0.008).","The presence of early instar larvae was significantly and positively associated with swamp habitat types (OR=22, 95% CI=6-86, P<0.001) and abundance of late Anopheles larvae (OR=359, CI=33-3941, P<0.001), whilst the association was negative with tadpole presence (OR=0.1, CI=0.0.01-0.5, P=0.008).","Modify,Clarity",Clarity
10771,9-1032,9-1032_v2_42@3,9-1032_v1_42@3,All six species of Anopheles mosquitoes were recorded in swamp habitats.,These six species of Anopheles mosquitoes were recorded in swamp habitats.,"Modify,Clarity",Clarity
10772,9-1032,9-1032_v2_42@5,9-1032_v1_42@5,"However, only three species of Anopheles mosquitoes ( An. arabiensis , An. ziemanni, and An. pharoensis ) were collected in habitats sparsely (1–25%) covered by graminoid plants.","However, only three species of Anopheles mosquitoes ( An. arabiensis , An. ziemanni, and An. pharoensis ) were collected in habitats sparsely (1–25%) covered by graminoids.","Modify,Clarity",Clarity
10773,9-1032,9-1032_v2_59@0,9-1032_v1_59@0,The presence and abundance of early instar Anopheles larvae were negatively associated with the presence of tadpoles.,The presence and abundance of early instar Anopheles larvae was negatively associated with the presence of tadpoles.,"Modify,Grammar",Grammar
10774,9-1032,9-1032_v2_62@3,9-1032_v1_62@3,"The habitats covered by these vegetations were abundantly colonized by early instar Anopheles larvae even though no specific preference for any of these could be detected, likely due to study limitations.","The habitats covered by this vegetation were abundantly colonized by early instar Anopheles larvae even though no specific preference for any of these could be detected, likely due to study limitations.","Modify,Grammar",Grammar
10775,9-1032,9-1032_v2_19@1,9-1032_v1_19@1,"The perimeter of every habitat was estimated, always by the same field worker for uniformity, by walking in large steps around the habitat.",The perimeter of every habitat was estimated by walking in large steps around the habitat.,"Modify,Fact/Evidence",Fact/Evidence
10802,9-113,9-113_v2_67@1,,"- - LiteratureCompilation: MAE=0.532, RMSE=0.785, r 2 =0.889)",,"Add,Fact/Evidence",Fact/Evidence
10803,9-113,9-113_v2_71@2,,"Since some molecules had to be omitted for prediction with OPERA due to none or multiple predicted pK a values, no consistent significance test could be performed for all comparisons.",,"Add,Claim",Claim
10804,9-113,9-113_v2_73@0,,The developed model offers the possibility to predict pK a values for monoprotic molecules with good accuracy.,,"Add,Claim",Claim
10805,9-113,9-113_v2_73@1,,"However, since the model has been trained exclusively with monoprotic molecules, only monoprotic molecules can be predicted properly.",,"Add,Claim",Claim
10806,9-113,9-113_v2_73@2,,In this respect the model is limited.,,"Add,Claim",Claim
10807,9-113,9-113_v2_73@3,,"Nevertheless, the results show that the performance for monoprotic molecules can compete with the performance of existing prediction tools.",,"Add,Claim",Claim
10808,9-113,9-113_v2_14@3,,"The Novartis data set consists of 280 unique molecules with a molecular weight between 129 and 670 daltons (mean value 348.68, standard deviation 94.17).",,"Add,Fact/Evidence",Fact/Evidence
10809,9-113,9-113_v2_14@4,,"The calculated LogP values vary between -1.54 and 6.30 (mean value 3.01, standard deviation 1.41).",,"Add,Fact/Evidence",Fact/Evidence
10810,9-113,9-113_v2_14@5,,The 280 molecules spread over 228 unique Murcko Scaffolds.,,"Add,Fact/Evidence",Fact/Evidence
10811,9-113,9-113_v2_14@6,,The ten most common murcko scaffolds cover 15% of the molecules of the total data set (42/280).,,"Add,Fact/Evidence",Fact/Evidence
10812,9-113,9-113_v2_14@7,,A histogram of the pairwise comparison between the training set and the two external test sets (Fingerprint: 4096 bit MorganFeatures radius=3) is given in Figure 2(A) and Figure 2(B),,"Add,Fact/Evidence",Fact/Evidence
10813,9-113,9-113_v2_22@3,,"To ensure that no training data was contained in the test data sets, the conical isomeric SMILES were checked for matches in both training and test data sets and corresponding hits were removed from the test data sets.",,"Add,Fact/Evidence",Fact/Evidence
10814,9-113,9-113_v2_56@0,,The compounds for which the pK a values between the different sources deviate by more than two units are as follows:,,"Add,Fact/Evidence",Fact/Evidence
10815,9-113,9-113_v2_60@0,,"Since the annotation about the experimental settings is not given in the DataWarrior file, we can only hypothesize that these differences are due to the different experimental settings.",,"Add,Claim",Claim
10816,9-113,9-113_v2_61@0,,Machine Learning,,"Add,Other",Other
10817,9-113,9-113_v2_20@7,9-113_v1_25@7,In the second configuration the parameter “gamma” was additionally set to the value “auto”.,"In the second configuration the parameter ""gamma"" was additionally set to the value ""auto"".","Modify,Grammar",Grammar
10818,9-113,9-113_v2_20@9,9-113_v1_25@9,"In the second configuration, early stopping was additionally activated, where 10% of the training data was separated as validation data.","In the second configuration, early stopping was additionally activated, where 10% of the training data is separated as validation data.","Modify,Grammar",Grammar
10819,9-113,9-113_v2_20@10,9-113_v1_25@10,"If the error of the validation data did not improve by more than 0.001 over ten training epochs, the training is stopped early to avoid overtraining.","If the error of the validation data does not improve by more than 0.001 over ten training epochs, the training is stopped early to avoid overtraining.","Modify,Grammar",Grammar
10820,9-113,9-113_v2_20@14,9-113_v1_25@14,This resulted in a total of seven different machine learning configurations.,This results in a total of seven different machine learning configurations.,"Modify,Grammar",Grammar
10821,9-113,9-113_v2_26@0,9-113_v1_31@0,First of all a working Miniconda/Anaconda installation is needed.,First of all you need a working Miniconda/Anaconda installation.,"Modify,Clarity",Clarity
10822,9-113,9-113_v2_26@1,9-113_v1_31@1,Miniconda can be downloaded at https://conda.io/en/latest/miniconda.html .,You can get Miniconda at https://conda.io/en/latest/miniconda.html .,"Modify,Clarity",Clarity
10823,9-113,9-113_v2_27@0,9-113_v1_32@0,"Now an environment named ""ml_pka"" with all needed dependencies can be created and activated with:","Now you can create an environment named ""ml_pka"" with all needed dependencies and activate it with:","Modify,Clarity",Clarity
10824,9-113,9-113_v2_29@0,9-113_v1_34@0,"Alternatively, a new environment can be created manually without the environment.yml file:",You can also create a new environment by yourself and install all dependencies without the environment.yml file:,"Modify,Claim",Claim
10825,9-113,9-113_v2_36@1,9-113_v1_41@1,To use the data preparation pipeline the repository folder hast to be entered and the created conda environment must be activated.,To use the data preparation pipeline you have to be in the repository folder and your conda environment have to be activated.,"Modify,Clarity",Clarity
10826,9-113,9-113_v2_36@2,9-113_v1_41@2,Additionally the Marvin <REF-10> commandline tool cxcalc and the QUACPAC <REF-26> commandline tool tautomers have to be added to the PATH variable.,Additionally the Marvin <REF-10> commandline tool cxcalc and the QUACPAC <REF-28> commandline tool tautomers have to be set in your PATH variable.,"Modify,Clarity",Clarity
10827,9-113,9-113_v2_37@0,9-113_v1_42@0,"Also the environment variables OE_LICENSE (containing the path to the OpenEye license file) and JAVA_HOME (referring to the Java installation folder, which is needed for cxcalc ) have to be set.","Also the environment variables OE_LICENSE (containing the path to your OpenEye license file) and JAVA_HOME (referring to the Java installation folder, which is needed for cxcalc ) have to be set.","Modify,Clarity",Clarity
10828,9-113,9-113_v2_38@0,9-113_v1_43@0,After preparation a small usage information can be displayed with bash run_pipeline.sh -h .,After preparation you can display a small usage information with bash run_pipeline.sh -h .,"Modify,Clarity",Clarity
10829,9-113,9-113_v2_40@1,9-113_v1_45@1,First of all the repository folder has to be entered and the created conda environment must be activated.,First of all you have to be in the repository folder and your conda environment have to be activated.,"Modify,Clarity",Clarity
10830,9-113,9-113_v2_40@2,9-113_v1_45@2,To use the prediction tool the machine learning model has to be retrained.,To use the prediction tool you have to retrain the machine learning model.,"Modify,Clarity",Clarity
10831,9-113,9-113_v2_40@3,9-113_v1_45@3,"To do so the training script should be called, it will train the 5-fold cross-validated Random Forest machine learning model using 12 cpu cores.","Therefore just call the training script, it will train the 5-fold cross-validated Random Forest machine learning model using 12 cpu cores.","Modify,Clarity",Clarity
10832,9-113,9-113_v2_40@4,9-113_v1_45@4,If the number of cores has to be adjusted the train_model.py can be edited by changing the value of the variable EST_JOBS .,If you want to adjust the number of cores you can edit the train_model.py by changing the value of the variable EST_JOBS .,"Modify,Clarity",Clarity
10833,9-113,9-113_v2_42@0,9-113_v1_47@0,To use the prediction tool with the trained model QUACPAC/Tautomers have to be available as mentioned in the section above.,To use the prediction tool with the trained model QUACPAC/Tautomers have to be available as it was mentioned in the section above.,"Modify,Clarity",Clarity
10834,9-113,9-113_v2_43@0,9-113_v1_48@0,Now the python script can be called with an SDF file and an output path:,Now you can call the python script with an SDF file and an output path:,"Modify,Clarity",Clarity
10835,9-113,9-113_v2_62@1,9-113_v1_52@1,"In terms of the mean absolute error, a random forest with scaled MorganFeatures (radius=3) and descriptors gave the best performing model (MAE=0.682, RMSE=1.032, r 2 =0.82).","In terms of the mean absolute error, a random forest with scaled MorganFeatures (radius=3) and descriptors gives the best performing model (MAE=0.682, RMSE=1.032, r 2 =0.82).","Modify,Grammar",Grammar
10836,9-113,9-113_v2_71@0,9-113_v1_52@4,"This showed that our model had a slightly better performance than Marvin for the LiteratureCompilation, but Marvin performed better for the Novartis dataset.","This shows that our model slightly outcompetes Marvin for the LiteratureCompilation, but Marvin performs better for the Novartis dataset.","Modify,Clarity",Clarity
10837,9-113,9-113_v2_71@1,9-113_v1_52@5,"For both data sets, our models <REF-17> had a better predictive performance than the OPERA tool.","For both data sets, our models <REF-17> have a better predictive performance than the OPERA tool.","Modify,Grammar",Grammar
10838,9-113,9-113_v2_4@6,9-113_v1_4@6,"In particular, the publication by Williams et al . <REF-15> makes use of a publicly available data set provided by the application DataWarrior <REF-16> and provides a freely available pK a prediction tool called OPERA.","In particular, the publication by Williams et al . <REF-15> make use of a publicly available data set provided by the application DataWarrior <REF-16> and provides a freely available pK a prediction tool called OPERA.","Modify,Grammar",Grammar
10839,9-113,9-113_v2_48@0,9-113_v1_8@0,"One crucial point in the field of pK a measurements (and its usage for pK a predictions) was linked to the different experimental methods <REF-25> , <REF-30> .","One crucial point in the field of pK a measurements (and its usage for pK a predictions) is linked to the different experimental methods <REF-25> , <REF-26> .","Modify,Grammar",Grammar
10840,9-113,9-113_v2_48@1,9-113_v1_8@1,"Based on the Novartis set, the correlation between capillary electrophoresis and potentiometric measurements (for 15 data points) was convincing enough (mean absolute error (MAE)=0.202, root mean squared error (RMSE)=0.264, correlation coefficient r 2 =0.981) for us to combine pK a measurements from these different experimental methods (see Figure 3 ).","Based on the Novartis set, the correlation between capillary electrophoresis and potentiometric measurements (for 15 data points) is convincing enough (mean absolute error (MAE)=0.202, root mean squared error (RMSE)=0.264, correlation coefficient r 2 =0.981) for us to combine pK a measurements from these different experimental methods (see Figure 1 ).","Modify,Grammar",Grammar
10841,9-113,9-113_v2_52@0,9-113_v1_11@0,We also compared the pK a values of 187 monoprotic molecules contained in both the ChEMBL and DataWarrior data sets.,"We also compare the overlap of the filtered (see next section) ChEMBL and DataWarrior data sets, 187 monoprotic molecules could be identified in both sources.","Modify,Fact/Evidence",Fact/Evidence
10842,9-113,9-113_v2_52@1,9-113_v1_11@1,"Due to the missing annotation, it remained unclear if different experimental methods were used or multiple measurements with the same experimental method have been performed (or a mixture of both).","Due to the missing annotation, it remains unclear if different experimental methods were used or multiple measurements with the same experimental method have been performed (or a mixture of both).","Modify,Grammar",Grammar
10843,9-113,9-113_v2_52@2,9-113_v1_11@2,"Either way, this comparison was an additional proof-of-concept that the ChEMBL and DataWarrior pK a data sources can be combined after careful curation.","Either way, this comparison is an additional proof-of-concept that the ChEMBL and DataWarrior pK a data sources can be combined after careful curation.","Modify,Grammar",Grammar
10844,9-113,9-113_v2_52@4,9-113_v1_11@4,"The correlation coefficient between the annotated pK a values for these two data sets r 2 was 0.949, the MAE was 0.275, and the RMSE was 0.576.","The correlation coefficient between the annotated pK a values for these two data sets r 2 is 0.949, the MAE is 0.275, and the RMSE is 0.576.","Modify,Grammar",Grammar
10845,9-113,9-113_v2_73@4,9-113_v1_58@0,The good performance of Marvin on the Novartis set is interesting to note: the RMSE was almost 0.4 units better than our top performing model.,The good performance of Marvin on the Novartis set is interesting to note: the RMSE is almost 0.4 units better than our top performing model.,"Modify,Grammar",Grammar
10846,9-113,9-113_v2_73@7,9-113_v1_58@3,"In contrast, Marvin performed slightly worse than our top model on the LiteratureCompilation.","In contrast, Marvin performs slightly worse than our top model on the LiteratureCompilation.","Modify,Grammar",Grammar
10847,9-113,9-113_v2_73@8,9-113_v1_58@4,The OPERA tool performed significantly worse than our model on both external test sets.,The OPERA tool performs significantly worse than our model on both external test sets.,"Modify,Grammar",Grammar
10848,9-113,9-113_v2_73@9,9-113_v1_58@5,We assume that the addition of 2470 ChEMBL pK a – datapoints to our training set which were not part of the OPERA training set led to this drop in predictive performance.,We assume that the addition of 2470 ChEMBL pKa-datapoints to our training set which are not part of the OPERA training set leads to this drop in predictive performance.,"Modify,Grammar",Grammar
10849,9-113,9-113_v2_73@10,9-113_v1_58@6,"In addition, the pre-processing of the data was performed differently by OPERA in comparison to our pre-processing procedure.","In addition, the pre-processing of the data is performed differently by OPERA in comparison to our pre-processing procedure.","Modify,Grammar",Grammar
10850,9-113,9-113_v2_8@1,9-113_v1_15@1,"The following restrictions were made: it must be a physicochemical assay, the measurements must be taken from scientific literature, the assay must be in “small-molecule physicochemical format” and the organism taxonomy must be set to “N/A”.","The following restrictions were made: it must be a physicochemical assay, the measurements must be taken from scientific literature, the assay must be in ""small-molecule physicochemical format"" and the organism taxonomy must be set to ""N/A"".","Modify,Grammar",Grammar
10851,9-113,9-113_v2_8@4,9-113_v1_15@4,"Only pK a measurements, i.e. ChEMBL activities, were taken into account that were specified as exact (“standard_relation” equals “=”) and for which one of the following names was specified as “standard_type”: “pka”, “pka value”, “pka1”, “pka2”, “pka3” or “pka4” (case-insensitive).","Only pKa measurements, i.e. ChEMBL activities, were taken into account that were specified as exact (""standard_relation"" equals ""="") and for which one of the following names was specified as ""standard_type"": ""pka"", ""pka value"", ""pka1"", ""pka2"", ""pka3"" or ""pka4"" (case-insensitive).","Modify,Grammar",Grammar
10852,9-113,9-113_v2_11@2,9-113_v1_18@2,- Filtering by Lipinski‘s rule of five (one violation allowed),- Filter by Lipinski‘s rule of five (one violation allowed),"Modify,Grammar",Grammar
10853,9-113,9-113_v2_13@2,9-113_v1_20@2,All molecules were then combined on the basis of the canonical isomeric SMILES.,All molecules were then combined on the basis of the isomeric SMILES.,"Modify,Clarity",Clarity
10854,9-113,9-113_v2_20@0,9-113_v1_25@0,"First, to simplify cross-validation, a class “CVRegressor” was defined, which can serve as a wrapper for any regressor implementing the Scikit-Learn <REF-27> interface.","First, to simplify cross-validation, a class ""CVRegressor"" was defined, which can serve as a wrapper for any regressor implementing the Scikit-Learn <REF-29> interface.","Modify,Fact/Evidence",Fact/Evidence
10855,9-113,9-113_v2_20@2,9-113_v1_25@2,"Next, 196 of the 200 available RDKit descriptors (“MaxPartialCharge”, “MinPartialCharge”, “MaxAbsPartialCharge” and “MinAbsPartialCharge” were not used because they are computed as “NaN” for many molecules), and a 4096-bit long MorganFeature fingerprint with radius 3 were calculated for the training data set.","Next, 196 of the 200 available RDKit descriptors (""MaxPartialCharge"", ""MinPartialCharge"", ""MaxAbsPartialCharge"" and ""MinAbsPartialCharge"" were not used because they are computed as ""NaN"" for many molecules), and a 4096-bit long MorganFeature fingerprint with radius 3 were calculated for the training data set.","Modify,Grammar",Grammar
10856,9-1143,,9-1143_v1_2@7,,"Therefore, we report a case of spontaneous rupture of bicornuate uterus with concomitant sarcoma occurred in a 47-year-old woman.","Delete,Fact/Evidence",Fact/Evidence
10857,9-1143,,9-1143_v1_27@0,,Spontaneous uterine rupture presents most commonly with labor and delivery <REF-1> .,"Delete,Fact/Evidence",Fact/Evidence
10858,9-1143,,9-1143_v1_27@2,,"However, spontaneous rupture of a uterus without a surgical scar is very uncommon and significantly less well known <REF-2> .","Delete,Fact/Evidence",Fact/Evidence
10859,9-1143,,9-1143_v1_30@5,,There are very few cases described in the literature of uterine sarcoma resulting in a life-threatening clinical scenario such as uterine rupture or hypovolemic shock <REF-6> .,"Delete,Fact/Evidence",Fact/Evidence
10860,9-1143,9-1143_v2_3@2,,"She was treated with 6 cycles of chemotherapy(etoposide, ifosfamide, cisplatin) postoperatively.",,"Add,Fact/Evidence",Fact/Evidence
10861,9-1143,9-1143_v2_3@3,,Chest and abdomen CT for follow up after chemotherapy showed no sign of cancer recurrence.,,"Add,Fact/Evidence",Fact/Evidence
10862,9-1143,9-1143_v2_3@4,,We suggest a bicornuate uterus with concomitant sarcoma should be concerned as a possible cause of uterine rupture by reviewing this case.,,"Add,Claim",Claim
10863,9-1143,9-1143_v2_8@2,,"Through this case, we suggest that a bicornuate uterus with concomitant sarcoma should be concerned as a possible cause of uterine rupture when a woman presents with hemoperitoneum in the setting of a pelvic mass and uterine anomaly with intact ovaries detected on imaging.",,"Add,Claim",Claim
10864,9-1143,,9-1143_v1_7@1,,"Preoperative pelvic ultrasonography, computed tomography (CT), magnetic resonance imaging (MRI), and positron emission tomography (PET)/CT were performed for diagnosis.","Delete,Fact/Evidence",Fact/Evidence
10865,9-1143,9-1143_v2_28@0,,The uterus is pear shaped and consists of two major but unequal parts.,,"Add,Claim",Claim
10866,9-1143,9-1143_v2_28@1,,"The upper, larger portion is the body or corpus, whereas the lower smaller cervix projects into vagina.",,"Add,Claim",Claim
10867,9-1143,9-1143_v2_28@2,,The bulk of the uterine body is muscle.,,"Add,Claim",Claim
10868,9-1143,9-1143_v2_28@3,,"Almost the entire posterior wall of the uterus is covered by serosa, that is, visceral peritoneum.",,"Add,Claim",Claim
10869,9-1143,9-1143_v2_28@4,,Uterine rupture can present with both complete rupture involves the full thickness of the uterine wall and incomplete rupture occurs with the visceral peritoneum remains intact.,,"Add,Claim",Claim
10870,9-1143,9-1143_v2_28@5,,Both types of uterine rupture are rare but serious events.,,"Add,Claim",Claim
10871,9-1143,9-1143_v2_28@6,,Several risk factors have been identified.,,"Add,Claim",Claim
10872,9-1143,9-1143_v2_33@0,,"Ultrasonography is useful when performed properly, but it has a limitation for revealing a large mass.",,"Add,Claim",Claim
10873,9-1143,9-1143_v2_33@1,,CT imaging is superior to ultrasonography especially for evaluation of a large mass.,,"Add,Claim",Claim
10874,9-1143,9-1143_v2_26@0,9-1143_v1_25@0,"Postoperatively, the patient was treated with a combination of etoposide (150 mg/m 2 for 3 days), ifosfamide (1.5 g/m 2 for 3 days), and cisplatin (70mg/m 2 for 1 day) once every 3 weeks.","Postoperatively, the patient was treated with a combination of etoposide (150 mg/m 2 for 3 days), ifospamide (1.5 g/m 2 for 3 days), and cisplatin (70mg/m 2 for 1 day) once every 3 weeks.","Modify,Grammar",Grammar
10875,9-1143,9-1143_v2_28@7,9-1143_v1_27@1,"The most common risk factor is previous transmyometrial surgical incision, typically the result of a cesarean section <REF-1> , <REF-2> .","The most common cause of uterine rupture is dehiscence of a previous transmyometrial surgical incision, typically the result of a cesarean section <REF-2> .","Modify,Fact/Evidence",Fact/Evidence
10876,9-1143,9-1143_v2_30@1,9-1143_v1_29@1,Potential etiologies for spontaneous rupture of leiomyomas are degeneration or sarcomatous changes of uterine leiomyomas.,"Potential etiologies for spontaneous rupture of leiomyomas are rupture of the superficial overlying vessels, degeneration or sarcomatous changes of uterine leiomyomas.","Modify,Claim",Claim
10877,9-1143,9-1143_v2_30@5,9-1143_v1_29@2,"Because uterine sarcoma is a rare neoplasm; therefore, uterine rupture as a result of sarcoma is even more unusual.","Uterine sarcoma is a rare neoplasm; therefore, uterine rupture as a result of sarcoma is even more unusual.","Modify,Clarity",Clarity
10878,9-1143,9-1143_v2_30@3,9-1143_v1_30@1,"Hemoperitoneum is the result of spontaneous rupture of the superficial vessels overlying leiomyomas <REF-14> or the result of avulsion of a pedunculated myoma by trauma <REF-15> , <REF-16> .","Hemoperitoneum is the result of spontaneous rupture of the superficial veins overlying leiomyomas <REF-15> or the result of avulsion of a pedunculated myoma by trauma <REF-16> , <REF-17> .","Modify,Clarity",Clarity
10879,9-1143,9-1143_v2_30@7,9-1143_v1_30@4,"Because a patient’s condition can deteriorate rapidly after uterine rupture, most patients will need immediate blood and fluid replacement therapy and an exploratory laparotomy to be done without a clear preoperative diagnosis before surgery.","Because a patient's condition can deteriorate rapidly after uterine rupture, most patients will need immediate blood and fluid replacement therapy and an exploratory laparotomy to be done without a clear preoperative diagnosis before surgery <REF-14> .","Modify,Fact/Evidence",Fact/Evidence
10880,9-1143,9-1143_v2_33@2,9-1143_v1_33@0,"Also CT imaging has good diagnostic value, because extravasation of contrast enhancement can be used to evaluate for active bleeding.","CT imaging has good diagnostic value, because extravasation of contrast enhancement can be used to evaluate for active bleeding.","Modify,Clarity",Clarity
10881,9-1143,9-1143_v2_35@3,9-1143_v1_35@3,"Therefore, we decided to perform PET/CT scan additionally to distinguish between leiomyoma and sarcoma to determine the scope of preoperative surgery.","CT imaging revealed that she had a bicornuate uterus, therefore, we decided to perform an pelvic MRI and PET/CT scan.","Modify,Fact/Evidence",Fact/Evidence
10882,9-1143,9-1143_v2_6@2,9-1143_v1_5@1,"Because when a zygote is implanted in a horn of a bicornuate uterus, it is unable to expand as a normal uterus does to accommodate a growing fetus <REF-4> .","When a zygote is implanted in a horn of a bicornuate uterus, it is unable to expand as a normal uterus does to accommodate a growing fetus <REF-4> .","Modify,Clarity",Clarity
10883,9-1143,9-1143_v2_6@3,9-1143_v1_5@2,"The walls of the anomalous uterus tend to become abnormally thin as pregnancies advance, and the uterine rupture can happen <REF-5> .",The walls of the anomalous uterus tend to become abnormally thin as pregnancies advance.,"Modify,Fact/Evidence",Fact/Evidence
10884,9-1143,9-1143_v2_6@1,9-1143_v1_5@3,Implantation of the zygote in a rudimentary horn of bicornuate uterus is considered an independent risk factor for uterine rupture.,Implantation of the zygote in a rudimentary horn is considered an independent risk factor for uterine rupture <REF-5> .,"Modify,Fact/Evidence",Fact/Evidence
10885,9-1143,9-1143_v2_8@0,9-1143_v1_7@0,"Herein, we report a case from diagnosis to surgical treatment of a 47-year-old woman with bicornuate uterus who had no previous history of spontaneous uterine rupture or uterine surgery.","Herein, we report a case from diagnosis to surgical treatment of a 47-year-old woman with bicornuate uterus who had no previous history of spontaneous uterine rupture or uterine sarcoma.","Modify,Fact/Evidence",Fact/Evidence
10886,9-1143,9-1143_v2_2@1,9-1143_v1_2@1,"Emergency pelvic ultrasound and abdominal CT were taken, which showed a significant amount of hemoperitoneum and a bicornuate uterus with about 18cm x 10cm mass on left uterus.","Emergency pelvic ultrasonography and abdominal CT were taken, which showed a significant amount of hemoperitoneum and a bicornuate uterus with about 18cm x 10cm mass on the left uterus.","Modify,Clarity",Clarity
10887,9-1143,9-1143_v2_8@1,9-1143_v1_7@2,"We hypothesize that as the uterine sarcoma advance, uterine rupture can occur as a result of congenitally malformed, bicornuate uterus.","We hypothesize that as her uterine sarcoma advanced, our patient experienced uterine rupture as a result of her congenitally malformed, bicornuate uterus.","Modify,Clarity",Clarity
10888,9-1143,9-1143_v2_13@0,9-1143_v1_12@0,Transrectal ultrasonography showed a bicornuate uterus and an 18.6- × 9.1-cm mass with heterogeneous echogenicity within the left uterus.,Transrectal ultrasonography showed a bicornuate uterus and an 18.6- × 9.1-cm mass with heterogenous echogenicity within the left uterus.,"Modify,Grammar",Grammar
10889,9-1143,9-1143_v2_2@3,9-1143_v1_2@3,MRI and PET/CT were taken additionally for oncologic evaluation before surgery.,Pelvic MRI and PET/CT were taken additionally for oncologic evaluation before surgery.,"Modify,Clarity",Clarity
10890,9-1155,9-1155_v2_74@1,,"Figure 9 shows the diagram of published literature on RTI Gulf focusing on the relationship among three factors including top keywords, journals and country.",,"Add,Fact/Evidence",Fact/Evidence
10891,9-1155,,9-1155_v1_19@0,,- TS=(road safety* OR road injury* OR traffic accident* OR vehicle accident* OR road trauma* OR road casualty* OR traffic casualty* OR traffic safety* OR traffic camera* OR seat belt* OR seatbelt* OR traffic fine* OR car accident* OR bike accident* OR motorbike accident* OR motorcycle accident* OR motorcycle crash* OR airbag* OR air bag* OR road fatality* OR child restraint OR road death* OR traffic enforcement OR pedestrian safety OR road crash*) AND AD=(Saudi Arabia OR Bahrain OR Oman OR Kuwait OR Qatar OR UAE OR United Arab Emi- rates OR Abu Dhabi OR Ajman OR Dubai OR Fujairah OR Ras al-Khaimah OR Sharjah OR Umm al-Quwain).,"Delete,Other",Other
10892,9-1155,9-1155_v2_101@0,,Non-motorized transport users such as pedestrians and cyclists are the most neglected group in the road traffic research in GCC nation despite of having higher fatality rates.,,"Add,Claim",Claim
10893,9-1155,9-1155_v2_101@1,,The researchers should focus on the safety impacts of the pedestrians and other non-motorized road users who are the most volatile and susceptible to road accidents.,,"Add,Claim",Claim
10894,9-1155,9-1155_v2_101@2,,The researches related to road user behavior and on the usage of cell phones and seatbelts are also not on the satisfactory level in GCC.,,"Add,Claim",Claim
10895,9-1155,9-1155_v2_101@3,,It is of utmost importance that the data sharing and collaboration between the institutes should be improved so that the quality and impact of the future RTI researches can be improved because of experienced team-work and professional feedbacks.,,"Add,Claim",Claim
10896,9-1155,9-1155_v2_101@4,,"This will also help to improve the current trend of researchers and institutions who are currently working in silos rather than in collaboration with the traffic practitioners, planners and professionals.",,"Add,Claim",Claim
10897,9-1155,,9-1155_v1_83@0,,"As noted previously, bibliographic coupling is a measure of subject matter commonality among different publications and occurs when two publications reference a common third publication.","Delete,Claim",Claim
10898,9-1155,,9-1155_v1_97@5,,"The UAE University had the highest RTI research productivity with 40 publications, but the Hamad Medical Corporation and Al Ain Hospital had the highest citation impact (16.33 and 14.58, respectively).","Delete,Fact/Evidence",Fact/Evidence
10899,9-1155,9-1155_v2_22@0,,Limitations of Study,,"Add,Other",Other
10900,9-1155,9-1155_v2_18@9,9-1155_v1_18@9,The authors tried to include all search terms for retrieval of entire spectrum of the literature related to study objectives (see Figure 2 ).,The authors tried to include all search terms for retrieval of entire spectrum of the literature related to study objectives.,"Modify,Fact/Evidence",Fact/Evidence
10901,9-1155,9-1155_v2_21@2,9-1155_v1_20@2,"We refined this initial query by excluding editorial materials (4), notes (2), meeting abstracts (5), letters (2), or corrections (1) as they are not peer reviewed.","We refined this initial query by excluding editorial materials, notes, meeting abstracts, letters, or corrections as they are not peer reviewed.","Modify,Fact/Evidence",Fact/Evidence
10902,9-1155,9-1155_v2_21@7,9-1155_v1_20@7,This practice helped the authors to discard 245 irrelevant records.,This practice helped the authors to discard 259 irrelevant or duplicate records.,"Modify,Fact/Evidence",Fact/Evidence
10903,9-1155,9-1155_v2_21@11,9-1155_v1_20@11,The author keyword analysis and bibliographic coupling was done with the help of VOSViewer.,"The author keyword analysis, bibliographic coupling, and three factor analysis was done with the help of VOSViewer.","Modify,Fact/Evidence",Fact/Evidence
10904,9-1155,9-1155_v2_21@12,9-1155_v1_20@12,"Global collaboration, topical trends and three factor analysis were generated by using Biblioshiny.",Global collaboration and topical trends were generated by using Biblioshiny.,"Modify,Fact/Evidence",Fact/Evidence
10905,9-1155,9-1155_v2_95@0,9-1155_v1_92@0,Future research directions,Limitations and future research directions,"Modify,Other",Other
10906,9-1155,9-1155_v2_99@4,9-1155_v1_97@4,The GCC nations with the highest and lowest publication volumes included Saudi Arabia and Bahrain respectively.,"The GCC nations with the highest and lowest publication volumes included Saudi Arabia and Bahrain, with 126 and 7 publications, respectively.","Modify,Fact/Evidence",Fact/Evidence
10907,9-1155,9-1155_v2_99@6,9-1155_v1_97@7,Only three individual authors had 10 or more RTI research publications.,"Only three individual authors had 10 or more RTI research publications including F.M. Abu-Zidan (17 publications), K. Shaaban (15 publications), and H.O. Eid (10 publications).","Modify,Fact/Evidence",Fact/Evidence
10908,9-1155,9-1155_v2_100@0,9-1155_v1_98@0,"Among the most prevalent publication journals for RTI research in the GCC region, Accident Analysis and Prevention had the highest number of publications, number of citations, and citation impact.","Among the most prevalent publication journals for RTI research in the GCC region, Accident Analysis and Prevention had the highest number of publications (25), number of citations (533), and citation impact (21.32).","Modify,Fact/Evidence",Fact/Evidence
10909,9-1155,9-1155_v2_100@3,9-1155_v1_98@3,The most commonly listed keywords in RTI research publications were road traffic accidents and road traffic injuries.,The most commonly listed keywords in RTI research publications were road traffic accidents (41 occurrences) and road traffic injuries (40 occurrences).,"Modify,Fact/Evidence",Fact/Evidence
10910,9-1155,9-1155_v2_100@4,9-1155_v1_98@4,"Terms such as mobile phones, pedestrian safety, pedestrians, and distracted driving were least common.","Terms such as mobile phones (5 occurrences), pedestrian safety (5 occurrences), pedestrians (5 occurrences), and distracted driving (4 occurrences) were least common.","Modify,Fact/Evidence",Fact/Evidence
10956,9-1204,,9-1204_v1_3@1,,"Thus, early detection and management of odontomas can help correction of any dental irregularity and avoid further complications.","Delete,Claim",Claim
10957,9-1204,,9-1204_v1_35@0,,"The anterior maxilla is the most common site for the development of a compound odontoma, causing various disturbances in eruption and teeth position.","Delete,Claim",Claim
10958,9-1204,,9-1204_v1_35@1,,Having distinctive clinical and radiographic features; an experienced clinician can accurately diagnose a compound odontoma.,"Delete,Claim",Claim
10959,9-1204,,9-1204_v1_35@2,,"Thus, early detection and management of odontomas can help the correction of any dental irregularity and avoid further complications.","Delete,Claim",Claim
10960,9-1204,9-1204_v2_3@0,,"The dentist should be aware of the probability of a close relationship between the development of odontoma and presence of the gubernacular tract, which could be used as a future radiographic diagnostic criterion of an odontoma.",,"Add,Claim",Claim
10961,9-1204,9-1204_v2_3@1,,"Also, we recommend that more studies be performed in this field to deeply analyze the imaging characteristics of GT and its spatial association with various pathological lesions in the future.",,"Add,Claim",Claim
10962,9-1204,9-1204_v2_34@4,,"Also, Oda M. et al. <REF-26> reported that the presence of GT helped in differentiating complex odontomas from bone dysplasia and cemento-ossifying fibromas.",,"Add,Fact/Evidence",Fact/Evidence
10963,9-1204,9-1204_v2_36@0,,"Furthermore, oda et al. <REF-29> found that the continuity of the pathological lesion with the GT could be a characteristic differentiating imaging feature between some types of odontogenic and non-odontogenic tumors as this continuity was detected in CT of almost all of the odontogenic lesions (93.7%) in this study.",,"Add,Fact/Evidence",Fact/Evidence
10964,9-1204,9-1204_v2_39@1,,"Also, we recommend that more studies to be performed in this field to deeply analyze imaging characteristics of GT and its spatial association with various pathological lesions in the future.",,"Add,Claim",Claim
10965,9-1204,,9-1204_v1_3@0,,"An experienced clinician can accurately diagnose a compound odontoma, as it has distinctive clinical and radiographic features.","Delete,Claim",Claim
10966,9-1204,9-1204_v2_29@0,9-1204_v1_29@0,"Odontomas are mostly located at the anterior maxilla and associated primarily with permanent teeth, although they can also be associated with deciduous teeth and also can be associated with some complications such as impacted teeth, as in the present case, maxillary sinus complications <REF-15> – <REF-18> or/and cystic association <REF-19> .","Odontomas are mostly located at the anterior maxilla and associated primarily with permanent teeth, although they can also be associated with deciduous teeth <REF-15> – <REF-18> .","Modify,Fact/Evidence",Fact/Evidence
10967,9-1204,9-1204_v2_31@0,9-1204_v1_30@1,"In the present case, the supernumerary tooth was non-syndromic, incompletely formed, and it was extracted along with the impacted canine and odontoma.","In the present case, the supernumerary tooth was incompletely formed, and it was extracted along with the impacted canine and odontoma.","Modify,Fact/Evidence",Fact/Evidence
10968,9-1204,9-1204_v2_5@0,9-1204_v1_5@0,"Odontoma is defined as a benign odontogenic tumor containing enamel, dentin and cementum, and are classified by the World Health Organization into two main types: compound and complex <REF-1> , <REF-2> .","Odontoma is defined as a benign odontogenic tumor containing enamel, dentin and cementum, and are classified by the World Health Organization into two main types: compound and mixed <REF-1> , <REF-2> .","Modify,Clarity",Clarity
10969,9-1204,9-1204_v2_37@0,9-1204_v1_33@4,"This was in harmony with our study, where during surgery, it was apparent that the GT was contiguous with the supernumerary follicle, suggesting that the GT was guiding the eruption of the supernumerary tooth, but the development of the odontoma prevented its eruption.","Furthermore, during surgery, it was apparent that the GT was contiguous with the supernumerary follicle, suggesting that the GT was guiding the eruption of the supernumerary tooth, but the development of the odontoma prevented its eruption.","Modify,Clarity",Clarity
10970,9-1204,9-1204_v2_37@1,9-1204_v1_33@5,Gaêta-Araujo H et al. reported that the most communal attachment site of GC was to the occlusal side of the dental sac of the unerupted tooth (93.2%) and was classified as a usual attachment.,Gaˆeta-Araujo H et al. reported that the most communal attachment site of GC was to the occlusal side of the dental sac of the unerupted tooth (93.2%) and was classified as a usual attachment.,"Modify,Grammar",Grammar
10971,9-1204,9-1204_v2_39@0,9-1204_v1_35@3,"The dentist should be aware of the probability of a close relationship between the development of odontoma and presence of the gubernacular tract, which could be used as a future radiographic diagnostic criterion of an odontoma.","The dentist should also be aware of the probability of a close relationship between the development of odontoma and presence of the gubernacular tract, which in future could be used as a radiographic diagnostic criterion of an odontoma.","Modify,Clarity",Clarity
10972,9-1204,9-1204_v2_9@0,9-1204_v1_9@0,"We present a case of an impacted upper canine with compound odontoma and a supernumerary tooth accompanied by gubernacular canal, where we utilized cone-beam computed tomography (CBCT) to locate each structure precisely prior to surgical treatment.","We present a case of an impacted upper canine with compound odontoma and a supernumerary tooth accompanied by gubernacular canal, where we utilised cone-beam computed tomography (CBCT) to diagnose the tumor prior to surgical treatment.","Modify,Clarity",Clarity
10973,9-1204,9-1204_v2_11@0,9-1204_v1_11@0,"A 47-year old female – of African origin - presented to the dental clinic to treat multiple carious teeth, and to replace multiple missing teeth.","A 47-year old house wife – of African origin - presented to the dental clinic to treat multiple carious teeth, and to replace multiple missing teeth.","Modify,Clarity",Clarity
10974,9-1204,9-1204_v2_11@2,9-1204_v1_11@2,The patient’s medical history showed no previous incidence of dental/maxillofacial trauma or infections.,The patient's medical history showed no previous incidence of dental/maxillofacial trauma or infections.,"Modify,Grammar",Grammar
10975,9-1204,9-1204_v2_14@0,9-1204_v1_14@0,CBCT showed that tooth #23 was palatal impacted between teeth #21 and #22.,CBCT showed that tooth #23 was palatally impacted between teeth #21 and #22.,"Modify,Grammar",Grammar
10976,9-1204,9-1204_v2_14@1,9-1204_v1_14@1,"There was a very small well defined rounded denticle like mass positioned distal to tooth #22 and coronal to the impacted supernumerary tooth (crown only), preventing its eruption.","There was a very small well defined rounded denticle like mass positioned distal to tooth #22 and coronal to the impacted supernumerary tooth (crown only), causing a small clinical buccal bulging and preventing its eruption.","Modify,Fact/Evidence",Fact/Evidence
10977,9-1204,9-1204_v2_2@3,9-1204_v1_2@3,The patient had uneventful healing and proceeded with the prosthodontic treatment plan.,Patient had uneventful healing and proceeded with the prosthodontic treatment plan.,"Modify,Grammar",Grammar
10978,9-1204,9-1204_v2_24@0,9-1204_v1_24@0,"Histopathologic examination of the excised mass showed a tooth-like structure with dentin, and some enamel matrix confirming the diagnosis of compound odontoma ( Figure 4 a,b ).","Histopathologic examination of the excised mass showed a tooth-like structure with dentin, dentinoid tissue, and some enamel matrix confirming the diagnosis of compound odontoma ( Figure 4 a,b ).","Modify,Fact/Evidence",Fact/Evidence
10979,9-1243,9-1243_v2_19@1,,"After general supportive treatment, including intravenous dopamine administration, electrolyte imbalance correction, supportive treatment of general weakness condition, anemia, hypoalbuminemia, and infection, the patient showed improvement in general condition.",,"Add,Fact/Evidence",Fact/Evidence
10980,9-1243,9-1243_v2_19@2,,No hemodynamic instability was observed when temporary pacemaker was turned off.,,"Add,Fact/Evidence",Fact/Evidence
10981,9-1243,9-1243_v2_20@0,,"Multidiscipline team discussions involving electrophysiologist, otolaryngologist, and internist, resulted in decision to focus more on palliative care for this patient.",,"Add,Fact/Evidence",Fact/Evidence
10982,9-1243,9-1243_v2_43@2,,Temporary pacemaker should be considered for patients presenting with CHB and unstable hemodynamic before deciding permanent pacemaker implantation.,,"Add,Claim",Claim
10983,9-1243,9-1243_v2_6@1,9-1243_v1_6@1,"Primary cardiac tumors are also rare (on postmortem analysis, commonly between 0.01% to 0.1%).",Primary cardiac tumors are also rare (on postmortem analysis commonly between 0.01% to 0.1%).,"Modify,Grammar",Grammar
10984,9-1243,9-1243_v2_31@1,9-1243_v1_28@1,Conduction system involvement may induce a various degree of atrioventricular blocks <REF-16> .,Conduction system involvement may induce various degree of atrioventricular blocks <REF-16> .,"Modify,Grammar",Grammar
10985,9-1243,9-1243_v2_38@0,9-1243_v1_35@0,"Predominantly, after a reversible or transient cause of bradycardia is excluded, cardiac pacing indication is decided by bradycardia severity instead of its etiology.","Predominantly, after a reversible or transient cause of bradycardia is excluded, cardiac pacing indication is decided by bradycardia severity, instead of its etiology.","Modify,Grammar",Grammar
10986,9-1243,9-1243_v2_10@0,9-1243_v1_10@0,A 24-year old Asian man was admitted to the cardiology department with CHB and hypotension.,A 24-year old Asian man was admitted the cardiology department with CHB and hypotension.,"Modify,Grammar",Grammar
10987,9-1243,9-1243_v2_41@0,9-1243_v1_38@0,"For patients with indications for permanent pacing but accompanied with significant comorbidities or who are anticipated having a shortened lifespan because of terminal progressive illness, the implantation of a PPM should not be performed if it is unlikely to deliver significant clinical benefits or if it hinders the main therapy for the patient’s goal of care.","For patients with indications for permanent pacing, but accompanied with significant comorbidities or who are anticipated having a shortened lifespan because of terminal progressive illness, the implantation of a PPM should not be performed if it is unlikely to deliver significant clinical benefits or if it hinders the main therapy for the patient’s goal of care.","Modify,Grammar",Grammar
10988,9-1243,9-1243_v2_10@1,9-1243_v1_10@1,"The patient was a chef and had a history of tongue cancer for six months, and had undergone 30 cycles of radiotherapy.",The patient was a chef and had a history of tongue cancer for six months and had undergone 30 cycles of radiotherapy.,"Modify,Grammar",Grammar
10989,9-1243,9-1243_v2_11@1,9-1243_v1_11@1,"He was hypotensive and bradycardic with a blood pressure of 80/40 mmHg, regular heart rate of 44 beats per minute, respiratory rate of 18 breaths per minute, and oxygen saturation of 97% on room air.","He was hypotensive and bradycardic with blood pressure of 80/40 mmHg, regular heart rate of 44 beats per minute, respiratory rate of 18 breaths per minute, and oxygen saturation of 97% on room air.","Modify,Grammar",Grammar
10990,9-1243,9-1243_v2_3@1,9-1243_v1_3@1,"An intracardiac mass and moderate pericardial effusion were present, presumed as the metastatic tumor of tongue cancer.","A intracardiac mass and moderate pericardial effusion were present, presumed as the metastatic tumor of tongue cancer.","Modify,Grammar",Grammar
10991,9-1243,9-1243_v2_19@3,9-1243_v1_19@1,"However, the CHB persisted despite electrolyte imbalance correction.",CHB persisted despite corrected electrolyte imbalance.,"Modify,Clarity",Clarity
10992,9-1243,9-1243_v2_22@1,9-1243_v1_19@3,Further chest X-ray evaluation on the 14 th day showed left parahilar ground glass appearance with suspicions of lung metastasis and pleural effusion ( Figure 4 ).,"Further chest X-ray evaluation on the 14 th day of treatment (which includes electrolyte imbalance correction, supportive treatment of general weakness condition, anemia, hypoalbuminemia, and infection) showed left parahilar ground glass appearance with suspicions of lung metastasis and pleural effusion ( Figure 4 ).","Modify,Fact/Evidence",Fact/Evidence
10993,9-1243,9-1243_v2_21@0,9-1243_v1_22@0,"Considering the risk of infection in prolong use of temporary pacemaker, on the 7 th day the temporary pacemaker was extracted.","Because the patient showed general improvement after supportive treatment for seven days and no symptoms of CHB, it was decided that the temporary pacemaker would be extracted.","Modify,Fact/Evidence",Fact/Evidence
10994,9-1276,,9-1276_v1_30@4,,"This clearly showed that in the ROI, there were more proliferative T cells than B cells that interacted with phagocytes.","Delete,Fact/Evidence",Fact/Evidence
10995,9-1276,,9-1276_v1_30@5,,Exportable statistical tables confirmed this observation.,"Delete,Fact/Evidence",Fact/Evidence
10996,9-1276,9-1276_v2_8@6,,The result file should contain at least two columns that provide intensities or other parameters necessary to create a scatterplot.,,"Add,Fact/Evidence",Fact/Evidence
10997,9-1276,9-1276_v2_9@1,,"For the TIFF image, since large images may alter the fluidity of the application, we decided that images with a X or Y dimension higher than 1024 would be resized proportionaly so the highest dimension is 1024 (e.g. a 2048 * 1536 image will become a 1024 * 768 image).",,"Add,Claim",Claim
10998,9-1276,9-1276_v2_9@2,,SAPHIR is able to load standard 2D ROI from Fiji.,,"Add,Claim",Claim
10999,9-1276,9-1276_v2_12@0,,The development of the app was made as follows.,,"Add,Fact/Evidence",Fact/Evidence
11000,9-1276,9-1276_v2_12@1,,"First, an interactive Shiny app was created, using the “shiny” library in R, to link a tissue section image and a scatterplot representing for each cell its fluorescence intensity on different channels.",,"Add,Fact/Evidence",Fact/Evidence
11001,9-1276,9-1276_v2_12@2,,"To do so, the libraries “ijtiff”, “RImageROI” and “ggplot2” were used.",,"Add,Fact/Evidence",Fact/Evidence
11002,9-1276,9-1276_v2_12@3,,"In addition, the statistical part of the app and the “Image to Plot” section were added.",,"Add,Fact/Evidence",Fact/Evidence
11003,9-1276,9-1276_v2_12@4,,"Second, the interface of the app was improved with “shinydashboard”, “shinyWidgets” and “shinycssloaders”.",,"Add,Fact/Evidence",Fact/Evidence
11004,9-1276,9-1276_v2_12@5,,"Third, a menu “Select your result” was created to load needed files (see Data requirement section).",,"Add,Fact/Evidence",Fact/Evidence
11005,9-1276,9-1276_v2_12@6,,"Fourth, the interactivity between the scatter plot and the image was improved using “plotly. A “filtering” option was also added to the scatterplot.",,"Add,Fact/Evidence",Fact/Evidence
11006,9-1276,9-1276_v2_12@7,,"Fifth, the visualization options of the scatterplot selections in the image, such as cell ID display, channel overlays and thickness of cells contours were added to the app.",,"Add,Fact/Evidence",Fact/Evidence
11007,9-1276,9-1276_v2_12@8,,This was done using “EBImage” and “magick” packages.,,"Add,Fact/Evidence",Fact/Evidence
11008,9-1276,9-1276_v2_12@9,,"Finally, the “Annotation” menu was added to allow result corrections based on scatterplot to image analysis and “Download” buttons were created to allow the download of SAPHIR results.",,"Add,Fact/Evidence",Fact/Evidence
11009,9-1276,9-1276_v2_17@2,,Fiji and the macro can be launched from the segmentation menu of the application.,,"Add,Fact/Evidence",Fact/Evidence
11010,9-1276,9-1276_v2_32@0,,We selected a spectral confocal image of a stained stimulated PP.,,"Add,Fact/Evidence",Fact/Evidence
11011,9-1276,9-1276_v2_32@1,,"It consisted of 12 optical slices with 6 channels distinguishing proliferative nuclei, B cells, T cells, monocyte-derived phagocytes, early-activated T cells and total nuclei.",,"Add,Fact/Evidence",Fact/Evidence
11012,9-1276,9-1276_v2_32@2,,All optical slices but only the first four channels were necessary for the purpose of this study.,,"Add,Fact/Evidence",Fact/Evidence
11013,9-1276,9-1276_v2_33@3,,"We were thus able to identify proliferative T cells (lower right quadrant, red contour), proliferative B cells (upper left quadrant) and uncharacterized proliferative cells (lower left quadrant).",,"Add,Fact/Evidence",Fact/Evidence
11014,9-1276,9-1276_v2_36@0,,"Finally, we obtained exportable statistical data for all gated cells validated or not by direct visualization onto the image ( Figure 6 , lower left panel with selected cells boxed in red).",,"Add,Fact/Evidence",Fact/Evidence
11015,9-1276,9-1276_v2_36@1,,"In our case, no errors were detected but if they were, the annotation menu would have allowed to correct them.",,"Add,Fact/Evidence",Fact/Evidence
11016,9-1276,9-1276_v2_36@2,,"Finally, based on the analysis of this image and several other similar images, we could document the propensity of proliferating T cells to interact with phagocytes at the periphery of the T cell zone upon stimulation (manuscript in preparation).",,"Add,Fact/Evidence",Fact/Evidence
11017,9-1276,9-1276_v2_38@2,,This is especially useful to locate cells that have been selected based on the extracted data.,,"Add,Claim",Claim
11018,9-1276,9-1276_v2_38@3,,It may thus reveal particular and unsuspected locations for the selected cells within the tissue.,,"Add,Claim",Claim
11019,9-1276,9-1276_v2_38@4,,"It can also be used to check some parameters of the selected cells (e.g., phenotype and interacting partners) on the image to correct any possible errors generated by the automatic analysis (e.g., segmentation and cell identity).",,"Add,Claim",Claim
11020,9-1276,,9-1276_v1_8@4,,"Another file, termed ROI.zip, should contain the image contour of each COI.","Delete,Fact/Evidence",Fact/Evidence
11021,9-1276,9-1276_v2_2@5,9-1276_v1_2@5,"Our application allows to characterize labeled cells, from their phenotype to their number and location in the tissue, as well as their interaction with other cells.","Our application allows to quickly characterize labeled cells, from their phenotype to their number and location in the tissue, as well as their interaction with other cells.","Modify,Clarity",Clarity
11022,9-1276,9-1276_v2_27@0,9-1276_v1_24@0,"Finally, the menu “Annotation” allows correction of the data from the result csv file but also from the scatterplot-gated cells when saved in the “Plot to Image” menu.","Finally, the menu “Annotation” allows, based on the previous analyses, correction of the data from the result csv file but also from the scatterplot-gated cells when saved in the “plot to image” menu.","Modify,Clarity",Clarity
11023,9-1276,9-1276_v2_27@1,9-1276_v1_24@1,"For each selected cell, a cropped image of this cell is displayed, and based on the previous analyses users can change its parameters (e.g., cell identity) if necessary ( Figure 5 ).","For each selected cell, a cropped image of this cell is displayed, and users can change its parameters if necessary ( Figure 5 ).","Modify,Clarity",Clarity
11024,9-1276,9-1276_v2_31@0,9-1276_v1_28@0,"To show the usefulness of our application, we used it on a project that aims to characterize in murine Peyer’s patches (PP) the interaction between phagocytes and proliferative immune effector cells, i.e. B and T cells.","To show the usefulness of our application, we used it on a project that aimed to characterize the interaction between phagocytes and proliferative immune effector cells in murine Peyer’s patches (PP), i.e. B and T cells.","Modify,Clarity",Clarity
11025,9-1276,9-1276_v2_31@2,9-1276_v1_28@2,"In PP, antigens are taken up by phagocytes, which, upon stimulation, migrate in the T cell zone and its periphery to interact with prime naïve T cells.","In PP, antigens are taken up by phagocytes that, upon stimulation, migrate in the T cell zone and its periphery to interact with and prime naïve T cells.","Modify,Clarity",Clarity
11026,9-1276,9-1276_v2_31@4,9-1276_v1_28@4,"We therefore decided to use SAPHIR to examine the evolution of proliferative cell number, to determine their identity (B or T cells) and to analyze their interaction with migratory phagocytes in this region during the course of a stimulation.","We therefore decided to examine the evolution of proliferative cell number, to determine their identity (B or T cells) and to analyze their interaction with migratory phagocytes during the course of the stimulation.","Modify,Clarity",Clarity
11027,9-1276,9-1276_v2_32@3,9-1276_v1_29@0,"First, we used two homemade Fiji macros as described in Data requirement.","We used SAPHIR application and two ImageJ macros, which are available on GitHub in the Demonstration Files .","Split+Modify,Fact/Evidence",Fact/Evidence
11028,9-1276,9-1276_v2_32@4,9-1276_v1_29@0,These macros are available on GitHub in the Demonstration Files and can be launched from the Segmentation menu of the application.,"We used SAPHIR application and two ImageJ macros, which are available on GitHub in the Demonstration Files .","Split+Modify,Fact/Evidence",Fact/Evidence
11029,9-1276,9-1276_v2_32@5,9-1276_v1_29@1,"The first macro allows the counting of proliferative cells through segmentation of Ki-67 + nuclei, provides their identity through analysis of T and B cell staining intensity of Ki-67 + cells, and determines their interaction with phagocytes.","The first macro allows the counting of proliferative cells through segmentation of Ki-67+ nuclei, provides their identity through analysis of T and B cell staining of Ki-67+ cell membrane, and analyses their interaction with phagocytes.","Modify,Clarity",Clarity
11030,9-1276,9-1276_v2_32@6,9-1276_v1_29@2,"The second macro identifies the area of high density in proliferative cells as ROI, thanks to the DBSCAN algorithm <REF-10> and determines whether previously analysed cells belong to this ROI.","The second macro identify the area of high density in proliferative cells as ROI, thanks to the DBSCAN algorithm and determine whether previously analysed cells belong to this ROI.","Modify,Fact/Evidence",Fact/Evidence
11031,9-1276,9-1276_v2_4@0,9-1276_v1_4@0,"The identification, localization and quantification of cell subsets in tissues is a difficult but essential task for biologists to understand spatial cellular organization in different settings (e.g. homeostasis vs inflammatory diseases or cancer).","The identification, localization and quantification of cell subsets in tissue is a difficult but essential task for biologists to understand spatial cellular organization in different settings (e.g. homeostasis vs inflammatory diseases or cancer).","Modify,Grammar",Grammar
11032,9-1276,9-1276_v2_33@0,9-1276_v1_30@0,"Then, we integrated these data into the SAPHIR application and generated scatterplots and statistical analyses.","Then, SAPHIR application allowed us to integrate these data and provided scatter plots and statistical analyses.","Modify,Clarity",Clarity
11033,9-1276,9-1276_v2_33@1,9-1276_v1_30@1,"Thus, with the “Filtering” tab we selected only proliferative cells belonging to the area of intense proliferation at the periphery of the T cell zone from which we wanted to obtain statistical data (green rectangle in the upper left histogram of Figure 6 ).","Thus, the filtering tab was used to select only proliferative cells belonging to the ROI ( Figure 6 , upper left).","Modify,Fact/Evidence",Fact/Evidence
11034,9-1276,9-1276_v2_33@2,9-1276_v1_30@2,"Then, these ROI-proliferative cells were split into B and T cells using the scatter plot ( Figure 6 , left mid-panel).","Then, ROI-proliferative cells were split into B and T cells using the scatter plot ( Figure 6 , lower left).","Modify,Clarity",Clarity
11035,9-1276,9-1276_v2_33@4,9-1276_v1_30@3,"Finally, we used the “symbol shape change parameter” option to highlight ROI-proliferative cells that interacted with phagocytes (circles vs triangles).","Finally, we used the “symbol shape change parameter” option to highlight ROI-proliferative cells that interacted with phagocytes.","Modify,Fact/Evidence",Fact/Evidence
11036,9-1276,9-1276_v2_33@5,9-1276_v1_30@6,"Selecting T cells, we could localize each of them on the optical slices and check their interaction or not with phagocytes directly into the image ( Figure 6 , right panel and higher magnification inserts).","Selecting these T cells, we could localize these cells interacting with phagocytes directly into the image ( Figure 6 , right).","Modify,Fact/Evidence",Fact/Evidence
11037,9-1276,9-1276_v2_38@1,9-1276_v1_34@1,It is based on the interactivity between quantitative data extracted from the image and the image itself.,It is based on the interactivity between quantitative data and image to simplify the analysis and limit bias.,"Modify,Fact/Evidence",Fact/Evidence
11038,9-1276,9-1276_v2_38@5,9-1276_v1_34@2,Further developments of SAPHIR will include use of pyramidal images to minimize loading and analysis time and will implement R spatial analysis algorithm to analyze cell clusters and cell neighborhood <REF-12> .,Further developments of SAPHIR will include use of pyramidal images to minimize loading and analysis time and unsupervised clustering methods for scatterplot generation <REF-12> .,"Modify,Claim",Claim
11039,9-1276,9-1276_v2_2@1,9-1276_v1_2@1,Image acquisitions performed by confocal microscopy notably allow excellent lateral resolution and more than 10 parameter measurements when using spectral or multiplex imaging.,Image acquisitions performed by confocal microscopy notably allow excellent lateral resolution and more than 10 parameter measurement when using spectral or multiplex imaging.,"Modify,Grammar",Grammar
11040,9-1276,9-1276_v2_5@2,9-1276_v1_5@2,"Therefore, we decided to separate segmentation from SAPHIR, but we provided in a segmentation menu the link to Fiji and the possibility to run Fiji segmentation macros on user image.","Therefore, we decided to separate segmentation from SAPHIR, but we provided two Fiji macro examples with associated images, which can be used to perform this task before running SAPHIR.","Split+Modify,Fact/Evidence",Fact/Evidence
11041,9-1276,9-1276_v2_5@3,9-1276_v1_5@2,"Two Fiji macro examples with associated images, which can be used to perform this task before running SAPHIR, are also provided with the application.","Therefore, we decided to separate segmentation from SAPHIR, but we provided two Fiji macro examples with associated images, which can be used to perform this task before running SAPHIR.","Split+Modify,Clarity",Clarity
11042,9-1276,9-1276_v2_8@0,9-1276_v1_8@0,"The segmentation process that is required to use the application SAPHIR was carried out under Fiji <REF-9> , with homemade macros.","The segmentation required to use the application SAPHIR has been carried out under Fiji <REF-9> , with custom-made macros, which are available on GitHub in the Demonstration Files .","Split+Modify,Clarity",Clarity
11043,9-1276,9-1276_v2_8@1,9-1276_v1_8@0,"These are available on GitHub in the Demonstration Files and can be loaded from the segmentation menu of the application, too.","The segmentation required to use the application SAPHIR has been carried out under Fiji <REF-9> , with custom-made macros, which are available on GitHub in the Demonstration Files .","Split+Modify,Fact/Evidence",Fact/Evidence
11044,9-1276,9-1276_v2_8@4,9-1276_v1_8@3,"The segmentation process of the image to be analyzed should create a csv result file containing the intensity values of each channel (ranging from 0 to 255) and, if required, the positioning (x, y, z) linked to each COI.","The segmentation process of the image to be analyzed should create a csv result file containing the channel intensity values (ranging from 0 to 255) and, if required, the positioning (x, y, z) linked to each COI.","Modify,Clarity",Clarity
11045,9-1276,9-1276_v2_8@5,9-1276_v1_8@5,"Importantly, many other morphological measurements like area, roundness, or solidity as well as other information (COI belonging to a region of interest, COI interaction with other cells) can be added to the segmentation result file.","Importantly, many other morphological measurements like area, roundness, or solidity as well as other information (COI belonging to a region of interest, COI interaction with other cells, COI centroid position) can be added to the segmentation result file.","Modify,Clarity",Clarity
11046,9-1276,9-1276_v2_9@0,9-1276_v1_8@6,"Finally, the minimal requirements to run the application are the image in TIFF with multiple channels and optionally slices, a legend file with all channel information written in column with name headers (Ch1, Ch2,..) and the corresponding labelling (e.g., LT or LB,..), a segmentation result file with intensity values of each COI in csv and the roi.zip file containing contours of each COI.","Finally, the minimal requirements to run the application are the image in TIFF with multiple channels and optionally slices, the segmentation result file with COI identity in csv and the roi.zip file containing contours of each COI.","Merge+Modify,Clarity",Clarity
11047,9-1276,9-1276_v2_9@0,9-1276_v1_8@7,"Finally, the minimal requirements to run the application are the image in TIFF with multiple channels and optionally slices, a legend file with all channel information written in column with name headers (Ch1, Ch2,..) and the corresponding labelling (e.g., LT or LB,..), a segmentation result file with intensity values of each COI in csv and the roi.zip file containing contours of each COI.",A legend file with all channel information can also be provided (optional).,"Merge+Modify,Fact/Evidence",Fact/Evidence
11048,9-1276,9-1276_v2_11@0,9-1276_v1_10@0,"SAPHIR was built in the R programming language (version 4.0.2), which has very powerful stastistical packages and excellent interactive dashboard programing package, Shiny and its derivatives like ShinyDashboard or Shinyfiles.","SAPHIR is built in the R programming language, version 4.0.2, and uses many packages available on CRAN (e.g. shinydashboard, ijtiff, magick, ggplot2, plotly) and one package (EBImage) available on Bioconductor.","Split+Modify,Claim",Claim
11049,9-1276,9-1276_v2_11@1,9-1276_v1_10@0,"Several packages available on CRAN (e.g. ijtiff, magick, ggplot2, plotly) and one package (EBImage) available on Bioconductor were used.","SAPHIR is built in the R programming language, version 4.0.2, and uses many packages available on CRAN (e.g. shinydashboard, ijtiff, magick, ggplot2, plotly) and one package (EBImage) available on Bioconductor.","Split+Modify,Clarity",Clarity
11050,9-1276,9-1276_v2_13@0,9-1276_v1_10@1,SAPHIR has been tested on macOS and Windows 10.,It has been tested on macOS and Windows 10.,"Modify,Clarity",Clarity
11051,9-1276,9-1276_v2_17@0,9-1276_v1_14@0,"The first step of SAPHIR is either to run a segmentation program to obtain appropriate files or to load the four required files (image.tif, roi.zip, results.csv, legend.csv) in the “select your results” menu of the application.","The first step of SAPHIR is either to run a segmentation program to obtain appropriate files or to load the three required files (image.tif, roi.zip, results.csv) and if needed the legend (csv file) in the “select your results” menu of the application.","Modify,Fact/Evidence",Fact/Evidence
11052,9-1276,9-1276_v2_17@1,9-1276_v1_14@1,"Here, result, region of interest (ROI) and legend files were obtained with a homemade segmentation macro developed under Fiji as described in the Data requirement section.","Here, result, region of interest (ROI) and legend files were obtained with an in house-made segmentation macro developed under Fiji.","Modify,Clarity",Clarity
11053,9-1276,9-1276_v2_18@4,9-1276_v1_15@4,"This can also be used to work only on given subpopulations filtered based on their location, interaction with other cells or other criteria (see Use case section below).","This can also be used to work only on given subpopulations filtered based on their location, interaction with other cells or other criteria (see use case section below).","Modify,Grammar",Grammar
11054,9-1276,9-1276_v2_23@1,9-1276_v1_20@1,"Interactivity between scatterplot and image is optional to avoid slow interaction when the size of images exceeds 300 MB, especially using Docker.",Interactivity between scatterplot and image is optional to avoid slow interaction when high-resolution images are used.,"Modify,Fact/Evidence",Fact/Evidence
11055,9-1276,9-1276_v2_24@0,9-1276_v1_21@0,The SAPHIR menu “Image to Plot” allows to select a region in the image and to display cells of this region on a two-parameter scatterplot ( Figure 4 ).,The SAPHIR menu “image to plot” allows to select a region in the image and to display cells of this region on a two-parameter scatterplot ( Figure 4 ).,"Modify,Grammar",Grammar
11056,9-1308,9-1308_v2_11@5,,Intensity correction can be achieved from either external correction masks or interactively adjusted from XY separable shading correction masks (Extended Data S3-V5 <REF-6> ).,,"Add,Fact/Evidence",Fact/Evidence
11057,9-1308,,9-1308_v1_12@4,,Several tile blending modes are available.,"Delete,Fact/Evidence",Fact/Evidence
11058,9-1308,9-1308_v2_4@2,9-1308_v1_4@2,"Even worse, this situation can be difficult to detect in practice since these tools often bring no or scarce support to check the results and finely correct for the observable residual errors manually.","Even worse, this situation can be difficult to detect in practice since these tools bring no or scarce support to check the results and correct for errors manually.","Modify,Clarity",Clarity
11059,9-1308,9-1308_v2_4@4,9-1308_v1_4@4,"Finally, until now only BigStitcher <REF-4> could handle dual-sided illumination and dual-sided camera detection, two useful lightsheet microscopy <REF-5> modalities that can advantageously be combined ( Figure 1 , Left).","Finally, none of these solutions handles both dual-side illumination and dual-side camera detection, two useful lightsheet microscopy <REF-5> modalities that can advantageously be combined ( Figure 1 , Left).","Modify,Fact/Evidence",Fact/Evidence
11060,9-1308,9-1308_v2_4@5,9-1308_v1_4@5,"We developed MosaicExplorerJ to address these shortcomings and bring a complementary alternative to ImageJ BigStitcher, the reference in the field.","We developed MosaicExplorerJ to address these shortcomings and bring a complementary alternative to ImageJ BigStitcher <REF-4> , the reference in the field.","Modify,Fact/Evidence",Fact/Evidence
11061,9-1308,9-1308_v2_2@0,9-1308_v1_2@0,"We introduce MosaicExplorerJ, an ImageJ macro to stitch 3D tiles from terabyte-size microscopy datasets organized on a regular 2D grid.","We introduce MosaicExplorerJ, an ImageJ macro to stitch 3D tiles from terabyte-size microscopy datasets.","Modify,Fact/Evidence",Fact/Evidence
11062,9-1308,9-1308_v2_9@0,9-1308_v1_9@0,"Whereas stitching the tiles of confocal microscopy datasets chiefly consists in compensating for the scanning head to sample stage tilt (assuming a perfectly orthogonal XYZ translation system), stitching lightsheet microscopy datasets is compounded by the fact that the lightsheet is not necessarily perfectly collinear to the object plane of the detection objective.","Whereas stitching the tiles of confocal microscopy datasets chiefly consists in compensating for the scanning head to sample stage tilt, stitching lightsheet microscopy datasets is compounded by the fact that the lightsheet is not necessarily perfectly collinear to the object plane of the detection objective.","Modify,Fact/Evidence",Fact/Evidence
11063,9-1308,9-1308_v2_2@1,9-1308_v1_2@1,"As opposed to existing software, stitching does not require any prior information on the actual positions of the tiles, or conversion of raw TIFF images to a multi-resolution format for interactive exploration and fast processing.","As opposed to existing software, stitching does not require any prior information on the actual positions of the tiles, sample fiducials, or conversion of raw TIFF images, and the stitched images can be explored instantly.","Modify,Claim",Claim
11064,9-1308,9-1308_v2_9@2,9-1308_v1_9@2,"This second effect can be simply compensated by axially offsetting the 3D tiles accordingly ( Figure 1 , Middle), but additional lightsheet non-uniformity (or lateral misalignment) can lead to differences in the features visible in the regions of tile overlap; potentially weakening correlation based stitching algorithms.","This second effect can be simply compensated by axially offsetting the 3D tiles accordingly ( Figure 1 , Middle), but additional lightsheet non-uniformity (or lateral misalignment) can lead to differences in the features visible in the regions of tile overlap; potentially weakening correlation based algorithms.","Modify,Clarity",Clarity
11065,9-1308,9-1308_v2_9@3,9-1308_v1_9@3,"To address these issues, MosaicExplorerJ assists the user in visually aligning the tiles along the possible degrees of freedom set by a predefined physical model by following a step-by-step procedure to compensate for mismatches highlighted in the regions of tiles overlap.","To address these issues, MosaicExplorerJ does not implement any automated stitching but instead assists the user in visually aligning the tiles along their possible degrees of freedom.","Merge+Modify,Clarity",Clarity
11066,9-1308,9-1308_v2_9@3,9-1308_v1_9@4,"To address these issues, MosaicExplorerJ assists the user in visually aligning the tiles along the possible degrees of freedom set by a predefined physical model by following a step-by-step procedure to compensate for mismatches highlighted in the regions of tiles overlap.",This is basically achieved by following a step-by-step procedure to compensate for the misalignments highlighted in the regions of overlap between adjacent tiles.,"Merge+Modify,Clarity",Clarity
11067,9-1308,9-1308_v2_11@1,9-1308_v1_11@1,"If no other data is available, the software can be tested with the sample data provided (Extended Data S1 <REF-6> ).","If no other data is available, the software can be tested with the data provided.","Modify,Fact/Evidence",Fact/Evidence
11068,9-1308,9-1308_v2_11@3,9-1308_v1_12@1,"This first operation can be as simple as joining two matching features between two adjacent tiles ( Figure 2B , Extended Data S3-V1 <REF-6> ), while compensating lightsheet tilt ( Figures 2C, 2D ) and the axial wobbling of the motors forming the mosaics might require to adjust the axial shift of a selected number of tiles in the top row/column of the mosaic (Extended Data S3-V2 <REF-6> ).","This first operation can be as simple as joining two matching features between two adjacent tiles ( Figure 2B ), while compensating lightsheet tilt ( Figures 2C, 2D ) and the axial wobbling of the motors forming the mosaics might respectively require to adjust the axial shift of the tiles forming the top left corner or the first row and first column of the mosaic.","Modify,Fact/Evidence",Fact/Evidence
11069,9-1308,9-1308_v2_11@4,9-1308_v1_12@2,"Dual-sided camera datasets alignment includes an extra calibration step to compensate for discrepancy between the magnifications of both detection objective lenses ( Figure 1 , Right, Extended Data S3-V3 <REF-6> ), while dual-sided illumination datasets can be stitched by following a similar procedure (Extended Data S3-V4 <REF-6> ).","Dual-camera alignment includes a calibration step to compensate for discrepancy between the magnifications of both detection objectives ( Figure 1 , Right).","Modify,Fact/Evidence",Fact/Evidence
11070,9-1308,9-1308_v2_2@3,9-1308_v1_2@3,"It can handle multiple fluorescence channels, dual-sided lightsheet illumination and dual-sided camera detection.","It can handle multiple fluorescence channels, dual-side lightsheet illumination and dual-side camera detection.","Modify,Grammar",Grammar
11071,9-1308,9-1308_v2_19@0,9-1308_v1_20@0,"Even though it only supports a subset of its features, MosaicExplorerJ brings a complementary alternative to BigStitcher and presents a number of advantages (Extended Data S2 <REF-6> and Table S2 <REF-6> ).","MosaicExplorerJ brings a complementary alternative to BigStitcher, and presents a number of advantages (Extended Data S2 and Table S2 <REF-6> ).","Modify,Fact/Evidence",Fact/Evidence
11072,9-1308,9-1308_v2_19@3,9-1308_v1_20@3,"Finally, all alignment steps are performed visually, which brings direct control and feedback both on the imperfections of the datasets and on the quality of the results, minimizing the risk of leaving coarse errors unnoticed.","Finally, dual-side camera detection is supported and all alignment steps are performed visually, which brings direct control and feedback both on the imperfections of the datasets and on the quality of the results, minimizing the risk of leaving coarse errors unnoticed.","Modify,Fact/Evidence",Fact/Evidence
11073,9-1308,9-1308_v2_4@0,9-1308_v1_4@0,A number of open source tools are available to stitch mosaics from optical microscopy 3D tiled scans <REF-1> – <REF-4> but they systematically implement automated algorithms which results might depend on the starting positions of the tiles and potentially converge to a suboptimal solution.,"A number of open source tools are available to stitch mosaics from optical microscopy 3D tiled scans <REF-1> – <REF-4> but they all implement automated algorithms, potentially converging to a suboptimal solution.","Modify,Claim",Claim
11074,9-1308,9-1308_v2_22@0,9-1308_v1_23@0,"A complete description of the datasets used to test MosaicExplorerJ, including sample preparation and imaging can be found in Extended Data S1 <REF-6> .","A complete description of the datasets used to test MosaicExplorerJ, including sample preparation and imaging can be found in Extended Data S1.","Modify,Fact/Evidence",Fact/Evidence
11075,9-1373,,9-1373_v1_25@4,,"For color selection, always consider visibility for color-blind, and traditions of scientific fields.","Delete,Claim",Claim
11076,9-1373,,9-1373_v1_25@5,,Apply color-schemes consistently.,"Delete,Claim",Claim
11077,9-1373,9-1373_v2_9@1,,"To acquire and resolve the biological structure of interest, choose a microscopy system with an objective lens that allows suitable resolution, optical sectioning and spatial sampling.",,"Add,Fact/Evidence",Fact/Evidence
11078,9-1373,9-1373_v2_9@2,,It is vital to sample intensity information properly by choosing a sufficient bit depth and avoiding saturation of high intensities.,,"Add,Claim",Claim
11079,9-1373,9-1373_v2_9@3,,"If the microscope-system allows changing the detector offset, low intensities should not be cut off.",,"Add,Claim",Claim
11080,9-1373,9-1373_v2_9@4,,"Rather than down sampling and cropping the image data, choose an appropriate magnification.",,"Add,Claim",Claim
11081,9-1373,9-1373_v2_9@5,,"When possible, align or rotate the sample to avoid image rotations.",,"Add,Claim",Claim
11082,9-1373,9-1373_v2_9@6,,"For comparison of image data, sample preparation and image acquisition settings need to be the same <REF-12> – <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
11083,9-1373,9-1373_v2_10@2,,Images are quantitative data.,,"Add,Claim",Claim
11084,9-1373,9-1373_v2_10@3,,"While image visualizations allow qualitative assessments, it is important to accompany them with quantitative measurements and appropriate statistical analysis.",,"Add,Claim",Claim
11085,9-1373,9-1373_v2_10@4,,This workflow strictly addresses the image processing necessary for presentations and figures.,,"Add,Claim",Claim
11086,9-1373,9-1373_v2_10@5,,"Images prepared for presentation (e.g. 8-bit, RGB) are unsuitable for subsequent quantification such as intensity measurements.",,"Add,Claim",Claim
11087,9-1373,9-1373_v2_10@6,,We therefore recommend separating image quantification and visualization workflows.,,"Add,Claim",Claim
11088,9-1373,9-1373_v2_10@7,,"Finally, documentation of any imaging and image processing workflows is key for reproducibility <REF-21> .",,"Add,Fact/Evidence",Fact/Evidence
11089,9-1373,9-1373_v2_14@2,,"When possible use the Bio-Formats plugin for import, as this reads key image metadata (e.g. scale) automatically along with the image <REF-22> .",,"Add,Fact/Evidence",Fact/Evidence
11090,9-1373,9-1373_v2_17@1,,"TIFF files however can rarely be properly used in programs for figure assembly (e.g. Inkscape, PowerPoint).",,"Add,Claim",Claim
11091,9-1373,9-1373_v2_17@3,,"Another common image presentation file format is JPEG , which should be rarely used due to its lossy compression <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
11092,9-1373,9-1373_v2_19@3,,"For adjustments, avoid auto-buttons as, depending on the software packages, the underlying code may differ, resulting in display differences.",,"Add,Claim",Claim
11093,9-1373,9-1373_v2_19@5,,"Entirely eliminating the background signal, or completely ‘clipping’ high intensities, is misleading (see also <REF-9> , <REF-19> , <REF-25> ).",,"Add,Fact/Evidence",Fact/Evidence
11094,9-1373,9-1373_v2_19@6,,"Some saturated pixels in the image are acceptable, if this helps the visualization.",,"Add,Claim",Claim
11095,9-1373,9-1373_v2_19@7,,"To identify problems with intensity sampling, or seeing if the image has been processed, the image histogram can be used to show its gray value distribution ( Figure 3 ).",,"Add,Claim",Claim
11096,9-1373,9-1373_v2_19@8,,"Briefly, good unprocessed images should have some offset in the low intensity range ( Figure 3 : Histogram A ).",,"Add,Claim",Claim
11097,9-1373,9-1373_v2_19@9,,The distribution should not be cut off in the high range ( Figure 3 : Histogram B ) and the range should be continuous ( Figure 3 : Histogram C ).,,"Add,Claim",Claim
11098,9-1373,9-1373_v2_20@1,,"Miura and Nørrelykke nicely describe why intensity adjustments (linear and non-linear) must be applied with special caution when images have already been pre-processed, e.g. cropped <REF-21> .",,"Add,Fact/Evidence",Fact/Evidence
11099,9-1373,9-1373_v2_22@1,,"For instance, advanced systems such as lightsheet microscopy require extensive image processing workflows to obtain a reconstructed volume of the biological specimen for visualization <REF-28> – <REF-32> .",,"Add,Fact/Evidence",Fact/Evidence
11100,9-1373,9-1373_v2_22@2,,Large 3D volumes of data are also hard to visualize in two dimensional figures and require the use of projection or rendering <REF-33> .,,"Add,Fact/Evidence",Fact/Evidence
11101,9-1373,9-1373_v2_22@3,,"Finally, microscopy systems add artefacts (noise, blur), which image processing using linear filters <REF-13> and deconvolution <REF-34> , <REF-35> can help to reduce.",,"Add,Claim",Claim
11102,9-1373,9-1373_v2_22@4,,Any processing for representing the image data needs to be carefully applied where necessary and is no replacement for an optimized imaging setup <REF-12> – <REF-18> .,,"Add,Fact/Evidence",Fact/Evidence
11103,9-1373,9-1373_v2_22@5,,"The processing needs to be clearly stated in the methods section, advanced or non-linear adjustments also in the figure legends <REF-13> , <REF-19> .",,"Add,Fact/Evidence",Fact/Evidence
11104,9-1373,9-1373_v2_26@3,,We discourage adjusting the intensity of individual crops especially for comparisons <REF-21> .,,"Add,Fact/Evidence",Fact/Evidence
11105,9-1373,9-1373_v2_28@1,,"Here, no signal is shown as black, and intensities of the fluorescent signal are displayed in steps of grey values with saturated pixels shown in white.",,"Add,Fact/Evidence",Fact/Evidence
11106,9-1373,9-1373_v2_28@3,,Consider also inverting the grayscale images as human brightness perception is logarithmic and can best differentiate bright areas <REF-27> .,,"Add,Fact/Evidence",Fact/Evidence
11107,9-1373,9-1373_v2_28@4,,Inverted grayscale images are also printer-friendly and have better visibility on a white page/slide.,,"Add,Claim",Claim
11108,9-1373,9-1373_v2_28@7,,"Additionally, we see at times the use of false color LUTs for visualizing image data; when used improperly, false color LUTs can be highly misleading <REF-27> and therefore should be explicitly mentioned in methods and figure legends.",,"Add,Claim",Claim
11109,9-1373,9-1373_v2_30@1,,"Adding scale information, ideally a scale bar with dimension, onto or next to the image, therefore is essential for self-explanatory figures.",,"Add,Claim",Claim
11110,9-1373,9-1373_v2_30@3,,The aim is to provide sufficient information to the reader to understand the presented result at a glance.,,"Add,Fact/Evidence",Fact/Evidence
11111,9-1373,9-1373_v2_30@4,,"Ensure that scale bar, dimensions and annotations are legible in the final figure to be published; it may be more time efficient to adjust scale bar and add dimensions/annotations in the figure preparation software (e.g. as described here <REF-37> ).",,"Add,Fact/Evidence",Fact/Evidence
11112,9-1373,9-1373_v2_42@2,,"Several options also exist to prepare publication-ready figures directly in ImageJ/FIJI, for example ScientiFig and FigureJ <REF-42> , <REF-43> .",,"Add,Fact/Evidence",Fact/Evidence
11113,9-1373,9-1373_v2_42@3,,Figure resolution is usually referred to as dots per inch ( DPI ).,,"Add,Claim",Claim
11114,9-1373,9-1373_v2_42@5,,(Note that the dots-per-inch do not correspond to the physical dimension of the microscopy object and scale bar but solely refer to image size in print or on the screen).,,"Add,Claim",Claim
11115,9-1373,,9-1373_v1_19@1,,Be familiar with these methods to decide if subsequent image intensity quantification is still truthful.,"Delete,Claim",Claim
11116,9-1373,,9-1373_v1_19@2,,"A maximum intensity projection is acceptable for visualization of a 3D stack, but intensity measurements should use ‘sum’ or ‘average’ projections.","Delete,Claim",Claim
11117,9-1373,,9-1373_v1_19@3,,"Similarly, noise is problematic for visualizations and is reduced with linear filters such as a Gaussian blur.","Delete,Fact/Evidence",Fact/Evidence
11118,9-1373,,9-1373_v1_19@4,,"Clearly state the image processing methods <REF-12> , <REF-20> .","Delete,Fact/Evidence",Fact/Evidence
11119,9-1373,9-1373_v2_28@0,9-1373_v1_25@0,"In fluorescence microscopy, cameras usually capture each wavelength (channel) with a separate grayscale image.",Scientific cameras capture each wavelength (channel) with grayscale images.,"Modify,Claim",Claim
11120,9-1373,9-1373_v2_28@2,9-1373_v1_25@1,"When only one fluorophore/wavelength/channel is shown in a figure, grayscale, which has the best contrast, is favorable.","If one channel is shown, grayscale, which has the best contrast with black background, is favorable.","Modify,Claim",Claim
11121,9-1373,9-1373_v2_30@2,9-1373_v1_27@1,"Also annotate what each color and symbol represents in an image, again best in the image itself or next to it.","Further, annotate what each color and symbol represents in an image.","Modify,Fact/Evidence",Fact/Evidence
11122,9-1373,9-1373_v2_34@0,9-1373_v1_31@0,"Using our example microscope images, we qualitatively compared the readability of images processed with or without the workflow described (schematic: Figure 2A ).","Using our example microscope images, we qualitatively compared the readability of images processed with or without the workflow described.","Modify,Fact/Evidence",Fact/Evidence
11123,9-1373,9-1373_v2_34@1,9-1373_v1_31@1,"Images for which the steps of the workflow were implemented contained the key information, were cropped to maximize focus, and sufficiently annotated (color channels, scale, organism), while images processed minimally without following the workflow have a “poor” readability ( Figure 2B ).","Images for which the steps of the workflow were implemented contained the key information, were cropped to maximize focus, and sufficiently annotated (color channels, scale, organism), while images processed minimally without following the workflow have a “poor” readability ( Figure 2A, B ).","Modify,Fact/Evidence",Fact/Evidence
11124,9-1373,9-1373_v2_34@2,9-1373_v1_31@2,"As further example of readability, we also demonstrated that images processed according to our workflow are accessible to color blind readers ( Figure 2B ).","Furthermore, we demonstrated that images processed according to our workflow (‘color’) are still accessible to color blind readers ( Figure 2C ).","Modify,Clarity",Clarity
11125,9-1373,9-1373_v2_41@1,9-1373_v1_34@0,"Our workflow is based on the open source software Fiji ( Figure 3 ), but its principles ( Figure 4 ) are applicable to other software.","Our workflow is based on the open source software Fiji, but its principles are applicable to other software.","Modify,Fact/Evidence",Fact/Evidence
11126,9-1373,9-1373_v2_42@1,9-1373_v1_39@1,Layouting images on a page can be done with design software such as the free and open source Inkscape ( https://inkscape.org ) or the proprietary Adobe Illustrator.,"Layouting images on a page can be done with design software or in Fiji plugins <REF-27> , <REF-28> .","Modify,Fact/Evidence",Fact/Evidence
11127,9-1373,9-1373_v2_5@0,9-1373_v1_5@0,"Every year, about 800,000 articles are newly indexed at Pubmed ( https://www.nlm.nih.gov/bsd/index_stats_comp.html ) of which 25% contain images <REF-1> ; this amounts to about 500 new articles with image figures per day.","Every day, around 2000 biomedical articles appear, 500 of which contain images.","Modify,Fact/Evidence",Fact/Evidence
11128,9-1373,9-1373_v2_42@4,9-1373_v1_39@2,"For an ‘unpixelated’ display of microscopy images in an electronic publication, publishers require 300 DPI images in RGB color mode.",Consider the final dimensions and orientation (landscape/portrait) and save figures for print with 300 dots per inch (DPI).,"Modify,Claim",Claim
11129,9-1373,9-1373_v2_53@0,9-1373_v1_50@0,Data are available under the terms of the Creative Commons Zero “No rights reserved” data waiver (CC0 1.0 Public domain dedication).,"Data are available under the terms of the Creative Commons Zero ""No rights reserved"" data waiver (CC0 1.0 Public domain dedication).","Modify,Grammar",Grammar
11130,9-1373,9-1373_v2_5@3,9-1373_v1_5@3,Another problem is that methods often insufficiently inform about image acquisition and processing <REF-4> .,Problematic is also that methods often insufficiently report on image acquisition and processing <REF-3> .,"Modify,Clarity",Clarity
11131,9-1373,9-1373_v2_9@0,9-1373_v1_9@0,"Obtaining high quality bioimages starts with specimen preparation such as fixation, labelling and clearing.",Obtaining high quality bioimages starts with optimal microscope settings and must be adapted to subsequent quantitative or qualitative analyses <REF-11> – <REF-16> .,"Modify,Fact/Evidence",Fact/Evidence
11132,9-1373,9-1373_v2_17@2,9-1373_v1_13@3,"For image presentation (figures, slides, online), save images in PNG format, which irreversibly merges the image with annotations, permanently applies brightness/contrast settings, and saves multiple channels as 24-bit RGB image .","For presentation, save images in PNG format, which irreversibly merges the image with annotations and saves multichannels as 24-bit RGB .","Modify,Fact/Evidence",Fact/Evidence
11133,9-1373,9-1373_v2_19@0,9-1373_v1_17@0,Images with a large gray value range may appear black when opening them in FIJI <REF-12> .,"After opening, images with a large gray value range may appear black <REF-11> .","Modify,Fact/Evidence",Fact/Evidence
11134,9-1373,9-1373_v2_19@2,9-1373_v1_17@2,"For comparisons of intensities across images, it is recommended to use the same fixed intensity values (‘set’).","When performing comparisons between images, we recommend using the same fixed values using the set button.","Modify,Clarity",Clarity
11135,9-1373,9-1373_v2_19@4,9-1373_v1_17@3,"Linear intensity adjustment is acceptable, as long as key features are not obscured and minimal background signal is still visible to provide audiences with a sense for signal specificity.",This linear intensity adjustment is acceptable if key features are not obscured.,"Modify,Claim",Claim
11136,9-1373,9-1373_v2_20@2,9-1373_v1_17@4,"Once images have been adjusted, ‘apply’ and ‘save as PNG’ irreversibly change the intensity range, which makes images unsuitable for intensity measurements.",Pressing apply/saving images as PNG changes the intensity range irreversibly and makes images unsuitable for intensity measurements.,"Modify,Clarity",Clarity
11137,9-1373,9-1373_v2_20@0,9-1373_v1_17@5,"Non-linear adjustments of brightness and contrast, for example histogram equalizations or gamma correction must be explained in both figure legend and method section <REF-19> , <REF-26> , <REF-27> .","Non-linear adjustments i.e. histogram equalizations or gamma correction need to be explained <REF-20> , <REF-21> .","Modify,Fact/Evidence",Fact/Evidence
11138,9-1373,9-1373_v2_22@0,9-1373_v1_19@0,"Depending on your specific scientific question and goal, further image processing may be necessary for image visualization.",Often further processing is necessary.,"Modify,Claim",Claim
11139,9-1373,9-1373_v2_24@0,9-1373_v1_21@0,Image rotations are sometimes necessary to compare image content properly.,"Image rotation sometimes helps for better comparisons, to reduce unnecessary information, or for aligning specimens.","Split+Modify,Clarity",Clarity
11140,9-1373,9-1373_v2_24@1,9-1373_v1_21@0,"For instance, when comparing specimens, it helps to align them in the same anatomical orientation.","Image rotation sometimes helps for better comparisons, to reduce unnecessary information, or for aligning specimens.","Split+Modify,Claim",Claim
11141,9-1373,9-1373_v2_24@4,9-1373_v1_21@2,"Loss of information by image rotation may be acceptable for image visualizations, however all image quantifications should be done beforehand <REF-19> , <REF-26> .","Such loss of information may be acceptable for visualization, but quantification and measurements must be done beforehand <REF-20> , <REF-21> .","Modify,Clarity",Clarity
11142,9-1373,9-1373_v2_26@0,9-1373_v1_23@0,Often larger fields-of-view are captured on the microscope than are required in the figure.,Often larger fields-of-view are captured than are required.,"Modify,Clarity",Clarity
11143,9-1452,9-1452_v2_9@7,,She denied bronzing of her skin.,,"Add,Fact/Evidence",Fact/Evidence
11144,9-1452,9-1452_v2_22@2,9-1452_v1_22@2,"After excluding all other potential causes, the author believed that the teeth whitening strips could have participated in the oral pigmented lesion in this patient, resulting in diffuse hyperpigmentation.","After excluding all other potential causes, the author believed that the teeth whitening strips could have participated in the oral pigmented lesion in this patient, resulting in diffused hyperpigmentation.","Modify,Grammar",Grammar
11145,9-1452,9-1452_v2_23@4,9-1452_v1_23@4,"In the present case, pigmentation gradually disappeared after discontinuation of the whitening strips.","In the present case, pigmentation gradually disappeared after performing the incisional gingival tissue biopsy of the lesion.","Modify,Fact/Evidence",Fact/Evidence
11146,9-1452,9-1452_v2_4@4,9-1452_v1_4@4,Eliminating all possible local sources of irritation and ruling out other causative factors are the standard first step in the treatment of oral melanoacanthoma.,Eliminating all possible local sources of irritation and ruling out other causative factors are the standard first steps in the oral melanoacanthoma therapy.,"Modify,Clarity",Clarity
11147,9-1452,9-1452_v2_0@0,9-1452_v1_0@0,Case Report: A rare presentation and diagnosis of gingival melanoacanthoma caused by teeth whitening strips: A Case Report,Case Report: A rare presentation and diagnosis of gingival melanoacanthoma caused by teeth whitening strips,"Modify,Clarity",Clarity
11148,9-1452,9-1452_v2_9@10,9-1452_v1_9@9,"Accordingly, a blood test was carried out and the results were all within normal limits; red blood cell count of 4.99 × 10 6 /μL, platelet count of 259 × 10 3 /μL, hemoglobin count of 13.3 g/dL, white blood cell count of 8.88 × 10 3 /μL, lymphocytes 33.6%, segmented neutrophil 54.6%, ferritin 31.11 ng/mL, iron 14.6 umol/L, FT4 17.67 ng/dL, TSH 0.079 mIU/L, Vitamin D 65 ng/mL serum Na 139 mmol/L, serum K 4.2 mmol/L, ACTH 26 pg/ml and cortisol 184.9 nmol/L.","Accordingly, a blood test was carried out and the results were all within normal limits; red blood cell count of 4.99 × 10 6 /μL, platelet count of 259× 10 3 /μL, hemoglobin count of 13.3 g/dL, white blood cell count of 8.88 × 10 3 /μL, lymphocytes 33.6%, segmented neutrophil 54.6%, ferritin 31.11 ng/mL, iron 14.6 umol/L, FT4 17.67 ng/dL, TSH 0.079 mIU/L, Vitamin D 65 ng/mL and cortisol 184.9 nmol/L.","Modify,Fact/Evidence",Fact/Evidence
11149,9-178,9-178_v2_17@5,,"Additionally we extracted information on the number of included participants and studies, the risk of bias etc. (See Data Availability for a file containing the full list).",,"Add,Fact/Evidence",Fact/Evidence
11150,9-178,9-178_v2_20@4,,There was no obvious pattern of improvement over time for trials included in systematic reviews published by both groups.,,"Add,Claim",Claim
11151,9-178,9-178_v2_30@0,,"Previous research found that small, underpowered studies make up the entirety of evidence in most meta-analyses reported by Cochrane reviews <REF-7> .",,"Add,Fact/Evidence",Fact/Evidence
11152,9-178,9-178_v2_30@1,,"Only 35% of the reviews in our sample mentioned sample size in the Implication for research, which suggests that reviewers may be underestimating the size of this problem.",,"Add,Claim",Claim
11153,9-178,9-178_v2_30@2,,"The most frequent issue raised in our work was the choice of outcome, a persistent problem that led to the COMET initiative to facilitate the development of core outcome sets <REF-5> , <REF-8> .",,"Add,Fact/Evidence",Fact/Evidence
11154,9-178,9-178_v2_30@3,,"Cochrane reviewers need to continue to highlight trial design problems; indeed they could perhaps do so more often, especially around sample sizes.",,"Add,Claim",Claim
11155,9-178,9-178_v2_39@0,,There are resources that can help with the above.,,"Add,Claim",Claim
11156,9-178,9-178_v2_39@1,,For example COMET (http://www.comet-initiative.org) can help guide outcome choice and PRECIS-2 can help with design decisions around comparators and follow-up <REF-9> .,,"Add,Fact/Evidence",Fact/Evidence
11157,9-178,9-178_v2_39@2,,Discussions with staff at clinical trial units and other research support centres are also likely to improve designs.,,"Add,Claim",Claim
11158,9-178,9-178_v2_39@3,,"Change is slow at present and initiatives to encourage, or force, trialists to consider these questions would be welcome, especially from funders.",,"Add,Claim",Claim
11159,9-178,9-178_v2_50@0,,This project contains the following data:,,"Add,Fact/Evidence",Fact/Evidence
11160,9-178,9-178_v2_4@1,9-178_v1_4@1,"We created 22 categories of recommendations in total, of which 12 were common to both groups.","We created 22 categories in total, of which 12 were common to both groups.","Modify,Clarity",Clarity
11161,9-178,9-178_v2_28@1,9-178_v1_29@1,These were easier to identify in the Schizophrenia Review Group’s reviews because of their consistent approach to presenting implications for research in accordance with published guidance <REF-6> .,These were clearer in the Schizophrenia Review Group’s reviews because of their structured approach to presenting implications for research in accordance with published guidance <REF-6> .,"Modify,Clarity",Clarity
11162,9-178,9-178_v2_28@2,9-178_v1_29@2,Many of their reviews also routinely include a suggested design for a future trial in this section.,Their reviews also routinely include a suggested design for a future trial in this section.,"Modify,Clarity",Clarity
11163,9-178,9-178_v2_29@0,9-178_v1_30@0,The five most frequently made recommendations are the same for both groups with better choice of outcomes being top of the list and used in over half the 205 reviews included in our study.,The five most frequently made recommendations are the same for both groups with better choice of outcomes being top of the list and cited in over half the 205 reviews included in our study.,"Modify,Clarity",Clarity
11164,9-178,9-178_v2_33@0,9-178_v1_33@0,"Despite looking at just two Cochrane review groups, we believe that our findings are likely to be generalisable to other areas of health and health care but, at a minimum, a good start for the 2020s would be for researchers planning trials in schizophrenia and multiple sclerosis to ask themselves (or be compelled to do so by others, e.g. funders) the following questions:","Despite looking at just two Cochrane review groups, we believe that our findings are likely to be generalisable to other areas of health and health care but, at a minimum, a good start for the 2020s would be for researchers planning trials in schizophrenia and multiple sclerosis to ask themselves the following questions:","Modify,Claim",Claim
11165,9-178,9-178_v2_44@1,9-178_v1_43@1,- - Data from Implications for Research section of Cochrane Schizophrenia Review Group 2009–2019.csv (Data extracted from Cochrane Schizophrenia Review Group),- - Data from Implications for Research section of Cochrane Schizophrenia Review Group 2009-2019.csv (Data extracted from Cochrane Schizophrenia Review Group),"Modify,Grammar",Grammar
11166,9-178,9-178_v2_0@0,9-178_v1_0@0,Learning from Cochrane systematic reviews: what improvements do these suggest for the design of trials?,What improvements do Cochrane systematic reviewers suggest for the design of trials?,"Modify,Clarity",Clarity
11167,9-178,9-178_v2_10@0,9-178_v1_10@0,- 1. Categorise the recommendations made in ‘ Implications for research ’.,1. Categorise the recommendations made in ‘ Implications for research ’.,"Modify,Grammar",Grammar
11168,9-178,9-178_v2_10@1,9-178_v1_11@0,- 2. Explore whether there have been changes over time and between the two groups.,2. Explore whether there have been changes over time and between the two groups.,"Modify,Grammar",Grammar
11169,9-178,9-178_v2_2@2,9-178_v1_2@2,"Cochrane systematic reviews have a section called ‘ Implications for research ’, which allows authors of the review to present their conclusions on how future research might be improved.","Cochrane systematic reviews all have a section called ‘ Implications for research ’, which allows authors of the review to present their conclusions on how future research might be improved.","Modify,Clarity",Clarity
11170,9-178,9-178_v2_20@3,9-178_v1_21@3,"However, the ranking of each category in that top five list varied from one year to the next; no category was consistently most used ( Figure 1 and Figure 2 ).","However, the use of these five categories varied over time for each group ( Figure 1 and Figure 2 ).","Modify,Fact/Evidence",Fact/Evidence
11171,9-178,9-178_v2_3@1,9-178_v1_3@1,Reviews with citation dates between 2009 and 2019 were identified and the recommendations of review authors in ‘ Implications for research’ were put into categories.,Reviews with citations between 2009 and 2019 were identified and the recommendations given by review authors in ‘ Implications for research’ were put into categories.,"Modify,Clarity",Clarity
11172,9-213,9-213_v2_27@2,,The alignmentviewer.org implementation uses the number of amino acid differences between pairs of sequences (the Hamming distance) as the distance metric parameter.,,"Add,Fact/Evidence",Fact/Evidence
11173,9-213,9-213_v2_27@3,,"The algorithm then iteratively calculates an embedding in two- or three-dimensional space, which is displayed in real time for the end users.",,"Add,Fact/Evidence",Fact/Evidence
11174,9-213,,9-213_v1_12@5,,Based on this and other small tests we can safely state that any computer that is able to run any modern web browser will be able to run any alignment that requires visualization.,"Delete,Claim",Claim
11175,9-213,9-213_v2_27@0,9-213_v1_27@0,Users can view representations of the MSA sequences in two- or three-dimensional space under the “sequence space” tab.,Users can view MSA sequences in two- or three-dimensional sequence space under the “sequence space” tab.,"Modify,Clarity",Clarity
11176,9-213,9-213_v2_27@1,9-213_v1_27@1,"These representations are generated using the Uniform Manifold Approximation and Projection (UMAP) dimensionality reduction algorithm ( McInnes et al. , 2018 ), whichhas been adapted for Javascript using the umap-js library ( https://github.com/PAIR-code/umap-js ).","Dimensionality reduction is performed using the UMAP algorithm ( McInnes et al. , 2018 ), adapted for Javascript as umap-js , using the Hamming distance between sequences.","Modify,Fact/Evidence",Fact/Evidence
11177,9-213,9-213_v2_27@4,9-213_v1_27@2,"UMAP hyperparameters are set to reasonable defaults, but can also be configured via the settings panel.","UMAP parameters are set to reasonable defaults, but can also be configured via the settings panel.","Modify,Clarity",Clarity
11178,9-213,9-213_v2_27@5,9-213_v1_27@3,"Sequences can be colored by user provided annotations (""upload annotations"" tab).","Sequences are colored by user provided annotations (""upload annotations"" tab).","Modify,Clarity",Clarity
11179,9-213,9-213_v2_29@0,9-213_v1_29@0,AlignmentViewer is a lightweight online viewer for biological multiple sequence alignments that focuses on usability and performance.,"AlignmentViewer ( Reguant, 2020 ) is a lightweight online viewer for biological multiple sequence alignments that focuses on usability and performance.","Modify,Fact/Evidence",Fact/Evidence
11180,9-213,9-213_v2_10@0,9-213_v1_10@0,AlignmentViewer is a web-based tool written in JavaScript with minimal system requirements.,"AlignmentViewer ( Reguant, 2020 ) is a web-based tool written in JavaScript with minimal system requirements.","Modify,Fact/Evidence",Fact/Evidence
11181,9-213,9-213_v2_10@1,9-213_v1_10@1,AlignmentViewer works best on Chrome regardless of operating system.,"AlignmentViewer runs on most modern web browsers such as Chrome, Safari, and Firefox regardless of operating system.","Modify,Claim",Claim
11182,9-213,9-213_v2_12@1,9-213_v1_12@1,"Hyperlinks for lookup in background databases, such as Uniprot or Pfam, are made directly from the client.","Hyperlinks for lookup in background databases, such as Uniprot or PFAM, are made directly from the client.","Modify,Grammar",Grammar
11183,9-213,9-213_v2_12@2,9-213_v1_12@2,"Alignments can be passed to AlignmentViewer also via a URL query parameter that is served by https and is properly encoded (e.g., https://alignmentviewer.org/?url=https://alignmentviewer.org/example/1bkr_A.1-108.msa.txt ), enabling seamless integration from external web services via a simple link (e.g. the EVcouplings, evcouplings.org, web server ( Hopf et al. , 2019 ) offers visualization of computed alignments via a link to AlignmentViewer).","Alignments can be passed to AlignmentViewer also via a URL query (e.g., https://alignmentviewer.org/? url =https://alignmentviewer.org/example/1bkr_A.1-108.msa.txt ), enabling seamless integration from external web services via a simple link (e.g. the EVcouplings, evcouplings.org, web server ( Hopf et al. , 2019 ) offers visualization of computed alignments via a link to AlignmentViewer).","Modify,Clarity",Clarity
11184,9-213,9-213_v2_14@0,9-213_v1_14@0,Figure 1 shows the main functionalities from AlignmentViewer explained in more detail in the next subsections.,"Figure 1 shows the main functionalities from AlignmentViewer ( Reguant, 2020 ) explained in more detail in the next subsections.","Modify,Fact/Evidence",Fact/Evidence
11185,9-238,,9-238_v1_12@3,,"Sample size calculation estimated that a minimum of 20,000 records were needed to find differences of at least four DALYs/1000 people between subgroups with 80% power and 95% significance.","Delete,Fact/Evidence",Fact/Evidence
11186,9-238,9-238_v2_18@3,9-238_v1_18@3,"YLL, YLD, and DALYs were estimated, summing these metrics in total and by subgroups using the 1994 Harvard and the 2015 GDB methods, and the 2015 GBD and the Peruvian Ministry of Health (MINSA) disability coefficients, which means four iterations were calculated for each metric.","YLL, YLD, and DALYs were estimated, summing these metrics in total and by subgroups using the 1994 WHO and the 2015 GDB methods, and the 2015 GBD and the Peruvian Ministry of Health (MINSA) disability coefficients, which means four iterations were calculated for each metric.","Modify,Fact/Evidence",Fact/Evidence
11187,9-238,9-238_v2_25@1,9-238_v1_25@1,"According to the 1994 Harvard methodology, osteoarthritis produced 399,884 DALYs using the latest WHO disability weights, or 678,591 DALYs if employing the Peruvian MINSA weights.","According to the 1994 WHO methodology, osteoarthritis produced 399,884 DALYs using the latest WHO disability weights, or 678,591 DALYs if employing the Peruvian MINSA weights.","Modify,Fact/Evidence",Fact/Evidence
11188,9-238,9-238_v2_7@1,9-238_v1_7@1,"In Peru, osteoarthritis is the sixth cause of disability-adjusted life years (DALYs), representing 3% of global burden of disease <REF-3> .","Worldwide, osteoarthritis is the sixth cause of disability-adjusted life years (DALYs), representing 3% of global burden of disease <REF-3> .","Modify,Fact/Evidence",Fact/Evidence
11189,9-238,9-238_v2_28@3,9-238_v1_28@3,"According to the 1994 Harvard methodology and using the Peruvian MINSA disability weights, knee osteoarthritis produced 16.6 DALYs/1000 patient per year among men, and 25.5 DALYs/1000 patient per year in women.","According to the 1994 WHO methodology and using the Peruvian MINSA disability weights, knee osteoarthritis produced 16.6 DALYs/1000 patient per year among men, and 25.5 DALYs/1000 patient per year in women.","Modify,Fact/Evidence",Fact/Evidence
11190,9-238,9-238_v2_31@2,9-238_v1_31@2,"According to the 1994 Harvard methodology and using the Peruvian MINSA disability weights, knee osteoarthritis produced 2.3 DALYs/1000 patients per year among men, and 5.3 DALYs/1000 patients per year in women.","According to the 1994 WHO methodology and using the Peruvian MINSA disability weights, knee osteoarthritis produced 2.3 DALYs/1000 patients per year among men, and 5.3 DALYs/1000 patients per year in women.","Modify,Fact/Evidence",Fact/Evidence
11191,9-238,9-238_v2_34@0,9-238_v1_34@0,"Considering MINSA had used the 1994 Harvard methodology and their own disability weights in their previous burden of disease studies, we will follow suit in order to compare our results with previous reports.","Considering MINSA had used the 1994 WHO methodology and their own disability weights in their previous burden of disease studies, we will follow suit in order to compare our results with previous reports.","Modify,Fact/Evidence",Fact/Evidence
11192,9-238,9-238_v2_34@2,9-238_v1_34@2,These estimates are consistently higher than the disease burden of osteoarthritis reported by all studies conducted in Peru under the 1994 Harvard methodology.,These estimates are consistently higher than the disease burden of osteoarthritis reported by all studies conducted in Peru under the 1994 WHO methodology.,"Modify,Fact/Evidence",Fact/Evidence
11193,9-238,9-238_v2_35@0,9-238_v1_35@0,"As observed in Table 4 , there has an increment in DALYs despite using the same methodology.","As observed in Table 4 , there has been an upward trend in the DALY estimates despite using the same methodology.","Modify,Clarity",Clarity
11194,9-238,9-238_v2_35@3,9-238_v1_35@3,"It is possible then, that the increment is just echoing a better registry of cases.","It is possible then, that the upward trend is just echoing a better registry of cases.","Modify,Clarity",Clarity
11195,9-238,9-238_v2_9@1,9-238_v1_9@1,"The original 1994 recommendations used life expectancy rates for men and women, gave less weight to the extremes of life, and penalized years when they were far from the current person age <REF-12> .","The original 1994 recommendations used tables based on 1966 data, employed different life expectancy for men and women, gave less weight to the extremes of life, and penalized years when they were far from the current person age <REF-12> .","Modify,Fact/Evidence",Fact/Evidence
11196,9-238,9-238_v2_9@2,9-238_v1_9@2,The current method recommended by WHO in its 2015 Global Burden of Disease (GBD) study uses standard life expectancy are based on lowest observed mortality rates in any age group in populations over 5 million and does not time-discounting <REF-13> .,The current method recommended by WHO in its 2015 Global Burden of Disease (GBD) study uses life expectancy projected to 2050 and does not consider age-weighting or time-discounting <REF-13> .,"Modify,Fact/Evidence",Fact/Evidence
11197,9-238,9-238_v2_39@2,9-238_v1_39@2,"In addition, the original 1994 Harvard method differentiated life expectancy values for men (80 years) and women (82.5 years), penalized the extremes of life ages, and discounted the value of years away in time, reducing the DALYs contributed by men and younger people <REF-22> – <REF-24> .","In addition, the original 1994 WHO method differentiated life expectancy values for men (80 years) and women (82.5 years), penalized the extremes of life ages, and discounted the value of years away in time, reducing the DALYs contributed by men and younger people <REF-22> – <REF-24> .","Modify,Fact/Evidence",Fact/Evidence
11198,9-238,9-238_v2_40@1,9-238_v1_40@1,"The original 1994 Harvard methodology recommends using a disability weight of 0.22 for diseases that limit recreation, occupation, education or procreation activities, and 0.40 if a disease limits two or more of these activities.","The original 1994 WHO methodology recommends using a disability weight of 0.22 for diseases that limit recreation, occupation, education or procreation activities, and 0.40 if a disease limits two or more of these activities.","Modify,Fact/Evidence",Fact/Evidence
11199,9-238,9-238_v2_12@2,9-238_v1_12@2,We excluded patients whose ICD-10 codes for osteoarthritis were registered in hospitalization and patients with previous treatment.,We excluded patients whose ICD-10 codes for osteoarthritis were registered during hospitalization and patients who were previously treated for osteoarthritis.,"Modify,Clarity",Clarity
11200,9-238,9-238_v2_15@0,9-238_v1_15@0,"Variables included sex, age, health center, geographical area, osteoarthritis of the hip (ICD-10: M16), osteoarthritis of the knee (ICD-10: M17), osteoarthritis of first carpometacarpal joint (ICD-10: M18), polyosteoarthritis (ICD-10: M15), unspecified osteoarthritis (ICD-10: M19), death due to osteoarthritis, and time between initial attention for osteoarthritis and death.","Covariates included sex, age, health center, geographical area, osteoarthritis of the hip (ICD-10: M16), osteoarthritis of the knee (ICD-10: M17), osteoarthritis of first carpometacarpal joint (ICD-10: M18), polyosteoarthritis (ICD-10: M15), unspecified osteoarthritis (ICD-10: M19), death due to osteoarthritis, and time between initial attention for osteoarthritis and death.","Modify,Clarity",Clarity
11201,9-238,9-238_v2_16@0,9-238_v1_16@0,"- Life expectancy at time of care delivered: Life expectancy was estimated according to two methods: The original Harvard burden of disease study from 1994 <REF-5> employed the West extended model life tables from level 26 <REF-12> to calculate life expectancy at the time the disability started (in our case, time of osteoarthritis diagnosis). It then applied an age-weighted function, defined by: Cxe -βx , where “x” is the age in years, “C” is the constant of age weighting adjustment (value: 0.16458) and “β” is the age weighting parameter (value: 0.04). This function draws a curve assigning different weights to ages, giving greater values to adult ages since they were considered “more productive”. Additionally, a 3% discount by year was applied, trying to capture the fact that people appreciate years in the immediate future than those further away more. The second method, used in the 2015 GBD study, uses standard life expectancy are based on lowest observed mortality rates in any age group in populations over 5 million and does not time-discounting <REF-13> .","- Life expectancy at time of care delivered: Life expectancy was estimated according to two methods: The original WHO burden of disease study from 1994 <REF-5> employed the West extended model life tables from level 26 <REF-12> to calculate life expectancy at the time the disability started (in our case, time of osteoarthritis diagnosis). It then applied an age-weighted function, defined by: Cxe -βx , where “x” is the age in years, “C” is the constant of age weighting adjustment (value: 0.16458) and “β” is the age weighting parameter (value: 0.04). This function draws a curve assigning different weights to ages, giving greater values to adult ages since they were considered “more productive”. Additionally, a 3% discount by year was applied, trying to capture the fact that people appreciate years in the immediate future than those further away more. The second method, employed in the 2015 GBD study, uses the maximum worldwide life expectancy projected to 2050, does not differentiate between men and women, and does not consider weights or discounts <REF-13> .","Modify,Fact/Evidence",Fact/Evidence
11202,9-257,9-257_v2_33@9,,"Finally, telehealth will play an increasing role in the medical follow-up of patients with TS, likely beyond the end of the pandemic.",,"Add,Claim",Claim
11203,9-257,9-257_v2_33@10,,It will be important to establish whether this type of care will be well accepted by patients and families alike.,,"Add,Claim",Claim
11204,9-257,9-257_v2_41@0,,"Data associated with the article are available under the terms of the Creative Commons Zero ""No rights reserved"" data waiver (CC0 1.0 Public domain dedication).",,"Add,Fact/Evidence",Fact/Evidence
11205,9-257,9-257_v2_19@2,9-257_v1_19@2,"In young children, their comprehension of the situation is limited, but the transmission of parental anxiety is a possible concern, either because of the pandemic itself and/or the economic consequences they face.","In young children, their comprehension of the situation is limited, but the transmission of parental anxiety is a possible concern, either because of the epidemic itself and/or the economic consequences they face.","Modify,Clarity",Clarity
11206,9-257,9-257_v2_20@1,9-257_v1_20@1,"In the current era of governmental and public health instructions designed to slow the spread of COVID-19, patients with contamination OCD are at particular risk of experiencing conflicting demands since their baseline cognitive-behavioural training (CBT) (if applicable) asks for less hand washing, the exact opposite of what is now being recommended: this may result in cognitive dissonance which may turn close to unbearable.","In the current era of governmental and public health instructions designed to slow the spread of COVID-19, patients with contamination OCD are at particular risk of experiencing conflicting demands since their baseline cognitive-behavioural (CBT) training (if applicable) asks for less hand washing, the exact opposite of what is now being recommended: this may result in cognitive dissonance which may turn close to unbearable.","Modify,Clarity",Clarity
11207,9-257,9-257_v2_27@3,9-257_v1_27@3,Touching other people is not an uncommon complex motor tic but in the “COVID-19 climate” could also represent NOSIS (see Table 1 ).,Touching other people is a not an uncommon complex motor tic but in the “COVID-19 climate” could also represent NOSIS (see Table 1 ).,"Modify,Grammar",Grammar
11208,9-257,9-257_v2_3@0,9-257_v1_3@0,Aetiology: COVID-19,Aetiology: COVID-19 (coronavirus),"Modify,Clarity",Clarity
11209,9-257,9-257_v2_30@0,9-257_v1_30@0,Neurotropic effects of SARS-CoV-2,Neurotropic effects of SARS-Cov-2,"Modify,Grammar",Grammar
11210,9-257,9-257_v2_31@0,9-257_v1_31@0,"To date, little is known about the potential neurological effects of SARS-CoV-2 but these have been suggested ( Baig et al. , 2020 ) and there is an evolving observation of high rates of anosmia and hypogeusia even in mild infection which may indicate neurotropism ( Hopkins & Kumar, 2020 ; Lüers et al. , 2020 ).","To date, little is known about the potential neurological effects of SARS-Cov-2 but these have been suggested ( Baig et al. , 2020 ) and there is an evolving observation of high rates of anosmia and hypogeusia even in mild infection which may indicate neurotropism ( Hopkins & Kumar, 2020 ; Lüers et al. , 2020 ).","Modify,Grammar",Grammar
11211,9-257,9-257_v2_31@4,9-257_v1_31@4,"In neurodevelopmental disorders such as GTS – and this also holds true for its comorbidities which are based on circuit dysfunctions – it is, at present, hard to see how a viral infection, and more specifically SARS-CoV-2, could lead to lasting CNS sequelae specific to GTS (for an evolving online resource, see here ).","In neurodevelopmental disorders such as GTS – and this also holds true for its comorbidities which are based on circuit dysfunctions – it is, at present, hard to see how a viral infection, and more specifically SARS-Cov-2, could lead to lasting CNS sequelae specific to GTS (for an evolving online resource, see here ).","Modify,Grammar",Grammar
11212,9-257,9-257_v2_33@5,9-257_v1_33@5,That is obviously true for anti-tic medication as it is for psychostimulants (for ADHD) and selective serotonin reuptake inhibitors (for anxiety and OCD).,That is obviously true for anti-tic medication as it is for psychostimulants (for ADHD) and SSRIs (selective serotonin reuptake inhibitors; for anxiety and OCD).,"Modify,Clarity",Clarity
11213,9-257,9-257_v2_36@8,9-257_v1_36@8,- For health-care professionals: keep up outpatient clinics by telephone or videoconferencing as much as possible. The latter may prove useful even after the pandemic will have abated.,- For health-care professionals: keep up outpatient clinics by telephone or videoconferencing as much as possible. The latter may prove useful even after the epidemic will have abated.,"Modify,Clarity",Clarity
11214,9-257,9-257_v2_5@0,9-257_v1_5@0,The virus that causes COVID-19 is known as SARS-CoV-2 (Severe Acute Respiratory Syndrome Corona Virus 2).,The virus that causes COVID-19 is known as SARS-Cov-2 (Severe Acute Respiratory Syndrome Corona Virus 2).,"Modify,Grammar",Grammar
11215,9-257,9-257_v2_36@9,9-257_v1_36@9,"- Finally, there are no indications that SARS-CoV-2 infections might lead to central nervous system sequelae for patients with GTS in the intermediate or long term. Neither does GTS alone put individuals in a higher risk group for general consequences of infection. If necessary, reassurance is needed in this matter.","- Finally, there are no indications that SARS-Cov-2 infections might lead to central nervous system sequelae for patients with GTS in the intermediate or long term. Neither does GTS alone put individuals in a higher risk group for general consequences of infection. If necessary, reassurance is needed in this matter.","Modify,Grammar",Grammar
11216,9-257,9-257_v2_5@3,9-257_v1_5@3,"Coronaviruses replicate their RNA genomes using enzymes called RNA-dependent RNA polymerases, which are prone to errors, but genomic analysis to date suggests that SARS-CoV-2 is mutating slowly, thus reducing the chance of it changing to become deadlier ( Wu et al. , 2020 ).","Coronaviruses replicate their RNA genomes using enzymes called RNA-dependent RNA polymerases, which are prone to errors, but genomic analysis to date suggests that SARS-Cov-2 is mutating slowly, thus reducing the chance of it changing to become deadlier ( Wu et al. , 2020 ).","Modify,Grammar",Grammar
11217,9-257,9-257_v2_5@4,9-257_v1_5@4,"It is worth mentioning that since 2003, viral diseases have caused major pandemics.","It is worth mentioning that since 2003, viral diseases have caused major epidemics.","Modify,Clarity",Clarity
11218,9-257,9-257_v2_5@5,9-257_v1_5@5,"These include the coronaviruses, which have caused multiple major public health events that resulted in global pandemics such as severe acute respiratory syndrome (SARS; or “bat SARS”), Middle East respiratory syndrome (MERS) and the current coronavirus disease (COVID-19) ( Kandeel et al. , 2020 ).","These include the coronaviruses, which have caused multiple major public health events that resulted in global epidemics such as severe acute respiratory syndrome (SARS; or “bat SARS”), Middle East respiratory syndrome (MERS) and the current coronavirus disease (COVID-19) ( Kandeel et al. , 2020 ).","Modify,Clarity",Clarity
11219,9-257,9-257_v2_10@1,9-257_v1_10@1,"Whereas the PANDAS (Pediatric Autoimmune Neuropsychiatric Disorders Associated with Streptococcal Infections) hypothesis is increasingly being discarded, an immunological trigger is possible in a subset of patients with GTS as they might show differences in immune responses compared to controls ( Martino et al. , 2015 ); however, how these might possibly affect response to viral infections and, more specifically SARS-CoV-2, remains as yet unknown (see below).","Whereas the PANDAS (Pediatric Autoimmune Neuropsychiatric Disorders Associated with Streptococcal Infections) hypothesis is increasingly being discarded, an immunological trigger is possible in a subset of patients with GTS as they might show differences in immune responses compared to controls ( Martino et al. , 2015 ); however, how these might possibly affect response to viral infections and, more specifically SARS-Cov-2, remains as yet unknown (see below).","Modify,Grammar",Grammar
11220,9-257,9-257_v2_12@3,9-257_v1_12@3,"Individuals may have the relatively rare (around 15–20%) but “press-worthy” symptom of coprolalia ( Freeman et al. , 2009 ).",Individuals may have the relatively rare (around 10%) but “press-worthy” symptom of coprolalia (involuntary swearing).,"Modify,Fact/Evidence",Fact/Evidence
11221,9-287,9-287_v2_8@3,,Studies from southern African countries have demonstrated the health and economic benefits of “Treat All” <REF-5> .,,"Add,Fact/Evidence",Fact/Evidence
11222,9-287,9-287_v2_18@0,,"Psychosocial criteria for ART initiation, also included completion of prescribed counselling sessions and an assessment of adherence to cotrimoxazole preventive therapy (CPT) in the past 3 months.",,"Add,Fact/Evidence",Fact/Evidence
11223,9-287,9-287_v2_18@1,,Adherence to CPT was used to assess the likelihood that the patient would adhere to ART.,,"Add,Fact/Evidence",Fact/Evidence
11224,9-287,9-287_v2_19@0,,"If a patient officially transfers-out to another ART clinic, they are issued with a transfer-out letter for presentation at the receiving ART clinic and they maintain their ART number.",,"Add,Fact/Evidence",Fact/Evidence
11225,9-287,9-287_v2_19@1,,"In other instances, patients may unofficially transfer out to another health facility without being assigned a transfer-out letter and are therefore declared lost to follow-up if they exceed 90 days after their last scheduled clinic or drug pick-up visit and all phone-call or physical follow-ups attempts by community health workers to trace them back to care have been futile.",,"Add,Claim",Claim
11226,9-287,9-287_v2_19@2,,The patients will often present at the transfer-in facility with a patient-held ART booklet which indicates their previous medical history and therefore continue receiving ART care whilst also maintaining their ART number.,,"Add,Claim",Claim
11227,9-287,9-287_v2_20@2,,Additional changes in the “Treat All” period included an emphasis for health workers to provide adequate counselling and start ART within a week with exception of pregnant and breast-feeding women who were to be started on ART on the same day of HIV diagnosis.,,"Add,Fact/Evidence",Fact/Evidence
11228,9-287,9-287_v2_20@3,,"However, for those patients who are not ready yet to start ART, they should receive on-going counselling and support.",,"Add,Claim",Claim
11229,9-287,9-287_v2_49@6,,High rates of LTFU before and during “Treat All” may not actually be LTFU but ‘silent transfers’ where patients enrol in a different clinic closer to home without being issued an official transfer-out letter.,,"Add,Claim",Claim
11230,9-287,9-287_v2_49@7,,"Due to stigma and discrimination, people tend to get tested out of their area of residence where they are not known and after enrolment tend to move closer to home for treatment.",,"Add,Claim",Claim
11231,9-287,9-287_v2_50@2,,The programme should consider qualitative systematic enquiry into why the retention did not improve during “Treat All” in Harare.,,"Add,Claim",Claim
11232,9-287,9-287_v2_51@4,,PLHIV transferred out were censored on their date of transfer out as we did not have details about their registration into the ‘transfer in’ ART clinic.,,"Add,Fact/Evidence",Fact/Evidence
11233,9-287,9-287_v2_4@1,9-287_v1_4@1,A cohort of 2289 PLHIV was newly initiated on ART before (April-June 2015) and 1682 during “Treat all” (April-June 2017).,A cohort of 2289 PLHIV were newly initiated on ART before (April-June 2015) and 1682 during “Treat all” (April-June 2017).,"Modify,Grammar",Grammar
11234,9-287,9-287_v2_4@5,9-287_v1_4@5,"Cumulative retention at three, six and 12 months was consistently lower during “Treat all” and was significant at six months (74.9% vs.78.1% p=0.022).","Cummulative retention at three, six and 12 months was consistently lower during “Treat all” and was significant at six months (74.9% vs.78.1% p=0.022).","Modify,Grammar",Grammar
11235,9-287,9-287_v2_8@4,9-287_v1_8@3,"Research in rural South Africa and Malawi demonstrated that after implementation of “Treat All”, people on ART had better retention in care <REF-6> , <REF-7> .","Research in other countries demonstrated that after implementation of “Treat All”, people on ART had better outcomes <REF-2> , <REF-5> – <REF-8> .","Modify,Fact/Evidence",Fact/Evidence
11236,9-287,9-287_v2_9@0,9-287_v1_9@0,"Zimbabwe has a generalized HIV epidemic, with an estimated 1.3 million PLHIV and an HIV prevalence of 14% among adults (15–49 years) as per the ZIMPHIA survey 2015–16 <REF-8> , <REF-9> .","Zimbabwe has a generalized HIV epidemic, with an estimated 1.3 million PLHIV and an HIV prevalence of 14% among adults (15-64 years) <REF-9> – <REF-11> .","Modify,Fact/Evidence",Fact/Evidence
11237,9-287,9-287_v2_13@1,9-287_v1_13@1,We included all PLHIV newly initiated on ART from 50 electronic patient management system (ePMS) sites in Harare before (April–June 2015) and during “Treat All” (April–June 2017).,We included all PLHIV newly initiated on ART from 50 electronic patient management system (ePMS) sites in Harare before (April-June 2015) and during “Treat All” (April-June 2017).,"Modify,Grammar",Grammar
11238,9-287,9-287_v2_15@2,9-287_v1_15@2,"It has the highest number of patients active on ART, with 77 public ART sites providing HIV diagnosis and treatment.","It has the highest number of patients active on ART, with 77 ART sites providing HIV diagnosis and treatment.","Modify,Clarity",Clarity
11239,9-287,9-287_v2_20@1,9-287_v1_19@1,All PLHIV are eligible for ART regardless of CD4 count or WHO clinical staging <REF-10> although baseline CD4 monitoring is still important for determining the degree of immune suppression of a patient in order to inform ‘differentiated care’.,All PLHIV are eligible for ART regardless of CD4 count or WHO clinical staging <REF-12> .,"Modify,Claim",Claim
11240,9-292,,9-292_v1_24@3,,Strategies for limiting cross infection in bathing facilities therefore need to include disinfection of public areas and managing social distancing and other behavior of staff and bathers.,"Delete,Claim",Claim
11241,9-292,9-292_v2_5@2,,"The upper airways also serve as the first line of defence against respiratory viruses by maintaining a protective mucosal barrier that filters and traps foreign particles and pathogens in a layer of watery mucus, and enables them to be identified by the immune system.",,"Add,Claim",Claim
11242,9-292,9-292_v2_10@2,,"Finnish sauna bathing, which involves brief exposures to high environmental temperature (80°C-100°C) has been shown to reduce the risk of all-cause mortality, sudden cardiac death, cardiovascular disease and vascular diseases such as high blood pressure and stroke, along with the risk of neurocognitive diseases, skin conditions and painful conditions such as rheumatic diseases and headache ( Laukkanen et al., 2015 ; Laukkanen et al., 2018 ; Laukkanen & Kunutsor, 2019 ).",,"Add,Fact/Evidence",Fact/Evidence
11243,9-292,9-292_v2_16@1,,"Heat stress improves respiratory function by reducing pulmonary congestion and increasing tidal volume, vital capacity, ventilation, and forced expiratory volume of the lungs ( Laitinen et al., 1988 ), and improves cardiovascular function by modulating the autonomic nervous system, reducing inflammation, oxidative stress and blood pressure, increasing cardiac output, plasma volume and peripheral blood flow, and improving endothelial function, lipid profile and arterial compliance ( Heinonen & Laukkanen 2018 ; Kunutsor et al., 2018 ; Laukkanen et al., 2018 ; Laukkanen & Kunutsor, 2019 ).",,"Add,Fact/Evidence",Fact/Evidence
11244,9-292,9-292_v2_22@3,,"FIR saunas, along with other heat-based technologies may therefore also prove useful in treating patients with COVID-19.",,"Add,Claim",Claim
11245,9-292,9-292_v2_17@3,9-292_v1_13@1,"The ability of a transient alkaline environment to inhibit viral replication and reduce infectivity has been demonstrated with human coronavirus 229E, which has maximal infectivity in acid conditions ( Lamarre & Talbot, 1989 ), and with coronavirus MHV-A59, which undergoes conformational changes in the spike glycoprotein at a pH of 8 at 37°C degrees and leads to rapid and irreversible inactivation and loss of infectivity ( Sturman et al., 1990 ).","The ability of a transient alkaline environment to inhibit viral replication and reduce infectivity has been demonstrated with human coronavirus 229E, which has maximal infectivity in acid conditions ( Lamarre & Talbot, 1989 ), and with coronavirus MHV-A59, which undergoes conformational changes in the spike glycoprotein at a pH of 8 at 37°C degrees, which leads to rapid and irreversible inactivation and loss of infectivity ( Sturman et al., 1990 ).","Modify,Clarity",Clarity
11246,9-292,9-292_v2_18@0,9-292_v1_14@0,"In addition to offering physiological advantages in the battle against viral infection such as COVID-19, heat-based treatments can support mental wellness and confer many psychological benefits.","In addition to offering physiological advantages in the battle against viral infection such as COVID-19, heat also confers many psychological advantages.","Modify,Claim",Claim
11247,9-292,9-292_v2_18@1,9-292_v1_14@1,Sauna bathing and other forms of heat therapy require time and effort devoted towards active relaxation that can help divert attention from anxiety-producing news and/or relieve boredom associated with social confinement.,Sauna bathing and other forms of heat therapy require time and effort to be devoted towards active relaxation that can help divert attention from anxiety-producing news and/or relieve boredom associated with social confinement.,"Modify,Clarity",Clarity
11248,9-292,9-292_v2_9@0,9-292_v1_16@0,The use of heat for cleansing and healing is a conscious extension of mammals’ use of heat that has been practiced throughout human history.,The use of heat for cleansing and healing forms a conscious extension of mammals’ use of heat that has been practiced throughout human history.,"Modify,Clarity",Clarity
11249,9-292,9-292_v2_9@2,9-292_v1_16@2,"Heat-based therapies are not widely used in mainstream medicine, other than the local application of hot packs for symptomatic relief, or the use of novel technologies such as microwaves, radiofrequency energy, ultrasound, infrared radiators, ferromagnetic seeds, nanoparticles and resistive implants that apply heat to treat various cancers ( Chicheł et al., 2007 ).","While heat-based therapies are not widely used in mainstream medicine, other than the local application of hot packs for symptomatic relief, heat-based treatments are standard offerings in wellness establishments, such as hot springs, bathing facilities, gymnasiums, fitness centers, hotels and resorts, where they are used both therapy and recreation ( Clark-Kennedy & Cohen, 2017 ).","Split+Modify,Fact/Evidence",Fact/Evidence
11250,9-292,9-292_v2_9@3,9-292_v1_16@2,"Heat-based treatments however, are standard offerings in wellness establishments, such as hot springs, bathing facilities, gymnasiums, fitness centers, hotels and resorts, where they are used for both therapy and recreation ( Clark-Kennedy & Cohen, 2017 ).","While heat-based therapies are not widely used in mainstream medicine, other than the local application of hot packs for symptomatic relief, heat-based treatments are standard offerings in wellness establishments, such as hot springs, bathing facilities, gymnasiums, fitness centers, hotels and resorts, where they are used both therapy and recreation ( Clark-Kennedy & Cohen, 2017 ).","Split+Modify,Clarity",Clarity
11251,9-292,9-292_v2_10@1,9-292_v1_17@1,"Historical and emerging evidence suggests regular sauna bathing enhances cardiovascular, respiratory and immune function as well as improving mood and quality of life ( Hussain & Cohen, 2018 )( Laukkanen et al., 2018 ).","Historical and emerging evidence suggests regular sauna bathing enhances cardiovascular, respiratory and immune function as well as improving mood and quality of life ( Hussain & Cohen, 2018 ).","Modify,Fact/Evidence",Fact/Evidence
11252,9-292,9-292_v2_10@3,9-292_v1_17@2,"Epidemiological evidence further suggests that frequent sauna bathing is associated with a reduced risk of pneumonia and viral infection ( Kunutsor et al., 2017a ) ( Kunutsor et al., 2017a ; Kunutsor et al., 2017b ), and randomised controlled trial evidence suggests that regular saunas can halve the incidence of respiratory viral infections ( Ernst et al., 1990 ).","Epidemiological evidence further suggests that frequent sauna bathing is associated with a reduced risk of pneumonia and viral infection ( Kunutsor et al., 2017 ), and randomised controlled trial evidence suggests that regular saunas can halve the incidence of respiratory viral infections ( Ernst et al., 1990 ).","Modify,Fact/Evidence",Fact/Evidence
11253,9-292,9-292_v2_10@4,9-292_v1_17@3,"Randomised controlled trials further suggest hot air can treat respiratory infections with humidified air at temperatures above 43°C for 20 to 30 minutes being found to reduce viral shedding, provide immediate relief of symptoms and improve the course of the common cold ( Tyrrell, 1988 ; Tyrrell et al., 1989 ).","Randomised controlled trials further suggest hot air can treat respiratory infection with humidified air at temperatures above 43°C for 20 to 30 minutes being found to reduce viral shedding, giving immediate relief of symptoms and improving the course of the common cold ( Tyrrell, 1988 ; Tyrrell et al., 1989 ).","Modify,Clarity",Clarity
11254,9-292,9-292_v2_2@6,9-292_v1_2@6,"Heat-based treatments also offer psychological benefits and enhanced mental wellness by focusing attention on positive action, enhancing relaxation and sleep, inducing 'forced-mindfulness', and invoking the power of positive thinking and ‘remembered wellness’.","Heat-based treatments also offer psychological benefits by directing focus on positive action, enhancing relaxation and sleep, inducing 'forced-mindfulness', and invoking the power of positive thinking and remembered wellness.","Modify,Claim",Claim
11255,9-292,9-292_v2_20@0,9-292_v1_19@0,There are a range of heat-based interventions that can be used alongside other personal hygiene measures to aid in overcoming COVID-19.,"There are a range of heat-based interventions that can be used alongside social distancing, hand washing and other personal hygiene measures to aid in overcoming COVID-19.","Modify,Clarity",Clarity
11256,9-292,9-292_v2_20@2,9-292_v1_19@2,"The direct application of heat to the upper airways, routinely or at the first signs of infection, may further serve to inhibit or deactivate virions in the place where they first lodge.",The direct application of heat to the upper airways at the first signs of infection may further serve to inhibit or deactivate virions in the place where they first lodge.,"Modify,Clarity",Clarity
11257,9-292,9-292_v2_20@3,9-292_v1_19@3,"This has been demonstrated in vitro with temperatures of 45°C for 20 minutes activating immune cells, releasing HSPs and suppressing rhinovirus multiplication by more than 90% ( Conti et al., 1999 ).","This has been demonstrated in vitro with temperatures of 45°C for 20 minutes activating immune cells and releasing HSPs while suppressing rhinovirus multiplication by more than 90% ( Conti et al., 1999 ).","Modify,Clarity",Clarity
11258,9-292,9-292_v2_21@1,9-292_v1_20@1,"Enhanced immunity has been demonstrated with hyperthermia induced by traditional Finnish saunas ( Pilch et al., 2013 ), far-infrared saunas ( Sobajima et al., 2018 ), heated nano-mist ( Tomiyama et al., 2015 ), hot baths ( Downing et al., 1988 ; Kappel et al., 1991 ; Tsuchiya et al., 2003 ; Zellner et al., 2002 ) and geothermal mineral water ( Uzunoglu et al., 2017 ).","Enhanced immunity has been demonstrated with hyperthermia induced by traditional Finnish saunas ( Pilch et al., 2013 ), far-infrared saunas ( Sobjima, 2018 ), heated nano-mist ( Tomiyama et al., 2015 ), hot baths ( Downing et al., 1988 ; Kappel et al., 1991 ; Tsuchiya et al., 2003 ; Zellner et al., 2002 ) and geothermal mineral water ( Uzunoglu et al., 2017 ).","Modify,Fact/Evidence",Fact/Evidence
11259,9-292,9-292_v2_21@2,9-292_v1_20@2,"The beneficial effects of heat-stress may be further potentiated by the traditional practice of alternating heat with exposure to cold, which may translate into greater resistance to viral infections as evidenced by a randomised controlled trial that found regular hot and cold showers reduced work absenteeism during an influenza outbreak ( Buijze et al., 2016 ).","The beneficial effects of heat-stress may be further potentiated by the traditional practice of alternating heat with exposure to cold, which has been shown to increase NK cell count and activity and raise circulating levels of IL-6 and norepinephrine ( Brenner et al., 1999 ).","Merge+Modify,Fact/Evidence",Fact/Evidence
11260,9-292,9-292_v2_21@2,9-292_v1_20@3,"The beneficial effects of heat-stress may be further potentiated by the traditional practice of alternating heat with exposure to cold, which may translate into greater resistance to viral infections as evidenced by a randomised controlled trial that found regular hot and cold showers reduced work absenteeism during an influenza outbreak ( Buijze et al., 2016 ).","This may translate into greater resistance to viral infections as evidenced by a randomised controlled trial that found regular hot and cold showers reduced work absenteeism during an influenza outbreak ( Buijze et al., 2016 ).","Merge+Modify,Clarity",Clarity
11261,9-292,9-292_v2_2@0,9-292_v1_2@0,Enveloped viruses such as SAR-CoV-2 are sensitive to heat and are destroyed by temperatures tolerable to humans.,Enveloped viruses such as SAR-CoV-2 are sensitive to temperature and are destroyed by temperatures tolerable to humans.,"Modify,Clarity",Clarity
11262,9-292,9-292_v2_22@1,9-292_v1_21@1,These saunas use infrared emitters without water or added humidity and generally run at lower temperatures than Finnish saunas.,These saunas use infrared emitters without water or humidity and generally run at lower temperatures than Finnish saunas.,"Modify,Clarity",Clarity
11263,9-292,9-292_v2_22@2,9-292_v1_21@2,"While the use of FIR saunas to treat viral infection has not been studied, FIR radiation is reported to deactivate single-strand RNA viruses ( Huang & Li, 2020 ) and FIR saunas have been shown to raise body temperature, induce hormetic stress responses and support host defenses ( Shemilt et al., 2019 ).","While the use of FIR saunas to treat viral infection has not been studied, FIR radiation is reported to deactivate single-strand RNA viruses ( Huang & Li, 2020 ) and FIR saunas have been shown to raise body temperature and induce hormetic stress responses, which support host defenses ( Shemilt et al., 2019 ).","Modify,Clarity",Clarity
11264,9-292,9-292_v2_23@3,9-292_v1_22@1,"Hydro-therapy treatment plans also need to consider timing, temperature and humidity, as water is 25 times more conductive than air, making steam rooms tolerable at temperatures around 50°C while dry saunas are tolerated at temperatures above 100°C.","Heat-based clinical protocols must consider temperature, timing and individual tolerance, along with humidity, as water is 25 times more conductive than air, making steam rooms tolerable at temperatures around 50°C while dry saunas can be tolerated at temperatures above 100°C.","Modify,Clarity",Clarity
11265,9-292,9-292_v2_23@1,9-292_v1_22@2,"While sauna bathing is generally well tolerated, heat-based clinical protocols are needed to design future studies and inform clinical practice in order to minimise the risk of cross-infection and reduce the incidence of adverse effects, which can range from burns, cramps, dizziness and fainting, to heat exhaustion, heat stroke and death.","Clinical protocols are needed to design future studies and inform clinical practice and while sauna bathing is generally well tolerated, protocols must consider contra-indications such as unstable angina, severe infection, high fever, or concomitant alcohol consumption ( Hannuksela & Ellahham, 2001 ) and the risk of adverse events, such as fainting, dizziness and burns, along with the risk of cross-infection.","Split+Modify,Claim",Claim
11266,9-292,9-292_v2_23@2,9-292_v1_22@2,"Such protocols must therefore consider contra-indications such as unstable angina, severe infection or high fever ( Hannuksela & Ellahham, 2001 ) along with factors such as age, weight, fitness, hydration status, co-morbidities and the use of alcohol or prescription drugs ( Leyk et al., 2019 ).","Clinical protocols are needed to design future studies and inform clinical practice and while sauna bathing is generally well tolerated, protocols must consider contra-indications such as unstable angina, severe infection, high fever, or concomitant alcohol consumption ( Hannuksela & Ellahham, 2001 ) and the risk of adverse events, such as fainting, dizziness and burns, along with the risk of cross-infection.","Split+Modify,Fact/Evidence",Fact/Evidence
11267,9-292,9-292_v2_24@1,9-292_v1_23@1,"The current pandemic has seen the fear of infection lead to the widespread closure of public facilities such as bathing facilities, commercial hot springs, spas, gymnasiums, hotels and fitness centers that offer saunas and heat treatments, and while some countries such as Finland have a large number of private saunas, in most other locations private sauna ownership is limited to people with high socio-economic status.","The current pandemic has seen the fear of infection lead to the widespread closure of public facilities that offer saunas and heat treatments, such as bathing facilities, commercial hot springs, spas, gymnasiums, hotels and fitness centers, and while some countries such as Finland have a large number of private saunas, in most other locations private sauna ownership is limited to people with high socio-economic status.","Modify,Clarity",Clarity
11268,9-292,9-292_v2_24@2,9-292_v1_23@2,"Thus, if sauna bathing is to be widely implemented, public bathing and sauna facilities will need to re-open and adopt infection control measures similar to those for dealing with COVID-19 in other public facilities ( Liang, 2020 ).","Thus, if sauna bathing is to be widely implemented, public bathing and sauna facilities will need to adopt infection control measures similar to those for dealing with COVID-19 in hospitals and medical facilities ( Liang, 2020 ).","Modify,Clarity",Clarity
11269,9-292,9-292_v2_25@2,9-292_v1_24@2,"While the temperatures, humidity and times required to specifically deactivate SAR-CoV-2 in vivo are yet to be determined, the temperature within a sauna makes risk of cross infection in public sauna facilities highly unlikely.","While the temperatures, humidity and times required to specifically deactivate SAR-CoV-2 in vivo are yet to be determined, the temperature within a sauna makes risk of cross infection in public facilities more likely to arise in changing rooms and ancillary spaces rather than within saunas themselves.","Modify,Claim",Claim
11270,9-292,9-292_v2_26@0,9-292_v1_25@0,"Strategies for limiting cross infection have been recently developed for re-opening some of the 3000 hot springs that were recently closed in China ( Wang, 2020 ).","Strategies for limiting cross infection, including procedures for maintaining social distancing by limiting group size, have been recently developed for re-opening some of the 3000 hot springs that were recently closed in China ( Wang, 2020 ).","Modify,Fact/Evidence",Fact/Evidence
11271,9-292,9-292_v2_28@0,9-292_v1_27@0,"Heat is a cheap, convenient and widely accessible therapeutic modality with a long history of traditional use, yet it remains to be seen if heat can be effective in the treatment or prevention of COVID-19.","Heat is a cheap, convenient and widely accessible therapeutic modality with a long history of traditional use, yet it remains to be seen whether heat can be effective in the treatment or prevention of COVID-19.","Modify,Clarity",Clarity
11272,9-292,9-292_v2_4@1,9-292_v1_4@1,"Enveloped viruses, such as rhinoviruses and coronaviruses, are most active in cool dry conditions, which are associated with increased occurrence of respiratory tract infections ( Mäkinen et al., 2009 ), including infections with SARS-CoV ( Chan et al., 2011 ) and SAR-CoV-2 ( Sajadi et al., 2020 ; Wang et al. , 2020 ).","Enveloped viruses, such as rhinoviruses and coronaviruses, are most active in cool dry conditions, which are associated with increased occurrence of respiratory tract infections ( Makinen et al., 2009 ), including infections with SARS-CoV ( Chan et al., 2011 ) and SAR-CoV-2 ( Sajadi et al., 2020 ; Wang et al. , 2020 ).","Modify,Grammar",Grammar
11273,9-292,9-292_v2_5@0,9-292_v1_5@0,"The first line of defence against respiratory viruses is the nasal cavity and sinuses, which maintains a protective mucosal barrier that allows viruses to be trapped, identified by the immune system and swept away, as well as serving an important thermoregulatory role.","The first line of defence against respiratory viruses is the nasal cavity and sinuses, which maintains a protective mucosal barrier that allows viruses to be trapped, identified by the immune system and then swept away, as well as serving an important thermoregulatory role.","Modify,Clarity",Clarity
11274,9-292,9-292_v2_5@1,9-292_v1_5@1,"The nasal cavity and sinuses in humans constantly exchanging heat with inhaled air through convection, conduction and evaporation, which serves to cool inhaled air in summer and warm and humidify air in winter ( Soni & Nayak, 2019 ).","The upper airways are constantly exchanging heat with inhaled air through convection, conduction and evaporation, which serves to cool inhaled air in summer and warm and humidify air in winter ( Soni & Nayak, 2019 ).","Modify,Clarity",Clarity
11275,9-292,9-292_v2_5@3,9-292_v1_5@2,"This mucus is then moved by cilia towards the pharynx, where it is either swallowed or expelled by coughing, sneezing and nose blowing.","The upper airways also filter inhaled air and trap foreign particles and pathogens in a layer of watery mucus that is continually moved by cilia towards the pharynx, where it is either swallowed or expelled by coughing, sneezing and nose blowing.","Modify,Claim",Claim
11276,9-292,9-292_v2_7@0,9-292_v1_7@0,"If respiratory viruses get past the first line of defence, fever is produced as part of the acute phase response, which forms the immune system’s second line of defence.","If respiratory viruses get past the first line of defence, fever is produced as part of the acute phase response which forms the immune system’s second line of defence.","Modify,Grammar",Grammar
11277,9-292,9-292_v2_7@1,9-292_v1_7@1,Fever is a cardinal response to infection that has been conserved within vertebrates for more than 600 million years.,Fever is a cardinal response to infection that has been conserved throughout vertebrates for more than 600 million years.,"Modify,Grammar",Grammar
11278,9-292,9-292_v2_13@2,9-292_v1_10@0,Inhalation of hot air supports the immune system’s first line of defence by direct inhibition or deactivation of virions in the upper airways where they first lodge.,"Inhalation of hot air can support the immune system’s first line of defence by directly inhibiting or deactivating virions in the upper airways where they first lodge and supporting muco-ciliary clearance, which can be further enhanced by inhalation of steam ( Gujrathi et al., 2016 ).","Split+Modify,Clarity",Clarity
11279,9-292,9-292_v2_13@3,9-292_v1_10@0,"Inhalation of hot humid air also supports muco-ciliary clearance, which can be further enhanced by inhalation of steam ( Gujrathi et al., 2016 ).","Inhalation of hot air can support the immune system’s first line of defence by directly inhibiting or deactivating virions in the upper airways where they first lodge and supporting muco-ciliary clearance, which can be further enhanced by inhalation of steam ( Gujrathi et al., 2016 ).","Split+Modify,Clarity",Clarity
11280,9-292,9-292_v2_13@0,9-292_v1_10@2,Hyperthermia and heat stress have multiple actions that may help mitigate viral infections.,"Fever has multiple actions when dealing with infections that includ direct inhibition of pathogens, stimulation of both the innate and adaptive arms of the immune system and activation of regulatory processes that serve to dampen inflammatory responses and avoid excessive tissue damage during the return to thermal homeostasis ( Evans et al., 2015 ).","Split+Modify,Claim",Claim
11281,9-292,9-292_v2_13@1,9-292_v1_10@2,"These include direct inhibition of pathogens, stimulation of both the innate and adaptive arms of the immune system and activation of regulatory processes that dampen inflammatory responses and prevent excessive tissue damage ( Evans et al., 2015 ).","Fever has multiple actions when dealing with infections that includ direct inhibition of pathogens, stimulation of both the innate and adaptive arms of the immune system and activation of regulatory processes that serve to dampen inflammatory responses and avoid excessive tissue damage during the return to thermal homeostasis ( Evans et al., 2015 ).","Split+Modify,Clarity",Clarity
11282,9-292,9-292_v2_2@3,9-292_v1_2@3,"In the initial phase of infection, heat applied to the upper airways can support the immune system’s first line of defence by supporting muco-ciliary clearance and inhibiting or deactivating virions where they first lodge.","In the initial phase of infection, heat applied to the upper airways can support the immune system’s first line of defence by supporting muco-ciliary clearance and inhibiting or deactivating virions in the place where they first lodge.","Modify,Clarity",Clarity
11283,9-292,9-292_v2_15@0,9-292_v1_11@2,"Acute heat stress has been shown to increase the TNF-alpha response of monocytes ( Zellner et al., 2002 ), enhance interleukin-2 induced activity of Natural Killer (NK) cells ( Kappel et al., 1991 ), and cause a 10-fold increase in interferon-γ production by T-lymphocytes ( Downing et al., 1988 ) while regular heat-stress has been shown to reduce adrenaline and cortisol, increase the cytotoxicity of NK cells, and enhance the proliferative response of B cells ( Tomiyama et al., 2015 ).","Acute heat stress has also been shown to increase the TNF-alpha response of monocytes ( Zellner et al., 2002 ), enhance interleukin-2 induced activity of Natural Killer (NK) cells ( Kappel et al., 1991 ), and cause a 10-fold increase in interferon-γ production by T-lymphocytes ( Downing et al., 1988 ).","Merge+Modify,Clarity",Clarity
11284,9-292,9-292_v2_15@0,9-292_v1_11@3,"Acute heat stress has been shown to increase the TNF-alpha response of monocytes ( Zellner et al., 2002 ), enhance interleukin-2 induced activity of Natural Killer (NK) cells ( Kappel et al., 1991 ), and cause a 10-fold increase in interferon-γ production by T-lymphocytes ( Downing et al., 1988 ) while regular heat-stress has been shown to reduce adrenaline and cortisol, increase the cytotoxicity of NK cells, and enhance the proliferative response of B cells ( Tomiyama et al., 2015 ).","Regular heat-stress has also been shown to reduce adrenaline and cortisol, increase the cytotoxicity of NK cells, and enhance the proliferative response of B cells ( Tomiyama et al., 2015 ).","Merge+Modify,Clarity",Clarity
11285,9-292,9-292_v2_17@0,9-292_v1_12@0,"Heat stress also aids in detoxification via sweating ( Crinnion, 2011 ) through which some toxic elements are preferentially excreted ( Genuis et al., 2011 ).","In addition to enhancing cellular responses, heat-stress increases cardiac output, plasma volume and peripheral blood flow, and induces detoxification through the liver and kidneys, as well as through the skin via sweating ( Crinnion, 2011 ) through which some toxic elements are preferentially excreted ( Genuis et al., 2011 ).","Modify,Fact/Evidence",Fact/Evidence
11286,9-292,9-292_v2_16@0,9-292_v1_12@1,"In addition to enhancing cellular responses, heat-stress induces a hormetic stress response that builds physiological resilience and confers tolerance to subsequent stress in a similar way to exercise ( Gálvez et al., 2018 ).","Heat-stress also induces a hormetic stress response that builds physiological resilience and confers tolerance to subsequent stress in a similar way to exercise ( Gálvez et al., 2018 ).","Modify,Clarity",Clarity
11287,9-292,9-292_v2_17@1,9-292_v1_12@2,"Furthermore, when heat stress is followed by cold exposure, blood is shunted to the internal organs, which induces a diuresis ( Epstein, 1978 ), and further aids in detoxification ( Cochrane, 2004 ).","The effects of heat stress may be further enhanced when it is followed by intermittent cold exposure, which shunts blood to internal organs and induces a diuresis ( Epstein, 1978 ), and further aids in detoxification ( Cochrane, 2004 ).","Modify,Clarity",Clarity
11288,9-292,9-292_v2_15@2,9-292_v1_12@3,"The immunostimulatory effects of heat stress on the innate immune system may be further enhanced by alternating heat exposure with exposure to cold ( Heinonen & Laukkanen, 2018 ), which leads to leukocytosis, granulocytosis, an increase in NK cell count and activity, and an elevation in circulating levels of IL-6 ( Brenner et al., 1999 ).","Heat-stress also enhances the immunostimulatory effects of cold exposure on the innate immune system, which include leukocytosis, granulocytosis, an increase in NK cell count and activity, and an elevation in circulating levels of IL-6 ( Brenner et al., 1999 ).","Modify,Clarity",Clarity
11289,9-302,9-302_v2_29@10,,"The slow efflux of this ligand (probably due to HaloTag Oregon Green ligand deacetylation; Technical Manual, HaloTag Technology) almost certainly underlies the initial decay of Oregon Green fluorescence ( Figure 6D ).",,"Add,Claim",Claim
11290,9-302,9-302_v2_29@12,,A second potential confound concerns the constancy of mTurq2 fluorescence (used here to normalize HaloTag ligand fluorescence).,,"Add,Claim",Claim
11291,9-302,9-302_v2_29@13,,"As shown in Figure 4D , a small decline was observed in some, but not all neurons, probably due to photobleaching (~13±16%, average ± standard deviation, 10 hours for all cells shown in Figure 4 – Figure 6 ) indicating that absolute JF635HT/mTurq2 increase rates might have been slightly overestimated.",,"Add,Fact/Evidence",Fact/Evidence
11292,9-302,9-302_v2_43@6,,"At later time points, however, the latter assumption was not always valid, as mTurq2 fluorescence declined slightly in some neurons, possibly due to mTurq2 photobleaching.",,"Add,Claim",Claim
11293,9-302,9-302_v2_43@7,,"Thus, quantitative assessments of protein synthesis rates based on this approach will require corrections for these potential confounds, as well as others, such as ligand photobleaching, efflux and unbinding, as well as HaloTag and FP maturation kinetics.",,"Add,Claim",Claim
11294,9-302,9-302_v2_24@1,9-302_v1_24@1,"Cell death was found to be negligible at all concentrations and treatment durations tested (0.89±0.44%, average ± standard deviation; maximum ~2% cell death) with no dependence whatsoever on CPXH concentration or exposure duration ( Figure 2E ).","Cell death was found to be negligible at all concentrations and treatment durations tested (0.89±0.44%, average ± standard deviation; maximum ~2% cell death) with no dependence whatsoever on CPXH concentration or exposure duration.","Modify,Fact/Evidence",Fact/Evidence
11295,9-302,9-302_v2_24@2,9-302_v1_24@2,"Furthermore, in networks of rat cortical neurons grown on multielectrode arrays <REF-40> , levels of spontaneous network activity - a sensitive measure of neuronal viability - did not decline following chronic exposure to 10 µM CPXH for 18 and 47 hours ( Figure 2F ; two experiments).","Furthermore, in networks of rat cortical neurons grown on multielectrode arrays <REF-40> , levels of spontaneous network activity - a sensitive measure of neuronal viability - did not decline following chronic exposure to 10 µM CPXH for 18 and 47 hours (two experiments; see Underlying data <REF-38> ).","Modify,Fact/Evidence",Fact/Evidence
11296,9-302,9-302_v2_29@1,9-302_v1_29@1,"To that end, we performed single and dual-labeling time-lapse experiments of neurons expressing HaloTag-mTurq2, using CPXH at concentrations derived from the experiments in HEK293 cells ( Figure 2 ) to block residual binding sites before applying the (second) label.","To that end, we performed single and dual-labeling time-lapse experiments of neurons expressing HaloTag-mTurq2, using CPXH to block residual binding sites before applying the (second) label.","Modify,Fact/Evidence",Fact/Evidence
11297,9-302,9-302_v2_29@6,9-302_v1_29@6,"To correct for nonspecific label accumulation, fluorescence values in neighboring mTurq2-negative areas were obtained at each time point and subtracted from JF635HT / Oregon Green fluorescence in mTurq2-positive cells.","To correct for nonspecific label accumulation, fluorescence values in neighboring mTurq2-negative cells were obtained at each time point and subtracted from JF635HT / Oregon Green fluorescence in mTurq2-positive cells.","Modify,Clarity",Clarity
11298,9-302,9-302_v2_29@9,9-302_v1_29@9,"Interestingly, we noted that labeling with Oregon Green ligand was associated with strong, non-specific labeling in all cells (mTurq2-positive and negative alike) that tended to wash out relatively slowly (over a few hours), in particular from cell bodies and thick neuronal processes.","Interestingly, we noted that labeling with Oregon Green ligand was associated with strong, non-specific labeling that washed out relatively slowly.","Modify,Fact/Evidence",Fact/Evidence
11299,9-302,9-302_v2_44@0,9-302_v1_44@0,"The affinity, cell entry, binding or washout kinetics of CPXH were not measured here or compared with those of 7-bromoheptanol, and thus their advantages and disadvantages with respect to each other remain unknown.","The cell entry, binding kinetics and affinity of CPXH were not compared here to those of 7-bromoheptanol and thus their advantages and disadvantages with respect to each other remain unknown.","Modify,Clarity",Clarity
11300,9-302,9-302_v2_8@2,9-302_v1_8@2,"Notably, ligands can remain in the cells even after multiple washes (due to slow efflux and reduced active clearance capability, especially in unhealthy cells or at low serum levels (Promega Technical Manual, HaloTag® Technology: Focus on Imaging ; see also <REF-32> ).","Notably, ligands can remain in the cells even after multiple washes (due to slow efflux and reduced active clearance capability, especially in unhealthy cells or at low serum levels; Promega “Focus on Imaging” HaloTag protocol; see also <REF-32> ).","Modify,Clarity",Clarity
11301,9-34,9-34_v2_14@10,9-34_v1_14@10,"In terms of genetic modifications, the development of the human brain therefore appears to be based on extending already existing features through gradual and common mechanisms, rather than being the result of a genetic quantum leap.","In terms of genetic modifications, the development of the human brain therefore appears to be based on extending already existing features through gradual and common mechanisms, rather than being the result of a developmental quantum leap.","Modify,Claim",Claim
11302,9-34,9-34_v2_23@4,9-34_v1_23@4,"It was therefore not the pre-existence of an articulate vocalisation, but only a physiological potential for it, that was sufficient for allowing the evolution of HI in humans.","It is therefore not the capacity for an articulate vocalisation, but only a predisposition for it, that is essential to the evolution of HI.","Modify,Claim",Claim
11303,9-34,9-34_v2_25@1,9-34_v1_25@1,"Thus, current evidence suggests that the capacity for developing a HI-supporting system of communication is not a feature strictly limited to humans or the human brain anatomy or speech production.","Thus, current evidence suggests that the evolution of a HI-supporting language is not a feature strictly limited to humans or the human brain anatomy or speech production.","Modify,Clarity",Clarity
11304,9-34,9-34_v2_29@3,9-34_v1_29@3,"Moreover, the complex cognitive abilities of some bird species (including tool use, episodic-like memory, predicting the behaviour of conspecifics based on own experiences and self-recognition) are produced by brains that are less than 10 g in weight <REF-75> .","Moreover, the complex cognitive abilities of some bird species (including tool use, episodic-like memory, predicting the behavior of conspecifics based on own experiences and self-recognition) are produced by brains that are less than 10 g in weight <REF-74> .","Modify,Grammar",Grammar
11305,9-34,9-34_v2_38@4,9-34_v1_38@4,"A possible additional explanation may be that the main barrier towards HI is not only the development of the required physical assets, but also that negative feedback from social, behavioural and neuroanatomical complexity, as well as negative environmental feedback make the development of HI increasingly unfavourable.","A possible additional explanation may be that the main barrier towards HI is not only the development of the required physical assets, but also that negative feedback from social, behavioural and molecular complexity, as well as negative environmental feedback make the development of HI increasingly unfavourable.","Modify,Clarity",Clarity
11306,9-34,9-34_v2_12@5,9-34_v1_12@5,"Additionally, if the competitive advantage and driving force of HI development lies in overcoming dependence of the environment <REF-14> , or enables favourable niche construction <REF-15> , then this advantage would profit many species, and hence is not a limiting factor.","Additionally, if the competitive advantage and driving force of HI development lies in overcoming dependence of the environment <REF-14> , then this advantage would profit many species, and hence is not a limiting factor.","Modify,Fact/Evidence",Fact/Evidence
11307,9-353,9-353_v2_27@7,,"CellProfiler (version 3.1.9) was used to quantify the percentage of cells immunopositive for SOX2, TBR2, and APOE at the intracellular regions.",,"Add,Fact/Evidence",Fact/Evidence
11308,9-353,9-353_v2_27@9,,Raw dataset for the quantification is available as an underlying data via Figshare (doi: 10.6084/m9.figshare.12781604.v1 ).,,"Add,Fact/Evidence",Fact/Evidence
11309,9-353,9-353_v2_43@0,,"In this study, qualitative analysis was performed on APOE immunocytochemistry results.",,"Add,Fact/Evidence",Fact/Evidence
11310,9-353,9-353_v2_43@1,,"As the cells became more differentiated from NSCs to NPCs, APOE localisation pattern became more intracellular.",,"Add,Fact/Evidence",Fact/Evidence
11311,9-353,9-353_v2_43@2,,"To validate this observation, however, additional experiments with a more direct quantitative approach should be conducted.",,"Add,Claim",Claim
11312,9-353,9-353_v2_43@3,,"For example, APOE protein levels in various subcellular compartments could be measured and compared by performing Western Blot.",,"Add,Claim",Claim
11313,9-353,9-353_v2_43@4,,"Since APOE has been shown to exist in both secreted and intracellular forms ( Huang & Mahley, 2014 ), it will be interesting to see which form of APOE is produced at each differentiation stage.",,"Add,Claim",Claim
11314,9-353,9-353_v2_43@5,,"It is possible that more APOE is secreted in undifferentiated cells compared to differentiated cells, which may not be fully captured using immunocytochemistry techniques performed on fixed cells.",,"Add,Claim",Claim
11315,9-353,9-353_v2_43@6,,"Interestingly, Gan and colleagues previously reported that APOE is indeed secreted by NSCs as well as NPCs, and secreted APOE was found to play a vital role in regulating NSC survival and neurosphere formation ( Gan et al. , 2011 ).",,"Add,Fact/Evidence",Fact/Evidence
11316,9-353,9-353_v2_43@7,,"Therefore, further investigations on secreted and intracellular APOE using quantitative approaches will be able to clarify whether cells indeed produce different forms and levels of APOE depending on its differentiation state.",,"Add,Claim",Claim
11317,9-353,9-353_v2_43@8,,This will in turn provide more definitive clues to whether APOE plays a stage-dependent role in neurodevelopment.,,"Add,Claim",Claim
11318,9-353,9-353_v2_44@0,,One limitation of this study is that the time-dependent changes of differentiation markers such as SOX2 and TBR2 were not examined alongside APOE.,,"Add,Fact/Evidence",Fact/Evidence
11319,9-353,9-353_v2_44@1,,"It is worth noting, however, that TBR2 was shown to be capable of suppressing SOX2 expression during differentiation of NSCs to NPCs ( Hodge et al. , 2012 ).",,"Add,Fact/Evidence",Fact/Evidence
11320,9-353,9-353_v2_44@2,,"Given this information, it is unlikely that TBR2-positive cells observed in this study at D18/19 will simultaneously express high levels of SOX2.",,"Add,Claim",Claim
11321,9-353,9-353_v2_44@3,,"However, time-dependent changes of various markers of differentiation would add further validity to our observations and unequivocally clarify whether APOE expression is indeed correlated with the differentiation state of the cells.",,"Add,Claim",Claim
11322,9-353,9-353_v2_44@4,,Another limitation of this study is that the exact locus of APOE expression could not be examined in detail using a standard epifluorescence microscope in this study.,,"Add,Claim",Claim
11323,9-353,9-353_v2_44@5,,High-resolution microscopy techniques (such as confocal microscopy) would have been more ideal to identify the accurate loci of APOE expression and overcome the challenges of imaging densely packed cells at the earliest stages of neural induction (D0–D7).,,"Add,Claim",Claim
11324,9-353,9-353_v2_44@6,,Further investigations with improved imaging capacity will therefore allow us to characterise APOE during the earlier stages of neural induction and hint at potential mechanisms underlying its role in neurodevelopment.,,"Add,Claim",Claim
11325,9-353,9-353_v2_45@0,,"Since NSCs derived from iPSCs in vitro may not fully resemble the developmental and postnatal NSCs found in vivo , APOE expression should be further investigated in animal models of brain development as well.",,"Add,Claim",Claim
11326,9-353,9-353_v2_45@1,,"The most direct evidence of in vivo APOE expression in NSCs to this date comes from a study by Yang and colleagues, where Nestin-positive NSCs in the mouse developing dentate gyrus was isolated using fluorescence-activated cell sorting, and APOE expression was examined from as early as postnatal day 7 (P7) ( Yang et al. , 2011 ).",,"Add,Fact/Evidence",Fact/Evidence
11327,9-353,9-353_v2_45@2,,"NSCs at P7 had low expression of APOE which increased with the age of mice, and the deletion of APOE had detrimental effects on the maintenance of stem cells in the dentate gyrus.",,"Add,Fact/Evidence",Fact/Evidence
11328,9-353,9-353_v2_45@3,,"Although these findings clearly demonstrate the importance of APOE in brain development, the study had limitations in that prenatal NSCs were not examined, and functional studies of APOE were based on global rather than conditional knockouts.",,"Add,Claim",Claim
11329,9-353,9-353_v2_45@4,,"Furthermore, Yang and colleagues’ data cannot be directly compared with our dataset due to species difference and the lack of detailed characterisation of NSCs in this study.",,"Add,Claim",Claim
11330,9-353,9-353_v2_45@5,,"To address this knowledge gap, more data from both in vitro and in vivo samples derived from various species should be generated and compared against each other.",,"Add,Claim",Claim
11331,9-353,9-353_v2_45@6,,We hope that our focused study has laid a strong foundation to such collaborative investigations that may be conducted in the future.,,"Add,Claim",Claim
11332,9-353,9-353_v2_59@0,,This project contains the following underlying data:,,"Add,Fact/Evidence",Fact/Evidence
11333,9-353,9-353_v2_24@0,9-353_v1_24@0,"Total RNA was extracted from D7, D12, D15/16, and D18/19 cells that were not used for neural passaging with TRIzol® reagent (Thermo Fisher) according to manufacturer’s instructions and eluted in 25–30 µL of diethyl pyrocarbonate (DEPC)-treated water.","Total RNA was extracted from D7, D12, D15/16, and D18/19 cells that were not used for neural passaging with TRIzol® reagent (Thermo Fisher) according to manufacturer’s instructions and eluted in 25-30 µL of diethyl pyrocarbonate (DEPC)-treated water.","Modify,Grammar",Grammar
11334,9-353,9-353_v2_6@0,9-353_v1_6@0,"Apolipoprotein E (APOE) is a pleiotropic protein that plays an important role in lipid metabolism ( Mahley & Rall, 2000 ) and is highly expressed in the brain mainly by glial cells ( Boyles et al. , 1985 ; Elshourbagy et al. , 1985 ).","Apolipoprotein E (APOE) is a pleiotropic protein that plays an important role in lipid metabolism ( Mahley & Rall, 2000 ) and is highly expressed in the brain ( Elshourbagy et al. , 1985 ).","Modify,Fact/Evidence",Fact/Evidence
11335,9-353,9-353_v2_27@0,9-353_v1_27@0,"Cells were fixed with 4% paraformaldehyde for 10 mins at room temperature, permeabilized with 0.1% Triton™ X-100 in 1X Tris-buffered saline (TBS) for 15–30 minutes, and then blocked with 5% normal donkey serum in TBS for 30 minutes.","Cells were fixed with 4% paraformaldehyde, permeabilized with 0.1% Triton™ X-100 in 1X Tris-buffered saline (TBS) for 15–30 minutes, and then blocked with 5% normal donkey serum in TBS for 30 minutes.","Modify,Fact/Evidence",Fact/Evidence
11336,9-353,9-353_v2_6@1,9-353_v1_6@1,"Although the primary function of APOE is lipid transport, its expression is also found in other cell types outside the context of lipid metabolism in the brain ( Liao et al. , 2017 ).","Although the primary function brain APOE is lipid transport, its expression is also found in other cell types outside the context of lipid metabolism ( Liao et al. , 2017 ).","Modify,Clarity",Clarity
11337,9-353,9-353_v2_27@8,9-353_v1_27@7,Raw dataset for the images is available as an underlying data via Figshare (doi: 10.6084/m9.figshare.12199745.v1 ).,Raw dataset is available as an underlying data via Figshare (doi: 10.6084/m9.figshare.12199745.v1 ).,"Modify,Fact/Evidence",Fact/Evidence
11338,9-353,9-353_v2_36@2,9-353_v1_36@2,"Qualitative analysis of immunocytochemistry results revealed that ApoE became more localised to the intracellular region at D18/19 compared to D12 ( Figure 3 ; ( Lee, 2020c ; Lee, 2020d )).","Qualitative analysis of immunocytochemistry results revealed that ApoE became more localised to the intracellular region at D18/19 compared to D12 ( Figure 2C ; ( Lee, 2020c )).","Modify,Fact/Evidence",Fact/Evidence
11339,9-353,9-353_v2_46@0,9-353_v1_41@0,"In conclusion, we report that human APOE gene expression levels are highly correlated with the undifferentiated state of cells during directed differentiation in vitro , and ApoE protein is localised more in the intracellular region in cells at later stages of differentiation.","In conclusion, we report that human APOE gene expression levels are highly correlated with the undifferentiated state of cells during directed differentiation in vitro , and ApoE protein is more clearly localised in the intracellular region as the cells become more differentiated.","Modify,Clarity",Clarity
11340,9-353,9-353_v2_46@1,9-353_v1_41@1,"Combining our observations and previous evidence reported in the literature, we speculate that APOE has an important role in stem cell maintenance and propose that further investigations should be carried out to validate our findings including methods that were not employed in this study.","Combining our observations and previous evidence reported in the literature, we speculate that APOE has an important role in stem cell maintenance and propose that further investigations should be carried out to investigate the exact underlying mechanisms such as 1) whether APOE is an upstream or downstream factor of stem cell maintenance, and 2) whether APOE4 genotype and APOE loss-of-function would produce similar phenotypes.","Split+Modify,Clarity",Clarity
11341,9-353,9-353_v2_46@2,9-353_v1_41@1,"Moreover, it would be interesting to examine the exact underlying mechanisms such as 1) whether APOE is an upstream or downstream factor of stem cell maintenance, and 2) whether APOE4 genotype and APOE loss-of-function would produce similar phenotypes.","Combining our observations and previous evidence reported in the literature, we speculate that APOE has an important role in stem cell maintenance and propose that further investigations should be carried out to investigate the exact underlying mechanisms such as 1) whether APOE is an upstream or downstream factor of stem cell maintenance, and 2) whether APOE4 genotype and APOE loss-of-function would produce similar phenotypes.","Split+Modify,Clarity",Clarity
11350,9-449,9-449_v2_71@1,,The blocking is caused because the VWF-platelet binding requires the A1 domain on VWF to be exposed in order to bind.,,"Add,Claim",Claim
11351,9-449,9-449_v2_71@3,,"Since our experimental condition are static VWF attaches to collagen IV, but does not bind the platelets <REF-29> , <REF-30> .",,"Add,Fact/Evidence",Fact/Evidence
11352,9-449,9-449_v2_82@5,,"At this stage the actin ring forms, seemingly by myosin-mediated contraction of actin filaments <REF-20> .",,"Add,Fact/Evidence",Fact/Evidence
11353,9-449,9-449_v2_87@5,,"By the use of high-resolution, close-to-native cryo-electron tomography, we witnessed the microtubules extending only into the base of the filopodia.",,"Add,Fact/Evidence",Fact/Evidence
11354,9-449,9-449_v2_87@6,,This stands in contrast with the findings of Patel-Hett et al. were they observed EB3-GFP molecules concentrate at the tips of growing filopodial projections <REF-38> .,,"Add,Fact/Evidence",Fact/Evidence
11355,9-449,9-449_v2_25@0,9-449_v1_25@0,"The integrated tapping activity of a platelet in a given frame in the image sequence was defined as the accumulation of all local alterations in the focal plane, in both attachment and detachment events.",The integrated tapping activity of a platelet in a given frame in the image sequence was defined as the accumulation of all local alterations in focal plane in both attachment of detachment events.,"Modify,Grammar",Grammar
11356,9-449,9-449_v2_29@0,9-449_v1_35@0,"Mn 2+ (250 μM), molecule sn528 (αIIbβ3 integrin inhibitor; 10 μM) or thrombin (0.015 U/ml) were added directly to the dishes containing fibrinogen or collagen IV in Tyrode's-HEPES buffer pH 7.4 containing 5 mM dextrose simultaneously as the fresh PRP-PL or PLT, which were seeded (10–15×10 6 ) in the microscope at 37°C in humidified atmosphere of 5% CO 2 and 95% air.","Mn 2+ (250 μM), molecule sn528 (αIIbβ3 integrin inhibitor; 10 μM) or thrombin (0.12 mg/ml) were added directly to the dishes containing fibrinogen or collagen IV in Tyrode's-HEPES buffer pH 7.4 containing 5 mM dextrose simultaneously as the fresh PRP-PL or PLT, which were seeded (10–15×10 6 ) in the microscope at 37°C in humidified atmosphere of 5% CO 2 and 95% air.","Modify,Fact/Evidence",Fact/Evidence
11357,9-449,9-449_v2_63@4,9-449_v1_63@4,"We also observe a plentitude of trans-membrane receptors <REF-26> – <REF-28> , many of who are integrins ( Figure 5E ).","We also observe a plentitude of trans-membrane, presumably including αIIbβ3 integrin, receptors ( Figure 5E ).","Modify,Fact/Evidence",Fact/Evidence
11358,9-449,9-449_v2_71@0,9-449_v1_71@0,"The failure of PRP-PL to adhere to collagen IV was attributed to von Willebrand factor (VWF), which was present in the plasma, and effectively block collagen IV binding.","The failure of PRP-PL to adhere to collagen IV was attributed to von Willebrand factor (VWF), which was present in the plasma, and effectively block collagen IV binding <REF-26> , <REF-27> .","Modify,Fact/Evidence",Fact/Evidence
11359,9-449,9-449_v2_82@6,9-449_v1_82@5,Later events in the platelets’ response appeared matrix-dependent.,"On the other hand, later events in the platelets’ response appeared matrix-dependent.","Modify,Clarity",Clarity
11360,9-449,9-449_v2_88@3,9-449_v1_88@3,"The collagen receptor complex GPVI-FcR γ-chain mediates platelet activation by ligand-mediated clustering of the receptor which triggers an increase in Src family kinases (SFKs) activity and downstream tyrosine phosphorylation of enzymes, adaptors, and cytoskeletal proteins that collectively propagate the signal and coordinate platelet activation in the sense of cytoskeletal remodeling including actin protrusions, degranulation and integrin activation <REF-41> , <REF-42> .","The collagen receptor complex GPVI-FcR γ-chain mediates platelet activation byligand-mediated clustering of the receptor which triggers an increase in Src family kinases (SFKs) activity and downstream tyrosine phosphorylation of enzymes, adaptors, and cytoskeletal proteins that collectively propagate the signal and coordinate platelet activation in the sense of cytoskeletal remodeling including actin protrusions, degranulation and integrin activation <REF-37> , <REF-38> .","Modify,Grammar",Grammar
11361,9-449,9-449_v2_90@2,9-449_v1_90@2,"This is consistent with the findings of Thornber et al. were they defined the necessity of αIIbβ3 in lamellipodia progression for platelets on collagen related peptide, fibrinogen and thrombin <REF-33> .","This is consistent with the findings of Thornber et al were they defined the necessity of αIIbβ3 in lamellipodia progression for platelets on collagen related peptide, fibrinogen and thrombin <REF-30> .","Modify,Grammar",Grammar
11362,9-449,9-449_v2_14@0,9-449_v1_14@0,"MatTek dishes were incubated with either 25 μg/ml human collagen IV (Sigma-Aldrich, Israel) in sterile PBS or with 50 μg/ml human fibrinogen (Sigma-Aldrich, Israel) in sterile PBS, overnight at 4°C.","MaTek dishes were incubated with either 25 μg/ml human collagen IV (Sigma-Aldrich, Israel) in sterile PBS or with 50 μg/ml human fibrinogen (Sigma-Aldrich, Israel) in sterile PBS, overnight at 4C 0 .","Modify,Grammar",Grammar
11363,9-449,9-449_v2_19@0,9-449_v1_19@0,Fresh PRP-PL or PLT were seeded (10–15×10 6 ) on collagen IV and fibrinogen MatTek plates directly in the microscope environmental chamber at 37°C in humidified atmosphere of 5% CO 2 and 95% air.,Fresh PRP-PL or PLT were seeded (10–15×10 6 ) on collagen IV and fibrinogen MaTek plates directly in the microscope environmental chamber at 37°C in humidified atmosphere of 5% CO 2 and 95% air.,"Modify,Grammar",Grammar
11373,9-512,9-512_v2_2@6,,"We envision the package and the built-in collection of common types of linear model designs to be useful for teaching and self-learning purposes, as well as for assisting more experienced users in the interpretation of complex model designs.",,"Add,Claim",Claim
11374,9-512,9-512_v2_8@6,,"It is worth noting that ExploreModelMatrix is not intended as a self-contained resource on generalized linear models, but rather as a complement to existing books and courses on the topic, and the application contains a list of suggested material for further study.",,"Add,Claim",Claim
11375,9-512,9-512_v2_14@2,,"In addition, clicking on the question mark icon within a specific panel opens up the guided tour at the corresponding step.",,"Add,Fact/Evidence",Fact/Evidence
11376,9-512,9-512_v2_25@0,,Figure 1 illustrates the ExploreModelMatrix output for a factorial design with two predictors (genotype and treatment).,,"Add,Fact/Evidence",Fact/Evidence
11377,9-512,9-512_v2_25@1,,"We consider the effects of the two predictors to be additive, which is indicated by the design formula (~ genotype + treatment).",,"Add,Fact/Evidence",Fact/Evidence
11378,9-512,9-512_v2_25@2,,"From the graphical representation of the fitted values (also shown in Figure 2A ), we can, for example, conclude that the intercept in the model directly represents the fitted value for the ‘genotype A, control’ group of samples.",,"Add,Fact/Evidence",Fact/Evidence
11379,9-512,9-512_v2_25@3,,"Similarly, the fitted value for the ‘genotype A, treated’ group is given by the sum of the intercept and the treatmenttrt coefficient.",,"Add,Fact/Evidence",Fact/Evidence
11380,9-512,9-512_v2_25@4,,"If we are interested in performing a hypothesis test to compare the treated and control groups for the samples with genotype A, we need to formulate a suitable linear contrast.",,"Add,Claim",Claim
11381,9-512,9-512_v2_25@5,,"Using the ExploreModelMatrix representation, the estimated effect size can be obtained by subtracting the fitted value for the ‘genotype A, control’ group from that of the ‘genotype A, treated’ group.",,"Add,Fact/Evidence",Fact/Evidence
11382,9-512,9-512_v2_25@6,,"The result is simply treatmenttrt , which indicates that a significance test for the difference between the two treatment groups in genotype A samples can be obtained by testing whether the coefficient treatmenttrt is zero.",,"Add,Claim",Claim
11383,9-512,9-512_v2_25@7,,"Interestingly, performing the same exercise in the genotype B samples yields the same result, indicating that the treatmenttrt coefficient represents the treatment effect in each of the two genotypes.",,"Add,Claim",Claim
11384,9-512,9-512_v2_25@8,,This is a result of using an additive model.,,"Add,Fact/Evidence",Fact/Evidence
11385,9-512,9-512_v2_25@9,,Changing the provided design formula to include an interaction between the two predictors (~ genotype + treatment + genotype:treatment; Figure 2B ) changes the interpretation.,,"Add,Fact/Evidence",Fact/Evidence
11386,9-512,9-512_v2_25@10,,"Now, while the treatment effect in the genotype A samples is still represented by the treatmenttrt coefficient, the treatment effect in the genotype B samples is represented by the sum of the treatmenttrt and genotypeB:treatmenttrt coefficients.",,"Add,Fact/Evidence",Fact/Evidence
11387,9-512,9-512_v2_25@11,,"The interaction effect, that is, the difference between the treatment effects in the two genotype groups, is represented by the genotypeB:treatmenttrt coefficient.",,"Add,Fact/Evidence",Fact/Evidence
11388,9-512,9-512_v2_25@12,,This example illustrates how the ExploreModelMatrix interface can be used to interpret coefficients in generalized linear models and create contrasts of interest.,,"Add,Claim",Claim
11389,9-512,9-512_v2_38@0,,"Both model formulations can be used to analyze this type of data, and the purpose of ExploreModelMatrix is not to select the ‘best’ among a set of plausible models, but rather to assist the user in the interpretation of a chosen model.",,"Add,Claim",Claim
11390,9-512,9-512_v2_18@0,9-512_v1_18@0,"Expressed in terms of the model coefficients, the panel in the first row of the application ( F ) illustrates, in graphical and tabular form, the value of the linear predictor in a generalized linear model, for each combination of levels for the predictors used in the design formula.","Expressed in terms of the model coefficients, the panels in the first row of the application ( F - G ) illustrate, in graphical and tabular form, the value of the linear predictor in a generalized linear model, for each combination of levels for the predictors used in the design formula.","Modify,Grammar",Grammar
11391,9-512,9-512_v2_22@3,9-512_v1_22@3,"To use the sample data table provided either as an argument to ExploreModelMatrix() or uploaded into the app at run time, select --- here.","To use the sample information table provided either as an argument to ExploreModelMatrix() or uploaded into the app at run time, select -- here.","Modify,Clarity",Clarity
11392,9-512,9-512_v2_22@5,9-512_v1_22@5,ExploreModelMatrix will convert each character variable to a factor when a sample data table is loaded; by default the baseline level will be the first in alphabetical order.,ExploreModelMatrix will convert each character variable to a factor when a sample information table is loaded; by default the baseline level will be the first in alphabetical order.,"Modify,Clarity",Clarity
11393,9-512,9-512_v2_28@0,9-512_v1_25@0,"To further illustrate how ExploreModelMatrix <REF-15> can be used to interpret the coefficients in a complex experimental design, we consider the example of differential allele-specific expression analysis with RNA-seq data.","To illustrate how ExploreModelMatrix <REF-15> can be used to interpret the coefficients in a complex experimental design, we consider the example of differential allele-specific expression analysis with RNA-seq data.","Modify,Clarity",Clarity
11394,9-512,9-512_v2_29@0,9-512_v1_26@0,The sample data table considered here is provided in Table 1 .,The sample annotation table considered here is provided in Table 1 .,"Modify,Clarity",Clarity
11395,9-512,9-512_v2_33@2,9-512_v1_30@2,"Given this design formula together with the sample data table from Table 1 as the input arguments, the ExploreModelMatrix functions determine the composition of the linear predictor for each combination of predictor variables shown in Figure 3A (corresponds to panel ( F ) in Figure 1 , shown here separately for increased readability).","Given this design formula together with the sample annotation table from Table 1 as the input arguments, the ExploreModelMatrix functions determine the composition of the linear predictor for each combination of predictor variables shown in Figure 2A (corresponds to panel ( F ) in Figure 1 , shown here separately for increased readability).","Modify,Clarity",Clarity
11396,9-512,9-512_v2_38@1,9-512_v1_35@0,"The example above stresses that knowing how to interpret a given coefficient in a generalized linear model is critical, that identically labelled coefficients can have different meanings depending on the chosen design formula, and that ExploreModelMatrix can help the user interpret the resulting coefficients for a given choice of design formula and set up an appropriate contrast.","This example stresses that knowing how to interpret a given coefficient in a generalized linear model is critical, that identically labelled coefficients can have different meanings depending on the chosen design formula, and that ExploreModelMatrix can help the user interpret the resulting coefficients for a given choice of design formula and set up an appropriate contrast.","Modify,Clarity",Clarity
11397,9-512,9-512_v2_11@1,9-512_v1_11@1,"The package is available via Bioconductor <REF-18> (from release 3.11 onwards), with the current development version accessible via GitHub .","The package is available via Bioconductor <REF-18> , with the current development version accessible via GitHub .","Modify,Fact/Evidence",Fact/Evidence
11398,9-512,9-512_v2_12@1,9-512_v1_12@1,"This function accepts two optional arguments; a data.frame with one row per observation and each column corresponding to a measured predictor variable (below referred to as the sample data table ), and a design formula.","This function accepts two optional arguments; a data.frame with one row per observation and each column corresponding to a measured predictor variable (below referred to as the sample information table ), and a design formula.","Modify,Clarity",Clarity
11399,9-512,9-512_v2_12@2,9-512_v1_12@2,"If the ExploreModelMatrix() function is called without any arguments, the user can either explore one of the built-in designs, or load a sample data table from a tab-separated text file.","If the ExploreModelMatrix() function is called without any arguments, the user can either explore one of the built-in designs, or load a sample information table from a tab-separated text file.","Modify,Clarity",Clarity
11400,9-512,9-512_v2_2@4,9-512_v1_2@4,"Given a sample data table and a desired design formula, the package displays how the model coefﬁcients are combined to give the ﬁtted values for each combination of predictor variables, which allows users to both extract the interpretation of each individual coefﬁcient, and formulate desired linear contrasts.","Given a sample annotation table and a desired design formula, the package displays how the model coefﬁcients are combined to give the ﬁtted values for each combination of predictor variables, which allows users to both extract the interpretation of each individual coefﬁcient, and formulate desired linear contrasts.","Modify,Clarity",Clarity
11401,9-512,9-512_v2_17@0,9-512_v1_17@0,"Given a sample data table and a design formula, either provided by the user or obtained via one of the built-in designs, ExploreModelMatrix will first check that the two objects are compatible, i.e., that the terms in the design formula use only variables that are present in the sample data table, and that the design formula is supported by the package.","Given a sample information table and a design formula, either provided by the user or obtained via one of the built-in designs, ExploreModelMatrix will first check that the two objects are compatible, i.e., that the terms in the design formula use only variables that are present in the sample information table, and that the design formula is supported by the package.","Modify,Clarity",Clarity
11402,9-573,,9-573_v1_74@0,,"However, the levels of IL1ß were quite variable even within each treatment group.","Delete,Fact/Evidence",Fact/Evidence
11403,9-573,,9-573_v1_74@1,,"In the two groups of pups from dams treated with either dose of paracetamol (15mg/kg or 3.75mg/kg), several individuals had concentrations of the cytokine markedly increased, up to 100pg/ml ( Figure 5 ).","Delete,Fact/Evidence",Fact/Evidence
11404,9-573,,9-573_v1_74@2,,"Overall, in dams treated with paracetamol, 19/39 fetuses had IL1ß levels above 5pg/ml.","Delete,Fact/Evidence",Fact/Evidence
11405,9-573,,9-573_v1_24@4,,Data were groomed using FASTQ groomer (Galaxy version 1.1.1) and checked for read quality using FASTQc read quality reports (Galaxy version 0.72).,"Delete,Fact/Evidence",Fact/Evidence
11406,9-573,9-573_v2_44@2,,We also tested our data using ANOVA followed by Tukey's posthoc test; this approach yielded the same outcomes.,,"Add,Fact/Evidence",Fact/Evidence
11407,9-573,9-573_v2_62@7,,"In addition, 10/50 genes were up-regulated following both treatments but 34/50 were down-regulated following both treatments.",,"Add,Fact/Evidence",Fact/Evidence
11408,9-573,9-573_v2_62@8,,Thus overall the down-regulatory effects of paracetamol were much more pronounced than the up-regulatory effects.,,"Add,Fact/Evidence",Fact/Evidence
11409,9-573,9-573_v2_103@0,,Fetuses were exposed to 14 C-sucrose either directly (fetal i.p. injection) or indirectly (maternal i.v. injection).,,"Add,Fact/Evidence",Fact/Evidence
11410,9-573,9-573_v2_103@1,,"Treatment groups investigated were control, no paracetamol (n=13), chronic low dose (3.75mg/kg, n=11) and chronic high dose (15mg/kg, n=11) in fetuses that were injected directly.",,"Add,Fact/Evidence",Fact/Evidence
11411,9-573,9-573_v2_60@1,9-573_v1_60@1,"Most genes were uniquely regulated, either up or down, depending on treatment duration, with relatively few that were common to both treatment regimes (64 up-regulated and 57 down-regulated).","Most genes were uniquely regulated, either up or down, depending on treatment duration, with relatively few that were common to both treatment regimes (65 up-regulated and 57 down-regulated).","Modify,Fact/Evidence",Fact/Evidence
11412,9-573,9-573_v2_62@0,9-573_v1_62@0,"Comparing datasets of placentas from chronically treated dams with untreated control dams, the expression of 737 genes was significantly different (either up or down p<0.05, see Methods) ( Figure 2 ).","Comparing datasets of placentas from chronically treated dams with untreated control dams, the expression of 737 genes was significantly different (either up or down) ( Figure 2 ).","Modify,Fact/Evidence",Fact/Evidence
11413,9-573,9-573_v2_62@6,9-573_v1_62@6,"This was particularly evident for the chronically treated group compared to the control group, with five genes down-regulated greater than 500-fold ( Afp, apoc2, rbp4, apob and fgb , Table 1 ).","This was particularly evident for the chronically treated group compared to the control group, with five genes down-regulated greater than 500-fold ( Afp, apoc2, rbp4, apob and fgb , Table 1 )","Modify,Grammar",Grammar
11414,9-573,9-573_v2_74@3,9-573_v1_73@3,None of the dams in any of the treatment groups had a detectable level of IL1ß in their plasma (limit <5pg/ml) nor was IL1ß detected in the control untreated fetuses.,None of the dams in any of the treatment groups had a detectable level of IL1ß in their plasma (limit <5pg/ml).,"Modify,Fact/Evidence",Fact/Evidence
11415,9-573,9-573_v2_74@4,9-573_v1_73@4,"In contrast, IL1ß in the plasma of many of the E19 fetuses whose mothers had been treated with paracetamol was detected.","In contrast, detectable levels of IL1ß in the plasma of many of the E19 fetuses whose mothers had been treated with paracetamol were demonstrated, and the levels were generally higher in fetuses of mothers treated chronically.","Split+Modify,Clarity",Clarity
11416,9-573,9-573_v2_74@5,9-573_v1_73@4,"The levels were generally higher in fetuses of mothers treated chronically (acute 2/4, chronic low 7/16 and chronic high 10/19).","In contrast, detectable levels of IL1ß in the plasma of many of the E19 fetuses whose mothers had been treated with paracetamol were demonstrated, and the levels were generally higher in fetuses of mothers treated chronically.","Split+Modify,Fact/Evidence",Fact/Evidence
11417,9-573,9-573_v2_81@2,9-573_v1_80@2,Following both treatments 26/50 genes were up-regulated and 40/50 were down-regulated.,Many more genes were up-regulated following acute treatment rather than chronic treatment.,"Merge+Modify,Fact/Evidence",Fact/Evidence
11418,9-573,9-573_v2_81@2,9-573_v1_80@3,Following both treatments 26/50 genes were up-regulated and 40/50 were down-regulated.,"In contrast, more genes were down-regulated in the brains of chronically treated fetuses compared with the acutely treated.","Merge+Modify,Fact/Evidence",Fact/Evidence
11419,9-573,9-573_v2_95@2,9-573_v1_94@2,Figure 8A shows the blot that contained both the fetal and maternal samples together with one negative control (non-pregnant female rat).,Figure 8A shows the blot that contained both the fetal and maternal samples together with a negative control (non-pregnant female rat).,"Modify,Clarity",Clarity
11420,9-573,9-573_v2_95@4,9-573_v1_94@4,There was no detectable band in the non-pregnant control sample and all maternal samples showed a much lower level of the protein than fetal samples.,There was no detectable band in the control sample and all maternal samples showed a much lower level of the protein than fetal samples.,"Modify,Clarity",Clarity
11421,9-573,9-573_v2_95@5,9-573_v1_94@5,"The levels of the protein in fetal samples did not appear to change between the control and any of the treatment groups ( Figure 8B ), but in maternal samples, AFP levels were higher in all chronically treated dams compared to un-treated controls.","The levels of the protein in fetal samples did not appear to change significantly between the control and any of the treatment groups ( Figure 8B ), but in maternal samples, AFP levels were higher in all treated dams compared to an un-treated control.","Modify,Clarity",Clarity
11422,9-573,9-573_v2_95@6,9-573_v1_94@6,"This was reflected in the ratios of AFP in maternal to fetal plasma ( Figure 8B , right panel) in which all of the chronically treated animals had ratios that were above those in untreated controls and in one acutely treated animal.","This was reflected in the ratios of AFP in maternal to fetal plasma ( Figure 8B , right panel), showing that even a single injection (acute) of paracetamol may increase placental transfer, while prolonged exposure to the drug increased AFP transfer by about three times compared to the control animals.","Split+Modify,Fact/Evidence",Fact/Evidence
11423,9-573,9-573_v2_95@7,9-573_v1_94@6,Prolonged exposure to the drug increased AFP transfer from fetus to dam by about three times compared to the control animals.,"This was reflected in the ratios of AFP in maternal to fetal plasma ( Figure 8B , right panel), showing that even a single injection (acute) of paracetamol may increase placental transfer, while prolonged exposure to the drug increased AFP transfer by about three times compared to the control animals.","Split+Modify,Clarity",Clarity
11424,9-573,9-573_v2_122@0,9-573_v1_120@0,"Paracetamol (acetaminophen) is generally considered “safe” to use in pregnancy and lactation ( Australian Medicines Handbook, 2019 ; Briggs et al. , 2017 ) although it is one of the most commonly overdosed drugs, including in pregnancy (Rayburn et al. , 1984).","Paracetamol (acetaminophen) is generally considered “safe” to use in pregnancy and lactation ( Australian Medicines Handbook, 2019 ; Briggs et al. , 2017 ) although it is one of the most commonly overdosed drugs, including in pregnancy ( Rayburn et al. , 1984 ).","Modify,Grammar",Grammar
11425,9-573,9-573_v2_10@4,9-573_v1_10@4,"Inflammatory responses during pregnancy have been linked to a range of clinical complications including pre-term birth, fetal cardiac conditions and neurological deficiencies ( Challis et al. , 2009 ; Fleiss et al. , 2020 ; Huleihel et al. , 2004 ; Romero et al. , 2007 ; Salafia et al. , 1989 ).","Inflammatory responses during pregnancy have been linked to a range of clinical complications including pre-term birth, fetal cardiac conditions and neurological deficiencies ( Challis et al. , 2009 ; Huleihel et al. , 2004 ; Romero et al. , 2007 ; Salafia et al. , 1989 ).","Modify,Fact/Evidence",Fact/Evidence
11426,9-573,9-573_v2_16@2,9-573_v1_16@2,"Age groups investigated (at treatment completion) were embryonic day 19 (E19) pups of both sexes and dams, which were all primigravida 350–400g body weight) and non-pregnant female adults (175–230g body weight).","Age groups investigated (at treatment completion) were embryonic day 19 (E19) pups of both sexes and dams, which were all primigravida 350–400g body weight) and non-pregnant female adults (175-230g body weight).","Modify,Grammar",Grammar
11427,9-581,9-581_v2_17@4,9-581_v1_17@4,The odds-ratio is ∞ in both cases.,The odds-ratio is 8 in both cases.,"Modify,Fact/Evidence",Fact/Evidence
11428,9-581,9-581_v2_17@5,9-581_v1_17@5,"In Figure 1c and Figure 1d , N 1 - n and N 2 - n are all negative, so it is not conceptually appropriate to use Fisher’s exact test to calculate the p -value and odds-ratio.","In cases c and d , N 1 - n and N 2 - n are all negative, so it is not conceptually appropriate to use Fisher’s exact test to calculate the p -value and odds-ratio.","Modify,Fact/Evidence",Fact/Evidence
11429,9-581,9-581_v2_4@2,9-581_v1_4@2,"A fundamental operation in genomic/epigenomic analysis is comparing two interval sets, and many algorithms and tools have been developed for this purpose ( Alekseyenko & Lee, 2007 ; Cormen et al. , 2001 ; Feng et al. , 2019 ; Giardine et al. , 2005 ; Jalili et al. , 2019 ; Kent et al. , 2002 ; Li, 2011 ; Neph et al. , 2012 ; Quinlan & Hall, 2010 ; Richardson, 2006 ).","A fundamental operation in genomic/epigenomic analysis is comparing two interval sets, and many algorithms and tools have been developed for this purpose ( Alekseyenko & Lee, 2007 ; Cormen et al. 2001 ; Feng et al. , 2019 ; Giardine et al. , 2005 ; Jalili et al. , 2019 ; Kent et al. , 2002 ; Li, 2011 ; Neph et al. , 2012 ; Quinlan & Hall 2010 ; Richardson, 2006 ).","Modify,Grammar",Grammar
11430,9-581,9-581_v2_0@0,9-581_v1_0@0,Seqpare : a novel metric of similarity between genomic interval sets,Seqpare : a self-consistent metric of similarity between genomic interval sets,"Modify,Claim",Claim
11431,9-581,9-581_v2_16@0,9-581_v1_16@0,"Since the number of total matching pairs ≤ Min( N 1 , N 2 ) — the minimum of N 1 and N 2 — and s is in range of [0, 1], we obtain O ≤ Min( N 1 , N 2 ), and S takes a value in the range of [0, 1].","Since the number of total matching pairs = Min( N 1 , N 2 ) — the minimum of N 1 and N 2 — and s is in range of [0, 1], we obtain O = Min( N 1 , N 2 ), and S takes a value in the range of [0, 1].","Modify,Fact/Evidence",Fact/Evidence
11432,9-581,9-581_v2_17@3,9-581_v1_17@3,"Assuming that the number of intervals N in the ‘universe set’ is 100, then Fisher’s exact test contingency table is [(2, 0), (0, 98)] in 1 a and [(3, 0), (0, 97)] in 1 b , which gives p a = 2.02×10 -4 and p b = 6.18×10 -6 respectively.","Assuming that the number of intervals N in the ‘universe set’ is 100, then Fisher’s exact test contingency table is [(2, 0), (0, 98)] in 1 a and [(3, 0), (0, 97)] in 1 b , which gives p a = 2.02x10 -4 and p b = 6.18x10 -6 respectively.","Modify,Grammar",Grammar
11433,9-603,,9-603_v1_22@4,,"To the best of our knowledge, this is the first reported case of OCS to arise from ameloblastic fibrodentinoma.","Delete,Claim",Claim
11434,9-603,9-603_v2_7@1,,There was prominent cortical expansion with areas of perforation ( Figure 1 ).,,"Add,Fact/Evidence",Fact/Evidence
11435,9-603,9-603_v2_12@1,,"The center of the follicles was filled by stellate reticulum like cells, which were basaloid in appearance in some follicles.",,"Add,Fact/Evidence",Fact/Evidence
11436,9-603,9-603_v2_15@1,,There were no palpable lymph nodes.,,"Add,Fact/Evidence",Fact/Evidence
11437,9-603,9-603_v2_15@5,,The typical ameloblastic architecture of the epithelial follicles was lost in some areas.,,"Add,Fact/Evidence",Fact/Evidence
11438,9-603,9-603_v2_15@6,,The ectomesenchymal component showed large pleomorphic cells ( Figure 4 ).,,"Add,Fact/Evidence",Fact/Evidence
11439,9-603,9-603_v2_18@4,,"In 2019 and after nearly a year and a half, the patient came to Oral & Maxillofacial Surgery department for the reconstruction surgery and the examination revealed neither a recurrence nor complications.",,"Add,Fact/Evidence",Fact/Evidence
11440,9-603,9-603_v2_29@0,,"Regarding the clinical behavior of OCS, it is a highly aggressive highly recurrent malignant neoplasm <REF-7> .",,"Add,Fact/Evidence",Fact/Evidence
11441,9-603,9-603_v2_29@1,,"In our case, the patient encountered recurrence of the lesion after 9 months follow up with no evident metastasis.",,"Add,Fact/Evidence",Fact/Evidence
11442,9-603,9-603_v2_29@2,,"In the English literature, six out of the eleven cases showed recurrence of the lesion and only 4 cases showed metastasis; whether to lungs or lymph nodes <REF-6> .",,"Add,Fact/Evidence",Fact/Evidence
11443,9-603,9-603_v2_29@3,,Kunkel et al . (2004) reported the late metastasis of their case; which was evident about 5 years after the first diagnosis <REF-10> .,,"Add,Fact/Evidence",Fact/Evidence
11444,9-603,9-603_v2_29@4,,"There were five out of the eleven cases encountered death <REF-6> , one of them was actually due to systemic complication after the resection of the lesion <REF-7> .",,"Add,Fact/Evidence",Fact/Evidence
11445,9-603,9-603_v2_32@1,,Close long follow-up is recommended; due to the possible late metastasis of the lesion.,,"Add,Claim",Claim
11446,9-603,,9-603_v1_12@1,,The epithelial cells showed little pleomorphism and hyperchromatism.,"Delete,Fact/Evidence",Fact/Evidence
11447,9-603,,9-603_v1_12@2,,"In some fields, dentinoid matrix was detected around the epithelial strands ( Figure 3 ).","Delete,Fact/Evidence",Fact/Evidence
11448,9-603,,9-603_v1_18@4,,The patient was missed for the follow-up appointment after the last excision of the lesion and could not be reached for further follow-up.,"Delete,Fact/Evidence",Fact/Evidence
11449,9-603,9-603_v2_24@3,9-603_v1_22@3,The present case arose from a preexisting immature odontoma which was formerly called ameloblastic fibrodentinoma.,The present case arose from a preexisting ameloblastic fibrodentinoma.,"Modify,Clarity",Clarity
11450,9-603,9-603_v2_25@1,9-603_v1_23@1,"In the English literature, there was a male predilection and only one case that occurred in maxilla <REF-4> .","In the English literature, there was only one case that occurred in maxilla <REF-4> .","Modify,Fact/Evidence",Fact/Evidence
11451,9-603,9-603_v2_25@3,9-603_v1_23@3,The current case showed multiple radiopacities; may be due to the preexisting immature odontoma.,The current case showed multiple radiopacities owing to the preexisting ameloblastic fibrodentinoma.,"Modify,Clarity",Clarity
11452,9-603,9-603_v2_27@0,9-603_v1_25@0,"In accordance with Dos Santos et al . (2018), α-SMA staining in the current case showed scattered staining in the epithelial cells <REF-4> .","In accordance with Dos Santos et al . (2018), α-SMA staining in the current case showed scattered cytoplasmic staining in both the ectomesenchymal and epithelial cells <REF-4> .","Modify,Fact/Evidence",Fact/Evidence
11453,9-603,9-603_v2_27@1,9-603_v1_25@1,Its expression in the epithelial cells could be attributed to the epithelial mesenchymal transition process; which increases the potentiality of the tumor cells to invade and metastasize <REF-14> .,"Its expression in the ectomesenchymal cells could be attributed to the emergence of cancer associated myofibroblasts, which play a significant role in tumor progression and the epithelial mesenchymal transition process, explaining α-SMA expression in the epithelial cells <REF-14> .","Modify,Fact/Evidence",Fact/Evidence
11454,9-603,9-603_v2_28@0,9-603_v1_26@0,The proliferative index Ki-67 in our case was around 7.5% in the epithelial component and 3% in the ectomesenchymal component.,The proliferative index Ki-67 in our case was around 40% in the epithelial component and 12% in the ectomesenchymal component.,"Modify,Fact/Evidence",Fact/Evidence
11455,9-603,9-603_v2_0@0,9-603_v1_0@0,Case Report: Odontogenic carcinosarcoma arising from premature odontoma with immunohistochemical profile,Case Report: Odontogenic carcinosarcoma arising from ameloblastic fibrodentinoma with immunohistochemical profile,"Modify,Clarity",Clarity
11456,9-603,9-603_v2_6@0,9-603_v1_6@0,"In December 2016, a 28-year-old Egyptian male patient working as an accountant was referred to the Department of Oral and Maxillofacial Surgery, Faculty of Dentistry, Cairo University, with a complaint of painless swelling of six months duration in the left side of his face measuring 7 × 6 cm.","A 28-year-old Egyptian male patient working as an accountant was referred to the Department of Oral and Maxillofacial Surgery, Faculty of Dentistry, Cairo University, with a complaint of painless swelling of six months duration in the left side of his face measuring 7 × 6 cm.","Modify,Fact/Evidence",Fact/Evidence
11457,9-603,9-603_v2_7@0,9-603_v1_7@0,A cone beam computed tomography examination revealed an ill-defined multilocular osteolytic lesion with fine radiopacities extending from the lower left second premolar up to the ramus.,A cone beam computed tomography examination revealed an ill-defined multilocular osteolytic lesion with fine radiopacities extending from the lower left second premolar up to the ramus ( Figure 1 ).,"Modify,Fact/Evidence",Fact/Evidence
11458,9-603,9-603_v2_12@0,9-603_v1_12@0,"Histopathological examination revealed hypercellular follicles and strands of odontogenic epithelium, that were lined peripherally by multilayers of tall columnar ameloblast like cells.",Histopathological examination revealed follicles of odontogenic epithelium that were compressed by highly cellular hyalinized primitive connective tissue resembling dental papilla.,"Split+Modify,Fact/Evidence",Fact/Evidence
11459,9-603,9-603_v2_12@2,9-603_v1_12@0,"In between the follicles, there was a highly cellular primitive ectomesenchyme resembling dental papilla.",Histopathological examination revealed follicles of odontogenic epithelium that were compressed by highly cellular hyalinized primitive connective tissue resembling dental papilla.,"Split+Modify,Fact/Evidence",Fact/Evidence
11460,9-603,9-603_v2_15@0,9-603_v1_15@0,"After nine months and after the publication of 2017 WHO classification, the patient returned with another large painless swelling in the left temporal and infra-temporal fossa of three months duration.","After nine months, the patient returned with another large painless swelling in the left temporal and infra-temporal fossa that had appeared three months previously.","Modify,Fact/Evidence",Fact/Evidence
11461,9-603,9-603_v2_15@4,9-603_v1_15@3,"Histopathological examination revealed highly cellular neoplasm, which showed cellular atypia and increased nuclear cytoplasmic ratio in both epithelial and ectomesenchymal components.","Histopathological examination revealed highly cellular neoplasm, which showed cellular atypia and increased mitosis in both epithelial and ectomesenchymal components ( Figure 4 ).","Modify,Fact/Evidence",Fact/Evidence
11462,9-603,9-603_v2_18@1,9-603_v1_18@1,Alpha-smooth muscle actin (α-SMA) showed positivity in the endothelial cells as well as in scattered epithelial cells ( Figure 5 ).,Alpha-smooth muscle actin (α-SMA) showed positivity in the endothelial cells as well as in scattered epithelial and ectomesenchymal cells.,"Modify,Fact/Evidence",Fact/Evidence
11463,9-603,9-603_v2_18@2,9-603_v1_18@2,"Ki-67 index was measured by Leica Qwin software and was 7.46% in the epithelial component, while in the ectomesenchymal component it was 2.78% ( Figure 6 ).","Ki-67 index was around 40% in the epithelial component, while in the ectomesenchymal component it was around 12% ( Figure 5 ).","Modify,Fact/Evidence",Fact/Evidence
11464,9-603,9-603_v2_18@3,9-603_v1_18@3,"Based on the histopathological and immunohistochemical findings, the case was diagnosed as OCS.","Based on the histopathological and immunohistochemical findings, the case was diagnosed as OCS arising from ameloblastic fibrodentinoma.","Modify,Fact/Evidence",Fact/Evidence
11465,9-618,9-618_v2_88@0,,The experiment results indicate that the performance of the proposed method yields satisfactory results and outperforms machine learning algorithms in migraine classification with a large gap in terms of accuracy and precision.,,"Add,Claim",Claim
11466,9-618,9-618_v2_88@1,,"The proposed method is generic as it does not need handcrafted features and can be easily adapted to different detection tasks, requiring minimal pre-processing.",,"Add,Claim",Claim
11467,9-618,9-618_v2_88@2,,The strategy proposed has successfully transferred knowledge from the source to the target domain despite the limited dataset size.,,"Add,Claim",Claim
11468,9-618,9-618_v2_88@3,,"During the proposed approach, we observed that no over-fitting occurs to impact the classification accuracy adversely.",,"Add,Fact/Evidence",Fact/Evidence
11469,9-618,,9-618_v1_30@1,,"There are various types of medicines to relieve symptoms, such as triptans, ergotamine, and painkillers.","Delete,Claim",Claim
11470,9-618,,9-618_v1_30@2,,"The sooner these medications are administered, the more effective they are.","Delete,Claim",Claim
11471,9-618,,9-618_v1_30@3,,"In addition, to relieve symptoms, you can rest with your eyes closed in a quiet and dark room, place a cold cloth or ice pack on your forehead, or drink liquids ( Burch, 2019 ; Charles, 2018 ; Diamond et al ., 2007 ; Evans, 2009 ; Viana et al. , 2017 ).","Delete,Fact/Evidence",Fact/Evidence
11472,9-618,9-618_v2_106@1,,Future research may be oriented to the comparison of different deep neural network architectures and the analysis of the treating physician's diagnosis versus the theoretical classification of the types of migraine.,,"Add,Claim",Claim
11473,9-618,,9-618_v1_30@4,,"Similarly, lifestyle changes can be adopted to control stress or other triggering factors.","Delete,Claim",Claim
11474,9-618,,9-618_v1_30@5,,"Furthermore, natural treatments can be used ( May & Schulte, 2016 ).","Delete,Fact/Evidence",Fact/Evidence
11475,9-618,,9-618_v1_31@0,,"Some studies report that approximately 15% of United States citizens and 12% of the world’s population suffer from migraines ( Burch, 2019 ; Burch et al. , 2018 ; Chen et al. , 2019 ; Diener et al ., 2012 ; Dodick, 2018 ; Parikh & Silberstein, 2019 ).","Delete,Fact/Evidence",Fact/Evidence
11476,9-618,,9-618_v1_31@1,,"Migraines can affect anyone, but their prevalence increases in women, i.e., women are three times more likely to suffer from migraines than men.","Delete,Claim",Claim
11477,9-618,,9-618_v1_31@2,,"Migraines also have a high prevalence in those with a family history of migraines or those who suffer from medical conditions such as depression, anxiety, bipolar disorder, sleep problems, and epilepsy.","Delete,Claim",Claim
11478,9-618,,9-618_v1_39@0,,Proposed methodology for migraine classification,"Delete,Other",Other
11479,9-618,,9-618_v1_48@0,,"The importance of making an adequate selection lies in the difficulties of convergence in learning, which can involve the inclusion of irrelevant variables and poor performance of models.","Delete,Claim",Claim
11480,9-618,,9-618_v1_48@1,,"Hota & Shrivas (2014) , and Londoño & Sánchez (2015) define the selection of variables as an optimization process intended to identify the best subset of variables from a fixed variable set.","Delete,Fact/Evidence",Fact/Evidence
11481,9-618,,9-618_v1_48@2,,"The goal of selection is to reduce the size of the input data to facilitate processing and analysis, discarding data that does not further contribute to the subsequent classification process.","Delete,Claim",Claim
11482,9-618,,9-618_v1_48@3,,This saves time in data processing without disregarding the generation of optimal results.,"Delete,Claim",Claim
11483,9-618,,9-618_v1_49@0,,"The selection of variables not only deals with the decrease in cardinality, i.e., setting a partial or predefined limit to the number of attributes that can be considered when creating a model, but also allows attributes to be properly discarded based on their utility for a good analysis process.","Delete,Claim",Claim
11484,9-618,,9-618_v1_11@0,,Migraines without aura,"Delete,Other",Other
11485,9-618,,9-618_v1_12@0,,A. At least five attacks that meet criteria B to D.,"Delete,Fact/Evidence",Fact/Evidence
11486,9-618,,9-618_v1_13@0,,B. Duration from 4 to 72 hours.,"Delete,Fact/Evidence",Fact/Evidence
11487,9-618,,9-618_v1_17@0,,Migraines with aura,"Delete,Other",Other
11488,9-618,,9-618_v1_18@0,,A. At least two attacks that meet criterion B.,"Delete,Claim",Claim
11489,9-618,,9-618_v1_19@0,,B. At least three of the following four characteristics should be met:,"Delete,Claim",Claim
11490,9-618,,9-618_v1_19@1,,1. One or more aura symptoms indicating focal cortical injury and/or brainstem dysfunction;,"Delete,Claim",Claim
11491,9-618,,9-618_v1_19@2,,2. At least one gradually developing aura symptom lasting longer than 4 minutes or two or more successive symptoms;,"Delete,Claim",Claim
11492,9-618,,9-618_v1_19@3,,3. The aura should not last for more than 60 minutes.,"Delete,Claim",Claim
11493,9-618,,9-618_v1_19@4,,"If there is more than one aura, the duration of its presentation is proportional;","Delete,Claim",Claim
11494,9-618,,9-618_v1_19@5,,4. Headaches follow aura at intervals no greater than 60 minutes.,"Delete,Claim",Claim
11495,9-618,,9-618_v1_19@6,,Pain can be experienced before the aura or at the time of the aura.,"Delete,Claim",Claim
11496,9-618,,9-618_v1_20@0,,C. At least one of the following characteristics should be met:,"Delete,Claim",Claim
11497,9-618,,9-618_v1_20@1,,1. Clinical history and physical and neurological examination that does not suggest secondary structural injury or metabolic disease;,"Delete,Claim",Claim
11498,9-618,,9-618_v1_20@2,,"2. If the clinical history or physical or neurological examination suggest secondary injury, this should be discarded via appropriate investigation;","Delete,Claim",Claim
11499,9-618,,9-618_v1_20@3,,"3. In the presence of secondary injury, this does not explain the pain, it has no temporal relationship, and it does not occur for the first time.","Delete,Claim",Claim
11500,9-618,,9-618_v1_22@0,,"Epidemiological studies examining various types of populations show that people suffering from migraines share a very hectic social and work life, and as these individuals do not usually observe orderly resting times or practice other activities that help clear the mind, they are under stress, with migraine being a sign of work and emotional burden ( Dodick, 2018 ; Parikh & Silberstein, 2019 ).","Delete,Fact/Evidence",Fact/Evidence
11501,9-618,9-618_v2_24@0,,Note: It is important to understand that the proposed methodology does not include the data collection process.,,"Add,Claim",Claim
11502,9-618,9-618_v2_24@1,,"In the current research, a retrospective database is used, to which the proposed methodology is applied.",,"Add,Claim",Claim
11503,9-618,9-618_v2_24@2,,The results section describes the data population and the selection and exclusion criteria.,,"Add,Fact/Evidence",Fact/Evidence
11504,9-618,,9-618_v1_22@1,,"Migraines also cause indirect damage to companies because they involve loss in labor productivity; annual losses in the United States are estimated at billions of dollars; such effects also apply to countries such as Colombia ( Burch et al. , 2018 ; Deza, 2010 ; Ramírez & Urrea, 2012 ).","Delete,Fact/Evidence",Fact/Evidence
11505,9-618,9-618_v2_41@4,,"However, this study only uses symptoms and diagnosis.",,"Add,Fact/Evidence",Fact/Evidence
11506,9-618,9-618_v2_42@0,,"As inclusion criteria, we have adult users diagnosed with migraine-associated pathologies.",,"Add,Fact/Evidence",Fact/Evidence
11507,9-618,9-618_v2_42@1,,Users with other pathologies are excluded.,,"Add,Fact/Evidence",Fact/Evidence
11508,9-618,,9-618_v1_24@1,,"Early signs and symptoms include food cravings, unexplained mood swings, uncontrollable yawning, fluid retention, and increased urination.","Delete,Claim",Claim
11509,9-618,,9-618_v1_25@1,,You may experience muscle weakness or a feeling of being touched or grabbed.,"Delete,Claim",Claim
11510,9-618,,9-618_v1_25@2,,Aura can occur just before or during a migraine.,"Delete,Claim",Claim
11511,9-618,,9-618_v1_26@1,,"It often causes throbbing or vibrating pain, usually unilaterally.","Delete,Claim",Claim
11512,9-618,,9-618_v1_26@2,,"However, you can experience a migraine without experiencing a headache.","Delete,Claim",Claim
11513,9-618,,9-618_v1_26@3,,"Other migraine symptoms may include increased sensitivity to light, noise, and odor; nausea and vomiting; pain that worsens with movement; coughing; and sneezing.","Delete,Claim",Claim
11514,9-618,,9-618_v1_27@1,,This can last up to 1 day.,"Delete,Claim",Claim
11515,9-618,,9-618_v1_28@0,,Migraines are more common during mornings.,"Delete,Claim",Claim
11516,9-618,,9-618_v1_28@1,,People often wake up suffering from migraines.,"Delete,Claim",Claim
11517,9-618,,9-618_v1_28@2,,"Others experience migraines at predictable times, such as before menstruation or on weekends after a stressful work week ( Kelman, 2007 ).","Delete,Fact/Evidence",Fact/Evidence
11518,9-618,9-618_v2_20@0,9-618_v1_40@0,"The strategy developed here is based on a systemic approach oriented to the specification of artificial neural network models for the classification of migraines with and without aura, highlighting the relevance of considering key aspects that lead to strong implications in their application, such as the selection of variables and the performance measures that allow for the selection of the best model.","The strategy developed here is based on a systemic approach oriented to the specification of neural network models for the classification of migraines with and without aura, highlighting the relevance of considering key aspects that lead to strong implications in their application, such as the selection of variables and the performance measures that allow for the selection of the best model.","Modify,Clarity",Clarity
11519,9-618,9-618_v2_28@3,9-618_v1_47@3,"Typically, not all potential variables are equally informative as they may be correlated, present noise, or have no meaningful relationship with the classification ( Londoño González & Sánchez, 2015 )","Typically, not all potential variables are equally informative as they may be correlated, present noise, or have no meaningful relationship with the classification.","Modify,Fact/Evidence",Fact/Evidence
11520,9-618,9-618_v2_30@0,9-618_v1_51@0,"The past few years have seen the proliferation of different automatic classification techniques based in learning machine, including artificial neural networks, decision trees, logistic regression, Bayesian classifiers, nearest neighbor, support vector machines (SVMs), and multiple discriminant analysis ( Doupe et al. , 2019 ; Waring et al. , 2020 ).","The past few years have seen the proliferation of different automatic classification techniques based in learning machine, including neural networks, decision trees, logistic regression, Bayesian classifiers, nearest neighbor, support vector machines (SVMs), and multiple discriminant analysis ( Doupe et al. , 2019 ; Waring et al. , 2020 ).","Modify,Clarity",Clarity
11521,9-618,9-618_v2_31@0,9-618_v1_52@0,"In this article, because of the robustness of the data management technique, adaptability, and acknowledged generalization capacity, artificial neural networks are used to classify patients with migraines.","In this article, because of the robustness of the data management technique, adaptability, and acknowledged generalization capacity, neural networks are used to classify patients with migraines.","Modify,Clarity",Clarity
11522,9-618,9-618_v2_15@0,9-618_v1_58@0,"The need for tools aimed at enabling appropriate decision-making has led to an accelerated interest in the development of data classification models in recent decades, which is especially intended to overcome the theoretical, conceptual, and practical limitations of many of the techniques currently available.","However, the need for tools aimed at enabling appropriate decision-making has led to an accelerated interest in the development of data classification models in recent decades, which is especially intended to overcome the theoretical, conceptual, and practical limitations of many of the techniques currently available.","Modify,Clarity",Clarity
11523,9-618,9-618_v2_15@1,9-618_v1_58@1,"This has resulted in the emergence of a wide range of models, among which artificial neural networks have demonstrated high potential given their adaptability, generalizability, and learning capabilities and because of the possibility of representing nonlinear relationships ( Sánchez-Sánchez & García-González, 2017 ).","This has resulted in the emergence of a wide range of models, among which neural networks have demonstrated high potential given their adaptability, generalizability, and learning capabilities and because of the possibility of representing nonlinear relationships ( Sánchez-Sánchez & García-González, 2017 ).","Modify,Clarity",Clarity
11524,9-618,9-618_v2_89@0,9-618_v1_59@0,"Some aspects that justify and favor the development of artificial neural network models for data classification are as follows ( Sánchez-Sánchez et al. , 2019a ):","Some aspects that justify and favor the development of neural network models for data classification are as follows ( Sánchez-Sánchez et al. , 2019a ):","Modify,Clarity",Clarity
11525,9-618,9-618_v2_90@1,9-618_v1_60@1,"Artificial neural networks are self-adaptive models that do not require a priori assumptions about the problem under study, a highly desirable feature in cases in which the data generating mechanism is unknown ( Qi & Zhang, 2001 ).","Neural networks are self-adaptive models that do not require a priori assumptions about the problem under study, a highly desirable feature in cases in which the data generating mechanism is unknown ( Qi & Zhang, 2001 ).","Modify,Clarity",Clarity
11526,9-618,9-618_v2_91@1,9-618_v1_61@1,"The ability of the artificial neural network to learn and be generalized allows the model to learn complex behaviors directly from the data and correctly infer the unseen part of the data from the acquired knowledge ( De Gooijer & Kumar, 1992 ).","The ability of the neural network to learn and be generalized allows the model to learn complex behaviors directly from the data and correctly infer the unseen part of the data from the acquired knowledge ( De Gooijer & Kumar, 1992 ).","Modify,Clarity",Clarity
11527,9-618,9-618_v2_92@1,9-618_v1_62@1,"The universal approximation characteristics of artificial neural networks allow them to identify hidden dependencies, especially nonlinear dependencies ( Cybenko, 1989 ; Franses & Van Dijk, 2000 ; Hornik, 1991 ; Hornik et al. , 1989 ), thereby favoring the representation of complex relationships.","The universal approximation characteristics of neural networks allow them to identify hidden dependencies, especially nonlinear dependencies ( Cybenko, 1989 ; Franses & Van Dijk, 2000 ; Hornik, 1991 ; Hornik et al. , 1989 ), thereby favoring the representation of complex relationships.","Modify,Clarity",Clarity
11528,9-618,9-618_v2_93@1,9-618_v1_63@1,Artificial neural networks are flexible in relation with the values they receive and deliver and do not require prior treatment.,Neural networks are flexible in relation with the values they receive and deliver and do not require prior treatment.,"Modify,Clarity",Clarity
11529,9-618,9-618_v2_94@1,9-618_v1_64@1,Their functional flexibility and characteristics as universal approximators allow artificial neural networks to represent complex behaviors regardless of the field of knowledge those data belong to.,Their functional flexibility and characteristics as universal approximators allow neural networks to represent complex behaviors regardless of the field of knowledge those data belong to.,"Modify,Clarity",Clarity
11530,9-618,9-618_v2_15@2,9-618_v1_65@0,"Artificial neural networks and their recent architectures, such as deep neural networks, have been used effectively in data classification tasks and display better results than other techniques, such as logistic regression, decision trees, Bayesian classifiers, etc.; their strength lies in their high capacity to dynamically create complex prediction functions and emulate human learning ( Nikam, 2015 ; Sánchez-Sánchez & García-González, 2017 ; Sánchez-Sánchez & García-González, 2018 ).","Neural networks and their recent architectures, such as deep neural networks, have been used effectively in data classification tasks and display better results than other techniques, such as logistic regression, decision trees, Bayesian classifiers, etc.; their strength lies in their high capacity to dynamically create complex prediction functions and emulate human learning ( Nikam, 2015 ; Sánchez-Sánchez & García-González, 2017 ; Sánchez-Sánchez & García-González, 2018 ).","Modify,Clarity",Clarity
11531,9-618,9-618_v2_31@1,9-618_v1_66@0,"Artificial neural network is represented as a three-layer model: an input layer, one or more hidden layers, and an output layer ( Figure 2 ) ( Sánchez-Sánchez et al ., 2020b ).","A neural network is represented as a three-layer model: an input layer, one or more hidden layers, and an output layer ( Figure 2 ) ( Sánchez-Sánchez et al ., 2020b ).","Modify,Clarity",Clarity
11532,9-618,9-618_v2_39@0,9-618_v1_69@0,Results,Migraine classification results,"Modify,Clarity",Clarity
11533,9-618,9-618_v2_44@0,9-618_v1_73@0,"Variables that influence the identification of the type of migraine were selected, focusing on symptoms and diagnosis and disregarding identification and treatment variables.","Finally, variables that influence the identification of the type of migraine were selected, focusing on symptoms and diagnosis and disregarding identification and treatment variables.","Modify,Clarity",Clarity
11534,9-618,9-618_v2_44@1,9-618_v1_73@1,"This led to a selection of 23 variables associated with the symptoms or signs that a patient may present, and 1 variable associated with the diagnosis that allows the identification of the type of migraine.",This led to a selection of 23 variables associated with the symptoms or signs that a patient may present and 1 variable associated with the diagnosis that allows the identification of the type of migraine.,"Modify,Grammar",Grammar
11535,9-618,9-618_v2_61@0,9-618_v1_90@0,The artificial neural network model used is equivalent to an MLP trained using backpropagation.,The neural network model used is equivalent to an MLP trained using backpropagation.,"Modify,Clarity",Clarity
11536,9-618,9-618_v2_61@1,9-618_v1_90@1,The configuration parameters used for the artificial neural network models are as follows:,The configuration parameters used for the neural network models are as follows:,"Modify,Clarity",Clarity
11537,9-618,9-618_v2_70@0,9-618_v1_99@0,"Logistic regression uses regularization with built-in cross-validation, which automatically selects the best hyperparameters for model fit.","Logistic regression uses logistic regression regularization with built-in cross-validation, which automatically selects the best hyperparameters for model fit.","Modify,Clarity",Clarity
11538,9-618,9-618_v2_75@0,9-618_v1_104@0,Discussion,Results and discussion,"Modify,Other",Other
11539,9-618,9-618_v2_76@0,9-618_v1_105@0,Results were validated based on the type of migraine diagnosed by the treating physician and using the respective measurement made during the classification process provided by the artificial neural network.,Results were validated based on the type of migraine diagnosed by the treating physician and using the respective measurement made during the classification process provided by the neural network.,"Modify,Clarity",Clarity
11540,9-618,9-618_v2_77@0,9-618_v1_106@0,Table 2 presents the results of the performance measures for various artificial neural network configurations and classification models.,Table 2 presents the results of the performance measures for various neural network configurations and classification models.,"Modify,Clarity",Clarity
11541,9-618,9-618_v2_81@0,9-618_v1_110@0,"• The maximum accuracy for both 23 and 18 variables is obtained by using a artificial neural network model with 10 hidden neurons, which results in an accuracy of 97.5%.","• The maximum accuracy for both 23 and 18 variables is obtained by using a neural network model with 10 hidden neurons, which results in an accuracy of 97.5%.","Modify,Clarity",Clarity
11542,9-618,9-618_v2_81@1,9-618_v1_110@1,This means that the classification of migraines by the artificial neural network coincides with that issued by the treating physician in 97% of the 80 cases comprising the test set.,This means that the classification of migraines by the neural network coincides with that issued by the treating physician in 97% of the 80 cases comprising the test set.,"Modify,Clarity",Clarity
11543,9-618,9-618_v2_82@0,9-618_v1_111@0,"• The artificial neural network models show accuracies and precisions >90%, highlighting values obtained with the artificial neural network model with 10 hidden neurons and a hidden layer for 23 variables and 20 hidden neurons for 18 variables, which reaches values >97% in both metrics, thereby indicating adequate classification.","• The neural network models show accuracies and precisions >90%, highlighting values obtained with the neural network model with 10 hidden neurons and a hidden layer for 23 variables and 20 hidden neurons for 18 variables, which reaches values >97% in both metrics, thereby indicating adequate classification.","Modify,Clarity",Clarity
11544,9-618,9-618_v2_84@0,9-618_v1_113@0,"• The maximum average weighted precision was obtained with the artificial neural network model with a layer of 20 hidden neurons that was reduced to 18 variables, which obtained a value of 98%; this indicates that there is a 98% probability that the model classifies the migraine within a certain type and that the treating physician has also classified it as such.","• The maximum average weighted precision was obtained with the neural network model with a layer of 20 hidden neurons that was reduced to 18 variables, which obtained a value of 98%; this indicates that there is a 98% probability that the model classifies the migraine within a certain type and that the treating physician has also classified it as such.","Modify,Clarity",Clarity
11545,9-618,9-618_v2_85@0,9-618_v1_114@0,"• The precisions obtained using logistic regression and SVM models do not differ greatly from the value obtained using artificial neural networks, even exceeding them in complex artificial neural network configurations with three and four hidden layers.","• The precisions obtained using logistic regression and SVM models do not differ greatly from the value obtained using neural networks, even exceeding them in complex neural network configurations with three and four hidden layers.","Modify,Clarity",Clarity
11546,9-618,9-618_v2_87@0,9-618_v1_116@0,"• The values of accuracy and precision obtained using artificial neural network models do not favor the increase of hidden layers, leading to reduction phenomena in both metrics as the number of hidden layers and neurons increases, which is representative of overlearning processes.","• The values of accuracy and precision obtained using neural network models do not favor the increase of hidden layers, leading to reduction phenomena in both metrics as the number of hidden layers and neurons increases, which is representative of overlearning processes.","Modify,Clarity",Clarity
11547,9-618,9-618_v2_11@0,9-618_v1_10@0,"Discrimination among migraines with and without aura and other types of migraines and headaches is established based on the specific criteria established by the International Headache Society ( Charles, 2018 ; IHS, 2018 ; Rasmussen & Olesen, 1992 ; Viana et al. , 2017 ).","Discrimination among migraines with and without aura and other types of migraines and headaches is established based on the specific criteria established by the International Headache Society ( Charles, 2018 ; IHS, 2018 ; Rasmussen & Olesen, 1992 ; Viana et al. , 2017 ) as follows:","Modify,Clarity",Clarity
11548,9-618,9-618_v2_101@1,9-618_v1_122@1,"The results show that artificial neural networks can achieve higher precision and accuracy than other classification models commonly used in machine learning, which is consistent with the results found when compared with various models proposed in the literature.","The results show that neural networks can achieve higher precision and accuracy than other classification models commonly used in machine learning, which is consistent with the results found when compared with various models proposed in the literature.","Modify,Clarity",Clarity
11549,9-618,9-618_v2_101@2,9-618_v1_122@2,"The first experiments included 24 variables involved in migraine diagnosis, achieving a 97% precision level for the artificial neural network model.","The first experiments included 24 variables involved in migraine diagnosis, achieving a 97% precision level for the neural network model.","Modify,Clarity",Clarity
11550,9-618,9-618_v2_101@4,9-618_v1_122@4,This not only proves that the artificial neural network model is effective for the proper classification of the different types of migraine but shows that it can also be improved by considering a reduced set of variables that significantly affect the classification.,This not only proves that the neural network model is effective for the proper classification of the different types of migraine but shows that it can also be improved by considering a reduced set of variables that significantly affect the classification.,"Modify,Clarity",Clarity
11551,9-618,9-618_v2_102@0,9-618_v1_123@0,The implementation of migraine classification through artificial neural networks is a powerful tool whose potential has only incipiently been developed and which constitutes a valuable preliminary progress on the broad problem that automatic detection of migraines can encompass.,The implementation of migraine classification through neural networks is a powerful tool whose potential has only incipiently been developed and which constitutes a valuable preliminary progress on the broad problem that automatic detection of migraines can encompass.,"Modify,Clarity",Clarity
11552,9-618,9-618_v2_124@0,9-618_v1_145@0,This research is not a clinical trial and doesn’t involve any direct patient contact.,"This research is not a clinical trial, and doesn’t involve any direct patient contact.","Modify,Grammar",Grammar
11553,9-660,,9-660_v1_3@6,,Those will be stored in eLabFTW too.,"Delete,Fact/Evidence",Fact/Evidence
11554,9-660,,9-660_v1_24@5,,We hypothesize that robotic assays increase the value and innovation of our work.,"Delete,Claim",Claim
11555,9-660,9-660_v2_7@0,,"By sharing our motivation and experiences in this effort, the aim of this article is serve as a reference supply for other leadership staff, both from academic or technical background, dedicated to responsible research innovation.",,"Add,Fact/Evidence",Fact/Evidence
11556,9-660,9-660_v2_7@1,,"Given the persistent hurdles in overcoming the bridge from biomedical lab discoveries to socio-economic applications in most of the projects, even with successful project development and breakthrough character, we dedicate this article especially to stakeholders involved in translational research.",,"Add,Claim",Claim
11557,9-660,9-660_v2_7@2,,"This spans from bench/animal scientists, to application specialists, to academic professors as well as to opinion leaders of funding agencies, scientific journals and governmental policy.",,"Add,Claim",Claim
11558,9-660,9-660_v2_8@0,,"In our minds, laboratory quality is defined by highly accurate, efficient, transparent, data protective and through internal feedback algorithms constancy improving lab procedures.",,"Add,Claim",Claim
11559,9-660,9-660_v2_8@1,,Laboratory quality control (QC) is the supervised sum of all measures put in place to aiming to achieve those parameters as most comprehensively as possible.,,"Add,Claim",Claim
11560,9-660,9-660_v2_8@2,,"We believe QC ensures lab operations streamlined to more efficiently than without leading to economic efficacy (by reducing time and resources due to minimizing wasteful replications), user loyalty and trust in own data since QC aims to minimize untrustable results.",,"Add,Claim",Claim
11561,9-660,9-660_v2_8@3,,"In a large picture, the authors believe that QC will shorten the delay of introducing innovation in clinics and market.",,"Add,Claim",Claim
11562,9-660,9-660_v2_8@4,,"Thus, unlike as considered by traditional society assumptions to restrict the innovation character of a lab, and, although for academic labs certain flexibilities need to be secured by not too heavy QC restrictions, QC represents an innovation mark and competition advancement especially in regards to sustainability (of results).",,"Add,Claim",Claim
11563,9-660,9-660_v2_9@0,,Two main factors urged us to introduce more stringent and monitored QC strategies in our lab.,,"Add,Claim",Claim
11564,9-660,9-660_v2_9@1,,"First, using same cell models and substance, a follow up project on an established, prior by at least two independent scientists of our lab confirmed model of pharmacological mediated suppression of a molecular signaling pathway in vitro, a new third lab member had difficult to replicate the model to the same extend.",,"Add,Claim",Claim
11565,9-660,9-660_v2_9@2,,"In the search of inequalities in the experimental design amongst the conducted, we identified differences in the manufacturer of the drug candidate, outdated cell authentication certificate, or even lack of knowledge of the genetic identity of one of the used cell model, as well as inconsistency in documenting the age of the cells when stressing them with the drug as contributors to the situation.",,"Add,Fact/Evidence",Fact/Evidence
11566,9-660,9-660_v2_17@1,,Furthermore it allows the import and export in common file formats and is translated into various languages.,,"Add,Fact/Evidence",Fact/Evidence
11567,9-660,9-660_v2_17@2,,"An instance of eLabFTW is hosted on out universities own servers, which ensures high availability.",,"Add,Claim",Claim
11568,9-660,9-660_v2_19@9,,"The SOPs are built that way, that one SOP describes one specific process.",,"Add,Fact/Evidence",Fact/Evidence
11569,9-660,9-660_v2_19@10,,"For the example of a qPCR, this would be one SOP for RNA extraction, one for cDNA synthesis, and one for the qPCR itself.",,"Add,Claim",Claim
11570,9-660,9-660_v2_19@11,,"The SOPs cover every area of lab work, from cell culture, over molecular methods and buffer preparation, to lab maintenance and data management.",,"Add,Claim",Claim
11571,9-660,9-660_v2_22@2,,The nitrogen tank is used to store cell culture cryo vials only.,,"Add,Fact/Evidence",Fact/Evidence
11572,9-660,9-660_v2_22@3,,Other samples are stored in the freezer.,,"Add,Fact/Evidence",Fact/Evidence
11573,9-660,9-660_v2_26@1,,"Here also the state of the QMS is constantly revised by all lab members, and the further development is coordinated.",,"Add,Fact/Evidence",Fact/Evidence
11574,9-660,9-660_v2_30@4,,The implementation of eLabFTW was a rather quick process.,,"Add,Claim",Claim
11575,9-660,9-660_v2_30@7,,"As eLabFTW is an open source freeware, there were no additional costs by our lab to use it.",,"Add,Fact/Evidence",Fact/Evidence
11576,9-660,9-660_v2_30@8,,"Exept from the 4 users mentioned before, for existing users old data is still stored in hand written lab books, but new projects are documented electronically.",,"Add,Fact/Evidence",Fact/Evidence
11577,9-660,9-660_v2_30@9,,All new lab members will directly start documentation with the electronic lab book.,,"Add,Claim",Claim
11578,9-660,9-660_v2_31@5,,"In addition, we decided, that only one person should write the final version of the SOPs, to keep constant wording and style.",,"Add,Fact/Evidence",Fact/Evidence
11579,9-660,9-660_v2_31@6,,However other lab members handed in drafts and were involved in creating preliminary versions for specific SOPs.,,"Add,Fact/Evidence",Fact/Evidence
11580,9-660,9-660_v2_31@7,,"Now the addition of new SOPs is not very time consuming, as a draft will be created by the researcher who introduces a new method, after this method is refined, and the person responsible for creating SOPs will finalize them.",,"Add,Claim",Claim
11581,9-660,9-660_v2_32@6,,The SQL-Database was set up by our IT department.,,"Add,Fact/Evidence",Fact/Evidence
11582,9-660,9-660_v2_32@7,,Before that the samples have already been moved to the biobank and all necessary information was already stored in an Excel-File that could then be imported to the SQL-Database.,,"Add,Fact/Evidence",Fact/Evidence
11583,9-660,9-660_v2_32@8,,"Because SQL Servers are also available as freeware, there are no additional costs, then running a Server for a lab that wants to implement such a database.",,"Add,Claim",Claim
11584,9-660,9-660_v2_33@3,,"We found out that both, mycoplasma PCR and STR-Analysis are no big additional time costs.",,"Add,Fact/Evidence",Fact/Evidence
11585,9-660,9-660_v2_33@4,,The PCR can be set up in about 5 minutes and then runs for 2.5 hours in which regular lab work can be continued.,,"Add,Fact/Evidence",Fact/Evidence
11586,9-660,9-660_v2_33@5,,"As the STR-Analysis is done by an in-house service, we just need to provide the DNA which can be extracted in about 30 minutes.",,"Add,Fact/Evidence",Fact/Evidence
11587,9-660,,9-660_v1_3@2,,"Moreover, we restrict presentations of our actions on those for what we received a positive feedback by the users regarding its applicability.","Delete,Fact/Evidence",Fact/Evidence
11588,9-660,9-660_v2_3@2,9-660_v1_3@3,"For this we used eLabFTW, an electronic lab book, as hub for all other components of our Quality Management System (QMS) and digital storage of lab journals.","For this we used eLabFTW, an electronic lab book, as hub for all other components of our quality management system (QMS).","Merge+Modify,Clarity",Clarity
11589,9-660,9-660_v2_3@2,9-660_v1_3@4,"For this we used eLabFTW, an electronic lab book, as hub for all other components of our Quality Management System (QMS) and digital storage of lab journals.",Storage of lab journals and project management will be done there as well.,"Merge+Modify,Fact/Evidence",Fact/Evidence
11590,9-660,9-660_v2_3@3,9-660_v1_3@5,We introduced Standard Operation Procedures (SOPs) as well as a managed bio bank for safer long-term storage of bio samples.,Standard operation procedures have been introduced.,"Merge+Modify,Clarity",Clarity
11591,9-660,9-660_v2_3@3,9-660_v1_3@7,We introduced Standard Operation Procedures (SOPs) as well as a managed bio bank for safer long-term storage of bio samples.,"Furthermore, we implemented a bio bank for safer long term storage of bio samples and cryo-cultures of cell lines.","Merge+Modify,Clarity",Clarity
11592,9-660,9-660_v2_3@4,9-660_v1_3@8,"Next, we set up a lab meeting as feedback mechanism for the QMS.",Next we set up a lab meeting as feedback mechanism for the QMS.,"Modify,Grammar",Grammar
11593,9-660,9-660_v2_3@5,9-660_v1_3@9,"Finally, we implemented an automated pipeline to be used for example for drug screens.",In a final step we implemented an automated pipeline to be used for example for drug screens.,"Modify,Clarity",Clarity
11594,9-660,9-660_v2_33@8,9-660_v1_29@5,The introduction of the QMS leads to big project adjustments and in some case to termination of experiments.,The introduction of the QMS leads to significant project adjustments and in some case to termination of experiments.,"Modify,Clarity",Clarity
11595,9-660,9-660_v2_0@0,9-660_v1_0@0,An inexpensive and easy-to-implement approach to a Quality Management System for an academic research lab,Measures to increase value of preclinical research - an inexpensive and easy-to-implement approach to a QMS for an academic research lab,"Modify,Clarity",Clarity
11596,9-660,9-660_v2_36@1,9-660_v1_32@1,"Given the deliverables of the meetings have a large influence on future lab procedures, we have experienced an increase in involvement and commitment of responsible lab members in this effort.","Given the deliverables of the meetings have significant influence on future lab procedures, we have experienced a significant increase in involvement and commitment of responsible lab members in this effort.","Modify,Clarity",Clarity
11597,9-660,9-660_v2_10@0,9-660_v1_7@0,"Due to its immense documentation load, the establishment of a quality management system (QMS) certified with ISO 9001 standard <REF-1> in biomedical research labs, like ours (state-funded lab with less than 20 employees, only two of them being permanent positions, one being the lab head, the other a technician), is challenging.","Due to its immense documentation load, the establishment of a quality management system (QMS) certified with ISO 9001 standard <REF-1> in biomedical research labs is challenging.","Modify,Fact/Evidence",Fact/Evidence
11598,9-660,9-660_v2_37@1,9-660_v1_33@1,"We believe that the robustness and transparency of the data generation, as well as the simplicity of its use in supporting repetitive work procedures are the reasons for high attractiveness to many lab users and that robotic assays increase the value and innovation of our work.","We believe that the robustness and transparency of the data generation, as well as the simplicity of its use in supporting repetitive work procedures are the reasons for high attractiveness to many lab users.","Modify,Claim",Claim
11599,9-660,9-660_v2_16@8,9-660_v1_13@8,"The journal part of eLabFTW is used by each researcher to document their research, and for project management.","The journal part of eLabFTW will be used by each researcher to document their research, and for project management.","Modify,Grammar",Grammar
11600,9-660,9-660_v2_16@10,9-660_v1_13@10,The database part makes up the backbone of our QMS.,The database part will be the backbone of our QMS.,"Modify,Clarity",Clarity
11601,9-660,9-660_v2_16@13,9-660_v1_13@13,"All finished experiments are time stamped (digital signature), and blocked for editing from any user by the server itself.","All finished experiments will be time stamped (digital signature), and will be blocked for editing from any user by the server itself.","Modify,Grammar",Grammar
11602,9-660,9-660_v2_19@0,9-660_v1_15@0,SOPs are a main principle of most QMS.,SOPs (standard operating procedures) are a main principle of most QMS.,"Modify,Clarity",Clarity
11603,9-660,9-660_v2_22@4,9-660_v1_18@3,"Both, freezer and nitrogen tank, contain labelled boxes with designated positions for bio samples.",Both contain labelled boxes with designated positions for bio samples.,"Modify,Clarity",Clarity
11604,9-662,9-662_v2_2@0,9-662_v1_2@0,"The SMARCB1/INI1 gene was first discovered in the mid-1990s, and since then it has been revealed that loss of function mutations in this gene result in aggressive rhabdoid tumors.","The SMARCB1/INI1 gene was first discovered in the mid-1990’s, and since then it has been revealed that loss of function mutations in this gene result in aggressive rhabdoid tumors.","Modify,Grammar",Grammar
11605,9-662,9-662_v2_12@1,9-662_v1_12@1,"Following diagnosis in any age or organ, nearly all SMARCB1/INI1-deficient malignancies characteristically follow an aggressive clinical pattern and prognosis is often poor ( Table 1 ).","Following diagnosis in any age or organ, nearly all SMARCB1/INI1-deficient malignancies characteristically follow an aggressive clinical pattern and prognosis if often poor ( Table 1 ).","Modify,Grammar",Grammar
11606,9-662,9-662_v2_14@5,9-662_v1_14@5,"Despite the SMARCB1/INI1 gene being discovered in the mid-1990s, the majority of previous reports were excluded for not mentioning the tumor’s SMARCB1/INI1-deficiency status.","Despite the SMARCB1/INI1 gene being discovered in the mid-1990’s, the majority of previous reports were excluded for not mentioning the tumor’s SMARCB1/INI1-deficiency status.","Modify,Grammar",Grammar
11607,9-662,9-662_v2_4@1,9-662_v1_4@1,SMARCB1/INI1 was first identified in yeast in the late 1980s <REF-1> .,SMARCB1/INI1 was first identified in yeast in the late 1980’s <REF-1> .,"Modify,Grammar",Grammar
11608,9-662,9-662_v2_4@5,9-662_v1_4@5,It was revealed in the early 2000s by studies in mice that biallelic knockout of the SMARCB1/INI1 gene resulted in early lethality <REF-5> .,It was revealed in the early 2000’s by studies in mice that biallelic knockout of the SMARCB1/INI1 gene resulted in early lethality <REF-5> .,"Modify,Grammar",Grammar
11609,9-662,9-662_v2_21@2,9-662_v1_21@2,"Currently, the most widely used regimen for soft tissue sarcomas is termed AIM, which includes Adriamycin (doxorubicin) plus ifosfamide and mesna <REF-109> – <REF-111> .","Currently, the most widely used regimen for soft tissue sarcomas is termed AIM, which includes doxorubicin plus ifosfamide and mesna <REF-109> – <REF-111> .","Modify,Clarity",Clarity
11610,9-662,9-662_v2_2@2,9-662_v1_2@2,"When genetic aberrations in the SMARCB1/INI1 gene occur, the result can cause complete loss of expression, decreased expression, and mosaic expression.","When genetic aberrations in the SMARCB1/INI1 gene occur, the result can cause reduced, complete loss, and mosaic expression.","Modify,Clarity",Clarity
11611,9-662,9-662_v2_24@2,9-662_v1_24@2,"Pazopanib, a TKI that targets angiogenesis by inhibiting vascular endothelial growth factor receptor, PDGFRA/B, and KIT proto-oncogene, has been shown to improve progression free survival in certain histologic types of sarcoma.","Pazopanib, a TKI that targets angiogenesis by inhibiting vascular endothelial growth factor receptor, PDGFRA/B, and KIT, has been shown to improve progression free survival in certain histologic types of sarcoma.","Modify,Clarity",Clarity
11612,9-662,9-662_v2_25@1,9-662_v1_25@1,Targeting the mammalian target of rapamycin (mTOR) signaling pathway by serine/threonine kinase inhibition has been widely studied.,Targeting mTOR by serine/threonine kinase inhibition has been widely studied.,"Modify,Clarity",Clarity
11613,9-662,9-662_v2_26@0,9-662_v1_26@0,"Preliminary data from pre-clinical and phase I/II trials is encouraging for small molecule inhibitors, such as with Murine double minute 2 (MDM2)–antagonists, histone deacetylase inhibitors, and histone methylation inhibitors <REF-124> .","Preliminary data from pre-clinical and phase I/II trials is encouraging for small molecule inhibitors, such as with MDM2-antagonists, histone deacetylase inhibitors, and histone methylation inhibitors <REF-124> .","Modify,Clarity",Clarity
11614,9-662,9-662_v2_26@1,9-662_v1_26@1,A possible breakthrough in small molecular inhibition is represented by the recent discovery of a specific methyltransferase termed Enhancer of zeste homolog 2 (EZH2) is upregulated in SMARCB1/INI1-deficient tumors <REF-127> .,A possible breakthrough in small molecular inhibition is represented by the recent discovery of histone-lysine N-methyltransferase EZH2 upregulation in SMARCB1/INI1-deficient tumors <REF-127> .,"Modify,Clarity",Clarity
11615,9-662,9-662_v2_26@2,9-662_v1_26@2,"Given the defining characteristic of SMARCB1/INI1 deficiency in the nearly all soft tissue sarcomas, tazemetostat has emerged as an intriguing compound for its direct inhibition of histone-lysine N-methyltransferase EZH2 <REF-127> , <REF-138> .","Given the defining characteristic of SMARCB1/INI1 deficiency in the nearly all soft tissue sarcomas, tazemetostat has emerged as a highly intriguing compound for its direct inhibition of histone-lysine N-methyltransferase EZH2 <REF-138> , <REF-139> .","Modify,Other",Other
11616,9-668,,9-668_v1_17@0,,"Due to the potential for additional publications about cutaneous findings in COVID-19 patients and the possibility of confusion between the previously reported acronym for chilblains-like lesions (CLL) and chronic lymphocytic leukemia (CLL), we propose to precisely distinguish the nomenclature of these new dermatologic findings with the acronym of cutaneous chilblains-like lesions (CCLL).","Delete,Claim",Claim
11617,9-668,9-668_v2_18@0,,In a recent article the Hubiche T et al. reported positive COVID-19 serology in only 30% of patients who presented with chilblains-like lesions suggesting that chilblains-like lesions are associated with mild or asymptomatic SARS-CoV-2 infection <REF-8> .,,"Add,Fact/Evidence",Fact/Evidence
11618,9-668,9-668_v2_17@0,9-668_v1_17@1,This is the first report of reflectance confocal microscopy findings in chilblains-like lesions and the large number of dendritic antigen-presenting cells may be a distinguishing feature in its presentation.,"In addition, this is the first report of reflectance confocal microscopy findings in CCLL and the large number of dendritic antigen-presenting cells may be a distinguishing feature of CCLL.","Modify,Clarity",Clarity
11619,9-668,9-668_v2_17@1,9-668_v1_17@2,"Further studies are needed to determine if these RCM findings are exclusive to chilblains-like lesions, due to the negative COVID-19 result, or also found in traditional chilblains.",Further studies are needed to determine if these RCM findings are exclusive to CCLL or also found in traditional chilblains.,"Modify,Claim",Claim
11620,9-668,9-668_v2_17@2,9-668_v1_17@3,It is not possible to conclude that our patient had COVID-19-associated chilblains-like lesions because she did not have a positive viral or antibody test and may be a limitation to our findings.,It is not possible to conclude that our patient had COVID-19-associated CCLL because she did not have a positive viral or antibody test and may be a limitation to our findings.,"Modify,Clarity",Clarity
11621,9-668,9-668_v2_17@3,9-668_v1_17@4,"However, she did have a pattern of development that is highly suspicious for infection-induced chilblains-like lesions, including a history of respiratory and gastrointestinal symptoms, aged below 50 years, no comorbidities, a previous state of good health, lack of prior history of skin findings consistent with chilblains, lack of cold temperatures in the region, latency between mild systemic symptoms and the morphology of chilblains-like lesions and the development of similar finding in her pet cat.","However, she did have a pattern of development that is highly suspicious for infection-induced CCLL, including a history of respiratory and gastrointestinal symptoms, aged below 50 years, no comorbidities, a previous state of good health, lack of prior history of skin findings consistent with chilblains, lack of cold temperatures in the region, latency between mild systemic symptoms and the morphology of CCLL and the development of similar finding in her pet cat.","Modify,Clarity",Clarity
11622,9-668,9-668_v2_18@1,9-668_v1_18@0,"While our findings in combination may be coincidental, we hypothesize that there may be a delayed immune-mediated reaction to SARS-COV-2 in genetically predisposed patients who may test negative during a certain diagnostic window.","While these findings in combination may be coincidental, we hypothesize that there may be a delayed immune-mediated reaction to SARS-COV-2 in genetically predisposed patients who may test negative during a certain diagnostic window.","Modify,Clarity",Clarity
11623,9-668,9-668_v2_4@3,9-668_v1_4@3,"Chilblains-like lesions, described in multiple case reports from around the globe, have demonstrated either an erythematous-edematous or blistering skin lesion that mostly affects the toes and soles.","Cutaneous chilblains-like lesions (CCLL), described in multiple case reports from around the globe, have demonstrated either an erythematous-edematous or blistering skin lesion that mostly affects the toes and soles.","Modify,Clarity",Clarity
11624,9-668,9-668_v2_4@5,9-668_v1_4@5,"The majority of patients with chilblains-like lesions are generally in good health, without significant coronavirus symptoms, may have a recent history of mild upper respiratory symptoms, but no prior history of similar cutaneous lesions <REF-2> .","The majority of patients with CCLL are generally in good health, without significant coronavirus symptoms, may have a recent history of mild upper respiratory symptoms, but no prior history of similar cutaneous lesions <REF-2> .","Modify,Clarity",Clarity
11625,9-668,9-668_v2_4@7,9-668_v1_4@7,"During recent months, chilblains-like lesions has been reported in association with COVID-19, although the timing of these lesions relative to active infection appears to vary.","During recent months, CCLL has been reported in association with COVID-19, although the timing of these lesions relative to active infection appears to vary.","Modify,Clarity",Clarity
11626,9-668,9-668_v2_0@0,9-668_v1_0@0,Case Report: Chilblains-like lesions (COVID-19 toes) during the pandemic - is there a diagnostic window?,"Case Report: Cutaneous chilblains-like lesions (CCLL) versus COVID-19 toes during the pandemic. Confocal findings and proposal for new acronym, CCLL – is there a diagnostic window?","Modify,Other",Other
11627,9-668,9-668_v2_5@0,9-668_v1_5@0,"The ill-defined timing of presentation of chilblains-like lesions in confirmed COVID-19 positive patients may be associated with onset, progression or resolution of the disease.","The ill-defined timing of presentation of CCLL in confirmed COVID-19 positive patients may be associated with onset, progression or resolution of the disease.","Modify,Clarity",Clarity
11628,9-668,9-668_v2_5@1,9-668_v1_5@1,"Due to potentially unreliable and subjective patient reporting, lack of awareness that these lesions may be a symptom of COVID-19 disease, and limited coronavirus testing availability, the diagnosis of COVID-19 and/or chilblains-like lesions may be missed or unreported.","Due to potentially unreliable and subjective patient reporting, lack of awareness that these lesions may be a symptom of COVID-19 disease, and limited coronavirus testing availability, the diagnosis of COVID-19 and/or CCLL may be missed or unreported.","Modify,Clarity",Clarity
11629,9-668,9-668_v2_5@2,9-668_v1_5@2,"Based on our experience with the COVID-19 population in Oregon, we hypothesize that there may be a limited and possibly non-overlapping diagnostic window for COVID-19 infection and chilblains-like lesions.","Based on our experience with the COVID-19 population in Oregon, we hypothesize that there may be a limited and possibly non-overlapping diagnostic window for COVID-19 infection and CCLL.","Modify,Clarity",Clarity
11630,9-668,9-668_v2_5@3,9-668_v1_5@3,"If true, this could result in classic chilblains-like lesions features in the absence of a positive COVID-19 diagnostic test.","If true, this could result in classic CCLL features in the absence of a positive COVID-19 diagnostic test.","Modify,Clarity",Clarity
11631,9-668,9-668_v2_5@4,9-668_v1_5@4,"Here, we present the case of a 48-year-old healthy woman, who presented with chilblains-like lesions on her toes and tested as negative for COVID-19.","Here, we present the case of a 48-year-old healthy woman, who presented with CCLL on her toes and tested as negative for COVID-19.","Modify,Clarity",Clarity
11632,9-668,9-668_v2_7@0,9-668_v1_7@0,A 48-year-old healthy female patient presented to our hospital with chilblains-like lesions on her toes.,A 48-year-old healthy female patient presented to our hospital with CCLL on her toes.,"Modify,Clarity",Clarity
11633,9-668,9-668_v2_7@3,9-668_v1_7@3,"The patient reported upper respiratory symptoms four weeks prior to development of lesions, which included mild sore throat, non-productive cough, and chest pain.","The patient reported upper respiratory symptoms four weeks prior to development of cutaneous lesions, which included mild sore throat, non-productive cough, and chest pain.","Modify,Clarity",Clarity
11634,9-668,9-668_v2_7@8,9-668_v1_7@8,"The patient began developing small blisters on both her feet, starting with a single, isolated lesion on the bottom of one toe.","The patient began developing blister-like lesions on both her feet, starting with a single, isolated lesion on the bottom of one toe.","Modify,Clarity",Clarity
11635,9-668,9-668_v2_10@0,9-668_v1_10@0,A 3mm punch biopsy was taken on the patient’s third left lateral toe in the most prominent area of chilblains-like lesions findings approximately 2 weeks after the onset of lesions and during early stages of lesion resolution.,A 3mm punch biopsy was taken on the patient’s third left lateral toe in the most prominent area of CCLL findings approximately 2 weeks after the onset of lesions and during early stages of lesion resolution.,"Modify,Clarity",Clarity
11636,9-668,9-668_v2_2@2,9-668_v1_2@2,One such feature resembles chilblains and this case report represents a presentation of this feature with a 48-year-old female with violaceous lesions with surrounding pink erythema on her toes who tested negative for COVID-19.,One such feature resembles chilblains and this case report represents a unique presentation of this feature.,"Modify,Fact/Evidence",Fact/Evidence
11637,9-971,9-971_v2_11@1,,"Our program was obligatory for participants of a larger, very inclusive program so that to the best of our knowledge the only bias in the sample was some degree of affiliation with the Jewish people.",,"Add,Claim",Claim
11638,9-971,9-971_v2_13@2,,"Upon the completion of the educational program, the participants returned to their home countries.",,"Add,Fact/Evidence",Fact/Evidence
11639,9-971,9-971_v2_19@2,,We did not perform separate study of different cohorts since the data available for them would not be statistically significant.,,"Add,Fact/Evidence",Fact/Evidence
11640,9-971,9-971_v2_40@2,,"We will see below that on their own the distances do not allow the distributions’ comparison, however in conjunction with statistical analysis they become useful.",,"Add,Claim",Claim
11641,9-971,9-971_v2_111@1,9-971_v1_112@1,Any researchers wishing to access the underlying data can contact the corresponding author ( itzhak8@gmail.com ).,Any researchers wishing to access the underlying data can contact the corresponding author (itzhak8@gmail.com).,"Modify,Grammar",Grammar
11642,9-971,9-971_v2_19@4,9-971_v1_19@3,"Therefore, we divided the historical period spanned by our data into four periods (1858–1894, 1895–1930, 1931–1966, 1967–2001; Table 1 ).","Therefore, we divided the historical period spanned by our data into four periods (1858-1894, 1895-1930, 1931-1966, 1967-2001; Table 1 ).","Modify,Grammar",Grammar
11643,9-971,9-971_v2_2@8,9-971_v1_2@8,"We use the self-collected database that consists of 858 and 1057 of the first two groups, respectively, and 7471 generic Jewish surnames.","We use the database that consists of 858 and 1057 of the first two groups, respectively, and 7471 generic Jewish surnames.","Modify,Clarity",Clarity
11644,9-971,9-971_v2_30@7,9-971_v1_30@6,"The usage of the variables X i (k) is necessary for the statistical considerations as explained in detail below, otherwise they give an idea how the described laws apply in practice when the sample sizes are moderate.","The usage of the variables X i (k) is necessary for the statistical considerations explained in detail below, otherwise they give an idea how the described laws apply in practice when the sample sizes are moderate.","Modify,Grammar",Grammar
11645,9-971,9-971_v2_11@0,9-971_v1_11@0,"Our data was acquired over four years (November 2015 – February 2020) from individuals who were part of an educational family history program that was implemented by the Am haZikaron Institute for Science and Heritage of the Jewish People in Tel Aviv, Israel.","Our data was acquired over four years (November 2015 - February 2020) from individuals who were part of an educational family history program that was implemented by the Am haZikaron Institute for Science and Heritage of the Jewish People in Tel Aviv, Israel.","Modify,Grammar",Grammar
11646,9-971,9-971_v2_16@0,9-971_v1_16@0,"In the research by Clark et al. ( Clark, 2015 ; Clark, 2012 ; Clark et al., 2015 ), the major source of information were professional directories that list all individuals in a particular professional area.","In the research by Clark et al ( Clark, 2015 ; Clark, 2012 ; Clark et al., 2015 ), the major source of information were professional directories that list all individuals in a particular professional area.","Modify,Grammar",Grammar
11647,9-971,9-971_v2_100@0,9-971_v1_101@0,Discussion and conclusions,Discussion and Conclusions,"Modify,Grammar",Grammar
